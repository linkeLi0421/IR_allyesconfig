; ModuleID = '/llk/IR_all_yes/drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c_pt.bc'
source_filename = "../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c"
target datalayout = "E-m:e-p:32:32-Fi8-i64:64-v128:64:128-a:0:32-n32-S64"
target triple = "armebv6k-unknown-linux-gnueabi"

module asm ".syntax unified"

%struct.amd_ip_funcs = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.amdgpu_ip_block_version = type { i32, i32, i32, i32, ptr }
%struct.amdgpu_gfx_funcs = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.amdgpu_ring_funcs = type { i32, i32, i32, i8, i8, i32, i32, ptr, ptr, ptr, ptr, ptr, i32, i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.arm_delay_ops = type { ptr, ptr, ptr, i32 }
%struct.vi_de_ib_state = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_gds_reg_offset = type { i32, i32, i32, i32 }
%struct.vi_ce_ib_state = type { i32, i32, i32, i32 }
%struct.amdgpu_irq_src_funcs = type { ptr, ptr }
%struct.pi_entry = type { ptr, ptr, ptr, i32, ptr, ptr }
%struct.amdgpu_rlc_funcs = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.cs_section_def = type { ptr, i32 }
%struct.cs_extent_def = type { ptr, i32, i32 }
%struct.lock_class_key = type { %union.anon }
%union.anon = type { %struct.hlist_node }
%struct.hlist_node = type { ptr, ptr }
%struct.atomic_t = type { i32 }
%struct.amdgpu_device = type { ptr, ptr, %struct.drm_device, %struct.amdgpu_acp, ptr, i32, i32, i32, i32, i32, i32, i32, ptr, i8, i8, i8, %struct.notifier_block, [16 x ptr], %struct.debugfs_blob_wrapper, %struct.debugfs_blob_wrapper, %struct.mutex, %struct.mutex, %struct.dev_pm_domain, i8, i8, i8, ptr, i32, i32, [16 x i32], i32, i32, ptr, %struct.spinlock, %struct.amdgpu_mmio_remap, %struct.spinlock, ptr, ptr, %struct.spinlock, ptr, ptr, ptr, ptr, ptr, ptr, %struct.spinlock, ptr, ptr, %struct.spinlock, ptr, ptr, %struct.spinlock, ptr, ptr, %struct.spinlock, ptr, ptr, %struct.spinlock, ptr, ptr, %struct.amdgpu_doorbell, %struct.amdgpu_clock, %struct.amdgpu_gmc, %struct.amdgpu_gart, i32, %struct.amdgpu_vm_manager, [3 x %struct.amdgpu_vmhub], i32, %struct.amdgpu_mman, %struct.amdgpu_vram_scratch, %struct.amdgpu_wb, %struct.atomic64_t, %struct.atomic64_t, %struct.atomic64_t, %struct.atomic_t, %struct.atomic_t, %struct.anon.97, i8, ptr, %struct.amdgpu_mode_info, %struct.work_struct, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, i64, i32, [28 x ptr], i8, [3 x %struct.amdgpu_sa_manager], [9 x [3 x %struct.amdgpu_sched]], %struct.amdgpu_irq, %struct.amd_powerplay, i8, %struct.smu_context, %struct.amdgpu_pm, i32, i32, %struct.amdgpu_nbio, %struct.amdgpu_hdp, %struct.amdgpu_smuio, %struct.amdgpu_mmhub, %struct.amdgpu_gfxhub, %struct.amdgpu_gfx, %struct.amdgpu_sdma, %struct.amdgpu_uvd, %struct.amdgpu_vce, %struct.amdgpu_vcn, %struct.amdgpu_jpeg, %struct.amdgpu_firmware, %struct.psp_context, %struct.amdgpu_gds, %struct.amdgpu_kfd_dev, %struct.amdgpu_umc, %struct.amdgpu_display_manager, i8, %struct.amdgpu_mes, %struct.amdgpu_df, %struct.amdgpu_mca, [16 x %struct.amdgpu_ip_block], i32, i32, %struct.mutex, [128 x %struct.hlist_head], %struct.atomic64_t, %struct.atomic64_t, %struct.atomic64_t, [31 x [10 x ptr]], %struct.delayed_work, %struct.amdgpu_virt, %struct.list_head, %struct.mutex, i8, [64 x i8], i8, i8, i8, i8, %struct.atomic_t, i32, %struct.rw_semaphore, %struct.amdgpu_doorbell_index, %struct.mutex, i32, %struct.work_struct, %struct.list_head, i32, i32, i32, i32, i64, [4 x i64], i8, i8, i8, i8, i8, i8, [16 x i8], [64 x i8], [20 x i8], %struct.atomic_t, %struct.ratelimit_state, i32, i32, i8, ptr, i32, ptr, [31 x [10 x i32]], i8 }
%struct.drm_device = type { i32, %struct.kref, ptr, %struct.anon.79, ptr, ptr, ptr, ptr, i8, ptr, i32, i8, ptr, ptr, %struct.mutex, %struct.mutex, %struct.atomic_t, %struct.mutex, %struct.list_head, %struct.list_head, %struct.mutex, %struct.list_head, i8, ptr, %struct.spinlock, %struct.spinlock, i32, %struct.list_head, %struct.spinlock, i32, %struct.drm_mode_config, %struct.mutex, %struct.idr, ptr, ptr, i32, ptr, %struct.list_head, ptr, %struct.list_head, %struct.mutex, %struct.idr, %struct.list_head, %struct.drm_open_hash, %struct.list_head, ptr, i32, i32, %struct.spinlock, i32, %struct.atomic_t, %struct.anon.89, ptr, i32, ptr, i8, i32 }
%struct.kref = type { %struct.refcount_struct }
%struct.refcount_struct = type { %struct.atomic_t }
%struct.anon.79 = type { %struct.list_head, ptr, %struct.spinlock }
%struct.drm_mode_config = type { %struct.mutex, %struct.drm_modeset_lock, ptr, %struct.mutex, %struct.idr, %struct.idr, %struct.mutex, i32, %struct.list_head, %struct.spinlock, i32, %struct.ida, %struct.list_head, %struct.llist_head, %struct.work_struct, i32, %struct.list_head, i32, %struct.list_head, i32, %struct.list_head, %struct.list_head, %struct.list_head, i32, i32, i32, i32, ptr, i32, i8, i8, i8, %struct.delayed_work, %struct.mutex, %struct.list_head, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i32, i32, i8, i8, i8, i8, i8, i8, ptr, i32, i32, ptr, ptr }
%struct.drm_modeset_lock = type { %struct.ww_mutex, %struct.list_head }
%struct.ww_mutex = type { %struct.mutex, ptr, ptr }
%struct.ida = type { %struct.xarray }
%struct.xarray = type { %struct.spinlock, i32, ptr }
%struct.llist_head = type { ptr }
%struct.idr = type { %struct.xarray, i32, i32 }
%struct.drm_open_hash = type { ptr, i8 }
%struct.anon.89 = type { i32, ptr }
%struct.amdgpu_acp = type { ptr, ptr, ptr, ptr, ptr, ptr }
%struct.notifier_block = type { ptr, ptr, i32 }
%struct.debugfs_blob_wrapper = type { ptr, i32 }
%struct.dev_pm_domain = type { %struct.dev_pm_ops, ptr, ptr, ptr, ptr, ptr }
%struct.dev_pm_ops = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.amdgpu_mmio_remap = type { i32, i32 }
%struct.spinlock = type { %union.anon.0 }
%union.anon.0 = type { %struct.raw_spinlock }
%struct.raw_spinlock = type { %struct.arch_spinlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_spinlock_t = type { %union.anon.1 }
%union.anon.1 = type { i32 }
%struct.lockdep_map = type { ptr, [2 x ptr], ptr, i8, i8, i8, i32, i32 }
%struct.amdgpu_doorbell = type { i32, i32, ptr, i32 }
%struct.amdgpu_clock = type { [3 x %struct.amdgpu_pll], %struct.amdgpu_pll, %struct.amdgpu_pll, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_pll = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_gmc = type { i32, i32, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i32, i64, i32, i64, ptr, i32, %struct.amdgpu_irq_src, i32, i8, i32, i8, i32, i64, i64, i64, i64, %struct.spinlock, i8, ptr, %struct.atomic_t, [256 x %struct.amdgpu_gmc_fault], [256 x %struct.anon.96], i8, i8, ptr, %struct.amdgpu_xgmi, %struct.amdgpu_irq_src, i32, i32, i32, ptr, ptr }
%struct.amdgpu_gmc_fault = type { i56, %struct.atomic64_t }
%struct.anon.96 = type { i8, [7 x i8] }
%struct.amdgpu_xgmi = type { i64, i64, i64, i32, i32, %struct.list_head, i8, ptr, i8, i8, ptr }
%struct.amdgpu_gart = type { ptr, ptr, i32, i32, i32, i8, i64 }
%struct.amdgpu_vm_manager = type { [3 x %struct.amdgpu_vmid_mgr], i32, i8, i64, [28 x i32], i64, i32, i32, i32, i32, i64, ptr, [28 x ptr], i32, ptr, %struct.spinlock, %struct.atomic_t, i32, %struct.xarray }
%struct.amdgpu_vmid_mgr = type { %struct.mutex, i32, %struct.list_head, [16 x %struct.amdgpu_vmid], %struct.atomic_t }
%struct.amdgpu_vmid = type { %struct.list_head, %struct.amdgpu_sync, ptr, i64, i64, ptr, i32, i32, i32, i32, i32, i32, i32, i32, ptr }
%struct.amdgpu_sync = type { [16 x %struct.hlist_head], ptr }
%struct.hlist_head = type { ptr }
%struct.amdgpu_vmhub = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, ptr }
%struct.amdgpu_mman = type { %struct.ttm_device, i8, ptr, ptr, ptr, i8, %struct.mutex, %struct.drm_sched_entity, %struct.amdgpu_vram_mgr, %struct.amdgpu_gtt_mgr, %struct.amdgpu_preempt_mgr, i64, ptr, i64, ptr, i8, ptr, i64, i64, ptr, i32, ptr, i64, i64, ptr, ptr }
%struct.ttm_device = type { %struct.list_head, ptr, %struct.ttm_resource_manager, [8 x ptr], ptr, %struct.ttm_pool, %struct.spinlock, %struct.list_head, %struct.list_head, ptr, %struct.delayed_work }
%struct.ttm_resource_manager = type { i8, i8, i64, ptr, %struct.spinlock, [4 x %struct.list_head], ptr }
%struct.ttm_pool = type { ptr, i8, i8, [3 x %struct.anon.93] }
%struct.anon.93 = type { [12 x %struct.ttm_pool_type] }
%struct.ttm_pool_type = type { ptr, i32, i32, %struct.list_head, %struct.spinlock, %struct.list_head }
%struct.drm_sched_entity = type { %struct.list_head, ptr, ptr, i32, i32, %struct.spinlock, %struct.spsc_queue, %struct.atomic_t, i64, ptr, %struct.dma_fence_cb, ptr, ptr, ptr, i8, %struct.completion }
%struct.spsc_queue = type { ptr, %struct.atomic_t, %struct.atomic_t }
%struct.dma_fence_cb = type { %struct.list_head, ptr }
%struct.completion = type { i32, %struct.swait_queue_head }
%struct.swait_queue_head = type { %struct.raw_spinlock, %struct.list_head }
%struct.amdgpu_vram_mgr = type { %struct.ttm_resource_manager, %struct.drm_mm, %struct.spinlock, %struct.list_head, %struct.list_head, %struct.atomic64_t, %struct.atomic64_t }
%struct.drm_mm = type { ptr, %struct.list_head, %struct.drm_mm_node, %struct.rb_root_cached, %struct.rb_root_cached, %struct.rb_root, i32 }
%struct.drm_mm_node = type { i32, i64, i64, ptr, %struct.list_head, %struct.list_head, %struct.rb_node, %struct.rb_node, %struct.rb_node, i64, i64, i64, i32, i32 }
%struct.rb_node = type { i32, ptr, ptr }
%struct.rb_root_cached = type { %struct.rb_root, ptr }
%struct.rb_root = type { ptr }
%struct.amdgpu_gtt_mgr = type { %struct.ttm_resource_manager, %struct.drm_mm, %struct.spinlock, %struct.atomic64_t }
%struct.amdgpu_preempt_mgr = type { %struct.ttm_resource_manager, %struct.atomic64_t }
%struct.amdgpu_vram_scratch = type { ptr, ptr, i64 }
%struct.amdgpu_wb = type { ptr, ptr, i64, i32, [8 x i32] }
%struct.anon.97 = type { %struct.spinlock, i64, i64, i64, i32 }
%struct.amdgpu_mode_info = type { ptr, ptr, i8, [6 x ptr], [6 x ptr], [9 x ptr], ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i32, i32, ptr, i8, %struct.amdgpu_audio, i32, i32, i32, i32, ptr, ptr }
%struct.amdgpu_audio = type { i8, [9 x %struct.amdgpu_audio_pin], i32 }
%struct.amdgpu_audio_pin = type { i32, i32, i32, i8, i8, i32, i8, i32 }
%struct.amdgpu_irq_src = type { i32, ptr, ptr }
%struct.amdgpu_sa_manager = type { %struct.wait_queue_head, ptr, ptr, [32 x %struct.list_head], %struct.list_head, i32, i64, ptr, i32, i32 }
%struct.wait_queue_head = type { %struct.spinlock, %struct.list_head }
%struct.amdgpu_sched = type { i32, [8 x ptr] }
%struct.amdgpu_irq = type { i8, i32, %struct.spinlock, [32 x %struct.amdgpu_irq_client], i8, %struct.amdgpu_ih_ring, %struct.amdgpu_ih_ring, %struct.amdgpu_ih_ring, %struct.amdgpu_ih_ring, ptr, %struct.work_struct, %struct.work_struct, %struct.work_struct, %struct.amdgpu_irq_src, ptr, [256 x i32], i32 }
%struct.amdgpu_irq_client = type { ptr }
%struct.amdgpu_ih_ring = type { i32, i32, i32, i8, i8, ptr, ptr, i64, i64, ptr, i64, ptr, i8, i32, %struct.amdgpu_ih_regs, %struct.wait_queue_head, i64 }
%struct.amdgpu_ih_regs = type { i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amd_powerplay = type { ptr, ptr }
%struct.smu_context = type { ptr, %struct.amdgpu_irq_src, ptr, ptr, ptr, ptr, ptr, ptr, ptr, %struct.mutex, %struct.mutex, %struct.mutex, %struct.mutex, i64, %struct.smu_table_context, %struct.smu_dpm_context, %struct.smu_power_context, %struct.smu_feature, ptr, %struct.smu_baco_context, %struct.smu_temperature_range, ptr, %struct.smu_umd_pstate_table, i32, i32, i8, i32, i32, i32, i32, i32, ptr, i8, i8, i32, i32, i8, i32, [7 x i32], [7 x i32], i32, i32, i8, i8, i32, i32, i32, i8, i8, %struct.work_struct, %struct.atomic64_t, %struct.work_struct, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i16, %struct.smu_user_dpm_profile, %struct.stb_context }
%struct.smu_table_context = type { ptr, i32, ptr, i32, ptr, ptr, ptr, ptr, %struct.smu_bios_boot_up_values, ptr, ptr, [15 x %struct.smu_table], %struct.smu_table, %struct.smu_table, %struct.smu_table, i8, ptr, ptr, ptr, i32, ptr }
%struct.smu_bios_boot_up_values = type { i32, i32, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8, i32, i32, i32, i32, i32, i32 }
%struct.smu_table = type { i64, i32, i8, i64, ptr, ptr }
%struct.smu_dpm_context = type { i32, ptr, ptr, i8, i32, i32, i32, ptr, ptr, ptr }
%struct.smu_power_context = type { ptr, i32, %struct.smu_power_gate }
%struct.smu_power_gate = type { i8, i8, %struct.atomic_t, %struct.atomic_t, %struct.mutex, %struct.mutex }
%struct.smu_feature = type { i32, [2 x i32], [2 x i32], [2 x i32], %struct.mutex }
%struct.smu_baco_context = type { %struct.mutex, i32, i8 }
%struct.smu_temperature_range = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.smu_umd_pstate_table = type { %struct.pstates_clk_freq, %struct.pstates_clk_freq, %struct.pstates_clk_freq, %struct.pstates_clk_freq, %struct.pstates_clk_freq }
%struct.pstates_clk_freq = type { i32, i32, i32, %struct.smu_freq_info, %struct.smu_freq_info }
%struct.smu_freq_info = type { i32, i32, i32 }
%struct.smu_user_dpm_profile = type { i32, i32, i32, i32, i32, i32, [23 x i32], i32 }
%struct.stb_context = type { i32, i8, %struct.spinlock }
%struct.amdgpu_pm = type { %struct.mutex, i32, i32, i32, i32, ptr, i8, i32, ptr, i8, i8, i8, i8, i8, i8, %struct.amdgpu_dpm, ptr, i32, i32, i32, %struct.amd_pp_display_configuration, i32, ptr, i8, i32, %struct.i2c_adapter, %struct.mutex, %struct.list_head, [14 x %struct.atomic_t], i32 }
%struct.amdgpu_dpm = type { ptr, i32, ptr, ptr, ptr, ptr, i32, [6 x %struct.amd_vce_state], i32, i32, i32, i32, i32, i32, i32, i32, ptr, i32, i32, i32, i32, %struct.amdgpu_dpm_dynamic_state, %struct.amdgpu_dpm_fan, i32, i32, i32, i32, i32, i16, i32, i16, i8, i8, i8, i8, %struct.amdgpu_dpm_thermal, i32 }
%struct.amd_vce_state = type { i32, i32, i32, i32, i8, i8 }
%struct.amdgpu_dpm_dynamic_state = type { %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_uvd_clock_voltage_dependency_table, %struct.amdgpu_vce_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_voltage_dependency_table, %struct.amdgpu_clock_array, %struct.amdgpu_clock_array, %struct.amdgpu_clock_and_voltage_limits, %struct.amdgpu_clock_and_voltage_limits, i32, i32, i16, i16, %struct.amdgpu_cac_leakage_table, %struct.amdgpu_phase_shedding_limits_table, ptr, ptr }
%struct.amdgpu_uvd_clock_voltage_dependency_table = type { i8, ptr }
%struct.amdgpu_vce_clock_voltage_dependency_table = type { i8, ptr }
%struct.amdgpu_clock_voltage_dependency_table = type { i32, ptr }
%struct.amdgpu_clock_array = type { i32, ptr }
%struct.amdgpu_clock_and_voltage_limits = type { i32, i32, i16, i16 }
%struct.amdgpu_cac_leakage_table = type { i32, ptr }
%struct.amdgpu_phase_shedding_limits_table = type { i32, ptr }
%struct.amdgpu_dpm_fan = type { i16, i16, i16, i16, i16, i16, i8, i32, i16, i8, i16, i16, i16, i8 }
%struct.amdgpu_dpm_thermal = type { %struct.work_struct, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, %struct.amdgpu_irq_src }
%struct.amd_pp_display_configuration = type { i8, i8, i8, i32, i32, i32, i32, i32, i32, i32, i32, [32 x %struct.single_display_configuration], i32, i32, i8, i32, i32, i8, i32, i32, i32, i32 }
%struct.single_display_configuration = type { i32, i32, i32, i32, i8, i8, i8, i8, i32, i32, i32, i32, i32, i32 }
%struct.i2c_adapter = type { ptr, i32, ptr, ptr, ptr, %struct.rt_mutex, %struct.rt_mutex, i32, i32, %struct.device, i32, i32, [48 x i8], %struct.completion, %struct.mutex, %struct.list_head, ptr, ptr, ptr, ptr }
%struct.rt_mutex = type { %struct.rt_mutex_base, %struct.lockdep_map }
%struct.rt_mutex_base = type { %struct.raw_spinlock, %struct.rb_root_cached, ptr }
%struct.device = type { %struct.kobject, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, %struct.mutex, %struct.mutex, %struct.dev_links_info, %struct.dev_pm_info, ptr, ptr, ptr, %struct.dev_msi_info, ptr, ptr, i64, i64, ptr, ptr, %struct.list_head, ptr, ptr, %struct.dev_archdata, ptr, ptr, i32, i32, %struct.spinlock, %struct.list_head, ptr, ptr, ptr, ptr, ptr, i32, i8 }
%struct.kobject = type { ptr, %struct.list_head, ptr, ptr, ptr, ptr, %struct.kref, %struct.delayed_work, i8 }
%struct.dev_links_info = type { %struct.list_head, %struct.list_head, %struct.list_head, i32 }
%struct.dev_pm_info = type { %struct.pm_message, i16, i32, %struct.spinlock, %struct.list_head, %struct.completion, ptr, i8, %struct.hrtimer, i64, %struct.work_struct, %struct.wait_queue_head, ptr, %struct.atomic_t, %struct.atomic_t, i16, i32, i32, i32, i32, i32, i32, i64, i64, i64, i64, ptr, ptr, ptr }
%struct.pm_message = type { i32 }
%struct.hrtimer = type { %struct.timerqueue_node, i64, ptr, ptr, i8, i8, i8, i8 }
%struct.timerqueue_node = type { %struct.rb_node, i64 }
%struct.dev_msi_info = type { ptr, ptr }
%struct.dev_archdata = type { ptr, i8 }
%struct.amdgpu_nbio = type { ptr, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, ptr, ptr, ptr }
%struct.amdgpu_hdp = type { ptr, ptr, ptr }
%struct.amdgpu_smuio = type { ptr }
%struct.amdgpu_mmhub = type { ptr, ptr, ptr }
%struct.amdgpu_gfxhub = type { ptr }
%struct.amdgpu_gfx = type { %struct.mutex, %struct.amdgpu_gfx_config, %struct.amdgpu_rlc, %struct.amdgpu_pfp, %struct.amdgpu_ce, %struct.amdgpu_me, %struct.amdgpu_mec, %struct.amdgpu_kiq, %struct.amdgpu_scratch, ptr, i32, ptr, i32, ptr, i32, ptr, i32, ptr, i32, ptr, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, i8, i8, [2 x %struct.amdgpu_ring], i32, [8 x %struct.amdgpu_ring], i32, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.sq_work, i32, i32, %struct.amdgpu_cu_info, ptr, i32, i32, i8, %struct.mutex, i32, %struct.delayed_work, %struct.mutex, [4 x i32], ptr, ptr }
%struct.amdgpu_gfx_config = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [32 x i32], [16 x i32], %struct.gb_addr_config, [4 x [2 x %struct.amdgpu_rb_config]], i32, i32, i32, i32, i32, i64 }
%struct.gb_addr_config = type { i16, i8, i8, i8, i8, i8, i8 }
%struct.amdgpu_rb_config = type { i32, i32, i32, i32 }
%struct.amdgpu_rlc = type { ptr, i64, ptr, ptr, i32, ptr, i64, ptr, ptr, i32, ptr, i64, ptr, i32, i8, ptr, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i8, ptr, i64, ptr, ptr, i64, ptr }
%struct.amdgpu_pfp = type { ptr, i64, ptr }
%struct.amdgpu_ce = type { ptr, i64, ptr }
%struct.amdgpu_me = type { ptr, i64, ptr, i32, i32, i32, [2 x ptr], [4 x i32] }
%struct.amdgpu_mec = type { ptr, i64, ptr, i64, i32, i32, i32, [9 x ptr], [4 x i32] }
%struct.amdgpu_kiq = type { i64, ptr, %struct.spinlock, %struct.amdgpu_ring, %struct.amdgpu_irq_src, ptr }
%struct.amdgpu_ring = type { ptr, ptr, %struct.amdgpu_fence_driver, %struct.drm_gpu_scheduler, ptr, ptr, i32, i64, i64, i32, i32, i32, i64, i64, i32, i32, i32, i32, i32, ptr, i64, ptr, i64, i32, i8, i8, i32, i32, i64, [16 x i8], i32, i32, i64, ptr, i32, i64, ptr, i32, ptr, i8, i8, i32 }
%struct.amdgpu_fence_driver = type { i64, ptr, i32, %struct.atomic_t, i8, ptr, i32, %struct.timer_list, i32, %struct.spinlock, ptr }
%struct.timer_list = type { %struct.hlist_node, i32, ptr, i32, %struct.lockdep_map }
%struct.drm_gpu_scheduler = type { ptr, i32, i32, ptr, [4 x %struct.drm_sched_rq], %struct.wait_queue_head, %struct.wait_queue_head, %struct.atomic_t, %struct.atomic64_t, ptr, %struct.delayed_work, ptr, %struct.list_head, %struct.spinlock, i32, ptr, %struct.atomic_t, i8, i8 }
%struct.drm_sched_rq = type { %struct.spinlock, ptr, %struct.list_head, ptr }
%struct.amdgpu_scratch = type { i32, i32, i32 }
%struct.sq_work = type { %struct.work_struct, i32 }
%struct.amdgpu_cu_info = type { i32, i32, i32, i32, i32, i32, i32, [4 x [4 x i32]], [4 x [4 x i32]] }
%struct.amdgpu_sdma = type { [8 x %struct.amdgpu_sdma_instance], %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, i32, i32, i8, ptr, ptr }
%struct.amdgpu_sdma_instance = type { ptr, i32, i32, %struct.amdgpu_ring, %struct.amdgpu_ring, i8 }
%struct.amdgpu_uvd = type { ptr, i32, i32, i32, i8, i8, i8, [2 x %struct.amdgpu_uvd_inst], [40 x ptr], [40 x %struct.atomic_t], %struct.drm_sched_entity, %struct.delayed_work, i32, i32, i32, ptr }
%struct.amdgpu_uvd_inst = type { ptr, ptr, i64, ptr, %struct.amdgpu_ring, [2 x %struct.amdgpu_ring], %struct.amdgpu_irq_src, i32 }
%struct.amdgpu_vce = type { ptr, i64, ptr, ptr, i32, i32, [16 x %struct.atomic_t], [16 x ptr], [16 x i32], %struct.delayed_work, %struct.mutex, ptr, [3 x %struct.amdgpu_ring], %struct.amdgpu_irq_src, i32, %struct.drm_sched_entity, i32, i32 }
%struct.amdgpu_vcn = type { i32, %struct.delayed_work, ptr, i32, i32, i8, i8, [2 x %struct.amdgpu_vcn_inst], [2 x i8], %struct.amdgpu_vcn_reg, %struct.mutex, %struct.mutex, %struct.atomic_t, i32, ptr }
%struct.amdgpu_vcn_inst = type { ptr, ptr, i64, ptr, %struct.amdgpu_ring, [3 x %struct.amdgpu_ring], %struct.atomic_t, %struct.amdgpu_irq_src, %struct.amdgpu_vcn_reg, ptr, %struct.dpg_pause_state, ptr, i64, ptr, %struct.atomic_t, ptr, i64 }
%struct.dpg_pause_state = type { i32, i32 }
%struct.amdgpu_vcn_reg = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_jpeg = type { i8, [2 x %struct.amdgpu_jpeg_inst], %struct.amdgpu_jpeg_reg, i32, %struct.delayed_work, i32, %struct.mutex, %struct.atomic_t }
%struct.amdgpu_jpeg_inst = type { %struct.amdgpu_ring, %struct.amdgpu_irq_src, %struct.amdgpu_jpeg_reg }
%struct.amdgpu_jpeg_reg = type { i32 }
%struct.amdgpu_firmware = type { [35 x %struct.amdgpu_firmware_info], i32, ptr, i32, i32, ptr, ptr, %struct.mutex, ptr, ptr, i64 }
%struct.amdgpu_firmware_info = type { i32, ptr, i64, ptr, i32, i32, i32 }
%struct.psp_context = type { ptr, %struct.psp_ring, ptr, ptr, ptr, i64, ptr, ptr, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, %struct.psp_bin_desc, ptr, i64, ptr, ptr, ptr, i64, ptr, ptr, i64, ptr, %struct.atomic_t, i8, i8, ptr, i32, %struct.ta_context, %struct.psp_xgmi_context, %struct.psp_ras_context, %struct.ta_cp_context, %struct.ta_cp_context, %struct.ta_cp_context, %struct.ta_cp_context, %struct.mutex, %struct.psp_memory_training_context, i32 }
%struct.psp_ring = type { i32, ptr, i64, ptr, i32, i32 }
%struct.psp_bin_desc = type { i32, i32, i32, ptr }
%struct.ta_context = type { i8, i32, %struct.ta_mem_context, %struct.psp_bin_desc, i32 }
%struct.ta_mem_context = type { ptr, i64, ptr, i32 }
%struct.psp_xgmi_context = type { %struct.ta_context, %struct.psp_xgmi_topology_info, i8 }
%struct.psp_xgmi_topology_info = type { i32, [64 x %struct.psp_xgmi_node_info] }
%struct.psp_xgmi_node_info = type { i64, i8, i8, i32, i8 }
%struct.psp_ras_context = type { %struct.ta_context, ptr }
%struct.ta_cp_context = type { %struct.ta_context, %struct.mutex }
%struct.psp_memory_training_context = type { i64, ptr, i64, i64, ptr, i32, i32, i8 }
%struct.amdgpu_gds = type { i32, i32, i32, i32 }
%struct.amdgpu_kfd_dev = type { ptr, i64, i8 }
%struct.amdgpu_umc = type { i32, i32, i32, i32, ptr, ptr, ptr, ptr }
%struct.amdgpu_display_manager = type { ptr, ptr, ptr, [5 x ptr], [5 x i8], ptr, ptr, ptr, i64, ptr, i32, ptr, ptr, ptr, i16, %struct.drm_private_obj, %struct.mutex, %struct.mutex, ptr, i8, [99 x %struct.list_head], [99 x %struct.list_head], [7 x %struct.common_irq_params], [6 x %struct.common_irq_params], [6 x %struct.common_irq_params], [6 x %struct.common_irq_params], [1 x %struct.common_irq_params], [1 x %struct.common_irq_params], %struct.spinlock, [2 x ptr], [2 x ptr], i8, [2 x %struct.amdgpu_dm_backlight_caps], ptr, ptr, ptr, ptr, %struct.dm_compressor_info, ptr, i32, ptr, ptr, [6 x %struct.amdgpu_encoder], i8, i8, i8, %struct.list_head, %struct.completion, ptr, [2 x i32] }
%struct.drm_private_obj = type { %struct.list_head, %struct.drm_modeset_lock, ptr, ptr }
%struct.common_irq_params = type { ptr, i32, %struct.atomic64_t }
%struct.amdgpu_dm_backlight_caps = type { ptr, i32, i32, i32, i32, i8, i8 }
%struct.dm_compressor_info = type { ptr, ptr, i64 }
%struct.amdgpu_encoder = type { %struct.drm_encoder, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, %struct.drm_display_mode, ptr, i32, i8, i16 }
%struct.drm_encoder = type { ptr, %struct.list_head, %struct.drm_mode_object, ptr, i32, i32, i32, i32, ptr, %struct.list_head, ptr, ptr }
%struct.drm_mode_object = type { i32, i32, ptr, %struct.kref, ptr }
%struct.drm_display_mode = type { i32, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i32, i32, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i16, i8, i8, %struct.list_head, [32 x i8], i32, i32 }
%struct.amdgpu_mes = type { ptr, i32, i32, i32, i64, i64, %struct.amdgpu_ring, ptr, ptr, i64, ptr, i32, i64, ptr, i64, ptr, i32, i64, ptr, i64, ptr, i32, i32, [8 x i32], [2 x i32], [2 x i32], [5 x i32], i32, i64, ptr, i32, i64, ptr, ptr }
%struct.amdgpu_df = type { %struct.amdgpu_df_hash_status, ptr }
%struct.amdgpu_df_hash_status = type { i8, i8, i8 }
%struct.amdgpu_mca = type { ptr, %struct.amdgpu_mca_ras, %struct.amdgpu_mca_ras, %struct.amdgpu_mca_ras }
%struct.amdgpu_mca_ras = type { ptr, ptr }
%struct.amdgpu_ip_block = type { %struct.amdgpu_ip_block_status, ptr }
%struct.amdgpu_ip_block_status = type { i8, i8, i8, i8, i8 }
%struct.atomic64_t = type { i64 }
%struct.delayed_work = type { %struct.work_struct, %struct.timer_list, ptr, i32 }
%struct.amdgpu_virt = type { i32, ptr, ptr, i8, i32, %struct.amdgpu_irq_src, %struct.amdgpu_irq_src, %struct.work_struct, %struct.amdgpu_mm_table, ptr, %struct.amdgpu_vf_error_buffer, %struct.amdgpu_virt_fw_reserve, i32, i32, i32, i8, ptr, i8, i32, %struct.delayed_work, i32, i8, i32, i32, i32, i32 }
%struct.amdgpu_mm_table = type { ptr, ptr, i64 }
%struct.amdgpu_vf_error_buffer = type { %struct.mutex, i32, i32, [16 x i16], [16 x i16], [16 x i64] }
%struct.amdgpu_virt_fw_reserve = type { ptr, ptr, i32 }
%struct.rw_semaphore = type { %struct.atomic_t, %struct.atomic_t, %struct.optimistic_spin_queue, %struct.raw_spinlock, %struct.list_head, ptr, %struct.lockdep_map }
%struct.optimistic_spin_queue = type { %struct.atomic_t }
%struct.amdgpu_doorbell_index = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [8 x i32], i32, i32, %union.anon.108, i32, i32, i32, i32 }
%union.anon.108 = type { %struct.anon.110 }
%struct.anon.110 = type { i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.mutex = type { %struct.atomic_t, %struct.raw_spinlock, %struct.optimistic_spin_queue, %struct.list_head, ptr, %struct.lockdep_map }
%struct.work_struct = type { %struct.atomic_t, %struct.list_head, ptr, %struct.lockdep_map }
%struct.list_head = type { ptr, ptr }
%struct.ratelimit_state = type { %struct.raw_spinlock, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_ib = type { ptr, i32, i64, ptr, i32 }
%struct.dma_fence = type { ptr, ptr, %union.anon.85, i64, i64, i32, %struct.kref, i32 }
%union.anon.85 = type { i64 }
%struct.pci_dev = type <{ %struct.list_head, ptr, ptr, ptr, ptr, ptr, i32, i16, i16, i16, i16, i32, i8, i8, i16, ptr, ptr, ptr, i32, i8, i8, i8, i8, i8, i8, i16, ptr, ptr, i64, %struct.device_dma_parameters, i32, i8, i8, i24, [2 x i8], i32, i32, ptr, i8, i8, i16, i8, [3 x i8], i32, %struct.device, i32, i32, [17 x %struct.resource], i8, [5 x i8], i16, %struct.atomic_t, [16 x i32], %struct.hlist_head, i32, [17 x ptr], [17 x ptr], i8, i8, [2 x i8], ptr, %struct.raw_spinlock, %struct.pci_vpd, i16, i8, i8, %union.anon.78, i16, i8, i8, i16, [2 x i8], i32, i8, i8, i16, i16, i16, i32, i32, ptr, i32, [7 x i8], i8 }>
%struct.device_dma_parameters = type { i32, i32, i32 }
%struct.resource = type { i32, i32, ptr, i32, i32, ptr, ptr, ptr }
%struct.pci_vpd = type { %struct.mutex, i32, i8 }
%union.anon.78 = type { ptr }
%union.anon.113 = type { %struct.vi_de_ib_state_chained_ib }
%struct.vi_de_ib_state_chained_ib = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_job = type { %struct.drm_sched_job, ptr, %struct.amdgpu_sync, %struct.amdgpu_sync, ptr, %struct.dma_fence, ptr, i32, i32, i32, i8, i64, i32, i32, i32, i32, i32, i32, i32, i32, i32, i64, i64, i32 }
%struct.drm_sched_job = type { %struct.spsc_node, %struct.list_head, ptr, ptr, %union.anon.92, i64, %struct.atomic_t, i32, ptr, %struct.dma_fence_cb, %struct.xarray, i32 }
%struct.spsc_node = type { ptr }
%union.anon.92 = type { %struct.irq_work }
%struct.irq_work = type { %struct.__call_single_node, ptr, %struct.rcuwait }
%struct.__call_single_node = type { %struct.llist_node, %union.anon.20 }
%struct.llist_node = type { ptr }
%union.anon.20 = type { i32 }
%struct.rcuwait = type { ptr }
%struct.amdgpu_gmc_funcs = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.amdgpu_iv_entry = type { ptr, i32, i32, i32, i32, i32, i64, i32, i32, i32, [4 x i32], ptr }
%struct.firmware = type { i32, ptr, ptr }
%struct.common_firmware_header = type { i32, i32, i16, i16, i16, i16, i32, i32, i32, i32 }
%struct.gfx_firmware_header_v1_0 = type { %struct.common_firmware_header, i32, i32, i32 }
%struct.rlc_firmware_header_v2_0 = type { %struct.common_firmware_header, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.amdgpu_bo = type { i32, i32, [3 x %struct.ttm_place], %struct.ttm_placement, %struct.ttm_buffer_object, %struct.ttm_bo_kmap_obj, i64, ptr, ptr, %struct.mmu_interval_notifier, ptr }
%struct.ttm_place = type { i32, i32, i32, i32 }
%struct.ttm_placement = type { i32, ptr, i32, ptr }
%struct.ttm_buffer_object = type { %struct.drm_gem_object, ptr, i32, i32, ptr, %struct.kref, ptr, ptr, i8, %struct.list_head, %struct.list_head, ptr, i32, i32, ptr }
%struct.drm_gem_object = type { %struct.kref, i32, ptr, ptr, %struct.drm_vma_offset_node, i32, i32, ptr, ptr, ptr, %struct.dma_resv, ptr }
%struct.drm_vma_offset_node = type { %struct.rwlock_t, %struct.drm_mm_node, %struct.rb_root, ptr }
%struct.rwlock_t = type { %struct.arch_rwlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_rwlock_t = type { i32 }
%struct.dma_resv = type { %struct.ww_mutex, %struct.seqcount_ww_mutex, ptr, ptr }
%struct.seqcount_ww_mutex = type { %struct.seqcount, ptr }
%struct.seqcount = type { i32, %struct.lockdep_map }
%struct.ttm_bo_kmap_obj = type { ptr, ptr, i32, ptr }
%struct.mmu_interval_notifier = type { %struct.interval_tree_node, ptr, ptr, %struct.hlist_node, i32 }
%struct.interval_tree_node = type { %struct.rb_node, i32, i32, i32 }
%struct.vi_mqd_allocation = type { %struct.vi_mqd, i32, i32, i32, i32 }
%struct.vi_mqd = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [256 x i32] }

@__UNIQUE_ID_firmware343 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/carrizo_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware344 = internal constant [39 x i8] c"amdgpu.firmware=amdgpu/carrizo_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware345 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/carrizo_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware346 = internal constant [39 x i8] c"amdgpu.firmware=amdgpu/carrizo_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware347 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/carrizo_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware348 = internal constant [39 x i8] c"amdgpu.firmware=amdgpu/carrizo_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware349 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/stoney_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware350 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/stoney_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware351 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/stoney_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware352 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/stoney_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware353 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/stoney_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware354 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/tonga_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware355 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/tonga_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware356 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/tonga_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware357 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/tonga_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware358 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/tonga_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware359 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/tonga_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware360 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/topaz_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware361 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/topaz_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware362 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/topaz_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware363 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/topaz_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware364 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/topaz_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware365 = internal constant [35 x i8] c"amdgpu.firmware=amdgpu/fiji_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware366 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/fiji_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware367 = internal constant [35 x i8] c"amdgpu.firmware=amdgpu/fiji_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware368 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/fiji_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware369 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/fiji_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware370 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/fiji_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware371 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris10_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware372 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris10_ce_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware373 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris10_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware374 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris10_pfp_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware375 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris10_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware376 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris10_me_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware377 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris10_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware378 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris10_mec_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware379 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris10_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware380 = internal constant [44 x i8] c"amdgpu.firmware=amdgpu/polaris10_mec2_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware381 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris10_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware382 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris11_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware383 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris11_ce_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware384 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris11_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware385 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris11_pfp_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware386 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris11_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware387 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris11_me_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware388 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris11_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware389 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris11_mec_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware390 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris11_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware391 = internal constant [44 x i8] c"amdgpu.firmware=amdgpu/polaris11_mec2_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware392 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris11_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware393 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris12_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware394 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris12_ce_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware395 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris12_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware396 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris12_pfp_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware397 = internal constant [40 x i8] c"amdgpu.firmware=amdgpu/polaris12_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware398 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris12_me_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware399 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris12_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware400 = internal constant [43 x i8] c"amdgpu.firmware=amdgpu/polaris12_mec_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware401 = internal constant [42 x i8] c"amdgpu.firmware=amdgpu/polaris12_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware402 = internal constant [44 x i8] c"amdgpu.firmware=amdgpu/polaris12_mec2_2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware403 = internal constant [41 x i8] c"amdgpu.firmware=amdgpu/polaris12_rlc.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware404 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/vegam_ce.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware405 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/vegam_pfp.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware406 = internal constant [36 x i8] c"amdgpu.firmware=amdgpu/vegam_me.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware407 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/vegam_mec.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware408 = internal constant [38 x i8] c"amdgpu.firmware=amdgpu/vegam_mec2.bin\00", section ".modinfo", align 1
@__UNIQUE_ID_firmware409 = internal constant [37 x i8] c"amdgpu.firmware=amdgpu/vegam_rlc.bin\00", section ".modinfo", align 1
@gfx_v8_0_ip_funcs = internal constant { %struct.amd_ip_funcs, [44 x i8] } { %struct.amd_ip_funcs { ptr @.str, ptr @gfx_v8_0_early_init, ptr @gfx_v8_0_late_init, ptr @gfx_v8_0_sw_init, ptr @gfx_v8_0_sw_fini, ptr null, ptr @gfx_v8_0_hw_init, ptr @gfx_v8_0_hw_fini, ptr null, ptr @gfx_v8_0_suspend, ptr @gfx_v8_0_resume, ptr @gfx_v8_0_is_idle, ptr @gfx_v8_0_wait_for_idle, ptr @gfx_v8_0_check_soft_reset, ptr @gfx_v8_0_pre_soft_reset, ptr @gfx_v8_0_soft_reset, ptr @gfx_v8_0_post_soft_reset, ptr @gfx_v8_0_set_clockgating_state, ptr @gfx_v8_0_set_powergating_state, ptr @gfx_v8_0_get_clockgating_state, ptr null }, [44 x i8] zeroinitializer }, align 32
@gfx_v8_0_ip_block = dso_local constant { %struct.amdgpu_ip_block_version, [44 x i8] } { %struct.amdgpu_ip_block_version { i32 6, i32 8, i32 0, i32 0, ptr @gfx_v8_0_ip_funcs }, [44 x i8] zeroinitializer }, align 32
@gfx_v8_1_ip_block = dso_local constant { %struct.amdgpu_ip_block_version, [44 x i8] } { %struct.amdgpu_ip_block_version { i32 6, i32 8, i32 1, i32 0, ptr @gfx_v8_0_ip_funcs }, [44 x i8] zeroinitializer }, align 32
@.str = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"gfx_v8_0\00", [23 x i8] zeroinitializer }, align 32
@gfx_v8_0_gfx_funcs = internal constant { %struct.amdgpu_gfx_funcs, [32 x i8] } { %struct.amdgpu_gfx_funcs { ptr @gfx_v8_0_get_gpu_clock_counter, ptr @gfx_v8_0_select_se_sh, ptr @gfx_v8_0_read_wave_data, ptr null, ptr @gfx_v8_0_read_wave_sgprs, ptr @gfx_v8_0_select_me_pipe_q, ptr null, ptr null }, [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_ring_funcs_kiq = internal constant { %struct.amdgpu_ring_funcs, [32 x i8] } { %struct.amdgpu_ring_funcs { i32 9, i32 255, i32 -61440, i8 0, i8 0, i32 0, i32 0, ptr @gfx_v8_0_ring_get_rptr, ptr @gfx_v8_0_ring_get_wptr_compute, ptr @gfx_v8_0_ring_set_wptr_compute, ptr null, ptr null, i32 77, i32 7, ptr null, ptr @gfx_v8_0_ring_emit_fence_kiq, ptr null, ptr null, ptr null, ptr null, ptr @gfx_v8_0_ring_test_ring, ptr null, ptr @amdgpu_ring_insert_nop, ptr null, ptr null, ptr @amdgpu_ring_generic_pad_ib, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @gfx_v8_0_ring_emit_rreg, ptr @gfx_v8_0_ring_emit_wreg, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null }, [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_ring_funcs_gfx = internal constant { %struct.amdgpu_ring_funcs, [32 x i8] } { %struct.amdgpu_ring_funcs { i32 0, i32 255, i32 -61440, i8 0, i8 0, i32 0, i32 0, ptr @gfx_v8_0_ring_get_rptr, ptr @gfx_v8_0_ring_get_wptr_gfx, ptr @gfx_v8_0_ring_set_wptr_gfx, ptr null, ptr null, i32 172, i32 4, ptr @gfx_v8_0_ring_emit_ib_gfx, ptr @gfx_v8_0_ring_emit_fence_gfx, ptr @gfx_v8_0_ring_emit_pipeline_sync, ptr @gfx_v8_0_ring_emit_vm_flush, ptr @gfx_v8_0_ring_emit_hdp_flush, ptr @gfx_v8_0_ring_emit_gds_switch, ptr @gfx_v8_0_ring_test_ring, ptr @gfx_v8_0_ring_test_ib, ptr @amdgpu_ring_insert_nop, ptr null, ptr null, ptr @amdgpu_ring_generic_pad_ib, ptr @gfx_v8_0_ring_emit_init_cond_exec, ptr @gfx_v8_0_ring_emit_patch_cond_exec, ptr null, ptr null, ptr @gfx_v8_ring_emit_sb, ptr @gfx_v8_ring_emit_cntxcntl, ptr null, ptr @gfx_v8_0_ring_emit_wreg, ptr null, ptr null, ptr null, ptr @gfx_v8_0_ring_soft_recovery, ptr null, ptr @gfx_v8_0_emit_mem_sync, ptr null }, [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_ring_funcs_compute = internal constant { %struct.amdgpu_ring_funcs, [32 x i8] } { %struct.amdgpu_ring_funcs { i32 1, i32 255, i32 -61440, i8 0, i8 0, i32 0, i32 0, ptr @gfx_v8_0_ring_get_rptr, ptr @gfx_v8_0_ring_get_wptr_compute, ptr @gfx_v8_0_ring_set_wptr_compute, ptr null, ptr null, i32 109, i32 7, ptr @gfx_v8_0_ring_emit_ib_compute, ptr @gfx_v8_0_ring_emit_fence_compute, ptr @gfx_v8_0_ring_emit_pipeline_sync, ptr @gfx_v8_0_ring_emit_vm_flush, ptr @gfx_v8_0_ring_emit_hdp_flush, ptr @gfx_v8_0_ring_emit_gds_switch, ptr @gfx_v8_0_ring_test_ring, ptr @gfx_v8_0_ring_test_ib, ptr @amdgpu_ring_insert_nop, ptr null, ptr null, ptr @amdgpu_ring_generic_pad_ib, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @gfx_v8_0_ring_emit_wreg, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @gfx_v8_0_emit_mem_sync_compute, ptr @gfx_v8_0_emit_wave_limit }, [32 x i8] zeroinitializer }, align 32
@.str.1 = internal constant { [56 x i8], [40 x i8] } { [56 x i8] c"amdgpu: writing more dwords to the ring than expected!\0A\00", [40 x i8] zeroinitializer }, align 32
@arm_delay_ops = external dso_local local_unnamed_addr global %struct.arm_delay_ops, align 4
@__const.gfx_v8_0_ring_emit_de_meta.de_payload = private unnamed_addr constant { %struct.vi_de_ib_state, [40 x i8] } { %struct.vi_de_ib_state zeroinitializer, [40 x i8] c"\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF" }, align 4
@amdgpu_gds_reg_offset = internal constant { [16 x %struct.amdgpu_gds_reg_offset], [64 x i8] } { [16 x %struct.amdgpu_gds_reg_offset] [%struct.amdgpu_gds_reg_offset { i32 13056, i32 13057, i32 13088, i32 13104 }, %struct.amdgpu_gds_reg_offset { i32 13058, i32 13059, i32 13089, i32 13105 }, %struct.amdgpu_gds_reg_offset { i32 13060, i32 13061, i32 13090, i32 13106 }, %struct.amdgpu_gds_reg_offset { i32 13062, i32 13063, i32 13091, i32 13107 }, %struct.amdgpu_gds_reg_offset { i32 13064, i32 13065, i32 13092, i32 13108 }, %struct.amdgpu_gds_reg_offset { i32 13066, i32 13067, i32 13093, i32 13109 }, %struct.amdgpu_gds_reg_offset { i32 13068, i32 13069, i32 13094, i32 13110 }, %struct.amdgpu_gds_reg_offset { i32 13070, i32 13071, i32 13095, i32 13111 }, %struct.amdgpu_gds_reg_offset { i32 13072, i32 13073, i32 13096, i32 13112 }, %struct.amdgpu_gds_reg_offset { i32 13074, i32 13075, i32 13097, i32 13113 }, %struct.amdgpu_gds_reg_offset { i32 13076, i32 13077, i32 13098, i32 13114 }, %struct.amdgpu_gds_reg_offset { i32 13078, i32 13079, i32 13099, i32 13115 }, %struct.amdgpu_gds_reg_offset { i32 13080, i32 13081, i32 13100, i32 13116 }, %struct.amdgpu_gds_reg_offset { i32 13082, i32 13083, i32 13101, i32 13117 }, %struct.amdgpu_gds_reg_offset { i32 13084, i32 13085, i32 13102, i32 13118 }, %struct.amdgpu_gds_reg_offset { i32 13086, i32 13087, i32 13103, i32 13119 }], [64 x i8] zeroinitializer }, align 32
@__const.gfx_v8_0_ring_emit_ce_meta.ce_payload = private unnamed_addr constant { %struct.vi_ce_ib_state, [24 x i8] } { %struct.vi_ce_ib_state zeroinitializer, [24 x i8] c"\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF" }, align 4
@.str.2 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"invalid pipe %d\0A\00", [47 x i8] zeroinitializer }, align 32
@gfx_v8_0_eop_irq_funcs = internal constant { %struct.amdgpu_irq_src_funcs, [24 x i8] } { %struct.amdgpu_irq_src_funcs { ptr @gfx_v8_0_set_eop_interrupt_state, ptr @gfx_v8_0_eop_irq }, [24 x i8] zeroinitializer }, align 32
@gfx_v8_0_priv_reg_irq_funcs = internal constant { %struct.amdgpu_irq_src_funcs, [24 x i8] } { %struct.amdgpu_irq_src_funcs { ptr @gfx_v8_0_set_priv_reg_fault_state, ptr @gfx_v8_0_priv_reg_irq }, [24 x i8] zeroinitializer }, align 32
@gfx_v8_0_priv_inst_irq_funcs = internal constant { %struct.amdgpu_irq_src_funcs, [24 x i8] } { %struct.amdgpu_irq_src_funcs { ptr @gfx_v8_0_set_priv_inst_fault_state, ptr @gfx_v8_0_priv_inst_irq }, [24 x i8] zeroinitializer }, align 32
@gfx_v8_0_cp_ecc_error_irq_funcs = internal constant { %struct.amdgpu_irq_src_funcs, [24 x i8] } { %struct.amdgpu_irq_src_funcs { ptr @gfx_v8_0_set_cp_ecc_int_state, ptr @gfx_v8_0_cp_ecc_error_irq }, [24 x i8] zeroinitializer }, align 32
@gfx_v8_0_sq_irq_funcs = internal constant { %struct.amdgpu_irq_src_funcs, [24 x i8] } { %struct.amdgpu_irq_src_funcs { ptr @gfx_v8_0_set_sq_int_state, ptr @gfx_v8_0_sq_irq }, [24 x i8] zeroinitializer }, align 32
@.str.3 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"invalid me %d\0A\00", [17 x i8] zeroinitializer }, align 32
@.str.4 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"IH: CP EOP\0A\00", [20 x i8] zeroinitializer }, align 32
@.str.5 = internal constant { [43 x i8], [53 x i8] } { [43 x i8] c"Illegal register access in command stream\0A\00", [53 x i8] zeroinitializer }, align 32
@.str.6 = internal constant { [39 x i8], [57 x i8] } { [39 x i8] c"Illegal instruction in command stream\0A\00", [57 x i8] zeroinitializer }, align 32
@.str.7 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"CP EDC/ECC error detected.\00", [37 x i8] zeroinitializer }, align 32
@gfx_v8_0_parse_sq_irq._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.8, ptr @.str.9, ptr @.str.10, i32 6752, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.8 = internal constant { [200 x i8], [56 x i8] } { [200 x i8] c"\016[drm] SQ general purpose intr detected:se_id %d, immed_overflow %d, host_reg_overflow %d,host_cmd_overflow %d, cmd_timestamp %d,reg_timestamp %d, thread_trace_buff_full %d,wlt %d, thread_trace %d.\0A\00", [56 x i8] zeroinitializer }, align 32
@.str.9 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"gfx_v8_0_parse_sq_irq\00", [42 x i8] zeroinitializer }, align 32
@.str.10 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\00", [58 x i8] zeroinitializer }, align 32
@gfx_v8_0_parse_sq_irq._entry_ptr = internal global ptr @gfx_v8_0_parse_sq_irq._entry, section ".printk_index", align 4
@.str.11 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"instruction intr\00", [47 x i8] zeroinitializer }, align 32
@.str.12 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"EDC/ECC error\00", [18 x i8] zeroinitializer }, align 32
@gfx_v8_0_parse_sq_irq._entry.13 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.14, ptr @.str.9, ptr @.str.10, i32 6790, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.14 = internal constant { [119 x i8], [41 x i8] } { [119 x i8] c"\016[drm] SQ %s detected: se_id %d, sh_id %d, cu_id %d, simd_id %d, wave_id %d, vm_id %d trap %s, sq_ed_info.source %s.\0A\00", [41 x i8] zeroinitializer }, align 32
@gfx_v8_0_parse_sq_irq._entry_ptr.15 = internal global ptr @gfx_v8_0_parse_sq_irq._entry.13, section ".printk_index", align 4
@.str.16 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"true\00", [27 x i8] zeroinitializer }, align 32
@.str.17 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"false\00", [26 x i8] zeroinitializer }, align 32
@sq_edc_source_names = internal constant { [7 x ptr], [36 x i8] } { [7 x ptr] [ptr @.str.20, ptr @.str.21, ptr @.str.22, ptr @.str.23, ptr @.str.24, ptr @.str.25, ptr @.str.26], [36 x i8] zeroinitializer }, align 32
@.str.18 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"unavailable\00", [20 x i8] zeroinitializer }, align 32
@.str.19 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"SQ invalid encoding type\0A.\00", [37 x i8] zeroinitializer }, align 32
@.str.20 = internal constant { [54 x i8], [42 x i8] } { [54 x i8] c"SQ_EDC_INFO_SOURCE_INVALID: No EDC error has occurred\00", [42 x i8] zeroinitializer }, align 32
@.str.21 = internal constant { [57 x i8], [39 x i8] } { [57 x i8] c"SQ_EDC_INFO_SOURCE_INST: EDC source is Instruction Fetch\00", [39 x i8] zeroinitializer }, align 32
@.str.22 = internal constant { [63 x i8], [33 x i8] } { [63 x i8] c"SQ_EDC_INFO_SOURCE_SGPR: EDC source is SGPR or SQC data return\00", [33 x i8] zeroinitializer }, align 32
@.str.23 = internal constant { [44 x i8], [52 x i8] } { [44 x i8] c"SQ_EDC_INFO_SOURCE_VGPR: EDC source is VGPR\00", [52 x i8] zeroinitializer }, align 32
@.str.24 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"SQ_EDC_INFO_SOURCE_LDS: EDC source is LDS\00", [54 x i8] zeroinitializer }, align 32
@.str.25 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"SQ_EDC_INFO_SOURCE_GDS: EDC source is GDS\00", [54 x i8] zeroinitializer }, align 32
@.str.26 = internal constant { [40 x i8], [56 x i8] } { [40 x i8] c"SQ_EDC_INFO_SOURCE_TA: EDC source is TA\00", [56 x i8] zeroinitializer }, align 32
@system_wq = external dso_local local_unnamed_addr global ptr, align 4
@iceland_rlc_funcs = internal constant { %struct.amdgpu_rlc_funcs, [36 x i8] } { %struct.amdgpu_rlc_funcs { ptr @gfx_v8_0_is_rlc_enabled, ptr @gfx_v8_0_set_safe_mode, ptr @gfx_v8_0_unset_safe_mode, ptr @gfx_v8_0_rlc_init, ptr @gfx_v8_0_get_csb_size, ptr @gfx_v8_0_get_csb_buffer, ptr @gfx_v8_0_cp_jump_table_num, ptr @gfx_v8_0_rlc_resume, ptr @gfx_v8_0_rlc_stop, ptr @gfx_v8_0_rlc_reset, ptr @gfx_v8_0_rlc_start, ptr @gfx_v8_0_update_spm_vmid, ptr null, ptr null, ptr null }, [36 x i8] zeroinitializer }, align 32
@vi_cs_data = internal constant { [2 x %struct.cs_section_def], [16 x i8] } { [2 x %struct.cs_section_def] [%struct.cs_section_def { ptr @vi_SECT_CONTEXT_defs, i32 1 }, %struct.cs_section_def zeroinitializer], [16 x i8] zeroinitializer }, align 32
@vi_SECT_CONTEXT_defs = internal constant { [8 x %struct.cs_extent_def], [32 x i8] } { [8 x %struct.cs_extent_def] [%struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_1, i32 40960, i32 212 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_2, i32 41174, i32 274 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_3, i32 41461, i32 6 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_4, i32 41472, i32 157 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_5, i32 41632, i32 2 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_6, i32 41635, i32 1 }, %struct.cs_extent_def { ptr @vi_SECT_CONTEXT_def_7, i32 41637, i32 233 }, %struct.cs_extent_def zeroinitializer], [32 x i8] zeroinitializer }, align 32
@vi_SECT_CONTEXT_def_1 = internal constant { [212 x i32], [208 x i8] } { [212 x i32] [i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1073758208, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 -2147483648, i32 1073758208, i32 65535, i32 0, i32 1073758208, i32 0, i32 1073758208, i32 0, i32 1073758208, i32 0, i32 1073758208, i32 -1432769878, i32 0, i32 -1, i32 -1, i32 -2147483648, i32 1073758208, i32 0, i32 0, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 -2147483648, i32 1073758208, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216, i32 0, i32 1065353216], [208 x i8] zeroinitializer }, align 32
@vi_SECT_CONTEXT_def_3 = internal constant { [6 x i32], [40 x i8] } zeroinitializer, align 32
@vi_SECT_CONTEXT_def_4 = internal constant { [157 x i32], [140 x i8] } { [157 x i32] [i32 0, i32 0, i32 0, i32 0, i32 589824, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 256, i32 128, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0], [140 x i8] zeroinitializer }, align 32
@vi_SECT_CONTEXT_def_5 = internal constant { [2 x i32], [24 x i8] } zeroinitializer, align 32
@vi_SECT_CONTEXT_def_6 = internal constant { [1 x i32], [28 x i8] } zeroinitializer, align 32
@vi_SECT_CONTEXT_def_2 = internal constant { <{ [225 x i32], [49 x i32] }>, [280 x i8] } { <{ [225 x i32], [49 x i32] }> <{ [225 x i32] [i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 -1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2], [49 x i32] zeroinitializer }>, [280 x i8] zeroinitializer }, align 32
@vi_SECT_CONTEXT_def_7 = internal constant { <{ [115 x i32], [118 x i32] }>, [252 x i8] } { <{ [115 x i32], [118 x i32] }> <{ [115 x i32] [i32 0, i32 0, i32 0, i32 0, i32 0, i32 255, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 4096, i32 0, i32 5, i32 1065353216, i32 1065353216, i32 1065353216, i32 1065353216, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 -1, i32 -1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 30, i32 32], [118 x i32] zeroinitializer }>, [252 x i8] zeroinitializer }, align 32
@gfx_v8_0_wait_for_rlc_serdes._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.29, ptr @.str.30, ptr @.str.10, i32 3875, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.29 = internal constant { [43 x i8], [53 x i8] } { [43 x i8] c"\016[drm] Timeout wait for RLC serdes %u,%u\0A\00", [53 x i8] zeroinitializer }, align 32
@.str.30 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"gfx_v8_0_wait_for_rlc_serdes\00", [35 x i8] zeroinitializer }, align 32
@gfx_v8_0_wait_for_rlc_serdes._entry_ptr = internal global ptr @gfx_v8_0_wait_for_rlc_serdes._entry, section ".printk_index", align 4
@.str.31 = internal constant { [52 x i8], [44 x i8] } { [52 x i8] c"amdgpu_irq_get() failed to get IRQ for EDC, r: %d.\0A\00", [44 x i8] zeroinitializer }, align 32
@.str.32 = internal constant { [51 x i8], [45 x i8] } { [51 x i8] c"amdgpu_irq_get() failed to get IRQ for SQ, r: %d.\0A\00", [45 x i8] zeroinitializer }, align 32
@.str.33 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"amdgpu: failed to get ib (%d).\0A\00", [32 x i8] zeroinitializer }, align 32
@vgpr_init_compute_shader = internal constant { [66 x i32], [88 x i8] } { [66 x i32] [i32 2113929737, i32 2114060808, i32 2114191879, i32 2114322950, i32 2114454021, i32 2114585092, i32 2114716163, i32 2114847234, i32 2114978305, i32 2115109376, i32 2115240457, i32 2115371528, i32 2115502599, i32 2115633670, i32 2115764741, i32 2115895812, i32 2116026883, i32 2116157954, i32 2116289025, i32 2116420096, i32 2116551177, i32 2116682248, i32 2116813319, i32 2116944390, i32 2117075461, i32 2117206532, i32 2117337603, i32 2117468674, i32 2117599745, i32 2117730816, i32 2117861897, i32 2117992968, i32 2118124039, i32 2118255110, i32 2118386181, i32 2118517252, i32 2118648323, i32 2118779394, i32 2118910465, i32 2119041536, i32 2119172617, i32 2119303688, i32 2119434759, i32 2119565830, i32 2119696901, i32 2119827972, i32 2119959043, i32 2120090114, i32 2120221185, i32 2120352256, i32 2120483337, i32 2120614408, i32 2120745479, i32 2120876550, i32 2121007621, i32 2121138692, i32 2121269763, i32 2121400834, i32 2121531905, i32 2121662976, i32 2121794057, i32 2121925128, i32 2122056199, i32 2122187270, i32 -1081475072, i32 -1082064896], [88 x i8] zeroinitializer }, align 32
@sgpr_init_compute_shader = internal constant { [42 x i32], [56 x i8] } { [42 x i32] [i32 -1098252032, i32 -1098120958, i32 -1097989884, i32 -1097858810, i32 -1097727736, i32 -1097596672, i32 -1097465598, i32 -1097334524, i32 -1097203450, i32 -1097072376, i32 -1096941312, i32 -1096810238, i32 -1096679164, i32 -1096548090, i32 -1096417016, i32 -1096285952, i32 -1096154878, i32 -1096023804, i32 -1095892730, i32 -1095761656, i32 -1095630592, i32 -1095499518, i32 -1095368444, i32 -1095237370, i32 -1095106296, i32 -1094975232, i32 -1094844158, i32 -1094713084, i32 -1094582010, i32 -1094450936, i32 -1094319872, i32 -1094188798, i32 -1092222972, i32 -1092157435, i32 -1091960826, i32 -1091895289, i32 -1092091896, i32 -1092026359, i32 -1090781184, i32 -1081475072, i32 -1082064896, i32 0], [56 x i8] zeroinitializer }, align 32
@vgpr_init_regs = internal constant { [34 x i32], [56 x i8] } { [34 x i32] [i32 11798, i32 -1, i32 11797, i32 16777216, i32 11783, i32 1024, i32 11784, i32 1, i32 11785, i32 1, i32 11794, i32 16777295, i32 11795, i32 20, i32 11840, i32 -305210368, i32 11841, i32 -305210367, i32 11842, i32 -305210366, i32 11843, i32 -305210365, i32 11844, i32 -305210364, i32 11845, i32 -305210363, i32 11846, i32 -305210362, i32 11847, i32 -305210361, i32 11848, i32 -305210360, i32 11849, i32 -305210359], [56 x i8] zeroinitializer }, align 32
@sgpr1_init_regs = internal constant { [34 x i32], [56 x i8] } { [34 x i32] [i32 11798, i32 15, i32 11797, i32 16777216, i32 11783, i32 1280, i32 11784, i32 1, i32 11785, i32 1, i32 11794, i32 576, i32 11795, i32 20, i32 11840, i32 -305210368, i32 11841, i32 -305210367, i32 11842, i32 -305210366, i32 11843, i32 -305210365, i32 11844, i32 -305210364, i32 11845, i32 -305210363, i32 11846, i32 -305210362, i32 11847, i32 -305210361, i32 11848, i32 -305210360, i32 11849, i32 -305210359], [56 x i8] zeroinitializer }, align 32
@sgpr2_init_regs = internal constant { [34 x i32], [56 x i8] } { [34 x i32] [i32 11798, i32 240, i32 11797, i32 16777216, i32 11783, i32 1280, i32 11784, i32 1, i32 11785, i32 1, i32 11794, i32 576, i32 11795, i32 20, i32 11840, i32 -305210368, i32 11841, i32 -305210367, i32 11842, i32 -305210366, i32 11843, i32 -305210365, i32 11844, i32 -305210364, i32 11845, i32 -305210363, i32 11846, i32 -305210362, i32 11847, i32 -305210361, i32 11848, i32 -305210360, i32 11849, i32 -305210359], [56 x i8] zeroinitializer }, align 32
@.str.34 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"amdgpu: ib submit failed (%d).\0A\00", [32 x i8] zeroinitializer }, align 32
@.str.35 = internal constant { [33 x i8], [63 x i8] } { [33 x i8] c"amdgpu: fence wait failed (%d).\0A\00", [63 x i8] zeroinitializer }, align 32
@sec_ded_counter_registers = internal constant { [25 x i32], [60 x i8] } { [25 x i32] [i32 12688, i32 12686, i32 12687, i32 12682, i32 12681, i32 12680, i32 12684, i32 12685, i32 12683, i32 12690, i32 12691, i32 12689, i32 9669, i32 9670, i32 9671, i32 9284, i32 9139, i32 9120, i32 9122, i32 9123, i32 9121, i32 11138, i32 12977, i32 11031, i32 9518], [60 x i8] zeroinitializer }, align 32
@.str.36 = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"amdgpu_irq_add() for SQ failed: %d\0A\00", [60 x i8] zeroinitializer }, align 32
@gfx_v8_0_sw_init.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.37 = internal constant { [43 x i8], [53 x i8] } { [43 x i8] c"(work_completion)(&adev->gfx.sq_work.work)\00", [53 x i8] zeroinitializer }, align 32
@.str.38 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"Failed to load gfx firmware!\0A\00", [34 x i8] zeroinitializer }, align 32
@.str.39 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"Failed to init rlc BOs!\0A\00", [39 x i8] zeroinitializer }, align 32
@.str.40 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"Failed to init MEC BOs!\0A\00", [39 x i8] zeroinitializer }, align 32
@.str.42 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"Failed to init KIQ BOs!\0A\00", [39 x i8] zeroinitializer }, align 32
@.str.43 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"\0A\00", [30 x i8] zeroinitializer }, align 32
@.str.44 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"topaz\00", [26 x i8] zeroinitializer }, align 32
@.str.45 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"tonga\00", [26 x i8] zeroinitializer }, align 32
@.str.46 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"carrizo\00", [24 x i8] zeroinitializer }, align 32
@.str.47 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"fiji\00", [27 x i8] zeroinitializer }, align 32
@.str.48 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"stoney\00", [25 x i8] zeroinitializer }, align 32
@.str.49 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"polaris10\00", [22 x i8] zeroinitializer }, align 32
@.str.50 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"polaris11\00", [22 x i8] zeroinitializer }, align 32
@.str.51 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"polaris12\00", [22 x i8] zeroinitializer }, align 32
@.str.52 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"vegam\00", [26 x i8] zeroinitializer }, align 32
@.str.53 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"amdgpu/%s_pfp_2.bin\00", [44 x i8] zeroinitializer }, align 32
@.str.54 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"amdgpu/%s_pfp.bin\00", [46 x i8] zeroinitializer }, align 32
@.str.55 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"amdgpu/%s_me_2.bin\00", [45 x i8] zeroinitializer }, align 32
@.str.56 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"amdgpu/%s_me.bin\00", [47 x i8] zeroinitializer }, align 32
@.str.57 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"amdgpu/%s_ce_2.bin\00", [45 x i8] zeroinitializer }, align 32
@.str.58 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"amdgpu/%s_ce.bin\00", [47 x i8] zeroinitializer }, align 32
@gfx_v8_0_init_microcode._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.59, ptr @.str.60, ptr @.str.10, i32 1072, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.59 = internal constant { [37 x i8], [59 x i8] } { [37 x i8] c"\016[drm] Chained IB support enabled!\0A\00", [59 x i8] zeroinitializer }, align 32
@.str.60 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"gfx_v8_0_init_microcode\00", [40 x i8] zeroinitializer }, align 32
@gfx_v8_0_init_microcode._entry_ptr = internal global ptr @gfx_v8_0_init_microcode._entry, section ".printk_index", align 4
@.str.61 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"amdgpu/%s_rlc.bin\00", [46 x i8] zeroinitializer }, align 32
@.str.62 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"amdgpu/%s_mec_2.bin\00", [44 x i8] zeroinitializer }, align 32
@.str.63 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"amdgpu/%s_mec.bin\00", [46 x i8] zeroinitializer }, align 32
@.str.64 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"amdgpu/%s_mec2_2.bin\00", [43 x i8] zeroinitializer }, align 32
@.str.65 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"amdgpu/%s_mec2.bin\00", [45 x i8] zeroinitializer }, align 32
@gfx_v8_0_init_microcode._entry.66 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.67, ptr @.str.60, ptr @.str.10, i32 1235, ptr @.str.68, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.67 = internal constant { [44 x i8], [52 x i8] } { [44 x i8] c"amdgpu: gfx8: Failed to load firmware \22%s\22\0A\00", [52 x i8] zeroinitializer }, align 32
@.str.68 = internal constant { [3 x i8], [29 x i8] } { [3 x i8] c"\013\00", [29 x i8] zeroinitializer }, align 32
@.str.69 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"%s %s: \00", [24 x i8] zeroinitializer }, align 32
@gfx_v8_0_init_microcode._entry_ptr.70 = internal global ptr @gfx_v8_0_init_microcode._entry.66, section ".printk_index", align 4
@gfx_v8_0_mec_init._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.71, ptr @.str.72, ptr @.str.10, i32 1362, ptr @.str.73, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.71 = internal constant { [39 x i8], [57 x i8] } { [39 x i8] c"amdgpu: (%d) create HDP EOP bo failed\0A\00", [57 x i8] zeroinitializer }, align 32
@.str.72 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"gfx_v8_0_mec_init\00", [46 x i8] zeroinitializer }, align 32
@.str.73 = internal constant { [3 x i8], [29 x i8] } { [3 x i8] c"\014\00", [29 x i8] zeroinitializer }, align 32
@gfx_v8_0_mec_init._entry_ptr = internal global ptr @gfx_v8_0_mec_init._entry, section ".printk_index", align 4
@.str.74 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"comp_%d.%d.%d\00", [18 x i8] zeroinitializer }, align 32
@iceland_mgcg_cgcg_init = internal constant { [192 x i32], [192 x i8] } { [192 x i32] [i32 60488, i32 -1, i32 -1, i32 49664, i32 -1, i32 -536870912, i32 61608, i32 -1, i32 256, i32 61570, i32 -1, i32 256, i32 61616, i32 -1, i32 -1073741568, i32 61618, i32 -1, i32 -1073741568, i32 61617, i32 -1, i32 -1073741568, i32 61600, i32 -1, i32 256, i32 61573, i32 -1, i32 100663552, i32 61576, i32 -1, i32 256, i32 61574, i32 -1, i32 100663552, i32 61569, i32 -1, i32 256, i32 61624, i32 -1, i32 256, i32 61577, i32 -1, i32 256, i32 61568, i32 -1, i32 256, i32 61580, i32 -1, i32 256, i32 61581, i32 -1, i32 256, i32 61588, i32 -1, i32 256, i32 61589, i32 -1, i32 256, i32 61590, i32 -1, i32 256, i32 61591, i32 -1, i32 256, i32 61592, i32 -1, i32 256, i32 61599, i32 -1, i32 -16776960, i32 61598, i32 -1, i32 256, i32 61572, i32 -1, i32 100663552, i32 61604, i32 -1, i32 256, i32 61597, i32 -1, i32 256, i32 61613, i32 -1, i32 256, i32 61612, i32 -1, i32 256, i32 61596, i32 -1, i32 256, i32 49664, i32 -1, i32 -536870912, i32 61448, i32 -1, i32 65536, i32 61449, i32 -1, i32 196610, i32 61450, i32 -1, i32 260312967, i32 61451, i32 -1, i32 393221, i32 61452, i32 -1, i32 589832, i32 61453, i32 -1, i32 65536, i32 61454, i32 -1, i32 196610, i32 61455, i32 -1, i32 262151, i32 61456, i32 -1, i32 393221, i32 61457, i32 -1, i32 589832, i32 61458, i32 -1, i32 65536, i32 61459, i32 -1, i32 196610, i32 61460, i32 -1, i32 262151, i32 61461, i32 -1, i32 393221, i32 61462, i32 -1, i32 589832, i32 61463, i32 -1, i32 65536, i32 61464, i32 -1, i32 196610, i32 61465, i32 -1, i32 262151, i32 61466, i32 -1, i32 393221, i32 61467, i32 -1, i32 589832, i32 61468, i32 -1, i32 65536, i32 61469, i32 -1, i32 196610, i32 61470, i32 -1, i32 260312967, i32 61471, i32 -1, i32 393221, i32 61472, i32 -1, i32 589832, i32 61473, i32 -1, i32 65536, i32 61474, i32 -1, i32 196610, i32 61475, i32 -1, i32 262151, i32 61476, i32 -1, i32 393221, i32 61477, i32 -1, i32 589832, i32 61440, i32 -1, i32 -1763704320, i32 8642, i32 -1, i32 9437440, i32 60489, i32 -1, i32 2097212], [192 x i8] zeroinitializer }, align 32
@golden_settings_iceland_a11 = internal constant { [48 x i32], [32 x i8] } { [48 x i32] [i32 9859, i32 64, i32 64, i32 9741, i32 -267386881, i32 1024, i32 9742, i32 -1073741824, i32 -1073741824, i32 9792, i32 15, i32 0, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 41172, i32 1061158911, i32 2, i32 41173, i32 63, i32 0, i32 60489, i32 3, i32 60, i32 8963, i32 2097151, i32 1789, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11140, i32 2, i32 2, i32 11013, i32 1023, i32 241, i32 11012, i32 -1, i32 0, i32 11011, i32 -1, i32 16], [32 x i8] zeroinitializer }, align 32
@iceland_golden_common_all = internal constant { [24 x i32], [32 x i8] } { [24 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 2, i32 41173, i32 -1, i32 0, i32 9790, i32 -1, i32 570490881, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [32 x i8] zeroinitializer }, align 32
@fiji_mgcg_cgcg_init = internal constant { [105 x i32], [124 x i8] } { [105 x i32] [i32 60488, i32 -1, i32 -1, i32 49664, i32 -1, i32 -536870912, i32 61608, i32 -1, i32 256, i32 61570, i32 -1, i32 256, i32 61616, i32 -1, i32 256, i32 61618, i32 -1, i32 256, i32 61617, i32 -1, i32 1073742080, i32 61600, i32 -1, i32 256, i32 61573, i32 -1, i32 100663552, i32 61576, i32 -1, i32 256, i32 61574, i32 -1, i32 100663552, i32 61569, i32 -1, i32 256, i32 61624, i32 -1, i32 256, i32 61577, i32 -1, i32 256, i32 61568, i32 -1, i32 256, i32 61580, i32 -1, i32 256, i32 61581, i32 -1, i32 256, i32 61588, i32 -1, i32 256, i32 61589, i32 -1, i32 256, i32 61590, i32 -1, i32 256, i32 61591, i32 -1, i32 256, i32 61592, i32 -1, i32 256, i32 61599, i32 -1, i32 256, i32 61598, i32 -1, i32 256, i32 61572, i32 -1, i32 100663552, i32 61604, i32 -1, i32 256, i32 61597, i32 -1, i32 256, i32 61613, i32 -1, i32 256, i32 61612, i32 -1, i32 256, i32 61596, i32 -1, i32 256, i32 49664, i32 -1, i32 -536870912, i32 61440, i32 -1, i32 -1763704320, i32 8642, i32 -1, i32 9437440, i32 60489, i32 -1, i32 2097212, i32 12409, i32 1, i32 1], [124 x i8] zeroinitializer }, align 32
@golden_settings_fiji_a10 = internal constant { [33 x i32], [60 x i8] } { [33 x i32] [i32 9859, i32 511, i32 64, i32 9741, i32 -267386881, i32 1024, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 60489, i32 3, i32 65596, i32 8963, i32 2097151, i32 1789, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11140, i32 2, i32 2, i32 11013, i32 1023, i32 255, i32 8754, i32 4, i32 4], [60 x i8] zeroinitializer }, align 32
@fiji_golden_common_all = internal constant { [30 x i32], [40 x i8] } { [30 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 973084186, i32 41173, i32 -1, i32 46, i32 9790, i32 -1, i32 570494979, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367, i32 49664, i32 -1, i32 -536870912, i32 9295, i32 15, i32 9], [40 x i8] zeroinitializer }, align 32
@tonga_mgcg_cgcg_init = internal constant { [225 x i32], [252 x i8] } { [225 x i32] [i32 60488, i32 -1, i32 -1, i32 49664, i32 -1, i32 -536870912, i32 61608, i32 -1, i32 256, i32 61570, i32 -1, i32 256, i32 61616, i32 -1, i32 256, i32 61618, i32 -1, i32 256, i32 61617, i32 -1, i32 1073742080, i32 61600, i32 -1, i32 256, i32 61573, i32 -1, i32 100663552, i32 61576, i32 -1, i32 256, i32 61574, i32 -1, i32 100663552, i32 61569, i32 -1, i32 256, i32 61624, i32 -1, i32 256, i32 61577, i32 -1, i32 256, i32 61568, i32 -1, i32 256, i32 61580, i32 -1, i32 256, i32 61581, i32 -1, i32 256, i32 61588, i32 -1, i32 256, i32 61589, i32 -1, i32 256, i32 61590, i32 -1, i32 256, i32 61591, i32 -1, i32 256, i32 61592, i32 -1, i32 256, i32 61599, i32 -1, i32 256, i32 61598, i32 -1, i32 256, i32 61572, i32 -1, i32 100663552, i32 61604, i32 -1, i32 256, i32 61597, i32 -1, i32 256, i32 61613, i32 -1, i32 256, i32 61612, i32 -1, i32 256, i32 61596, i32 -1, i32 256, i32 49664, i32 -1, i32 -536870912, i32 61448, i32 -1, i32 65536, i32 61449, i32 -1, i32 196610, i32 61450, i32 -1, i32 262151, i32 61451, i32 -1, i32 393221, i32 61452, i32 -1, i32 589832, i32 61453, i32 -1, i32 65536, i32 61454, i32 -1, i32 196610, i32 61455, i32 -1, i32 262151, i32 61456, i32 -1, i32 393221, i32 61457, i32 -1, i32 589832, i32 61458, i32 -1, i32 65536, i32 61459, i32 -1, i32 196610, i32 61460, i32 -1, i32 262151, i32 61461, i32 -1, i32 393221, i32 61462, i32 -1, i32 589832, i32 61463, i32 -1, i32 65536, i32 61464, i32 -1, i32 196610, i32 61465, i32 -1, i32 262151, i32 61466, i32 -1, i32 393221, i32 61467, i32 -1, i32 589832, i32 61468, i32 -1, i32 65536, i32 61469, i32 -1, i32 196610, i32 61470, i32 -1, i32 262151, i32 61471, i32 -1, i32 393221, i32 61472, i32 -1, i32 589832, i32 61473, i32 -1, i32 65536, i32 61474, i32 -1, i32 196610, i32 61475, i32 -1, i32 262151, i32 61476, i32 -1, i32 393221, i32 61477, i32 -1, i32 589832, i32 61478, i32 -1, i32 65536, i32 61479, i32 -1, i32 196610, i32 61480, i32 -1, i32 262151, i32 61481, i32 -1, i32 393221, i32 61482, i32 -1, i32 589832, i32 61483, i32 -1, i32 65536, i32 61484, i32 -1, i32 196610, i32 61485, i32 -1, i32 262151, i32 61486, i32 -1, i32 393221, i32 61487, i32 -1, i32 589832, i32 61440, i32 -1, i32 -1763704320, i32 8642, i32 -1, i32 9437440, i32 60489, i32 -1, i32 2097212, i32 12409, i32 1, i32 1], [252 x i8] zeroinitializer }, align 32
@golden_settings_tonga_a11 = internal constant { [48 x i32], [32 x i8] } { [48 x i32] [i32 9860, i32 -134193, i32 29192, i32 9859, i32 64, i32 64, i32 9741, i32 -267386881, i32 1024, i32 9792, i32 15, i32 0, i32 8956, i32 -1, i32 536870913, i32 8853, i32 1023, i32 252, i32 49793, i32 65295, i32 0, i32 60489, i32 3, i32 60, i32 8963, i32 2097151, i32 1789, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11140, i32 2, i32 2, i32 11013, i32 1023, i32 763, i32 11012, i32 -1, i32 21563, i32 11011, i32 -1, i32 -1457452938, i32 8754, i32 4, i32 4], [32 x i8] zeroinitializer }, align 32
@tonga_golden_common_all = internal constant { [24 x i32], [32 x i8] } { [24 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 369098770, i32 41173, i32 -1, i32 42, i32 9790, i32 -1, i32 570494979, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [32 x i8] zeroinitializer }, align 32
@golden_settings_vegam_a11 = internal constant { [51 x i32], [52 x i8] } { [51 x i32] [i32 9860, i32 127951, i32 29192, i32 9862, i32 251658240, i32 218103808, i32 9859, i32 511, i32 64, i32 9741, i32 -267386881, i32 1024, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 41172, i32 1061158911, i32 973084186, i32 41173, i32 63, i32 46, i32 60489, i32 3, i32 65596, i32 60573, i32 -1, i32 65596, i32 8960, i32 133693440, i32 18350080, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11013, i32 1023, i32 247, i32 11012, i32 -1, i32 0, i32 11011, i32 -1, i32 846598228, i32 8754, i32 4, i32 4], [52 x i8] zeroinitializer }, align 32
@vegam_golden_common_all = internal constant { [18 x i32], [56 x i8] } { [18 x i32] [i32 49664, i32 -1, i32 -536870912, i32 9790, i32 -1, i32 570494979, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [56 x i8] zeroinitializer }, align 32
@golden_settings_polaris11_a11 = internal constant { [51 x i32], [52 x i8] } { [51 x i32] [i32 9860, i32 62415, i32 29192, i32 9862, i32 251658240, i32 251658240, i32 9859, i32 511, i32 64, i32 9741, i32 -267386881, i32 1024, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 41172, i32 1061158911, i32 369098770, i32 41173, i32 63, i32 0, i32 60489, i32 3, i32 65596, i32 60573, i32 -1, i32 65596, i32 8960, i32 133693440, i32 18350080, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11013, i32 1023, i32 243, i32 11012, i32 -1, i32 0, i32 11011, i32 -1, i32 12816, i32 8754, i32 4, i32 4], [52 x i8] zeroinitializer }, align 32
@polaris11_golden_common_all = internal constant { [18 x i32], [56 x i8] } { [18 x i32] [i32 49664, i32 -1, i32 -536870912, i32 9790, i32 -1, i32 570494978, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [56 x i8] zeroinitializer }, align 32
@golden_settings_polaris10_a11 = internal constant { [51 x i32], [52 x i8] } { [51 x i32] [i32 3284, i32 790464, i32 786944, i32 9860, i32 127951, i32 29192, i32 9862, i32 251658240, i32 251658240, i32 9859, i32 511, i32 64, i32 9741, i32 -267386881, i32 1024, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 41172, i32 1061158911, i32 369098770, i32 41173, i32 63, i32 42, i32 60489, i32 3, i32 65596, i32 60573, i32 -1, i32 65596, i32 8960, i32 133693440, i32 119013376, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11013, i32 1023, i32 247, i32 11012, i32 -1, i32 0, i32 8754, i32 4, i32 4], [52 x i8] zeroinitializer }, align 32
@polaris10_golden_common_all = internal constant { [24 x i32], [32 x i8] } { [24 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 369098770, i32 41173, i32 -1, i32 42, i32 9790, i32 -1, i32 570494979, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [32 x i8] zeroinitializer }, align 32
@cz_mgcg_cgcg_init = internal constant { [225 x i32], [252 x i8] } { [225 x i32] [i32 60488, i32 -1, i32 -1, i32 49664, i32 -1, i32 -536870912, i32 61608, i32 -1, i32 256, i32 61570, i32 -1, i32 256, i32 61616, i32 -1, i32 256, i32 61618, i32 -1, i32 256, i32 61617, i32 -1, i32 256, i32 61600, i32 -1, i32 256, i32 61573, i32 -1, i32 100663552, i32 61576, i32 -1, i32 256, i32 61574, i32 -1, i32 100663552, i32 61569, i32 -1, i32 256, i32 61624, i32 -1, i32 256, i32 61577, i32 -1, i32 256, i32 61568, i32 -1, i32 256, i32 61580, i32 -1, i32 256, i32 61581, i32 -1, i32 256, i32 61588, i32 -1, i32 256, i32 61589, i32 -1, i32 256, i32 61590, i32 -1, i32 256, i32 61591, i32 -1, i32 256, i32 61592, i32 -1, i32 256, i32 61599, i32 -1, i32 256, i32 61598, i32 -1, i32 256, i32 61572, i32 -1, i32 100663552, i32 61604, i32 -1, i32 256, i32 61597, i32 -1, i32 256, i32 61613, i32 -1, i32 256, i32 61612, i32 -1, i32 256, i32 61596, i32 -1, i32 256, i32 49664, i32 -1, i32 -536870912, i32 61448, i32 -1, i32 65536, i32 61449, i32 -1, i32 196610, i32 61450, i32 -1, i32 262151, i32 61451, i32 -1, i32 393221, i32 61452, i32 -1, i32 589832, i32 61453, i32 -1, i32 65536, i32 61454, i32 -1, i32 196610, i32 61455, i32 -1, i32 262151, i32 61456, i32 -1, i32 393221, i32 61457, i32 -1, i32 589832, i32 61458, i32 -1, i32 65536, i32 61459, i32 -1, i32 196610, i32 61460, i32 -1, i32 262151, i32 61461, i32 -1, i32 393221, i32 61462, i32 -1, i32 589832, i32 61463, i32 -1, i32 65536, i32 61464, i32 -1, i32 196610, i32 61465, i32 -1, i32 262151, i32 61466, i32 -1, i32 393221, i32 61467, i32 -1, i32 589832, i32 61468, i32 -1, i32 65536, i32 61469, i32 -1, i32 196610, i32 61470, i32 -1, i32 262151, i32 61471, i32 -1, i32 393221, i32 61472, i32 -1, i32 589832, i32 61473, i32 -1, i32 65536, i32 61474, i32 -1, i32 196610, i32 61475, i32 -1, i32 262151, i32 61476, i32 -1, i32 393221, i32 61477, i32 -1, i32 589832, i32 61478, i32 -1, i32 65536, i32 61479, i32 -1, i32 196610, i32 61480, i32 -1, i32 262151, i32 61481, i32 -1, i32 393221, i32 61482, i32 -1, i32 589832, i32 61483, i32 -1, i32 65536, i32 61484, i32 -1, i32 196610, i32 61485, i32 -1, i32 262151, i32 61486, i32 -1, i32 393221, i32 61487, i32 -1, i32 589832, i32 61440, i32 -1, i32 -1763704320, i32 8642, i32 -1, i32 9437440, i32 60489, i32 -1, i32 2097215, i32 12409, i32 1, i32 1], [252 x i8] zeroinitializer }, align 32
@cz_golden_settings_a11 = internal constant { [36 x i32], [48 x i8] } { [36 x i32] [i32 9859, i32 64, i32 64, i32 9741, i32 -267386881, i32 1024, i32 9792, i32 15, i32 0, i32 8956, i32 -1, i32 1, i32 49793, i32 65295, i32 0, i32 60489, i32 3, i32 60, i32 8963, i32 2097151, i32 1789, i32 9538, i32 983055, i32 65536, i32 11136, i32 1048576, i32 -216006785, i32 11140, i32 2, i32 2, i32 11013, i32 15, i32 243, i32 11011, i32 -1, i32 4866], [48 x i8] zeroinitializer }, align 32
@cz_golden_common_all = internal constant { [24 x i32], [32 x i8] } { [24 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 2, i32 41173, i32 -1, i32 0, i32 9790, i32 -1, i32 570490881, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [32 x i8] zeroinitializer }, align 32
@stoney_mgcg_cgcg_init = internal constant { [15 x i32], [36 x i8] } { [15 x i32] [i32 49664, i32 -1, i32 -536870912, i32 60489, i32 -1, i32 2097215, i32 12409, i32 -1, i32 131585, i32 60422, i32 -1, i32 131585, i32 61440, i32 -1, i32 -1768685056], [36 x i8] zeroinitializer }, align 32
@stoney_golden_settings_a11 = internal constant { [30 x i32], [40 x i8] } { [30 x i32] [i32 9741, i32 -267386881, i32 1024, i32 9792, i32 15, i32 0, i32 8956, i32 -1, i32 536870913, i32 49793, i32 65295, i32 0, i32 60489, i32 3, i32 65596, i32 9538, i32 983055, i32 720896, i32 11136, i32 1048576, i32 -216006785, i32 11140, i32 2, i32 2, i32 11013, i32 15, i32 241, i32 11011, i32 -1, i32 269488144], [40 x i8] zeroinitializer }, align 32
@stoney_golden_common_all = internal constant { [24 x i32], [32 x i8] } { [24 x i32] [i32 49664, i32 -1, i32 -536870912, i32 41172, i32 -1, i32 0, i32 41173, i32 -1, i32 0, i32 9790, i32 -1, i32 302055425, i32 12764, i32 -1, i32 2048, i32 12765, i32 -1, i32 2048, i32 12774, i32 -1, i32 16744383, i32 12775, i32 -1, i32 16744367], [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_tiling_mode_table_init._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.75, ptr @.str.76, ptr @.str.10, i32 3262, ptr @.str.73, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.75 = internal constant { [110 x i8], [50 x i8] } { [110 x i8] c"amdgpu: Unknown chip type (%d) in function gfx_v8_0_tiling_mode_table_init() falling through to CHIP_CARRIZO\0A\00", [50 x i8] zeroinitializer }, align 32
@.str.76 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"gfx_v8_0_tiling_mode_table_init\00", [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_tiling_mode_table_init._entry_ptr = internal global ptr @gfx_v8_0_tiling_mode_table_init._entry, section ".printk_index", align 4
@.str.77 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"unknown asic: 0x%x\0A\00", [44 x i8] zeroinitializer }, align 32
@amdgpu_bo_reserve._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.78, ptr @.str.79, ptr @.str.80, i32 179, ptr @.str.68, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.78 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"amdgpu: %p reserve failed\0A\00", [37 x i8] zeroinitializer }, align 32
@.str.79 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"amdgpu_bo_reserve\00", [46 x i8] zeroinitializer }, align 32
@.str.80 = internal constant { [53 x i8], [43 x i8] } { [53 x i8] c"drivers/gpu/drm/amd/amdgpu/../amdgpu/amdgpu_object.h\00", [43 x i8] zeroinitializer }, align 32
@amdgpu_bo_reserve._entry_ptr = internal global ptr @amdgpu_bo_reserve._entry, section ".printk_index", align 4
@.str.82 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"amdgpu: cp failed to lock ring (%d).\0A\00", [58 x i8] zeroinitializer }, align 32
@.str.83 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"Invalid KCQ enabled: %d\0A\00", [39 x i8] zeroinitializer }, align 32
@.str.84 = internal constant { [26 x i8], [38 x i8] } { [26 x i8] c"Failed to lock KIQ (%d).\0A\00", [38 x i8] zeroinitializer }, align 32
@gfx_v8_0_hw_fini.__UNIQUE_ID_ddebug418 = internal global { ptr, ptr, ptr, ptr, i8, i8, i8, i8, { { { %struct.atomic_t, { ptr } } } }, [4 x i8] } { ptr @.str.85, ptr @.str.86, ptr @.str.10, ptr @.str.87, i8 4, i8 -45, i8 -64, i8 0, { { { %struct.atomic_t, { ptr } } } } zeroinitializer, [4 x i8] undef }, section "__dyndbg", align 8
@.str.85 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"amdgpu\00", [25 x i8] zeroinitializer }, align 32
@.str.86 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"gfx_v8_0_hw_fini\00", [47 x i8] zeroinitializer }, align 32
@.str.87 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"For SRIOV client, shouldn't do anything.\0A\00", [54 x i8] zeroinitializer }, align 32
@.str.88 = internal constant { [50 x i8], [46 x i8] } { [50 x i8] c"amdgpu: For SRIOV client, shouldn't do anything.\0A\00", [46 x i8] zeroinitializer }, align 32
@gfx_v8_0_hw_fini._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.89, ptr @.str.86, ptr @.str.10, i32 4950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.89 = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"\013amdgpu: cp is busy, skip halt cp\0A\00", [60 x i8] zeroinitializer }, align 32
@gfx_v8_0_hw_fini._entry_ptr = internal global ptr @gfx_v8_0_hw_fini._entry, section ".printk_index", align 4
@gfx_v8_0_hw_fini._entry.90 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.91, ptr @.str.86, ptr @.str.10, i32 4954, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.91 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"\013amdgpu: rlc is busy, skip halt rlc\0A\00", [58 x i8] zeroinitializer }, align 32
@gfx_v8_0_hw_fini._entry_ptr.92 = internal global ptr @gfx_v8_0_hw_fini._entry.90, section ".printk_index", align 4
@.str.93 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"KCQ disable failed\0A\00", [44 x i8] zeroinitializer }, align 32
@gfx_v8_0_soft_reset._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.94, ptr @.str.95, ptr @.str.10, i32 5097, ptr @.str.96, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.94 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"amdgpu: GRBM_SOFT_RESET=0x%08X\0A\00", [32 x i8] zeroinitializer }, align 32
@.str.95 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"gfx_v8_0_soft_reset\00", [44 x i8] zeroinitializer }, align 32
@.str.96 = internal constant { [3 x i8], [29 x i8] } { [3 x i8] c"\016\00", [29 x i8] zeroinitializer }, align 32
@gfx_v8_0_soft_reset._entry_ptr = internal global ptr @gfx_v8_0_soft_reset._entry, section ".printk_index", align 4
@gfx_v8_0_soft_reset._entry.97 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.98, ptr @.str.95, ptr @.str.10, i32 5111, ptr @.str.96, ptr @.str.69 }, [40 x i8] zeroinitializer }, align 32
@.str.98 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"amdgpu: SRBM_SOFT_RESET=0x%08X\0A\00", [32 x i8] zeroinitializer }, align 32
@gfx_v8_0_soft_reset._entry_ptr.99 = internal global ptr @gfx_v8_0_soft_reset._entry.97, section ".printk_index", align 4
@switch.table.gfx_v8_0_sw_init = internal constant { [8 x i32], [32 x i8] } { [8 x i32] [i32 2, i32 2, i32 2, i32 1, i32 2, i32 2, i32 2, i32 2], [32 x i8] zeroinitializer }, align 32
@switch.table.gfx_v8_0_hw_init = internal constant { [9 x i32], [60 x i8] } { [9 x i32] [i32 2, i32 369098770, i32 973084186, i32 2, i32 0, i32 369098770, i32 369098770, i32 369098770, i32 973084186], [60 x i8] zeroinitializer }, align 32
@switch.table.gfx_v8_0_hw_init.100 = internal constant { [9 x i32], [60 x i8] } { [9 x i32] [i32 0, i32 42, i32 46, i32 0, i32 0, i32 42, i32 0, i32 0, i32 46], [60 x i8] zeroinitializer }, align 32
@__sancov_gen_cov_switch_values = internal global [4 x i64] [i64 2, i64 32, i64 10, i64 14]
@__sancov_gen_cov_switch_values.101 = internal global [11 x i64] [i64 9, i64 32, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.102 = internal global [5 x i64] [i64 3, i64 16, i64 1192, i64 2871, i64 38016]
@__sancov_gen_cov_switch_values.103 = internal global [11 x i64] [i64 9, i64 32, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.104 = internal global [6 x i64] [i64 4, i64 32, i64 7, i64 12, i64 17, i64 23]
@__sancov_gen_cov_switch_values.105 = internal global [6 x i64] [i64 4, i64 32, i64 7, i64 12, i64 17, i64 23]
@__sancov_gen_cov_switch_values.106 = internal global [6 x i64] [i64 4, i64 32, i64 7, i64 12, i64 17, i64 23]
@__sancov_gen_cov_switch_values.107 = internal global [5 x i64] [i64 3, i64 32, i64 1, i64 2, i64 4]
@__sancov_gen_cov_switch_values.108 = internal global [10 x i64] [i64 8, i64 32, i64 11, i64 12, i64 13, i64 14, i64 15, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.109 = internal global [7 x i64] [i64 5, i64 32, i64 13, i64 14, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.110 = internal global [4 x i64] [i64 2, i64 32, i64 1, i64 9]
@__sancov_gen_cov_switch_values.111 = internal global [4 x i64] [i64 2, i64 32, i64 1, i64 2]
@__sancov_gen_cov_switch_values.112 = internal global [11 x i64] [i64 9, i64 32, i64 0, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i64 8, i64 9]
@__sancov_gen_cov_switch_values.113 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 1]
@__sancov_gen_cov_switch_values.114 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 1]
@__sancov_gen_cov_switch_values.115 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 1]
@__sancov_gen_cov_switch_values.116 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 1]
@__sancov_gen_cov_switch_values.117 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 1, i64 2]
@__sancov_gen_cov_switch_values.118 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 1, i64 2]
@__sancov_gen_cov_switch_values.119 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 1, i64 2]
@__sancov_gen_cov_switch_values.120 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 1]
@__sancov_gen_cov_switch_values.121 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 1, i64 2]
@__sancov_gen_cov_switch_values.122 = internal global [7 x i64] [i64 5, i64 32, i64 13, i64 14, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.123 = internal global [11 x i64] [i64 9, i64 32, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.124 = internal global [4 x i64] [i64 2, i64 32, i64 10, i64 14]
@__sancov_gen_cov_switch_values.125 = internal global [11 x i64] [i64 9, i64 32, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15, i64 16, i64 17, i64 18]
@__sancov_gen_cov_switch_values.126 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 3, i64 4]
@__sancov_gen_cov_switch_values.127 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 3, i64 4]
@__sancov_gen_cov_switch_values.128 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 3, i64 4]
@__sancov_gen_cov_switch_values.129 = internal global [5 x i64] [i64 3, i64 32, i64 0, i64 3, i64 4]
@__sancov_gen_cov_switch_values.130 = internal global [4 x i64] [i64 2, i64 32, i64 2, i64 4]
@__sancov_gen_cov_switch_values.131 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 4294966784]
@__sancov_gen_cov_switch_values.132 = internal global [4 x i64] [i64 2, i64 32, i64 0, i64 4294966784]
@___asan_gen_.133 = private unnamed_addr constant [18 x i8] c"gfx_v8_0_ip_funcs\00", align 1
@___asan_gen_.135 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6915, i32 34 }
@___asan_gen_.136 = private unnamed_addr constant [18 x i8] c"gfx_v8_0_ip_block\00", align 1
@___asan_gen_.138 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7193, i32 38 }
@___asan_gen_.139 = private unnamed_addr constant [18 x i8] c"gfx_v8_1_ip_block\00", align 1
@___asan_gen_.141 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7202, i32 38 }
@___asan_gen_.144 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6916, i32 10 }
@___asan_gen_.145 = private unnamed_addr constant [19 x i8] c"gfx_v8_0_gfx_funcs\00", align 1
@___asan_gen_.147 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5295, i32 38 }
@___asan_gen_.148 = private unnamed_addr constant [24 x i8] c"gfx_v8_0_ring_funcs_kiq\00", align 1
@___asan_gen_.150 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7017, i32 39 }
@___asan_gen_.151 = private unnamed_addr constant [24 x i8] c"gfx_v8_0_ring_funcs_gfx\00", align 1
@___asan_gen_.153 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6936, i32 39 }
@___asan_gen_.154 = private unnamed_addr constant [28 x i8] c"gfx_v8_0_ring_funcs_compute\00", align 1
@___asan_gen_.156 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6983, i32 39 }
@___asan_gen_.158 = private unnamed_addr constant [54 x i8] c"../drivers/gpu/drm/amd/amdgpu/../amdgpu/amdgpu_ring.h\00", align 1
@___asan_gen_.159 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.158, i32 314, i32 3 }
@___asan_gen_.160 = private unnamed_addr constant [22 x i8] c"amdgpu_gds_reg_offset\00", align 1
@___asan_gen_.162 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 177, i32 43 }
@___asan_gen_.165 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6880, i32 3 }
@___asan_gen_.166 = private unnamed_addr constant [23 x i8] c"gfx_v8_0_eop_irq_funcs\00", align 1
@___asan_gen_.168 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7054, i32 42 }
@___asan_gen_.169 = private unnamed_addr constant [28 x i8] c"gfx_v8_0_priv_reg_irq_funcs\00", align 1
@___asan_gen_.171 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7059, i32 42 }
@___asan_gen_.172 = private unnamed_addr constant [29 x i8] c"gfx_v8_0_priv_inst_irq_funcs\00", align 1
@___asan_gen_.174 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7064, i32 42 }
@___asan_gen_.175 = private unnamed_addr constant [32 x i8] c"gfx_v8_0_cp_ecc_error_irq_funcs\00", align 1
@___asan_gen_.177 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7069, i32 42 }
@___asan_gen_.178 = private unnamed_addr constant [22 x i8] c"gfx_v8_0_sq_irq_funcs\00", align 1
@___asan_gen_.180 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 7074, i32 42 }
@___asan_gen_.183 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6489, i32 3 }
@___asan_gen_.186 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6649, i32 2 }
@___asan_gen_.189 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6704, i32 2 }
@___asan_gen_.192 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6713, i32 2 }
@___asan_gen_.195 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6722, i32 2 }
@___asan_gen_.207 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6738, i32 4 }
@___asan_gen_.210 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6776, i32 19 }
@___asan_gen_.213 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6778, i32 19 }
@___asan_gen_.226 = private unnamed_addr constant [20 x i8] c"sq_edc_source_names\00", align 1
@___asan_gen_.228 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 714, i32 27 }
@___asan_gen_.231 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6780, i32 4 }
@___asan_gen_.234 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 6793, i32 4 }
@___asan_gen_.237 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 715, i32 2 }
@___asan_gen_.240 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 716, i32 2 }
@___asan_gen_.243 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 717, i32 2 }
@___asan_gen_.246 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 718, i32 2 }
@___asan_gen_.249 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 719, i32 2 }
@___asan_gen_.252 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 720, i32 2 }
@___asan_gen_.255 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 721, i32 2 }
@___asan_gen_.256 = private unnamed_addr constant [18 x i8] c"iceland_rlc_funcs\00", align 1
@___asan_gen_.258 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5645, i32 38 }
@___asan_gen_.259 = private unnamed_addr constant [11 x i8] c"vi_cs_data\00", align 1
@___asan_gen_.261 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 941, i32 36 }
@___asan_gen_.262 = private unnamed_addr constant [21 x i8] c"vi_SECT_CONTEXT_defs\00", align 1
@___asan_gen_.264 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 930, i32 35 }
@___asan_gen_.265 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_1\00", align 1
@___asan_gen_.267 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 24, i32 27 }
@___asan_gen_.268 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_3\00", align 1
@___asan_gen_.270 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 516, i32 27 }
@___asan_gen_.271 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_4\00", align 1
@___asan_gen_.273 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 525, i32 27 }
@___asan_gen_.274 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_5\00", align 1
@___asan_gen_.276 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 685, i32 27 }
@___asan_gen_.277 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_6\00", align 1
@___asan_gen_.279 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 690, i32 27 }
@___asan_gen_.280 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_2\00", align 1
@___asan_gen_.282 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 239, i32 27 }
@___asan_gen_.283 = private unnamed_addr constant [22 x i8] c"vi_SECT_CONTEXT_def_7\00", align 1
@___asan_gen_.284 = private unnamed_addr constant [56 x i8] c"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h\00", align 1
@___asan_gen_.285 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.284, i32 694, i32 27 }
@___asan_gen_.294 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 3874, i32 5 }
@___asan_gen_.297 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5339, i32 3 }
@___asan_gen_.300 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5345, i32 3 }
@___asan_gen_.303 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1567, i32 3 }
@___asan_gen_.304 = private unnamed_addr constant [25 x i8] c"vgpr_init_compute_shader\00", align 1
@___asan_gen_.306 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1375, i32 18 }
@___asan_gen_.307 = private unnamed_addr constant [25 x i8] c"sgpr_init_compute_shader\00", align 1
@___asan_gen_.309 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1412, i32 18 }
@___asan_gen_.310 = private unnamed_addr constant [15 x i8] c"vgpr_init_regs\00", align 1
@___asan_gen_.312 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1437, i32 18 }
@___asan_gen_.313 = private unnamed_addr constant [16 x i8] c"sgpr1_init_regs\00", align 1
@___asan_gen_.315 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1458, i32 18 }
@___asan_gen_.316 = private unnamed_addr constant [16 x i8] c"sgpr2_init_regs\00", align 1
@___asan_gen_.318 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1479, i32 18 }
@___asan_gen_.321 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1662, i32 3 }
@___asan_gen_.324 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1669, i32 3 }
@___asan_gen_.325 = private unnamed_addr constant [26 x i8] c"sec_ded_counter_registers\00", align 1
@___asan_gen_.327 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1500, i32 18 }
@___asan_gen_.330 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1995, i32 3 }
@___asan_gen_.331 = private unnamed_addr constant [6 x i8] c"__key\00", align 1
@___asan_gen_.336 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1999, i32 2 }
@___asan_gen_.339 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 2007, i32 3 }
@___asan_gen_.342 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 2013, i32 3 }
@___asan_gen_.345 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 2019, i32 3 }
@___asan_gen_.348 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 2063, i32 3 }
@___asan_gen_.351 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 970, i32 2 }
@___asan_gen_.354 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 974, i32 15 }
@___asan_gen_.357 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 977, i32 15 }
@___asan_gen_.360 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 980, i32 15 }
@___asan_gen_.363 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 983, i32 15 }
@___asan_gen_.366 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 986, i32 15 }
@___asan_gen_.369 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 989, i32 15 }
@___asan_gen_.372 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 992, i32 15 }
@___asan_gen_.375 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 995, i32 15 }
@___asan_gen_.378 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 998, i32 15 }
@___asan_gen_.381 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1005, i32 38 }
@___asan_gen_.384 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1008, i32 39 }
@___asan_gen_.387 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1025, i32 38 }
@___asan_gen_.390 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1028, i32 39 }
@___asan_gen_.393 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1046, i32 38 }
@___asan_gen_.396 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1049, i32 39 }
@___asan_gen_.405 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1072, i32 3 }
@___asan_gen_.408 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1076, i32 37 }
@___asan_gen_.411 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1126, i32 38 }
@___asan_gen_.414 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1129, i32 39 }
@___asan_gen_.417 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1148, i32 39 }
@___asan_gen_.420 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1151, i32 40 }
@___asan_gen_.432 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1233, i32 3 }
@___asan_gen_.444 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1362, i32 4 }
@___asan_gen_.447 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 1921, i32 22 }
@___asan_gen_.448 = private unnamed_addr constant [23 x i8] c"iceland_mgcg_cgcg_init\00", align 1
@___asan_gen_.450 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 503, i32 18 }
@___asan_gen_.451 = private unnamed_addr constant [28 x i8] c"golden_settings_iceland_a11\00", align 1
@___asan_gen_.453 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 471, i32 18 }
@___asan_gen_.454 = private unnamed_addr constant [26 x i8] c"iceland_golden_common_all\00", align 1
@___asan_gen_.456 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 491, i32 18 }
@___asan_gen_.457 = private unnamed_addr constant [20 x i8] c"fiji_mgcg_cgcg_init\00", align 1
@___asan_gen_.459 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 432, i32 18 }
@___asan_gen_.460 = private unnamed_addr constant [25 x i8] c"golden_settings_fiji_a10\00", align 1
@___asan_gen_.462 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 417, i32 18 }
@___asan_gen_.463 = private unnamed_addr constant [23 x i8] c"fiji_golden_common_all\00", align 1
@___asan_gen_.465 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 403, i32 18 }
@___asan_gen_.466 = private unnamed_addr constant [21 x i8] c"tonga_mgcg_cgcg_init\00", align 1
@___asan_gen_.468 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 229, i32 18 }
@___asan_gen_.469 = private unnamed_addr constant [26 x i8] c"golden_settings_tonga_a11\00", align 1
@___asan_gen_.471 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 197, i32 18 }
@___asan_gen_.472 = private unnamed_addr constant [24 x i8] c"tonga_golden_common_all\00", align 1
@___asan_gen_.474 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 217, i32 18 }
@___asan_gen_.475 = private unnamed_addr constant [26 x i8] c"golden_settings_vegam_a11\00", align 1
@___asan_gen_.477 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 308, i32 18 }
@___asan_gen_.478 = private unnamed_addr constant [24 x i8] c"vegam_golden_common_all\00", align 1
@___asan_gen_.480 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 329, i32 18 }
@___asan_gen_.481 = private unnamed_addr constant [30 x i8] c"golden_settings_polaris11_a11\00", align 1
@___asan_gen_.483 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 339, i32 18 }
@___asan_gen_.484 = private unnamed_addr constant [28 x i8] c"polaris11_golden_common_all\00", align 1
@___asan_gen_.486 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 360, i32 18 }
@___asan_gen_.487 = private unnamed_addr constant [30 x i8] c"golden_settings_polaris10_a11\00", align 1
@___asan_gen_.489 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 370, i32 18 }
@___asan_gen_.490 = private unnamed_addr constant [28 x i8] c"polaris10_golden_common_all\00", align 1
@___asan_gen_.492 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 391, i32 18 }
@___asan_gen_.493 = private unnamed_addr constant [18 x i8] c"cz_mgcg_cgcg_init\00", align 1
@___asan_gen_.495 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 599, i32 18 }
@___asan_gen_.496 = private unnamed_addr constant [23 x i8] c"cz_golden_settings_a11\00", align 1
@___asan_gen_.498 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 571, i32 18 }
@___asan_gen_.499 = private unnamed_addr constant [21 x i8] c"cz_golden_common_all\00", align 1
@___asan_gen_.501 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 587, i32 18 }
@___asan_gen_.502 = private unnamed_addr constant [22 x i8] c"stoney_mgcg_cgcg_init\00", align 1
@___asan_gen_.504 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 704, i32 18 }
@___asan_gen_.505 = private unnamed_addr constant [27 x i8] c"stoney_golden_settings_a11\00", align 1
@___asan_gen_.507 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 678, i32 18 }
@___asan_gen_.508 = private unnamed_addr constant [25 x i8] c"stoney_golden_common_all\00", align 1
@___asan_gen_.510 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 692, i32 18 }
@___asan_gen_.519 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 3260, i32 3 }
@___asan_gen_.522 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 3519, i32 3 }
@___asan_gen_.533 = private unnamed_addr constant [56 x i8] c"../drivers/gpu/drm/amd/amdgpu/../amdgpu/amdgpu_object.h\00", align 1
@___asan_gen_.534 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.533, i32 179, i32 4 }
@___asan_gen_.537 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4197, i32 3 }
@___asan_gen_.540 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4372, i32 4 }
@___asan_gen_.543 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4381, i32 3 }
@___asan_gen_.555 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4943, i32 3 }
@___asan_gen_.561 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4950, i32 3 }
@___asan_gen_.567 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4954, i32 3 }
@___asan_gen_.570 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 4874, i32 3 }
@___asan_gen_.582 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5097, i32 3 }
@___asan_gen_.583 = private unnamed_addr constant [7 x i8] c"_entry\00", align 1
@___asan_gen_.586 = private unnamed_addr constant [17 x i8] c"<string literal>\00", align 1
@___asan_gen_.587 = private constant [41 x i8] c"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\00", align 1
@___asan_gen_.588 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.587, i32 5111, i32 3 }
@___asan_gen_.589 = private unnamed_addr constant [30 x i8] c"switch.table.gfx_v8_0_sw_init\00", align 1
@___asan_gen_.590 = private unnamed_addr constant [30 x i8] c"switch.table.gfx_v8_0_hw_init\00", align 1
@___asan_gen_.591 = private unnamed_addr constant [34 x i8] c"switch.table.gfx_v8_0_hw_init.100\00", align 1
@llvm.compiler.used = appending global [234 x ptr] [ptr @__UNIQUE_ID_firmware343, ptr @__UNIQUE_ID_firmware344, ptr @__UNIQUE_ID_firmware345, ptr @__UNIQUE_ID_firmware346, ptr @__UNIQUE_ID_firmware347, ptr @__UNIQUE_ID_firmware348, ptr @__UNIQUE_ID_firmware349, ptr @__UNIQUE_ID_firmware350, ptr @__UNIQUE_ID_firmware351, ptr @__UNIQUE_ID_firmware352, ptr @__UNIQUE_ID_firmware353, ptr @__UNIQUE_ID_firmware354, ptr @__UNIQUE_ID_firmware355, ptr @__UNIQUE_ID_firmware356, ptr @__UNIQUE_ID_firmware357, ptr @__UNIQUE_ID_firmware358, ptr @__UNIQUE_ID_firmware359, ptr @__UNIQUE_ID_firmware360, ptr @__UNIQUE_ID_firmware361, ptr @__UNIQUE_ID_firmware362, ptr @__UNIQUE_ID_firmware363, ptr @__UNIQUE_ID_firmware364, ptr @__UNIQUE_ID_firmware365, ptr @__UNIQUE_ID_firmware366, ptr @__UNIQUE_ID_firmware367, ptr @__UNIQUE_ID_firmware368, ptr @__UNIQUE_ID_firmware369, ptr @__UNIQUE_ID_firmware370, ptr @__UNIQUE_ID_firmware371, ptr @__UNIQUE_ID_firmware372, ptr @__UNIQUE_ID_firmware373, ptr @__UNIQUE_ID_firmware374, ptr @__UNIQUE_ID_firmware375, ptr @__UNIQUE_ID_firmware376, ptr @__UNIQUE_ID_firmware377, ptr @__UNIQUE_ID_firmware378, ptr @__UNIQUE_ID_firmware379, ptr @__UNIQUE_ID_firmware380, ptr @__UNIQUE_ID_firmware381, ptr @__UNIQUE_ID_firmware382, ptr @__UNIQUE_ID_firmware383, ptr @__UNIQUE_ID_firmware384, ptr @__UNIQUE_ID_firmware385, ptr @__UNIQUE_ID_firmware386, ptr @__UNIQUE_ID_firmware387, ptr @__UNIQUE_ID_firmware388, ptr @__UNIQUE_ID_firmware389, ptr @__UNIQUE_ID_firmware390, ptr @__UNIQUE_ID_firmware391, ptr @__UNIQUE_ID_firmware392, ptr @__UNIQUE_ID_firmware393, ptr @__UNIQUE_ID_firmware394, ptr @__UNIQUE_ID_firmware395, ptr @__UNIQUE_ID_firmware396, ptr @__UNIQUE_ID_firmware397, ptr @__UNIQUE_ID_firmware398, ptr @__UNIQUE_ID_firmware399, ptr @__UNIQUE_ID_firmware400, ptr @__UNIQUE_ID_firmware401, ptr @__UNIQUE_ID_firmware402, ptr @__UNIQUE_ID_firmware403, ptr @__UNIQUE_ID_firmware404, ptr @__UNIQUE_ID_firmware405, ptr @__UNIQUE_ID_firmware406, ptr @__UNIQUE_ID_firmware407, ptr @__UNIQUE_ID_firmware408, ptr @__UNIQUE_ID_firmware409, ptr @amdgpu_bo_reserve._entry, ptr @amdgpu_bo_reserve._entry_ptr, ptr @gfx_v8_0_hw_fini._entry, ptr @gfx_v8_0_hw_fini._entry.90, ptr @gfx_v8_0_hw_fini._entry_ptr, ptr @gfx_v8_0_hw_fini._entry_ptr.92, ptr @gfx_v8_0_init_microcode._entry, ptr @gfx_v8_0_init_microcode._entry.66, ptr @gfx_v8_0_init_microcode._entry_ptr, ptr @gfx_v8_0_init_microcode._entry_ptr.70, ptr @gfx_v8_0_mec_init._entry, ptr @gfx_v8_0_mec_init._entry_ptr, ptr @gfx_v8_0_parse_sq_irq._entry, ptr @gfx_v8_0_parse_sq_irq._entry.13, ptr @gfx_v8_0_parse_sq_irq._entry_ptr, ptr @gfx_v8_0_parse_sq_irq._entry_ptr.15, ptr @gfx_v8_0_soft_reset._entry, ptr @gfx_v8_0_soft_reset._entry.97, ptr @gfx_v8_0_soft_reset._entry_ptr, ptr @gfx_v8_0_soft_reset._entry_ptr.99, ptr @gfx_v8_0_tiling_mode_table_init._entry, ptr @gfx_v8_0_tiling_mode_table_init._entry_ptr, ptr @gfx_v8_0_wait_for_rlc_serdes._entry, ptr @gfx_v8_0_wait_for_rlc_serdes._entry_ptr, ptr @gfx_v8_0_ip_funcs, ptr @gfx_v8_0_ip_block, ptr @gfx_v8_1_ip_block, ptr @.str, ptr @gfx_v8_0_gfx_funcs, ptr @gfx_v8_0_ring_funcs_kiq, ptr @gfx_v8_0_ring_funcs_gfx, ptr @gfx_v8_0_ring_funcs_compute, ptr @.str.1, ptr @amdgpu_gds_reg_offset, ptr @.str.2, ptr @gfx_v8_0_eop_irq_funcs, ptr @gfx_v8_0_priv_reg_irq_funcs, ptr @gfx_v8_0_priv_inst_irq_funcs, ptr @gfx_v8_0_cp_ecc_error_irq_funcs, ptr @gfx_v8_0_sq_irq_funcs, ptr @.str.3, ptr @.str.4, ptr @.str.5, ptr @.str.6, ptr @.str.7, ptr @.str.8, ptr @.str.9, ptr @.str.10, ptr @.str.11, ptr @.str.12, ptr @.str.14, ptr @.str.16, ptr @.str.17, ptr @sq_edc_source_names, ptr @.str.18, ptr @.str.19, ptr @.str.20, ptr @.str.21, ptr @.str.22, ptr @.str.23, ptr @.str.24, ptr @.str.25, ptr @.str.26, ptr @iceland_rlc_funcs, ptr @vi_cs_data, ptr @vi_SECT_CONTEXT_defs, ptr @vi_SECT_CONTEXT_def_1, ptr @vi_SECT_CONTEXT_def_3, ptr @vi_SECT_CONTEXT_def_4, ptr @vi_SECT_CONTEXT_def_5, ptr @vi_SECT_CONTEXT_def_6, ptr @vi_SECT_CONTEXT_def_2, ptr @vi_SECT_CONTEXT_def_7, ptr @.str.29, ptr @.str.30, ptr @.str.31, ptr @.str.32, ptr @.str.33, ptr @vgpr_init_compute_shader, ptr @sgpr_init_compute_shader, ptr @vgpr_init_regs, ptr @sgpr1_init_regs, ptr @sgpr2_init_regs, ptr @.str.34, ptr @.str.35, ptr @sec_ded_counter_registers, ptr @.str.36, ptr @gfx_v8_0_sw_init.__key, ptr @.str.37, ptr @.str.38, ptr @.str.39, ptr @.str.40, ptr @.str.42, ptr @.str.43, ptr @.str.44, ptr @.str.45, ptr @.str.46, ptr @.str.47, ptr @.str.48, ptr @.str.49, ptr @.str.50, ptr @.str.51, ptr @.str.52, ptr @.str.53, ptr @.str.54, ptr @.str.55, ptr @.str.56, ptr @.str.57, ptr @.str.58, ptr @.str.59, ptr @.str.60, ptr @.str.61, ptr @.str.62, ptr @.str.63, ptr @.str.64, ptr @.str.65, ptr @.str.67, ptr @.str.68, ptr @.str.69, ptr @.str.71, ptr @.str.72, ptr @.str.73, ptr @.str.74, ptr @iceland_mgcg_cgcg_init, ptr @golden_settings_iceland_a11, ptr @iceland_golden_common_all, ptr @fiji_mgcg_cgcg_init, ptr @golden_settings_fiji_a10, ptr @fiji_golden_common_all, ptr @tonga_mgcg_cgcg_init, ptr @golden_settings_tonga_a11, ptr @tonga_golden_common_all, ptr @golden_settings_vegam_a11, ptr @vegam_golden_common_all, ptr @golden_settings_polaris11_a11, ptr @polaris11_golden_common_all, ptr @golden_settings_polaris10_a11, ptr @polaris10_golden_common_all, ptr @cz_mgcg_cgcg_init, ptr @cz_golden_settings_a11, ptr @cz_golden_common_all, ptr @stoney_mgcg_cgcg_init, ptr @stoney_golden_settings_a11, ptr @stoney_golden_common_all, ptr @.str.75, ptr @.str.76, ptr @.str.77, ptr @.str.78, ptr @.str.79, ptr @.str.80, ptr @.str.82, ptr @.str.83, ptr @.str.84, ptr @.str.85, ptr @.str.86, ptr @.str.87, ptr @.str.88, ptr @.str.89, ptr @.str.91, ptr @.str.93, ptr @.str.94, ptr @.str.95, ptr @.str.96, ptr @.str.98, ptr @switch.table.gfx_v8_0_sw_init, ptr @switch.table.gfx_v8_0_hw_init, ptr @switch.table.gfx_v8_0_hw_init.100], section "llvm.metadata"
@0 = internal global [155 x { i32, i32, i32, i32, i32, i32, i32, i32 }] [{ i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_ip_funcs to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.133 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.135 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_ip_block to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.136 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.138 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_1_ip_block to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.139 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.141 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.144 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_gfx_funcs to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.145 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.147 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_ring_funcs_kiq to i32), i32 160, i32 192, i32 ptrtoint (ptr @___asan_gen_.148 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.150 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_ring_funcs_gfx to i32), i32 160, i32 192, i32 ptrtoint (ptr @___asan_gen_.151 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.153 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_ring_funcs_compute to i32), i32 160, i32 192, i32 ptrtoint (ptr @___asan_gen_.154 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.156 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.1 to i32), i32 56, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.159 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @amdgpu_gds_reg_offset to i32), i32 256, i32 320, i32 ptrtoint (ptr @___asan_gen_.160 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.162 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.2 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.165 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_eop_irq_funcs to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.166 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.168 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_priv_reg_irq_funcs to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.169 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.171 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_priv_inst_irq_funcs to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.172 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.174 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_cp_ecc_error_irq_funcs to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.175 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.177 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_sq_irq_funcs to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.178 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.180 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.3 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.183 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.4 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.186 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.5 to i32), i32 43, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.189 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.6 to i32), i32 39, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.192 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.7 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.195 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_parse_sq_irq._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.207 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.8 to i32), i32 200, i32 256, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.207 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.9 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.207 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.10 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.207 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.11 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.210 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.12 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.213 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_parse_sq_irq._entry.13 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.231 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.14 to i32), i32 119, i32 160, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.231 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.16 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.231 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.17 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.231 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sq_edc_source_names to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.226 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.228 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.18 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.231 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.19 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.234 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.20 to i32), i32 54, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.237 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.21 to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.240 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.22 to i32), i32 63, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.243 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.23 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.246 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.24 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.249 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.25 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.252 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.26 to i32), i32 40, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.255 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @iceland_rlc_funcs to i32), i32 60, i32 96, i32 ptrtoint (ptr @___asan_gen_.256 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.258 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_cs_data to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.259 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.261 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_defs to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.262 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.264 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_1 to i32), i32 848, i32 1056, i32 ptrtoint (ptr @___asan_gen_.265 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.267 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_3 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.268 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.270 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_4 to i32), i32 628, i32 768, i32 ptrtoint (ptr @___asan_gen_.271 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.273 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_5 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.274 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.276 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_6 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.277 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.279 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_2 to i32), i32 1096, i32 1376, i32 ptrtoint (ptr @___asan_gen_.280 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.282 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vi_SECT_CONTEXT_def_7 to i32), i32 932, i32 1184, i32 ptrtoint (ptr @___asan_gen_.283 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.285 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_wait_for_rlc_serdes._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.294 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.29 to i32), i32 43, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.294 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.30 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.294 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.31 to i32), i32 52, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.297 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.32 to i32), i32 51, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.300 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.33 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.303 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vgpr_init_compute_shader to i32), i32 264, i32 352, i32 ptrtoint (ptr @___asan_gen_.304 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.306 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sgpr_init_compute_shader to i32), i32 168, i32 224, i32 ptrtoint (ptr @___asan_gen_.307 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.309 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vgpr_init_regs to i32), i32 136, i32 192, i32 ptrtoint (ptr @___asan_gen_.310 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.312 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sgpr1_init_regs to i32), i32 136, i32 192, i32 ptrtoint (ptr @___asan_gen_.313 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.315 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sgpr2_init_regs to i32), i32 136, i32 192, i32 ptrtoint (ptr @___asan_gen_.316 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.318 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.34 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.321 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.35 to i32), i32 33, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.324 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sec_ded_counter_registers to i32), i32 100, i32 160, i32 ptrtoint (ptr @___asan_gen_.325 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.327 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.36 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.330 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_sw_init.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.331 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.37 to i32), i32 43, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.38 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.339 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.39 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.342 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.40 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.345 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.42 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.43 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.351 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.44 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.354 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.45 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.46 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.360 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.47 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.363 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.48 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.366 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.49 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.369 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.50 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.372 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.51 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.375 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.52 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.53 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.54 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.384 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.55 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.387 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.56 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.57 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.393 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.58 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_init_microcode._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.405 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.59 to i32), i32 37, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.405 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.60 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.405 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.61 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.408 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.62 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.411 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.63 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.414 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.64 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.417 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.65 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.420 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_init_microcode._entry.66 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.67 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.68 to i32), i32 3, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.69 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_mec_init._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.444 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.71 to i32), i32 39, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.444 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.72 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.444 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.73 to i32), i32 3, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.444 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.74 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.447 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @iceland_mgcg_cgcg_init to i32), i32 768, i32 960, i32 ptrtoint (ptr @___asan_gen_.448 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.450 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_iceland_a11 to i32), i32 192, i32 224, i32 ptrtoint (ptr @___asan_gen_.451 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.453 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @iceland_golden_common_all to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.454 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.456 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fiji_mgcg_cgcg_init to i32), i32 420, i32 544, i32 ptrtoint (ptr @___asan_gen_.457 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.459 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_fiji_a10 to i32), i32 132, i32 192, i32 ptrtoint (ptr @___asan_gen_.460 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.462 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fiji_golden_common_all to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.463 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.465 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @tonga_mgcg_cgcg_init to i32), i32 900, i32 1152, i32 ptrtoint (ptr @___asan_gen_.466 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.468 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_tonga_a11 to i32), i32 192, i32 224, i32 ptrtoint (ptr @___asan_gen_.469 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.471 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @tonga_golden_common_all to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.472 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.474 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_vegam_a11 to i32), i32 204, i32 256, i32 ptrtoint (ptr @___asan_gen_.475 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @vegam_golden_common_all to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.478 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.480 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_polaris11_a11 to i32), i32 204, i32 256, i32 ptrtoint (ptr @___asan_gen_.481 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.483 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @polaris11_golden_common_all to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.484 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.486 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @golden_settings_polaris10_a11 to i32), i32 204, i32 256, i32 ptrtoint (ptr @___asan_gen_.487 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.489 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @polaris10_golden_common_all to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.490 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.492 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cz_mgcg_cgcg_init to i32), i32 900, i32 1152, i32 ptrtoint (ptr @___asan_gen_.493 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.495 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cz_golden_settings_a11 to i32), i32 144, i32 192, i32 ptrtoint (ptr @___asan_gen_.496 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.498 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cz_golden_common_all to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.499 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.501 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @stoney_mgcg_cgcg_init to i32), i32 60, i32 96, i32 ptrtoint (ptr @___asan_gen_.502 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.504 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @stoney_golden_settings_a11 to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.505 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.507 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @stoney_golden_common_all to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.508 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.510 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_tiling_mode_table_init._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.519 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.75 to i32), i32 110, i32 160, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.519 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.76 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.519 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.77 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.522 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @amdgpu_bo_reserve._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.534 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.78 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.534 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.79 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.534 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.80 to i32), i32 53, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.534 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.82 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.537 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.83 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.540 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.84 to i32), i32 26, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.543 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.85 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.555 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.86 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.555 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.87 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.555 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.88 to i32), i32 50, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.555 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_hw_fini._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.561 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.89 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.561 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_hw_fini._entry.90 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.567 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.91 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.567 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.93 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.570 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_soft_reset._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.582 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.94 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.582 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.95 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.582 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.96 to i32), i32 3, i32 32, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.582 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @gfx_v8_0_soft_reset._entry.97 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.583 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.588 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.98 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.586 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.588 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @switch.table.gfx_v8_0_sw_init to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.589 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 0, i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @switch.table.gfx_v8_0_hw_init to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.590 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 0, i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @switch.table.gfx_v8_0_hw_init.100 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.591 to i32), i32 ptrtoint (ptr @___asan_gen_.587 to i32), i32 0, i32 0, i32 -1 }]
@llvm.used = appending global [2 x ptr] [ptr @asan.module_ctor, ptr @asan.module_dtor], section "llvm.metadata"
@llvm.global_ctors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_ctor, ptr null }]
@llvm.global_dtors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_dtor, ptr null }]

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_early_init(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %num_gfx_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 37
  %0 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 1, ptr %num_gfx_rings, align 8
  %call = tail call i32 @amdgpu_gfx_get_num_kcq(ptr noundef %handle) #12
  %1 = tail call i32 @llvm.smin.i32(i32 %call, i32 8)
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %2 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 %1, ptr %num_compute_rings, align 8
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 49
  %3 = ptrtoint ptr %funcs to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr @gfx_v8_0_gfx_funcs, ptr %funcs, align 4
  %funcs.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 1
  %4 = ptrtoint ptr %funcs.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr @gfx_v8_0_ring_funcs_kiq, ptr %funcs.i, align 4
  %5 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %num_gfx_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %6)
  %cmp23.not.i = icmp eq i32 %6, 0
  br i1 %cmp23.not.i, label %entry.for.cond4.preheader.i_crit_edge, label %entry.for.body.i_crit_edge

entry.for.body.i_crit_edge:                       ; preds = %entry
  br label %for.body.i

entry.for.cond4.preheader.i_crit_edge:            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond4.preheader.i

for.cond4.preheader.i:                            ; preds = %for.body.i.for.cond4.preheader.i_crit_edge, %entry.for.cond4.preheader.i_crit_edge
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp625.not.i = icmp eq i32 %1, 0
  br i1 %cmp625.not.i, label %for.cond4.preheader.i.gfx_v8_0_set_ring_funcs.exit_crit_edge, label %for.cond4.preheader.i.for.body7.i_crit_edge

for.cond4.preheader.i.for.body7.i_crit_edge:      ; preds = %for.cond4.preheader.i
  br label %for.body7.i

for.cond4.preheader.i.gfx_v8_0_set_ring_funcs.exit_crit_edge: ; preds = %for.cond4.preheader.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_set_ring_funcs.exit

for.body.i:                                       ; preds = %for.body.i.for.body.i_crit_edge, %entry.for.body.i_crit_edge
  %i.024.i = phi i32 [ %inc.i, %for.body.i.for.body.i_crit_edge ], [ 0, %entry.for.body.i_crit_edge ]
  %funcs3.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.024.i, i32 1
  %7 = ptrtoint ptr %funcs3.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store ptr @gfx_v8_0_ring_funcs_gfx, ptr %funcs3.i, align 4
  %inc.i = add nuw i32 %i.024.i, 1
  %exitcond.not.i = icmp eq i32 %inc.i, %6
  br i1 %exitcond.not.i, label %for.body.i.for.cond4.preheader.i_crit_edge, label %for.body.i.for.body.i_crit_edge

for.body.i.for.body.i_crit_edge:                  ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

for.body.i.for.cond4.preheader.i_crit_edge:       ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond4.preheader.i

for.body7.i:                                      ; preds = %for.body7.i.for.body7.i_crit_edge, %for.cond4.preheader.i.for.body7.i_crit_edge
  %i.126.i = phi i32 [ %inc12.i, %for.body7.i.for.body7.i_crit_edge ], [ 0, %for.cond4.preheader.i.for.body7.i_crit_edge ]
  %funcs10.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.126.i, i32 1
  %8 = ptrtoint ptr %funcs10.i to i32
  call void @__asan_store4_noabort(i32 %8)
  store ptr @gfx_v8_0_ring_funcs_compute, ptr %funcs10.i, align 4
  %inc12.i = add nuw i32 %i.126.i, 1
  %exitcond27.not.i = icmp eq i32 %inc12.i, %1
  br i1 %exitcond27.not.i, label %for.body7.i.gfx_v8_0_set_ring_funcs.exit_crit_edge, label %for.body7.i.for.body7.i_crit_edge

for.body7.i.for.body7.i_crit_edge:                ; preds = %for.body7.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body7.i

for.body7.i.gfx_v8_0_set_ring_funcs.exit_crit_edge: ; preds = %for.body7.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_set_ring_funcs.exit

gfx_v8_0_set_ring_funcs.exit:                     ; preds = %for.body7.i.gfx_v8_0_set_ring_funcs.exit_crit_edge, %for.cond4.preheader.i.gfx_v8_0_set_ring_funcs.exit_crit_edge
  %eop_irq.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 40
  %9 = ptrtoint ptr %eop_irq.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 10, ptr %eop_irq.i, align 4
  %funcs.i12 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 40, i32 2
  %10 = ptrtoint ptr %funcs.i12 to i32
  call void @__asan_store4_noabort(i32 %10)
  store ptr @gfx_v8_0_eop_irq_funcs, ptr %funcs.i12, align 4
  %priv_reg_irq.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 41
  %11 = ptrtoint ptr %priv_reg_irq.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 1, ptr %priv_reg_irq.i, align 8
  %funcs7.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 41, i32 2
  %12 = ptrtoint ptr %funcs7.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store ptr @gfx_v8_0_priv_reg_irq_funcs, ptr %funcs7.i, align 8
  %priv_inst_irq.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 42
  %13 = ptrtoint ptr %priv_inst_irq.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 1, ptr %priv_inst_irq.i, align 4
  %funcs12.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 42, i32 2
  %14 = ptrtoint ptr %funcs12.i to i32
  call void @__asan_store4_noabort(i32 %14)
  store ptr @gfx_v8_0_priv_inst_irq_funcs, ptr %funcs12.i, align 4
  %cp_ecc_error_irq.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 43
  %15 = ptrtoint ptr %cp_ecc_error_irq.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 1, ptr %cp_ecc_error_irq.i, align 8
  %funcs17.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 43, i32 2
  %16 = ptrtoint ptr %funcs17.i to i32
  call void @__asan_store4_noabort(i32 %16)
  store ptr @gfx_v8_0_cp_ecc_error_irq_funcs, ptr %funcs17.i, align 8
  %sq_irq.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 44
  %17 = ptrtoint ptr %sq_irq.i to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 1, ptr %sq_irq.i, align 4
  %funcs22.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 44, i32 2
  %18 = ptrtoint ptr %funcs22.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr @gfx_v8_0_sq_irq_funcs, ptr %funcs22.i, align 4
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 13057, i32 noundef 0) #12
  %gds.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 114
  %19 = ptrtoint ptr %gds.i to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %call.i, ptr %gds.i, align 8
  %gws_size.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 114, i32 1
  %20 = ptrtoint ptr %gws_size.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 64, ptr %gws_size.i, align 4
  %oa_size.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 114, i32 2
  %21 = ptrtoint ptr %oa_size.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 16, ptr %oa_size.i, align 8
  %call3.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 13128, i32 noundef 0) #12
  %gds_compute_max_wave_id.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 114, i32 3
  %22 = ptrtoint ptr %gds_compute_max_wave_id.i to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %call3.i, ptr %gds_compute_max_wave_id.i, align 4
  %funcs.i13 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %23 = ptrtoint ptr %funcs.i13 to i32
  call void @__asan_store4_noabort(i32 %23)
  store ptr @iceland_rlc_funcs, ptr %funcs.i13, align 4
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_late_init(ptr noundef %handle) #0 align 64 {
entry:
  %ib.i = alloca %struct.amdgpu_ib, align 8
  %f.i = alloca ptr, align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %priv_reg_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 41
  %call = tail call i32 @amdgpu_irq_get(ptr noundef %handle, ptr noundef %priv_reg_irq, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %priv_inst_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 42
  %call2 = tail call i32 @amdgpu_irq_get(ptr noundef %handle, ptr noundef %priv_inst_irq, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2)
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %if.end5, label %if.end.cleanup_crit_edge

if.end.cleanup_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end5:                                          ; preds = %if.end
  %compute_ring.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %ib.i) #12
  %0 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib.i, i32 0, i32 1
  %1 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib.i, i32 0, i32 2
  %2 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib.i, i32 0, i32 3
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %f.i) #12
  %3 = ptrtoint ptr %f.i to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr null, ptr %f.i, align 4
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %4 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 13, i32 %5)
  %cmp.not.i = icmp eq i32 %5, 13
  br i1 %cmp.not.i, label %if.end.i, label %if.end5.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge

if.end5.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge: ; preds = %if.end5
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit.thread

if.end.i:                                         ; preds = %if.end5
  %ready.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 0, i32 3, i32 17
  %6 = ptrtoint ptr %ready.i to i32
  call void @__asan_load1_noabort(i32 %6)
  %7 = load i8, ptr %ready.i, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %7)
  %tobool.not.i = icmp eq i8 %7, 0
  br i1 %tobool.not.i, label %if.end.i.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge, label %if.end2.i

if.end.i.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge: ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit.thread

if.end2.i:                                        ; preds = %if.end.i
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12414, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12414, i32 noundef 0, i32 noundef 0) #12
  %8 = call ptr @memset(ptr %ib.i, i32 0, i32 24)
  %call7.i = call i32 @amdgpu_ib_get(ptr noundef %handle, ptr noundef null, i32 noundef 1448, i32 noundef 2, ptr noundef nonnull %ib.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call7.i)
  %tobool8.not.i = icmp eq i32 %call7.i, 0
  br i1 %tobool8.not.i, label %if.end2.i.for.body.i_crit_edge, label %gfx_v8_0_do_edc_gpr_workarounds.exit.thread42

if.end2.i.for.body.i_crit_edge:                   ; preds = %if.end2.i
  br label %for.body.i

gfx_v8_0_do_edc_gpr_workarounds.exit.thread42:    ; preds = %if.end2.i
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.33, i32 noundef %call7.i) #12
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %f.i) #12
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %ib.i) #12
  br label %cleanup

for.body.i:                                       ; preds = %for.body.i.for.body.i_crit_edge, %if.end2.i.for.body.i_crit_edge
  %i.0341.i = phi i32 [ %inc.i, %for.body.i.for.body.i_crit_edge ], [ 0, %if.end2.i.for.body.i_crit_edge ]
  %arrayidx12.i = getelementptr [66 x i32], ptr @vgpr_init_compute_shader, i32 0, i32 %i.0341.i
  %9 = ptrtoint ptr %arrayidx12.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx12.i, align 4
  %11 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %2, align 8
  %add13.i = add nuw nsw i32 %i.0341.i, 192
  %arrayidx14.i = getelementptr i32, ptr %12, i32 %add13.i
  %13 = ptrtoint ptr %arrayidx14.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 %10, ptr %arrayidx14.i, align 4
  %inc.i = add nuw nsw i32 %i.0341.i, 1
  %exitcond.not.i = icmp eq i32 %inc.i, 66
  br i1 %exitcond.not.i, label %for.body.i.for.body17.i_crit_edge, label %for.body.i.for.body.i_crit_edge

for.body.i.for.body.i_crit_edge:                  ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

for.body.i.for.body17.i_crit_edge:                ; preds = %for.body.i
  br label %for.body17.i

for.body17.i:                                     ; preds = %for.body17.i.for.body17.i_crit_edge, %for.body.i.for.body17.i_crit_edge
  %i.1342.i = phi i32 [ %inc24.i, %for.body17.i.for.body17.i_crit_edge ], [ 0, %for.body.i.for.body17.i_crit_edge ]
  %arrayidx18.i = getelementptr [42 x i32], ptr @sgpr_init_compute_shader, i32 0, i32 %i.1342.i
  %14 = ptrtoint ptr %arrayidx18.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx18.i, align 4
  %16 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %2, align 8
  %add21.i = add nuw nsw i32 %i.1342.i, 320
  %arrayidx22.i = getelementptr i32, ptr %17, i32 %add21.i
  %18 = ptrtoint ptr %arrayidx22.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %15, ptr %arrayidx22.i, align 4
  %inc24.i = add nuw nsw i32 %i.1342.i, 1
  %exitcond347.not.i = icmp eq i32 %inc24.i, 42
  br i1 %exitcond347.not.i, label %for.end25.i, label %for.body17.i.for.body17.i_crit_edge

for.body17.i.for.body17.i_crit_edge:              ; preds = %for.body17.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body17.i

for.end25.i:                                      ; preds = %for.body17.i
  %19 = ptrtoint ptr %0 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 0, ptr %0, align 4
  br label %for.body28.i

for.body28.i:                                     ; preds = %for.body28.i.for.body28.i_crit_edge, %for.end25.i
  %i.2343.i = phi i32 [ 0, %for.end25.i ], [ %add45.i, %for.body28.i.for.body28.i_crit_edge ]
  %20 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %2, align 8
  %22 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %0, align 4
  %inc31.i = add i32 %23, 1
  store i32 %inc31.i, ptr %0, align 4
  %arrayidx32.i = getelementptr i32, ptr %21, i32 %23
  %24 = ptrtoint ptr %arrayidx32.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 -1073646080, ptr %arrayidx32.i, align 4
  %arrayidx33.i = getelementptr [34 x i32], ptr @vgpr_init_regs, i32 0, i32 %i.2343.i
  %25 = ptrtoint ptr %arrayidx33.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %arrayidx33.i, align 4
  %sub.i = add i32 %26, -11264
  %27 = load ptr, ptr %2, align 8
  %28 = load i32, ptr %0, align 4
  %inc36.i = add i32 %28, 1
  store i32 %inc36.i, ptr %0, align 4
  %arrayidx37.i = getelementptr i32, ptr %27, i32 %28
  %29 = ptrtoint ptr %arrayidx37.i to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %sub.i, ptr %arrayidx37.i, align 4
  %add38.i = or i32 %i.2343.i, 1
  %arrayidx39.i = getelementptr [34 x i32], ptr @vgpr_init_regs, i32 0, i32 %add38.i
  %30 = ptrtoint ptr %arrayidx39.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx39.i, align 4
  %32 = load ptr, ptr %2, align 8
  %33 = load i32, ptr %0, align 4
  %inc42.i = add i32 %33, 1
  store i32 %inc42.i, ptr %0, align 4
  %arrayidx43.i = getelementptr i32, ptr %32, i32 %33
  %34 = ptrtoint ptr %arrayidx43.i to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 %31, ptr %arrayidx43.i, align 4
  %add45.i = add nuw nsw i32 %i.2343.i, 2
  %cmp27.i = icmp ult i32 %i.2343.i, 32
  br i1 %cmp27.i, label %for.body28.i.for.body28.i_crit_edge, label %for.end46.i

for.body28.i.for.body28.i_crit_edge:              ; preds = %for.body28.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body28.i

for.end46.i:                                      ; preds = %for.body28.i
  %35 = ptrtoint ptr %1 to i32
  call void @__asan_load8_noabort(i32 %35)
  %36 = load i64, ptr %1, align 8
  %add48.i = add i64 %36, 768
  %shr.i = lshr i64 %add48.i, 8
  %37 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %2, align 8
  %39 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %0, align 4
  %inc51.i = add i32 %40, 1
  store i32 %inc51.i, ptr %0, align 4
  %arrayidx52.i = getelementptr i32, ptr %38, i32 %40
  %41 = ptrtoint ptr %arrayidx52.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 -1073580544, ptr %arrayidx52.i, align 4
  %42 = load ptr, ptr %2, align 8
  %43 = load i32, ptr %0, align 4
  %inc55.i = add i32 %43, 1
  store i32 %inc55.i, ptr %0, align 4
  %arrayidx56.i = getelementptr i32, ptr %42, i32 %43
  %44 = ptrtoint ptr %arrayidx56.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 524, ptr %arrayidx56.i, align 4
  %conv58.i = trunc i64 %shr.i to i32
  %45 = load ptr, ptr %2, align 8
  %46 = load i32, ptr %0, align 4
  %inc61.i = add i32 %46, 1
  store i32 %inc61.i, ptr %0, align 4
  %arrayidx62.i = getelementptr i32, ptr %45, i32 %46
  %47 = ptrtoint ptr %arrayidx62.i to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 %conv58.i, ptr %arrayidx62.i, align 4
  %shr63.i = lshr i64 %add48.i, 40
  %conv65.i = trunc i64 %shr63.i to i32
  %48 = load ptr, ptr %2, align 8
  %49 = load i32, ptr %0, align 4
  %inc68.i = add i32 %49, 1
  store i32 %inc68.i, ptr %0, align 4
  %arrayidx69.i = getelementptr i32, ptr %48, i32 %49
  %50 = ptrtoint ptr %arrayidx69.i to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 %conv65.i, ptr %arrayidx69.i, align 4
  %51 = load ptr, ptr %2, align 8
  %52 = load i32, ptr %0, align 4
  %inc72.i = add i32 %52, 1
  store i32 %inc72.i, ptr %0, align 4
  %arrayidx73.i = getelementptr i32, ptr %51, i32 %52
  %53 = ptrtoint ptr %arrayidx73.i to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 -1073539840, ptr %arrayidx73.i, align 4
  %54 = load ptr, ptr %2, align 8
  %55 = load i32, ptr %0, align 4
  %inc76.i = add i32 %55, 1
  store i32 %inc76.i, ptr %0, align 4
  %arrayidx77.i = getelementptr i32, ptr %54, i32 %55
  %56 = ptrtoint ptr %arrayidx77.i to i32
  call void @__asan_store4_noabort(i32 %56)
  store i32 8, ptr %arrayidx77.i, align 4
  %57 = load ptr, ptr %2, align 8
  %58 = load i32, ptr %0, align 4
  %inc80.i = add i32 %58, 1
  store i32 %inc80.i, ptr %0, align 4
  %arrayidx81.i = getelementptr i32, ptr %57, i32 %58
  %59 = ptrtoint ptr %arrayidx81.i to i32
  call void @__asan_store4_noabort(i32 %59)
  store i32 1, ptr %arrayidx81.i, align 4
  %60 = load ptr, ptr %2, align 8
  %61 = load i32, ptr %0, align 4
  %inc84.i = add i32 %61, 1
  store i32 %inc84.i, ptr %0, align 4
  %arrayidx85.i = getelementptr i32, ptr %60, i32 %61
  %62 = ptrtoint ptr %arrayidx85.i to i32
  call void @__asan_store4_noabort(i32 %62)
  store i32 1, ptr %arrayidx85.i, align 4
  %63 = load ptr, ptr %2, align 8
  %64 = load i32, ptr %0, align 4
  %inc88.i = add i32 %64, 1
  store i32 %inc88.i, ptr %0, align 4
  %arrayidx89.i = getelementptr i32, ptr %63, i32 %64
  %65 = ptrtoint ptr %arrayidx89.i to i32
  call void @__asan_store4_noabort(i32 %65)
  store i32 1, ptr %arrayidx89.i, align 4
  %66 = load ptr, ptr %2, align 8
  %67 = load i32, ptr %0, align 4
  %inc92.i = add i32 %67, 1
  store i32 %inc92.i, ptr %0, align 4
  %arrayidx93.i = getelementptr i32, ptr %66, i32 %67
  %68 = ptrtoint ptr %arrayidx93.i to i32
  call void @__asan_store4_noabort(i32 %68)
  store i32 -1073723904, ptr %arrayidx93.i, align 4
  %69 = load ptr, ptr %2, align 8
  %70 = load i32, ptr %0, align 4
  %inc96.i = add i32 %70, 1
  store i32 %inc96.i, ptr %0, align 4
  %arrayidx97.i = getelementptr i32, ptr %69, i32 %70
  %71 = ptrtoint ptr %arrayidx97.i to i32
  call void @__asan_store4_noabort(i32 %71)
  store i32 1031, ptr %arrayidx97.i, align 4
  br label %for.body101.i

for.body101.i:                                    ; preds = %for.body101.i.for.body101.i_crit_edge, %for.end46.i
  %i.3344.i = phi i32 [ 0, %for.end46.i ], [ %add119.i, %for.body101.i.for.body101.i_crit_edge ]
  %72 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load ptr, ptr %2, align 8
  %74 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load i32, ptr %0, align 4
  %inc104.i = add i32 %75, 1
  store i32 %inc104.i, ptr %0, align 4
  %arrayidx105.i = getelementptr i32, ptr %73, i32 %75
  %76 = ptrtoint ptr %arrayidx105.i to i32
  call void @__asan_store4_noabort(i32 %76)
  store i32 -1073646080, ptr %arrayidx105.i, align 4
  %arrayidx106.i = getelementptr [34 x i32], ptr @sgpr1_init_regs, i32 0, i32 %i.3344.i
  %77 = ptrtoint ptr %arrayidx106.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %arrayidx106.i, align 4
  %sub107.i = add i32 %78, -11264
  %79 = load ptr, ptr %2, align 8
  %80 = load i32, ptr %0, align 4
  %inc110.i = add i32 %80, 1
  store i32 %inc110.i, ptr %0, align 4
  %arrayidx111.i = getelementptr i32, ptr %79, i32 %80
  %81 = ptrtoint ptr %arrayidx111.i to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 %sub107.i, ptr %arrayidx111.i, align 4
  %add112.i = or i32 %i.3344.i, 1
  %arrayidx113.i = getelementptr [34 x i32], ptr @sgpr1_init_regs, i32 0, i32 %add112.i
  %82 = ptrtoint ptr %arrayidx113.i to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load i32, ptr %arrayidx113.i, align 4
  %84 = load ptr, ptr %2, align 8
  %85 = load i32, ptr %0, align 4
  %inc116.i = add i32 %85, 1
  store i32 %inc116.i, ptr %0, align 4
  %arrayidx117.i = getelementptr i32, ptr %84, i32 %85
  %86 = ptrtoint ptr %arrayidx117.i to i32
  call void @__asan_store4_noabort(i32 %86)
  store i32 %83, ptr %arrayidx117.i, align 4
  %add119.i = add nuw nsw i32 %i.3344.i, 2
  %cmp99.i = icmp ult i32 %i.3344.i, 32
  br i1 %cmp99.i, label %for.body101.i.for.body101.i_crit_edge, label %for.end120.i

for.body101.i.for.body101.i_crit_edge:            ; preds = %for.body101.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body101.i

for.end120.i:                                     ; preds = %for.body101.i
  %87 = ptrtoint ptr %1 to i32
  call void @__asan_load8_noabort(i32 %87)
  %88 = load i64, ptr %1, align 8
  %add123.i = add i64 %88, 1280
  %shr124.i = lshr i64 %add123.i, 8
  %89 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load ptr, ptr %2, align 8
  %91 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %0, align 4
  %inc127.i = add i32 %92, 1
  store i32 %inc127.i, ptr %0, align 4
  %arrayidx128.i = getelementptr i32, ptr %90, i32 %92
  %93 = ptrtoint ptr %arrayidx128.i to i32
  call void @__asan_store4_noabort(i32 %93)
  store i32 -1073580544, ptr %arrayidx128.i, align 4
  %94 = load ptr, ptr %2, align 8
  %95 = load i32, ptr %0, align 4
  %inc131.i = add i32 %95, 1
  store i32 %inc131.i, ptr %0, align 4
  %arrayidx132.i = getelementptr i32, ptr %94, i32 %95
  %96 = ptrtoint ptr %arrayidx132.i to i32
  call void @__asan_store4_noabort(i32 %96)
  store i32 524, ptr %arrayidx132.i, align 4
  %conv134.i = trunc i64 %shr124.i to i32
  %97 = load ptr, ptr %2, align 8
  %98 = load i32, ptr %0, align 4
  %inc137.i = add i32 %98, 1
  store i32 %inc137.i, ptr %0, align 4
  %arrayidx138.i = getelementptr i32, ptr %97, i32 %98
  %99 = ptrtoint ptr %arrayidx138.i to i32
  call void @__asan_store4_noabort(i32 %99)
  store i32 %conv134.i, ptr %arrayidx138.i, align 4
  %shr139.i = lshr i64 %add123.i, 40
  %conv141.i = trunc i64 %shr139.i to i32
  %100 = load ptr, ptr %2, align 8
  %101 = load i32, ptr %0, align 4
  %inc144.i = add i32 %101, 1
  store i32 %inc144.i, ptr %0, align 4
  %arrayidx145.i = getelementptr i32, ptr %100, i32 %101
  %102 = ptrtoint ptr %arrayidx145.i to i32
  call void @__asan_store4_noabort(i32 %102)
  store i32 %conv141.i, ptr %arrayidx145.i, align 4
  %103 = load ptr, ptr %2, align 8
  %104 = load i32, ptr %0, align 4
  %inc148.i = add i32 %104, 1
  store i32 %inc148.i, ptr %0, align 4
  %arrayidx149.i = getelementptr i32, ptr %103, i32 %104
  %105 = ptrtoint ptr %arrayidx149.i to i32
  call void @__asan_store4_noabort(i32 %105)
  store i32 -1073539840, ptr %arrayidx149.i, align 4
  %106 = load ptr, ptr %2, align 8
  %107 = load i32, ptr %0, align 4
  %inc152.i = add i32 %107, 1
  store i32 %inc152.i, ptr %0, align 4
  %arrayidx153.i = getelementptr i32, ptr %106, i32 %107
  %108 = ptrtoint ptr %arrayidx153.i to i32
  call void @__asan_store4_noabort(i32 %108)
  store i32 8, ptr %arrayidx153.i, align 4
  %109 = load ptr, ptr %2, align 8
  %110 = load i32, ptr %0, align 4
  %inc156.i = add i32 %110, 1
  store i32 %inc156.i, ptr %0, align 4
  %arrayidx157.i = getelementptr i32, ptr %109, i32 %110
  %111 = ptrtoint ptr %arrayidx157.i to i32
  call void @__asan_store4_noabort(i32 %111)
  store i32 1, ptr %arrayidx157.i, align 4
  %112 = load ptr, ptr %2, align 8
  %113 = load i32, ptr %0, align 4
  %inc160.i = add i32 %113, 1
  store i32 %inc160.i, ptr %0, align 4
  %arrayidx161.i = getelementptr i32, ptr %112, i32 %113
  %114 = ptrtoint ptr %arrayidx161.i to i32
  call void @__asan_store4_noabort(i32 %114)
  store i32 1, ptr %arrayidx161.i, align 4
  %115 = load ptr, ptr %2, align 8
  %116 = load i32, ptr %0, align 4
  %inc164.i = add i32 %116, 1
  store i32 %inc164.i, ptr %0, align 4
  %arrayidx165.i = getelementptr i32, ptr %115, i32 %116
  %117 = ptrtoint ptr %arrayidx165.i to i32
  call void @__asan_store4_noabort(i32 %117)
  store i32 1, ptr %arrayidx165.i, align 4
  %118 = load ptr, ptr %2, align 8
  %119 = load i32, ptr %0, align 4
  %inc168.i = add i32 %119, 1
  store i32 %inc168.i, ptr %0, align 4
  %arrayidx169.i = getelementptr i32, ptr %118, i32 %119
  %120 = ptrtoint ptr %arrayidx169.i to i32
  call void @__asan_store4_noabort(i32 %120)
  store i32 -1073723904, ptr %arrayidx169.i, align 4
  %121 = load ptr, ptr %2, align 8
  %122 = load i32, ptr %0, align 4
  %inc172.i = add i32 %122, 1
  store i32 %inc172.i, ptr %0, align 4
  %arrayidx173.i = getelementptr i32, ptr %121, i32 %122
  %123 = ptrtoint ptr %arrayidx173.i to i32
  call void @__asan_store4_noabort(i32 %123)
  store i32 1031, ptr %arrayidx173.i, align 4
  br label %for.body177.i

for.body177.i:                                    ; preds = %for.body177.i.for.body177.i_crit_edge, %for.end120.i
  %i.4345.i = phi i32 [ 0, %for.end120.i ], [ %add195.i, %for.body177.i.for.body177.i_crit_edge ]
  %124 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load ptr, ptr %2, align 8
  %126 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load i32, ptr %0, align 4
  %inc180.i = add i32 %127, 1
  store i32 %inc180.i, ptr %0, align 4
  %arrayidx181.i = getelementptr i32, ptr %125, i32 %127
  %128 = ptrtoint ptr %arrayidx181.i to i32
  call void @__asan_store4_noabort(i32 %128)
  store i32 -1073646080, ptr %arrayidx181.i, align 4
  %arrayidx182.i = getelementptr [34 x i32], ptr @sgpr2_init_regs, i32 0, i32 %i.4345.i
  %129 = ptrtoint ptr %arrayidx182.i to i32
  call void @__asan_load4_noabort(i32 %129)
  %130 = load i32, ptr %arrayidx182.i, align 4
  %sub183.i = add i32 %130, -11264
  %131 = load ptr, ptr %2, align 8
  %132 = load i32, ptr %0, align 4
  %inc186.i = add i32 %132, 1
  store i32 %inc186.i, ptr %0, align 4
  %arrayidx187.i = getelementptr i32, ptr %131, i32 %132
  %133 = ptrtoint ptr %arrayidx187.i to i32
  call void @__asan_store4_noabort(i32 %133)
  store i32 %sub183.i, ptr %arrayidx187.i, align 4
  %add188.i = or i32 %i.4345.i, 1
  %arrayidx189.i = getelementptr [34 x i32], ptr @sgpr2_init_regs, i32 0, i32 %add188.i
  %134 = ptrtoint ptr %arrayidx189.i to i32
  call void @__asan_load4_noabort(i32 %134)
  %135 = load i32, ptr %arrayidx189.i, align 4
  %136 = load ptr, ptr %2, align 8
  %137 = load i32, ptr %0, align 4
  %inc192.i = add i32 %137, 1
  store i32 %inc192.i, ptr %0, align 4
  %arrayidx193.i = getelementptr i32, ptr %136, i32 %137
  %138 = ptrtoint ptr %arrayidx193.i to i32
  call void @__asan_store4_noabort(i32 %138)
  store i32 %135, ptr %arrayidx193.i, align 4
  %add195.i = add nuw nsw i32 %i.4345.i, 2
  %cmp175.i = icmp ult i32 %i.4345.i, 32
  br i1 %cmp175.i, label %for.body177.i.for.body177.i_crit_edge, label %for.end196.i

for.body177.i.for.body177.i_crit_edge:            ; preds = %for.body177.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body177.i

for.end196.i:                                     ; preds = %for.body177.i
  %139 = ptrtoint ptr %1 to i32
  call void @__asan_load8_noabort(i32 %139)
  %140 = load i64, ptr %1, align 8
  %add199.i = add i64 %140, 1280
  %shr200.i = lshr i64 %add199.i, 8
  %141 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %141)
  %142 = load ptr, ptr %2, align 8
  %143 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %143)
  %144 = load i32, ptr %0, align 4
  %inc203.i = add i32 %144, 1
  store i32 %inc203.i, ptr %0, align 4
  %arrayidx204.i = getelementptr i32, ptr %142, i32 %144
  %145 = ptrtoint ptr %arrayidx204.i to i32
  call void @__asan_store4_noabort(i32 %145)
  store i32 -1073580544, ptr %arrayidx204.i, align 4
  %146 = load ptr, ptr %2, align 8
  %147 = load i32, ptr %0, align 4
  %inc207.i = add i32 %147, 1
  store i32 %inc207.i, ptr %0, align 4
  %arrayidx208.i = getelementptr i32, ptr %146, i32 %147
  %148 = ptrtoint ptr %arrayidx208.i to i32
  call void @__asan_store4_noabort(i32 %148)
  store i32 524, ptr %arrayidx208.i, align 4
  %conv210.i = trunc i64 %shr200.i to i32
  %149 = load ptr, ptr %2, align 8
  %150 = load i32, ptr %0, align 4
  %inc213.i = add i32 %150, 1
  store i32 %inc213.i, ptr %0, align 4
  %arrayidx214.i = getelementptr i32, ptr %149, i32 %150
  %151 = ptrtoint ptr %arrayidx214.i to i32
  call void @__asan_store4_noabort(i32 %151)
  store i32 %conv210.i, ptr %arrayidx214.i, align 4
  %shr215.i = lshr i64 %add199.i, 40
  %conv217.i = trunc i64 %shr215.i to i32
  %152 = load ptr, ptr %2, align 8
  %153 = load i32, ptr %0, align 4
  %inc220.i = add i32 %153, 1
  store i32 %inc220.i, ptr %0, align 4
  %arrayidx221.i = getelementptr i32, ptr %152, i32 %153
  %154 = ptrtoint ptr %arrayidx221.i to i32
  call void @__asan_store4_noabort(i32 %154)
  store i32 %conv217.i, ptr %arrayidx221.i, align 4
  %155 = load ptr, ptr %2, align 8
  %156 = load i32, ptr %0, align 4
  %inc224.i = add i32 %156, 1
  store i32 %inc224.i, ptr %0, align 4
  %arrayidx225.i = getelementptr i32, ptr %155, i32 %156
  %157 = ptrtoint ptr %arrayidx225.i to i32
  call void @__asan_store4_noabort(i32 %157)
  store i32 -1073539840, ptr %arrayidx225.i, align 4
  %158 = load ptr, ptr %2, align 8
  %159 = load i32, ptr %0, align 4
  %inc228.i = add i32 %159, 1
  store i32 %inc228.i, ptr %0, align 4
  %arrayidx229.i = getelementptr i32, ptr %158, i32 %159
  %160 = ptrtoint ptr %arrayidx229.i to i32
  call void @__asan_store4_noabort(i32 %160)
  store i32 8, ptr %arrayidx229.i, align 4
  %161 = load ptr, ptr %2, align 8
  %162 = load i32, ptr %0, align 4
  %inc232.i = add i32 %162, 1
  store i32 %inc232.i, ptr %0, align 4
  %arrayidx233.i = getelementptr i32, ptr %161, i32 %162
  %163 = ptrtoint ptr %arrayidx233.i to i32
  call void @__asan_store4_noabort(i32 %163)
  store i32 1, ptr %arrayidx233.i, align 4
  %164 = load ptr, ptr %2, align 8
  %165 = load i32, ptr %0, align 4
  %inc236.i = add i32 %165, 1
  store i32 %inc236.i, ptr %0, align 4
  %arrayidx237.i = getelementptr i32, ptr %164, i32 %165
  %166 = ptrtoint ptr %arrayidx237.i to i32
  call void @__asan_store4_noabort(i32 %166)
  store i32 1, ptr %arrayidx237.i, align 4
  %167 = load ptr, ptr %2, align 8
  %168 = load i32, ptr %0, align 4
  %inc240.i = add i32 %168, 1
  store i32 %inc240.i, ptr %0, align 4
  %arrayidx241.i = getelementptr i32, ptr %167, i32 %168
  %169 = ptrtoint ptr %arrayidx241.i to i32
  call void @__asan_store4_noabort(i32 %169)
  store i32 1, ptr %arrayidx241.i, align 4
  %170 = load ptr, ptr %2, align 8
  %171 = load i32, ptr %0, align 4
  %inc244.i = add i32 %171, 1
  store i32 %inc244.i, ptr %0, align 4
  %arrayidx245.i = getelementptr i32, ptr %170, i32 %171
  %172 = ptrtoint ptr %arrayidx245.i to i32
  call void @__asan_store4_noabort(i32 %172)
  store i32 -1073723904, ptr %arrayidx245.i, align 4
  %173 = load ptr, ptr %2, align 8
  %174 = load i32, ptr %0, align 4
  %inc248.i = add i32 %174, 1
  store i32 %inc248.i, ptr %0, align 4
  %arrayidx249.i = getelementptr i32, ptr %173, i32 %174
  %175 = ptrtoint ptr %arrayidx249.i to i32
  call void @__asan_store4_noabort(i32 %175)
  store i32 1031, ptr %arrayidx249.i, align 4
  %call250.i = call i32 @amdgpu_ib_schedule(ptr noundef %compute_ring.i, i32 noundef 1, ptr noundef nonnull %ib.i, ptr noundef null, ptr noundef nonnull %f.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call250.i)
  %tobool251.not.i = icmp eq i32 %call250.i, 0
  br i1 %tobool251.not.i, label %if.end253.i, label %if.then252.i

if.then252.i:                                     ; preds = %for.end196.i
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.34, i32 noundef %call250.i) #12
  br label %fail.i

if.end253.i:                                      ; preds = %for.end196.i
  %176 = ptrtoint ptr %f.i to i32
  call void @__asan_load4_noabort(i32 %176)
  %177 = load ptr, ptr %f.i, align 4
  %call.i.i = call i32 @dma_fence_wait_timeout(ptr noundef %177, i1 noundef zeroext false, i32 noundef 2147483647) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %call.i.i)
  %tobool255.not.i = icmp sgt i32 %call.i.i, -1
  br i1 %tobool255.not.i, label %if.end257.i, label %if.then256.i

if.then256.i:                                     ; preds = %if.end253.i
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.35, i32 noundef %call.i.i) #12
  br label %fail.i

if.end257.i:                                      ; preds = %if.end253.i
  %and258.i = and i32 %call.i, -540016641
  %or260.i = or i32 %and258.i, 538968064
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12414, i32 noundef %or260.i, i32 noundef 0) #12
  %call261.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12440, i32 noundef 0) #12
  %and262.i = and i32 %call261.i, -4
  %or264.i = or i32 %and262.i, 1
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12440, i32 noundef %or264.i, i32 noundef 0) #12
  br label %for.body268.i

for.body268.i:                                    ; preds = %for.body268.i.for.body268.i_crit_edge, %if.end257.i
  %i.5346.i = phi i32 [ 0, %if.end257.i ], [ %inc272.i, %for.body268.i.for.body268.i_crit_edge ]
  %arrayidx269.i = getelementptr [25 x i32], ptr @sec_ded_counter_registers, i32 0, i32 %i.5346.i
  %178 = ptrtoint ptr %arrayidx269.i to i32
  call void @__asan_load4_noabort(i32 %178)
  %179 = load i32, ptr %arrayidx269.i, align 4
  %call270.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef %179, i32 noundef 0) #12
  %inc272.i = add nuw nsw i32 %i.5346.i, 1
  %exitcond348.not.i = icmp eq i32 %inc272.i, 25
  br i1 %exitcond348.not.i, label %for.body268.i.fail.i_crit_edge, label %for.body268.i.for.body268.i_crit_edge

for.body268.i.for.body268.i_crit_edge:            ; preds = %for.body268.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body268.i

for.body268.i.fail.i_crit_edge:                   ; preds = %for.body268.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %fail.i

fail.i:                                           ; preds = %for.body268.i.fail.i_crit_edge, %if.then256.i, %if.then252.i
  %r.0.i = phi i32 [ %call250.i, %if.then252.i ], [ %call.i.i, %if.then256.i ], [ 0, %for.body268.i.fail.i_crit_edge ]
  call void @amdgpu_ib_free(ptr noundef %handle, ptr noundef nonnull %ib.i, ptr noundef null) #12
  %180 = ptrtoint ptr %f.i to i32
  call void @__asan_load4_noabort(i32 %180)
  %181 = load ptr, ptr %f.i, align 4
  %tobool.not.i.i = icmp eq ptr %181, null
  br i1 %tobool.not.i.i, label %fail.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge, label %if.then.i.i

fail.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge: ; preds = %fail.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit

if.then.i.i:                                      ; preds = %fail.i
  %refcount.i.i = getelementptr inbounds %struct.dma_fence, ptr %181, i32 0, i32 6
  %call.i.i.i.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %refcount.i.i, i32 noundef 4) #12
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #12, !srcloc !433
  call void @llvm.prefetch.p0(ptr %refcount.i.i, i32 1, i32 3, i32 1) #12
  %182 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %refcount.i.i, ptr %refcount.i.i, i32 1, ptr elementtype(i32) %refcount.i.i) #12, !srcloc !434
  %asmresult.i.i.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %182, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %asmresult.i.i.i.i.i.i.i.i.i)
  %cmp.i.i.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i.i.i, label %if.then.i.i.i, label %if.end5.i.i.i.i.i.i

if.end5.i.i.i.i.i.i:                              ; preds = %if.then.i.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %asmresult.i.i.i.i.i.i.i.i.i)
  %.not.i.i.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i.i.i, label %if.end5.i.i.i.i.i.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge, label %if.then10.i.i.i.i.i.i, !prof !435

if.end5.i.i.i.i.i.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge: ; preds = %if.end5.i.i.i.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit

if.then10.i.i.i.i.i.i:                            ; preds = %if.end5.i.i.i.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  call void @refcount_warn_saturate(ptr noundef %refcount.i.i, i32 noundef 3) #12
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit

if.then.i.i.i:                                    ; preds = %if.then.i.i
  call void @__sanitizer_cov_trace_pc() #14
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #12, !srcloc !436
  call void @dma_fence_release(ptr noundef %refcount.i.i) #12
  br label %gfx_v8_0_do_edc_gpr_workarounds.exit

gfx_v8_0_do_edc_gpr_workarounds.exit.thread:      ; preds = %if.end.i.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge, %if.end5.gfx_v8_0_do_edc_gpr_workarounds.exit.thread_crit_edge
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %f.i) #12
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %ib.i) #12
  br label %if.end9

gfx_v8_0_do_edc_gpr_workarounds.exit:             ; preds = %if.then.i.i.i, %if.then10.i.i.i.i.i.i, %if.end5.i.i.i.i.i.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge, %fail.i.gfx_v8_0_do_edc_gpr_workarounds.exit_crit_edge
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %f.i) #12
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %ib.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %r.0.i)
  %tobool7.not = icmp eq i32 %r.0.i, 0
  br i1 %tobool7.not, label %gfx_v8_0_do_edc_gpr_workarounds.exit.if.end9_crit_edge, label %gfx_v8_0_do_edc_gpr_workarounds.exit.cleanup_crit_edge

gfx_v8_0_do_edc_gpr_workarounds.exit.cleanup_crit_edge: ; preds = %gfx_v8_0_do_edc_gpr_workarounds.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

gfx_v8_0_do_edc_gpr_workarounds.exit.if.end9_crit_edge: ; preds = %gfx_v8_0_do_edc_gpr_workarounds.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end9

if.end9:                                          ; preds = %gfx_v8_0_do_edc_gpr_workarounds.exit.if.end9_crit_edge, %gfx_v8_0_do_edc_gpr_workarounds.exit.thread
  %cp_ecc_error_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 43
  %call11 = call i32 @amdgpu_irq_get(ptr noundef %handle, ptr noundef %cp_ecc_error_irq, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call11)
  %tobool12.not = icmp eq i32 %call11, 0
  br i1 %tobool12.not, label %if.end14, label %if.then13

if.then13:                                        ; preds = %if.end9
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.31, i32 noundef %call11) #12
  br label %cleanup

if.end14:                                         ; preds = %if.end9
  %sq_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 44
  %call16 = call i32 @amdgpu_irq_get(ptr noundef %handle, ptr noundef %sq_irq, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call16)
  %tobool17.not = icmp eq i32 %call16, 0
  br i1 %tobool17.not, label %if.end14.cleanup_crit_edge, label %if.then18

if.end14.cleanup_crit_edge:                       ; preds = %if.end14
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then18:                                        ; preds = %if.end14
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.32, i32 noundef %call16) #12
  br label %cleanup

cleanup:                                          ; preds = %if.then18, %if.end14.cleanup_crit_edge, %if.then13, %gfx_v8_0_do_edc_gpr_workarounds.exit.cleanup_crit_edge, %gfx_v8_0_do_edc_gpr_workarounds.exit.thread42, %if.end.cleanup_crit_edge, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ %call11, %if.then13 ], [ %call16, %if.then18 ], [ %call, %entry.cleanup_crit_edge ], [ %call2, %if.end.cleanup_crit_edge ], [ %r.0.i, %gfx_v8_0_do_edc_gpr_workarounds.exit.cleanup_crit_edge ], [ 0, %if.end14.cleanup_crit_edge ], [ %call7.i, %gfx_v8_0_do_edc_gpr_workarounds.exit.thread42 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_sw_init(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %0 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %asic_type, align 8
  %switch.tableidx = add i32 %1, -11
  call void @__sanitizer_cov_trace_const_cmp4(i32 8, i32 %switch.tableidx)
  %2 = icmp ult i32 %switch.tableidx, 8
  br i1 %2, label %switch.lookup, label %entry.sw.epilog_crit_edge

entry.sw.epilog_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

switch.lookup:                                    ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %switch.gep = getelementptr inbounds [8 x i32], ptr @switch.table.gfx_v8_0_sw_init, i32 0, i32 %switch.tableidx
  %3 = ptrtoint ptr %switch.gep to i32
  call void @__asan_load4_noabort(i32 %3)
  %switch.load = load i32, ptr %switch.gep, align 4
  br label %sw.epilog

sw.epilog:                                        ; preds = %switch.lookup, %entry.sw.epilog_crit_edge
  %.sink = phi i32 [ %switch.load, %switch.lookup ], [ 1, %entry.sw.epilog_crit_edge ]
  %num_mec4 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 6, i32 4
  %4 = ptrtoint ptr %num_mec4 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %.sink, ptr %num_mec4, align 8
  %num_pipe_per_mec = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 6, i32 5
  %5 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 4, ptr %num_pipe_per_mec, align 4
  %num_queue_per_pipe = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 6, i32 6
  %6 = ptrtoint ptr %num_queue_per_pipe to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 8, ptr %num_queue_per_pipe, align 8
  %eop_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 40
  %call = tail call i32 @amdgpu_irq_add_id(ptr noundef %handle, i32 noundef 0, i32 noundef 181, ptr noundef %eop_irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %sw.epilog.cleanup_crit_edge

sw.epilog.cleanup_crit_edge:                      ; preds = %sw.epilog
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %sw.epilog
  %priv_reg_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 41
  %call11 = tail call i32 @amdgpu_irq_add_id(ptr noundef %handle, i32 noundef 0, i32 noundef 184, ptr noundef %priv_reg_irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call11)
  %tobool12.not = icmp eq i32 %call11, 0
  br i1 %tobool12.not, label %if.end14, label %if.end.cleanup_crit_edge

if.end.cleanup_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end14:                                         ; preds = %if.end
  %priv_inst_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 42
  %call16 = tail call i32 @amdgpu_irq_add_id(ptr noundef %handle, i32 noundef 0, i32 noundef 185, ptr noundef %priv_inst_irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call16)
  %tobool17.not = icmp eq i32 %call16, 0
  br i1 %tobool17.not, label %if.end19, label %if.end14.cleanup_crit_edge

if.end14.cleanup_crit_edge:                       ; preds = %if.end14
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end19:                                         ; preds = %if.end14
  %cp_ecc_error_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 43
  %call21 = tail call i32 @amdgpu_irq_add_id(ptr noundef %handle, i32 noundef 0, i32 noundef 197, ptr noundef %cp_ecc_error_irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call21)
  %tobool22.not = icmp eq i32 %call21, 0
  br i1 %tobool22.not, label %if.end24, label %if.end19.cleanup_crit_edge

if.end19.cleanup_crit_edge:                       ; preds = %if.end19
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end24:                                         ; preds = %if.end19
  %sq_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 44
  %call26 = tail call i32 @amdgpu_irq_add_id(ptr noundef %handle, i32 noundef 0, i32 noundef 239, ptr noundef %sq_irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call26)
  %tobool27.not = icmp eq i32 %call26, 0
  br i1 %tobool27.not, label %do.body, label %if.then28

if.then28:                                        ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.36, i32 noundef %call26) #12
  br label %cleanup

do.body:                                          ; preds = %if.end24
  %sq_work = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 45
  tail call void @__init_work(ptr noundef %sq_work, i32 noundef 0) #12
  %7 = ptrtoint ptr %sq_work to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -64, ptr %sq_work, align 8
  %lockdep_map = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 45, i32 0, i32 3
  tail call void @lockdep_init_map_type(ptr noundef %lockdep_map, ptr noundef nonnull @.str.37, ptr noundef nonnull @gfx_v8_0_sw_init.__key, i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #12
  %entry40 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 45, i32 0, i32 1
  %8 = ptrtoint ptr %entry40 to i32
  call void @__asan_store4_noabort(i32 %8)
  store volatile ptr %entry40, ptr %entry40, align 4
  %prev.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 45, i32 0, i32 1, i32 1
  %9 = ptrtoint ptr %prev.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store ptr %entry40, ptr %prev.i, align 4
  %func = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 45, i32 0, i32 2
  %10 = ptrtoint ptr %func to i32
  call void @__asan_store4_noabort(i32 %10)
  store ptr @gfx_v8_0_sq_irq_work_func, ptr %func, align 4
  %gfx_current_status = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 46
  %11 = ptrtoint ptr %gfx_current_status to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 0, ptr %gfx_current_status, align 8
  %scratch.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 8
  %12 = ptrtoint ptr %scratch.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 8, ptr %scratch.i, align 8
  %reg_base.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 8, i32 1
  %13 = ptrtoint ptr %reg_base.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 49216, ptr %reg_base.i, align 4
  %free_mask.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 8, i32 2
  %14 = ptrtoint ptr %free_mask.i to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 255, ptr %free_mask.i, align 8
  %call45 = tail call fastcc i32 @gfx_v8_0_init_microcode(ptr noundef %handle)
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call45)
  %tobool46.not = icmp eq i32 %call45, 0
  br i1 %tobool46.not, label %if.end48, label %if.then47

if.then47:                                        ; preds = %do.body
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.38) #12
  br label %cleanup

if.end48:                                         ; preds = %do.body
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %15 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %funcs, align 4
  %init = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %16, i32 0, i32 3
  %17 = ptrtoint ptr %init to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %init, align 4
  %call50 = tail call i32 %18(ptr noundef %handle) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call50)
  %tobool51.not = icmp eq i32 %call50, 0
  br i1 %tobool51.not, label %if.end53, label %if.then52

if.then52:                                        ; preds = %if.end48
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.39) #12
  br label %cleanup

if.end53:                                         ; preds = %if.end48
  %call54 = tail call fastcc i32 @gfx_v8_0_mec_init(ptr noundef %handle)
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call54)
  %tobool55.not = icmp eq i32 %call54, 0
  br i1 %tobool55.not, label %for.cond.preheader, label %if.then56

for.cond.preheader:                               ; preds = %if.end53
  %num_gfx_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 37
  %19 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %num_gfx_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %20)
  %cmp225.not = icmp eq i32 %20, 0
  br i1 %cmp225.not, label %for.cond.preheader.for.cond72.preheader_crit_edge, label %for.body.lr.ph

for.cond.preheader.for.cond72.preheader_crit_edge: ; preds = %for.cond.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond72.preheader

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %gfx_ring0 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 144, i32 11
  br label %for.body

if.then56:                                        ; preds = %if.end53
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.40) #12
  br label %cleanup

for.cond:                                         ; preds = %if.end65
  %inc = add nuw i32 %i.0226, 1
  %21 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %num_gfx_rings, align 8
  %cmp = icmp ult i32 %inc, %22
  br i1 %cmp, label %for.cond.for.body_crit_edge, label %for.cond.for.cond72.preheader_crit_edge

for.cond.for.cond72.preheader_crit_edge:          ; preds = %for.cond
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond72.preheader

for.cond.for.body_crit_edge:                      ; preds = %for.cond
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.cond72.preheader:                             ; preds = %for.cond.for.cond72.preheader_crit_edge, %for.cond.preheader.for.cond72.preheader_crit_edge
  %num_mec75 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 6, i32 4
  %23 = ptrtoint ptr %num_mec75 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %num_mec75, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %24)
  %cmp76237.not = icmp eq i32 %24, 0
  br i1 %cmp76237.not, label %for.cond72.preheader.for.end106_crit_edge, label %for.cond72.preheader.for.cond78.preheader_crit_edge

for.cond72.preheader.for.cond78.preheader_crit_edge: ; preds = %for.cond72.preheader
  br label %for.cond78.preheader

for.cond72.preheader.for.end106_crit_edge:        ; preds = %for.cond72.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end106

for.body:                                         ; preds = %for.cond.for.body_crit_edge, %for.body.lr.ph
  %i.0226 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.cond.for.body_crit_edge ]
  %arrayidx = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.0226
  %ring_obj = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.0226, i32 4
  %25 = ptrtoint ptr %ring_obj to i32
  call void @__asan_store4_noabort(i32 %25)
  store ptr null, ptr %ring_obj, align 8
  %name = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.0226, i32 29
  %26 = ptrtoint ptr %name to i32
  call void @__asan_storeN_noabort(i32 %26, i32 4)
  store i32 1734768640, ptr %name, align 1
  %27 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %asic_type, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 10, i32 %28)
  %cmp62.not = icmp eq i32 %28, 10
  br i1 %cmp62.not, label %for.body.if.end65_crit_edge, label %if.then63

for.body.if.end65_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end65

if.then63:                                        ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  %use_doorbell = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.0226, i32 24
  %29 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_store1_noabort(i32 %29)
  store i8 1, ptr %use_doorbell, align 4
  %30 = ptrtoint ptr %gfx_ring0 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %gfx_ring0, align 4
  %doorbell_index64 = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.0226, i32 23
  %32 = ptrtoint ptr %doorbell_index64 to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %31, ptr %doorbell_index64, align 8
  br label %if.end65

if.end65:                                         ; preds = %if.then63, %for.body.if.end65_crit_edge
  %call68 = tail call i32 @amdgpu_ring_init(ptr noundef %handle, ptr noundef %arrayidx, i32 noundef 1024, ptr noundef %eop_irq, i32 noundef 0, i32 noundef 1, ptr noundef null) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call68)
  %tobool69.not = icmp eq i32 %call68, 0
  br i1 %tobool69.not, label %for.cond, label %if.end65.cleanup_crit_edge

if.end65.cleanup_crit_edge:                       ; preds = %if.end65
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

for.cond78.preheader:                             ; preds = %for.inc104.for.cond78.preheader_crit_edge, %for.cond72.preheader.for.cond78.preheader_crit_edge
  %ring_id.0240 = phi i32 [ %ring_id.1.lcssa, %for.inc104.for.cond78.preheader_crit_edge ], [ 0, %for.cond72.preheader.for.cond78.preheader_crit_edge ]
  %i.1238 = phi i32 [ %inc105, %for.inc104.for.cond78.preheader_crit_edge ], [ 0, %for.cond72.preheader.for.cond78.preheader_crit_edge ]
  %33 = ptrtoint ptr %num_queue_per_pipe to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %num_queue_per_pipe, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %34)
  %cmp82232.not = icmp eq i32 %34, 0
  br i1 %cmp82232.not, label %for.cond78.preheader.for.inc104_crit_edge, label %for.cond78.preheader.for.cond84.preheader_crit_edge

for.cond78.preheader.for.cond84.preheader_crit_edge: ; preds = %for.cond78.preheader
  br label %for.cond84.preheader

for.cond78.preheader.for.inc104_crit_edge:        ; preds = %for.cond78.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc104

for.cond84.preheader:                             ; preds = %for.inc101.for.cond84.preheader_crit_edge, %for.cond78.preheader.for.cond84.preheader_crit_edge
  %ring_id.1235 = phi i32 [ %ring_id.2.lcssa, %for.inc101.for.cond84.preheader_crit_edge ], [ %ring_id.0240, %for.cond78.preheader.for.cond84.preheader_crit_edge ]
  %j.0233 = phi i32 [ %inc102, %for.inc101.for.cond84.preheader_crit_edge ], [ 0, %for.cond78.preheader.for.cond84.preheader_crit_edge ]
  %35 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %36)
  %cmp88228.not = icmp eq i32 %36, 0
  br i1 %cmp88228.not, label %for.cond84.preheader.for.inc101_crit_edge, label %for.cond84.preheader.for.body89_crit_edge

for.cond84.preheader.for.body89_crit_edge:        ; preds = %for.cond84.preheader
  br label %for.body89

for.cond84.preheader.for.inc101_crit_edge:        ; preds = %for.cond84.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc101

for.body89:                                       ; preds = %for.inc98.for.body89_crit_edge, %for.cond84.preheader.for.body89_crit_edge
  %ring_id.2231 = phi i32 [ %ring_id.3, %for.inc98.for.body89_crit_edge ], [ %ring_id.1235, %for.cond84.preheader.for.body89_crit_edge ]
  %k.0229 = phi i32 [ %inc99, %for.inc98.for.body89_crit_edge ], [ 0, %for.cond84.preheader.for.body89_crit_edge ]
  %call90 = tail call zeroext i1 @amdgpu_gfx_is_mec_queue_enabled(ptr noundef %handle, i32 noundef %i.1238, i32 noundef %k.0229, i32 noundef %j.0233) #12
  br i1 %call90, label %if.end92, label %for.body89.for.inc98_crit_edge

for.body89.for.inc98_crit_edge:                   ; preds = %for.body89
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc98

if.end92:                                         ; preds = %for.body89
  %call93 = tail call fastcc i32 @gfx_v8_0_compute_ring_init(ptr noundef %handle, i32 noundef %ring_id.2231, i32 noundef %i.1238, i32 noundef %k.0229, i32 noundef %j.0233)
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call93)
  %tobool94.not = icmp eq i32 %call93, 0
  br i1 %tobool94.not, label %if.end96, label %if.end92.cleanup_crit_edge

if.end92.cleanup_crit_edge:                       ; preds = %if.end92
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end96:                                         ; preds = %if.end92
  call void @__sanitizer_cov_trace_pc() #14
  %inc97 = add i32 %ring_id.2231, 1
  br label %for.inc98

for.inc98:                                        ; preds = %if.end96, %for.body89.for.inc98_crit_edge
  %ring_id.3 = phi i32 [ %inc97, %if.end96 ], [ %ring_id.2231, %for.body89.for.inc98_crit_edge ]
  %inc99 = add nuw i32 %k.0229, 1
  %37 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %num_pipe_per_mec, align 4
  %cmp88 = icmp ult i32 %inc99, %38
  br i1 %cmp88, label %for.inc98.for.body89_crit_edge, label %for.inc98.for.inc101_crit_edge

for.inc98.for.inc101_crit_edge:                   ; preds = %for.inc98
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc101

for.inc98.for.body89_crit_edge:                   ; preds = %for.inc98
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body89

for.inc101:                                       ; preds = %for.inc98.for.inc101_crit_edge, %for.cond84.preheader.for.inc101_crit_edge
  %ring_id.2.lcssa = phi i32 [ %ring_id.1235, %for.cond84.preheader.for.inc101_crit_edge ], [ %ring_id.3, %for.inc98.for.inc101_crit_edge ]
  %inc102 = add nuw i32 %j.0233, 1
  %39 = ptrtoint ptr %num_queue_per_pipe to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %num_queue_per_pipe, align 8
  %cmp82 = icmp ult i32 %inc102, %40
  br i1 %cmp82, label %for.inc101.for.cond84.preheader_crit_edge, label %for.inc101.for.inc104_crit_edge

for.inc101.for.inc104_crit_edge:                  ; preds = %for.inc101
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc104

for.inc101.for.cond84.preheader_crit_edge:        ; preds = %for.inc101
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond84.preheader

for.inc104:                                       ; preds = %for.inc101.for.inc104_crit_edge, %for.cond78.preheader.for.inc104_crit_edge
  %ring_id.1.lcssa = phi i32 [ %ring_id.0240, %for.cond78.preheader.for.inc104_crit_edge ], [ %ring_id.2.lcssa, %for.inc101.for.inc104_crit_edge ]
  %inc105 = add nuw i32 %i.1238, 1
  %41 = ptrtoint ptr %num_mec75 to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %num_mec75, align 8
  %cmp76 = icmp ult i32 %inc105, %42
  br i1 %cmp76, label %for.inc104.for.cond78.preheader_crit_edge, label %for.inc104.for.end106_crit_edge

for.inc104.for.end106_crit_edge:                  ; preds = %for.inc104
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end106

for.inc104.for.cond78.preheader_crit_edge:        ; preds = %for.inc104
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond78.preheader

for.end106:                                       ; preds = %for.inc104.for.end106_crit_edge, %for.cond72.preheader.for.end106_crit_edge
  %call107 = tail call i32 @amdgpu_gfx_kiq_init(ptr noundef %handle, i32 noundef 4096) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call107)
  %tobool108.not = icmp eq i32 %call107, 0
  br i1 %tobool108.not, label %if.end110, label %if.then109

if.then109:                                       ; preds = %for.end106
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.42) #12
  br label %cleanup

if.end110:                                        ; preds = %for.end106
  %ring113 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3
  %irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 4
  %call114 = tail call i32 @amdgpu_gfx_kiq_init_ring(ptr noundef %handle, ptr noundef %ring113, ptr noundef %irq) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call114)
  %tobool115.not = icmp eq i32 %call114, 0
  br i1 %tobool115.not, label %if.end117, label %if.end110.cleanup_crit_edge

if.end110.cleanup_crit_edge:                      ; preds = %if.end110
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end117:                                        ; preds = %if.end110
  %call118 = tail call i32 @amdgpu_gfx_mqd_sw_init(ptr noundef %handle, i32 noundef 2064) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call118)
  %tobool119.not = icmp eq i32 %call118, 0
  br i1 %tobool119.not, label %if.end121, label %if.end117.cleanup_crit_edge

if.end117.cleanup_crit_edge:                      ; preds = %if.end117
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end121:                                        ; preds = %if.end117
  call void @__sanitizer_cov_trace_pc() #14
  %ce_ram_size = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 47
  %43 = ptrtoint ptr %ce_ram_size to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 32768, ptr %ce_ram_size, align 4
  %call123 = tail call fastcc i32 @gfx_v8_0_gpu_early_init(ptr noundef %handle)
  br label %cleanup

cleanup:                                          ; preds = %if.end121, %if.end117.cleanup_crit_edge, %if.end110.cleanup_crit_edge, %if.then109, %if.end92.cleanup_crit_edge, %if.end65.cleanup_crit_edge, %if.then56, %if.then52, %if.then47, %if.then28, %if.end19.cleanup_crit_edge, %if.end14.cleanup_crit_edge, %if.end.cleanup_crit_edge, %sw.epilog.cleanup_crit_edge
  %retval.0 = phi i32 [ %call26, %if.then28 ], [ %call45, %if.then47 ], [ %call50, %if.then52 ], [ %call54, %if.then56 ], [ %call107, %if.then109 ], [ %call, %sw.epilog.cleanup_crit_edge ], [ %call11, %if.end.cleanup_crit_edge ], [ %call16, %if.end14.cleanup_crit_edge ], [ %call21, %if.end19.cleanup_crit_edge ], [ %call114, %if.end110.cleanup_crit_edge ], [ %call118, %if.end117.cleanup_crit_edge ], [ %call123, %if.end121 ], [ %call93, %if.end92.cleanup_crit_edge ], [ %call68, %if.end65.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_sw_fini(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %num_gfx_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 37
  %0 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %num_gfx_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp48.not = icmp eq i32 %1, 0
  br i1 %cmp48.not, label %entry.for.cond2.preheader_crit_edge, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  br label %for.body

entry.for.cond2.preheader_crit_edge:              ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond2.preheader

for.cond2.preheader:                              ; preds = %for.body.for.cond2.preheader_crit_edge, %entry.for.cond2.preheader_crit_edge
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %2 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %cmp450.not = icmp eq i32 %3, 0
  br i1 %cmp450.not, label %for.cond2.preheader.for.end10_crit_edge, label %for.cond2.preheader.for.body5_crit_edge

for.cond2.preheader.for.body5_crit_edge:          ; preds = %for.cond2.preheader
  br label %for.body5

for.cond2.preheader.for.end10_crit_edge:          ; preds = %for.cond2.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end10

for.body:                                         ; preds = %for.body.for.body_crit_edge, %entry.for.body_crit_edge
  %i.049 = phi i32 [ %inc, %for.body.for.body_crit_edge ], [ 0, %entry.for.body_crit_edge ]
  %arrayidx = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36, i32 %i.049
  tail call void @amdgpu_ring_fini(ptr noundef %arrayidx) #12
  %inc = add nuw i32 %i.049, 1
  %4 = ptrtoint ptr %num_gfx_rings to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %num_gfx_rings, align 8
  %cmp = icmp ult i32 %inc, %5
  br i1 %cmp, label %for.body.for.body_crit_edge, label %for.body.for.cond2.preheader_crit_edge

for.body.for.cond2.preheader_crit_edge:           ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond2.preheader

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.body5:                                        ; preds = %for.body5.for.body5_crit_edge, %for.cond2.preheader.for.body5_crit_edge
  %i.151 = phi i32 [ %inc9, %for.body5.for.body5_crit_edge ], [ 0, %for.cond2.preheader.for.body5_crit_edge ]
  %arrayidx7 = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.151
  tail call void @amdgpu_ring_fini(ptr noundef %arrayidx7) #12
  %inc9 = add nuw i32 %i.151, 1
  %6 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %num_compute_rings, align 8
  %cmp4 = icmp ult i32 %inc9, %7
  br i1 %cmp4, label %for.body5.for.body5_crit_edge, label %for.body5.for.end10_crit_edge

for.body5.for.end10_crit_edge:                    ; preds = %for.body5
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end10

for.body5.for.body5_crit_edge:                    ; preds = %for.body5
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body5

for.end10:                                        ; preds = %for.body5.for.end10_crit_edge, %for.cond2.preheader.for.end10_crit_edge
  tail call void @amdgpu_gfx_mqd_sw_fini(ptr noundef %handle) #12
  %ring = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3
  tail call void @amdgpu_gfx_kiq_free_ring(ptr noundef %ring) #12
  tail call void @amdgpu_gfx_kiq_fini(ptr noundef %handle) #12
  %mec.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 6
  tail call void @amdgpu_bo_free_kernel(ptr noundef %mec.i, ptr noundef null, ptr noundef null) #12
  tail call void @amdgpu_gfx_rlc_fini(ptr noundef %handle) #12
  %clear_state_obj = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 5
  %clear_state_gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 6
  %cs_ptr = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 7
  tail call void @amdgpu_bo_free_kernel(ptr noundef %clear_state_obj, ptr noundef %clear_state_gpu_addr, ptr noundef %cs_ptr) #12
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %8 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %asic_type, align 8
  %.off = add i32 %9, -13
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %.off)
  %switch = icmp ult i32 %.off, 2
  br i1 %switch, label %if.then, label %for.end10.if.end_crit_edge

for.end10.if.end_crit_edge:                       ; preds = %for.end10
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %for.end10
  call void @__sanitizer_cov_trace_pc() #14
  %cp_table_obj = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 10
  %cp_table_gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 11
  %cp_table_ptr = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 12
  tail call void @amdgpu_bo_free_kernel(ptr noundef %cp_table_obj, ptr noundef %cp_table_gpu_addr, ptr noundef %cp_table_ptr) #12
  br label %if.end

if.end:                                           ; preds = %if.then, %for.end10.if.end_crit_edge
  %pfp_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 11
  %10 = ptrtoint ptr %pfp_fw.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %pfp_fw.i, align 4
  tail call void @release_firmware(ptr noundef %11) #12
  %12 = ptrtoint ptr %pfp_fw.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store ptr null, ptr %pfp_fw.i, align 4
  %me_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 9
  %13 = ptrtoint ptr %me_fw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %me_fw.i, align 4
  tail call void @release_firmware(ptr noundef %14) #12
  %15 = ptrtoint ptr %me_fw.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store ptr null, ptr %me_fw.i, align 4
  %ce_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 13
  %16 = ptrtoint ptr %ce_fw.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %ce_fw.i, align 4
  tail call void @release_firmware(ptr noundef %17) #12
  %18 = ptrtoint ptr %ce_fw.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr null, ptr %ce_fw.i, align 4
  %rlc_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 15
  %19 = ptrtoint ptr %rlc_fw.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %rlc_fw.i, align 4
  tail call void @release_firmware(ptr noundef %20) #12
  %21 = ptrtoint ptr %rlc_fw.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store ptr null, ptr %rlc_fw.i, align 4
  %mec_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 17
  %22 = ptrtoint ptr %mec_fw.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %mec_fw.i, align 4
  tail call void @release_firmware(ptr noundef %23) #12
  %24 = ptrtoint ptr %mec_fw.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store ptr null, ptr %mec_fw.i, align 4
  %25 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %asic_type, align 8
  %27 = zext i32 %26 to i64
  call void @__sanitizer_cov_trace_switch(i64 %27, ptr @__sancov_gen_cov_switch_values)
  switch i32 %26, label %if.then.i [
    i32 14, label %if.end.gfx_v8_0_free_microcode.exit_crit_edge
    i32 10, label %if.end.gfx_v8_0_free_microcode.exit_crit_edge52
  ]

if.end.gfx_v8_0_free_microcode.exit_crit_edge52:  ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_free_microcode.exit

if.end.gfx_v8_0_free_microcode.exit_crit_edge:    ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_free_microcode.exit

if.then.i:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %mec2_fw.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 19
  %28 = ptrtoint ptr %mec2_fw.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %mec2_fw.i, align 4
  tail call void @release_firmware(ptr noundef %29) #12
  br label %gfx_v8_0_free_microcode.exit

gfx_v8_0_free_microcode.exit:                     ; preds = %if.then.i, %if.end.gfx_v8_0_free_microcode.exit_crit_edge, %if.end.gfx_v8_0_free_microcode.exit_crit_edge52
  %mec2_fw19.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 19
  %30 = ptrtoint ptr %mec2_fw19.i to i32
  call void @__asan_store4_noabort(i32 %30)
  store ptr null, ptr %mec2_fw19.i, align 4
  %register_list_format.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 31
  %31 = ptrtoint ptr %register_list_format.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %register_list_format.i, align 4
  tail call void @kfree(ptr noundef %32) #12
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_hw_init(ptr noundef %handle) #0 align 64 {
entry:
  %disable_masks.i.i = alloca [8 x i32], align 4
  %se_mask.i.i.i = alloca [4 x i32], align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %0 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %asic_type.i, align 8
  %2 = zext i32 %1 to i64
  call void @__sanitizer_cov_trace_switch(i64 %2, ptr @__sancov_gen_cov_switch_values.101)
  switch i32 %1, label %entry.gfx_v8_0_init_golden_registers.exit_crit_edge [
    i32 10, label %sw.bb.i
    i32 12, label %sw.bb1.i
    i32 11, label %sw.bb2.i
    i32 18, label %sw.bb3.i
    i32 16, label %entry.sw.bb4.i_crit_edge
    i32 17, label %entry.sw.bb4.i_crit_edge54
    i32 15, label %sw.bb5.i
    i32 13, label %sw.bb44.i
    i32 14, label %sw.bb45.i
  ]

entry.sw.bb4.i_crit_edge54:                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb4.i

entry.sw.bb4.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb4.i

entry.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb.i:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @iceland_mgcg_cgcg_init, i32 noundef 192) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_iceland_a11, i32 noundef 48) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @iceland_golden_common_all, i32 noundef 24) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb1.i:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @fiji_mgcg_cgcg_init, i32 noundef 105) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_fiji_a10, i32 noundef 33) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @fiji_golden_common_all, i32 noundef 30) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb2.i:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @tonga_mgcg_cgcg_init, i32 noundef 225) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_tonga_a11, i32 noundef 48) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @tonga_golden_common_all, i32 noundef 24) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb3.i:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_vegam_a11, i32 noundef 51) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @vegam_golden_common_all, i32 noundef 18) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb4.i:                                         ; preds = %entry.sw.bb4.i_crit_edge, %entry.sw.bb4.i_crit_edge54
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_polaris11_a11, i32 noundef 51) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @polaris11_golden_common_all, i32 noundef 18) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb5.i:                                         ; preds = %entry
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @golden_settings_polaris10_a11, i32 noundef 51) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @polaris10_golden_common_all, i32 noundef 24) #12
  %smc_rreg.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 36
  %3 = ptrtoint ptr %smc_rreg.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %smc_rreg.i, align 4
  %call.i = tail call i32 %4(ptr noundef %handle, i32 noundef -1068498724) #12
  %and.i = and i32 %call.i, -128
  %or.i = or i32 %and.i, 24
  %smc_wreg.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 37
  %5 = ptrtoint ptr %smc_wreg.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %smc_wreg.i, align 8
  tail call void %6(ptr noundef %handle, i32 noundef -1068498724, i32 noundef %or.i) #12
  %pdev.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 1
  %7 = ptrtoint ptr %pdev.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %pdev.i, align 4
  %device.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 8
  %9 = ptrtoint ptr %device.i to i32
  call void @__asan_load2_noabort(i32 %9)
  %10 = load i16, ptr %device.i, align 2
  call void @__sanitizer_cov_trace_const_cmp2(i16 26591, i16 %10)
  %cmp.i = icmp eq i16 %10, 26591
  br i1 %cmp.i, label %land.lhs.true.i, label %sw.bb5.i.gfx_v8_0_init_golden_registers.exit_crit_edge

sw.bb5.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %sw.bb5.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true.i:                                  ; preds = %sw.bb5.i
  %revision.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 12
  %11 = ptrtoint ptr %revision.i to i32
  call void @__asan_load1_noabort(i32 %11)
  %12 = load i8, ptr %revision.i, align 4
  call void @__sanitizer_cov_trace_const_cmp1(i8 -57, i8 %12)
  %cmp9.i = icmp eq i8 %12, -57
  br i1 %cmp9.i, label %land.lhs.true11.i, label %land.lhs.true.i.gfx_v8_0_init_golden_registers.exit_crit_edge

land.lhs.true.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true11.i:                                ; preds = %land.lhs.true.i
  %subsystem_device.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 10
  %13 = ptrtoint ptr %subsystem_device.i to i32
  call void @__asan_load2_noabort(i32 %13)
  %14 = load i16, ptr %subsystem_device.i, align 2
  %15 = zext i16 %14 to i64
  call void @__sanitizer_cov_trace_switch(i64 %15, ptr @__sancov_gen_cov_switch_values.102)
  switch i16 %14, label %land.lhs.true11.i.gfx_v8_0_init_golden_registers.exit_crit_edge [
    i16 2871, label %land.lhs.true16.i
    i16 1192, label %land.lhs.true26.i
    i16 -27520, label %land.lhs.true38.i
  ]

land.lhs.true11.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %land.lhs.true11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true16.i:                                ; preds = %land.lhs.true11.i
  %subsystem_vendor.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 9
  %16 = ptrtoint ptr %subsystem_vendor.i to i32
  call void @__asan_load2_noabort(i32 %16)
  %17 = load i16, ptr %subsystem_vendor.i, align 4
  call void @__sanitizer_cov_trace_const_cmp2(i16 4098, i16 %17)
  %cmp19.i = icmp eq i16 %17, 4098
  br i1 %cmp19.i, label %land.lhs.true16.i.if.then.i_crit_edge, label %land.lhs.true16.i.gfx_v8_0_init_golden_registers.exit_crit_edge

land.lhs.true16.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %land.lhs.true16.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true16.i.if.then.i_crit_edge:            ; preds = %land.lhs.true16.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i

land.lhs.true26.i:                                ; preds = %land.lhs.true11.i
  %subsystem_vendor28.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 9
  %18 = ptrtoint ptr %subsystem_vendor28.i to i32
  call void @__asan_load2_noabort(i32 %18)
  %19 = load i16, ptr %subsystem_vendor28.i, align 4
  call void @__sanitizer_cov_trace_const_cmp2(i16 4163, i16 %19)
  %cmp30.i = icmp eq i16 %19, 4163
  br i1 %cmp30.i, label %land.lhs.true26.i.if.then.i_crit_edge, label %land.lhs.true26.i.gfx_v8_0_init_golden_registers.exit_crit_edge

land.lhs.true26.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %land.lhs.true26.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true26.i.if.then.i_crit_edge:            ; preds = %land.lhs.true26.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i

land.lhs.true38.i:                                ; preds = %land.lhs.true11.i
  %subsystem_vendor40.i = getelementptr inbounds %struct.pci_dev, ptr %8, i32 0, i32 9
  %20 = ptrtoint ptr %subsystem_vendor40.i to i32
  call void @__asan_load2_noabort(i32 %20)
  %21 = load i16, ptr %subsystem_vendor40.i, align 4
  call void @__sanitizer_cov_trace_const_cmp2(i16 5760, i16 %21)
  %cmp42.i = icmp eq i16 %21, 5760
  br i1 %cmp42.i, label %land.lhs.true38.i.if.then.i_crit_edge, label %land.lhs.true38.i.gfx_v8_0_init_golden_registers.exit_crit_edge

land.lhs.true38.i.gfx_v8_0_init_golden_registers.exit_crit_edge: ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_golden_registers.exit

land.lhs.true38.i.if.then.i_crit_edge:            ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true38.i.if.then.i_crit_edge, %land.lhs.true26.i.if.then.i_crit_edge, %land.lhs.true16.i.if.then.i_crit_edge
  tail call void @amdgpu_atombios_i2c_channel_trans(ptr noundef %handle, i8 noundef zeroext 16, i8 noundef zeroext -106, i8 noundef zeroext 30, i8 noundef zeroext -35) #12
  tail call void @amdgpu_atombios_i2c_channel_trans(ptr noundef %handle, i8 noundef zeroext 16, i8 noundef zeroext -106, i8 noundef zeroext 31, i8 noundef zeroext -48) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb44.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @cz_mgcg_cgcg_init, i32 noundef 225) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @cz_golden_settings_a11, i32 noundef 36) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @cz_golden_common_all, i32 noundef 24) #12
  br label %gfx_v8_0_init_golden_registers.exit

sw.bb45.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @stoney_mgcg_cgcg_init, i32 noundef 15) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @stoney_golden_settings_a11, i32 noundef 30) #12
  tail call void @amdgpu_device_program_register_sequence(ptr noundef %handle, ptr noundef nonnull @stoney_golden_common_all, i32 noundef 24) #12
  br label %gfx_v8_0_init_golden_registers.exit

gfx_v8_0_init_golden_registers.exit:              ; preds = %sw.bb45.i, %sw.bb44.i, %if.then.i, %land.lhs.true38.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %land.lhs.true26.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %land.lhs.true16.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %land.lhs.true11.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %land.lhs.true.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %sw.bb5.i.gfx_v8_0_init_golden_registers.exit_crit_edge, %sw.bb4.i, %sw.bb3.i, %sw.bb2.i, %sw.bb1.i, %sw.bb.i, %entry.gfx_v8_0_init_golden_registers.exit_crit_edge
  %call.i9 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8192, i32 noundef 0) #12
  %or.i10 = or i32 %call.i9, 255
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8192, i32 noundef %or.i10, i32 noundef 0) #12
  %gb_addr_config.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 23
  %22 = ptrtoint ptr %gb_addr_config.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %gb_addr_config.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 9790, i32 noundef %23, i32 noundef 0) #12
  %24 = ptrtoint ptr %gb_addr_config.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %gb_addr_config.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 3026, i32 noundef %25, i32 noundef 0) #12
  %26 = ptrtoint ptr %gb_addr_config.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %gb_addr_config.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 771, i32 noundef %27, i32 noundef 0) #12
  %tile_mode_array.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27
  %macrotile_mode_array.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28
  %28 = call ptr @memset(ptr %tile_mode_array.i.i, i32 0, i32 192)
  %29 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %asic_type.i, align 8
  %31 = zext i32 %30 to i64
  call void @__sanitizer_cov_trace_switch(i64 %31, ptr @__sancov_gen_cov_switch_values.103)
  switch i32 %30, label %do.end.i.i [
    i32 10, label %sw.bb.i.i
    i32 12, label %gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge
    i32 18, label %gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge55
    i32 11, label %sw.bb140.i.i
    i32 16, label %gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge
    i32 17, label %gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge56
    i32 15, label %sw.bb270.i.i
    i32 14, label %sw.bb335.i.i
    i32 13, label %gfx_v8_0_init_golden_registers.exit.sw.bb405.i.i_crit_edge
  ]

gfx_v8_0_init_golden_registers.exit.sw.bb405.i.i_crit_edge: ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb405.i.i

gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge56: ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb205.i.i

gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge: ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb205.i.i

gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge55: ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb75.i.i

gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge: ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb75.i.i

sw.bb.i.i:                                        ; preds = %gfx_v8_0_init_golden_registers.exit
  %32 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 8388624, ptr %tile_mode_array.i.i, align 4
  %arrayidx12.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %33 = ptrtoint ptr %arrayidx12.i.i to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 8390672, ptr %arrayidx12.i.i, align 4
  %arrayidx13.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %34 = ptrtoint ptr %arrayidx13.i.i to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 8392720, ptr %arrayidx13.i.i, align 4
  %arrayidx14.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %35 = ptrtoint ptr %arrayidx14.i.i to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 8394768, ptr %arrayidx14.i.i, align 4
  %arrayidx15.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %36 = ptrtoint ptr %arrayidx15.i.i to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 8398864, ptr %arrayidx15.i.i, align 4
  %arrayidx16.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %37 = ptrtoint ptr %arrayidx16.i.i to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 8398856, ptr %arrayidx16.i.i, align 4
  %arrayidx17.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %38 = ptrtoint ptr %arrayidx17.i.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 8398868, ptr %arrayidx17.i.i, align 4
  %arrayidx18.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %39 = ptrtoint ptr %arrayidx18.i.i to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 4, ptr %arrayidx18.i.i, align 4
  %arrayidx19.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %40 = ptrtoint ptr %arrayidx19.i.i to i32
  call void @__asan_store4_noabort(i32 %40)
  store i32 33554440, ptr %arrayidx19.i.i, align 4
  %arrayidx20.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %41 = ptrtoint ptr %arrayidx20.i.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 33554448, ptr %arrayidx20.i.i, align 4
  %arrayidx21.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %42 = ptrtoint ptr %arrayidx21.i.i to i32
  call void @__asan_store4_noabort(i32 %42)
  store i32 100663316, ptr %arrayidx21.i.i, align 4
  %arrayidx22.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %43 = ptrtoint ptr %arrayidx22.i.i to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 37748744, ptr %arrayidx22.i.i, align 4
  %arrayidx23.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %44 = ptrtoint ptr %arrayidx23.i.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 37748752, ptr %arrayidx23.i.i, align 4
  %arrayidx24.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %45 = ptrtoint ptr %arrayidx24.i.i to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 37748784, ptr %arrayidx24.i.i, align 4
  %arrayidx25.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %46 = ptrtoint ptr %arrayidx25.i.i to i32
  call void @__asan_store4_noabort(i32 %46)
  store i32 104857620, ptr %arrayidx25.i.i, align 4
  %arrayidx26.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %47 = ptrtoint ptr %arrayidx26.i.i to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 4194316, ptr %arrayidx26.i.i, align 4
  %arrayidx27.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %48 = ptrtoint ptr %arrayidx27.i.i to i32
  call void @__asan_store4_noabort(i32 %48)
  store i32 16777228, ptr %arrayidx27.i.i, align 4
  %arrayidx28.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %49 = ptrtoint ptr %arrayidx28.i.i to i32
  call void @__asan_store4_noabort(i32 %49)
  store i32 16777244, ptr %arrayidx28.i.i, align 4
  %arrayidx29.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %50 = ptrtoint ptr %arrayidx29.i.i to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 16777268, ptr %arrayidx29.i.i, align 4
  %arrayidx30.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %51 = ptrtoint ptr %arrayidx30.i.i to i32
  call void @__asan_store4_noabort(i32 %51)
  store i32 16777252, ptr %arrayidx30.i.i, align 4
  %arrayidx31.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %52 = ptrtoint ptr %arrayidx31.i.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 4194332, ptr %arrayidx31.i.i, align 4
  %arrayidx32.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %53 = ptrtoint ptr %arrayidx32.i.i to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 16777248, ptr %arrayidx32.i.i, align 4
  %arrayidx33.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %54 = ptrtoint ptr %arrayidx33.i.i to i32
  call void @__asan_store4_noabort(i32 %54)
  store i32 16777272, ptr %arrayidx33.i.i, align 4
  %arrayidx34.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %55 = ptrtoint ptr %arrayidx34.i.i to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 46137352, ptr %arrayidx34.i.i, align 4
  %arrayidx35.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %56 = ptrtoint ptr %arrayidx35.i.i to i32
  call void @__asan_store4_noabort(i32 %56)
  store i32 46137360, ptr %arrayidx35.i.i, align 4
  %arrayidx36.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %57 = ptrtoint ptr %arrayidx36.i.i to i32
  call void @__asan_store4_noabort(i32 %57)
  store i32 113246228, ptr %arrayidx36.i.i, align 4
  %58 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %58)
  store i32 154, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx38.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %59 = ptrtoint ptr %arrayidx38.i.i to i32
  call void @__asan_store4_noabort(i32 %59)
  store i32 154, ptr %arrayidx38.i.i, align 4
  %arrayidx39.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %60 = ptrtoint ptr %arrayidx39.i.i to i32
  call void @__asan_store4_noabort(i32 %60)
  store i32 153, ptr %arrayidx39.i.i, align 4
  %arrayidx40.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %61 = ptrtoint ptr %arrayidx40.i.i to i32
  call void @__asan_store4_noabort(i32 %61)
  store i32 168, ptr %arrayidx40.i.i, align 4
  %arrayidx41.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %62 = ptrtoint ptr %arrayidx41.i.i to i32
  call void @__asan_store4_noabort(i32 %62)
  store i32 148, ptr %arrayidx41.i.i, align 4
  %arrayidx42.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %63 = ptrtoint ptr %arrayidx42.i.i to i32
  call void @__asan_store4_noabort(i32 %63)
  store i32 144, ptr %arrayidx42.i.i, align 4
  %arrayidx43.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %64 = ptrtoint ptr %arrayidx43.i.i to i32
  call void @__asan_store4_noabort(i32 %64)
  store i32 144, ptr %arrayidx43.i.i, align 4
  %arrayidx44.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %65 = ptrtoint ptr %arrayidx44.i.i to i32
  call void @__asan_store4_noabort(i32 %65)
  store i32 238, ptr %arrayidx44.i.i, align 4
  %arrayidx45.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %66 = ptrtoint ptr %arrayidx45.i.i to i32
  call void @__asan_store4_noabort(i32 %66)
  store i32 234, ptr %arrayidx45.i.i, align 4
  %arrayidx46.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %67 = ptrtoint ptr %arrayidx46.i.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store i32 233, ptr %arrayidx46.i.i, align 4
  %arrayidx47.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %68 = ptrtoint ptr %arrayidx47.i.i to i32
  call void @__asan_store4_noabort(i32 %68)
  store i32 229, ptr %arrayidx47.i.i, align 4
  %arrayidx48.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %69 = ptrtoint ptr %arrayidx48.i.i to i32
  call void @__asan_store4_noabort(i32 %69)
  store i32 228, ptr %arrayidx48.i.i, align 4
  %arrayidx49.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %70 = ptrtoint ptr %arrayidx49.i.i to i32
  call void @__asan_store4_noabort(i32 %70)
  store i32 224, ptr %arrayidx49.i.i, align 4
  %arrayidx50.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %71 = ptrtoint ptr %arrayidx50.i.i to i32
  call void @__asan_store4_noabort(i32 %71)
  store i32 144, ptr %arrayidx50.i.i, align 4
  br label %for.body53.i.i

for.body53.i.i:                                   ; preds = %for.inc61.i.i.for.body53.i.i_crit_edge, %sw.bb.i.i
  %reg_offset.2910.i.i = phi i32 [ 0, %sw.bb.i.i ], [ %inc62.i.i, %for.inc61.i.i.for.body53.i.i_crit_edge ]
  %72 = zext i32 %reg_offset.2910.i.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %72, ptr @__sancov_gen_cov_switch_values.104)
  switch i32 %reg_offset.2910.i.i, label %if.then.i.i [
    i32 7, label %for.body53.i.i.for.inc61.i.i_crit_edge
    i32 12, label %for.body53.i.i.for.inc61.i.i_crit_edge57
    i32 17, label %for.body53.i.i.for.inc61.i.i_crit_edge58
    i32 23, label %for.body53.i.i.for.inc61.i.i_crit_edge59
  ]

for.body53.i.i.for.inc61.i.i_crit_edge59:         ; preds = %for.body53.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc61.i.i

for.body53.i.i.for.inc61.i.i_crit_edge58:         ; preds = %for.body53.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc61.i.i

for.body53.i.i.for.inc61.i.i_crit_edge57:         ; preds = %for.body53.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc61.i.i

for.body53.i.i.for.inc61.i.i_crit_edge:           ; preds = %for.body53.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc61.i.i

if.then.i.i:                                      ; preds = %for.body53.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add.i.i = add nuw nsw i32 %reg_offset.2910.i.i, 9796
  %arrayidx60.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.2910.i.i
  %73 = ptrtoint ptr %arrayidx60.i.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load i32, ptr %arrayidx60.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add.i.i, i32 noundef %74, i32 noundef 0) #12
  br label %for.inc61.i.i

for.inc61.i.i:                                    ; preds = %if.then.i.i, %for.body53.i.i.for.inc61.i.i_crit_edge, %for.body53.i.i.for.inc61.i.i_crit_edge57, %for.body53.i.i.for.inc61.i.i_crit_edge58, %for.body53.i.i.for.inc61.i.i_crit_edge59
  %inc62.i.i = add nuw nsw i32 %reg_offset.2910.i.i, 1
  %exitcond933.not.i.i = icmp eq i32 %inc62.i.i, 32
  br i1 %exitcond933.not.i.i, label %for.inc61.i.i.for.body66.i.i_crit_edge, label %for.inc61.i.i.for.body53.i.i_crit_edge

for.inc61.i.i.for.body53.i.i_crit_edge:           ; preds = %for.inc61.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body53.i.i

for.inc61.i.i.for.body66.i.i_crit_edge:           ; preds = %for.inc61.i.i
  br label %for.body66.i.i

for.body66.i.i:                                   ; preds = %for.inc72.i.i.for.body66.i.i_crit_edge, %for.inc61.i.i.for.body66.i.i_crit_edge
  %reg_offset.3912.i.i = phi i32 [ %inc73.i.i, %for.inc72.i.i.for.body66.i.i_crit_edge ], [ 0, %for.inc61.i.i.for.body66.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.3912.i.i)
  %cmp67.not.i.i = icmp eq i32 %reg_offset.3912.i.i, 7
  br i1 %cmp67.not.i.i, label %for.body66.i.i.for.inc72.i.i_crit_edge, label %if.then68.i.i

for.body66.i.i.for.inc72.i.i_crit_edge:           ; preds = %for.body66.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc72.i.i

if.then68.i.i:                                    ; preds = %for.body66.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add69.i.i = add nuw nsw i32 %reg_offset.3912.i.i, 9828
  %arrayidx70.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.3912.i.i
  %75 = ptrtoint ptr %arrayidx70.i.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %arrayidx70.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add69.i.i, i32 noundef %76, i32 noundef 0) #12
  br label %for.inc72.i.i

for.inc72.i.i:                                    ; preds = %if.then68.i.i, %for.body66.i.i.for.inc72.i.i_crit_edge
  %inc73.i.i = add nuw nsw i32 %reg_offset.3912.i.i, 1
  %exitcond934.not.i.i = icmp eq i32 %inc73.i.i, 16
  br i1 %exitcond934.not.i.i, label %for.inc72.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc72.i.i.for.body66.i.i_crit_edge

for.inc72.i.i.for.body66.i.i_crit_edge:           ; preds = %for.inc72.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body66.i.i

for.inc72.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc72.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

sw.bb75.i.i:                                      ; preds = %gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge, %gfx_v8_0_init_golden_registers.exit.sw.bb75.i.i_crit_edge55
  %77 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %77)
  store i32 8389712, ptr %tile_mode_array.i.i, align 4
  %arrayidx77.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %78 = ptrtoint ptr %arrayidx77.i.i to i32
  call void @__asan_store4_noabort(i32 %78)
  store i32 8391760, ptr %arrayidx77.i.i, align 4
  %arrayidx78.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %79 = ptrtoint ptr %arrayidx78.i.i to i32
  call void @__asan_store4_noabort(i32 %79)
  store i32 8393808, ptr %arrayidx78.i.i, align 4
  %arrayidx79.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %80 = ptrtoint ptr %arrayidx79.i.i to i32
  call void @__asan_store4_noabort(i32 %80)
  store i32 8395856, ptr %arrayidx79.i.i, align 4
  %arrayidx80.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %81 = ptrtoint ptr %arrayidx80.i.i to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 8399952, ptr %arrayidx80.i.i, align 4
  %arrayidx81.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %82 = ptrtoint ptr %arrayidx81.i.i to i32
  call void @__asan_store4_noabort(i32 %82)
  store i32 8399944, ptr %arrayidx81.i.i, align 4
  %arrayidx82.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %83 = ptrtoint ptr %arrayidx82.i.i to i32
  call void @__asan_store4_noabort(i32 %83)
  store i32 8399956, ptr %arrayidx82.i.i, align 4
  %arrayidx83.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 7
  %84 = ptrtoint ptr %arrayidx83.i.i to i32
  call void @__asan_store4_noabort(i32 %84)
  store i32 8399188, ptr %arrayidx83.i.i, align 4
  %arrayidx84.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %85 = ptrtoint ptr %arrayidx84.i.i to i32
  call void @__asan_store4_noabort(i32 %85)
  store i32 1092, ptr %arrayidx84.i.i, align 4
  %arrayidx85.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %86 = ptrtoint ptr %arrayidx85.i.i to i32
  call void @__asan_store4_noabort(i32 %86)
  store i32 33555528, ptr %arrayidx85.i.i, align 4
  %arrayidx86.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %87 = ptrtoint ptr %arrayidx86.i.i to i32
  call void @__asan_store4_noabort(i32 %87)
  store i32 33555536, ptr %arrayidx86.i.i, align 4
  %arrayidx87.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %88 = ptrtoint ptr %arrayidx87.i.i to i32
  call void @__asan_store4_noabort(i32 %88)
  store i32 100664404, ptr %arrayidx87.i.i, align 4
  %arrayidx88.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 12
  %89 = ptrtoint ptr %arrayidx88.i.i to i32
  call void @__asan_store4_noabort(i32 %89)
  store i32 100663636, ptr %arrayidx88.i.i, align 4
  %arrayidx89.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %90 = ptrtoint ptr %arrayidx89.i.i to i32
  call void @__asan_store4_noabort(i32 %90)
  store i32 37749832, ptr %arrayidx89.i.i, align 4
  %arrayidx90.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %91 = ptrtoint ptr %arrayidx90.i.i to i32
  call void @__asan_store4_noabort(i32 %91)
  store i32 37749840, ptr %arrayidx90.i.i, align 4
  %arrayidx91.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %92 = ptrtoint ptr %arrayidx91.i.i to i32
  call void @__asan_store4_noabort(i32 %92)
  store i32 37749872, ptr %arrayidx91.i.i, align 4
  %arrayidx92.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %93 = ptrtoint ptr %arrayidx92.i.i to i32
  call void @__asan_store4_noabort(i32 %93)
  store i32 104858708, ptr %arrayidx92.i.i, align 4
  %arrayidx93.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 17
  %94 = ptrtoint ptr %arrayidx93.i.i to i32
  call void @__asan_store4_noabort(i32 %94)
  store i32 104857940, ptr %arrayidx93.i.i, align 4
  %arrayidx94.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %95 = ptrtoint ptr %arrayidx94.i.i to i32
  call void @__asan_store4_noabort(i32 %95)
  store i32 4195404, ptr %arrayidx94.i.i, align 4
  %arrayidx95.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %96 = ptrtoint ptr %arrayidx95.i.i to i32
  call void @__asan_store4_noabort(i32 %96)
  store i32 16778316, ptr %arrayidx95.i.i, align 4
  %arrayidx96.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %97 = ptrtoint ptr %arrayidx96.i.i to i32
  call void @__asan_store4_noabort(i32 %97)
  store i32 16778332, ptr %arrayidx96.i.i, align 4
  %arrayidx97.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %98 = ptrtoint ptr %arrayidx97.i.i to i32
  call void @__asan_store4_noabort(i32 %98)
  store i32 16778356, ptr %arrayidx97.i.i, align 4
  %arrayidx98.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %99 = ptrtoint ptr %arrayidx98.i.i to i32
  call void @__asan_store4_noabort(i32 %99)
  store i32 16778340, ptr %arrayidx98.i.i, align 4
  %arrayidx99.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 23
  %100 = ptrtoint ptr %arrayidx99.i.i to i32
  call void @__asan_store4_noabort(i32 %100)
  store i32 16777572, ptr %arrayidx99.i.i, align 4
  %arrayidx100.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %101 = ptrtoint ptr %arrayidx100.i.i to i32
  call void @__asan_store4_noabort(i32 %101)
  store i32 4195420, ptr %arrayidx100.i.i, align 4
  %arrayidx101.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %102 = ptrtoint ptr %arrayidx101.i.i to i32
  call void @__asan_store4_noabort(i32 %102)
  store i32 16778336, ptr %arrayidx101.i.i, align 4
  %arrayidx102.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %103 = ptrtoint ptr %arrayidx102.i.i to i32
  call void @__asan_store4_noabort(i32 %103)
  store i32 16778360, ptr %arrayidx102.i.i, align 4
  %arrayidx103.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %104 = ptrtoint ptr %arrayidx103.i.i to i32
  call void @__asan_store4_noabort(i32 %104)
  store i32 46138440, ptr %arrayidx103.i.i, align 4
  %arrayidx104.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %105 = ptrtoint ptr %arrayidx104.i.i to i32
  call void @__asan_store4_noabort(i32 %105)
  store i32 46138448, ptr %arrayidx104.i.i, align 4
  %arrayidx105.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %106 = ptrtoint ptr %arrayidx105.i.i to i32
  call void @__asan_store4_noabort(i32 %106)
  store i32 113247316, ptr %arrayidx105.i.i, align 4
  %arrayidx106.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 30
  %107 = ptrtoint ptr %arrayidx106.i.i to i32
  call void @__asan_store4_noabort(i32 %107)
  store i32 113246548, ptr %arrayidx106.i.i, align 4
  %108 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %108)
  store i32 152, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx108.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %109 = ptrtoint ptr %arrayidx108.i.i to i32
  call void @__asan_store4_noabort(i32 %109)
  store i32 152, ptr %arrayidx108.i.i, align 4
  %arrayidx109.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %110 = ptrtoint ptr %arrayidx109.i.i to i32
  call void @__asan_store4_noabort(i32 %110)
  store i32 152, ptr %arrayidx109.i.i, align 4
  %arrayidx110.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %111 = ptrtoint ptr %arrayidx110.i.i to i32
  call void @__asan_store4_noabort(i32 %111)
  store i32 152, ptr %arrayidx110.i.i, align 4
  %arrayidx111.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %112 = ptrtoint ptr %arrayidx111.i.i to i32
  call void @__asan_store4_noabort(i32 %112)
  store i32 132, ptr %arrayidx111.i.i, align 4
  %arrayidx112.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %113 = ptrtoint ptr %arrayidx112.i.i to i32
  call void @__asan_store4_noabort(i32 %113)
  store i32 128, ptr %arrayidx112.i.i, align 4
  %arrayidx113.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %114 = ptrtoint ptr %arrayidx113.i.i to i32
  call void @__asan_store4_noabort(i32 %114)
  store i32 128, ptr %arrayidx113.i.i, align 4
  %arrayidx114.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %115 = ptrtoint ptr %arrayidx114.i.i to i32
  call void @__asan_store4_noabort(i32 %115)
  store i32 156, ptr %arrayidx114.i.i, align 4
  %arrayidx115.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %116 = ptrtoint ptr %arrayidx115.i.i to i32
  call void @__asan_store4_noabort(i32 %116)
  store i32 152, ptr %arrayidx115.i.i, align 4
  %arrayidx116.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %117 = ptrtoint ptr %arrayidx116.i.i to i32
  call void @__asan_store4_noabort(i32 %117)
  store i32 132, ptr %arrayidx116.i.i, align 4
  %arrayidx117.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %118 = ptrtoint ptr %arrayidx117.i.i to i32
  call void @__asan_store4_noabort(i32 %118)
  store i32 128, ptr %arrayidx117.i.i, align 4
  %arrayidx118.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %119 = ptrtoint ptr %arrayidx118.i.i to i32
  call void @__asan_store4_noabort(i32 %119)
  store i32 148, ptr %arrayidx118.i.i, align 4
  %arrayidx119.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %120 = ptrtoint ptr %arrayidx119.i.i to i32
  call void @__asan_store4_noabort(i32 %120)
  store i32 144, ptr %arrayidx119.i.i, align 4
  %arrayidx120.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %121 = ptrtoint ptr %arrayidx120.i.i to i32
  call void @__asan_store4_noabort(i32 %121)
  store i32 64, ptr %arrayidx120.i.i, align 4
  br label %for.body123.i.i

for.body123.i.i:                                  ; preds = %for.body123.i.i.for.body123.i.i_crit_edge, %sw.bb75.i.i
  %reg_offset.4907.i.i = phi i32 [ 0, %sw.bb75.i.i ], [ %inc127.i.i, %for.body123.i.i.for.body123.i.i_crit_edge ]
  %add124.i.i = add nuw nsw i32 %reg_offset.4907.i.i, 9796
  %arrayidx125.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.4907.i.i
  %122 = ptrtoint ptr %arrayidx125.i.i to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load i32, ptr %arrayidx125.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add124.i.i, i32 noundef %123, i32 noundef 0) #12
  %inc127.i.i = add nuw nsw i32 %reg_offset.4907.i.i, 1
  %exitcond931.not.i.i = icmp eq i32 %inc127.i.i, 32
  br i1 %exitcond931.not.i.i, label %for.body123.i.i.for.body131.i.i_crit_edge, label %for.body123.i.i.for.body123.i.i_crit_edge

for.body123.i.i.for.body123.i.i_crit_edge:        ; preds = %for.body123.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body123.i.i

for.body123.i.i.for.body131.i.i_crit_edge:        ; preds = %for.body123.i.i
  br label %for.body131.i.i

for.body131.i.i:                                  ; preds = %for.inc137.i.i.for.body131.i.i_crit_edge, %for.body123.i.i.for.body131.i.i_crit_edge
  %reg_offset.5908.i.i = phi i32 [ %inc138.i.i, %for.inc137.i.i.for.body131.i.i_crit_edge ], [ 0, %for.body123.i.i.for.body131.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.5908.i.i)
  %cmp132.not.i.i = icmp eq i32 %reg_offset.5908.i.i, 7
  br i1 %cmp132.not.i.i, label %for.body131.i.i.for.inc137.i.i_crit_edge, label %if.then133.i.i

for.body131.i.i.for.inc137.i.i_crit_edge:         ; preds = %for.body131.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc137.i.i

if.then133.i.i:                                   ; preds = %for.body131.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add134.i.i = add nuw nsw i32 %reg_offset.5908.i.i, 9828
  %arrayidx135.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.5908.i.i
  %124 = ptrtoint ptr %arrayidx135.i.i to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %arrayidx135.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add134.i.i, i32 noundef %125, i32 noundef 0) #12
  br label %for.inc137.i.i

for.inc137.i.i:                                   ; preds = %if.then133.i.i, %for.body131.i.i.for.inc137.i.i_crit_edge
  %inc138.i.i = add nuw nsw i32 %reg_offset.5908.i.i, 1
  %exitcond932.not.i.i = icmp eq i32 %inc138.i.i, 16
  br i1 %exitcond932.not.i.i, label %for.inc137.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc137.i.i.for.body131.i.i_crit_edge

for.inc137.i.i.for.body131.i.i_crit_edge:         ; preds = %for.inc137.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body131.i.i

for.inc137.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc137.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

sw.bb140.i.i:                                     ; preds = %gfx_v8_0_init_golden_registers.exit
  %126 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %126)
  store i32 8389392, ptr %tile_mode_array.i.i, align 4
  %arrayidx142.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %127 = ptrtoint ptr %arrayidx142.i.i to i32
  call void @__asan_store4_noabort(i32 %127)
  store i32 8391440, ptr %arrayidx142.i.i, align 4
  %arrayidx143.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %128 = ptrtoint ptr %arrayidx143.i.i to i32
  call void @__asan_store4_noabort(i32 %128)
  store i32 8393488, ptr %arrayidx143.i.i, align 4
  %arrayidx144.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %129 = ptrtoint ptr %arrayidx144.i.i to i32
  call void @__asan_store4_noabort(i32 %129)
  store i32 8395536, ptr %arrayidx144.i.i, align 4
  %arrayidx145.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %130 = ptrtoint ptr %arrayidx145.i.i to i32
  call void @__asan_store4_noabort(i32 %130)
  store i32 8399632, ptr %arrayidx145.i.i, align 4
  %arrayidx146.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %131 = ptrtoint ptr %arrayidx146.i.i to i32
  call void @__asan_store4_noabort(i32 %131)
  store i32 8399624, ptr %arrayidx146.i.i, align 4
  %arrayidx147.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %132 = ptrtoint ptr %arrayidx147.i.i to i32
  call void @__asan_store4_noabort(i32 %132)
  store i32 8399636, ptr %arrayidx147.i.i, align 4
  %arrayidx148.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 7
  %133 = ptrtoint ptr %arrayidx148.i.i to i32
  call void @__asan_store4_noabort(i32 %133)
  store i32 8399188, ptr %arrayidx148.i.i, align 4
  %arrayidx149.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %134 = ptrtoint ptr %arrayidx149.i.i to i32
  call void @__asan_store4_noabort(i32 %134)
  store i32 772, ptr %arrayidx149.i.i, align 4
  %arrayidx150.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %135 = ptrtoint ptr %arrayidx150.i.i to i32
  call void @__asan_store4_noabort(i32 %135)
  store i32 33555208, ptr %arrayidx150.i.i, align 4
  %arrayidx151.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %136 = ptrtoint ptr %arrayidx151.i.i to i32
  call void @__asan_store4_noabort(i32 %136)
  store i32 33555216, ptr %arrayidx151.i.i, align 4
  %arrayidx152.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %137 = ptrtoint ptr %arrayidx152.i.i to i32
  call void @__asan_store4_noabort(i32 %137)
  store i32 100664084, ptr %arrayidx152.i.i, align 4
  %arrayidx153.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 12
  %138 = ptrtoint ptr %arrayidx153.i.i to i32
  call void @__asan_store4_noabort(i32 %138)
  store i32 100663636, ptr %arrayidx153.i.i, align 4
  %arrayidx154.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %139 = ptrtoint ptr %arrayidx154.i.i to i32
  call void @__asan_store4_noabort(i32 %139)
  store i32 37749512, ptr %arrayidx154.i.i, align 4
  %arrayidx155.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %140 = ptrtoint ptr %arrayidx155.i.i to i32
  call void @__asan_store4_noabort(i32 %140)
  store i32 37749520, ptr %arrayidx155.i.i, align 4
  %arrayidx156.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %141 = ptrtoint ptr %arrayidx156.i.i to i32
  call void @__asan_store4_noabort(i32 %141)
  store i32 37749552, ptr %arrayidx156.i.i, align 4
  %arrayidx157.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %142 = ptrtoint ptr %arrayidx157.i.i to i32
  call void @__asan_store4_noabort(i32 %142)
  store i32 104858388, ptr %arrayidx157.i.i, align 4
  %arrayidx158.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 17
  %143 = ptrtoint ptr %arrayidx158.i.i to i32
  call void @__asan_store4_noabort(i32 %143)
  store i32 104857940, ptr %arrayidx158.i.i, align 4
  %arrayidx159.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %144 = ptrtoint ptr %arrayidx159.i.i to i32
  call void @__asan_store4_noabort(i32 %144)
  store i32 4195084, ptr %arrayidx159.i.i, align 4
  %arrayidx160.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %145 = ptrtoint ptr %arrayidx160.i.i to i32
  call void @__asan_store4_noabort(i32 %145)
  store i32 16777996, ptr %arrayidx160.i.i, align 4
  %arrayidx161.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %146 = ptrtoint ptr %arrayidx161.i.i to i32
  call void @__asan_store4_noabort(i32 %146)
  store i32 16778012, ptr %arrayidx161.i.i, align 4
  %arrayidx162.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %147 = ptrtoint ptr %arrayidx162.i.i to i32
  call void @__asan_store4_noabort(i32 %147)
  store i32 16778036, ptr %arrayidx162.i.i, align 4
  %arrayidx163.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %148 = ptrtoint ptr %arrayidx163.i.i to i32
  call void @__asan_store4_noabort(i32 %148)
  store i32 16778020, ptr %arrayidx163.i.i, align 4
  %arrayidx164.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 23
  %149 = ptrtoint ptr %arrayidx164.i.i to i32
  call void @__asan_store4_noabort(i32 %149)
  store i32 16777572, ptr %arrayidx164.i.i, align 4
  %arrayidx165.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %150 = ptrtoint ptr %arrayidx165.i.i to i32
  call void @__asan_store4_noabort(i32 %150)
  store i32 4195100, ptr %arrayidx165.i.i, align 4
  %arrayidx166.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %151 = ptrtoint ptr %arrayidx166.i.i to i32
  call void @__asan_store4_noabort(i32 %151)
  store i32 16778016, ptr %arrayidx166.i.i, align 4
  %arrayidx167.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %152 = ptrtoint ptr %arrayidx167.i.i to i32
  call void @__asan_store4_noabort(i32 %152)
  store i32 16778040, ptr %arrayidx167.i.i, align 4
  %arrayidx168.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %153 = ptrtoint ptr %arrayidx168.i.i to i32
  call void @__asan_store4_noabort(i32 %153)
  store i32 46138120, ptr %arrayidx168.i.i, align 4
  %arrayidx169.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %154 = ptrtoint ptr %arrayidx169.i.i to i32
  call void @__asan_store4_noabort(i32 %154)
  store i32 46138128, ptr %arrayidx169.i.i, align 4
  %arrayidx170.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %155 = ptrtoint ptr %arrayidx170.i.i to i32
  call void @__asan_store4_noabort(i32 %155)
  store i32 113246996, ptr %arrayidx170.i.i, align 4
  %arrayidx171.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 30
  %156 = ptrtoint ptr %arrayidx171.i.i to i32
  call void @__asan_store4_noabort(i32 %156)
  store i32 113246548, ptr %arrayidx171.i.i, align 4
  %157 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %157)
  store i32 232, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx173.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %158 = ptrtoint ptr %arrayidx173.i.i to i32
  call void @__asan_store4_noabort(i32 %158)
  store i32 232, ptr %arrayidx173.i.i, align 4
  %arrayidx174.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %159 = ptrtoint ptr %arrayidx174.i.i to i32
  call void @__asan_store4_noabort(i32 %159)
  store i32 232, ptr %arrayidx174.i.i, align 4
  %arrayidx175.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %160 = ptrtoint ptr %arrayidx175.i.i to i32
  call void @__asan_store4_noabort(i32 %160)
  store i32 232, ptr %arrayidx175.i.i, align 4
  %arrayidx176.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %161 = ptrtoint ptr %arrayidx176.i.i to i32
  call void @__asan_store4_noabort(i32 %161)
  store i32 212, ptr %arrayidx176.i.i, align 4
  %arrayidx177.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %162 = ptrtoint ptr %arrayidx177.i.i to i32
  call void @__asan_store4_noabort(i32 %162)
  store i32 192, ptr %arrayidx177.i.i, align 4
  %arrayidx178.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %163 = ptrtoint ptr %arrayidx178.i.i to i32
  call void @__asan_store4_noabort(i32 %163)
  store i32 192, ptr %arrayidx178.i.i, align 4
  %arrayidx179.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %164 = ptrtoint ptr %arrayidx179.i.i to i32
  call void @__asan_store4_noabort(i32 %164)
  store i32 236, ptr %arrayidx179.i.i, align 4
  %arrayidx180.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %165 = ptrtoint ptr %arrayidx180.i.i to i32
  call void @__asan_store4_noabort(i32 %165)
  store i32 232, ptr %arrayidx180.i.i, align 4
  %arrayidx181.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %166 = ptrtoint ptr %arrayidx181.i.i to i32
  call void @__asan_store4_noabort(i32 %166)
  store i32 212, ptr %arrayidx181.i.i, align 4
  %arrayidx182.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %167 = ptrtoint ptr %arrayidx182.i.i to i32
  call void @__asan_store4_noabort(i32 %167)
  store i32 208, ptr %arrayidx182.i.i, align 4
  %arrayidx183.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %168 = ptrtoint ptr %arrayidx183.i.i to i32
  call void @__asan_store4_noabort(i32 %168)
  store i32 128, ptr %arrayidx183.i.i, align 4
  %arrayidx184.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %169 = ptrtoint ptr %arrayidx184.i.i to i32
  call void @__asan_store4_noabort(i32 %169)
  store i32 64, ptr %arrayidx184.i.i, align 4
  %arrayidx185.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %170 = ptrtoint ptr %arrayidx185.i.i to i32
  call void @__asan_store4_noabort(i32 %170)
  store i32 64, ptr %arrayidx185.i.i, align 4
  br label %for.body188.i.i

for.body188.i.i:                                  ; preds = %for.body188.i.i.for.body188.i.i_crit_edge, %sw.bb140.i.i
  %reg_offset.6904.i.i = phi i32 [ 0, %sw.bb140.i.i ], [ %inc192.i.i, %for.body188.i.i.for.body188.i.i_crit_edge ]
  %add189.i.i = add nuw nsw i32 %reg_offset.6904.i.i, 9796
  %arrayidx190.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.6904.i.i
  %171 = ptrtoint ptr %arrayidx190.i.i to i32
  call void @__asan_load4_noabort(i32 %171)
  %172 = load i32, ptr %arrayidx190.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add189.i.i, i32 noundef %172, i32 noundef 0) #12
  %inc192.i.i = add nuw nsw i32 %reg_offset.6904.i.i, 1
  %exitcond929.not.i.i = icmp eq i32 %inc192.i.i, 32
  br i1 %exitcond929.not.i.i, label %for.body188.i.i.for.body196.i.i_crit_edge, label %for.body188.i.i.for.body188.i.i_crit_edge

for.body188.i.i.for.body188.i.i_crit_edge:        ; preds = %for.body188.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body188.i.i

for.body188.i.i.for.body196.i.i_crit_edge:        ; preds = %for.body188.i.i
  br label %for.body196.i.i

for.body196.i.i:                                  ; preds = %for.inc202.i.i.for.body196.i.i_crit_edge, %for.body188.i.i.for.body196.i.i_crit_edge
  %reg_offset.7905.i.i = phi i32 [ %inc203.i.i, %for.inc202.i.i.for.body196.i.i_crit_edge ], [ 0, %for.body188.i.i.for.body196.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.7905.i.i)
  %cmp197.not.i.i = icmp eq i32 %reg_offset.7905.i.i, 7
  br i1 %cmp197.not.i.i, label %for.body196.i.i.for.inc202.i.i_crit_edge, label %if.then198.i.i

for.body196.i.i.for.inc202.i.i_crit_edge:         ; preds = %for.body196.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc202.i.i

if.then198.i.i:                                   ; preds = %for.body196.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add199.i.i = add nuw nsw i32 %reg_offset.7905.i.i, 9828
  %arrayidx200.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.7905.i.i
  %173 = ptrtoint ptr %arrayidx200.i.i to i32
  call void @__asan_load4_noabort(i32 %173)
  %174 = load i32, ptr %arrayidx200.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add199.i.i, i32 noundef %174, i32 noundef 0) #12
  br label %for.inc202.i.i

for.inc202.i.i:                                   ; preds = %if.then198.i.i, %for.body196.i.i.for.inc202.i.i_crit_edge
  %inc203.i.i = add nuw nsw i32 %reg_offset.7905.i.i, 1
  %exitcond930.not.i.i = icmp eq i32 %inc203.i.i, 16
  br i1 %exitcond930.not.i.i, label %for.inc202.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc202.i.i.for.body196.i.i_crit_edge

for.inc202.i.i.for.body196.i.i_crit_edge:         ; preds = %for.inc202.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body196.i.i

for.inc202.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc202.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

sw.bb205.i.i:                                     ; preds = %gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge, %gfx_v8_0_init_golden_registers.exit.sw.bb205.i.i_crit_edge56
  %175 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %175)
  store i32 8388944, ptr %tile_mode_array.i.i, align 4
  %arrayidx207.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %176 = ptrtoint ptr %arrayidx207.i.i to i32
  call void @__asan_store4_noabort(i32 %176)
  store i32 8390992, ptr %arrayidx207.i.i, align 4
  %arrayidx208.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %177 = ptrtoint ptr %arrayidx208.i.i to i32
  call void @__asan_store4_noabort(i32 %177)
  store i32 8393040, ptr %arrayidx208.i.i, align 4
  %arrayidx209.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %178 = ptrtoint ptr %arrayidx209.i.i to i32
  call void @__asan_store4_noabort(i32 %178)
  store i32 8395088, ptr %arrayidx209.i.i, align 4
  %arrayidx210.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %179 = ptrtoint ptr %arrayidx210.i.i to i32
  call void @__asan_store4_noabort(i32 %179)
  store i32 8399184, ptr %arrayidx210.i.i, align 4
  %arrayidx211.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %180 = ptrtoint ptr %arrayidx211.i.i to i32
  call void @__asan_store4_noabort(i32 %180)
  store i32 8399176, ptr %arrayidx211.i.i, align 4
  %arrayidx212.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %181 = ptrtoint ptr %arrayidx212.i.i to i32
  call void @__asan_store4_noabort(i32 %181)
  store i32 8399188, ptr %arrayidx212.i.i, align 4
  %arrayidx213.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 7
  %182 = ptrtoint ptr %arrayidx213.i.i to i32
  call void @__asan_store4_noabort(i32 %182)
  store i32 8399188, ptr %arrayidx213.i.i, align 4
  %arrayidx214.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %183 = ptrtoint ptr %arrayidx214.i.i to i32
  call void @__asan_store4_noabort(i32 %183)
  store i32 324, ptr %arrayidx214.i.i, align 4
  %arrayidx215.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %184 = ptrtoint ptr %arrayidx215.i.i to i32
  call void @__asan_store4_noabort(i32 %184)
  store i32 33554760, ptr %arrayidx215.i.i, align 4
  %arrayidx216.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %185 = ptrtoint ptr %arrayidx216.i.i to i32
  call void @__asan_store4_noabort(i32 %185)
  store i32 33554768, ptr %arrayidx216.i.i, align 4
  %arrayidx217.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %186 = ptrtoint ptr %arrayidx217.i.i to i32
  call void @__asan_store4_noabort(i32 %186)
  store i32 100663636, ptr %arrayidx217.i.i, align 4
  %arrayidx218.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 12
  %187 = ptrtoint ptr %arrayidx218.i.i to i32
  call void @__asan_store4_noabort(i32 %187)
  store i32 100663636, ptr %arrayidx218.i.i, align 4
  %arrayidx219.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %188 = ptrtoint ptr %arrayidx219.i.i to i32
  call void @__asan_store4_noabort(i32 %188)
  store i32 37749064, ptr %arrayidx219.i.i, align 4
  %arrayidx220.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %189 = ptrtoint ptr %arrayidx220.i.i to i32
  call void @__asan_store4_noabort(i32 %189)
  store i32 37749072, ptr %arrayidx220.i.i, align 4
  %arrayidx221.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %190 = ptrtoint ptr %arrayidx221.i.i to i32
  call void @__asan_store4_noabort(i32 %190)
  store i32 37749104, ptr %arrayidx221.i.i, align 4
  %arrayidx222.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %191 = ptrtoint ptr %arrayidx222.i.i to i32
  call void @__asan_store4_noabort(i32 %191)
  store i32 104857940, ptr %arrayidx222.i.i, align 4
  %arrayidx223.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 17
  %192 = ptrtoint ptr %arrayidx223.i.i to i32
  call void @__asan_store4_noabort(i32 %192)
  store i32 104857940, ptr %arrayidx223.i.i, align 4
  %arrayidx224.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %193 = ptrtoint ptr %arrayidx224.i.i to i32
  call void @__asan_store4_noabort(i32 %193)
  store i32 4194636, ptr %arrayidx224.i.i, align 4
  %arrayidx225.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %194 = ptrtoint ptr %arrayidx225.i.i to i32
  call void @__asan_store4_noabort(i32 %194)
  store i32 16777548, ptr %arrayidx225.i.i, align 4
  %arrayidx226.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %195 = ptrtoint ptr %arrayidx226.i.i to i32
  call void @__asan_store4_noabort(i32 %195)
  store i32 16777564, ptr %arrayidx226.i.i, align 4
  %arrayidx227.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %196 = ptrtoint ptr %arrayidx227.i.i to i32
  call void @__asan_store4_noabort(i32 %196)
  store i32 16777588, ptr %arrayidx227.i.i, align 4
  %arrayidx228.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %197 = ptrtoint ptr %arrayidx228.i.i to i32
  call void @__asan_store4_noabort(i32 %197)
  store i32 16777572, ptr %arrayidx228.i.i, align 4
  %arrayidx229.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 23
  %198 = ptrtoint ptr %arrayidx229.i.i to i32
  call void @__asan_store4_noabort(i32 %198)
  store i32 16777572, ptr %arrayidx229.i.i, align 4
  %arrayidx230.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %199 = ptrtoint ptr %arrayidx230.i.i to i32
  call void @__asan_store4_noabort(i32 %199)
  store i32 4194652, ptr %arrayidx230.i.i, align 4
  %arrayidx231.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %200 = ptrtoint ptr %arrayidx231.i.i to i32
  call void @__asan_store4_noabort(i32 %200)
  store i32 16777568, ptr %arrayidx231.i.i, align 4
  %arrayidx232.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %201 = ptrtoint ptr %arrayidx232.i.i to i32
  call void @__asan_store4_noabort(i32 %201)
  store i32 16777592, ptr %arrayidx232.i.i, align 4
  %arrayidx233.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %202 = ptrtoint ptr %arrayidx233.i.i to i32
  call void @__asan_store4_noabort(i32 %202)
  store i32 46137672, ptr %arrayidx233.i.i, align 4
  %arrayidx234.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %203 = ptrtoint ptr %arrayidx234.i.i to i32
  call void @__asan_store4_noabort(i32 %203)
  store i32 46137680, ptr %arrayidx234.i.i, align 4
  %arrayidx235.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %204 = ptrtoint ptr %arrayidx235.i.i to i32
  call void @__asan_store4_noabort(i32 %204)
  store i32 113246548, ptr %arrayidx235.i.i, align 4
  %arrayidx236.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 30
  %205 = ptrtoint ptr %arrayidx236.i.i to i32
  call void @__asan_store4_noabort(i32 %205)
  store i32 113246548, ptr %arrayidx236.i.i, align 4
  %206 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %206)
  store i32 232, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx238.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %207 = ptrtoint ptr %arrayidx238.i.i to i32
  call void @__asan_store4_noabort(i32 %207)
  store i32 232, ptr %arrayidx238.i.i, align 4
  %arrayidx239.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %208 = ptrtoint ptr %arrayidx239.i.i to i32
  call void @__asan_store4_noabort(i32 %208)
  store i32 232, ptr %arrayidx239.i.i, align 4
  %arrayidx240.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %209 = ptrtoint ptr %arrayidx240.i.i to i32
  call void @__asan_store4_noabort(i32 %209)
  store i32 228, ptr %arrayidx240.i.i, align 4
  %arrayidx241.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %210 = ptrtoint ptr %arrayidx241.i.i to i32
  call void @__asan_store4_noabort(i32 %210)
  store i32 208, ptr %arrayidx241.i.i, align 4
  %arrayidx242.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %211 = ptrtoint ptr %arrayidx242.i.i to i32
  call void @__asan_store4_noabort(i32 %211)
  store i32 208, ptr %arrayidx242.i.i, align 4
  %arrayidx243.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %212 = ptrtoint ptr %arrayidx243.i.i to i32
  call void @__asan_store4_noabort(i32 %212)
  store i32 208, ptr %arrayidx243.i.i, align 4
  %arrayidx244.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %213 = ptrtoint ptr %arrayidx244.i.i to i32
  call void @__asan_store4_noabort(i32 %213)
  store i32 237, ptr %arrayidx244.i.i, align 4
  %arrayidx245.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %214 = ptrtoint ptr %arrayidx245.i.i to i32
  call void @__asan_store4_noabort(i32 %214)
  store i32 233, ptr %arrayidx245.i.i, align 4
  %arrayidx246.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %215 = ptrtoint ptr %arrayidx246.i.i to i32
  call void @__asan_store4_noabort(i32 %215)
  store i32 232, ptr %arrayidx246.i.i, align 4
  %arrayidx247.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %216 = ptrtoint ptr %arrayidx247.i.i to i32
  call void @__asan_store4_noabort(i32 %216)
  store i32 228, ptr %arrayidx247.i.i, align 4
  %arrayidx248.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %217 = ptrtoint ptr %arrayidx248.i.i to i32
  call void @__asan_store4_noabort(i32 %217)
  store i32 208, ptr %arrayidx248.i.i, align 4
  %arrayidx249.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %218 = ptrtoint ptr %arrayidx249.i.i to i32
  call void @__asan_store4_noabort(i32 %218)
  store i32 144, ptr %arrayidx249.i.i, align 4
  %arrayidx250.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %219 = ptrtoint ptr %arrayidx250.i.i to i32
  call void @__asan_store4_noabort(i32 %219)
  store i32 64, ptr %arrayidx250.i.i, align 4
  br label %for.body253.i.i

for.body253.i.i:                                  ; preds = %for.body253.i.i.for.body253.i.i_crit_edge, %sw.bb205.i.i
  %reg_offset.8901.i.i = phi i32 [ 0, %sw.bb205.i.i ], [ %inc257.i.i, %for.body253.i.i.for.body253.i.i_crit_edge ]
  %add254.i.i = add nuw nsw i32 %reg_offset.8901.i.i, 9796
  %arrayidx255.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.8901.i.i
  %220 = ptrtoint ptr %arrayidx255.i.i to i32
  call void @__asan_load4_noabort(i32 %220)
  %221 = load i32, ptr %arrayidx255.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add254.i.i, i32 noundef %221, i32 noundef 0) #12
  %inc257.i.i = add nuw nsw i32 %reg_offset.8901.i.i, 1
  %exitcond927.not.i.i = icmp eq i32 %inc257.i.i, 32
  br i1 %exitcond927.not.i.i, label %for.body253.i.i.for.body261.i.i_crit_edge, label %for.body253.i.i.for.body253.i.i_crit_edge

for.body253.i.i.for.body253.i.i_crit_edge:        ; preds = %for.body253.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body253.i.i

for.body253.i.i.for.body261.i.i_crit_edge:        ; preds = %for.body253.i.i
  br label %for.body261.i.i

for.body261.i.i:                                  ; preds = %for.inc267.i.i.for.body261.i.i_crit_edge, %for.body253.i.i.for.body261.i.i_crit_edge
  %reg_offset.9902.i.i = phi i32 [ %inc268.i.i, %for.inc267.i.i.for.body261.i.i_crit_edge ], [ 0, %for.body253.i.i.for.body261.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.9902.i.i)
  %cmp262.not.i.i = icmp eq i32 %reg_offset.9902.i.i, 7
  br i1 %cmp262.not.i.i, label %for.body261.i.i.for.inc267.i.i_crit_edge, label %if.then263.i.i

for.body261.i.i.for.inc267.i.i_crit_edge:         ; preds = %for.body261.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc267.i.i

if.then263.i.i:                                   ; preds = %for.body261.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add264.i.i = add nuw nsw i32 %reg_offset.9902.i.i, 9828
  %arrayidx265.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.9902.i.i
  %222 = ptrtoint ptr %arrayidx265.i.i to i32
  call void @__asan_load4_noabort(i32 %222)
  %223 = load i32, ptr %arrayidx265.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add264.i.i, i32 noundef %223, i32 noundef 0) #12
  br label %for.inc267.i.i

for.inc267.i.i:                                   ; preds = %if.then263.i.i, %for.body261.i.i.for.inc267.i.i_crit_edge
  %inc268.i.i = add nuw nsw i32 %reg_offset.9902.i.i, 1
  %exitcond928.not.i.i = icmp eq i32 %inc268.i.i, 16
  br i1 %exitcond928.not.i.i, label %for.inc267.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc267.i.i.for.body261.i.i_crit_edge

for.inc267.i.i.for.body261.i.i_crit_edge:         ; preds = %for.inc267.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body261.i.i

for.inc267.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc267.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

sw.bb270.i.i:                                     ; preds = %gfx_v8_0_init_golden_registers.exit
  %224 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %224)
  store i32 8389392, ptr %tile_mode_array.i.i, align 4
  %arrayidx272.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %225 = ptrtoint ptr %arrayidx272.i.i to i32
  call void @__asan_store4_noabort(i32 %225)
  store i32 8391440, ptr %arrayidx272.i.i, align 4
  %arrayidx273.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %226 = ptrtoint ptr %arrayidx273.i.i to i32
  call void @__asan_store4_noabort(i32 %226)
  store i32 8393488, ptr %arrayidx273.i.i, align 4
  %arrayidx274.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %227 = ptrtoint ptr %arrayidx274.i.i to i32
  call void @__asan_store4_noabort(i32 %227)
  store i32 8395536, ptr %arrayidx274.i.i, align 4
  %arrayidx275.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %228 = ptrtoint ptr %arrayidx275.i.i to i32
  call void @__asan_store4_noabort(i32 %228)
  store i32 8399632, ptr %arrayidx275.i.i, align 4
  %arrayidx276.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %229 = ptrtoint ptr %arrayidx276.i.i to i32
  call void @__asan_store4_noabort(i32 %229)
  store i32 8399624, ptr %arrayidx276.i.i, align 4
  %arrayidx277.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %230 = ptrtoint ptr %arrayidx277.i.i to i32
  call void @__asan_store4_noabort(i32 %230)
  store i32 8399636, ptr %arrayidx277.i.i, align 4
  %arrayidx278.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 7
  %231 = ptrtoint ptr %arrayidx278.i.i to i32
  call void @__asan_store4_noabort(i32 %231)
  store i32 8399188, ptr %arrayidx278.i.i, align 4
  %arrayidx279.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %232 = ptrtoint ptr %arrayidx279.i.i to i32
  call void @__asan_store4_noabort(i32 %232)
  store i32 772, ptr %arrayidx279.i.i, align 4
  %arrayidx280.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %233 = ptrtoint ptr %arrayidx280.i.i to i32
  call void @__asan_store4_noabort(i32 %233)
  store i32 33555208, ptr %arrayidx280.i.i, align 4
  %arrayidx281.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %234 = ptrtoint ptr %arrayidx281.i.i to i32
  call void @__asan_store4_noabort(i32 %234)
  store i32 33555216, ptr %arrayidx281.i.i, align 4
  %arrayidx282.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %235 = ptrtoint ptr %arrayidx282.i.i to i32
  call void @__asan_store4_noabort(i32 %235)
  store i32 100664084, ptr %arrayidx282.i.i, align 4
  %arrayidx283.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 12
  %236 = ptrtoint ptr %arrayidx283.i.i to i32
  call void @__asan_store4_noabort(i32 %236)
  store i32 100663636, ptr %arrayidx283.i.i, align 4
  %arrayidx284.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %237 = ptrtoint ptr %arrayidx284.i.i to i32
  call void @__asan_store4_noabort(i32 %237)
  store i32 37749512, ptr %arrayidx284.i.i, align 4
  %arrayidx285.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %238 = ptrtoint ptr %arrayidx285.i.i to i32
  call void @__asan_store4_noabort(i32 %238)
  store i32 37749520, ptr %arrayidx285.i.i, align 4
  %arrayidx286.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %239 = ptrtoint ptr %arrayidx286.i.i to i32
  call void @__asan_store4_noabort(i32 %239)
  store i32 37749552, ptr %arrayidx286.i.i, align 4
  %arrayidx287.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %240 = ptrtoint ptr %arrayidx287.i.i to i32
  call void @__asan_store4_noabort(i32 %240)
  store i32 104858388, ptr %arrayidx287.i.i, align 4
  %arrayidx288.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 17
  %241 = ptrtoint ptr %arrayidx288.i.i to i32
  call void @__asan_store4_noabort(i32 %241)
  store i32 104857940, ptr %arrayidx288.i.i, align 4
  %arrayidx289.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %242 = ptrtoint ptr %arrayidx289.i.i to i32
  call void @__asan_store4_noabort(i32 %242)
  store i32 4195084, ptr %arrayidx289.i.i, align 4
  %arrayidx290.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %243 = ptrtoint ptr %arrayidx290.i.i to i32
  call void @__asan_store4_noabort(i32 %243)
  store i32 16777996, ptr %arrayidx290.i.i, align 4
  %arrayidx291.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %244 = ptrtoint ptr %arrayidx291.i.i to i32
  call void @__asan_store4_noabort(i32 %244)
  store i32 16778012, ptr %arrayidx291.i.i, align 4
  %arrayidx292.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %245 = ptrtoint ptr %arrayidx292.i.i to i32
  call void @__asan_store4_noabort(i32 %245)
  store i32 16778036, ptr %arrayidx292.i.i, align 4
  %arrayidx293.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %246 = ptrtoint ptr %arrayidx293.i.i to i32
  call void @__asan_store4_noabort(i32 %246)
  store i32 16778020, ptr %arrayidx293.i.i, align 4
  %arrayidx294.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 23
  %247 = ptrtoint ptr %arrayidx294.i.i to i32
  call void @__asan_store4_noabort(i32 %247)
  store i32 16777572, ptr %arrayidx294.i.i, align 4
  %arrayidx295.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %248 = ptrtoint ptr %arrayidx295.i.i to i32
  call void @__asan_store4_noabort(i32 %248)
  store i32 4195100, ptr %arrayidx295.i.i, align 4
  %arrayidx296.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %249 = ptrtoint ptr %arrayidx296.i.i to i32
  call void @__asan_store4_noabort(i32 %249)
  store i32 16778016, ptr %arrayidx296.i.i, align 4
  %arrayidx297.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %250 = ptrtoint ptr %arrayidx297.i.i to i32
  call void @__asan_store4_noabort(i32 %250)
  store i32 16778040, ptr %arrayidx297.i.i, align 4
  %arrayidx298.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %251 = ptrtoint ptr %arrayidx298.i.i to i32
  call void @__asan_store4_noabort(i32 %251)
  store i32 46138120, ptr %arrayidx298.i.i, align 4
  %arrayidx299.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %252 = ptrtoint ptr %arrayidx299.i.i to i32
  call void @__asan_store4_noabort(i32 %252)
  store i32 46138128, ptr %arrayidx299.i.i, align 4
  %arrayidx300.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %253 = ptrtoint ptr %arrayidx300.i.i to i32
  call void @__asan_store4_noabort(i32 %253)
  store i32 113246996, ptr %arrayidx300.i.i, align 4
  %arrayidx301.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 30
  %254 = ptrtoint ptr %arrayidx301.i.i to i32
  call void @__asan_store4_noabort(i32 %254)
  store i32 113246548, ptr %arrayidx301.i.i, align 4
  %255 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %255)
  store i32 232, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx303.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %256 = ptrtoint ptr %arrayidx303.i.i to i32
  call void @__asan_store4_noabort(i32 %256)
  store i32 232, ptr %arrayidx303.i.i, align 4
  %arrayidx304.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %257 = ptrtoint ptr %arrayidx304.i.i to i32
  call void @__asan_store4_noabort(i32 %257)
  store i32 232, ptr %arrayidx304.i.i, align 4
  %arrayidx305.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %258 = ptrtoint ptr %arrayidx305.i.i to i32
  call void @__asan_store4_noabort(i32 %258)
  store i32 232, ptr %arrayidx305.i.i, align 4
  %arrayidx306.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %259 = ptrtoint ptr %arrayidx306.i.i to i32
  call void @__asan_store4_noabort(i32 %259)
  store i32 212, ptr %arrayidx306.i.i, align 4
  %arrayidx307.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %260 = ptrtoint ptr %arrayidx307.i.i to i32
  call void @__asan_store4_noabort(i32 %260)
  store i32 192, ptr %arrayidx307.i.i, align 4
  %arrayidx308.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %261 = ptrtoint ptr %arrayidx308.i.i to i32
  call void @__asan_store4_noabort(i32 %261)
  store i32 192, ptr %arrayidx308.i.i, align 4
  %arrayidx309.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %262 = ptrtoint ptr %arrayidx309.i.i to i32
  call void @__asan_store4_noabort(i32 %262)
  store i32 236, ptr %arrayidx309.i.i, align 4
  %arrayidx310.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %263 = ptrtoint ptr %arrayidx310.i.i to i32
  call void @__asan_store4_noabort(i32 %263)
  store i32 232, ptr %arrayidx310.i.i, align 4
  %arrayidx311.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %264 = ptrtoint ptr %arrayidx311.i.i to i32
  call void @__asan_store4_noabort(i32 %264)
  store i32 212, ptr %arrayidx311.i.i, align 4
  %arrayidx312.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %265 = ptrtoint ptr %arrayidx312.i.i to i32
  call void @__asan_store4_noabort(i32 %265)
  store i32 208, ptr %arrayidx312.i.i, align 4
  %arrayidx313.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %266 = ptrtoint ptr %arrayidx313.i.i to i32
  call void @__asan_store4_noabort(i32 %266)
  store i32 128, ptr %arrayidx313.i.i, align 4
  %arrayidx314.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %267 = ptrtoint ptr %arrayidx314.i.i to i32
  call void @__asan_store4_noabort(i32 %267)
  store i32 64, ptr %arrayidx314.i.i, align 4
  %arrayidx315.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %268 = ptrtoint ptr %arrayidx315.i.i to i32
  call void @__asan_store4_noabort(i32 %268)
  store i32 64, ptr %arrayidx315.i.i, align 4
  br label %for.body318.i.i

for.body318.i.i:                                  ; preds = %for.body318.i.i.for.body318.i.i_crit_edge, %sw.bb270.i.i
  %reg_offset.10898.i.i = phi i32 [ 0, %sw.bb270.i.i ], [ %inc322.i.i, %for.body318.i.i.for.body318.i.i_crit_edge ]
  %add319.i.i = add nuw nsw i32 %reg_offset.10898.i.i, 9796
  %arrayidx320.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.10898.i.i
  %269 = ptrtoint ptr %arrayidx320.i.i to i32
  call void @__asan_load4_noabort(i32 %269)
  %270 = load i32, ptr %arrayidx320.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add319.i.i, i32 noundef %270, i32 noundef 0) #12
  %inc322.i.i = add nuw nsw i32 %reg_offset.10898.i.i, 1
  %exitcond925.not.i.i = icmp eq i32 %inc322.i.i, 32
  br i1 %exitcond925.not.i.i, label %for.body318.i.i.for.body326.i.i_crit_edge, label %for.body318.i.i.for.body318.i.i_crit_edge

for.body318.i.i.for.body318.i.i_crit_edge:        ; preds = %for.body318.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body318.i.i

for.body318.i.i.for.body326.i.i_crit_edge:        ; preds = %for.body318.i.i
  br label %for.body326.i.i

for.body326.i.i:                                  ; preds = %for.inc332.i.i.for.body326.i.i_crit_edge, %for.body318.i.i.for.body326.i.i_crit_edge
  %reg_offset.11899.i.i = phi i32 [ %inc333.i.i, %for.inc332.i.i.for.body326.i.i_crit_edge ], [ 0, %for.body318.i.i.for.body326.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.11899.i.i)
  %cmp327.not.i.i = icmp eq i32 %reg_offset.11899.i.i, 7
  br i1 %cmp327.not.i.i, label %for.body326.i.i.for.inc332.i.i_crit_edge, label %if.then328.i.i

for.body326.i.i.for.inc332.i.i_crit_edge:         ; preds = %for.body326.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc332.i.i

if.then328.i.i:                                   ; preds = %for.body326.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add329.i.i = add nuw nsw i32 %reg_offset.11899.i.i, 9828
  %arrayidx330.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.11899.i.i
  %271 = ptrtoint ptr %arrayidx330.i.i to i32
  call void @__asan_load4_noabort(i32 %271)
  %272 = load i32, ptr %arrayidx330.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add329.i.i, i32 noundef %272, i32 noundef 0) #12
  br label %for.inc332.i.i

for.inc332.i.i:                                   ; preds = %if.then328.i.i, %for.body326.i.i.for.inc332.i.i_crit_edge
  %inc333.i.i = add nuw nsw i32 %reg_offset.11899.i.i, 1
  %exitcond926.not.i.i = icmp eq i32 %inc333.i.i, 16
  br i1 %exitcond926.not.i.i, label %for.inc332.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc332.i.i.for.body326.i.i_crit_edge

for.inc332.i.i.for.body326.i.i_crit_edge:         ; preds = %for.inc332.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body326.i.i

for.inc332.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc332.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

sw.bb335.i.i:                                     ; preds = %gfx_v8_0_init_golden_registers.exit
  %273 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %273)
  store i32 8388624, ptr %tile_mode_array.i.i, align 4
  %arrayidx337.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %274 = ptrtoint ptr %arrayidx337.i.i to i32
  call void @__asan_store4_noabort(i32 %274)
  store i32 8390672, ptr %arrayidx337.i.i, align 4
  %arrayidx338.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %275 = ptrtoint ptr %arrayidx338.i.i to i32
  call void @__asan_store4_noabort(i32 %275)
  store i32 8392720, ptr %arrayidx338.i.i, align 4
  %arrayidx339.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %276 = ptrtoint ptr %arrayidx339.i.i to i32
  call void @__asan_store4_noabort(i32 %276)
  store i32 8394768, ptr %arrayidx339.i.i, align 4
  %arrayidx340.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %277 = ptrtoint ptr %arrayidx340.i.i to i32
  call void @__asan_store4_noabort(i32 %277)
  store i32 8398864, ptr %arrayidx340.i.i, align 4
  %arrayidx341.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %278 = ptrtoint ptr %arrayidx341.i.i to i32
  call void @__asan_store4_noabort(i32 %278)
  store i32 8398856, ptr %arrayidx341.i.i, align 4
  %arrayidx342.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %279 = ptrtoint ptr %arrayidx342.i.i to i32
  call void @__asan_store4_noabort(i32 %279)
  store i32 8398868, ptr %arrayidx342.i.i, align 4
  %arrayidx343.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %280 = ptrtoint ptr %arrayidx343.i.i to i32
  call void @__asan_store4_noabort(i32 %280)
  store i32 4, ptr %arrayidx343.i.i, align 4
  %arrayidx344.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %281 = ptrtoint ptr %arrayidx344.i.i to i32
  call void @__asan_store4_noabort(i32 %281)
  store i32 33554440, ptr %arrayidx344.i.i, align 4
  %arrayidx345.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %282 = ptrtoint ptr %arrayidx345.i.i to i32
  call void @__asan_store4_noabort(i32 %282)
  store i32 33554448, ptr %arrayidx345.i.i, align 4
  %arrayidx346.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %283 = ptrtoint ptr %arrayidx346.i.i to i32
  call void @__asan_store4_noabort(i32 %283)
  store i32 100663316, ptr %arrayidx346.i.i, align 4
  %arrayidx347.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %284 = ptrtoint ptr %arrayidx347.i.i to i32
  call void @__asan_store4_noabort(i32 %284)
  store i32 37748744, ptr %arrayidx347.i.i, align 4
  %arrayidx348.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %285 = ptrtoint ptr %arrayidx348.i.i to i32
  call void @__asan_store4_noabort(i32 %285)
  store i32 37748752, ptr %arrayidx348.i.i, align 4
  %arrayidx349.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %286 = ptrtoint ptr %arrayidx349.i.i to i32
  call void @__asan_store4_noabort(i32 %286)
  store i32 37748784, ptr %arrayidx349.i.i, align 4
  %arrayidx350.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %287 = ptrtoint ptr %arrayidx350.i.i to i32
  call void @__asan_store4_noabort(i32 %287)
  store i32 104857620, ptr %arrayidx350.i.i, align 4
  %arrayidx351.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %288 = ptrtoint ptr %arrayidx351.i.i to i32
  call void @__asan_store4_noabort(i32 %288)
  store i32 4194316, ptr %arrayidx351.i.i, align 4
  %arrayidx352.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %289 = ptrtoint ptr %arrayidx352.i.i to i32
  call void @__asan_store4_noabort(i32 %289)
  store i32 16777228, ptr %arrayidx352.i.i, align 4
  %arrayidx353.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %290 = ptrtoint ptr %arrayidx353.i.i to i32
  call void @__asan_store4_noabort(i32 %290)
  store i32 16777244, ptr %arrayidx353.i.i, align 4
  %arrayidx354.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %291 = ptrtoint ptr %arrayidx354.i.i to i32
  call void @__asan_store4_noabort(i32 %291)
  store i32 16777268, ptr %arrayidx354.i.i, align 4
  %arrayidx355.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %292 = ptrtoint ptr %arrayidx355.i.i to i32
  call void @__asan_store4_noabort(i32 %292)
  store i32 16777252, ptr %arrayidx355.i.i, align 4
  %arrayidx356.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %293 = ptrtoint ptr %arrayidx356.i.i to i32
  call void @__asan_store4_noabort(i32 %293)
  store i32 4194332, ptr %arrayidx356.i.i, align 4
  %arrayidx357.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %294 = ptrtoint ptr %arrayidx357.i.i to i32
  call void @__asan_store4_noabort(i32 %294)
  store i32 16777248, ptr %arrayidx357.i.i, align 4
  %arrayidx358.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %295 = ptrtoint ptr %arrayidx358.i.i to i32
  call void @__asan_store4_noabort(i32 %295)
  store i32 16777272, ptr %arrayidx358.i.i, align 4
  %arrayidx359.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %296 = ptrtoint ptr %arrayidx359.i.i to i32
  call void @__asan_store4_noabort(i32 %296)
  store i32 46137352, ptr %arrayidx359.i.i, align 4
  %arrayidx360.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %297 = ptrtoint ptr %arrayidx360.i.i to i32
  call void @__asan_store4_noabort(i32 %297)
  store i32 46137360, ptr %arrayidx360.i.i, align 4
  %arrayidx361.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %298 = ptrtoint ptr %arrayidx361.i.i to i32
  call void @__asan_store4_noabort(i32 %298)
  store i32 113246228, ptr %arrayidx361.i.i, align 4
  %299 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %299)
  store i32 168, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx363.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %300 = ptrtoint ptr %arrayidx363.i.i to i32
  call void @__asan_store4_noabort(i32 %300)
  store i32 164, ptr %arrayidx363.i.i, align 4
  %arrayidx364.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %301 = ptrtoint ptr %arrayidx364.i.i to i32
  call void @__asan_store4_noabort(i32 %301)
  store i32 144, ptr %arrayidx364.i.i, align 4
  %arrayidx365.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %302 = ptrtoint ptr %arrayidx365.i.i to i32
  call void @__asan_store4_noabort(i32 %302)
  store i32 144, ptr %arrayidx365.i.i, align 4
  %arrayidx366.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %303 = ptrtoint ptr %arrayidx366.i.i to i32
  call void @__asan_store4_noabort(i32 %303)
  store i32 144, ptr %arrayidx366.i.i, align 4
  %arrayidx367.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %304 = ptrtoint ptr %arrayidx367.i.i to i32
  call void @__asan_store4_noabort(i32 %304)
  store i32 144, ptr %arrayidx367.i.i, align 4
  %arrayidx368.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %305 = ptrtoint ptr %arrayidx368.i.i to i32
  call void @__asan_store4_noabort(i32 %305)
  store i32 144, ptr %arrayidx368.i.i, align 4
  %arrayidx369.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %306 = ptrtoint ptr %arrayidx369.i.i to i32
  call void @__asan_store4_noabort(i32 %306)
  store i32 238, ptr %arrayidx369.i.i, align 4
  %arrayidx370.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %307 = ptrtoint ptr %arrayidx370.i.i to i32
  call void @__asan_store4_noabort(i32 %307)
  store i32 234, ptr %arrayidx370.i.i, align 4
  %arrayidx371.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %308 = ptrtoint ptr %arrayidx371.i.i to i32
  call void @__asan_store4_noabort(i32 %308)
  store i32 233, ptr %arrayidx371.i.i, align 4
  %arrayidx372.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %309 = ptrtoint ptr %arrayidx372.i.i to i32
  call void @__asan_store4_noabort(i32 %309)
  store i32 229, ptr %arrayidx372.i.i, align 4
  %arrayidx373.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %310 = ptrtoint ptr %arrayidx373.i.i to i32
  call void @__asan_store4_noabort(i32 %310)
  store i32 228, ptr %arrayidx373.i.i, align 4
  %arrayidx374.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %311 = ptrtoint ptr %arrayidx374.i.i to i32
  call void @__asan_store4_noabort(i32 %311)
  store i32 224, ptr %arrayidx374.i.i, align 4
  %arrayidx375.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %312 = ptrtoint ptr %arrayidx375.i.i to i32
  call void @__asan_store4_noabort(i32 %312)
  store i32 144, ptr %arrayidx375.i.i, align 4
  br label %for.body378.i.i

for.body378.i.i:                                  ; preds = %for.inc390.i.i.for.body378.i.i_crit_edge, %sw.bb335.i.i
  %reg_offset.12894.i.i = phi i32 [ 0, %sw.bb335.i.i ], [ %inc391.i.i, %for.inc390.i.i.for.body378.i.i_crit_edge ]
  %313 = zext i32 %reg_offset.12894.i.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %313, ptr @__sancov_gen_cov_switch_values.105)
  switch i32 %reg_offset.12894.i.i, label %if.then386.i.i [
    i32 7, label %for.body378.i.i.for.inc390.i.i_crit_edge
    i32 12, label %for.body378.i.i.for.inc390.i.i_crit_edge60
    i32 17, label %for.body378.i.i.for.inc390.i.i_crit_edge61
    i32 23, label %for.body378.i.i.for.inc390.i.i_crit_edge62
  ]

for.body378.i.i.for.inc390.i.i_crit_edge62:       ; preds = %for.body378.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc390.i.i

for.body378.i.i.for.inc390.i.i_crit_edge61:       ; preds = %for.body378.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc390.i.i

for.body378.i.i.for.inc390.i.i_crit_edge60:       ; preds = %for.body378.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc390.i.i

for.body378.i.i.for.inc390.i.i_crit_edge:         ; preds = %for.body378.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc390.i.i

if.then386.i.i:                                   ; preds = %for.body378.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add387.i.i = add nuw nsw i32 %reg_offset.12894.i.i, 9796
  %arrayidx388.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.12894.i.i
  %314 = ptrtoint ptr %arrayidx388.i.i to i32
  call void @__asan_load4_noabort(i32 %314)
  %315 = load i32, ptr %arrayidx388.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add387.i.i, i32 noundef %315, i32 noundef 0) #12
  br label %for.inc390.i.i

for.inc390.i.i:                                   ; preds = %if.then386.i.i, %for.body378.i.i.for.inc390.i.i_crit_edge, %for.body378.i.i.for.inc390.i.i_crit_edge60, %for.body378.i.i.for.inc390.i.i_crit_edge61, %for.body378.i.i.for.inc390.i.i_crit_edge62
  %inc391.i.i = add nuw nsw i32 %reg_offset.12894.i.i, 1
  %exitcond.not.i.i = icmp eq i32 %inc391.i.i, 32
  br i1 %exitcond.not.i.i, label %for.inc390.i.i.for.body395.i.i_crit_edge, label %for.inc390.i.i.for.body378.i.i_crit_edge

for.inc390.i.i.for.body378.i.i_crit_edge:         ; preds = %for.inc390.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body378.i.i

for.inc390.i.i.for.body395.i.i_crit_edge:         ; preds = %for.inc390.i.i
  br label %for.body395.i.i

for.body395.i.i:                                  ; preds = %for.inc401.i.i.for.body395.i.i_crit_edge, %for.inc390.i.i.for.body395.i.i_crit_edge
  %reg_offset.13896.i.i = phi i32 [ %inc402.i.i, %for.inc401.i.i.for.body395.i.i_crit_edge ], [ 0, %for.inc390.i.i.for.body395.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.13896.i.i)
  %cmp396.not.i.i = icmp eq i32 %reg_offset.13896.i.i, 7
  br i1 %cmp396.not.i.i, label %for.body395.i.i.for.inc401.i.i_crit_edge, label %if.then397.i.i

for.body395.i.i.for.inc401.i.i_crit_edge:         ; preds = %for.body395.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc401.i.i

if.then397.i.i:                                   ; preds = %for.body395.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add398.i.i = add nuw nsw i32 %reg_offset.13896.i.i, 9828
  %arrayidx399.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.13896.i.i
  %316 = ptrtoint ptr %arrayidx399.i.i to i32
  call void @__asan_load4_noabort(i32 %316)
  %317 = load i32, ptr %arrayidx399.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add398.i.i, i32 noundef %317, i32 noundef 0) #12
  br label %for.inc401.i.i

for.inc401.i.i:                                   ; preds = %if.then397.i.i, %for.body395.i.i.for.inc401.i.i_crit_edge
  %inc402.i.i = add nuw nsw i32 %reg_offset.13896.i.i, 1
  %exitcond924.not.i.i = icmp eq i32 %inc402.i.i, 16
  br i1 %exitcond924.not.i.i, label %for.inc401.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc401.i.i.for.body395.i.i_crit_edge

for.inc401.i.i.for.body395.i.i_crit_edge:         ; preds = %for.inc401.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body395.i.i

for.inc401.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc401.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

do.end.i.i:                                       ; preds = %gfx_v8_0_init_golden_registers.exit
  call void @__sanitizer_cov_trace_pc() #14
  %318 = ptrtoint ptr %handle to i32
  call void @__asan_load4_noabort(i32 %318)
  %319 = load ptr, ptr %handle, align 8
  tail call void (ptr, ptr, ...) @_dev_warn(ptr noundef %319, ptr noundef nonnull @.str.75, i32 noundef %30) #15
  br label %sw.bb405.i.i

sw.bb405.i.i:                                     ; preds = %do.end.i.i, %gfx_v8_0_init_golden_registers.exit.sw.bb405.i.i_crit_edge
  %320 = ptrtoint ptr %tile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %320)
  store i32 8388624, ptr %tile_mode_array.i.i, align 4
  %arrayidx407.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 1
  %321 = ptrtoint ptr %arrayidx407.i.i to i32
  call void @__asan_store4_noabort(i32 %321)
  store i32 8390672, ptr %arrayidx407.i.i, align 4
  %arrayidx408.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 2
  %322 = ptrtoint ptr %arrayidx408.i.i to i32
  call void @__asan_store4_noabort(i32 %322)
  store i32 8392720, ptr %arrayidx408.i.i, align 4
  %arrayidx409.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 3
  %323 = ptrtoint ptr %arrayidx409.i.i to i32
  call void @__asan_store4_noabort(i32 %323)
  store i32 8394768, ptr %arrayidx409.i.i, align 4
  %arrayidx410.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 4
  %324 = ptrtoint ptr %arrayidx410.i.i to i32
  call void @__asan_store4_noabort(i32 %324)
  store i32 8398864, ptr %arrayidx410.i.i, align 4
  %arrayidx411.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 5
  %325 = ptrtoint ptr %arrayidx411.i.i to i32
  call void @__asan_store4_noabort(i32 %325)
  store i32 8398856, ptr %arrayidx411.i.i, align 4
  %arrayidx412.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 6
  %326 = ptrtoint ptr %arrayidx412.i.i to i32
  call void @__asan_store4_noabort(i32 %326)
  store i32 8398868, ptr %arrayidx412.i.i, align 4
  %arrayidx413.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 8
  %327 = ptrtoint ptr %arrayidx413.i.i to i32
  call void @__asan_store4_noabort(i32 %327)
  store i32 4, ptr %arrayidx413.i.i, align 4
  %arrayidx414.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 9
  %328 = ptrtoint ptr %arrayidx414.i.i to i32
  call void @__asan_store4_noabort(i32 %328)
  store i32 33554440, ptr %arrayidx414.i.i, align 4
  %arrayidx415.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 10
  %329 = ptrtoint ptr %arrayidx415.i.i to i32
  call void @__asan_store4_noabort(i32 %329)
  store i32 33554448, ptr %arrayidx415.i.i, align 4
  %arrayidx416.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 11
  %330 = ptrtoint ptr %arrayidx416.i.i to i32
  call void @__asan_store4_noabort(i32 %330)
  store i32 100663316, ptr %arrayidx416.i.i, align 4
  %arrayidx417.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 13
  %331 = ptrtoint ptr %arrayidx417.i.i to i32
  call void @__asan_store4_noabort(i32 %331)
  store i32 37748744, ptr %arrayidx417.i.i, align 4
  %arrayidx418.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 14
  %332 = ptrtoint ptr %arrayidx418.i.i to i32
  call void @__asan_store4_noabort(i32 %332)
  store i32 37748752, ptr %arrayidx418.i.i, align 4
  %arrayidx419.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 15
  %333 = ptrtoint ptr %arrayidx419.i.i to i32
  call void @__asan_store4_noabort(i32 %333)
  store i32 37748784, ptr %arrayidx419.i.i, align 4
  %arrayidx420.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 16
  %334 = ptrtoint ptr %arrayidx420.i.i to i32
  call void @__asan_store4_noabort(i32 %334)
  store i32 104857620, ptr %arrayidx420.i.i, align 4
  %arrayidx421.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 18
  %335 = ptrtoint ptr %arrayidx421.i.i to i32
  call void @__asan_store4_noabort(i32 %335)
  store i32 4194316, ptr %arrayidx421.i.i, align 4
  %arrayidx422.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 19
  %336 = ptrtoint ptr %arrayidx422.i.i to i32
  call void @__asan_store4_noabort(i32 %336)
  store i32 16777228, ptr %arrayidx422.i.i, align 4
  %arrayidx423.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 20
  %337 = ptrtoint ptr %arrayidx423.i.i to i32
  call void @__asan_store4_noabort(i32 %337)
  store i32 16777244, ptr %arrayidx423.i.i, align 4
  %arrayidx424.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 21
  %338 = ptrtoint ptr %arrayidx424.i.i to i32
  call void @__asan_store4_noabort(i32 %338)
  store i32 16777268, ptr %arrayidx424.i.i, align 4
  %arrayidx425.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 22
  %339 = ptrtoint ptr %arrayidx425.i.i to i32
  call void @__asan_store4_noabort(i32 %339)
  store i32 16777252, ptr %arrayidx425.i.i, align 4
  %arrayidx426.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 24
  %340 = ptrtoint ptr %arrayidx426.i.i to i32
  call void @__asan_store4_noabort(i32 %340)
  store i32 4194332, ptr %arrayidx426.i.i, align 4
  %arrayidx427.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 25
  %341 = ptrtoint ptr %arrayidx427.i.i to i32
  call void @__asan_store4_noabort(i32 %341)
  store i32 16777248, ptr %arrayidx427.i.i, align 4
  %arrayidx428.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 26
  %342 = ptrtoint ptr %arrayidx428.i.i to i32
  call void @__asan_store4_noabort(i32 %342)
  store i32 16777272, ptr %arrayidx428.i.i, align 4
  %arrayidx429.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 27
  %343 = ptrtoint ptr %arrayidx429.i.i to i32
  call void @__asan_store4_noabort(i32 %343)
  store i32 46137352, ptr %arrayidx429.i.i, align 4
  %arrayidx430.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 28
  %344 = ptrtoint ptr %arrayidx430.i.i to i32
  call void @__asan_store4_noabort(i32 %344)
  store i32 46137360, ptr %arrayidx430.i.i, align 4
  %arrayidx431.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 27, i32 29
  %345 = ptrtoint ptr %arrayidx431.i.i to i32
  call void @__asan_store4_noabort(i32 %345)
  store i32 113246228, ptr %arrayidx431.i.i, align 4
  %346 = ptrtoint ptr %macrotile_mode_array.i.i to i32
  call void @__asan_store4_noabort(i32 %346)
  store i32 168, ptr %macrotile_mode_array.i.i, align 4
  %arrayidx433.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 1
  %347 = ptrtoint ptr %arrayidx433.i.i to i32
  call void @__asan_store4_noabort(i32 %347)
  store i32 164, ptr %arrayidx433.i.i, align 4
  %arrayidx434.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 2
  %348 = ptrtoint ptr %arrayidx434.i.i to i32
  call void @__asan_store4_noabort(i32 %348)
  store i32 144, ptr %arrayidx434.i.i, align 4
  %arrayidx435.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 3
  %349 = ptrtoint ptr %arrayidx435.i.i to i32
  call void @__asan_store4_noabort(i32 %349)
  store i32 144, ptr %arrayidx435.i.i, align 4
  %arrayidx436.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 4
  %350 = ptrtoint ptr %arrayidx436.i.i to i32
  call void @__asan_store4_noabort(i32 %350)
  store i32 144, ptr %arrayidx436.i.i, align 4
  %arrayidx437.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 5
  %351 = ptrtoint ptr %arrayidx437.i.i to i32
  call void @__asan_store4_noabort(i32 %351)
  store i32 144, ptr %arrayidx437.i.i, align 4
  %arrayidx438.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 6
  %352 = ptrtoint ptr %arrayidx438.i.i to i32
  call void @__asan_store4_noabort(i32 %352)
  store i32 144, ptr %arrayidx438.i.i, align 4
  %arrayidx439.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 8
  %353 = ptrtoint ptr %arrayidx439.i.i to i32
  call void @__asan_store4_noabort(i32 %353)
  store i32 238, ptr %arrayidx439.i.i, align 4
  %arrayidx440.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 9
  %354 = ptrtoint ptr %arrayidx440.i.i to i32
  call void @__asan_store4_noabort(i32 %354)
  store i32 234, ptr %arrayidx440.i.i, align 4
  %arrayidx441.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 10
  %355 = ptrtoint ptr %arrayidx441.i.i to i32
  call void @__asan_store4_noabort(i32 %355)
  store i32 233, ptr %arrayidx441.i.i, align 4
  %arrayidx442.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 11
  %356 = ptrtoint ptr %arrayidx442.i.i to i32
  call void @__asan_store4_noabort(i32 %356)
  store i32 229, ptr %arrayidx442.i.i, align 4
  %arrayidx443.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 12
  %357 = ptrtoint ptr %arrayidx443.i.i to i32
  call void @__asan_store4_noabort(i32 %357)
  store i32 228, ptr %arrayidx443.i.i, align 4
  %arrayidx444.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 13
  %358 = ptrtoint ptr %arrayidx444.i.i to i32
  call void @__asan_store4_noabort(i32 %358)
  store i32 224, ptr %arrayidx444.i.i, align 4
  %arrayidx445.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 28, i32 14
  %359 = ptrtoint ptr %arrayidx445.i.i to i32
  call void @__asan_store4_noabort(i32 %359)
  store i32 144, ptr %arrayidx445.i.i, align 4
  br label %for.body448.i.i

for.body448.i.i:                                  ; preds = %for.inc460.i.i.for.body448.i.i_crit_edge, %sw.bb405.i.i
  %reg_offset.14914.i.i = phi i32 [ 0, %sw.bb405.i.i ], [ %inc461.i.i, %for.inc460.i.i.for.body448.i.i_crit_edge ]
  %360 = zext i32 %reg_offset.14914.i.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %360, ptr @__sancov_gen_cov_switch_values.106)
  switch i32 %reg_offset.14914.i.i, label %if.then456.i.i [
    i32 7, label %for.body448.i.i.for.inc460.i.i_crit_edge
    i32 12, label %for.body448.i.i.for.inc460.i.i_crit_edge63
    i32 17, label %for.body448.i.i.for.inc460.i.i_crit_edge64
    i32 23, label %for.body448.i.i.for.inc460.i.i_crit_edge65
  ]

for.body448.i.i.for.inc460.i.i_crit_edge65:       ; preds = %for.body448.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc460.i.i

for.body448.i.i.for.inc460.i.i_crit_edge64:       ; preds = %for.body448.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc460.i.i

for.body448.i.i.for.inc460.i.i_crit_edge63:       ; preds = %for.body448.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc460.i.i

for.body448.i.i.for.inc460.i.i_crit_edge:         ; preds = %for.body448.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc460.i.i

if.then456.i.i:                                   ; preds = %for.body448.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add457.i.i = add nuw nsw i32 %reg_offset.14914.i.i, 9796
  %arrayidx458.i.i = getelementptr i32, ptr %tile_mode_array.i.i, i32 %reg_offset.14914.i.i
  %361 = ptrtoint ptr %arrayidx458.i.i to i32
  call void @__asan_load4_noabort(i32 %361)
  %362 = load i32, ptr %arrayidx458.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add457.i.i, i32 noundef %362, i32 noundef 0) #12
  br label %for.inc460.i.i

for.inc460.i.i:                                   ; preds = %if.then456.i.i, %for.body448.i.i.for.inc460.i.i_crit_edge, %for.body448.i.i.for.inc460.i.i_crit_edge63, %for.body448.i.i.for.inc460.i.i_crit_edge64, %for.body448.i.i.for.inc460.i.i_crit_edge65
  %inc461.i.i = add nuw nsw i32 %reg_offset.14914.i.i, 1
  %exitcond935.not.i.i = icmp eq i32 %inc461.i.i, 32
  br i1 %exitcond935.not.i.i, label %for.inc460.i.i.for.body465.i.i_crit_edge, label %for.inc460.i.i.for.body448.i.i_crit_edge

for.inc460.i.i.for.body448.i.i_crit_edge:         ; preds = %for.inc460.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body448.i.i

for.inc460.i.i.for.body465.i.i_crit_edge:         ; preds = %for.inc460.i.i
  br label %for.body465.i.i

for.body465.i.i:                                  ; preds = %for.inc471.i.i.for.body465.i.i_crit_edge, %for.inc460.i.i.for.body465.i.i_crit_edge
  %reg_offset.15916.i.i = phi i32 [ %inc472.i.i, %for.inc471.i.i.for.body465.i.i_crit_edge ], [ 0, %for.inc460.i.i.for.body465.i.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %reg_offset.15916.i.i)
  %cmp466.not.i.i = icmp eq i32 %reg_offset.15916.i.i, 7
  br i1 %cmp466.not.i.i, label %for.body465.i.i.for.inc471.i.i_crit_edge, label %if.then467.i.i

for.body465.i.i.for.inc471.i.i_crit_edge:         ; preds = %for.body465.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc471.i.i

if.then467.i.i:                                   ; preds = %for.body465.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add468.i.i = add nuw nsw i32 %reg_offset.15916.i.i, 9828
  %arrayidx469.i.i = getelementptr i32, ptr %macrotile_mode_array.i.i, i32 %reg_offset.15916.i.i
  %363 = ptrtoint ptr %arrayidx469.i.i to i32
  call void @__asan_load4_noabort(i32 %363)
  %364 = load i32, ptr %arrayidx469.i.i, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %add468.i.i, i32 noundef %364, i32 noundef 0) #12
  br label %for.inc471.i.i

for.inc471.i.i:                                   ; preds = %if.then467.i.i, %for.body465.i.i.for.inc471.i.i_crit_edge
  %inc472.i.i = add nuw nsw i32 %reg_offset.15916.i.i, 1
  %exitcond936.not.i.i = icmp eq i32 %inc472.i.i, 16
  br i1 %exitcond936.not.i.i, label %for.inc471.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, label %for.inc471.i.i.for.body465.i.i_crit_edge

for.inc471.i.i.for.body465.i.i_crit_edge:         ; preds = %for.inc471.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body465.i.i

for.inc471.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge: ; preds = %for.inc471.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_tiling_mode_table_init.exit.i

gfx_v8_0_tiling_mode_table_init.exit.i:           ; preds = %for.inc471.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc401.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc332.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc267.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc202.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc137.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge, %for.inc72.i.i.gfx_v8_0_tiling_mode_table_init.exit.i_crit_edge
  %config.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1
  %max_backends_per_se.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 4
  %365 = ptrtoint ptr %max_backends_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %365)
  %366 = load i32, ptr %max_backends_per_se.i.i, align 8
  %max_sh_per_se.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 3
  %367 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %367)
  %368 = load i32, ptr %max_sh_per_se.i.i, align 4
  %div.i.i = udiv i32 %366, %368
  %grbm_idx_mutex.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 21
  tail call void @mutex_lock_nested(ptr noundef %grbm_idx_mutex.i.i, i32 noundef 0) #12
  %369 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %369)
  %370 = load i32, ptr %config.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %370)
  %cmp492.not.i.i = icmp eq i32 %370, 0
  br i1 %cmp492.not.i.i, label %gfx_v8_0_tiling_mode_table_init.exit.i.for.end17.i.i_crit_edge, label %gfx_v8_0_tiling_mode_table_init.exit.i.for.cond5.preheader.i.i_crit_edge

gfx_v8_0_tiling_mode_table_init.exit.i.for.cond5.preheader.i.i_crit_edge: ; preds = %gfx_v8_0_tiling_mode_table_init.exit.i
  br label %for.cond5.preheader.i.i

gfx_v8_0_tiling_mode_table_init.exit.i.for.end17.i.i_crit_edge: ; preds = %gfx_v8_0_tiling_mode_table_init.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end17.i.i

for.cond5.preheader.i.i:                          ; preds = %for.inc15.i.i.for.cond5.preheader.i.i_crit_edge, %gfx_v8_0_tiling_mode_table_init.exit.i.for.cond5.preheader.i.i_crit_edge
  %i.0494.i.i = phi i32 [ %inc16.i.i, %for.inc15.i.i.for.cond5.preheader.i.i_crit_edge ], [ 0, %gfx_v8_0_tiling_mode_table_init.exit.i.for.cond5.preheader.i.i_crit_edge ]
  %active_rbs.0493.i.i = phi i32 [ %active_rbs.1.lcssa.i.i, %for.inc15.i.i.for.cond5.preheader.i.i_crit_edge ], [ 0, %gfx_v8_0_tiling_mode_table_init.exit.i.for.cond5.preheader.i.i_crit_edge ]
  %371 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %371)
  %372 = load i32, ptr %max_sh_per_se.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %372)
  %cmp9489.not.i.i = icmp eq i32 %372, 0
  br i1 %cmp9489.not.i.i, label %for.cond5.preheader.i.i.for.inc15.i.i_crit_edge, label %for.body10.lr.ph.i.i

for.cond5.preheader.i.i.for.inc15.i.i_crit_edge:  ; preds = %for.cond5.preheader.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc15.i.i

for.body10.lr.ph.i.i:                             ; preds = %for.cond5.preheader.i.i
  %shl7.i.i.i = shl i32 %i.0494.i.i, 16
  %and8.i.i.i = and i32 %shl7.i.i.i, 16711680
  br label %for.body10.i.i

for.body10.i.i:                                   ; preds = %for.body10.i.i.for.body10.i.i_crit_edge, %for.body10.lr.ph.i.i
  %active_rbs.1491.i.i = phi i32 [ %active_rbs.0493.i.i, %for.body10.lr.ph.i.i ], [ %or.i.i, %for.body10.i.i.for.body10.i.i_crit_edge ]
  %j.0490.i.i = phi i32 [ 0, %for.body10.lr.ph.i.i ], [ %inc.i.i, %for.body10.i.i.for.body10.i.i_crit_edge ]
  %shl17.i.i.i = shl i32 %j.0490.i.i, 8
  %and18.i.i.i = and i32 %shl17.i.i.i, 65280
  %and8.i.op.i.i = or i32 %and8.i.i.i, %and18.i.i.i
  %data.2.i.i.i = or i32 %and8.i.op.i.i, 1073741824
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef %data.2.i.i.i, i32 noundef 0) #12
  %call.i.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 9789, i32 noundef 0) #12
  %call1.i.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 9951, i32 noundef 0) #12
  %or.i.i.i = or i32 %call1.i.i.i, %call.i.i.i
  %and.i.i.i = lshr i32 %or.i.i.i, 16
  %shr.i.i.i = and i32 %and.i.i.i, 255
  %373 = ptrtoint ptr %max_backends_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %373)
  %374 = load i32, ptr %max_backends_per_se.i.i, align 8
  %375 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %375)
  %376 = load i32, ptr %max_sh_per_se.i.i, align 4
  %div.i.i.i = udiv i32 %374, %376
  %sh_prom.i.i.i.i = zext i32 %div.i.i.i to i64
  %notmask.i.i.i.i = shl nsw i64 -1, %sh_prom.i.i.i.i
  %377 = trunc i64 %notmask.i.i.i.i to i32
  %and5.demorgan.i.i.i = or i32 %shr.i.i.i, %377
  %and5.i.i.i = xor i32 %and5.demorgan.i.i.i, -1
  %mul.i.i = mul i32 %376, %i.0494.i.i
  %add.i97.i = add i32 %mul.i.i, %j.0490.i.i
  %mul14.i.i = mul i32 %add.i97.i, %div.i.i
  %shl.i.i = shl i32 %and5.i.i.i, %mul14.i.i
  %or.i.i = or i32 %shl.i.i, %active_rbs.1491.i.i
  %inc.i.i = add nuw i32 %j.0490.i.i, 1
  %cmp9.i.i = icmp ult i32 %inc.i.i, %376
  br i1 %cmp9.i.i, label %for.body10.i.i.for.body10.i.i_crit_edge, label %for.body10.i.i.for.inc15.i.i_crit_edge

for.body10.i.i.for.inc15.i.i_crit_edge:           ; preds = %for.body10.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc15.i.i

for.body10.i.i.for.body10.i.i_crit_edge:          ; preds = %for.body10.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body10.i.i

for.inc15.i.i:                                    ; preds = %for.body10.i.i.for.inc15.i.i_crit_edge, %for.cond5.preheader.i.i.for.inc15.i.i_crit_edge
  %active_rbs.1.lcssa.i.i = phi i32 [ %active_rbs.0493.i.i, %for.cond5.preheader.i.i.for.inc15.i.i_crit_edge ], [ %or.i.i, %for.body10.i.i.for.inc15.i.i_crit_edge ]
  %inc16.i.i = add nuw i32 %i.0494.i.i, 1
  %378 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %378)
  %379 = load i32, ptr %config.i.i, align 8
  %cmp.i.i = icmp ult i32 %inc16.i.i, %379
  br i1 %cmp.i.i, label %for.inc15.i.i.for.cond5.preheader.i.i_crit_edge, label %for.inc15.i.i.for.end17.i.i_crit_edge

for.inc15.i.i.for.end17.i.i_crit_edge:            ; preds = %for.inc15.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end17.i.i

for.inc15.i.i.for.cond5.preheader.i.i_crit_edge:  ; preds = %for.inc15.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond5.preheader.i.i

for.end17.i.i:                                    ; preds = %for.inc15.i.i.for.end17.i.i_crit_edge, %gfx_v8_0_tiling_mode_table_init.exit.i.for.end17.i.i_crit_edge
  %active_rbs.0.lcssa.i.i = phi i32 [ 0, %gfx_v8_0_tiling_mode_table_init.exit.i.for.end17.i.i_crit_edge ], [ %active_rbs.1.lcssa.i.i, %for.inc15.i.i.for.end17.i.i_crit_edge ]
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  %backend_enable_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 14
  %380 = ptrtoint ptr %backend_enable_mask.i.i to i32
  call void @__asan_store4_noabort(i32 %380)
  store i32 %active_rbs.0.lcssa.i.i, ptr %backend_enable_mask.i.i, align 8
  %call.i465.i.i = tail call i32 @__sw_hweight32(i32 noundef %active_rbs.0.lcssa.i.i) #12
  %num_rbs.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 24
  %381 = ptrtoint ptr %num_rbs.i.i to i32
  call void @__asan_store4_noabort(i32 %381)
  store i32 %call.i465.i.i, ptr %num_rbs.i.i, align 8
  %382 = ptrtoint ptr %max_backends_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %382)
  %383 = load i32, ptr %max_backends_per_se.i.i, align 8
  %384 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %384)
  %385 = load i32, ptr %config.i.i, align 8
  %mul309.i.i = mul i32 %385, %383
  %386 = tail call i32 @llvm.umin.i32(i32 %mul309.i.i, i32 16) #12
  %387 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %387)
  %388 = load i32, ptr %asic_type.i, align 8
  %switch.tableidx = add i32 %388, -10
  call void @__sanitizer_cov_trace_const_cmp4(i32 9, i32 %switch.tableidx)
  %389 = icmp ult i32 %switch.tableidx, 9
  br i1 %389, label %switch.lookup, label %sw.default.i.i.i

sw.default.i.i.i:                                 ; preds = %for.end17.i.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.77, i32 noundef %388) #12
  br label %gfx_v8_0_raster_config.exit.i.i

switch.lookup:                                    ; preds = %for.end17.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %switch.gep = getelementptr inbounds [9 x i32], ptr @switch.table.gfx_v8_0_hw_init, i32 0, i32 %switch.tableidx
  %390 = ptrtoint ptr %switch.gep to i32
  call void @__asan_load4_noabort(i32 %390)
  %switch.load = load i32, ptr %switch.gep, align 4
  %switch.gep46 = getelementptr inbounds [9 x i32], ptr @switch.table.gfx_v8_0_hw_init.100, i32 0, i32 %switch.tableidx
  %391 = ptrtoint ptr %switch.gep46 to i32
  call void @__asan_load4_noabort(i32 %391)
  %switch.load47 = load i32, ptr %switch.gep46, align 4
  br label %gfx_v8_0_raster_config.exit.i.i

gfx_v8_0_raster_config.exit.i.i:                  ; preds = %switch.lookup, %sw.default.i.i.i
  %raster_config.0.i.i = phi i32 [ 0, %sw.default.i.i.i ], [ %switch.load, %switch.lookup ]
  %raster_config_1.0.i.i = phi i32 [ 0, %sw.default.i.i.i ], [ %switch.load47, %switch.lookup ]
  %392 = ptrtoint ptr %backend_enable_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %392)
  %393 = load i32, ptr %backend_enable_mask.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %393)
  %tobool319.not.i.i = icmp eq i32 %393, 0
  br i1 %tobool319.not.i.i, label %gfx_v8_0_raster_config.exit.i.i.if.then.i98.i_crit_edge, label %lor.lhs.false.i.i

gfx_v8_0_raster_config.exit.i.i.if.then.i98.i_crit_edge: ; preds = %gfx_v8_0_raster_config.exit.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i98.i

lor.lhs.false.i.i:                                ; preds = %gfx_v8_0_raster_config.exit.i.i
  %394 = ptrtoint ptr %num_rbs.i.i to i32
  call void @__asan_load4_noabort(i32 %394)
  %395 = load i32, ptr %num_rbs.i.i, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %395, i32 %386)
  %cmp323.not.i.i = icmp ult i32 %395, %386
  br i1 %cmp323.not.i.i, label %if.else.i.i, label %lor.lhs.false.i.i.if.then.i98.i_crit_edge

lor.lhs.false.i.i.if.then.i98.i_crit_edge:        ; preds = %lor.lhs.false.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i98.i

if.then.i98.i:                                    ; preds = %lor.lhs.false.i.i.if.then.i98.i_crit_edge, %gfx_v8_0_raster_config.exit.i.i.if.then.i98.i_crit_edge
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 41172, i32 noundef %raster_config.0.i.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 41173, i32 noundef %raster_config_1.0.i.i, i32 noundef 0) #12
  br label %if.end.i.i

if.else.i.i:                                      ; preds = %lor.lhs.false.i.i
  %396 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %396)
  %397 = load i32, ptr %max_sh_per_se.i.i, align 4
  %398 = tail call i32 @llvm.umax.i32(i32 %397, i32 1) #12
  %399 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %399)
  %400 = load i32, ptr %config.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %400)
  %cmp4.i.i.i = icmp ugt i32 %400, 1
  %401 = tail call i32 @llvm.umax.i32(i32 %400, i32 1) #12
  %div.i468.i.i = udiv i32 %386, %401
  %div9.i.i.i = udiv i32 %div.i468.i.i, %398
  %402 = tail call i32 @llvm.umin.i32(i32 %div9.i.i.i, i32 2) #12
  call void @llvm.lifetime.start.p0(i64 16, ptr nonnull %se_mask.i.i.i) #12
  %403 = getelementptr inbounds [4 x i32], ptr %se_mask.i.i.i, i32 0, i32 1
  %404 = getelementptr inbounds [4 x i32], ptr %se_mask.i.i.i, i32 0, i32 2
  %405 = getelementptr inbounds [4 x i32], ptr %se_mask.i.i.i, i32 0, i32 3
  %notmask.i.i.i = shl nsw i32 -1, %div.i468.i.i
  %sub.i.i.i = xor i32 %notmask.i.i.i, -1
  %and.i469.i.i = and i32 %393, %sub.i.i.i
  %406 = ptrtoint ptr %se_mask.i.i.i to i32
  call void @__asan_store4_noabort(i32 %406)
  store i32 %and.i469.i.i, ptr %se_mask.i.i.i, align 4
  %shl18.i.i.i = shl i32 %and.i469.i.i, %div.i468.i.i
  %and19.i.i.i = and i32 %shl18.i.i.i, %393
  %407 = ptrtoint ptr %403 to i32
  call void @__asan_store4_noabort(i32 %407)
  store i32 %and19.i.i.i, ptr %403, align 4
  %shl22.i.i.i = shl i32 %and19.i.i.i, %div.i468.i.i
  %and23.i.i.i = and i32 %shl22.i.i.i, %393
  %408 = ptrtoint ptr %404 to i32
  call void @__asan_store4_noabort(i32 %408)
  store i32 %and23.i.i.i, ptr %404, align 4
  %shl26.i.i.i = shl i32 %and23.i.i.i, %div.i468.i.i
  %and27.i.i.i = and i32 %shl26.i.i.i, %393
  %409 = ptrtoint ptr %405 to i32
  call void @__asan_store4_noabort(i32 %409)
  store i32 %and27.i.i.i, ptr %405, align 4
  %410 = zext i32 %401 to i64
  call void @__sanitizer_cov_trace_switch(i64 %410, ptr @__sancov_gen_cov_switch_values.107)
  switch i32 %401, label %do.end.critedge.i.i.i [
    i32 1, label %if.else.i.i.if.end.i.i.i_crit_edge
    i32 2, label %if.else.i.i.if.end.i.i.i_crit_edge66
    i32 4, label %if.else.i.i.if.end.i.i.i_crit_edge67
  ]

if.else.i.i.if.end.i.i.i_crit_edge67:             ; preds = %if.else.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i.i.i

if.else.i.i.if.end.i.i.i_crit_edge66:             ; preds = %if.else.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i.i.i

if.else.i.i.if.end.i.i.i_crit_edge:               ; preds = %if.else.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i.i.i

do.end.critedge.i.i.i:                            ; preds = %if.else.i.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.10, i32 noundef 3541, i32 noundef 9, ptr noundef null) #12
  br label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %do.end.critedge.i.i.i, %if.else.i.i.if.end.i.i.i_crit_edge, %if.else.i.i.if.end.i.i.i_crit_edge66, %if.else.i.i.if.end.i.i.i_crit_edge67
  %..off.i.i.i = add i32 %398, -1
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %..off.i.i.i)
  %switch.i.i.i = icmp ult i32 %..off.i.i.i, 2
  br i1 %switch.i.i.i, label %if.end.i.i.i.if.end80.i.i.i_crit_edge, label %do.end74.i.i.i

if.end.i.i.i.if.end80.i.i.i_crit_edge:            ; preds = %if.end.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end80.i.i.i

do.end74.i.i.i:                                   ; preds = %if.end.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.10, i32 noundef 3542, i32 noundef 9, ptr noundef null) #12
  br label %if.end80.i.i.i

if.end80.i.i.i:                                   ; preds = %do.end74.i.i.i, %if.end.i.i.i.if.end80.i.i.i_crit_edge
  %cond15.off.i.i.i = add nsw i32 %402, -1
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %cond15.off.i.i.i)
  %switch317.i.i.i = icmp ult i32 %cond15.off.i.i.i, 2
  br i1 %switch317.i.i.i, label %if.end80.i.i.i.if.end116.i.i.i_crit_edge, label %do.end110.i.i.i

if.end80.i.i.i.if.end116.i.i.i_crit_edge:         ; preds = %if.end80.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end116.i.i.i

do.end110.i.i.i:                                  ; preds = %if.end80.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.10, i32 noundef 3543, i32 noundef 9, ptr noundef null) #12
  br label %if.end116.i.i.i

if.end116.i.i.i:                                  ; preds = %do.end110.i.i.i, %if.end80.i.i.i.if.end116.i.i.i_crit_edge
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %401)
  %cmp124.i.i.i = icmp ugt i32 %401, 2
  br i1 %cmp124.i.i.i, label %land.lhs.true.i.i.i, label %if.end116.i.i.i.if.end146.i.i.i_crit_edge

if.end116.i.i.i.if.end146.i.i.i_crit_edge:        ; preds = %if.end116.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end146.i.i.i

land.lhs.true.i.i.i:                              ; preds = %if.end116.i.i.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i469.i.i)
  %tobool126.not.i.i.i = icmp eq i32 %and.i469.i.i, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and19.i.i.i)
  %tobool129.not.i.i.i = icmp eq i32 %and19.i.i.i, 0
  %or.cond323.i.i.i = select i1 %tobool126.not.i.i.i, i1 %tobool129.not.i.i.i, i1 false
  br i1 %or.cond323.i.i.i, label %if.then136.thread.i.i.i, label %lor.lhs.false130.i.i.i

if.then136.thread.i.i.i:                          ; preds = %land.lhs.true.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %and137318.i.i.i = and i32 %raster_config_1.0.i.i, 44
  br label %land.lhs.true140.i.i.i

lor.lhs.false130.i.i.i:                           ; preds = %land.lhs.true.i.i.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and23.i.i.i)
  %tobool132.not.i.i.i = icmp eq i32 %and23.i.i.i, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and27.i.i.i)
  %tobool135.not.i.i.i = icmp eq i32 %and27.i.i.i, 0
  %or.cond324.i.i.i = select i1 %tobool132.not.i.i.i, i1 %tobool135.not.i.i.i, i1 false
  br i1 %or.cond324.i.i.i, label %if.then136.i.i.i, label %lor.lhs.false130.i.i.i.if.end146.i.i.i_crit_edge

lor.lhs.false130.i.i.i.if.end146.i.i.i_crit_edge: ; preds = %lor.lhs.false130.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end146.i.i.i

if.then136.i.i.i:                                 ; preds = %lor.lhs.false130.i.i.i
  %and137.i.i.i = and i32 %raster_config_1.0.i.i, 44
  br i1 %tobool126.not.i.i.i, label %if.then136.i.i.i.land.lhs.true140.i.i.i_crit_edge, label %if.then136.i.i.i.if.end146.i.i.i_crit_edge

if.then136.i.i.i.if.end146.i.i.i_crit_edge:       ; preds = %if.then136.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end146.i.i.i

if.then136.i.i.i.land.lhs.true140.i.i.i_crit_edge: ; preds = %if.then136.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %land.lhs.true140.i.i.i

land.lhs.true140.i.i.i:                           ; preds = %if.then136.i.i.i.land.lhs.true140.i.i.i_crit_edge, %if.then136.thread.i.i.i
  %and137319.i.i.i = phi i32 [ %and137318.i.i.i, %if.then136.thread.i.i.i ], [ %and137.i.i.i, %if.then136.i.i.i.land.lhs.true140.i.i.i_crit_edge ]
  %or.i470.i.i = or i32 %raster_config_1.0.i.i, 3
  %spec.select.i.i.i = select i1 %tobool129.not.i.i.i, i32 %or.i470.i.i, i32 %and137319.i.i.i
  br label %if.end146.i.i.i

if.end146.i.i.i:                                  ; preds = %land.lhs.true140.i.i.i, %if.then136.i.i.i.if.end146.i.i.i_crit_edge, %lor.lhs.false130.i.i.i.if.end146.i.i.i_crit_edge, %if.end116.i.i.i.if.end146.i.i.i_crit_edge
  %raster_config_1.addr.0.i.i.i = phi i32 [ %raster_config_1.0.i.i, %lor.lhs.false130.i.i.i.if.end146.i.i.i_crit_edge ], [ %raster_config_1.0.i.i, %if.end116.i.i.i.if.end146.i.i.i_crit_edge ], [ %and137.i.i.i, %if.then136.i.i.i.if.end146.i.i.i_crit_edge ], [ %spec.select.i.i.i, %land.lhs.true140.i.i.i ]
  %notmask312.i.i.i = shl nsw i32 -1, %402
  %sub149.i.i.i = xor i32 %notmask312.i.i.i, -1
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %div.i468.i.i)
  %cmp173.i.i.i = icmp ugt i32 %div.i468.i.i, 2
  %and162.i.i.i = and i32 %raster_config.0.i.i, 1006638618
  %or166.i.i.i = or i32 %raster_config.0.i.i, 50331648
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %div.i468.i.i)
  %cmp187.i.i.i = icmp eq i32 %div.i468.i.i, 2
  br label %for.body.i.i.i

for.body.i.i.i:                                   ; preds = %if.end227.i.i.i.for.body.i.i.i_crit_edge, %if.end146.i.i.i
  %se.0326.i.i.i = phi i32 [ 0, %if.end146.i.i.i ], [ %inc.i.i.i, %if.end227.i.i.i.for.body.i.i.i_crit_edge ]
  %mul.i.i.i = mul i32 %se.0326.i.i.i, %div.i468.i.i
  %shl150.i.i.i = shl i32 %sub149.i.i.i, %mul.i.i.i
  %shl151.i.i.i = shl i32 %shl150.i.i.i, %402
  br i1 %cmp4.i.i.i, label %land.lhs.true155.i.i.i, label %for.body.i.i.i.if.end170.i.i.i_crit_edge

for.body.i.i.i.if.end170.i.i.i_crit_edge:         ; preds = %for.body.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end170.i.i.i

land.lhs.true155.i.i.i:                           ; preds = %for.body.i.i.i
  %div152313.i.i.i = and i32 %se.0326.i.i.i, -2
  %arrayidx156.i.i.i = getelementptr [4 x i32], ptr %se_mask.i.i.i, i32 0, i32 %div152313.i.i.i
  %411 = ptrtoint ptr %arrayidx156.i.i.i to i32
  call void @__asan_load4_noabort(i32 %411)
  %412 = load i32, ptr %arrayidx156.i.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %412)
  %tobool157.not.i.i.i = icmp eq i32 %412, 0
  br i1 %tobool157.not.i.i.i, label %land.lhs.true155.i.i.i.if.end170.i.i.i_crit_edge, label %lor.lhs.false158.i.i.i

land.lhs.true155.i.i.i.if.end170.i.i.i_crit_edge: ; preds = %land.lhs.true155.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end170.i.i.i

lor.lhs.false158.i.i.i:                           ; preds = %land.lhs.true155.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add.i.i.i = or i32 %se.0326.i.i.i, 1
  %arrayidx159.i.i.i = getelementptr [4 x i32], ptr %se_mask.i.i.i, i32 0, i32 %add.i.i.i
  %413 = ptrtoint ptr %arrayidx159.i.i.i to i32
  call void @__asan_load4_noabort(i32 %413)
  %414 = load i32, ptr %arrayidx159.i.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %414)
  %tobool160.not.i.i.i = icmp eq i32 %414, 0
  %spec.select325.i.i.i = select i1 %tobool160.not.i.i.i, i32 %and162.i.i.i, i32 %raster_config.0.i.i
  br label %if.end170.i.i.i

if.end170.i.i.i:                                  ; preds = %lor.lhs.false158.i.i.i, %land.lhs.true155.i.i.i.if.end170.i.i.i_crit_edge, %for.body.i.i.i.if.end170.i.i.i_crit_edge
  %raster_config_se.0.i.i.i = phi i32 [ %raster_config.0.i.i, %for.body.i.i.i.if.end170.i.i.i_crit_edge ], [ %spec.select325.i.i.i, %lor.lhs.false158.i.i.i ], [ %or166.i.i.i, %land.lhs.true155.i.i.i.if.end170.i.i.i_crit_edge ]
  br i1 %cmp173.i.i.i, label %land.lhs.true174.i.i.i, label %if.end186.i.i.i

land.lhs.true174.i.i.i:                           ; preds = %if.end170.i.i.i
  %and172.i.i.i = and i32 %shl151.i.i.i, %393
  %and171.i.i.i = and i32 %shl150.i.i.i, %393
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and171.i.i.i)
  %tobool175.not.i.i.i = icmp eq i32 %and171.i.i.i, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and172.i.i.i)
  %tobool177.not.i.i.i = icmp eq i32 %and172.i.i.i, 0
  %or.cond.i.i.i = select i1 %tobool175.not.i.i.i, i1 true, i1 %tobool177.not.i.i.i
  br i1 %or.cond.i.i.i, label %if.then178.i.i.i, label %land.lhs.true174.i.i.i.if.then188.i.i.i_crit_edge

land.lhs.true174.i.i.i.if.then188.i.i.i_crit_edge: ; preds = %land.lhs.true174.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then188.i.i.i

if.then178.i.i.i:                                 ; preds = %land.lhs.true174.i.i.i
  br i1 %tobool175.not.i.i.i, label %if.then181.i.i.i, label %if.else183.i.i.i

if.then181.i.i.i:                                 ; preds = %if.then178.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %or182.i.i.i = or i32 %raster_config_se.0.i.i.i, 768
  br label %if.then188.i.i.i

if.else183.i.i.i:                                 ; preds = %if.then178.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %and179.i.i.i = and i32 %raster_config_se.0.i.i.i, -769
  br label %if.then188.i.i.i

if.end186.i.i.i:                                  ; preds = %if.end170.i.i.i
  br i1 %cmp187.i.i.i, label %if.end186.i.i.i.if.then188.i.i.i_crit_edge, label %if.end186.i.i.i.if.end227.i.i.i_crit_edge

if.end186.i.i.i.if.end227.i.i.i_crit_edge:        ; preds = %if.end186.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end227.i.i.i

if.end186.i.i.i.if.then188.i.i.i_crit_edge:       ; preds = %if.end186.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then188.i.i.i

if.then188.i.i.i:                                 ; preds = %if.end186.i.i.i.if.then188.i.i.i_crit_edge, %if.else183.i.i.i, %if.then181.i.i.i, %land.lhs.true174.i.i.i.if.then188.i.i.i_crit_edge
  %raster_config_se.1322.i.i.i = phi i32 [ %raster_config_se.0.i.i.i, %if.end186.i.i.i.if.then188.i.i.i_crit_edge ], [ %raster_config_se.0.i.i.i, %land.lhs.true174.i.i.i.if.then188.i.i.i_crit_edge ], [ %or182.i.i.i, %if.then181.i.i.i ], [ %and179.i.i.i, %if.else183.i.i.i ]
  %shl190.i.i.i = shl nuw i32 1, %mul.i.i.i
  %and192.i.i.i = and i32 %shl190.i.i.i, %393
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and192.i.i.i)
  %tobool194.not.i.i.i = icmp eq i32 %and192.i.i.i, 0
  %shl191.i.i.i = shl i32 %shl190.i.i.i, 1
  %and193.i.i.i = and i32 %shl191.i.i.i, %393
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and193.i.i.i)
  %tobool196.not.i.i.i = icmp eq i32 %and193.i.i.i, 0
  %or.cond315.i.i.i = select i1 %tobool194.not.i.i.i, i1 true, i1 %tobool196.not.i.i.i
  br i1 %or.cond315.i.i.i, label %if.then197.i.i.i, label %if.then188.i.i.i.if.end205.i.i.i_crit_edge

if.then188.i.i.i.if.end205.i.i.i_crit_edge:       ; preds = %if.then188.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end205.i.i.i

if.then197.i.i.i:                                 ; preds = %if.then188.i.i.i
  br i1 %tobool194.not.i.i.i, label %if.then200.i.i.i, label %if.else202.i.i.i

if.then200.i.i.i:                                 ; preds = %if.then197.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %or201.i.i.i = or i32 %raster_config_se.1322.i.i.i, 3
  br label %if.end205.i.i.i

if.else202.i.i.i:                                 ; preds = %if.then197.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %and198.i.i.i = and i32 %raster_config_se.1322.i.i.i, -4
  br label %if.end205.i.i.i

if.end205.i.i.i:                                  ; preds = %if.else202.i.i.i, %if.then200.i.i.i, %if.then188.i.i.i.if.end205.i.i.i_crit_edge
  %raster_config_se.2.i.i.i = phi i32 [ %and198.i.i.i, %if.else202.i.i.i ], [ %or201.i.i.i, %if.then200.i.i.i ], [ %raster_config_se.1322.i.i.i, %if.then188.i.i.i.if.end205.i.i.i_crit_edge ]
  br i1 %cmp173.i.i.i, label %if.then207.i.i.i, label %if.end205.i.i.i.if.end227.i.i.i_crit_edge

if.end205.i.i.i.if.end227.i.i.i_crit_edge:        ; preds = %if.end205.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end227.i.i.i

if.then207.i.i.i:                                 ; preds = %if.end205.i.i.i
  %add209.i.i.i = add i32 %mul.i.i.i, %402
  %shl210.i.i.i = shl nuw i32 1, %add209.i.i.i
  %and212.i.i.i = and i32 %shl210.i.i.i, %393
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and212.i.i.i)
  %tobool214.not.i.i.i = icmp eq i32 %and212.i.i.i, 0
  %shl211.i.i.i = shl i32 %shl210.i.i.i, 1
  %and213.i.i.i = and i32 %shl211.i.i.i, %393
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and213.i.i.i)
  %tobool216.not.i.i.i = icmp eq i32 %and213.i.i.i, 0
  %or.cond316.i.i.i = select i1 %tobool214.not.i.i.i, i1 true, i1 %tobool216.not.i.i.i
  br i1 %or.cond316.i.i.i, label %if.then217.i.i.i, label %if.then207.i.i.i.if.end227.i.i.i_crit_edge

if.then207.i.i.i.if.end227.i.i.i_crit_edge:       ; preds = %if.then207.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end227.i.i.i

if.then217.i.i.i:                                 ; preds = %if.then207.i.i.i
  br i1 %tobool214.not.i.i.i, label %if.then220.i.i.i, label %if.else222.i.i.i

if.then220.i.i.i:                                 ; preds = %if.then217.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %or221.i.i.i = or i32 %raster_config_se.2.i.i.i, 12
  br label %if.end227.i.i.i

if.else222.i.i.i:                                 ; preds = %if.then217.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %and218.i.i.i = and i32 %raster_config_se.2.i.i.i, -13
  br label %if.end227.i.i.i

if.end227.i.i.i:                                  ; preds = %if.else222.i.i.i, %if.then220.i.i.i, %if.then207.i.i.i.if.end227.i.i.i_crit_edge, %if.end205.i.i.i.if.end227.i.i.i_crit_edge, %if.end186.i.i.i.if.end227.i.i.i_crit_edge
  %raster_config_se.4.i.i.i = phi i32 [ %raster_config_se.0.i.i.i, %if.end186.i.i.i.if.end227.i.i.i_crit_edge ], [ %and218.i.i.i, %if.else222.i.i.i ], [ %or221.i.i.i, %if.then220.i.i.i ], [ %raster_config_se.2.i.i.i, %if.end205.i.i.i.if.end227.i.i.i_crit_edge ], [ %raster_config_se.2.i.i.i, %if.then207.i.i.i.if.end227.i.i.i_crit_edge ]
  %shl7.i.i.i.i = shl i32 %se.0326.i.i.i, 16
  %and8.i.i.i.i = and i32 %shl7.i.i.i.i, 16711680
  %and8.i.op.op.i.i.i = or i32 %and8.i.i.i.i, 1610612736
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef %and8.i.op.op.i.i.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 41172, i32 noundef %raster_config_se.4.i.i.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 41173, i32 noundef %raster_config_1.addr.0.i.i.i, i32 noundef 0) #12
  %inc.i.i.i = add nuw i32 %se.0326.i.i.i, 1
  %exitcond.not.i.i.i = icmp eq i32 %inc.i.i.i, %401
  br i1 %exitcond.not.i.i.i, label %gfx_v8_0_write_harvested_raster_configs.exit.i.i, label %if.end227.i.i.i.for.body.i.i.i_crit_edge

if.end227.i.i.i.for.body.i.i.i_crit_edge:         ; preds = %if.end227.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i.i.i

gfx_v8_0_write_harvested_raster_configs.exit.i.i: ; preds = %if.end227.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  call void @llvm.lifetime.end.p0(i64 16, ptr nonnull %se_mask.i.i.i) #12
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %gfx_v8_0_write_harvested_raster_configs.exit.i.i, %if.then.i98.i
  %415 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %415)
  %416 = load i32, ptr %config.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %416)
  %cmp332499.not.i.i = icmp eq i32 %416, 0
  br i1 %cmp332499.not.i.i, label %if.end.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge, label %if.end.i.i.for.cond335.preheader.i.i_crit_edge

if.end.i.i.for.cond335.preheader.i.i_crit_edge:   ; preds = %if.end.i.i
  br label %for.cond335.preheader.i.i

if.end.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge:    ; preds = %if.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_setup_rb.exit.i

for.cond335.preheader.i.i:                        ; preds = %for.inc369.i.i.for.cond335.preheader.i.i_crit_edge, %if.end.i.i.for.cond335.preheader.i.i_crit_edge
  %i.1500.i.i = phi i32 [ %inc370.i.i, %for.inc369.i.i.for.cond335.preheader.i.i_crit_edge ], [ 0, %if.end.i.i.for.cond335.preheader.i.i_crit_edge ]
  %417 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %417)
  %418 = load i32, ptr %max_sh_per_se.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %418)
  %cmp339497.not.i.i = icmp eq i32 %418, 0
  br i1 %cmp339497.not.i.i, label %for.cond335.preheader.i.i.for.inc369.i.i_crit_edge, label %for.body341.lr.ph.i.i

for.cond335.preheader.i.i.for.inc369.i.i_crit_edge: ; preds = %for.cond335.preheader.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc369.i.i

for.body341.lr.ph.i.i:                            ; preds = %for.cond335.preheader.i.i
  %shl7.i472.i.i = shl i32 %i.1500.i.i, 16
  %and8.i473.i.i = and i32 %shl7.i472.i.i, 16711680
  br label %for.body341.i.i

for.body341.i.i:                                  ; preds = %for.body341.i.i.for.body341.i.i_crit_edge, %for.body341.lr.ph.i.i
  %j.1498.i.i = phi i32 [ 0, %for.body341.lr.ph.i.i ], [ %inc367.i.i, %for.body341.i.i.for.body341.i.i_crit_edge ]
  %shl17.i477.i.i = shl i32 %j.1498.i.i, 8
  %and18.i478.i.i = and i32 %shl17.i477.i.i, 65280
  %and8.i473.op.i.i = or i32 %and8.i473.i.i, %and18.i478.i.i
  %data.2.i480.i.i = or i32 %and8.i473.op.i.i, 1073741824
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef %data.2.i480.i.i, i32 noundef 0) #12
  %call342.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 9789, i32 noundef 0) #12
  %arrayidx345.i99.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 30, i32 %i.1500.i.i, i32 %j.1498.i.i
  %419 = ptrtoint ptr %arrayidx345.i99.i to i32
  call void @__asan_store4_noabort(i32 %419)
  store i32 %call342.i.i, ptr %arrayidx345.i99.i, align 4
  %call346.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 9951, i32 noundef 0) #12
  %user_rb_backend_disable.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 30, i32 %i.1500.i.i, i32 %j.1498.i.i, i32 1
  %420 = ptrtoint ptr %user_rb_backend_disable.i.i to i32
  call void @__asan_store4_noabort(i32 %420)
  store i32 %call346.i.i, ptr %user_rb_backend_disable.i.i, align 4
  %call352.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 41172, i32 noundef 0) #12
  %raster_config358.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 30, i32 %i.1500.i.i, i32 %j.1498.i.i, i32 2
  %421 = ptrtoint ptr %raster_config358.i.i to i32
  call void @__asan_store4_noabort(i32 %421)
  store i32 %call352.i.i, ptr %raster_config358.i.i, align 4
  %call359.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 41173, i32 noundef 0) #12
  %raster_config_1365.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 30, i32 %i.1500.i.i, i32 %j.1498.i.i, i32 3
  %422 = ptrtoint ptr %raster_config_1365.i.i to i32
  call void @__asan_store4_noabort(i32 %422)
  store i32 %call359.i.i, ptr %raster_config_1365.i.i, align 4
  %inc367.i.i = add nuw i32 %j.1498.i.i, 1
  %423 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %423)
  %424 = load i32, ptr %max_sh_per_se.i.i, align 4
  %cmp339.i.i = icmp ult i32 %inc367.i.i, %424
  br i1 %cmp339.i.i, label %for.body341.i.i.for.body341.i.i_crit_edge, label %for.body341.i.i.for.inc369.i.i_crit_edge

for.body341.i.i.for.inc369.i.i_crit_edge:         ; preds = %for.body341.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc369.i.i

for.body341.i.i.for.body341.i.i_crit_edge:        ; preds = %for.body341.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body341.i.i

for.inc369.i.i:                                   ; preds = %for.body341.i.i.for.inc369.i.i_crit_edge, %for.cond335.preheader.i.i.for.inc369.i.i_crit_edge
  %inc370.i.i = add nuw i32 %i.1500.i.i, 1
  %425 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %425)
  %426 = load i32, ptr %config.i.i, align 8
  %cmp332.i.i = icmp ult i32 %inc370.i.i, %426
  br i1 %cmp332.i.i, label %for.inc369.i.i.for.cond335.preheader.i.i_crit_edge, label %for.inc369.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge

for.inc369.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge: ; preds = %for.inc369.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_setup_rb.exit.i

for.inc369.i.i.for.cond335.preheader.i.i_crit_edge: ; preds = %for.inc369.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond335.preheader.i.i

gfx_v8_0_setup_rb.exit.i:                         ; preds = %for.inc369.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge, %if.end.i.i.gfx_v8_0_setup_rb.exit.i_crit_edge
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %grbm_idx_mutex.i.i) #12
  %cu_info1.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48
  call void @llvm.lifetime.start.p0(i64 32, ptr nonnull %disable_masks.i.i) #12
  %427 = call ptr @memset(ptr %disable_masks.i.i, i32 255, i32 32)
  %428 = call ptr @memset(ptr %cu_info1.i.i, i32 0, i32 156)
  %flags.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 9
  %429 = ptrtoint ptr %flags.i.i to i32
  call void @__asan_load4_noabort(i32 %429)
  %430 = load i32, ptr %flags.i.i, align 8
  %and.i100.i = and i32 %430, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i100.i)
  %tobool.not.i.i = icmp eq i32 %and.i100.i, 0
  br i1 %tobool.not.i.i, label %if.else.i101.i, label %gfx_v8_0_setup_rb.exit.i.if.end.i103.i_crit_edge

gfx_v8_0_setup_rb.exit.i.if.end.i103.i_crit_edge: ; preds = %gfx_v8_0_setup_rb.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i103.i

if.else.i101.i:                                   ; preds = %gfx_v8_0_setup_rb.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  %max_cu_per_sh.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 2
  %431 = ptrtoint ptr %max_cu_per_sh.i.i to i32
  call void @__asan_load4_noabort(i32 %431)
  %432 = load i32, ptr %max_cu_per_sh.i.i, align 8
  br label %if.end.i103.i

if.end.i103.i:                                    ; preds = %if.else.i101.i, %gfx_v8_0_setup_rb.exit.i.if.end.i103.i_crit_edge
  %ao_cu_num.0.i.i = phi i32 [ %432, %if.else.i101.i ], [ 2, %gfx_v8_0_setup_rb.exit.i.if.end.i103.i_crit_edge ]
  call void @amdgpu_gfx_parse_disable_cu(ptr noundef nonnull %disable_masks.i.i, i32 noundef 4, i32 noundef 2) #12
  call void @mutex_lock_nested(ptr noundef %grbm_idx_mutex.i.i, i32 noundef 0) #12
  %433 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %433)
  %434 = load i32, ptr %config.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %434)
  %cmp111.not.i.i = icmp eq i32 %434, 0
  br i1 %cmp111.not.i.i, label %if.end.i103.i.gfx_v8_0_get_cu_info.exit.i_crit_edge, label %for.cond5.preheader.lr.ph.i.i

if.end.i103.i.gfx_v8_0_get_cu_info.exit.i_crit_edge: ; preds = %if.end.i103.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_get_cu_info.exit.i

for.cond5.preheader.lr.ph.i.i:                    ; preds = %if.end.i103.i
  %max_cu_per_sh.i.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 2
  br label %for.cond5.preheader.i105.i

for.cond5.preheader.i105.i:                       ; preds = %for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge, %for.cond5.preheader.lr.ph.i.i
  %ao_cu_mask.0115.i.i = phi i32 [ 0, %for.cond5.preheader.lr.ph.i.i ], [ %ao_cu_mask.1.lcssa.i.i, %for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge ]
  %active_cu_number.0114.i.i = phi i32 [ 0, %for.cond5.preheader.lr.ph.i.i ], [ %active_cu_number.1.lcssa.i.i, %for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge ]
  %i.0112.i.i = phi i32 [ 0, %for.cond5.preheader.lr.ph.i.i ], [ %inc48.i.i, %for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge ]
  %435 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %435)
  %436 = load i32, ptr %max_sh_per_se.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %436)
  %cmp8105.not.i.i = icmp eq i32 %436, 0
  br i1 %cmp8105.not.i.i, label %for.cond5.preheader.i105.i.for.inc47.i.i_crit_edge, label %for.body9.lr.ph.i.i

for.cond5.preheader.i105.i.for.inc47.i.i_crit_edge: ; preds = %for.cond5.preheader.i105.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc47.i.i

for.body9.lr.ph.i.i:                              ; preds = %for.cond5.preheader.i105.i
  %shl7.i.i106.i = shl i32 %i.0112.i.i, 16
  %and8.i.i107.i = and i32 %shl7.i.i106.i, 16711680
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %i.0112.i.i)
  %cmp10.i.i = icmp slt i32 %i.0112.i.i, 4
  %mul.i109.i = shl i32 %i.0112.i.i, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %i.0112.i.i)
  %cmp32.i.i = icmp slt i32 %i.0112.i.i, 2
  %mul36.i.i = shl i32 %i.0112.i.i, 4
  br label %for.body9.i.i

for.body9.i.i:                                    ; preds = %for.end.i.i.for.body9.i.i_crit_edge, %for.body9.lr.ph.i.i
  %ao_cu_mask.1108.i.i = phi i32 [ %ao_cu_mask.0115.i.i, %for.body9.lr.ph.i.i ], [ %ao_cu_mask.2.i.i, %for.end.i.i.for.body9.i.i_crit_edge ]
  %active_cu_number.1107.i.i = phi i32 [ %active_cu_number.0114.i.i, %for.body9.lr.ph.i.i ], [ %add31.i.i, %for.end.i.i.for.body9.i.i_crit_edge ]
  %j.0106.i.i = phi i32 [ 0, %for.body9.lr.ph.i.i ], [ %inc45.i.i, %for.end.i.i.for.body9.i.i_crit_edge ]
  %shl17.i.i110.i = shl i32 %j.0106.i.i, 8
  %and18.i.i111.i = and i32 %shl17.i.i110.i, 65280
  %and8.i.op.i108.i = or i32 %and8.i.i107.i, %and18.i.i111.i
  %data.2.i.i112.i = or i32 %and8.i.op.i108.i, 1073741824
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef %data.2.i.i112.i, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %j.0106.i.i)
  %cmp11.i.i = icmp slt i32 %j.0106.i.i, 2
  %or.cond.i.i = select i1 %cmp10.i.i, i1 %cmp11.i.i, i1 false
  br i1 %or.cond.i.i, label %if.then12.i.i, label %for.body9.i.i.if.end13.i.i_crit_edge

for.body9.i.i.if.end13.i.i_crit_edge:             ; preds = %for.body9.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end13.i.i

if.then12.i.i:                                    ; preds = %for.body9.i.i
  %add.i113.i = add i32 %j.0106.i.i, %mul.i109.i
  %arrayidx.i.i = getelementptr [8 x i32], ptr %disable_masks.i.i, i32 0, i32 %add.i113.i
  %437 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %437)
  %438 = load i32, ptr %arrayidx.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %438)
  %tobool.not.i.i.i = icmp eq i32 %438, 0
  br i1 %tobool.not.i.i.i, label %if.then12.i.i.if.end13.i.i_crit_edge, label %if.end.i.i114.i

if.then12.i.i.if.end13.i.i_crit_edge:             ; preds = %if.then12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end13.i.i

if.end.i.i114.i:                                  ; preds = %if.then12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %shl.i.i.i = shl i32 %438, 16
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8816, i32 noundef %shl.i.i.i, i32 noundef 0) #12
  br label %if.end13.i.i

if.end13.i.i:                                     ; preds = %if.end.i.i114.i, %if.then12.i.i.if.end13.i.i_crit_edge, %for.body9.i.i.if.end13.i.i_crit_edge
  %call.i.i115.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8815, i32 noundef 0) #12
  %call1.i.i116.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8816, i32 noundef 0) #12
  %or.i.i117.i = or i32 %call1.i.i116.i, %call.i.i115.i
  %439 = ptrtoint ptr %max_cu_per_sh.i.i.i to i32
  call void @__asan_load4_noabort(i32 %439)
  %440 = load i32, ptr %max_cu_per_sh.i.i.i, align 8
  %sh_prom.i.i.i118.i = zext i32 %440 to i64
  %notmask.i.i.i119.i = shl nsw i64 -1, %sh_prom.i.i.i118.i
  %441 = trunc i64 %notmask.i.i.i119.i to i32
  %shr.i.i120.i = lshr i32 %or.i.i117.i, 16
  %and3.demorgan.i.i.i = or i32 %shr.i.i120.i, %441
  %and3.i.i.i = xor i32 %and3.demorgan.i.i.i, -1
  %arrayidx16.i121.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 8, i32 %i.0112.i.i, i32 %j.0106.i.i
  %442 = ptrtoint ptr %arrayidx16.i121.i to i32
  call void @__asan_store4_noabort(i32 %442)
  store i32 %and3.i.i.i, ptr %arrayidx16.i121.i, align 4
  %443 = load i32, ptr %max_cu_per_sh.i.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %443)
  %cmp2199.not.i.i = icmp eq i32 %443, 0
  br i1 %cmp2199.not.i.i, label %if.end13.i.i.for.end.i.i_crit_edge, label %if.end13.i.i.for.body22.i.i_crit_edge

if.end13.i.i.for.body22.i.i_crit_edge:            ; preds = %if.end13.i.i
  br label %for.body22.i.i

if.end13.i.i.for.end.i.i_crit_edge:               ; preds = %if.end13.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i.i

for.body22.i.i:                                   ; preds = %for.body22.i.i.for.body22.i.i_crit_edge, %if.end13.i.i.for.body22.i.i_crit_edge
  %ao_bitmap.0103.i.i = phi i32 [ %ao_bitmap.2.i.i, %for.body22.i.i.for.body22.i.i_crit_edge ], [ 0, %if.end13.i.i.for.body22.i.i_crit_edge ]
  %mask.0102.i.i = phi i32 [ %shl.i124.i, %for.body22.i.i.for.body22.i.i_crit_edge ], [ 1, %if.end13.i.i.for.body22.i.i_crit_edge ]
  %counter.0101.i.i = phi i32 [ %counter.1.i.i, %for.body22.i.i.for.body22.i.i_crit_edge ], [ 0, %if.end13.i.i.for.body22.i.i_crit_edge ]
  %k.0100.i.i = phi i32 [ %inc30.i.i, %for.body22.i.i.for.body22.i.i_crit_edge ], [ 0, %if.end13.i.i.for.body22.i.i_crit_edge ]
  %and23.i.i = and i32 %mask.0102.i.i, %and3.i.i.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and23.i.i)
  %tobool24.not.i.i = icmp eq i32 %and23.i.i, 0
  call void @__sanitizer_cov_trace_cmp4(i32 %counter.0101.i.i, i32 %ao_cu_num.0.i.i)
  %cmp26.i.i = icmp ult i32 %counter.0101.i.i, %ao_cu_num.0.i.i
  %or.i122.i = select i1 %cmp26.i.i, i32 %mask.0102.i.i, i32 0
  %not.tobool24.not.i.i = xor i1 %tobool24.not.i.i, true
  %inc.i123.i = zext i1 %not.tobool24.not.i.i to i32
  %counter.1.i.i = add i32 %counter.0101.i.i, %inc.i123.i
  %spec.select.i.i = select i1 %tobool24.not.i.i, i32 0, i32 %or.i122.i
  %ao_bitmap.2.i.i = or i32 %spec.select.i.i, %ao_bitmap.0103.i.i
  %shl.i124.i = shl i32 %mask.0102.i.i, 1
  %inc30.i.i = add nuw i32 %k.0100.i.i, 1
  %exitcond.not.i125.i = icmp eq i32 %inc30.i.i, %443
  br i1 %exitcond.not.i125.i, label %for.body22.i.i.for.end.i.i_crit_edge, label %for.body22.i.i.for.body22.i.i_crit_edge

for.body22.i.i.for.body22.i.i_crit_edge:          ; preds = %for.body22.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body22.i.i

for.body22.i.i.for.end.i.i_crit_edge:             ; preds = %for.body22.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i.i

for.end.i.i:                                      ; preds = %for.body22.i.i.for.end.i.i_crit_edge, %if.end13.i.i.for.end.i.i_crit_edge
  %counter.0.lcssa.i.i = phi i32 [ 0, %if.end13.i.i.for.end.i.i_crit_edge ], [ %counter.1.i.i, %for.body22.i.i.for.end.i.i_crit_edge ]
  %ao_bitmap.0.lcssa.i.i = phi i32 [ 0, %if.end13.i.i.for.end.i.i_crit_edge ], [ %ao_bitmap.2.i.i, %for.body22.i.i.for.end.i.i_crit_edge ]
  %add31.i.i = add i32 %counter.0.lcssa.i.i, %active_cu_number.1107.i.i
  %or.cond98.i.i = select i1 %cmp32.i.i, i1 %cmp11.i.i, i1 false
  %mul37.i.i = shl i32 %j.0106.i.i, 3
  %add38.i.i = add i32 %mul37.i.i, %mul36.i.i
  %shl39.i.i = shl i32 %ao_bitmap.0.lcssa.i.i, %add38.i.i
  %or40.i.i = select i1 %or.cond98.i.i, i32 %shl39.i.i, i32 0
  %ao_cu_mask.2.i.i = or i32 %or40.i.i, %ao_cu_mask.1108.i.i
  %arrayidx43.i126.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 7, i32 %i.0112.i.i, i32 %j.0106.i.i
  %444 = ptrtoint ptr %arrayidx43.i126.i to i32
  call void @__asan_store4_noabort(i32 %444)
  store i32 %ao_bitmap.0.lcssa.i.i, ptr %arrayidx43.i126.i, align 4
  %inc45.i.i = add nuw i32 %j.0106.i.i, 1
  %445 = ptrtoint ptr %max_sh_per_se.i.i to i32
  call void @__asan_load4_noabort(i32 %445)
  %446 = load i32, ptr %max_sh_per_se.i.i, align 4
  %cmp8.i.i = icmp ult i32 %inc45.i.i, %446
  br i1 %cmp8.i.i, label %for.end.i.i.for.body9.i.i_crit_edge, label %for.end.i.i.for.inc47.i.i_crit_edge

for.end.i.i.for.inc47.i.i_crit_edge:              ; preds = %for.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc47.i.i

for.end.i.i.for.body9.i.i_crit_edge:              ; preds = %for.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body9.i.i

for.inc47.i.i:                                    ; preds = %for.end.i.i.for.inc47.i.i_crit_edge, %for.cond5.preheader.i105.i.for.inc47.i.i_crit_edge
  %active_cu_number.1.lcssa.i.i = phi i32 [ %active_cu_number.0114.i.i, %for.cond5.preheader.i105.i.for.inc47.i.i_crit_edge ], [ %add31.i.i, %for.end.i.i.for.inc47.i.i_crit_edge ]
  %ao_cu_mask.1.lcssa.i.i = phi i32 [ %ao_cu_mask.0115.i.i, %for.cond5.preheader.i105.i.for.inc47.i.i_crit_edge ], [ %ao_cu_mask.2.i.i, %for.end.i.i.for.inc47.i.i_crit_edge ]
  %inc48.i.i = add nuw i32 %i.0112.i.i, 1
  %447 = ptrtoint ptr %config.i.i to i32
  call void @__asan_load4_noabort(i32 %447)
  %448 = load i32, ptr %config.i.i, align 8
  %cmp.i127.i = icmp ult i32 %inc48.i.i, %448
  br i1 %cmp.i127.i, label %for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge, label %for.inc47.i.i.gfx_v8_0_get_cu_info.exit.i_crit_edge

for.inc47.i.i.gfx_v8_0_get_cu_info.exit.i_crit_edge: ; preds = %for.inc47.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_get_cu_info.exit.i

for.inc47.i.i.for.cond5.preheader.i105.i_crit_edge: ; preds = %for.inc47.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond5.preheader.i105.i

gfx_v8_0_get_cu_info.exit.i:                      ; preds = %for.inc47.i.i.gfx_v8_0_get_cu_info.exit.i_crit_edge, %if.end.i103.i.gfx_v8_0_get_cu_info.exit.i_crit_edge
  %active_cu_number.0.lcssa.i.i = phi i32 [ 0, %if.end.i103.i.gfx_v8_0_get_cu_info.exit.i_crit_edge ], [ %active_cu_number.1.lcssa.i.i, %for.inc47.i.i.gfx_v8_0_get_cu_info.exit.i_crit_edge ]
  %ao_cu_mask.0.lcssa.i.i = phi i32 [ 0, %if.end.i103.i.gfx_v8_0_get_cu_info.exit.i_crit_edge ], [ %ao_cu_mask.1.lcssa.i.i, %for.inc47.i.i.gfx_v8_0_get_cu_info.exit.i_crit_edge ]
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  call void @mutex_unlock(ptr noundef %grbm_idx_mutex.i.i) #12
  %number.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 5
  %449 = ptrtoint ptr %number.i.i to i32
  call void @__asan_store4_noabort(i32 %449)
  store i32 %active_cu_number.0.lcssa.i.i, ptr %number.i.i, align 4
  %ao_cu_mask51.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 6
  %450 = ptrtoint ptr %ao_cu_mask51.i.i to i32
  call void @__asan_store4_noabort(i32 %450)
  store i32 %ao_cu_mask.0.lcssa.i.i, ptr %ao_cu_mask51.i.i, align 4
  %451 = ptrtoint ptr %cu_info1.i.i to i32
  call void @__asan_store4_noabort(i32 %451)
  store i32 4, ptr %cu_info1.i.i, align 4
  %max_waves_per_simd.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 1
  %452 = ptrtoint ptr %max_waves_per_simd.i.i to i32
  call void @__asan_store4_noabort(i32 %452)
  store i32 10, ptr %max_waves_per_simd.i.i, align 4
  %max_scratch_slots_per_cu.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 3
  %453 = ptrtoint ptr %max_scratch_slots_per_cu.i.i to i32
  call void @__asan_store4_noabort(i32 %453)
  store i32 32, ptr %max_scratch_slots_per_cu.i.i, align 4
  %wave_front_size.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 2
  %454 = ptrtoint ptr %wave_front_size.i.i to i32
  call void @__asan_store4_noabort(i32 %454)
  store i32 64, ptr %wave_front_size.i.i, align 4
  %lds_size.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 48, i32 4
  %455 = ptrtoint ptr %lds_size.i.i to i32
  call void @__asan_store4_noabort(i32 %455)
  store i32 64, ptr %lds_size.i.i, align 4
  call void @llvm.lifetime.end.p0(i64 32, ptr nonnull %disable_masks.i.i) #12
  %456 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %456)
  %457 = load i32, ptr %asic_type.i, align 8
  %458 = add i32 %457, -15
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %458)
  %switch.i.i = icmp ult i32 %458, -2
  %spec.select.i129.i = zext i1 %switch.i.i to i32
  %459 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 31
  %460 = ptrtoint ptr %459 to i32
  call void @__asan_store4_noabort(i32 %460)
  store i32 %spec.select.i129.i, ptr %459, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 9601, i32 noundef 27, i32 noundef 0) #12
  %srbm_mutex.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 20
  call void @mutex_lock_nested(ptr noundef %srbm_mutex.i, i32 noundef 0) #12
  %num_ids.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 65, i32 0, i32 0, i32 1
  %461 = ptrtoint ptr %num_ids.i to i32
  call void @__asan_load4_noabort(i32 %461)
  %462 = load i32, ptr %num_ids.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %462)
  %cmp148.not.i = icmp eq i32 %462, 0
  br i1 %cmp148.not.i, label %gfx_v8_0_get_cu_info.exit.i.for.end.i_crit_edge, label %if.end.peel.i

gfx_v8_0_get_cu_info.exit.i.for.end.i_crit_edge:  ; preds = %gfx_v8_0_get_cu_info.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i

if.end.peel.i:                                    ; preds = %gfx_v8_0_get_cu_info.exit.i
  %shared_aperture_start.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 62, i32 26
  call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8973, i32 noundef 888, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8970, i32 noundef 0, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8971, i32 noundef 1, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8972, i32 noundef 0, i32 noundef 0) #12
  %463 = ptrtoint ptr %num_ids.i to i32
  call void @__asan_load4_noabort(i32 %463)
  %464 = load i32, ptr %num_ids.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %464)
  %cmp.peel.i = icmp ugt i32 %464, 1
  br i1 %cmp.peel.i, label %if.end.peel.i.if.end.i_crit_edge, label %if.end.peel.i.for.end.i_crit_edge

if.end.peel.i.for.end.i_crit_edge:                ; preds = %if.end.peel.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i

if.end.peel.i.if.end.i_crit_edge:                 ; preds = %if.end.peel.i
  br label %if.end.i

if.end.i:                                         ; preds = %if.end.i.if.end.i_crit_edge, %if.end.peel.i.if.end.i_crit_edge
  %i.0149.i = phi i32 [ %inc.i, %if.end.i.if.end.i_crit_edge ], [ 1, %if.end.peel.i.if.end.i_crit_edge ]
  call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef %i.0149.i) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8973, i32 noundef 824, i32 noundef 0) #12
  %465 = ptrtoint ptr %shared_aperture_start.i to i32
  call void @__asan_load8_noabort(i32 %465)
  %466 = load i64, ptr %shared_aperture_start.i, align 8
  %shr.i = lshr i64 %466, 48
  %conv.i = trunc i64 %shr.i to i32
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8970, i32 noundef %conv.i, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8971, i32 noundef 1, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8972, i32 noundef 0, i32 noundef 0) #12
  %inc.i = add nuw i32 %i.0149.i, 1
  %467 = ptrtoint ptr %num_ids.i to i32
  call void @__asan_load4_noabort(i32 %467)
  %468 = load i32, ptr %num_ids.i, align 4
  %cmp.i11 = icmp ult i32 %inc.i, %468
  br i1 %cmp.i11, label %if.end.i.if.end.i_crit_edge, label %if.end.i.for.end.i_crit_edge, !llvm.loop !437

if.end.i.for.end.i_crit_edge:                     ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i

if.end.i.if.end.i_crit_edge:                      ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i

for.end.i:                                        ; preds = %if.end.i.for.end.i_crit_edge, %if.end.peel.i.for.end.i_crit_edge, %gfx_v8_0_get_cu_info.exit.i.for.end.i_crit_edge
  call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  call void @mutex_unlock(ptr noundef %srbm_mutex.i) #12
  call void @mutex_lock_nested(ptr noundef %srbm_mutex.i, i32 noundef 0) #12
  %first_kfd_vmid.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 65, i32 1
  %469 = ptrtoint ptr %first_kfd_vmid.i.i to i32
  call void @__asan_load4_noabort(i32 %469)
  %470 = load i32, ptr %first_kfd_vmid.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 16, i32 %470)
  %cmp34.i.i = icmp slt i32 %470, 16
  br i1 %cmp34.i.i, label %for.end.i.for.body.i.i_crit_edge, label %for.end.i.for.end.i132.i_crit_edge

for.end.i.for.end.i132.i_crit_edge:               ; preds = %for.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i132.i

for.end.i.for.body.i.i_crit_edge:                 ; preds = %for.end.i
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %for.body.i.i.for.body.i.i_crit_edge, %for.end.i.for.body.i.i_crit_edge
  %i.035.i.i = phi i32 [ %inc.i130.i, %for.body.i.i.for.body.i.i_crit_edge ], [ %470, %for.end.i.for.body.i.i_crit_edge ]
  call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef %i.035.i.i) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8973, i32 noundef 94, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8971, i32 noundef 1, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8972, i32 noundef 0, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8970, i32 noundef 1610637312, i32 noundef 0) #12
  %inc.i130.i = add i32 %i.035.i.i, 1
  %exitcond.not.i131.i = icmp eq i32 %inc.i130.i, 16
  br i1 %exitcond.not.i131.i, label %for.body.i.i.for.end.i132.i_crit_edge, label %for.body.i.i.for.body.i.i_crit_edge

for.body.i.i.for.body.i.i_crit_edge:              ; preds = %for.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i.i

for.body.i.i.for.end.i132.i_crit_edge:            ; preds = %for.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i132.i

for.end.i132.i:                                   ; preds = %for.body.i.i.for.end.i132.i_crit_edge, %for.end.i.for.end.i132.i_crit_edge
  call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  call void @mutex_unlock(ptr noundef %srbm_mutex.i) #12
  %471 = ptrtoint ptr %first_kfd_vmid.i.i to i32
  call void @__asan_load4_noabort(i32 %471)
  %472 = load i32, ptr %first_kfd_vmid.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 16, i32 %472)
  %cmp536.i.i = icmp slt i32 %472, 16
  br i1 %cmp536.i.i, label %for.end.i132.i.for.body6.i.i_crit_edge, label %for.end.i132.i.for.body.i140.i.preheader_crit_edge

for.end.i132.i.for.body.i140.i.preheader_crit_edge: ; preds = %for.end.i132.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i140.i.preheader

for.end.i132.i.for.body6.i.i_crit_edge:           ; preds = %for.end.i132.i
  br label %for.body6.i.i

for.body6.i.i:                                    ; preds = %for.body6.i.i.for.body6.i.i_crit_edge, %for.end.i132.i.for.body6.i.i_crit_edge
  %i.137.i.i = phi i32 [ %inc11.i.i, %for.body6.i.i.for.body6.i.i_crit_edge ], [ %472, %for.end.i132.i.for.body6.i.i_crit_edge ]
  %arrayidx.i133.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %i.137.i.i
  %473 = ptrtoint ptr %arrayidx.i133.i to i32
  call void @__asan_load4_noabort(i32 %473)
  %474 = load i32, ptr %arrayidx.i133.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %474, i32 noundef 0, i32 noundef 0) #12
  %mem_size.i.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %i.137.i.i, i32 1
  %475 = ptrtoint ptr %mem_size.i.i to i32
  call void @__asan_load4_noabort(i32 %475)
  %476 = load i32, ptr %mem_size.i.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %476, i32 noundef 0, i32 noundef 0) #12
  %gws.i.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %i.137.i.i, i32 2
  %477 = ptrtoint ptr %gws.i.i to i32
  call void @__asan_load4_noabort(i32 %477)
  %478 = load i32, ptr %gws.i.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %478, i32 noundef 0, i32 noundef 0) #12
  %oa.i.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %i.137.i.i, i32 3
  %479 = ptrtoint ptr %oa.i.i to i32
  call void @__asan_load4_noabort(i32 %479)
  %480 = load i32, ptr %oa.i.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %480, i32 noundef 0, i32 noundef 0) #12
  %inc11.i.i = add i32 %i.137.i.i, 1
  %exitcond38.not.i.i = icmp eq i32 %inc11.i.i, 16
  br i1 %exitcond38.not.i.i, label %for.body6.i.i.for.body.i140.i.preheader_crit_edge, label %for.body6.i.i.for.body6.i.i_crit_edge

for.body6.i.i.for.body6.i.i_crit_edge:            ; preds = %for.body6.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body6.i.i

for.body6.i.i.for.body.i140.i.preheader_crit_edge: ; preds = %for.body6.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i140.i.preheader

for.body.i140.i.preheader:                        ; preds = %for.body6.i.i.for.body.i140.i.preheader_crit_edge, %for.end.i132.i.for.body.i140.i.preheader_crit_edge
  br label %for.body.i140.i

for.body.i140.i:                                  ; preds = %for.body.i140.i.for.body.i140.i_crit_edge, %for.body.i140.i.preheader
  %vmid.012.i.i = phi i32 [ %inc.i138.i, %for.body.i140.i.for.body.i140.i_crit_edge ], [ 1, %for.body.i140.i.preheader ]
  %arrayidx.i134.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid.012.i.i
  %481 = ptrtoint ptr %arrayidx.i134.i to i32
  call void @__asan_load4_noabort(i32 %481)
  %482 = load i32, ptr %arrayidx.i134.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %482, i32 noundef 0, i32 noundef 0) #12
  %mem_size.i135.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid.012.i.i, i32 1
  %483 = ptrtoint ptr %mem_size.i135.i to i32
  call void @__asan_load4_noabort(i32 %483)
  %484 = load i32, ptr %mem_size.i135.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %484, i32 noundef 0, i32 noundef 0) #12
  %gws.i136.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid.012.i.i, i32 2
  %485 = ptrtoint ptr %gws.i136.i to i32
  call void @__asan_load4_noabort(i32 %485)
  %486 = load i32, ptr %gws.i136.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %486, i32 noundef 0, i32 noundef 0) #12
  %oa.i137.i = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid.012.i.i, i32 3
  %487 = ptrtoint ptr %oa.i137.i to i32
  call void @__asan_load4_noabort(i32 %487)
  %488 = load i32, ptr %oa.i137.i, align 4
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef %488, i32 noundef 0, i32 noundef 0) #12
  %inc.i138.i = add nuw nsw i32 %vmid.012.i.i, 1
  %exitcond.not.i139.i = icmp eq i32 %inc.i138.i, 16
  br i1 %exitcond.not.i139.i, label %gfx_v8_0_constants_init.exit, label %for.body.i140.i.for.body.i140.i_crit_edge

for.body.i140.i.for.body.i140.i_crit_edge:        ; preds = %for.body.i140.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i140.i

gfx_v8_0_constants_init.exit:                     ; preds = %for.body.i140.i
  call void @mutex_lock_nested(ptr noundef %grbm_idx_mutex.i.i, i32 noundef 0) #12
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  %sc_prim_fifo_size_frontend.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 9
  %489 = ptrtoint ptr %sc_prim_fifo_size_frontend.i to i32
  call void @__asan_load4_noabort(i32 %489)
  %490 = load i32, ptr %sc_prim_fifo_size_frontend.i, align 4
  %sc_prim_fifo_size_backend.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 10
  %491 = ptrtoint ptr %sc_prim_fifo_size_backend.i to i32
  call void @__asan_load4_noabort(i32 %491)
  %492 = load i32, ptr %sc_prim_fifo_size_backend.i, align 8
  %shl25.i = shl i32 %492, 6
  %or26.i = or i32 %shl25.i, %490
  %sc_hiz_tile_fifo_size.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 11
  %493 = ptrtoint ptr %sc_hiz_tile_fifo_size.i to i32
  call void @__asan_load4_noabort(i32 %493)
  %494 = load i32, ptr %sc_hiz_tile_fifo_size.i, align 4
  %shl29.i = shl i32 %494, 15
  %or30.i = or i32 %or26.i, %shl29.i
  %sc_earlyz_tile_fifo_size.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 1, i32 12
  %495 = ptrtoint ptr %sc_earlyz_tile_fifo_size.i to i32
  call void @__asan_load4_noabort(i32 %495)
  %496 = load i32, ptr %sc_earlyz_tile_fifo_size.i, align 8
  %shl33.i = shl i32 %496, 23
  %or34.i = or i32 %or30.i, %shl33.i
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8947, i32 noundef %or34.i, i32 noundef 0) #12
  %call35.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12736, i32 noundef 0) #12
  %and36.i = and i32 %call35.i, -4096
  %or43.i = or i32 %and36.i, 1170
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12736, i32 noundef %or43.i, i32 noundef 0) #12
  call void @mutex_unlock(ptr noundef %grbm_idx_mutex.i.i) #12
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %497 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %497)
  %498 = load ptr, ptr %funcs, align 4
  %resume = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %498, i32 0, i32 7
  %499 = ptrtoint ptr %resume to i32
  call void @__asan_load4_noabort(i32 %499)
  %500 = load ptr, ptr %resume, align 4
  %call = call i32 %500(ptr noundef %handle) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %gfx_v8_0_constants_init.exit.cleanup_crit_edge

gfx_v8_0_constants_init.exit.cleanup_crit_edge:   ; preds = %gfx_v8_0_constants_init.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %gfx_v8_0_constants_init.exit
  %501 = ptrtoint ptr %flags.i.i to i32
  call void @__asan_load4_noabort(i32 %501)
  %502 = load i32, ptr %flags.i.i, align 8
  %and.i12 = and i32 %502, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i12)
  %tobool.not.i = icmp eq i32 %and.i12, 0
  br i1 %tobool.not.i, label %if.then.i14, label %if.end.if.end.i16_crit_edge

if.end.if.end.i16_crit_edge:                      ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i16

if.then.i14:                                      ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %call.i.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12394, i32 noundef 0) #12
  %and.i.i13 = and i32 %call.i.i, -3932161
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12394, i32 noundef %and.i.i13, i32 noundef 0) #12
  br label %if.end.i16

if.end.i16:                                       ; preds = %if.then.i14, %if.end.if.end.i16_crit_edge
  %call.i15 = call fastcc i32 @gfx_v8_0_kiq_resume(ptr noundef %handle) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i15)
  %tobool1.not.i = icmp eq i32 %call.i15, 0
  br i1 %tobool1.not.i, label %if.end3.i, label %if.end.i16.cleanup_crit_edge

if.end.i16.cleanup_crit_edge:                     ; preds = %if.end.i16
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end3.i:                                        ; preds = %if.end.i16
  call fastcc void @gfx_v8_0_cp_gfx_resume(ptr noundef %handle) #12
  %call8.i = call fastcc i32 @gfx_v8_0_kcq_resume(ptr noundef %handle) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call8.i)
  %tobool9.not.i = icmp eq i32 %call8.i, 0
  br i1 %tobool9.not.i, label %if.end11.i, label %if.end3.i.cleanup_crit_edge

if.end3.i.cleanup_crit_edge:                      ; preds = %if.end3.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end11.i:                                       ; preds = %if.end3.i
  %gfx_ring.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36
  %call.i29.i = call i32 @amdgpu_ring_test_helper(ptr noundef %gfx_ring.i.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i29.i)
  %tobool.not.i.i17 = icmp eq i32 %call.i29.i, 0
  br i1 %tobool.not.i.i17, label %if.end.i.i18, label %if.end11.i.cleanup_crit_edge

if.end11.i.cleanup_crit_edge:                     ; preds = %if.end11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end.i.i18:                                     ; preds = %if.end11.i
  %ring2.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3
  %call3.i.i = call i32 @amdgpu_ring_test_helper(ptr noundef %ring2.i.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call3.i.i)
  %tobool4.not.i.i = icmp eq i32 %call3.i.i, 0
  br i1 %tobool4.not.i.i, label %for.cond.preheader.i.i, label %if.end.i.i18.cleanup_crit_edge

if.end.i.i18.cleanup_crit_edge:                   ; preds = %if.end.i.i18
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

for.cond.preheader.i.i:                           ; preds = %if.end.i.i18
  %num_compute_rings.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %503 = ptrtoint ptr %num_compute_rings.i.i to i32
  call void @__asan_load4_noabort(i32 %503)
  %504 = load i32, ptr %num_compute_rings.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %504)
  %cmp23.not.i.i = icmp eq i32 %504, 0
  br i1 %cmp23.not.i.i, label %for.cond.preheader.i.i.if.end15.i_crit_edge, label %for.cond.preheader.i.i.for.body.i.i21_crit_edge

for.cond.preheader.i.i.for.body.i.i21_crit_edge:  ; preds = %for.cond.preheader.i.i
  br label %for.body.i.i21

for.cond.preheader.i.i.if.end15.i_crit_edge:      ; preds = %for.cond.preheader.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end15.i

for.body.i.i21:                                   ; preds = %for.body.i.i21.for.body.i.i21_crit_edge, %for.cond.preheader.i.i.for.body.i.i21_crit_edge
  %i.024.i.i = phi i32 [ %inc.i.i19, %for.body.i.i21.for.body.i.i21_crit_edge ], [ 0, %for.cond.preheader.i.i.for.body.i.i21_crit_edge ]
  %arrayidx9.i.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.024.i.i
  %call10.i.i = call i32 @amdgpu_ring_test_helper(ptr noundef %arrayidx9.i.i) #12
  %inc.i.i19 = add nuw i32 %i.024.i.i, 1
  %505 = ptrtoint ptr %num_compute_rings.i.i to i32
  call void @__asan_load4_noabort(i32 %505)
  %506 = load i32, ptr %num_compute_rings.i.i, align 8
  %cmp.i.i20 = icmp ult i32 %inc.i.i19, %506
  br i1 %cmp.i.i20, label %for.body.i.i21.for.body.i.i21_crit_edge, label %for.body.i.i21.if.end15.i_crit_edge

for.body.i.i21.if.end15.i_crit_edge:              ; preds = %for.body.i.i21
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end15.i

for.body.i.i21.for.body.i.i21_crit_edge:          ; preds = %for.body.i.i21
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i.i21

if.end15.i:                                       ; preds = %for.body.i.i21.if.end15.i_crit_edge, %for.cond.preheader.i.i.if.end15.i_crit_edge
  %call.i30.i = call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12394, i32 noundef 0) #12
  %or19.i.i = or i32 %call.i30.i, 3932160
  call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 12394, i32 noundef %or19.i.i, i32 noundef 0) #12
  br label %cleanup

cleanup:                                          ; preds = %if.end15.i, %if.end.i.i18.cleanup_crit_edge, %if.end11.i.cleanup_crit_edge, %if.end3.i.cleanup_crit_edge, %if.end.i16.cleanup_crit_edge, %gfx_v8_0_constants_init.exit.cleanup_crit_edge
  %retval.0 = phi i32 [ %call, %gfx_v8_0_constants_init.exit.cleanup_crit_edge ], [ 0, %if.end15.i ], [ %call.i15, %if.end.i16.cleanup_crit_edge ], [ %call8.i, %if.end3.i.cleanup_crit_edge ], [ %call.i29.i, %if.end11.i.cleanup_crit_edge ], [ %call3.i.i, %if.end.i.i18.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_hw_fini(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %priv_reg_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 41
  %call = tail call i32 @amdgpu_irq_put(ptr noundef %handle, ptr noundef %priv_reg_irq, i32 noundef 0) #12
  %priv_inst_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 42
  %call2 = tail call i32 @amdgpu_irq_put(ptr noundef %handle, ptr noundef %priv_inst_irq, i32 noundef 0) #12
  %cp_ecc_error_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 43
  %call4 = tail call i32 @amdgpu_irq_put(ptr noundef %handle, ptr noundef %cp_ecc_error_irq, i32 noundef 0) #12
  %sq_irq = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 44
  %call6 = tail call i32 @amdgpu_irq_put(ptr noundef %handle, ptr noundef %sq_irq, i32 noundef 0) #12
  %ring.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3
  %num_compute_rings.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %0 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %num_compute_rings.i, align 8
  %mul.i = mul i32 %1, 6
  %call.i = tail call i32 @amdgpu_ring_alloc(ptr noundef %ring.i, i32 noundef %mul.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool.not.i, label %entry.if.end.i_crit_edge, label %if.then.i

entry.if.end.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.84, i32 noundef %call.i) #12
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %entry.if.end.i_crit_edge
  %2 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %num_compute_rings.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %cmp66.not.i = icmp eq i32 %3, 0
  br i1 %cmp66.not.i, label %if.end.i.for.end.i_crit_edge, label %for.body.lr.ph.i

if.end.i.for.end.i_crit_edge:                     ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i

for.body.lr.ph.i:                                 ; preds = %if.end.i
  %count_dw.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 11
  %ring1.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 5
  %wptr.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 7
  %buf_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 14
  %ptr_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 13
  %4 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %.pr.i = load i32, ptr %count_dw.i.i, align 8
  br label %for.body.i

for.body.i:                                       ; preds = %amdgpu_ring_write.exit65.i.for.body.i_crit_edge, %for.body.lr.ph.i
  %5 = phi i32 [ %.pr.i, %for.body.lr.ph.i ], [ %dec.i64.i, %amdgpu_ring_write.exit65.i.for.body.i_crit_edge ]
  %i.067.i = phi i32 [ 0, %for.body.lr.ph.i ], [ %inc.i, %amdgpu_ring_write.exit65.i.for.body.i_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %5)
  %cmp.i.i = icmp slt i32 %5, 1
  br i1 %cmp.i.i, label %if.then.i.i, label %for.body.i.amdgpu_ring_write.exit.i_crit_edge

for.body.i.amdgpu_ring_write.exit.i_crit_edge:    ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i

if.then.i.i:                                      ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i

amdgpu_ring_write.exit.i:                         ; preds = %if.then.i.i, %for.body.i.amdgpu_ring_write.exit.i_crit_edge
  %6 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %ring1.i.i, align 4
  %8 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %wptr.i.i, align 8
  %inc.i.i = add i64 %9, 1
  store i64 %inc.i.i, ptr %wptr.i.i, align 8
  %10 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %buf_mask.i.i, align 8
  %12 = trunc i64 %9 to i32
  %idxprom.i.i = and i32 %11, %12
  %arrayidx.i.i = getelementptr i32, ptr %7, i32 %idxprom.i.i
  %13 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store volatile i32 -1073437952, ptr %arrayidx.i.i, align 4
  %14 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %14)
  %15 = load i64, ptr %ptr_mask.i.i, align 8
  %16 = load i64, ptr %wptr.i.i, align 8
  %and3.i.i = and i64 %16, %15
  store i64 %and3.i.i, ptr %wptr.i.i, align 8
  %17 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %count_dw.i.i, align 8
  %dec.i.i = add i32 %18, -1
  store i32 %dec.i.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i)
  %cmp.i2.i = icmp slt i32 %dec.i.i, 1
  br i1 %cmp.i2.i, label %if.then.i3.i, label %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit13.i_crit_edge

amdgpu_ring_write.exit.i.amdgpu_ring_write.exit13.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit13.i

if.then.i3.i:                                     ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit13.i

amdgpu_ring_write.exit13.i:                       ; preds = %if.then.i3.i, %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit13.i_crit_edge
  %19 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %ring1.i.i, align 4
  %21 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %21)
  %22 = load i64, ptr %wptr.i.i, align 8
  %inc.i6.i = add i64 %22, 1
  store i64 %inc.i6.i, ptr %wptr.i.i, align 8
  %23 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %buf_mask.i.i, align 8
  %25 = trunc i64 %22 to i32
  %idxprom.i8.i = and i32 %24, %25
  %arrayidx.i9.i = getelementptr i32, ptr %20, i32 %idxprom.i8.i
  %26 = ptrtoint ptr %arrayidx.i9.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store volatile i32 536870913, ptr %arrayidx.i9.i, align 4
  %27 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %27)
  %28 = load i64, ptr %ptr_mask.i.i, align 8
  %29 = load i64, ptr %wptr.i.i, align 8
  %and3.i11.i = and i64 %29, %28
  store i64 %and3.i11.i, ptr %wptr.i.i, align 8
  %30 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %count_dw.i.i, align 8
  %dec.i12.i = add i32 %31, -1
  store i32 %dec.i12.i, ptr %count_dw.i.i, align 8
  %doorbell_index.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.067.i, i32 23
  %32 = ptrtoint ptr %doorbell_index.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %doorbell_index.i, align 8
  %shl.i = shl i32 %33, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i12.i)
  %cmp.i15.i = icmp slt i32 %dec.i12.i, 1
  br i1 %cmp.i15.i, label %if.then.i16.i, label %amdgpu_ring_write.exit13.i.amdgpu_ring_write.exit26.i_crit_edge

amdgpu_ring_write.exit13.i.amdgpu_ring_write.exit26.i_crit_edge: ; preds = %amdgpu_ring_write.exit13.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit26.i

if.then.i16.i:                                    ; preds = %amdgpu_ring_write.exit13.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit26.i

amdgpu_ring_write.exit26.i:                       ; preds = %if.then.i16.i, %amdgpu_ring_write.exit13.i.amdgpu_ring_write.exit26.i_crit_edge
  %34 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %ring1.i.i, align 4
  %36 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %wptr.i.i, align 8
  %inc.i19.i = add i64 %37, 1
  store i64 %inc.i19.i, ptr %wptr.i.i, align 8
  %38 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %buf_mask.i.i, align 8
  %40 = trunc i64 %37 to i32
  %idxprom.i21.i = and i32 %39, %40
  %arrayidx.i22.i = getelementptr i32, ptr %35, i32 %idxprom.i21.i
  %41 = ptrtoint ptr %arrayidx.i22.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store volatile i32 %shl.i, ptr %arrayidx.i22.i, align 4
  %42 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %42)
  %43 = load i64, ptr %ptr_mask.i.i, align 8
  %44 = load i64, ptr %wptr.i.i, align 8
  %and3.i24.i = and i64 %44, %43
  store i64 %and3.i24.i, ptr %wptr.i.i, align 8
  %45 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %count_dw.i.i, align 8
  %dec.i25.i = add i32 %46, -1
  store i32 %dec.i25.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i25.i)
  %cmp.i28.i = icmp slt i32 %dec.i25.i, 1
  br i1 %cmp.i28.i, label %if.then.i29.i, label %amdgpu_ring_write.exit26.i.amdgpu_ring_write.exit39.i_crit_edge

amdgpu_ring_write.exit26.i.amdgpu_ring_write.exit39.i_crit_edge: ; preds = %amdgpu_ring_write.exit26.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit39.i

if.then.i29.i:                                    ; preds = %amdgpu_ring_write.exit26.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit39.i

amdgpu_ring_write.exit39.i:                       ; preds = %if.then.i29.i, %amdgpu_ring_write.exit26.i.amdgpu_ring_write.exit39.i_crit_edge
  %47 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %ring1.i.i, align 4
  %49 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %wptr.i.i, align 8
  %inc.i32.i = add i64 %50, 1
  store i64 %inc.i32.i, ptr %wptr.i.i, align 8
  %51 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %buf_mask.i.i, align 8
  %53 = trunc i64 %50 to i32
  %idxprom.i34.i = and i32 %52, %53
  %arrayidx.i35.i = getelementptr i32, ptr %48, i32 %idxprom.i34.i
  %54 = ptrtoint ptr %arrayidx.i35.i to i32
  call void @__asan_store4_noabort(i32 %54)
  store volatile i32 0, ptr %arrayidx.i35.i, align 4
  %55 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %55)
  %56 = load i64, ptr %ptr_mask.i.i, align 8
  %57 = load i64, ptr %wptr.i.i, align 8
  %and3.i37.i = and i64 %57, %56
  store i64 %and3.i37.i, ptr %wptr.i.i, align 8
  %58 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %count_dw.i.i, align 8
  %dec.i38.i = add i32 %59, -1
  store i32 %dec.i38.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i38.i)
  %cmp.i41.i = icmp slt i32 %dec.i38.i, 1
  br i1 %cmp.i41.i, label %if.then.i42.i, label %amdgpu_ring_write.exit39.i.amdgpu_ring_write.exit52.i_crit_edge

amdgpu_ring_write.exit39.i.amdgpu_ring_write.exit52.i_crit_edge: ; preds = %amdgpu_ring_write.exit39.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit52.i

if.then.i42.i:                                    ; preds = %amdgpu_ring_write.exit39.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit52.i

amdgpu_ring_write.exit52.i:                       ; preds = %if.then.i42.i, %amdgpu_ring_write.exit39.i.amdgpu_ring_write.exit52.i_crit_edge
  %60 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %ring1.i.i, align 4
  %62 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %wptr.i.i, align 8
  %inc.i45.i = add i64 %63, 1
  store i64 %inc.i45.i, ptr %wptr.i.i, align 8
  %64 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %buf_mask.i.i, align 8
  %66 = trunc i64 %63 to i32
  %idxprom.i47.i = and i32 %65, %66
  %arrayidx.i48.i = getelementptr i32, ptr %61, i32 %idxprom.i47.i
  %67 = ptrtoint ptr %arrayidx.i48.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store volatile i32 0, ptr %arrayidx.i48.i, align 4
  %68 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %68)
  %69 = load i64, ptr %ptr_mask.i.i, align 8
  %70 = load i64, ptr %wptr.i.i, align 8
  %and3.i50.i = and i64 %70, %69
  store i64 %and3.i50.i, ptr %wptr.i.i, align 8
  %71 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %count_dw.i.i, align 8
  %dec.i51.i = add i32 %72, -1
  store i32 %dec.i51.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i51.i)
  %cmp.i54.i = icmp slt i32 %dec.i51.i, 1
  br i1 %cmp.i54.i, label %if.then.i55.i, label %amdgpu_ring_write.exit52.i.amdgpu_ring_write.exit65.i_crit_edge

amdgpu_ring_write.exit52.i.amdgpu_ring_write.exit65.i_crit_edge: ; preds = %amdgpu_ring_write.exit52.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit65.i

if.then.i55.i:                                    ; preds = %amdgpu_ring_write.exit52.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit65.i

amdgpu_ring_write.exit65.i:                       ; preds = %if.then.i55.i, %amdgpu_ring_write.exit52.i.amdgpu_ring_write.exit65.i_crit_edge
  %73 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %ring1.i.i, align 4
  %75 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %75)
  %76 = load i64, ptr %wptr.i.i, align 8
  %inc.i58.i = add i64 %76, 1
  store i64 %inc.i58.i, ptr %wptr.i.i, align 8
  %77 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %buf_mask.i.i, align 8
  %79 = trunc i64 %76 to i32
  %idxprom.i60.i = and i32 %78, %79
  %arrayidx.i61.i = getelementptr i32, ptr %74, i32 %idxprom.i60.i
  %80 = ptrtoint ptr %arrayidx.i61.i to i32
  call void @__asan_store4_noabort(i32 %80)
  store volatile i32 0, ptr %arrayidx.i61.i, align 4
  %81 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %81)
  %82 = load i64, ptr %ptr_mask.i.i, align 8
  %83 = load i64, ptr %wptr.i.i, align 8
  %and3.i63.i = and i64 %83, %82
  store i64 %and3.i63.i, ptr %wptr.i.i, align 8
  %84 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load i32, ptr %count_dw.i.i, align 8
  %dec.i64.i = add i32 %85, -1
  store i32 %dec.i64.i, ptr %count_dw.i.i, align 8
  %inc.i = add nuw i32 %i.067.i, 1
  %86 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load i32, ptr %num_compute_rings.i, align 8
  %cmp.i = icmp ult i32 %inc.i, %87
  br i1 %cmp.i, label %amdgpu_ring_write.exit65.i.for.body.i_crit_edge, label %amdgpu_ring_write.exit65.i.for.end.i_crit_edge

amdgpu_ring_write.exit65.i.for.end.i_crit_edge:   ; preds = %amdgpu_ring_write.exit65.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end.i

amdgpu_ring_write.exit65.i.for.body.i_crit_edge:  ; preds = %amdgpu_ring_write.exit65.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

for.end.i:                                        ; preds = %amdgpu_ring_write.exit65.i.for.end.i_crit_edge, %if.end.i.for.end.i_crit_edge
  %call6.i = tail call i32 @amdgpu_ring_test_helper(ptr noundef %ring.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call6.i)
  %tobool7.not.i = icmp eq i32 %call6.i, 0
  br i1 %tobool7.not.i, label %for.end.i.gfx_v8_0_kcq_disable.exit_crit_edge, label %if.then8.i

for.end.i.gfx_v8_0_kcq_disable.exit_crit_edge:    ; preds = %for.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_kcq_disable.exit

if.then8.i:                                       ; preds = %for.end.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.93) #12
  br label %gfx_v8_0_kcq_disable.exit

gfx_v8_0_kcq_disable.exit:                        ; preds = %if.then8.i, %for.end.i.gfx_v8_0_kcq_disable.exit_crit_edge
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 132
  %88 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load i32, ptr %virt, align 8
  %and = and i32 %89, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end13, label %do.body

do.body:                                          ; preds = %gfx_v8_0_kcq_disable.exit
  call void @__sanitizer_cov_trace_pc() #14
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, ptr, ptr, ptr, i8, i8, i8, i8, { { { %struct.atomic_t, { ptr } } } }, [4 x i8] }, ptr @gfx_v8_0_hw_fini.__UNIQUE_ID_ddebug418, i32 0, i32 8, i32 0, i32 0, i32 0, i32 0), ptr blockaddress(@gfx_v8_0_hw_fini, %if.then12)) #12
          to label %cleanup [label %if.then12], !srcloc !439

if.then12:                                        ; preds = %do.body
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ptr, ...) @__dynamic_pr_debug(ptr noundef nonnull @gfx_v8_0_hw_fini.__UNIQUE_ID_ddebug418, ptr noundef nonnull @.str.88) #12
  br label %cleanup

if.end13:                                         ; preds = %gfx_v8_0_kcq_disable.exit
  tail call void @amdgpu_gfx_rlc_enter_safe_mode(ptr noundef %handle) #12
  %usec_timeout.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 11
  %90 = ptrtoint ptr %usec_timeout.i to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load i32, ptr %usec_timeout.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %91)
  %cmp5.not.i = icmp eq i32 %91, 0
  br i1 %cmp5.not.i, label %if.end13.do.end19_crit_edge, label %if.end13.for.body.i50_crit_edge

if.end13.for.body.i50_crit_edge:                  ; preds = %if.end13
  br label %for.body.i50

if.end13.do.end19_crit_edge:                      ; preds = %if.end13
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end19

for.body.i50:                                     ; preds = %if.end.i53.for.body.i50_crit_edge, %if.end13.for.body.i50_crit_edge
  %i.06.i = phi i32 [ %inc.i51, %if.end.i53.for.body.i50_crit_edge ], [ 0, %if.end13.for.body.i50_crit_edge ]
  %call.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8196, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %call.i.i)
  %tobool.not.i.i = icmp sgt i32 %call.i.i, -1
  br i1 %tobool.not.i.i, label %gfx_v8_0_is_idle.exit.i, label %for.body.i50.if.end.i53_crit_edge

for.body.i50.if.end.i53_crit_edge:                ; preds = %for.body.i50
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i53

gfx_v8_0_is_idle.exit.i:                          ; preds = %for.body.i50
  %call1.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8194, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 8, i32 %call1.i.i)
  %cmp.not.i.i = icmp eq i32 %call1.i.i, 8
  br i1 %cmp.not.i.i, label %if.then16, label %gfx_v8_0_is_idle.exit.i.if.end.i53_crit_edge

gfx_v8_0_is_idle.exit.i.if.end.i53_crit_edge:     ; preds = %gfx_v8_0_is_idle.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i53

if.end.i53:                                       ; preds = %gfx_v8_0_is_idle.exit.i.if.end.i53_crit_edge, %for.body.i50.if.end.i53_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %92 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %92(i32 noundef 214748) #12
  %inc.i51 = add nuw i32 %i.06.i, 1
  %93 = ptrtoint ptr %usec_timeout.i to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %usec_timeout.i, align 8
  %cmp.i52 = icmp ult i32 %inc.i51, %94
  br i1 %cmp.i52, label %if.end.i53.for.body.i50_crit_edge, label %if.end.i53.do.end19_crit_edge

if.end.i53.do.end19_crit_edge:                    ; preds = %if.end.i53
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end19

if.end.i53.for.body.i50_crit_edge:                ; preds = %if.end.i53
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i50

if.then16:                                        ; preds = %gfx_v8_0_is_idle.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  %call.i.i55 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8630, i32 noundef 0) #12
  %tmp.0.i.i = or i32 %call.i.i55, 352321536
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8630, i32 noundef %tmp.0.i.i, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %95 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %95(i32 noundef 10737400) #12
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8333, i32 noundef 1342177280, i32 noundef 0) #12
  %ready.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 3, i32 17
  %96 = ptrtoint ptr %ready.i.i to i32
  call void @__asan_store1_noabort(i32 %96)
  store i8 0, ptr %ready.i.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %97 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %97(i32 noundef 10737400) #12
  br label %if.end22

do.end19:                                         ; preds = %if.end.i53.do.end19_crit_edge, %if.end13.do.end19_crit_edge
  %call21 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.89) #15
  br label %if.end22

if.end22:                                         ; preds = %do.end19, %if.then16
  %98 = ptrtoint ptr %usec_timeout.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %usec_timeout.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %99)
  %cmp4.not.i = icmp eq i32 %99, 0
  br i1 %cmp4.not.i, label %if.end22.do.end30_crit_edge, label %if.end22.for.body.i59_crit_edge

if.end22.for.body.i59_crit_edge:                  ; preds = %if.end22
  br label %for.body.i59

if.end22.do.end30_crit_edge:                      ; preds = %if.end22
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end30

for.body.i59:                                     ; preds = %if.end.i62.for.body.i59_crit_edge, %if.end22.for.body.i59_crit_edge
  %i.05.i = phi i32 [ %inc.i60, %if.end.i62.for.body.i59_crit_edge ], [ 0, %if.end22.for.body.i59_crit_edge ]
  %call.i.i57 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8194, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 8, i32 %call.i.i57)
  %cmp.not.i.i58 = icmp eq i32 %call.i.i57, 8
  br i1 %cmp.not.i.i58, label %if.then25, label %if.end.i62

if.end.i62:                                       ; preds = %for.body.i59
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %100 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %100(i32 noundef 214748) #12
  %inc.i60 = add nuw i32 %i.05.i, 1
  %101 = ptrtoint ptr %usec_timeout.i to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load i32, ptr %usec_timeout.i, align 8
  %cmp.i61 = icmp ult i32 %inc.i60, %102
  br i1 %cmp.i61, label %if.end.i62.for.body.i59_crit_edge, label %if.end.i62.do.end30_crit_edge

if.end.i62.do.end30_crit_edge:                    ; preds = %if.end.i62
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end30

if.end.i62.for.body.i59_crit_edge:                ; preds = %if.end.i62
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i59

if.then25:                                        ; preds = %for.body.i59
  call void @__sanitizer_cov_trace_pc() #14
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %103 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %103)
  %104 = load ptr, ptr %funcs, align 4
  %stop = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %104, i32 0, i32 8
  %105 = ptrtoint ptr %stop to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load ptr, ptr %stop, align 4
  tail call void %106(ptr noundef %handle) #12
  br label %if.end33

do.end30:                                         ; preds = %if.end.i62.do.end30_crit_edge, %if.end22.do.end30_crit_edge
  %call32 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.91) #15
  br label %if.end33

if.end33:                                         ; preds = %do.end30, %if.then25
  tail call void @amdgpu_gfx_rlc_exit_safe_mode(ptr noundef %handle) #12
  br label %cleanup

cleanup:                                          ; preds = %if.end33, %if.then12, %do.body
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_suspend(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @gfx_v8_0_hw_fini(ptr noundef %handle)
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_resume(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @gfx_v8_0_hw_init(ptr noundef %handle)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal zeroext i1 @gfx_v8_0_is_idle(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8196, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %call)
  %tobool.not = icmp sgt i32 %call, -1
  br i1 %tobool.not, label %lor.lhs.false, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

lor.lhs.false:                                    ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8194, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 8, i32 %call1)
  %cmp.not = icmp eq i32 %call1, 8
  br label %cleanup

cleanup:                                          ; preds = %lor.lhs.false, %entry.cleanup_crit_edge
  %retval.0 = phi i1 [ false, %entry.cleanup_crit_edge ], [ %cmp.not, %lor.lhs.false ]
  ret i1 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_wait_for_idle(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 11
  %0 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp5.not = icmp eq i32 %1, 0
  br i1 %cmp5.not, label %entry.cleanup_crit_edge, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  br label %for.body

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

for.body:                                         ; preds = %if.end.for.body_crit_edge, %entry.for.body_crit_edge
  %i.06 = phi i32 [ %inc, %if.end.for.body_crit_edge ], [ 0, %entry.for.body_crit_edge ]
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8196, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %call.i)
  %tobool.not.i = icmp sgt i32 %call.i, -1
  br i1 %tobool.not.i, label %gfx_v8_0_is_idle.exit, label %for.body.if.end_crit_edge

for.body.if.end_crit_edge:                        ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

gfx_v8_0_is_idle.exit:                            ; preds = %for.body
  %call1.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8194, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 8, i32 %call1.i)
  %cmp.not.i = icmp eq i32 %call1.i, 8
  br i1 %cmp.not.i, label %gfx_v8_0_is_idle.exit.cleanup_crit_edge, label %gfx_v8_0_is_idle.exit.if.end_crit_edge

gfx_v8_0_is_idle.exit.if.end_crit_edge:           ; preds = %gfx_v8_0_is_idle.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

gfx_v8_0_is_idle.exit.cleanup_crit_edge:          ; preds = %gfx_v8_0_is_idle.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %gfx_v8_0_is_idle.exit.if.end_crit_edge, %for.body.if.end_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %2 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %2(i32 noundef 214748) #12
  %inc = add nuw i32 %i.06, 1
  %3 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %usec_timeout, align 8
  %cmp = icmp ult i32 %inc, %4
  br i1 %cmp, label %if.end.for.body_crit_edge, label %if.end.cleanup_crit_edge

if.end.cleanup_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end.for.body_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

cleanup:                                          ; preds = %if.end.cleanup_crit_edge, %gfx_v8_0_is_idle.exit.cleanup_crit_edge, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ -110, %entry.cleanup_crit_edge ], [ -110, %if.end.cleanup_crit_edge ], [ 0, %gfx_v8_0_is_idle.exit.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal zeroext i1 @gfx_v8_0_check_soft_reset(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8196, i32 noundef 0) #12
  %and = and i32 %call, 2011086848
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 65537
  %call6 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8194, i32 noundef 0) #12
  %0 = lshr i32 %call6, 22
  %1 = and i32 %0, 4
  %2 = or i32 %1, %spec.select
  %3 = and i32 %call6, 1879048192
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %4 = icmp eq i32 %3, 0
  %or29 = or i32 %2, 917504
  %grbm_soft_reset.2 = select i1 %4, i32 %2, i32 %or29
  %call33 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 916, i32 noundef 0) #12
  %5 = and i32 %call33, 32
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %5)
  %tobool36.not = icmp eq i32 %5, 0
  %6 = select i1 %tobool36.not, i1 %4, i1 false
  %7 = select i1 %6, i1 %tobool.not, i1 false
  %srbm_soft_reset.2 = select i1 %7, i32 0, i32 256
  %8 = shl i32 %call33, 1
  %9 = and i32 %8, 32768
  %10 = or i32 %srbm_soft_reset.2, %9
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %grbm_soft_reset.2)
  %tobool48.not = icmp eq i32 %grbm_soft_reset.2, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %10)
  %tobool50.not = icmp eq i32 %10, 0
  %or.cond88 = select i1 %tobool48.not, i1 %tobool50.not, i1 false
  %spec.select89 = select i1 %or.cond88, i32 0, i32 %grbm_soft_reset.2
  %spec.select90 = select i1 %or.cond88, i32 0, i32 %10
  %11 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 50
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 %spec.select89, ptr %11, align 8
  %13 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 51
  %14 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %spec.select90, ptr %13, align 4
  %15 = xor i1 %or.cond88, true
  ret i1 %15
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_pre_soft_reset(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %grbm_soft_reset1 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 50
  %0 = ptrtoint ptr %grbm_soft_reset1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %grbm_soft_reset1, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %tobool.not = icmp eq i32 %1, 0
  br i1 %tobool.not, label %land.lhs.true, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

land.lhs.true:                                    ; preds = %entry
  %srbm_soft_reset = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 51
  %2 = ptrtoint ptr %srbm_soft_reset to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %srbm_soft_reset, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %tobool3.not = icmp eq i32 %3, 0
  br i1 %tobool3.not, label %land.lhs.true.cleanup_crit_edge, label %land.lhs.true.if.end_crit_edge

land.lhs.true.if.end_crit_edge:                   ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

land.lhs.true.cleanup_crit_edge:                  ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %land.lhs.true.if.end_crit_edge, %entry.if.end_crit_edge
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %4 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %funcs, align 4
  %stop = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %5, i32 0, i32 8
  %6 = ptrtoint ptr %stop to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %stop, align 4
  tail call void %7(ptr noundef %handle) #12
  %8 = and i32 %1, 65537
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %8)
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %if.end.if.end12_crit_edge, label %if.then11

if.end.if.end12_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end12

if.then11:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8630, i32 noundef 0) #12
  %tmp.0.i = or i32 %call.i, 352321536
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8630, i32 noundef %tmp.0.i, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %10 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %10(i32 noundef 10737400) #12
  br label %if.end12

if.end12:                                         ; preds = %if.then11, %if.end.if.end12_crit_edge
  %11 = and i32 %1, 917505
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %if.end12.cleanup_crit_edge, label %for.cond.preheader

if.end12.cleanup_crit_edge:                       ; preds = %if.end12
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

for.cond.preheader:                               ; preds = %if.end12
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %13 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp59.not = icmp eq i32 %14, 0
  br i1 %cmp59.not, label %for.cond.preheader.for.end_crit_edge, label %for.body.lr.ph

for.cond.preheader.for.end_crit_edge:             ; preds = %for.cond.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %srbm_mutex = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 20
  br label %for.body

for.body:                                         ; preds = %for.body.for.body_crit_edge, %for.body.lr.ph
  %i.060 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body.for.body_crit_edge ]
  tail call void @mutex_lock_nested(ptr noundef %srbm_mutex, i32 noundef 0) #12
  %me = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.060, i32 16
  %15 = ptrtoint ptr %me to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %me, align 8
  %pipe = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.060, i32 17
  %17 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %pipe, align 4
  %queue = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.060, i32 18
  %19 = ptrtoint ptr %queue to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %queue, align 8
  tail call void @vi_srbm_select(ptr noundef %handle, i32 noundef %16, i32 noundef %18, i32 noundef %20, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_deactivate_hqd(ptr noundef %handle)
  tail call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %srbm_mutex) #12
  %inc = add nuw i32 %i.060, 1
  %21 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %num_compute_rings, align 8
  %cmp = icmp ult i32 %inc, %22
  br i1 %cmp, label %for.body.for.body_crit_edge, label %for.body.for.end_crit_edge

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.body.for.end_crit_edge, %for.cond.preheader.for.end_crit_edge
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8333, i32 noundef 1342177280, i32 noundef 0) #12
  %ready.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3, i32 3, i32 17
  %23 = ptrtoint ptr %ready.i to i32
  call void @__asan_store1_noabort(i32 %23)
  store i8 0, ptr %ready.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %24 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %24(i32 noundef 10737400) #12
  br label %cleanup

cleanup:                                          ; preds = %for.end, %if.end12.cleanup_crit_edge, %land.lhs.true.cleanup_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_soft_reset(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %grbm_soft_reset1 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 50
  %0 = ptrtoint ptr %grbm_soft_reset1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %grbm_soft_reset1, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %tobool.not = icmp eq i32 %1, 0
  %srbm_soft_reset3 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 51
  %2 = ptrtoint ptr %srbm_soft_reset3 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %srbm_soft_reset3, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %tobool4.not = icmp eq i32 %3, 0
  br i1 %tobool.not, label %land.lhs.true, label %entry.if.end14_crit_edge

entry.if.end14_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end14

land.lhs.true:                                    ; preds = %entry
  br i1 %tobool4.not, label %land.lhs.true.cleanup_crit_edge, label %if.end

land.lhs.true.cleanup_crit_edge:                  ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %land.lhs.true
  %4 = ptrtoint ptr %srbm_soft_reset3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %srbm_soft_reset3, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %5)
  %tobool10.not = icmp eq i32 %5, 0
  br i1 %tobool10.not, label %if.end.if.end45_crit_edge, label %if.end.if.end14_crit_edge

if.end.if.end14_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end14

if.end.if.end45_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end45

if.end14:                                         ; preds = %if.end.if.end14_crit_edge, %entry.if.end14_crit_edge
  %tobool10.not95 = phi i1 [ false, %if.end.if.end14_crit_edge ], [ %tobool4.not, %entry.if.end14_crit_edge ]
  %6 = phi i32 [ %5, %if.end.if.end14_crit_edge ], [ %3, %entry.if.end14_crit_edge ]
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 3423, i32 noundef 0) #12
  %or13 = or i32 %call, 3
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 3423, i32 noundef %or13, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %7 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %7(i32 noundef 10737400) #12
  br i1 %tobool.not, label %if.end22, label %if.then16

if.then16:                                        ; preds = %if.end14
  %call17 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8200, i32 noundef 0) #12
  %or18 = or i32 %call17, %1
  %8 = ptrtoint ptr %handle to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %handle, align 8
  tail call void (ptr, ptr, ...) @_dev_info(ptr noundef %9, ptr noundef nonnull @.str.94, i32 noundef %or18) #15
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8200, i32 noundef %or18, i32 noundef 0) #12
  %call19 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8200, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %10 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %10(i32 noundef 10737400) #12
  %neg = xor i32 %1, -1
  %and20 = and i32 %call19, %neg
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 8200, i32 noundef %and20, i32 noundef 0) #12
  %call21 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 8200, i32 noundef 0) #12
  br i1 %tobool10.not95, label %if.then16.if.then39_crit_edge, label %if.then16.if.then24_crit_edge

if.then16.if.then24_crit_edge:                    ; preds = %if.then16
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then24

if.then16.if.then39_crit_edge:                    ; preds = %if.then16
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then39

if.end22:                                         ; preds = %if.end14
  br i1 %tobool10.not95, label %if.end22.if.end45_crit_edge, label %if.end22.if.then24_crit_edge

if.end22.if.then24_crit_edge:                     ; preds = %if.end22
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then24

if.end22.if.end45_crit_edge:                      ; preds = %if.end22
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end45

if.then24:                                        ; preds = %if.end22.if.then24_crit_edge, %if.then16.if.then24_crit_edge
  %call25 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 920, i32 noundef 0) #12
  %or26 = or i32 %call25, %6
  %11 = ptrtoint ptr %handle to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %handle, align 8
  tail call void (ptr, ptr, ...) @_dev_info(ptr noundef %12, ptr noundef nonnull @.str.98, i32 noundef %or26) #15
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 920, i32 noundef %or26, i32 noundef 0) #12
  %call31 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 920, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %13 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %13(i32 noundef 10737400) #12
  %neg32 = xor i32 %6, -1
  %and33 = and i32 %call31, %neg32
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 920, i32 noundef %and33, i32 noundef 0) #12
  %call34 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 920, i32 noundef 0) #12
  br label %if.then39

if.then39:                                        ; preds = %if.then24, %if.then16.if.then39_crit_edge
  %call40 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 3423, i32 noundef 0) #12
  %and43 = and i32 %call40, -4
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 3423, i32 noundef %and43, i32 noundef 0) #12
  br label %if.end45

if.end45:                                         ; preds = %if.then39, %if.end22.if.end45_crit_edge, %if.end.if.end45_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %14 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %14(i32 noundef 10737400) #12
  br label %cleanup

cleanup:                                          ; preds = %if.end45, %land.lhs.true.cleanup_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_post_soft_reset(ptr noundef %handle) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %grbm_soft_reset1 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 50
  %0 = ptrtoint ptr %grbm_soft_reset1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %grbm_soft_reset1, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %tobool.not = icmp eq i32 %1, 0
  br i1 %tobool.not, label %land.lhs.true, label %if.end

land.lhs.true:                                    ; preds = %entry
  %srbm_soft_reset = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 51
  %2 = ptrtoint ptr %srbm_soft_reset to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %srbm_soft_reset, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %tobool3.not = icmp eq i32 %3, 0
  br i1 %tobool3.not, label %land.lhs.true.cleanup_crit_edge, label %land.lhs.true.if.end34_crit_edge

land.lhs.true.if.end34_crit_edge:                 ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34

land.lhs.true.cleanup_crit_edge:                  ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %4 = and i32 %1, 917505
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %4)
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %if.end.if.end24_crit_edge, label %for.cond.preheader

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end24

for.cond.preheader:                               ; preds = %if.end
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %6 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %7)
  %cmp65.not = icmp eq i32 %7, 0
  br i1 %cmp65.not, label %for.cond.preheader.for.end_crit_edge, label %for.body.lr.ph

for.cond.preheader.for.end_crit_edge:             ; preds = %for.cond.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %srbm_mutex = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 20
  br label %for.body

for.body:                                         ; preds = %for.body.for.body_crit_edge, %for.body.lr.ph
  %i.066 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body.for.body_crit_edge ]
  tail call void @mutex_lock_nested(ptr noundef %srbm_mutex, i32 noundef 0) #12
  %me = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.066, i32 16
  %8 = ptrtoint ptr %me to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %me, align 8
  %pipe = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.066, i32 17
  %10 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %pipe, align 4
  %queue = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.066, i32 18
  %12 = ptrtoint ptr %queue to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %queue, align 8
  tail call void @vi_srbm_select(ptr noundef %handle, i32 noundef %9, i32 noundef %11, i32 noundef %13, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_deactivate_hqd(ptr noundef %handle)
  tail call void @vi_srbm_select(ptr noundef %handle, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %srbm_mutex) #12
  %inc = add nuw i32 %i.066, 1
  %14 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %num_compute_rings, align 8
  %cmp = icmp ult i32 %inc, %15
  br i1 %cmp, label %for.body.for.body_crit_edge, label %for.body.for.end_crit_edge

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.body.for.end_crit_edge, %for.cond.preheader.for.end_crit_edge
  %call22 = tail call fastcc i32 @gfx_v8_0_kiq_resume(ptr noundef %handle)
  %call23 = tail call fastcc i32 @gfx_v8_0_kcq_resume(ptr noundef %handle)
  br label %if.end24

if.end24:                                         ; preds = %for.end, %if.end.if.end24_crit_edge
  %16 = and i32 %1, 65537
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %16)
  %17 = icmp eq i32 %16, 0
  br i1 %17, label %if.end24.if.end34_crit_edge, label %if.then32

if.end24.if.end34_crit_edge:                      ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34

if.then32:                                        ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #14
  tail call fastcc void @gfx_v8_0_cp_gfx_resume(ptr noundef %handle)
  br label %if.end34

if.end34:                                         ; preds = %if.then32, %if.end24.if.end34_crit_edge, %land.lhs.true.if.end34_crit_edge
  %gfx_ring.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 36
  %call.i = tail call i32 @amdgpu_ring_test_helper(ptr noundef %gfx_ring.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool.not.i, label %if.end.i, label %if.end34.gfx_v8_0_cp_test_all_rings.exit_crit_edge

if.end34.gfx_v8_0_cp_test_all_rings.exit_crit_edge: ; preds = %if.end34
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_cp_test_all_rings.exit

if.end.i:                                         ; preds = %if.end34
  %ring2.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 7, i32 3
  %call3.i = tail call i32 @amdgpu_ring_test_helper(ptr noundef %ring2.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call3.i)
  %tobool4.not.i = icmp eq i32 %call3.i, 0
  br i1 %tobool4.not.i, label %for.cond.preheader.i, label %if.end.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge

if.end.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge: ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_cp_test_all_rings.exit

for.cond.preheader.i:                             ; preds = %if.end.i
  %num_compute_rings.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 39
  %18 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %num_compute_rings.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %19)
  %cmp23.not.i = icmp eq i32 %19, 0
  br i1 %cmp23.not.i, label %for.cond.preheader.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge, label %for.cond.preheader.i.for.body.i_crit_edge

for.cond.preheader.i.for.body.i_crit_edge:        ; preds = %for.cond.preheader.i
  br label %for.body.i

for.cond.preheader.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge: ; preds = %for.cond.preheader.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_cp_test_all_rings.exit

for.body.i:                                       ; preds = %for.body.i.for.body.i_crit_edge, %for.cond.preheader.i.for.body.i_crit_edge
  %i.024.i = phi i32 [ %inc.i, %for.body.i.for.body.i_crit_edge ], [ 0, %for.cond.preheader.i.for.body.i_crit_edge ]
  %arrayidx9.i = getelementptr %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 38, i32 %i.024.i
  %call10.i = tail call i32 @amdgpu_ring_test_helper(ptr noundef %arrayidx9.i) #12
  %inc.i = add nuw i32 %i.024.i, 1
  %20 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %num_compute_rings.i, align 8
  %cmp.i = icmp ult i32 %inc.i, %21
  br i1 %cmp.i, label %for.body.i.for.body.i_crit_edge, label %for.body.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge

for.body.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge: ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_cp_test_all_rings.exit

for.body.i.for.body.i_crit_edge:                  ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

gfx_v8_0_cp_test_all_rings.exit:                  ; preds = %for.body.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge, %for.cond.preheader.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge, %if.end.i.gfx_v8_0_cp_test_all_rings.exit_crit_edge, %if.end34.gfx_v8_0_cp_test_all_rings.exit_crit_edge
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 106, i32 2, i32 15
  %22 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %funcs, align 4
  %start = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %23, i32 0, i32 10
  %24 = ptrtoint ptr %start to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %start, align 4
  tail call void %25(ptr noundef %handle) #12
  br label %cleanup

cleanup:                                          ; preds = %gfx_v8_0_cp_test_all_rings.exit, %land.lhs.true.cleanup_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_clockgating_state(ptr noundef %handle, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 132
  %0 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %virt, align 8
  %and = and i32 %1, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %2 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %asic_type, align 8
  %4 = zext i32 %3 to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.108)
  switch i32 %3, label %if.end.cleanup_crit_edge [
    i32 12, label %if.end.sw.bb_crit_edge
    i32 13, label %if.end.sw.bb_crit_edge38
    i32 14, label %if.end.sw.bb_crit_edge39
    i32 11, label %sw.bb1
    i32 15, label %if.end.sw.bb3_crit_edge
    i32 16, label %if.end.sw.bb3_crit_edge40
    i32 17, label %if.end.sw.bb3_crit_edge41
    i32 18, label %if.end.sw.bb3_crit_edge42
  ]

if.end.sw.bb3_crit_edge42:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb3

if.end.sw.bb3_crit_edge41:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb3

if.end.sw.bb3_crit_edge40:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb3

if.end.sw.bb3_crit_edge:                          ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb3

if.end.sw.bb_crit_edge39:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb

if.end.sw.bb_crit_edge38:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb

if.end.sw.bb_crit_edge:                           ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb

if.end.cleanup_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.bb:                                            ; preds = %if.end.sw.bb_crit_edge, %if.end.sw.bb_crit_edge38, %if.end.sw.bb_crit_edge39
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %state)
  %cmp = icmp eq i32 %state, 0
  br i1 %cmp, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %sw.bb
  call void @__sanitizer_cov_trace_pc() #14
  tail call fastcc void @gfx_v8_0_update_medium_grain_clock_gating(ptr noundef %handle, i1 noundef zeroext true) #12
  tail call fastcc void @gfx_v8_0_update_coarse_grain_clock_gating(ptr noundef %handle, i1 noundef zeroext true) #12
  br label %cleanup

if.else.i:                                        ; preds = %sw.bb
  call void @__sanitizer_cov_trace_pc() #14
  tail call fastcc void @gfx_v8_0_update_coarse_grain_clock_gating(ptr noundef %handle, i1 noundef zeroext false) #12
  tail call fastcc void @gfx_v8_0_update_medium_grain_clock_gating(ptr noundef %handle, i1 noundef zeroext false) #12
  br label %cleanup

sw.bb1:                                           ; preds = %if.end
  %cg_flags.i = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 99
  %5 = ptrtoint ptr %cg_flags.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %cg_flags.i, align 8
  %and.i = and i32 %6, 12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i)
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %sw.bb1.if.end16.i_crit_edge, label %if.then.i11

sw.bb1.if.end16.i_crit_edge:                      ; preds = %sw.bb1
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end16.i

if.then.i11:                                      ; preds = %sw.bb1
  call void @__sanitizer_cov_trace_pc() #14
  %and2.i = shl i32 %6, 2
  %7 = lshr i32 %6, 2
  %8 = and i32 %7, 3
  %9 = and i32 %and2.i, 48
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp.i = icmp eq i32 %state, 1
  %pp_state.2.i = select i1 %cmp.i, i32 0, i32 %8
  %or13.i = or i32 %9, %pp_state.2.i
  %or15.i = or i32 %or13.i, 268435712
  %call.i = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %or15.i) #12
  br label %if.end16.i

if.end16.i:                                       ; preds = %if.then.i11, %sw.bb1.if.end16.i_crit_edge
  %pp_state.3.i = phi i32 [ %pp_state.2.i, %if.then.i11 ], [ 0, %sw.bb1.if.end16.i_crit_edge ]
  %pp_support_state.2.i = phi i32 [ %9, %if.then.i11 ], [ 0, %sw.bb1.if.end16.i_crit_edge ]
  %10 = ptrtoint ptr %cg_flags.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %cg_flags.i, align 8
  %and18.i = and i32 %11, 3
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and18.i)
  %tobool19.not.i = icmp eq i32 %and18.i, 0
  br i1 %tobool19.not.i, label %if.end16.i.cleanup_crit_edge, label %if.then20.i

if.end16.i.cleanup_crit_edge:                     ; preds = %if.end16.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then20.i:                                      ; preds = %if.end16.i
  call void @__sanitizer_cov_trace_pc() #14
  %and22.i = and i32 %11, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and22.i)
  %tobool23.not.i = icmp eq i32 %and22.i, 0
  %spec.select2.i = select i1 %tobool23.not.i, i32 %pp_state.3.i, i32 2
  %spec.select3.i = select i1 %tobool23.not.i, i32 %pp_support_state.2.i, i32 32
  %and27.i = and i32 %11, 1
  %12 = or i32 %spec.select2.i, %and27.i
  %13 = shl nuw nsw i32 %and27.i, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp33.i = icmp eq i32 %state, 1
  %pp_state.6.i = select i1 %cmp33.i, i32 0, i32 %12
  %14 = or i32 %13, %spec.select3.i
  %or37.i = or i32 %14, %pp_state.6.i
  %or39.i = or i32 %or37.i, 268435968
  %call40.i = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %or39.i) #12
  br label %cleanup

sw.bb3:                                           ; preds = %if.end.sw.bb3_crit_edge, %if.end.sw.bb3_crit_edge40, %if.end.sw.bb3_crit_edge41, %if.end.sw.bb3_crit_edge42
  %cg_flags.i12 = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 99
  %15 = ptrtoint ptr %cg_flags.i12 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %cg_flags.i12, align 8
  %and.i13 = and i32 %16, 12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i13)
  %tobool.not.i14 = icmp eq i32 %and.i13, 0
  br i1 %tobool.not.i14, label %sw.bb3.if.end16.i26_crit_edge, label %if.then.i21

sw.bb3.if.end16.i26_crit_edge:                    ; preds = %sw.bb3
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end16.i26

if.then.i21:                                      ; preds = %sw.bb3
  call void @__sanitizer_cov_trace_pc() #14
  %and2.i15 = shl i32 %16, 2
  %17 = lshr i32 %16, 2
  %18 = and i32 %17, 3
  %19 = and i32 %and2.i15, 48
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp.i16 = icmp eq i32 %state, 1
  %pp_state.2.i17 = select i1 %cmp.i16, i32 0, i32 %18
  %or13.i18 = or i32 %19, %pp_state.2.i17
  %or15.i19 = or i32 %or13.i18, 268435712
  %call.i20 = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %or15.i19) #12
  br label %if.end16.i26

if.end16.i26:                                     ; preds = %if.then.i21, %sw.bb3.if.end16.i26_crit_edge
  %pp_state.3.i22 = phi i32 [ %pp_state.2.i17, %if.then.i21 ], [ 0, %sw.bb3.if.end16.i26_crit_edge ]
  %pp_support_state.2.i23 = phi i32 [ %19, %if.then.i21 ], [ 0, %sw.bb3.if.end16.i26_crit_edge ]
  %20 = ptrtoint ptr %cg_flags.i12 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %cg_flags.i12, align 8
  %and18.i24 = and i32 %21, 3145728
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and18.i24)
  %tobool19.not.i25 = icmp eq i32 %and18.i24, 0
  br i1 %tobool19.not.i25, label %if.end16.i26.if.end41.i_crit_edge, label %if.then20.i37

if.end16.i26.if.end41.i_crit_edge:                ; preds = %if.end16.i26
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end41.i

if.then20.i37:                                    ; preds = %if.end16.i26
  call void @__sanitizer_cov_trace_pc() #14
  %and22.i27 = and i32 %21, 2097152
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and22.i27)
  %tobool23.not.i28 = icmp eq i32 %and22.i27, 0
  %spec.select2.i29 = select i1 %tobool23.not.i28, i32 %pp_state.3.i22, i32 2
  %spec.select3.i30 = select i1 %tobool23.not.i28, i32 %pp_support_state.2.i23, i32 32
  %and27.i31 = and i32 %21, 1048576
  %22 = lshr exact i32 %and27.i31, 20
  %23 = or i32 %spec.select2.i29, %22
  %24 = lshr exact i32 %and27.i31, 16
  %25 = or i32 %spec.select3.i30, %24
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp33.i32 = icmp eq i32 %state, 1
  %pp_state.6.i33 = select i1 %cmp33.i32, i32 0, i32 %23
  %or37.i34 = or i32 %25, %pp_state.6.i33
  %or39.i35 = or i32 %or37.i34, 268436480
  %call40.i36 = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %or39.i35) #12
  br label %if.end41.i

if.end41.i:                                       ; preds = %if.then20.i37, %if.end16.i26.if.end41.i_crit_edge
  %pp_state.7.i = phi i32 [ %pp_state.6.i33, %if.then20.i37 ], [ %pp_state.3.i22, %if.end16.i26.if.end41.i_crit_edge ]
  %pp_support_state.5.i = phi i32 [ %25, %if.then20.i37 ], [ %pp_support_state.2.i23, %if.end16.i26.if.end41.i_crit_edge ]
  %26 = ptrtoint ptr %cg_flags.i12 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cg_flags.i12, align 8
  %and43.i = and i32 %27, 3
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and43.i)
  %tobool44.not.i = icmp eq i32 %and43.i, 0
  br i1 %tobool44.not.i, label %if.end41.i.if.end66.i_crit_edge, label %if.then45.i

if.end41.i.if.end66.i_crit_edge:                  ; preds = %if.end41.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end66.i

if.then45.i:                                      ; preds = %if.end41.i
  call void @__sanitizer_cov_trace_pc() #14
  %and47.i = and i32 %27, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and47.i)
  %tobool48.not.i = icmp eq i32 %and47.i, 0
  %spec.select4.i = select i1 %tobool48.not.i, i32 %pp_state.7.i, i32 2
  %spec.select5.i = select i1 %tobool48.not.i, i32 %pp_support_state.5.i, i32 32
  %and52.i = and i32 %27, 1
  %28 = or i32 %spec.select4.i, %and52.i
  %29 = shl nuw nsw i32 %and52.i, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp58.i = icmp eq i32 %state, 1
  %pp_state.10.i = select i1 %cmp58.i, i32 0, i32 %28
  %30 = or i32 %29, %spec.select5.i
  %or62.i = or i32 %30, %pp_state.10.i
  %or64.i = or i32 %or62.i, 268435968
  %call65.i = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %or64.i) #12
  br label %if.end66.i

if.end66.i:                                       ; preds = %if.then45.i, %if.end41.i.if.end66.i_crit_edge
  %31 = ptrtoint ptr %cg_flags.i12 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %cg_flags.i12, align 8
  %and68.i = and i32 %32, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and68.i)
  %tobool69.not.i = icmp eq i32 %and68.i, 0
  br i1 %tobool69.not.i, label %if.end66.i.if.end79.i_crit_edge, label %if.then70.i

if.end66.i.if.end79.i_crit_edge:                  ; preds = %if.end66.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end79.i

if.then70.i:                                      ; preds = %if.end66.i
  call void @__sanitizer_cov_trace_pc() #14
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp71.i = icmp eq i32 %state, 1
  %..i = select i1 %cmp71.i, i32 268437536, i32 268437538
  %call78.i = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %..i) #12
  br label %if.end79.i

if.end79.i:                                       ; preds = %if.then70.i, %if.end66.i.if.end79.i_crit_edge
  %33 = ptrtoint ptr %cg_flags.i12 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %cg_flags.i12, align 8
  %and81.i = and i32 %34, 64
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and81.i)
  %tobool82.not.i = icmp eq i32 %and81.i, 0
  br i1 %tobool82.not.i, label %if.end79.i.cleanup_crit_edge, label %if.then83.i

if.end79.i.cleanup_crit_edge:                     ; preds = %if.end79.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then83.i:                                      ; preds = %if.end79.i
  call void @__sanitizer_cov_trace_pc() #14
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %state)
  %cmp84.i = icmp eq i32 %state, 1
  %.6.i = select i1 %cmp84.i, i32 268439584, i32 268439586
  %call92.i = tail call i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef %handle, i32 noundef %.6.i) #12
  br label %cleanup

cleanup:                                          ; preds = %if.then83.i, %if.end79.i.cleanup_crit_edge, %if.then20.i, %if.end16.i.cleanup_crit_edge, %if.else.i, %if.then.i, %if.end.cleanup_crit_edge, %entry.cleanup_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_powergating_state(ptr noundef %handle, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %state)
  %cmp = icmp eq i32 %state, 0
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 132
  %0 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %virt, align 8
  %and = and i32 %1, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %pg_flags = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 100
  %2 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pg_flags, align 4
  %and1 = and i32 %3, 166
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and1)
  %tobool2.not = icmp eq i32 %and1, 0
  br i1 %tobool2.not, label %if.end.if.end4_crit_edge, label %if.then3

if.end.if.end4_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end4

if.then3:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_gfx_rlc_enter_safe_mode(ptr noundef %handle) #12
  br label %if.end4

if.end4:                                          ; preds = %if.then3, %if.end.if.end4_crit_edge
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 5
  %4 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %asic_type, align 8
  %6 = zext i32 %5 to i64
  call void @__sanitizer_cov_trace_switch(i64 %6, ptr @__sancov_gen_cov_switch_values.109)
  switch i32 %5, label %if.end4.sw.epilog_crit_edge [
    i32 13, label %if.end4.sw.bb_crit_edge
    i32 14, label %if.end4.sw.bb_crit_edge163
    i32 16, label %if.end4.sw.bb32_crit_edge
    i32 17, label %if.end4.sw.bb32_crit_edge164
    i32 18, label %if.end4.sw.bb32_crit_edge165
  ]

if.end4.sw.bb32_crit_edge165:                     ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb32

if.end4.sw.bb32_crit_edge164:                     ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb32

if.end4.sw.bb32_crit_edge:                        ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb32

if.end4.sw.bb_crit_edge163:                       ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb

if.end4.sw.bb_crit_edge:                          ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb

if.end4.sw.epilog_crit_edge:                      ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb:                                            ; preds = %if.end4.sw.bb_crit_edge, %if.end4.sw.bb_crit_edge163
  %7 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %pg_flags, align 4
  %and6 = and i32 %8, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and6)
  %tobool7.not = icmp eq i32 %and6, 0
  %call.i108 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  br i1 %tobool7.not, label %if.else, label %if.then8

if.then8:                                         ; preds = %sw.bb
  call void @__sanitizer_cov_trace_pc() #14
  %or.i = or i32 %call.i108, 131072
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %or.i, i32 noundef 0) #12
  %call.i105 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %or.i107 = or i32 %call.i105, 262144
  br label %if.end9

if.else:                                          ; preds = %sw.bb
  call void @__sanitizer_cov_trace_pc() #14
  %and.i109 = and i32 %call.i108, -131073
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i109, i32 noundef 0) #12
  %call.i110 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i111 = and i32 %call.i110, -262145
  br label %if.end9

if.end9:                                          ; preds = %if.else, %if.then8
  %and.i111.sink = phi i32 [ %and.i111, %if.else ], [ %or.i107, %if.then8 ]
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i111.sink, i32 noundef 0) #12
  %9 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %pg_flags, align 4
  %call.i114 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i113 = and i32 %call.i114, -32769
  %and11 = shl i32 %10, 10
  %11 = and i32 %and11, 32768
  %12 = or i32 %11, %and.i113
  %or.i116.sink = xor i32 %12, 32768
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %or.i116.sink, i32 noundef 0) #12
  %13 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %pg_flags, align 4
  %and.i117 = and i32 %14, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i117)
  %tobool.not.i = icmp ne i32 %and.i117, 0
  %15 = and i1 %cmp, %tobool.not.i
  %call.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  br i1 %15, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %if.end9
  %or.i.i = or i32 %call.i.i, 1
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %or.i.i, i32 noundef 0) #12
  %16 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %pg_flags, align 4
  %and3.i = and i32 %17, 4096
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and3.i)
  %tobool4.not.i = icmp eq i32 %and3.i, 0
  br i1 %tobool4.not.i, label %if.then.i.cz_update_gfx_cg_power_gating.exit_crit_edge, label %if.then5.i

if.then.i.cz_update_gfx_cg_power_gating.exit_crit_edge: ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %cz_update_gfx_cg_power_gating.exit

if.then5.i:                                       ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  %call.i12.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %or.i14.i = or i32 %call.i12.i, 16
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %or.i14.i, i32 noundef 0) #12
  br label %cz_update_gfx_cg_power_gating.exit

if.else.i:                                        ; preds = %if.end9
  call void @__sanitizer_cov_trace_pc() #14
  %and.i16.i = and i32 %call.i.i, -2
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i16.i, i32 noundef 0) #12
  %call.i17.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i18.i = and i32 %call.i17.i, -17
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i18.i, i32 noundef 0) #12
  %call2.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 40960, i32 noundef 0) #12
  br label %cz_update_gfx_cg_power_gating.exit

cz_update_gfx_cg_power_gating.exit:               ; preds = %if.else.i, %if.then5.i, %if.then.i.cz_update_gfx_cg_power_gating.exit_crit_edge
  %18 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %pg_flags, align 4
  %and18 = and i32 %19, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and18)
  %tobool19.not = icmp ne i32 %and18, 0
  %20 = and i1 %cmp, %tobool19.not
  %21 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %asic_type, align 8
  %.off.i = add i32 %22, -16
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %.off.i)
  %switch.i = icmp ult i32 %.off.i, 3
  br i1 %20, label %if.then21, label %if.else22

if.then21:                                        ; preds = %cz_update_gfx_cg_power_gating.exit
  br i1 %switch.i, label %if.then.i119, label %if.then21.gfx_v8_0_enable_gfx_static_mg_power_gating.exit_crit_edge

if.then21.gfx_v8_0_enable_gfx_static_mg_power_gating.exit_crit_edge: ; preds = %if.then21
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit

if.then.i119:                                     ; preds = %if.then21
  call void @__sanitizer_cov_trace_pc() #14
  %call.i118 = tail call i32 @amdgpu_dpm_set_powergating_by_smu(ptr noundef %handle, i32 noundef 6, i1 noundef zeroext true) #12
  br label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit

gfx_v8_0_enable_gfx_static_mg_power_gating.exit:  ; preds = %if.then.i119, %if.then21.gfx_v8_0_enable_gfx_static_mg_power_gating.exit_crit_edge
  %call6.i = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %or.i121 = or i32 %call6.i, 8
  br label %if.end23

if.else22:                                        ; preds = %cz_update_gfx_cg_power_gating.exit
  br i1 %switch.i, label %if.then.i126, label %if.else22.gfx_v8_0_enable_gfx_static_mg_power_gating.exit129_crit_edge

if.else22.gfx_v8_0_enable_gfx_static_mg_power_gating.exit129_crit_edge: ; preds = %if.else22
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit129

if.then.i126:                                     ; preds = %if.else22
  call void @__sanitizer_cov_trace_pc() #14
  %call.i125 = tail call i32 @amdgpu_dpm_set_powergating_by_smu(ptr noundef %handle, i32 noundef 6, i1 noundef zeroext false) #12
  br label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit129

gfx_v8_0_enable_gfx_static_mg_power_gating.exit129: ; preds = %if.then.i126, %if.else22.gfx_v8_0_enable_gfx_static_mg_power_gating.exit129_crit_edge
  %call6.i127 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i128 = and i32 %call6.i127, -9
  br label %if.end23

if.end23:                                         ; preds = %gfx_v8_0_enable_gfx_static_mg_power_gating.exit129, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit
  %and.i128.sink = phi i32 [ %and.i128, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit129 ], [ %or.i121, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit ]
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i128.sink, i32 noundef 0) #12
  %23 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %pg_flags, align 4
  %and25 = and i32 %24, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and25)
  %tobool26.not = icmp ne i32 %and25, 0
  %25 = and i1 %cmp, %tobool26.not
  %call.i130 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  br i1 %25, label %if.then29, label %if.else30

if.then29:                                        ; preds = %if.end23
  call void @__sanitizer_cov_trace_pc() #14
  %or.i132 = or i32 %call.i130, 4
  br label %sw.epilog.sink.split

if.else30:                                        ; preds = %if.end23
  call void @__sanitizer_cov_trace_pc() #14
  %and.i134 = and i32 %call.i130, -5
  br label %sw.epilog.sink.split

sw.bb32:                                          ; preds = %if.end4.sw.bb32_crit_edge, %if.end4.sw.bb32_crit_edge164, %if.end4.sw.bb32_crit_edge165
  %26 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %pg_flags, align 4
  %and34 = and i32 %27, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and34)
  %tobool35.not = icmp ne i32 %and34, 0
  %28 = and i1 %cmp, %tobool35.not
  br i1 %28, label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit143, label %gfx_v8_0_enable_gfx_static_mg_power_gating.exit151

gfx_v8_0_enable_gfx_static_mg_power_gating.exit143: ; preds = %sw.bb32
  call void @__sanitizer_cov_trace_pc() #14
  %call.i138 = tail call i32 @amdgpu_dpm_set_powergating_by_smu(ptr noundef %handle, i32 noundef 6, i1 noundef zeroext true) #12
  %call6.i140 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %or.i142 = or i32 %call6.i140, 8
  br label %if.end40

gfx_v8_0_enable_gfx_static_mg_power_gating.exit151: ; preds = %sw.bb32
  call void @__sanitizer_cov_trace_pc() #14
  %call.i147 = tail call i32 @amdgpu_dpm_set_powergating_by_smu(ptr noundef %handle, i32 noundef 6, i1 noundef zeroext false) #12
  %call6.i149 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i150 = and i32 %call6.i149, -9
  br label %if.end40

if.end40:                                         ; preds = %gfx_v8_0_enable_gfx_static_mg_power_gating.exit151, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit143
  %and.i150.sink = phi i32 [ %and.i150, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit151 ], [ %or.i142, %gfx_v8_0_enable_gfx_static_mg_power_gating.exit143 ]
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i150.sink, i32 noundef 0) #12
  %29 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %pg_flags, align 4
  %and42 = and i32 %30, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and42)
  %tobool43.not = icmp ne i32 %and42, 0
  %31 = and i1 %cmp, %tobool43.not
  %call.i152 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  %and.i156 = and i32 %call.i152, -5
  %masksel = select i1 %31, i32 4, i32 0
  %and.i156.sink = or i32 %and.i156, %masksel
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %and.i156.sink, i32 noundef 0) #12
  %32 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %pg_flags, align 4
  %and50 = and i32 %33, 2048
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and50)
  %tobool51.not = icmp ne i32 %and50, 0
  %34 = and i1 %cmp, %tobool51.not
  %call.i157 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60483, i32 noundef 0) #12
  br i1 %34, label %if.then54, label %if.else55

if.then54:                                        ; preds = %if.end40
  call void @__sanitizer_cov_trace_pc() #14
  %or.i159 = or i32 %call.i157, 1048576
  br label %sw.epilog.sink.split

if.else55:                                        ; preds = %if.end40
  call void @__sanitizer_cov_trace_pc() #14
  %and.i161 = and i32 %call.i157, -1048577
  br label %sw.epilog.sink.split

sw.epilog.sink.split:                             ; preds = %if.else55, %if.then54, %if.else30, %if.then29
  %or.i159.sink = phi i32 [ %or.i159, %if.then54 ], [ %and.i161, %if.else55 ], [ %or.i132, %if.then29 ], [ %and.i134, %if.else30 ]
  tail call void @amdgpu_device_wreg(ptr noundef %handle, i32 noundef 60483, i32 noundef %or.i159.sink, i32 noundef 0) #12
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.epilog.sink.split, %if.end4.sw.epilog_crit_edge
  %35 = ptrtoint ptr %pg_flags to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %pg_flags, align 4
  %and58 = and i32 %36, 166
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and58)
  %tobool59.not = icmp eq i32 %and58, 0
  br i1 %tobool59.not, label %sw.epilog.cleanup_crit_edge, label %if.then60

sw.epilog.cleanup_crit_edge:                      ; preds = %sw.epilog
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then60:                                        ; preds = %sw.epilog
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_gfx_rlc_exit_safe_mode(ptr noundef %handle) #12
  br label %cleanup

cleanup:                                          ; preds = %if.then60, %sw.epilog.cleanup_crit_edge, %entry.cleanup_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_get_clockgating_state(ptr noundef %handle, ptr nocapture noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %handle, i32 0, i32 132
  %0 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %virt, align 8
  %and = and i32 %1, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %if.then

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %2 = ptrtoint ptr %flags to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 0, ptr %flags, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60488, i32 noundef 0) #12
  %and1 = and i32 %call, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and1)
  %tobool2.not = icmp eq i32 %and1, 0
  br i1 %tobool2.not, label %if.then3, label %if.end.if.end4_crit_edge

if.end.if.end4_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end4

if.then3:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %3 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %flags, align 4
  %or = or i32 %4, 1
  store i32 %or, ptr %flags, align 4
  br label %if.end4

if.end4:                                          ; preds = %if.then3, %if.end.if.end4_crit_edge
  %call5 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60489, i32 noundef 0) #12
  %and6 = and i32 %call5, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and6)
  %tobool7.not = icmp eq i32 %and6, 0
  br i1 %tobool7.not, label %if.end4.if.end10_crit_edge, label %if.then8

if.end4.if.end10_crit_edge:                       ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end10

if.then8:                                         ; preds = %if.end4
  call void @__sanitizer_cov_trace_pc() #14
  %5 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %flags, align 4
  %or9 = or i32 %6, 4
  store i32 %or9, ptr %flags, align 4
  br label %if.end10

if.end10:                                         ; preds = %if.then8, %if.end4.if.end10_crit_edge
  %and11 = and i32 %call5, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and11)
  %tobool12.not = icmp eq i32 %and11, 0
  br i1 %tobool12.not, label %if.end10.if.end15_crit_edge, label %if.then13

if.end10.if.end15_crit_edge:                      ; preds = %if.end10
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end15

if.then13:                                        ; preds = %if.end10
  call void @__sanitizer_cov_trace_pc() #14
  %7 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %flags, align 4
  %or14 = or i32 %8, 8
  store i32 %or14, ptr %flags, align 4
  br label %if.end15

if.end15:                                         ; preds = %if.then13, %if.end10.if.end15_crit_edge
  %call16 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 61440, i32 noundef 0) #12
  %and17 = and i32 %call16, 2097152
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and17)
  %tobool18.not = icmp eq i32 %and17, 0
  br i1 %tobool18.not, label %if.then19, label %if.end15.if.end21_crit_edge

if.end15.if.end21_crit_edge:                      ; preds = %if.end15
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end21

if.then19:                                        ; preds = %if.end15
  call void @__sanitizer_cov_trace_pc() #14
  %9 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %flags, align 4
  %or20 = or i32 %10, 16
  store i32 %or20, ptr %flags, align 4
  br label %if.end21

if.end21:                                         ; preds = %if.then19, %if.end15.if.end21_crit_edge
  %and22 = and i32 %call16, 4194304
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and22)
  %tobool23.not = icmp eq i32 %and22, 0
  br i1 %tobool23.not, label %if.then24, label %if.end21.if.end26_crit_edge

if.end21.if.end26_crit_edge:                      ; preds = %if.end21
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end26

if.then24:                                        ; preds = %if.end21
  call void @__sanitizer_cov_trace_pc() #14
  %11 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %flags, align 4
  %or25 = or i32 %12, 32
  store i32 %or25, ptr %flags, align 4
  br label %if.end26

if.end26:                                         ; preds = %if.then24, %if.end21.if.end26_crit_edge
  %call27 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 60422, i32 noundef 0) #12
  %and28 = and i32 %call27, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and28)
  %tobool29.not = icmp eq i32 %and28, 0
  br i1 %tobool29.not, label %if.end26.if.end32_crit_edge, label %if.then30

if.end26.if.end32_crit_edge:                      ; preds = %if.end26
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end32

if.then30:                                        ; preds = %if.end26
  call void @__sanitizer_cov_trace_pc() #14
  %13 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %flags, align 4
  %or31 = or i32 %14, 130
  store i32 %or31, ptr %flags, align 4
  br label %if.end32

if.end32:                                         ; preds = %if.then30, %if.end26.if.end32_crit_edge
  %call33 = tail call i32 @amdgpu_device_rreg(ptr noundef %handle, i32 noundef 12409, i32 noundef 0) #12
  %and34 = and i32 %call33, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and34)
  %tobool35.not = icmp eq i32 %and34, 0
  br i1 %tobool35.not, label %if.end32.if.end38_crit_edge, label %if.then36

if.end32.if.end38_crit_edge:                      ; preds = %if.end32
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end38

if.then36:                                        ; preds = %if.end32
  call void @__sanitizer_cov_trace_pc() #14
  %15 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %flags, align 4
  %or37 = or i32 %16, 66
  store i32 %or37, ptr %flags, align 4
  br label %if.end38

if.end38:                                         ; preds = %if.then36, %if.end32.if.end38_crit_edge
  ret void
}

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #1

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_get_num_kcq(ptr noundef) local_unnamed_addr #2

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #1

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i64 @gfx_v8_0_get_gpu_clock_counter(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %gfx = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106
  tail call void @mutex_lock_nested(ptr noundef %gfx, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60454, i32 noundef 1, i32 noundef 0) #12
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60452, i32 noundef 0) #12
  %conv = zext i32 %call to i64
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60453, i32 noundef 0) #12
  %conv2 = zext i32 %call1 to i64
  %shl = shl nuw i64 %conv2, 32
  %or = or i64 %shl, %conv
  tail call void @mutex_unlock(ptr noundef %gfx) #12
  ret i64 %or
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_select_se_sh(ptr noundef %adev, i32 noundef %se_num, i32 noundef %sh_num, i32 noundef %instance) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %instance)
  %cmp = icmp eq i32 %instance, -1
  %and = and i32 %instance, 255
  %data.0 = select i1 %cmp, i32 1073741824, i32 %and
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %se_num)
  %cmp1 = icmp eq i32 %se_num, -1
  %shl7 = shl i32 %se_num, 16
  %and8 = and i32 %shl7, 16711680
  %data.1.v = select i1 %cmp1, i32 -2147483648, i32 %and8
  %data.1 = or i32 %data.0, %data.1.v
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %sh_num)
  %cmp11 = icmp eq i32 %sh_num, -1
  %shl17 = shl i32 %sh_num, 8
  %and18 = and i32 %shl17, 65280
  %data.2.v = select i1 %cmp11, i32 536870912, i32 %and18
  %data.2 = or i32 %data.1, %data.2.v
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef %data.2, i32 noundef 0) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_read_wave_data(ptr noundef %adev, i32 noundef %simd, i32 noundef %wave, ptr nocapture noundef writeonly %dst, ptr noundef %no_fields) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %no_fields, align 4
  %inc = add i32 %1, 1
  store i32 %inc, ptr %no_fields, align 4
  %arrayidx = getelementptr i32, ptr %dst, i32 %1
  %2 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 0, ptr %arrayidx, align 4
  %shl1.i = shl i32 %simd, 4
  %or.i = or i32 %shl1.i, %wave
  %or4.i = or i32 %or.i, 1187840
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i, i32 noundef 0) #12
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %3 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %no_fields, align 4
  %inc1 = add i32 %4, 1
  store i32 %inc1, ptr %no_fields, align 4
  %arrayidx2 = getelementptr i32, ptr %dst, i32 %4
  %5 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 %call.i, ptr %arrayidx2, align 4
  %or4.i152 = or i32 %or.i, 1581056
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i152, i32 noundef 0) #12
  %call.i153 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %6 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %no_fields, align 4
  %inc4 = add i32 %7, 1
  store i32 %inc4, ptr %no_fields, align 4
  %arrayidx5 = getelementptr i32, ptr %dst, i32 %7
  %8 = ptrtoint ptr %arrayidx5 to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 %call.i153, ptr %arrayidx5, align 4
  %or4.i157 = or i32 %or.i, 1646592
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i157, i32 noundef 0) #12
  %call.i158 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %9 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %no_fields, align 4
  %inc7 = add i32 %10, 1
  store i32 %inc7, ptr %no_fields, align 4
  %arrayidx8 = getelementptr i32, ptr %dst, i32 %10
  %11 = ptrtoint ptr %arrayidx8 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 %call.i158, ptr %arrayidx8, align 4
  %or4.i162 = or i32 %or.i, 41820160
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i162, i32 noundef 0) #12
  %call.i163 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %12 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %no_fields, align 4
  %inc10 = add i32 %13, 1
  store i32 %inc10, ptr %no_fields, align 4
  %arrayidx11 = getelementptr i32, ptr %dst, i32 %13
  %14 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %call.i163, ptr %arrayidx11, align 4
  %or4.i167 = or i32 %or.i, 41885696
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i167, i32 noundef 0) #12
  %call.i168 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %15 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %no_fields, align 4
  %inc13 = add i32 %16, 1
  store i32 %inc13, ptr %no_fields, align 4
  %arrayidx14 = getelementptr i32, ptr %dst, i32 %16
  %17 = ptrtoint ptr %arrayidx14 to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 %call.i168, ptr %arrayidx14, align 4
  %or4.i172 = or i32 %or.i, 1318912
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i172, i32 noundef 0) #12
  %call.i173 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %18 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %no_fields, align 4
  %inc16 = add i32 %19, 1
  store i32 %inc16, ptr %no_fields, align 4
  %arrayidx17 = getelementptr i32, ptr %dst, i32 %19
  %20 = ptrtoint ptr %arrayidx17 to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %call.i173, ptr %arrayidx17, align 4
  %or4.i177 = or i32 %or.i, 1712128
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i177, i32 noundef 0) #12
  %call.i178 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %21 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %no_fields, align 4
  %inc19 = add i32 %22, 1
  store i32 %inc19, ptr %no_fields, align 4
  %arrayidx20 = getelementptr i32, ptr %dst, i32 %22
  %23 = ptrtoint ptr %arrayidx20 to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %call.i178, ptr %arrayidx20, align 4
  %or4.i182 = or i32 %or.i, 1777664
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i182, i32 noundef 0) #12
  %call.i183 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %24 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %no_fields, align 4
  %inc22 = add i32 %25, 1
  store i32 %inc22, ptr %no_fields, align 4
  %arrayidx23 = getelementptr i32, ptr %dst, i32 %25
  %26 = ptrtoint ptr %arrayidx23 to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %call.i183, ptr %arrayidx23, align 4
  %or4.i187 = or i32 %or.i, 1384448
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i187, i32 noundef 0) #12
  %call.i188 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %27 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %no_fields, align 4
  %inc25 = add i32 %28, 1
  store i32 %inc25, ptr %no_fields, align 4
  %arrayidx26 = getelementptr i32, ptr %dst, i32 %28
  %29 = ptrtoint ptr %arrayidx26 to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %call.i188, ptr %arrayidx26, align 4
  %or4.i192 = or i32 %or.i, 1449984
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i192, i32 noundef 0) #12
  %call.i193 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %30 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %no_fields, align 4
  %inc28 = add i32 %31, 1
  store i32 %inc28, ptr %no_fields, align 4
  %arrayidx29 = getelementptr i32, ptr %dst, i32 %31
  %32 = ptrtoint ptr %arrayidx29 to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %call.i193, ptr %arrayidx29, align 4
  %or4.i197 = or i32 %or.i, 1253376
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i197, i32 noundef 0) #12
  %call.i198 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %33 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %no_fields, align 4
  %inc31 = add i32 %34, 1
  store i32 %inc31, ptr %no_fields, align 4
  %arrayidx32 = getelementptr i32, ptr %dst, i32 %34
  %35 = ptrtoint ptr %arrayidx32 to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 %call.i198, ptr %arrayidx32, align 4
  %or4.i202 = or i32 %or.i, 1515520
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i202, i32 noundef 0) #12
  %call.i203 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %36 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %no_fields, align 4
  %inc34 = add i32 %37, 1
  store i32 %inc34, ptr %no_fields, align 4
  %arrayidx35 = getelementptr i32, ptr %dst, i32 %37
  %38 = ptrtoint ptr %arrayidx35 to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %call.i203, ptr %arrayidx35, align 4
  %or4.i207 = or i32 %or.i, 40640512
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i207, i32 noundef 0) #12
  %call.i208 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %39 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %no_fields, align 4
  %inc37 = add i32 %40, 1
  store i32 %inc37, ptr %no_fields, align 4
  %arrayidx38 = getelementptr i32, ptr %dst, i32 %40
  %41 = ptrtoint ptr %arrayidx38 to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 %call.i208, ptr %arrayidx38, align 4
  %or4.i212 = or i32 %or.i, 40706048
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i212, i32 noundef 0) #12
  %call.i213 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %42 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %no_fields, align 4
  %inc40 = add i32 %43, 1
  store i32 %inc40, ptr %no_fields, align 4
  %arrayidx41 = getelementptr i32, ptr %dst, i32 %43
  %44 = ptrtoint ptr %arrayidx41 to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 %call.i213, ptr %arrayidx41, align 4
  %or4.i217 = or i32 %or.i, 40771584
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i217, i32 noundef 0) #12
  %call.i218 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %45 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %no_fields, align 4
  %inc43 = add i32 %46, 1
  store i32 %inc43, ptr %no_fields, align 4
  %arrayidx44 = getelementptr i32, ptr %dst, i32 %46
  %47 = ptrtoint ptr %arrayidx44 to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 %call.i218, ptr %arrayidx44, align 4
  %or4.i222 = or i32 %or.i, 40837120
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i222, i32 noundef 0) #12
  %call.i223 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %48 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %no_fields, align 4
  %inc46 = add i32 %49, 1
  store i32 %inc46, ptr %no_fields, align 4
  %arrayidx47 = getelementptr i32, ptr %dst, i32 %49
  %50 = ptrtoint ptr %arrayidx47 to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 %call.i223, ptr %arrayidx47, align 4
  %or4.i227 = or i32 %or.i, 1843200
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i227, i32 noundef 0) #12
  %call.i228 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %51 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %no_fields, align 4
  %inc49 = add i32 %52, 1
  store i32 %inc49, ptr %no_fields, align 4
  %arrayidx50 = getelementptr i32, ptr %dst, i32 %52
  %53 = ptrtoint ptr %arrayidx50 to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %call.i228, ptr %arrayidx50, align 4
  %or4.i232 = or i32 %or.i, 41689088
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i232, i32 noundef 0) #12
  %call.i233 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %54 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %no_fields, align 4
  %inc52 = add i32 %55, 1
  store i32 %inc52, ptr %no_fields, align 4
  %arrayidx53 = getelementptr i32, ptr %dst, i32 %55
  %56 = ptrtoint ptr %arrayidx53 to i32
  call void @__asan_store4_noabort(i32 %56)
  store i32 %call.i233, ptr %arrayidx53, align 4
  %or4.i237 = or i32 %or.i, 1122304
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or4.i237, i32 noundef 0) #12
  %call.i238 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %57 = ptrtoint ptr %no_fields to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %no_fields, align 4
  %inc55 = add i32 %58, 1
  store i32 %inc55, ptr %no_fields, align 4
  %arrayidx56 = getelementptr i32, ptr %dst, i32 %58
  %59 = ptrtoint ptr %arrayidx56 to i32
  call void @__asan_store4_noabort(i32 %59)
  store i32 %call.i238, ptr %arrayidx56, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_read_wave_sgprs(ptr noundef %adev, i32 noundef %simd, i32 noundef %wave, i32 noundef %start, i32 noundef %size, ptr nocapture noundef writeonly %dst) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %shl1.i = shl i32 %simd, 4
  %add = shl i32 %start, 16
  %shl2.i = add i32 %add, 33554432
  %or.i = or i32 %shl1.i, %wave
  %or3.i = or i32 %or.i, %shl2.i
  %or7.i = or i32 %or3.i, 12288
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 9080, i32 noundef %or7.i, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %size)
  %tobool.not1.i = icmp eq i32 %size, 0
  br i1 %tobool.not1.i, label %entry.wave_read_regs.exit_crit_edge, label %entry.while.body.i_crit_edge

entry.while.body.i_crit_edge:                     ; preds = %entry
  br label %while.body.i

entry.wave_read_regs.exit_crit_edge:              ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %wave_read_regs.exit

while.body.i:                                     ; preds = %while.body.i.while.body.i_crit_edge, %entry.while.body.i_crit_edge
  %out.addr.03.i = phi ptr [ %incdec.ptr.i, %while.body.i.while.body.i_crit_edge ], [ %dst, %entry.while.body.i_crit_edge ]
  %num.addr.02.i = phi i32 [ %dec.i, %while.body.i.while.body.i_crit_edge ], [ %size, %entry.while.body.i_crit_edge ]
  %dec.i = add i32 %num.addr.02.i, -1
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9081, i32 noundef 0) #12
  %incdec.ptr.i = getelementptr i32, ptr %out.addr.03.i, i32 1
  %0 = ptrtoint ptr %out.addr.03.i to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 %call.i, ptr %out.addr.03.i, align 4
  %tobool.not.i = icmp eq i32 %dec.i, 0
  br i1 %tobool.not.i, label %while.body.i.wave_read_regs.exit_crit_edge, label %while.body.i.while.body.i_crit_edge

while.body.i.while.body.i_crit_edge:              ; preds = %while.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %while.body.i

while.body.i.wave_read_regs.exit_crit_edge:       ; preds = %while.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %wave_read_regs.exit

wave_read_regs.exit:                              ; preds = %while.body.i.wave_read_regs.exit_crit_edge, %entry.wave_read_regs.exit_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_select_me_pipe_q(ptr noundef %adev, i32 noundef %me, i32 noundef %pipe, i32 noundef %q, i32 noundef %vm) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @vi_srbm_select(ptr noundef %adev, i32 noundef %me, i32 noundef %pipe, i32 noundef %q, i32 noundef %vm) #12
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_lock_nested(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_device_wreg(ptr noundef, i32 noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_device_rreg(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_unlock(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @vi_srbm_select(ptr noundef, i32 noundef, i32 noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: mustprogress nofree norecurse nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync)
define internal i64 @gfx_v8_0_ring_get_rptr(ptr nocapture noundef readonly %ring) #3 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %wb1 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %2 = ptrtoint ptr %wb1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %wb1, align 4
  %rptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 6
  %4 = ptrtoint ptr %rptr_offs to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %rptr_offs, align 8
  %arrayidx = getelementptr i32, ptr %3, i32 %5
  %6 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %arrayidx, align 4
  %conv = zext i32 %7 to i64
  ret i64 %conv
}

; Function Attrs: mustprogress nofree norecurse nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync)
define internal i64 @gfx_v8_0_ring_get_wptr_compute(ptr nocapture noundef readonly %ring) #3 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %wb1 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %2 = ptrtoint ptr %wb1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %wb1, align 4
  %wptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 26
  %4 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %wptr_offs, align 8
  %arrayidx = getelementptr i32, ptr %3, i32 %5
  %6 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %arrayidx, align 4
  %conv = zext i32 %7 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_set_wptr_compute(ptr nocapture noundef readonly %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %wptr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %2 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %2)
  %3 = load i64, ptr %wptr, align 8
  %conv = trunc i64 %3 to i32
  %wb2 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %4 = ptrtoint ptr %wb2 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %wb2, align 4
  %wptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 26
  %6 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %wptr_offs, align 8
  %arrayidx = getelementptr i32, ptr %5, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %8)
  store volatile i32 %conv, ptr %arrayidx, align 4
  %doorbell_index = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 23
  %9 = ptrtoint ptr %doorbell_index to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %doorbell_index, align 8
  %11 = load i64, ptr %wptr, align 8
  %conv5 = trunc i64 %11 to i32
  tail call void @amdgpu_mm_wdoorbell(ptr noundef %1, i32 noundef %10, i32 noundef %conv5) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_fence_kiq(ptr noundef %ring, i64 noundef %addr, i64 noundef %seq, i32 noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %and = and i32 %flags, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %do.end6, label %do.body3, !prof !435

do.body3:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 6311, 0\0A.popsection", ""() #12, !srcloc !440
  unreachable

do.end6:                                          ; preds = %entry
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %do.end6.amdgpu_ring_write.exit_crit_edge

do.end6.amdgpu_ring_write.exit_crit_edge:         ; preds = %do.end6
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %do.end6
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %do.end6.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073531136, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i28 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i28, label %if.then.i29, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit39_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit39_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit39

if.then.i29:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit39

amdgpu_ring_write.exit39:                         ; preds = %if.then.i29, %amdgpu_ring_write.exit.amdgpu_ring_write.exit39_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i32 = add i64 %18, 1
  store i64 %inc.i32, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i34 = and i32 %20, %21
  %arrayidx.i35 = getelementptr i32, ptr %16, i32 %idxprom.i34
  %22 = ptrtoint ptr %arrayidx.i35 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 1049856, ptr %arrayidx.i35, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i37 = and i64 %25, %24
  store i64 %and3.i37, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i38 = add i32 %27, -1
  store i32 %dec.i38, ptr %count_dw.i, align 8
  %conv = trunc i64 %addr to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i38)
  %cmp.i41 = icmp slt i32 %dec.i38, 1
  br i1 %cmp.i41, label %if.then.i42, label %amdgpu_ring_write.exit39.amdgpu_ring_write.exit52_crit_edge

amdgpu_ring_write.exit39.amdgpu_ring_write.exit52_crit_edge: ; preds = %amdgpu_ring_write.exit39
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit52

if.then.i42:                                      ; preds = %amdgpu_ring_write.exit39
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit52

amdgpu_ring_write.exit52:                         ; preds = %if.then.i42, %amdgpu_ring_write.exit39.amdgpu_ring_write.exit52_crit_edge
  %28 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %ring1.i, align 4
  %30 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %wptr.i, align 8
  %inc.i45 = add i64 %31, 1
  store i64 %inc.i45, ptr %wptr.i, align 8
  %32 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %buf_mask.i, align 8
  %34 = trunc i64 %31 to i32
  %idxprom.i47 = and i32 %33, %34
  %arrayidx.i48 = getelementptr i32, ptr %29, i32 %idxprom.i47
  %35 = ptrtoint ptr %arrayidx.i48 to i32
  call void @__asan_store4_noabort(i32 %35)
  store volatile i32 %conv, ptr %arrayidx.i48, align 4
  %36 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %ptr_mask.i, align 8
  %38 = load i64, ptr %wptr.i, align 8
  %and3.i50 = and i64 %38, %37
  store i64 %and3.i50, ptr %wptr.i, align 8
  %39 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %count_dw.i, align 8
  %dec.i51 = add i32 %40, -1
  store i32 %dec.i51, ptr %count_dw.i, align 8
  %shr = lshr i64 %addr, 32
  %conv9 = trunc i64 %shr to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i51)
  %cmp.i54 = icmp slt i32 %dec.i51, 1
  br i1 %cmp.i54, label %if.then.i55, label %amdgpu_ring_write.exit52.amdgpu_ring_write.exit65_crit_edge

amdgpu_ring_write.exit52.amdgpu_ring_write.exit65_crit_edge: ; preds = %amdgpu_ring_write.exit52
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit65

if.then.i55:                                      ; preds = %amdgpu_ring_write.exit52
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit65

amdgpu_ring_write.exit65:                         ; preds = %if.then.i55, %amdgpu_ring_write.exit52.amdgpu_ring_write.exit65_crit_edge
  %41 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %ring1.i, align 4
  %43 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %wptr.i, align 8
  %inc.i58 = add i64 %44, 1
  store i64 %inc.i58, ptr %wptr.i, align 8
  %45 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %buf_mask.i, align 8
  %47 = trunc i64 %44 to i32
  %idxprom.i60 = and i32 %46, %47
  %arrayidx.i61 = getelementptr i32, ptr %42, i32 %idxprom.i60
  %48 = ptrtoint ptr %arrayidx.i61 to i32
  call void @__asan_store4_noabort(i32 %48)
  store volatile i32 %conv9, ptr %arrayidx.i61, align 4
  %49 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %ptr_mask.i, align 8
  %51 = load i64, ptr %wptr.i, align 8
  %and3.i63 = and i64 %51, %50
  store i64 %and3.i63, ptr %wptr.i, align 8
  %52 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %count_dw.i, align 8
  %dec.i64 = add i32 %53, -1
  store i32 %dec.i64, ptr %count_dw.i, align 8
  %conv11 = trunc i64 %seq to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i64)
  %cmp.i67 = icmp slt i32 %dec.i64, 1
  br i1 %cmp.i67, label %if.then.i68, label %amdgpu_ring_write.exit65.amdgpu_ring_write.exit78_crit_edge

amdgpu_ring_write.exit65.amdgpu_ring_write.exit78_crit_edge: ; preds = %amdgpu_ring_write.exit65
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit78

if.then.i68:                                      ; preds = %amdgpu_ring_write.exit65
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit78

amdgpu_ring_write.exit78:                         ; preds = %if.then.i68, %amdgpu_ring_write.exit65.amdgpu_ring_write.exit78_crit_edge
  %54 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %ring1.i, align 4
  %56 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %56)
  %57 = load i64, ptr %wptr.i, align 8
  %inc.i71 = add i64 %57, 1
  store i64 %inc.i71, ptr %wptr.i, align 8
  %58 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %buf_mask.i, align 8
  %60 = trunc i64 %57 to i32
  %idxprom.i73 = and i32 %59, %60
  %arrayidx.i74 = getelementptr i32, ptr %55, i32 %idxprom.i73
  %61 = ptrtoint ptr %arrayidx.i74 to i32
  call void @__asan_store4_noabort(i32 %61)
  store volatile i32 %conv11, ptr %arrayidx.i74, align 4
  %62 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %ptr_mask.i, align 8
  %64 = load i64, ptr %wptr.i, align 8
  %and3.i76 = and i64 %64, %63
  store i64 %and3.i76, ptr %wptr.i, align 8
  %65 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %count_dw.i, align 8
  %dec.i77 = add i32 %66, -1
  store i32 %dec.i77, ptr %count_dw.i, align 8
  %and12 = and i32 %flags, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and12)
  %tobool13.not = icmp eq i32 %and12, 0
  br i1 %tobool13.not, label %amdgpu_ring_write.exit78.if.end15_crit_edge, label %if.then14

amdgpu_ring_write.exit78.if.end15_crit_edge:      ; preds = %amdgpu_ring_write.exit78
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end15

if.then14:                                        ; preds = %amdgpu_ring_write.exit78
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i77)
  %cmp.i80 = icmp slt i32 %dec.i77, 1
  br i1 %cmp.i80, label %if.then.i81, label %if.then14.amdgpu_ring_write.exit91_crit_edge

if.then14.amdgpu_ring_write.exit91_crit_edge:     ; preds = %if.then14
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit91

if.then.i81:                                      ; preds = %if.then14
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit91

amdgpu_ring_write.exit91:                         ; preds = %if.then.i81, %if.then14.amdgpu_ring_write.exit91_crit_edge
  %67 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %ring1.i, align 4
  %69 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %69)
  %70 = load i64, ptr %wptr.i, align 8
  %inc.i84 = add i64 %70, 1
  store i64 %inc.i84, ptr %wptr.i, align 8
  %71 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %buf_mask.i, align 8
  %73 = trunc i64 %70 to i32
  %idxprom.i86 = and i32 %72, %73
  %arrayidx.i87 = getelementptr i32, ptr %68, i32 %idxprom.i86
  %74 = ptrtoint ptr %arrayidx.i87 to i32
  call void @__asan_store4_noabort(i32 %74)
  store volatile i32 -1073531136, ptr %arrayidx.i87, align 4
  %75 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %75)
  %76 = load i64, ptr %ptr_mask.i, align 8
  %77 = load i64, ptr %wptr.i, align 8
  %and3.i89 = and i64 %77, %76
  store i64 %and3.i89, ptr %wptr.i, align 8
  %78 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load i32, ptr %count_dw.i, align 8
  %dec.i90 = add i32 %79, -1
  store i32 %dec.i90, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i90)
  %cmp.i93 = icmp slt i32 %dec.i90, 1
  br i1 %cmp.i93, label %if.then.i94, label %amdgpu_ring_write.exit91.amdgpu_ring_write.exit104_crit_edge

amdgpu_ring_write.exit91.amdgpu_ring_write.exit104_crit_edge: ; preds = %amdgpu_ring_write.exit91
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit104

if.then.i94:                                      ; preds = %amdgpu_ring_write.exit91
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit104

amdgpu_ring_write.exit104:                        ; preds = %if.then.i94, %amdgpu_ring_write.exit91.amdgpu_ring_write.exit104_crit_edge
  %80 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load ptr, ptr %ring1.i, align 4
  %82 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %82)
  %83 = load i64, ptr %wptr.i, align 8
  %inc.i97 = add i64 %83, 1
  store i64 %inc.i97, ptr %wptr.i, align 8
  %84 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load i32, ptr %buf_mask.i, align 8
  %86 = trunc i64 %83 to i32
  %idxprom.i99 = and i32 %85, %86
  %arrayidx.i100 = getelementptr i32, ptr %81, i32 %idxprom.i99
  %87 = ptrtoint ptr %arrayidx.i100 to i32
  call void @__asan_store4_noabort(i32 %87)
  store volatile i32 1048576, ptr %arrayidx.i100, align 4
  %88 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %88)
  %89 = load i64, ptr %ptr_mask.i, align 8
  %90 = load i64, ptr %wptr.i, align 8
  %and3.i102 = and i64 %90, %89
  store i64 %and3.i102, ptr %wptr.i, align 8
  %91 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %count_dw.i, align 8
  %dec.i103 = add i32 %92, -1
  store i32 %dec.i103, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i103)
  %cmp.i106 = icmp slt i32 %dec.i103, 1
  br i1 %cmp.i106, label %if.then.i107, label %amdgpu_ring_write.exit104.amdgpu_ring_write.exit117_crit_edge

amdgpu_ring_write.exit104.amdgpu_ring_write.exit117_crit_edge: ; preds = %amdgpu_ring_write.exit104
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit117

if.then.i107:                                     ; preds = %amdgpu_ring_write.exit104
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit117

amdgpu_ring_write.exit117:                        ; preds = %if.then.i107, %amdgpu_ring_write.exit104.amdgpu_ring_write.exit117_crit_edge
  %93 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load ptr, ptr %ring1.i, align 4
  %95 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %95)
  %96 = load i64, ptr %wptr.i, align 8
  %inc.i110 = add i64 %96, 1
  store i64 %inc.i110, ptr %wptr.i, align 8
  %97 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %97)
  %98 = load i32, ptr %buf_mask.i, align 8
  %99 = trunc i64 %96 to i32
  %idxprom.i112 = and i32 %98, %99
  %arrayidx.i113 = getelementptr i32, ptr %94, i32 %idxprom.i112
  %100 = ptrtoint ptr %arrayidx.i113 to i32
  call void @__asan_store4_noabort(i32 %100)
  store volatile i32 12469, ptr %arrayidx.i113, align 4
  %101 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %101)
  %102 = load i64, ptr %ptr_mask.i, align 8
  %103 = load i64, ptr %wptr.i, align 8
  %and3.i115 = and i64 %103, %102
  store i64 %and3.i115, ptr %wptr.i, align 8
  %104 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %104)
  %105 = load i32, ptr %count_dw.i, align 8
  %dec.i116 = add i32 %105, -1
  store i32 %dec.i116, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i116)
  %cmp.i119 = icmp slt i32 %dec.i116, 1
  br i1 %cmp.i119, label %if.then.i120, label %amdgpu_ring_write.exit117.amdgpu_ring_write.exit130_crit_edge

amdgpu_ring_write.exit117.amdgpu_ring_write.exit130_crit_edge: ; preds = %amdgpu_ring_write.exit117
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit130

if.then.i120:                                     ; preds = %amdgpu_ring_write.exit117
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit130

amdgpu_ring_write.exit130:                        ; preds = %if.then.i120, %amdgpu_ring_write.exit117.amdgpu_ring_write.exit130_crit_edge
  %106 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %106)
  %107 = load ptr, ptr %ring1.i, align 4
  %108 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %108)
  %109 = load i64, ptr %wptr.i, align 8
  %inc.i123 = add i64 %109, 1
  store i64 %inc.i123, ptr %wptr.i, align 8
  %110 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %110)
  %111 = load i32, ptr %buf_mask.i, align 8
  %112 = trunc i64 %109 to i32
  %idxprom.i125 = and i32 %111, %112
  %arrayidx.i126 = getelementptr i32, ptr %107, i32 %idxprom.i125
  %113 = ptrtoint ptr %arrayidx.i126 to i32
  call void @__asan_store4_noabort(i32 %113)
  store volatile i32 0, ptr %arrayidx.i126, align 4
  %114 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %114)
  %115 = load i64, ptr %ptr_mask.i, align 8
  %116 = load i64, ptr %wptr.i, align 8
  %and3.i128 = and i64 %116, %115
  store i64 %and3.i128, ptr %wptr.i, align 8
  %117 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %117)
  %118 = load i32, ptr %count_dw.i, align 8
  %dec.i129 = add i32 %118, -1
  store i32 %dec.i129, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i129)
  %cmp.i132 = icmp slt i32 %dec.i129, 1
  br i1 %cmp.i132, label %if.then.i133, label %amdgpu_ring_write.exit130.amdgpu_ring_write.exit143_crit_edge

amdgpu_ring_write.exit130.amdgpu_ring_write.exit143_crit_edge: ; preds = %amdgpu_ring_write.exit130
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit143

if.then.i133:                                     ; preds = %amdgpu_ring_write.exit130
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit143

amdgpu_ring_write.exit143:                        ; preds = %if.then.i133, %amdgpu_ring_write.exit130.amdgpu_ring_write.exit143_crit_edge
  %119 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %119)
  %120 = load ptr, ptr %ring1.i, align 4
  %121 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %121)
  %122 = load i64, ptr %wptr.i, align 8
  %inc.i136 = add i64 %122, 1
  store i64 %inc.i136, ptr %wptr.i, align 8
  %123 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %123)
  %124 = load i32, ptr %buf_mask.i, align 8
  %125 = trunc i64 %122 to i32
  %idxprom.i138 = and i32 %124, %125
  %arrayidx.i139 = getelementptr i32, ptr %120, i32 %idxprom.i138
  %126 = ptrtoint ptr %arrayidx.i139 to i32
  call void @__asan_store4_noabort(i32 %126)
  store volatile i32 536870912, ptr %arrayidx.i139, align 4
  %127 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %127)
  %128 = load i64, ptr %ptr_mask.i, align 8
  %129 = load i64, ptr %wptr.i, align 8
  %and3.i141 = and i64 %129, %128
  store i64 %and3.i141, ptr %wptr.i, align 8
  %130 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load i32, ptr %count_dw.i, align 8
  %dec.i142 = add i32 %131, -1
  store i32 %dec.i142, ptr %count_dw.i, align 8
  br label %if.end15

if.end15:                                         ; preds = %amdgpu_ring_write.exit143, %amdgpu_ring_write.exit78.if.end15_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_ring_test_ring(ptr noundef %ring) #0 align 64 {
entry:
  %scratch = alloca i32, align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %scratch) #12
  %2 = ptrtoint ptr %scratch to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %scratch, align 4, !annotation !441
  %call = call i32 @amdgpu_gfx_scratch_get(ptr noundef %1, ptr noundef nonnull %scratch) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %3 = ptrtoint ptr %scratch to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %scratch, align 4
  call void @amdgpu_device_wreg(ptr noundef %1, i32 noundef %4, i32 noundef -889266515, i32 noundef 0) #12
  %call2 = call i32 @amdgpu_ring_alloc(ptr noundef %ring, i32 noundef 3) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2)
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %if.end5, label %if.end.error_free_scratch_crit_edge

if.end.error_free_scratch_crit_edge:              ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %error_free_scratch

if.end5:                                          ; preds = %if.end
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %5 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %6)
  %cmp.i = icmp slt i32 %6, 1
  br i1 %cmp.i, label %if.then.i, label %if.end5.amdgpu_ring_write.exit_crit_edge

if.end5.amdgpu_ring_write.exit_crit_edge:         ; preds = %if.end5
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %if.end5
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %if.end5.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %7 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %9 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %9)
  %10 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %10, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %11 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %buf_mask.i, align 8
  %13 = trunc i64 %10 to i32
  %idxprom.i = and i32 %12, %13
  %arrayidx.i = getelementptr i32, ptr %8, i32 %idxprom.i
  %14 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %14)
  store volatile i32 -1073645312, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %15 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %15)
  %16 = load i64, ptr %ptr_mask.i, align 8
  %17 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %17, %16
  store i64 %and3.i, ptr %wptr.i, align 8
  %18 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %19, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  %20 = ptrtoint ptr %scratch to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %scratch, align 4
  %sub = add i32 %21, -49152
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i34 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i34, label %if.then.i35, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit45_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit45_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit45

if.then.i35:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit45

amdgpu_ring_write.exit45:                         ; preds = %if.then.i35, %amdgpu_ring_write.exit.amdgpu_ring_write.exit45_crit_edge
  %22 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %ring1.i, align 4
  %24 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %24)
  %25 = load i64, ptr %wptr.i, align 8
  %inc.i38 = add i64 %25, 1
  store i64 %inc.i38, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %buf_mask.i, align 8
  %28 = trunc i64 %25 to i32
  %idxprom.i40 = and i32 %27, %28
  %arrayidx.i41 = getelementptr i32, ptr %23, i32 %idxprom.i40
  %29 = ptrtoint ptr %arrayidx.i41 to i32
  call void @__asan_store4_noabort(i32 %29)
  store volatile i32 %sub, ptr %arrayidx.i41, align 4
  %30 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %ptr_mask.i, align 8
  %32 = load i64, ptr %wptr.i, align 8
  %and3.i43 = and i64 %32, %31
  store i64 %and3.i43, ptr %wptr.i, align 8
  %33 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %count_dw.i, align 8
  %dec.i44 = add i32 %34, -1
  store i32 %dec.i44, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i44)
  %cmp.i47 = icmp slt i32 %dec.i44, 1
  br i1 %cmp.i47, label %if.then.i48, label %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge

amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge: ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit58

if.then.i48:                                      ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit58

amdgpu_ring_write.exit58:                         ; preds = %if.then.i48, %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge
  %35 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %ring1.i, align 4
  %37 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %37)
  %38 = load i64, ptr %wptr.i, align 8
  %inc.i51 = add i64 %38, 1
  store i64 %inc.i51, ptr %wptr.i, align 8
  %39 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %buf_mask.i, align 8
  %41 = trunc i64 %38 to i32
  %idxprom.i53 = and i32 %40, %41
  %arrayidx.i54 = getelementptr i32, ptr %36, i32 %idxprom.i53
  %42 = ptrtoint ptr %arrayidx.i54 to i32
  call void @__asan_store4_noabort(i32 %42)
  store volatile i32 -559038737, ptr %arrayidx.i54, align 4
  %43 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %ptr_mask.i, align 8
  %45 = load i64, ptr %wptr.i, align 8
  %and3.i56 = and i64 %45, %44
  store i64 %and3.i56, ptr %wptr.i, align 8
  %46 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %count_dw.i, align 8
  %dec.i57 = add i32 %47, -1
  store i32 %dec.i57, ptr %count_dw.i, align 8
  call void @amdgpu_ring_commit(ptr noundef %ring) #12
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 11
  %48 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %49)
  %cmp59.not = icmp eq i32 %49, 0
  br i1 %cmp59.not, label %amdgpu_ring_write.exit58.for.end_crit_edge, label %amdgpu_ring_write.exit58.for.body_crit_edge

amdgpu_ring_write.exit58.for.body_crit_edge:      ; preds = %amdgpu_ring_write.exit58
  br label %for.body

amdgpu_ring_write.exit58.for.end_crit_edge:       ; preds = %amdgpu_ring_write.exit58
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body:                                         ; preds = %if.end9.for.body_crit_edge, %amdgpu_ring_write.exit58.for.body_crit_edge
  %i.060 = phi i32 [ %inc, %if.end9.for.body_crit_edge ], [ 0, %amdgpu_ring_write.exit58.for.body_crit_edge ]
  %50 = ptrtoint ptr %scratch to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %scratch, align 4
  %call6 = call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef %51, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -559038737, i32 %call6)
  %cmp7 = icmp eq i32 %call6, -559038737
  br i1 %cmp7, label %for.body.for.end_crit_edge, label %if.end9

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end9:                                          ; preds = %for.body
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %52 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  call void %52(i32 noundef 214748) #12
  %inc = add nuw i32 %i.060, 1
  %53 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %usec_timeout, align 8
  %cmp = icmp ult i32 %inc, %54
  br i1 %cmp, label %if.end9.for.body_crit_edge, label %if.end9.for.end_crit_edge

if.end9.for.end_crit_edge:                        ; preds = %if.end9
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end9.for.body_crit_edge:                       ; preds = %if.end9
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %if.end9.for.end_crit_edge, %for.body.for.end_crit_edge, %amdgpu_ring_write.exit58.for.end_crit_edge
  %i.0.lcssa = phi i32 [ 0, %amdgpu_ring_write.exit58.for.end_crit_edge ], [ %i.060, %for.body.for.end_crit_edge ], [ %inc, %if.end9.for.end_crit_edge ]
  %55 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %i.0.lcssa, i32 %56)
  %cmp11.not = icmp ult i32 %i.0.lcssa, %56
  %spec.select = select i1 %cmp11.not, i32 0, i32 -110
  br label %error_free_scratch

error_free_scratch:                               ; preds = %for.end, %if.end.error_free_scratch_crit_edge
  %r.0 = phi i32 [ %call2, %if.end.error_free_scratch_crit_edge ], [ %spec.select, %for.end ]
  %57 = ptrtoint ptr %scratch to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %scratch, align 4
  call void @amdgpu_gfx_scratch_free(ptr noundef %1, i32 noundef %58) #12
  br label %cleanup

cleanup:                                          ; preds = %error_free_scratch, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ %r.0, %error_free_scratch ], [ %call, %entry.cleanup_crit_edge ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %scratch) #12
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_ring_insert_nop(ptr noundef, i32 noundef) #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_ring_generic_pad_ib(ptr noundef, ptr noundef) #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_rreg(ptr noundef %ring, i32 noundef %reg, i32 noundef %reg_val_offs) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %2 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %3)
  %cmp.i = icmp slt i32 %3, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %4 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %6 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %7, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %8 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %buf_mask.i, align 8
  %10 = trunc i64 %7 to i32
  %idxprom.i = and i32 %9, %10
  %arrayidx.i = getelementptr i32, ptr %5, i32 %idxprom.i
  %11 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store volatile i32 -1073463296, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %12 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %12)
  %13 = load i64, ptr %ptr_mask.i, align 8
  %14 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %14, %13
  store i64 %and3.i, ptr %wptr.i, align 8
  %15 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %16, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i19 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i19, label %if.then.i20, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit30_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit30_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit30

if.then.i20:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit30

amdgpu_ring_write.exit30:                         ; preds = %if.then.i20, %amdgpu_ring_write.exit.amdgpu_ring_write.exit30_crit_edge
  %17 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %ring1.i, align 4
  %19 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %19)
  %20 = load i64, ptr %wptr.i, align 8
  %inc.i23 = add i64 %20, 1
  store i64 %inc.i23, ptr %wptr.i, align 8
  %21 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %buf_mask.i, align 8
  %23 = trunc i64 %20 to i32
  %idxprom.i25 = and i32 %22, %23
  %arrayidx.i26 = getelementptr i32, ptr %18, i32 %idxprom.i25
  %24 = ptrtoint ptr %arrayidx.i26 to i32
  call void @__asan_store4_noabort(i32 %24)
  store volatile i32 1049856, ptr %arrayidx.i26, align 4
  %25 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %25)
  %26 = load i64, ptr %ptr_mask.i, align 8
  %27 = load i64, ptr %wptr.i, align 8
  %and3.i28 = and i64 %27, %26
  store i64 %and3.i28, ptr %wptr.i, align 8
  %28 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %count_dw.i, align 8
  %dec.i29 = add i32 %29, -1
  store i32 %dec.i29, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i29)
  %cmp.i32 = icmp slt i32 %dec.i29, 1
  br i1 %cmp.i32, label %if.then.i33, label %amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge

amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge: ; preds = %amdgpu_ring_write.exit30
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit43

if.then.i33:                                      ; preds = %amdgpu_ring_write.exit30
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit43

amdgpu_ring_write.exit43:                         ; preds = %if.then.i33, %amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge
  %30 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %ring1.i, align 4
  %32 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %32)
  %33 = load i64, ptr %wptr.i, align 8
  %inc.i36 = add i64 %33, 1
  store i64 %inc.i36, ptr %wptr.i, align 8
  %34 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %buf_mask.i, align 8
  %36 = trunc i64 %33 to i32
  %idxprom.i38 = and i32 %35, %36
  %arrayidx.i39 = getelementptr i32, ptr %31, i32 %idxprom.i38
  %37 = ptrtoint ptr %arrayidx.i39 to i32
  call void @__asan_store4_noabort(i32 %37)
  store volatile i32 %reg, ptr %arrayidx.i39, align 4
  %38 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %38)
  %39 = load i64, ptr %ptr_mask.i, align 8
  %40 = load i64, ptr %wptr.i, align 8
  %and3.i41 = and i64 %40, %39
  store i64 %and3.i41, ptr %wptr.i, align 8
  %41 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %count_dw.i, align 8
  %dec.i42 = add i32 %42, -1
  store i32 %dec.i42, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i42)
  %cmp.i45 = icmp slt i32 %dec.i42, 1
  br i1 %cmp.i45, label %if.then.i46, label %amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge

amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge: ; preds = %amdgpu_ring_write.exit43
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit56

if.then.i46:                                      ; preds = %amdgpu_ring_write.exit43
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit56

amdgpu_ring_write.exit56:                         ; preds = %if.then.i46, %amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge
  %43 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %ring1.i, align 4
  %45 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %45)
  %46 = load i64, ptr %wptr.i, align 8
  %inc.i49 = add i64 %46, 1
  store i64 %inc.i49, ptr %wptr.i, align 8
  %47 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %buf_mask.i, align 8
  %49 = trunc i64 %46 to i32
  %idxprom.i51 = and i32 %48, %49
  %arrayidx.i52 = getelementptr i32, ptr %44, i32 %idxprom.i51
  %50 = ptrtoint ptr %arrayidx.i52 to i32
  call void @__asan_store4_noabort(i32 %50)
  store volatile i32 0, ptr %arrayidx.i52, align 4
  %51 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %51)
  %52 = load i64, ptr %ptr_mask.i, align 8
  %53 = load i64, ptr %wptr.i, align 8
  %and3.i54 = and i64 %53, %52
  store i64 %and3.i54, ptr %wptr.i, align 8
  %54 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %count_dw.i, align 8
  %dec.i55 = add i32 %55, -1
  store i32 %dec.i55, ptr %count_dw.i, align 8
  %gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 2
  %56 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %56)
  %57 = load i64, ptr %gpu_addr, align 8
  %mul = shl i32 %reg_val_offs, 2
  %58 = trunc i64 %57 to i32
  %conv2 = add i32 %mul, %58
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i55)
  %cmp.i58 = icmp slt i32 %dec.i55, 1
  br i1 %cmp.i58, label %if.then.i59, label %amdgpu_ring_write.exit56.amdgpu_ring_write.exit69_crit_edge

amdgpu_ring_write.exit56.amdgpu_ring_write.exit69_crit_edge: ; preds = %amdgpu_ring_write.exit56
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit69

if.then.i59:                                      ; preds = %amdgpu_ring_write.exit56
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit69

amdgpu_ring_write.exit69:                         ; preds = %if.then.i59, %amdgpu_ring_write.exit56.amdgpu_ring_write.exit69_crit_edge
  %59 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %ring1.i, align 4
  %61 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %61)
  %62 = load i64, ptr %wptr.i, align 8
  %inc.i62 = add i64 %62, 1
  store i64 %inc.i62, ptr %wptr.i, align 8
  %63 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load i32, ptr %buf_mask.i, align 8
  %65 = trunc i64 %62 to i32
  %idxprom.i64 = and i32 %64, %65
  %arrayidx.i65 = getelementptr i32, ptr %60, i32 %idxprom.i64
  %66 = ptrtoint ptr %arrayidx.i65 to i32
  call void @__asan_store4_noabort(i32 %66)
  store volatile i32 %conv2, ptr %arrayidx.i65, align 4
  %67 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %67)
  %68 = load i64, ptr %ptr_mask.i, align 8
  %69 = load i64, ptr %wptr.i, align 8
  %and3.i67 = and i64 %69, %68
  store i64 %and3.i67, ptr %wptr.i, align 8
  %70 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load i32, ptr %count_dw.i, align 8
  %dec.i68 = add i32 %71, -1
  store i32 %dec.i68, ptr %count_dw.i, align 8
  %72 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %72)
  %73 = load i64, ptr %gpu_addr, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i68)
  %cmp.i71 = icmp slt i32 %dec.i68, 1
  br i1 %cmp.i71, label %if.then.i72, label %amdgpu_ring_write.exit69.amdgpu_ring_write.exit82_crit_edge

amdgpu_ring_write.exit69.amdgpu_ring_write.exit82_crit_edge: ; preds = %amdgpu_ring_write.exit69
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit82

if.then.i72:                                      ; preds = %amdgpu_ring_write.exit69
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit82

amdgpu_ring_write.exit82:                         ; preds = %if.then.i72, %amdgpu_ring_write.exit69.amdgpu_ring_write.exit82_crit_edge
  %conv = zext i32 %mul to i64
  %add7 = add i64 %73, %conv
  %shr = lshr i64 %add7, 32
  %conv9 = trunc i64 %shr to i32
  %74 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load ptr, ptr %ring1.i, align 4
  %76 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %76)
  %77 = load i64, ptr %wptr.i, align 8
  %inc.i75 = add i64 %77, 1
  store i64 %inc.i75, ptr %wptr.i, align 8
  %78 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load i32, ptr %buf_mask.i, align 8
  %80 = trunc i64 %77 to i32
  %idxprom.i77 = and i32 %79, %80
  %arrayidx.i78 = getelementptr i32, ptr %75, i32 %idxprom.i77
  %81 = ptrtoint ptr %arrayidx.i78 to i32
  call void @__asan_store4_noabort(i32 %81)
  store volatile i32 %conv9, ptr %arrayidx.i78, align 4
  %82 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %82)
  %83 = load i64, ptr %ptr_mask.i, align 8
  %84 = load i64, ptr %wptr.i, align 8
  %and3.i80 = and i64 %84, %83
  store i64 %and3.i80, ptr %wptr.i, align 8
  %85 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %count_dw.i, align 8
  %dec.i81 = add i32 %86, -1
  store i32 %dec.i81, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_wreg(ptr noundef %ring, i32 noundef %reg, i32 noundef %val) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %funcs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %0 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %funcs, align 4
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %1, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 9, i32 %3)
  %switch.selectcmp = icmp eq i32 %3, 9
  %switch.select = select i1 %switch.selectcmp, i32 65536, i32 1048576
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %switch.selectcmp7 = icmp eq i32 %3, 0
  %switch.select8 = select i1 %switch.selectcmp7, i32 1074790400, i32 %switch.select
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %4 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %5)
  %cmp.i = icmp slt i32 %5, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %6 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %8 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %9, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %10 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %buf_mask.i, align 8
  %12 = trunc i64 %9 to i32
  %idxprom.i = and i32 %11, %12
  %arrayidx.i = getelementptr i32, ptr %7, i32 %idxprom.i
  %13 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store volatile i32 -1073531136, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %14 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %14)
  %15 = load i64, ptr %ptr_mask.i, align 8
  %16 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %16, %15
  store i64 %and3.i, ptr %wptr.i, align 8
  %17 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %18, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i10 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i10, label %if.then.i11, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit21_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit21_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit21

if.then.i11:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit21

amdgpu_ring_write.exit21:                         ; preds = %if.then.i11, %amdgpu_ring_write.exit.amdgpu_ring_write.exit21_crit_edge
  %19 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %ring1.i, align 4
  %21 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %21)
  %22 = load i64, ptr %wptr.i, align 8
  %inc.i14 = add i64 %22, 1
  store i64 %inc.i14, ptr %wptr.i, align 8
  %23 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %buf_mask.i, align 8
  %25 = trunc i64 %22 to i32
  %idxprom.i16 = and i32 %24, %25
  %arrayidx.i17 = getelementptr i32, ptr %20, i32 %idxprom.i16
  %26 = ptrtoint ptr %arrayidx.i17 to i32
  call void @__asan_store4_noabort(i32 %26)
  store volatile i32 %switch.select8, ptr %arrayidx.i17, align 4
  %27 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %27)
  %28 = load i64, ptr %ptr_mask.i, align 8
  %29 = load i64, ptr %wptr.i, align 8
  %and3.i19 = and i64 %29, %28
  store i64 %and3.i19, ptr %wptr.i, align 8
  %30 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %count_dw.i, align 8
  %dec.i20 = add i32 %31, -1
  store i32 %dec.i20, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i20)
  %cmp.i23 = icmp slt i32 %dec.i20, 1
  br i1 %cmp.i23, label %if.then.i24, label %amdgpu_ring_write.exit21.amdgpu_ring_write.exit34_crit_edge

amdgpu_ring_write.exit21.amdgpu_ring_write.exit34_crit_edge: ; preds = %amdgpu_ring_write.exit21
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit34

if.then.i24:                                      ; preds = %amdgpu_ring_write.exit21
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit34

amdgpu_ring_write.exit34:                         ; preds = %if.then.i24, %amdgpu_ring_write.exit21.amdgpu_ring_write.exit34_crit_edge
  %32 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %ring1.i, align 4
  %34 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %34)
  %35 = load i64, ptr %wptr.i, align 8
  %inc.i27 = add i64 %35, 1
  store i64 %inc.i27, ptr %wptr.i, align 8
  %36 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %buf_mask.i, align 8
  %38 = trunc i64 %35 to i32
  %idxprom.i29 = and i32 %37, %38
  %arrayidx.i30 = getelementptr i32, ptr %33, i32 %idxprom.i29
  %39 = ptrtoint ptr %arrayidx.i30 to i32
  call void @__asan_store4_noabort(i32 %39)
  store volatile i32 %reg, ptr %arrayidx.i30, align 4
  %40 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %40)
  %41 = load i64, ptr %ptr_mask.i, align 8
  %42 = load i64, ptr %wptr.i, align 8
  %and3.i32 = and i64 %42, %41
  store i64 %and3.i32, ptr %wptr.i, align 8
  %43 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %count_dw.i, align 8
  %dec.i33 = add i32 %44, -1
  store i32 %dec.i33, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i33)
  %cmp.i36 = icmp slt i32 %dec.i33, 1
  br i1 %cmp.i36, label %if.then.i37, label %amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge

amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge: ; preds = %amdgpu_ring_write.exit34
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit47

if.then.i37:                                      ; preds = %amdgpu_ring_write.exit34
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit47

amdgpu_ring_write.exit47:                         ; preds = %if.then.i37, %amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge
  %45 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %ring1.i, align 4
  %47 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %47)
  %48 = load i64, ptr %wptr.i, align 8
  %inc.i40 = add i64 %48, 1
  store i64 %inc.i40, ptr %wptr.i, align 8
  %49 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %buf_mask.i, align 8
  %51 = trunc i64 %48 to i32
  %idxprom.i42 = and i32 %50, %51
  %arrayidx.i43 = getelementptr i32, ptr %46, i32 %idxprom.i42
  %52 = ptrtoint ptr %arrayidx.i43 to i32
  call void @__asan_store4_noabort(i32 %52)
  store volatile i32 0, ptr %arrayidx.i43, align 4
  %53 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %53)
  %54 = load i64, ptr %ptr_mask.i, align 8
  %55 = load i64, ptr %wptr.i, align 8
  %and3.i45 = and i64 %55, %54
  store i64 %and3.i45, ptr %wptr.i, align 8
  %56 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %count_dw.i, align 8
  %dec.i46 = add i32 %57, -1
  store i32 %dec.i46, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i46)
  %cmp.i49 = icmp slt i32 %dec.i46, 1
  br i1 %cmp.i49, label %if.then.i50, label %amdgpu_ring_write.exit47.amdgpu_ring_write.exit60_crit_edge

amdgpu_ring_write.exit47.amdgpu_ring_write.exit60_crit_edge: ; preds = %amdgpu_ring_write.exit47
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit60

if.then.i50:                                      ; preds = %amdgpu_ring_write.exit47
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit60

amdgpu_ring_write.exit60:                         ; preds = %if.then.i50, %amdgpu_ring_write.exit47.amdgpu_ring_write.exit60_crit_edge
  %58 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %ring1.i, align 4
  %60 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %60)
  %61 = load i64, ptr %wptr.i, align 8
  %inc.i53 = add i64 %61, 1
  store i64 %inc.i53, ptr %wptr.i, align 8
  %62 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %buf_mask.i, align 8
  %64 = trunc i64 %61 to i32
  %idxprom.i55 = and i32 %63, %64
  %arrayidx.i56 = getelementptr i32, ptr %59, i32 %idxprom.i55
  %65 = ptrtoint ptr %arrayidx.i56 to i32
  call void @__asan_store4_noabort(i32 %65)
  store volatile i32 %val, ptr %arrayidx.i56, align 4
  %66 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %66)
  %67 = load i64, ptr %ptr_mask.i, align 8
  %68 = load i64, ptr %wptr.i, align 8
  %and3.i58 = and i64 %68, %67
  store i64 %and3.i58, ptr %wptr.i, align 8
  %69 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %count_dw.i, align 8
  %dec.i59 = add i32 %70, -1
  store i32 %dec.i59, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_mm_wdoorbell(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__drm_err(ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_scratch_get(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ring_alloc(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_ring_commit(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_scratch_free(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i64 @gfx_v8_0_ring_get_wptr_gfx(ptr nocapture noundef readonly %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %use_doorbell = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 24
  %2 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_load1_noabort(i32 %2)
  %3 = load i8, ptr %use_doorbell, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %3)
  %tobool.not = icmp eq i8 %3, 0
  br i1 %tobool.not, label %if.else, label %if.then

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %wb3 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %4 = ptrtoint ptr %wb3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %wb3, align 4
  %wptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 26
  %6 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %wptr_offs, align 8
  %arrayidx = getelementptr i32, ptr %5, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %arrayidx, align 4
  br label %cleanup

if.else:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12357, i32 noundef 0) #12
  br label %cleanup

cleanup:                                          ; preds = %if.else, %if.then
  %retval.0.in = phi i32 [ %9, %if.then ], [ %call, %if.else ]
  %retval.0 = zext i32 %retval.0.in to i64
  ret i64 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_set_wptr_gfx(ptr nocapture noundef readonly %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %use_doorbell = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 24
  %2 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_load1_noabort(i32 %2)
  %3 = load i8, ptr %use_doorbell, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %3)
  %tobool.not = icmp eq i8 %3, 0
  %wptr6 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr6 to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr6, align 8
  %conv8 = trunc i64 %5 to i32
  br i1 %tobool.not, label %if.else, label %if.then

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %wb2 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %6 = ptrtoint ptr %wb2 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %wb2, align 4
  %wptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 26
  %8 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %wptr_offs, align 8
  %arrayidx = getelementptr i32, ptr %7, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %10)
  store volatile i32 %conv8, ptr %arrayidx, align 4
  %doorbell_index = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 23
  %11 = ptrtoint ptr %doorbell_index to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %doorbell_index, align 8
  %13 = ptrtoint ptr %wptr6 to i32
  call void @__asan_load8_noabort(i32 %13)
  %14 = load i64, ptr %wptr6, align 8
  %conv5 = trunc i64 %14 to i32
  tail call void @amdgpu_mm_wdoorbell(ptr noundef %1, i32 noundef %12, i32 noundef %conv5) #12
  br label %if.end

if.else:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %1, i32 noundef 12357, i32 noundef %conv8, i32 noundef 0) #12
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12357, i32 noundef 0) #12
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_ib_gfx(ptr noundef %ring, ptr noundef readonly %job, ptr nocapture noundef readonly %ib, i32 noundef %flags) #0 align 64 {
entry:
  %de_payload.i = alloca %union.anon.113, align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %tobool.not = icmp eq ptr %job, null
  br i1 %tobool.not, label %entry.cond.end_crit_edge, label %cond.true

entry.cond.end_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cond.end

cond.true:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %vmid1 = getelementptr inbounds %struct.amdgpu_job, ptr %job, i32 0, i32 12
  %0 = ptrtoint ptr %vmid1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %vmid1, align 8
  br label %cond.end

cond.end:                                         ; preds = %cond.true, %entry.cond.end_crit_edge
  %cond = phi i32 [ %1, %cond.true ], [ 0, %entry.cond.end_crit_edge ]
  %flags2 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 4
  %2 = ptrtoint ptr %flags2 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %flags2, align 4
  %and = and i32 %3, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool3.not = icmp eq i32 %and, 0
  %. = select i1 %tobool3.not, i32 -1073594624, i32 -1073597696
  %length_dw = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 1
  %4 = ptrtoint ptr %length_dw to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %length_dw, align 4
  %shl = shl i32 %cond, 24
  %or = or i32 %5, %shl
  %6 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %ring, align 8
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %7, i32 0, i32 132
  %8 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %virt, align 8
  %and5 = and i32 %9, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and5)
  %tobool6.not = icmp eq i32 %and5, 0
  %and8 = and i32 %3, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and8)
  %tobool9.not = icmp eq i32 %and8, 0
  %or.cond84 = select i1 %tobool6.not, i1 true, i1 %tobool9.not
  br i1 %or.cond84, label %cond.end.if.end19_crit_edge, label %if.then10

cond.end.if.end19_crit_edge:                      ; preds = %cond.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end19

if.then10:                                        ; preds = %cond.end
  %or11 = or i32 %or, 2097152
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool14.not = icmp ne i32 %and, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %cond)
  %tobool16.not = icmp eq i32 %cond, 0
  %or.cond = select i1 %tobool14.not, i1 true, i1 %tobool16.not
  br i1 %or.cond, label %if.then10.if.end19_crit_edge, label %if.then17

if.then10.if.end19_crit_edge:                     ; preds = %if.then10
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end19

if.then17:                                        ; preds = %if.then10
  call void @llvm.lifetime.start.p0(i64 108, ptr nonnull %de_payload.i) #12
  %10 = call ptr @memcpy(ptr %de_payload.i, ptr @__const.gfx_v8_0_ring_emit_de_meta.de_payload, i32 108)
  %call.i = tail call i64 @amdgpu_csa_vaddr(ptr noundef %7) #12
  %add.i = add i64 %call.i, 4096
  %11 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %ring, align 8
  %chained_ib_support.i = getelementptr inbounds %struct.amdgpu_device, ptr %12, i32 0, i32 132, i32 3
  %13 = ptrtoint ptr %chained_ib_support.i to i32
  call void @__asan_load1_noabort(i32 %13)
  %14 = load i8, ptr %chained_ib_support.i, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %14)
  %tobool.not.i = icmp eq i8 %14, 0
  %conv6.i = trunc i64 %add.i to i32
  br i1 %tobool.not.i, label %if.else.i, label %if.then.i

if.then.i:                                        ; preds = %if.then17
  call void @__sanitizer_cov_trace_pc() #14
  %gds_backup_addrlo.i = getelementptr inbounds %struct.vi_de_ib_state_chained_ib, ptr %de_payload.i, i32 0, i32 22
  %15 = ptrtoint ptr %gds_backup_addrlo.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 %conv6.i, ptr %gds_backup_addrlo.i, align 4
  %shr.i = lshr i64 %add.i, 32
  %conv3.i = trunc i64 %shr.i to i32
  %gds_backup_addrhi.i = getelementptr inbounds %struct.vi_de_ib_state_chained_ib, ptr %de_payload.i, i32 0, i32 23
  %16 = ptrtoint ptr %gds_backup_addrhi.i to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 %conv3.i, ptr %gds_backup_addrhi.i, align 4
  br label %if.end.i

if.else.i:                                        ; preds = %if.then17
  call void @__sanitizer_cov_trace_pc() #14
  %gds_backup_addrlo7.i = getelementptr inbounds %struct.vi_de_ib_state, ptr %de_payload.i, i32 0, i32 12
  %17 = ptrtoint ptr %gds_backup_addrlo7.i to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 %conv6.i, ptr %gds_backup_addrlo7.i, align 4
  %shr8.i = lshr i64 %add.i, 32
  %conv10.i = trunc i64 %shr8.i to i32
  %gds_backup_addrhi11.i = getelementptr inbounds %struct.vi_de_ib_state, ptr %de_payload.i, i32 0, i32 13
  %18 = ptrtoint ptr %gds_backup_addrhi11.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %conv10.i, ptr %gds_backup_addrhi11.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.else.i, %if.then.i
  %cnt_de.0.i = phi i32 [ 29, %if.then.i ], [ 19, %if.else.i ]
  %de_payload_addr.0.i = add i64 %call.i, 256
  %shl.i = shl nuw nsw i32 %cnt_de.0.i, 16
  %or.i = or i32 %shl.i, -1073727744
  %count_dw.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %19 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %20)
  %cmp.i.i = icmp slt i32 %20, 1
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.amdgpu_ring_write.exit.i_crit_edge

if.end.i.amdgpu_ring_write.exit.i_crit_edge:      ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i

if.then.i.i:                                      ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i

amdgpu_ring_write.exit.i:                         ; preds = %if.then.i.i, %if.end.i.amdgpu_ring_write.exit.i_crit_edge
  %ring1.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %21 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %ring1.i.i, align 4
  %wptr.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %23 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %wptr.i.i, align 8
  %inc.i.i = add i64 %24, 1
  store i64 %inc.i.i, ptr %wptr.i.i, align 8
  %buf_mask.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %25 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %buf_mask.i.i, align 8
  %27 = trunc i64 %24 to i32
  %idxprom.i.i = and i32 %26, %27
  %arrayidx.i.i = getelementptr i32, ptr %22, i32 %idxprom.i.i
  %28 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store volatile i32 %or.i, ptr %arrayidx.i.i, align 4
  %ptr_mask.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %29 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %29)
  %30 = load i64, ptr %ptr_mask.i.i, align 8
  %31 = load i64, ptr %wptr.i.i, align 8
  %and3.i.i = and i64 %31, %30
  store i64 %and3.i.i, ptr %wptr.i.i, align 8
  %32 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %count_dw.i.i, align 8
  %dec.i.i = add i32 %33, -1
  store i32 %dec.i.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i)
  %cmp.i33.i = icmp slt i32 %dec.i.i, 1
  br i1 %cmp.i33.i, label %if.then.i34.i, label %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit44.i_crit_edge

amdgpu_ring_write.exit.i.amdgpu_ring_write.exit44.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit44.i

if.then.i34.i:                                    ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit44.i

amdgpu_ring_write.exit44.i:                       ; preds = %if.then.i34.i, %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit44.i_crit_edge
  %34 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %ring1.i.i, align 4
  %36 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %wptr.i.i, align 8
  %inc.i37.i = add i64 %37, 1
  store i64 %inc.i37.i, ptr %wptr.i.i, align 8
  %38 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %buf_mask.i.i, align 8
  %40 = trunc i64 %37 to i32
  %idxprom.i39.i = and i32 %39, %40
  %arrayidx.i40.i = getelementptr i32, ptr %35, i32 %idxprom.i39.i
  %41 = ptrtoint ptr %arrayidx.i40.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store volatile i32 1074792448, ptr %arrayidx.i40.i, align 4
  %42 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %42)
  %43 = load i64, ptr %ptr_mask.i.i, align 8
  %44 = load i64, ptr %wptr.i.i, align 8
  %and3.i42.i = and i64 %44, %43
  store i64 %and3.i42.i, ptr %wptr.i.i, align 8
  %45 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %count_dw.i.i, align 8
  %dec.i43.i = add i32 %46, -1
  store i32 %dec.i43.i, ptr %count_dw.i.i, align 8
  %conv15.i = trunc i64 %de_payload_addr.0.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i43.i)
  %cmp.i46.i = icmp slt i32 %dec.i43.i, 1
  br i1 %cmp.i46.i, label %if.then.i47.i, label %amdgpu_ring_write.exit44.i.amdgpu_ring_write.exit57.i_crit_edge

amdgpu_ring_write.exit44.i.amdgpu_ring_write.exit57.i_crit_edge: ; preds = %amdgpu_ring_write.exit44.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit57.i

if.then.i47.i:                                    ; preds = %amdgpu_ring_write.exit44.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit57.i

amdgpu_ring_write.exit57.i:                       ; preds = %if.then.i47.i, %amdgpu_ring_write.exit44.i.amdgpu_ring_write.exit57.i_crit_edge
  %47 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %ring1.i.i, align 4
  %49 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %wptr.i.i, align 8
  %inc.i50.i = add i64 %50, 1
  store i64 %inc.i50.i, ptr %wptr.i.i, align 8
  %51 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %buf_mask.i.i, align 8
  %53 = trunc i64 %50 to i32
  %idxprom.i52.i = and i32 %52, %53
  %arrayidx.i53.i = getelementptr i32, ptr %48, i32 %idxprom.i52.i
  %54 = ptrtoint ptr %arrayidx.i53.i to i32
  call void @__asan_store4_noabort(i32 %54)
  store volatile i32 %conv15.i, ptr %arrayidx.i53.i, align 4
  %55 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %55)
  %56 = load i64, ptr %ptr_mask.i.i, align 8
  %57 = load i64, ptr %wptr.i.i, align 8
  %and3.i55.i = and i64 %57, %56
  store i64 %and3.i55.i, ptr %wptr.i.i, align 8
  %58 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %count_dw.i.i, align 8
  %dec.i56.i = add i32 %59, -1
  store i32 %dec.i56.i, ptr %count_dw.i.i, align 8
  %shr16.i = lshr i64 %de_payload_addr.0.i, 32
  %conv18.i = trunc i64 %shr16.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i56.i)
  %cmp.i59.i = icmp slt i32 %dec.i56.i, 1
  br i1 %cmp.i59.i, label %if.then.i60.i, label %amdgpu_ring_write.exit57.i.amdgpu_ring_write.exit70.i_crit_edge

amdgpu_ring_write.exit57.i.amdgpu_ring_write.exit70.i_crit_edge: ; preds = %amdgpu_ring_write.exit57.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit70.i

if.then.i60.i:                                    ; preds = %amdgpu_ring_write.exit57.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit70.i

amdgpu_ring_write.exit70.i:                       ; preds = %if.then.i60.i, %amdgpu_ring_write.exit57.i.amdgpu_ring_write.exit70.i_crit_edge
  %60 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %ring1.i.i, align 4
  %62 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %wptr.i.i, align 8
  %inc.i63.i = add i64 %63, 1
  store i64 %inc.i63.i, ptr %wptr.i.i, align 8
  %64 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %buf_mask.i.i, align 8
  %66 = trunc i64 %63 to i32
  %idxprom.i65.i = and i32 %65, %66
  %arrayidx.i66.i = getelementptr i32, ptr %61, i32 %idxprom.i65.i
  %67 = ptrtoint ptr %arrayidx.i66.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store volatile i32 %conv18.i, ptr %arrayidx.i66.i, align 4
  %68 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %68)
  %69 = load i64, ptr %ptr_mask.i.i, align 8
  %70 = load i64, ptr %wptr.i.i, align 8
  %and3.i68.i = and i64 %70, %69
  store i64 %and3.i68.i, ptr %wptr.i.i, align 8
  %71 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %count_dw.i.i, align 8
  %dec.i69.i = add i32 %72, -1
  store i32 %dec.i69.i, ptr %count_dw.i.i, align 8
  %sub.i = add nsw i32 %cnt_de.0.i, -2
  call void @__sanitizer_cov_trace_cmp4(i32 %dec.i69.i, i32 %sub.i)
  %cmp.i71.i = icmp slt i32 %dec.i69.i, %sub.i
  br i1 %cmp.i71.i, label %if.then.i72.i, label %amdgpu_ring_write.exit70.i.if.end.i.i_crit_edge, !prof !442

amdgpu_ring_write.exit70.i.if.end.i.i_crit_edge:  ; preds = %amdgpu_ring_write.exit70.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i.i

if.then.i72.i:                                    ; preds = %amdgpu_ring_write.exit70.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i72.i, %amdgpu_ring_write.exit70.i.if.end.i.i_crit_edge
  %73 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %73)
  %74 = load i64, ptr %wptr.i.i, align 8
  %75 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %buf_mask.i.i, align 8
  %77 = trunc i64 %74 to i32
  %conv3.i.i = and i32 %76, %77
  %add.i.i = add i32 %76, 1
  %sub.i.i = sub i32 %add.i.i, %conv3.i.i
  %78 = tail call i32 @llvm.umin.i32(i32 %sub.i.i, i32 %sub.i) #12
  %sub8.i.i = sub nsw i32 %sub.i, %78
  %shl.i.i = shl nuw nsw i32 %78, 2
  %shl9.i.i = shl nsw i32 %sub8.i.i, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %78)
  %tobool10.not.i.i = icmp eq i32 %78, 0
  br i1 %tobool10.not.i.i, label %if.end.i.i.if.end12.i.i_crit_edge, label %if.then11.i.i

if.end.i.i.if.end12.i.i_crit_edge:                ; preds = %if.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end12.i.i

if.then11.i.i:                                    ; preds = %if.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %79 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load ptr, ptr %ring1.i.i, align 4
  %arrayidx.i75.i = getelementptr i32, ptr %80, i32 %conv3.i.i
  %81 = call ptr @memcpy(ptr %arrayidx.i75.i, ptr %de_payload.i, i32 %shl.i.i)
  br label %if.end12.i.i

if.end12.i.i:                                     ; preds = %if.then11.i.i, %if.end.i.i.if.end12.i.i_crit_edge
  call void @__sanitizer_cov_trace_cmp4(i32 %sub.i, i32 %sub.i.i)
  %tobool13.not.i.not.i = icmp ugt i32 %sub.i, %sub.i.i
  br i1 %tobool13.not.i.not.i, label %if.then14.i.i, label %if.end12.i.i.gfx_v8_0_ring_emit_de_meta.exit_crit_edge

if.end12.i.i.gfx_v8_0_ring_emit_de_meta.exit_crit_edge: ; preds = %if.end12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_ring_emit_de_meta.exit

if.then14.i.i:                                    ; preds = %if.end12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add.ptr.i.i = getelementptr i8, ptr %de_payload.i, i32 %shl.i.i
  %82 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load ptr, ptr %ring1.i.i, align 4
  %84 = call ptr @memcpy(ptr %83, ptr %add.ptr.i.i, i32 %shl9.i.i)
  br label %gfx_v8_0_ring_emit_de_meta.exit

gfx_v8_0_ring_emit_de_meta.exit:                  ; preds = %if.then14.i.i, %if.end12.i.i.gfx_v8_0_ring_emit_de_meta.exit_crit_edge
  %85 = zext i32 %sub.i to i64
  %86 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %86)
  %87 = load i64, ptr %wptr.i.i, align 8
  %add19.i.i = add i64 %87, %85
  %88 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %88)
  %89 = load i64, ptr %ptr_mask.i.i, align 8
  %and21.i.i = and i64 %89, %add19.i.i
  store i64 %and21.i.i, ptr %wptr.i.i, align 8
  %90 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load i32, ptr %count_dw.i.i, align 8
  %sub23.i.i = sub i32 %91, %sub.i
  store i32 %sub23.i.i, ptr %count_dw.i.i, align 8
  call void @llvm.lifetime.end.p0(i64 108, ptr nonnull %de_payload.i) #12
  br label %if.end19

if.end19:                                         ; preds = %gfx_v8_0_ring_emit_de_meta.exit, %if.then10.if.end19_crit_edge, %cond.end.if.end19_crit_edge
  %control.0 = phi i32 [ %or11, %if.then10.if.end19_crit_edge ], [ %or11, %gfx_v8_0_ring_emit_de_meta.exit ], [ %or, %cond.end.if.end19_crit_edge ]
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %92 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %93)
  %cmp.i = icmp slt i32 %93, 1
  br i1 %cmp.i, label %if.then.i40, label %if.end19.amdgpu_ring_write.exit_crit_edge

if.end19.amdgpu_ring_write.exit_crit_edge:        ; preds = %if.end19
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i40:                                      ; preds = %if.end19
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i40, %if.end19.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %94 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %96 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %96)
  %97 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %97, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %98 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %buf_mask.i, align 8
  %100 = trunc i64 %97 to i32
  %idxprom.i = and i32 %99, %100
  %arrayidx.i = getelementptr i32, ptr %95, i32 %idxprom.i
  %101 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %101)
  store volatile i32 %., ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %102 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %102)
  %103 = load i64, ptr %ptr_mask.i, align 8
  %104 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %104, %103
  store i64 %and3.i, ptr %wptr.i, align 8
  %105 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %106, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  %gpu_addr = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 2
  %107 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %107)
  %108 = load i64, ptr %gpu_addr, align 8
  %109 = trunc i64 %108 to i32
  %110 = and i32 %109, -4
  %conv = or i32 %110, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i43 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i43, label %if.then.i44, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit55_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit55_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit55

if.then.i44:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit55

amdgpu_ring_write.exit55:                         ; preds = %if.then.i44, %amdgpu_ring_write.exit.amdgpu_ring_write.exit55_crit_edge
  %111 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load ptr, ptr %ring1.i, align 4
  %113 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %113)
  %114 = load i64, ptr %wptr.i, align 8
  %inc.i47 = add i64 %114, 1
  store i64 %inc.i47, ptr %wptr.i, align 8
  %115 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %115)
  %116 = load i32, ptr %buf_mask.i, align 8
  %117 = trunc i64 %114 to i32
  %idxprom.i49 = and i32 %116, %117
  %arrayidx.i50 = getelementptr i32, ptr %112, i32 %idxprom.i49
  %118 = ptrtoint ptr %arrayidx.i50 to i32
  call void @__asan_store4_noabort(i32 %118)
  store volatile i32 %conv, ptr %arrayidx.i50, align 4
  %119 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %119)
  %120 = load i64, ptr %ptr_mask.i, align 8
  %121 = load i64, ptr %wptr.i, align 8
  %and3.i52 = and i64 %121, %120
  store i64 %and3.i52, ptr %wptr.i, align 8
  %122 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load i32, ptr %count_dw.i, align 8
  %dec.i53 = add i32 %123, -1
  store i32 %dec.i53, ptr %count_dw.i, align 8
  %124 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %124)
  %125 = load i64, ptr %gpu_addr, align 8
  %shr = lshr i64 %125, 32
  %conv24 = trunc i64 %shr to i32
  %and25 = and i32 %conv24, 65535
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i53)
  %cmp.i57 = icmp slt i32 %dec.i53, 1
  br i1 %cmp.i57, label %if.then.i58, label %amdgpu_ring_write.exit55.amdgpu_ring_write.exit69_crit_edge

amdgpu_ring_write.exit55.amdgpu_ring_write.exit69_crit_edge: ; preds = %amdgpu_ring_write.exit55
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit69

if.then.i58:                                      ; preds = %amdgpu_ring_write.exit55
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit69

amdgpu_ring_write.exit69:                         ; preds = %if.then.i58, %amdgpu_ring_write.exit55.amdgpu_ring_write.exit69_crit_edge
  %126 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load ptr, ptr %ring1.i, align 4
  %128 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %128)
  %129 = load i64, ptr %wptr.i, align 8
  %inc.i61 = add i64 %129, 1
  store i64 %inc.i61, ptr %wptr.i, align 8
  %130 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load i32, ptr %buf_mask.i, align 8
  %132 = trunc i64 %129 to i32
  %idxprom.i63 = and i32 %131, %132
  %arrayidx.i64 = getelementptr i32, ptr %127, i32 %idxprom.i63
  %133 = ptrtoint ptr %arrayidx.i64 to i32
  call void @__asan_store4_noabort(i32 %133)
  store volatile i32 %and25, ptr %arrayidx.i64, align 4
  %134 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %134)
  %135 = load i64, ptr %ptr_mask.i, align 8
  %136 = load i64, ptr %wptr.i, align 8
  %and3.i66 = and i64 %136, %135
  store i64 %and3.i66, ptr %wptr.i, align 8
  %137 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %137)
  %138 = load i32, ptr %count_dw.i, align 8
  %dec.i67 = add i32 %138, -1
  store i32 %dec.i67, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i67)
  %cmp.i71 = icmp slt i32 %dec.i67, 1
  br i1 %cmp.i71, label %if.then.i72, label %amdgpu_ring_write.exit69.amdgpu_ring_write.exit83_crit_edge

amdgpu_ring_write.exit69.amdgpu_ring_write.exit83_crit_edge: ; preds = %amdgpu_ring_write.exit69
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit83

if.then.i72:                                      ; preds = %amdgpu_ring_write.exit69
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit83

amdgpu_ring_write.exit83:                         ; preds = %if.then.i72, %amdgpu_ring_write.exit69.amdgpu_ring_write.exit83_crit_edge
  %139 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %139)
  %140 = load ptr, ptr %ring1.i, align 4
  %141 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %141)
  %142 = load i64, ptr %wptr.i, align 8
  %inc.i75 = add i64 %142, 1
  store i64 %inc.i75, ptr %wptr.i, align 8
  %143 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %143)
  %144 = load i32, ptr %buf_mask.i, align 8
  %145 = trunc i64 %142 to i32
  %idxprom.i77 = and i32 %144, %145
  %arrayidx.i78 = getelementptr i32, ptr %140, i32 %idxprom.i77
  %146 = ptrtoint ptr %arrayidx.i78 to i32
  call void @__asan_store4_noabort(i32 %146)
  store volatile i32 %control.0, ptr %arrayidx.i78, align 4
  %147 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %147)
  %148 = load i64, ptr %ptr_mask.i, align 8
  %149 = load i64, ptr %wptr.i, align 8
  %and3.i80 = and i64 %149, %148
  store i64 %and3.i80, ptr %wptr.i, align 8
  %150 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %150)
  %151 = load i32, ptr %count_dw.i, align 8
  %dec.i81 = add i32 %151, -1
  store i32 %dec.i81, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_fence_gfx(ptr noundef %ring, i64 noundef %addr, i64 noundef %seq, i32 noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %and = and i32 %flags, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073461504, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i53 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i53, label %if.then.i54, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit64_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit64_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit64

if.then.i54:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit64

amdgpu_ring_write.exit64:                         ; preds = %if.then.i54, %amdgpu_ring_write.exit.amdgpu_ring_write.exit64_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i57 = add i64 %18, 1
  store i64 %inc.i57, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i59 = and i32 %20, %21
  %arrayidx.i60 = getelementptr i32, ptr %16, i32 %idxprom.i59
  %22 = ptrtoint ptr %arrayidx.i60 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 230676, ptr %arrayidx.i60, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i62 = and i64 %25, %24
  store i64 %and3.i62, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i63 = add i32 %27, -1
  store i32 %dec.i63, ptr %count_dw.i, align 8
  %28 = trunc i64 %addr to i32
  %conv = and i32 %28, -4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i63)
  %cmp.i66 = icmp slt i32 %dec.i63, 1
  br i1 %cmp.i66, label %if.then.i67, label %amdgpu_ring_write.exit64.amdgpu_ring_write.exit77_crit_edge

amdgpu_ring_write.exit64.amdgpu_ring_write.exit77_crit_edge: ; preds = %amdgpu_ring_write.exit64
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit77

if.then.i67:                                      ; preds = %amdgpu_ring_write.exit64
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit77

amdgpu_ring_write.exit77:                         ; preds = %if.then.i67, %amdgpu_ring_write.exit64.amdgpu_ring_write.exit77_crit_edge
  %29 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %ring1.i, align 4
  %31 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %31)
  %32 = load i64, ptr %wptr.i, align 8
  %inc.i70 = add i64 %32, 1
  store i64 %inc.i70, ptr %wptr.i, align 8
  %33 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %buf_mask.i, align 8
  %35 = trunc i64 %32 to i32
  %idxprom.i72 = and i32 %34, %35
  %arrayidx.i73 = getelementptr i32, ptr %30, i32 %idxprom.i72
  %36 = ptrtoint ptr %arrayidx.i73 to i32
  call void @__asan_store4_noabort(i32 %36)
  store volatile i32 %conv, ptr %arrayidx.i73, align 4
  %37 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %37)
  %38 = load i64, ptr %ptr_mask.i, align 8
  %39 = load i64, ptr %wptr.i, align 8
  %and3.i75 = and i64 %39, %38
  store i64 %and3.i75, ptr %wptr.i, align 8
  %40 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %count_dw.i, align 8
  %dec.i76 = add i32 %41, -1
  store i32 %dec.i76, ptr %count_dw.i, align 8
  %shr = lshr i64 %addr, 32
  %conv6 = trunc i64 %shr to i32
  %and7 = and i32 %conv6, 65535
  %or = or i32 %and7, 536870912
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i76)
  %cmp.i79 = icmp slt i32 %dec.i76, 1
  br i1 %cmp.i79, label %if.then.i80, label %amdgpu_ring_write.exit77.amdgpu_ring_write.exit90_crit_edge

amdgpu_ring_write.exit77.amdgpu_ring_write.exit90_crit_edge: ; preds = %amdgpu_ring_write.exit77
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit90

if.then.i80:                                      ; preds = %amdgpu_ring_write.exit77
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit90

amdgpu_ring_write.exit90:                         ; preds = %if.then.i80, %amdgpu_ring_write.exit77.amdgpu_ring_write.exit90_crit_edge
  %42 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %ring1.i, align 4
  %44 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %44)
  %45 = load i64, ptr %wptr.i, align 8
  %inc.i83 = add i64 %45, 1
  store i64 %inc.i83, ptr %wptr.i, align 8
  %46 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %buf_mask.i, align 8
  %48 = trunc i64 %45 to i32
  %idxprom.i85 = and i32 %47, %48
  %arrayidx.i86 = getelementptr i32, ptr %43, i32 %idxprom.i85
  %49 = ptrtoint ptr %arrayidx.i86 to i32
  call void @__asan_store4_noabort(i32 %49)
  store volatile i32 %or, ptr %arrayidx.i86, align 4
  %50 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %50)
  %51 = load i64, ptr %ptr_mask.i, align 8
  %52 = load i64, ptr %wptr.i, align 8
  %and3.i88 = and i64 %52, %51
  store i64 %and3.i88, ptr %wptr.i, align 8
  %53 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %count_dw.i, align 8
  %dec.i89 = add i32 %54, -1
  store i32 %dec.i89, ptr %count_dw.i, align 8
  %sub = add i64 %seq, -1
  %conv10 = trunc i64 %sub to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i89)
  %cmp.i92 = icmp slt i32 %dec.i89, 1
  br i1 %cmp.i92, label %if.then.i93, label %amdgpu_ring_write.exit90.amdgpu_ring_write.exit103_crit_edge

amdgpu_ring_write.exit90.amdgpu_ring_write.exit103_crit_edge: ; preds = %amdgpu_ring_write.exit90
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit103

if.then.i93:                                      ; preds = %amdgpu_ring_write.exit90
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit103

amdgpu_ring_write.exit103:                        ; preds = %if.then.i93, %amdgpu_ring_write.exit90.amdgpu_ring_write.exit103_crit_edge
  %55 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %ring1.i, align 4
  %57 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %57)
  %58 = load i64, ptr %wptr.i, align 8
  %inc.i96 = add i64 %58, 1
  store i64 %inc.i96, ptr %wptr.i, align 8
  %59 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load i32, ptr %buf_mask.i, align 8
  %61 = trunc i64 %58 to i32
  %idxprom.i98 = and i32 %60, %61
  %arrayidx.i99 = getelementptr i32, ptr %56, i32 %idxprom.i98
  %62 = ptrtoint ptr %arrayidx.i99 to i32
  call void @__asan_store4_noabort(i32 %62)
  store volatile i32 %conv10, ptr %arrayidx.i99, align 4
  %63 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %63)
  %64 = load i64, ptr %ptr_mask.i, align 8
  %65 = load i64, ptr %wptr.i, align 8
  %and3.i101 = and i64 %65, %64
  store i64 %and3.i101, ptr %wptr.i, align 8
  %66 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %count_dw.i, align 8
  %dec.i102 = add i32 %67, -1
  store i32 %dec.i102, ptr %count_dw.i, align 8
  %shr12 = lshr i64 %sub, 32
  %conv14 = trunc i64 %shr12 to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i102)
  %cmp.i105 = icmp slt i32 %dec.i102, 1
  br i1 %cmp.i105, label %if.then.i106, label %amdgpu_ring_write.exit103.amdgpu_ring_write.exit116_crit_edge

amdgpu_ring_write.exit103.amdgpu_ring_write.exit116_crit_edge: ; preds = %amdgpu_ring_write.exit103
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit116

if.then.i106:                                     ; preds = %amdgpu_ring_write.exit103
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit116

amdgpu_ring_write.exit116:                        ; preds = %if.then.i106, %amdgpu_ring_write.exit103.amdgpu_ring_write.exit116_crit_edge
  %68 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %ring1.i, align 4
  %70 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %70)
  %71 = load i64, ptr %wptr.i, align 8
  %inc.i109 = add i64 %71, 1
  store i64 %inc.i109, ptr %wptr.i, align 8
  %72 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load i32, ptr %buf_mask.i, align 8
  %74 = trunc i64 %71 to i32
  %idxprom.i111 = and i32 %73, %74
  %arrayidx.i112 = getelementptr i32, ptr %69, i32 %idxprom.i111
  %75 = ptrtoint ptr %arrayidx.i112 to i32
  call void @__asan_store4_noabort(i32 %75)
  store volatile i32 %conv14, ptr %arrayidx.i112, align 4
  %76 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %76)
  %77 = load i64, ptr %ptr_mask.i, align 8
  %78 = load i64, ptr %wptr.i, align 8
  %and3.i114 = and i64 %78, %77
  store i64 %and3.i114, ptr %wptr.i, align 8
  %79 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %count_dw.i, align 8
  %dec.i115 = add i32 %80, -1
  store i32 %dec.i115, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i115)
  %cmp.i118 = icmp slt i32 %dec.i115, 1
  br i1 %cmp.i118, label %if.then.i119, label %amdgpu_ring_write.exit116.amdgpu_ring_write.exit129_crit_edge

amdgpu_ring_write.exit116.amdgpu_ring_write.exit129_crit_edge: ; preds = %amdgpu_ring_write.exit116
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit129

if.then.i119:                                     ; preds = %amdgpu_ring_write.exit116
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit129

amdgpu_ring_write.exit129:                        ; preds = %if.then.i119, %amdgpu_ring_write.exit116.amdgpu_ring_write.exit129_crit_edge
  %81 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load ptr, ptr %ring1.i, align 4
  %83 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %83)
  %84 = load i64, ptr %wptr.i, align 8
  %inc.i122 = add i64 %84, 1
  store i64 %inc.i122, ptr %wptr.i, align 8
  %85 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %buf_mask.i, align 8
  %87 = trunc i64 %84 to i32
  %idxprom.i124 = and i32 %86, %87
  %arrayidx.i125 = getelementptr i32, ptr %82, i32 %idxprom.i124
  %88 = ptrtoint ptr %arrayidx.i125 to i32
  call void @__asan_store4_noabort(i32 %88)
  store volatile i32 -1073461504, ptr %arrayidx.i125, align 4
  %89 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %89)
  %90 = load i64, ptr %ptr_mask.i, align 8
  %91 = load i64, ptr %wptr.i, align 8
  %and3.i127 = and i64 %91, %90
  store i64 %and3.i127, ptr %wptr.i, align 8
  %92 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load i32, ptr %count_dw.i, align 8
  %dec.i128 = add i32 %93, -1
  store i32 %dec.i128, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i128)
  %cmp.i131 = icmp slt i32 %dec.i128, 1
  br i1 %cmp.i131, label %if.then.i132, label %amdgpu_ring_write.exit129.amdgpu_ring_write.exit142_crit_edge

amdgpu_ring_write.exit129.amdgpu_ring_write.exit142_crit_edge: ; preds = %amdgpu_ring_write.exit129
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit142

if.then.i132:                                     ; preds = %amdgpu_ring_write.exit129
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit142

amdgpu_ring_write.exit142:                        ; preds = %if.then.i132, %amdgpu_ring_write.exit129.amdgpu_ring_write.exit142_crit_edge
  %94 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %ring1.i, align 4
  %96 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %96)
  %97 = load i64, ptr %wptr.i, align 8
  %inc.i135 = add i64 %97, 1
  store i64 %inc.i135, ptr %wptr.i, align 8
  %98 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %buf_mask.i, align 8
  %100 = trunc i64 %97 to i32
  %idxprom.i137 = and i32 %99, %100
  %arrayidx.i138 = getelementptr i32, ptr %95, i32 %idxprom.i137
  %101 = ptrtoint ptr %arrayidx.i138 to i32
  call void @__asan_store4_noabort(i32 %101)
  store volatile i32 230676, ptr %arrayidx.i138, align 4
  %102 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %102)
  %103 = load i64, ptr %ptr_mask.i, align 8
  %104 = load i64, ptr %wptr.i, align 8
  %and3.i140 = and i64 %104, %103
  store i64 %and3.i140, ptr %wptr.i, align 8
  %105 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load i32, ptr %count_dw.i, align 8
  %dec.i141 = add i32 %106, -1
  store i32 %dec.i141, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i141)
  %cmp.i144 = icmp slt i32 %dec.i141, 1
  br i1 %cmp.i144, label %if.then.i145, label %amdgpu_ring_write.exit142.amdgpu_ring_write.exit155_crit_edge

amdgpu_ring_write.exit142.amdgpu_ring_write.exit155_crit_edge: ; preds = %amdgpu_ring_write.exit142
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit155

if.then.i145:                                     ; preds = %amdgpu_ring_write.exit142
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit155

amdgpu_ring_write.exit155:                        ; preds = %if.then.i145, %amdgpu_ring_write.exit142.amdgpu_ring_write.exit155_crit_edge
  %107 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load ptr, ptr %ring1.i, align 4
  %109 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %109)
  %110 = load i64, ptr %wptr.i, align 8
  %inc.i148 = add i64 %110, 1
  store i64 %inc.i148, ptr %wptr.i, align 8
  %111 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load i32, ptr %buf_mask.i, align 8
  %113 = trunc i64 %110 to i32
  %idxprom.i150 = and i32 %112, %113
  %arrayidx.i151 = getelementptr i32, ptr %108, i32 %idxprom.i150
  %114 = ptrtoint ptr %arrayidx.i151 to i32
  call void @__asan_store4_noabort(i32 %114)
  store volatile i32 %conv, ptr %arrayidx.i151, align 4
  %115 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %115)
  %116 = load i64, ptr %ptr_mask.i, align 8
  %117 = load i64, ptr %wptr.i, align 8
  %and3.i153 = and i64 %117, %116
  store i64 %and3.i153, ptr %wptr.i, align 8
  %118 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %118)
  %119 = load i32, ptr %count_dw.i, align 8
  %dec.i154 = add i32 %119, -1
  store i32 %dec.i154, ptr %count_dw.i, align 8
  %cond = select i1 %tobool.not, i32 536870912, i32 1073741824
  %and1 = shl i32 %flags, 24
  %shl27 = and i32 %and1, 33554432
  %or23 = or i32 %shl27, %and7
  %or28 = or i32 %or23, %cond
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i154)
  %cmp.i157 = icmp slt i32 %dec.i154, 1
  br i1 %cmp.i157, label %if.then.i158, label %amdgpu_ring_write.exit155.amdgpu_ring_write.exit168_crit_edge

amdgpu_ring_write.exit155.amdgpu_ring_write.exit168_crit_edge: ; preds = %amdgpu_ring_write.exit155
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit168

if.then.i158:                                     ; preds = %amdgpu_ring_write.exit155
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit168

amdgpu_ring_write.exit168:                        ; preds = %if.then.i158, %amdgpu_ring_write.exit155.amdgpu_ring_write.exit168_crit_edge
  %120 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load ptr, ptr %ring1.i, align 4
  %122 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %122)
  %123 = load i64, ptr %wptr.i, align 8
  %inc.i161 = add i64 %123, 1
  store i64 %inc.i161, ptr %wptr.i, align 8
  %124 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %buf_mask.i, align 8
  %126 = trunc i64 %123 to i32
  %idxprom.i163 = and i32 %125, %126
  %arrayidx.i164 = getelementptr i32, ptr %121, i32 %idxprom.i163
  %127 = ptrtoint ptr %arrayidx.i164 to i32
  call void @__asan_store4_noabort(i32 %127)
  store volatile i32 %or28, ptr %arrayidx.i164, align 4
  %128 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %128)
  %129 = load i64, ptr %ptr_mask.i, align 8
  %130 = load i64, ptr %wptr.i, align 8
  %and3.i166 = and i64 %130, %129
  store i64 %and3.i166, ptr %wptr.i, align 8
  %131 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %131)
  %132 = load i32, ptr %count_dw.i, align 8
  %dec.i167 = add i32 %132, -1
  store i32 %dec.i167, ptr %count_dw.i, align 8
  %conv30 = trunc i64 %seq to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i167)
  %cmp.i170 = icmp slt i32 %dec.i167, 1
  br i1 %cmp.i170, label %if.then.i171, label %amdgpu_ring_write.exit168.amdgpu_ring_write.exit181_crit_edge

amdgpu_ring_write.exit168.amdgpu_ring_write.exit181_crit_edge: ; preds = %amdgpu_ring_write.exit168
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit181

if.then.i171:                                     ; preds = %amdgpu_ring_write.exit168
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit181

amdgpu_ring_write.exit181:                        ; preds = %if.then.i171, %amdgpu_ring_write.exit168.amdgpu_ring_write.exit181_crit_edge
  %133 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %133)
  %134 = load ptr, ptr %ring1.i, align 4
  %135 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %135)
  %136 = load i64, ptr %wptr.i, align 8
  %inc.i174 = add i64 %136, 1
  store i64 %inc.i174, ptr %wptr.i, align 8
  %137 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %137)
  %138 = load i32, ptr %buf_mask.i, align 8
  %139 = trunc i64 %136 to i32
  %idxprom.i176 = and i32 %138, %139
  %arrayidx.i177 = getelementptr i32, ptr %134, i32 %idxprom.i176
  %140 = ptrtoint ptr %arrayidx.i177 to i32
  call void @__asan_store4_noabort(i32 %140)
  store volatile i32 %conv30, ptr %arrayidx.i177, align 4
  %141 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %141)
  %142 = load i64, ptr %ptr_mask.i, align 8
  %143 = load i64, ptr %wptr.i, align 8
  %and3.i179 = and i64 %143, %142
  store i64 %and3.i179, ptr %wptr.i, align 8
  %144 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %144)
  %145 = load i32, ptr %count_dw.i, align 8
  %dec.i180 = add i32 %145, -1
  store i32 %dec.i180, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i180)
  %cmp.i183 = icmp slt i32 %dec.i180, 1
  br i1 %cmp.i183, label %if.then.i184, label %amdgpu_ring_write.exit181.amdgpu_ring_write.exit194_crit_edge

amdgpu_ring_write.exit181.amdgpu_ring_write.exit194_crit_edge: ; preds = %amdgpu_ring_write.exit181
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit194

if.then.i184:                                     ; preds = %amdgpu_ring_write.exit181
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit194

amdgpu_ring_write.exit194:                        ; preds = %if.then.i184, %amdgpu_ring_write.exit181.amdgpu_ring_write.exit194_crit_edge
  %shr31 = lshr i64 %seq, 32
  %conv33 = trunc i64 %shr31 to i32
  %146 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %146)
  %147 = load ptr, ptr %ring1.i, align 4
  %148 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %148)
  %149 = load i64, ptr %wptr.i, align 8
  %inc.i187 = add i64 %149, 1
  store i64 %inc.i187, ptr %wptr.i, align 8
  %150 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %150)
  %151 = load i32, ptr %buf_mask.i, align 8
  %152 = trunc i64 %149 to i32
  %idxprom.i189 = and i32 %151, %152
  %arrayidx.i190 = getelementptr i32, ptr %147, i32 %idxprom.i189
  %153 = ptrtoint ptr %arrayidx.i190 to i32
  call void @__asan_store4_noabort(i32 %153)
  store volatile i32 %conv33, ptr %arrayidx.i190, align 4
  %154 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %154)
  %155 = load i64, ptr %ptr_mask.i, align 8
  %156 = load i64, ptr %wptr.i, align 8
  %and3.i192 = and i64 %156, %155
  store i64 %and3.i192, ptr %wptr.i, align 8
  %157 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %157)
  %158 = load i32, ptr %count_dw.i, align 8
  %dec.i193 = add i32 %158, -1
  store i32 %dec.i193, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_pipeline_sync(ptr noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %funcs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %0 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %funcs, align 4
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %1, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %cmp = icmp eq i32 %3, 0
  %fence_drv = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 2
  %sync_seq = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 2, i32 2
  %4 = ptrtoint ptr %sync_seq to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %sync_seq, align 4
  %6 = ptrtoint ptr %fence_drv to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %fence_drv, align 8
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %8 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %9)
  %cmp.i = icmp slt i32 %9, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %10 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %12 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %12)
  %13 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %13, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %14 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %buf_mask.i, align 8
  %16 = trunc i64 %13 to i32
  %idxprom.i = and i32 %15, %16
  %arrayidx.i = getelementptr i32, ptr %11, i32 %idxprom.i
  %17 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %17)
  store volatile i32 -1073398784, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %18 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %18)
  %19 = load i64, ptr %ptr_mask.i, align 8
  %20 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %20, %19
  store i64 %and3.i, ptr %wptr.i, align 8
  %21 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %22, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  %or = select i1 %cmp, i32 275, i32 19
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i17 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i17, label %if.then.i18, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit28_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit28_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit28

if.then.i18:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit28

amdgpu_ring_write.exit28:                         ; preds = %if.then.i18, %amdgpu_ring_write.exit.amdgpu_ring_write.exit28_crit_edge
  %23 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %ring1.i, align 4
  %25 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %25)
  %26 = load i64, ptr %wptr.i, align 8
  %inc.i21 = add i64 %26, 1
  store i64 %inc.i21, ptr %wptr.i, align 8
  %27 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %buf_mask.i, align 8
  %29 = trunc i64 %26 to i32
  %idxprom.i23 = and i32 %28, %29
  %arrayidx.i24 = getelementptr i32, ptr %24, i32 %idxprom.i23
  %30 = ptrtoint ptr %arrayidx.i24 to i32
  call void @__asan_store4_noabort(i32 %30)
  store volatile i32 %or, ptr %arrayidx.i24, align 4
  %31 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %31)
  %32 = load i64, ptr %ptr_mask.i, align 8
  %33 = load i64, ptr %wptr.i, align 8
  %and3.i26 = and i64 %33, %32
  store i64 %and3.i26, ptr %wptr.i, align 8
  %34 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %count_dw.i, align 8
  %dec.i27 = add i32 %35, -1
  store i32 %dec.i27, ptr %count_dw.i, align 8
  %36 = trunc i64 %7 to i32
  %conv2 = and i32 %36, -4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i27)
  %cmp.i30 = icmp slt i32 %dec.i27, 1
  br i1 %cmp.i30, label %if.then.i31, label %amdgpu_ring_write.exit28.amdgpu_ring_write.exit41_crit_edge

amdgpu_ring_write.exit28.amdgpu_ring_write.exit41_crit_edge: ; preds = %amdgpu_ring_write.exit28
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit41

if.then.i31:                                      ; preds = %amdgpu_ring_write.exit28
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit41

amdgpu_ring_write.exit41:                         ; preds = %if.then.i31, %amdgpu_ring_write.exit28.amdgpu_ring_write.exit41_crit_edge
  %37 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %ring1.i, align 4
  %39 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %39)
  %40 = load i64, ptr %wptr.i, align 8
  %inc.i34 = add i64 %40, 1
  store i64 %inc.i34, ptr %wptr.i, align 8
  %41 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %buf_mask.i, align 8
  %43 = trunc i64 %40 to i32
  %idxprom.i36 = and i32 %42, %43
  %arrayidx.i37 = getelementptr i32, ptr %38, i32 %idxprom.i36
  %44 = ptrtoint ptr %arrayidx.i37 to i32
  call void @__asan_store4_noabort(i32 %44)
  store volatile i32 %conv2, ptr %arrayidx.i37, align 4
  %45 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %45)
  %46 = load i64, ptr %ptr_mask.i, align 8
  %47 = load i64, ptr %wptr.i, align 8
  %and3.i39 = and i64 %47, %46
  store i64 %and3.i39, ptr %wptr.i, align 8
  %48 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %count_dw.i, align 8
  %dec.i40 = add i32 %49, -1
  store i32 %dec.i40, ptr %count_dw.i, align 8
  %shr = lshr i64 %7, 32
  %conv4 = trunc i64 %shr to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i40)
  %cmp.i43 = icmp slt i32 %dec.i40, 1
  br i1 %cmp.i43, label %if.then.i44, label %amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge

amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge: ; preds = %amdgpu_ring_write.exit41
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit54

if.then.i44:                                      ; preds = %amdgpu_ring_write.exit41
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit54

amdgpu_ring_write.exit54:                         ; preds = %if.then.i44, %amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge
  %50 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %ring1.i, align 4
  %52 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %52)
  %53 = load i64, ptr %wptr.i, align 8
  %inc.i47 = add i64 %53, 1
  store i64 %inc.i47, ptr %wptr.i, align 8
  %54 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %buf_mask.i, align 8
  %56 = trunc i64 %53 to i32
  %idxprom.i49 = and i32 %55, %56
  %arrayidx.i50 = getelementptr i32, ptr %51, i32 %idxprom.i49
  %57 = ptrtoint ptr %arrayidx.i50 to i32
  call void @__asan_store4_noabort(i32 %57)
  store volatile i32 %conv4, ptr %arrayidx.i50, align 4
  %58 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %58)
  %59 = load i64, ptr %ptr_mask.i, align 8
  %60 = load i64, ptr %wptr.i, align 8
  %and3.i52 = and i64 %60, %59
  store i64 %and3.i52, ptr %wptr.i, align 8
  %61 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load i32, ptr %count_dw.i, align 8
  %dec.i53 = add i32 %62, -1
  store i32 %dec.i53, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i53)
  %cmp.i56 = icmp slt i32 %dec.i53, 1
  br i1 %cmp.i56, label %if.then.i57, label %amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge

amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge: ; preds = %amdgpu_ring_write.exit54
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit67

if.then.i57:                                      ; preds = %amdgpu_ring_write.exit54
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit67

amdgpu_ring_write.exit67:                         ; preds = %if.then.i57, %amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge
  %63 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %ring1.i, align 4
  %65 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %65)
  %66 = load i64, ptr %wptr.i, align 8
  %inc.i60 = add i64 %66, 1
  store i64 %inc.i60, ptr %wptr.i, align 8
  %67 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %buf_mask.i, align 8
  %69 = trunc i64 %66 to i32
  %idxprom.i62 = and i32 %68, %69
  %arrayidx.i63 = getelementptr i32, ptr %64, i32 %idxprom.i62
  %70 = ptrtoint ptr %arrayidx.i63 to i32
  call void @__asan_store4_noabort(i32 %70)
  store volatile i32 %5, ptr %arrayidx.i63, align 4
  %71 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %71)
  %72 = load i64, ptr %ptr_mask.i, align 8
  %73 = load i64, ptr %wptr.i, align 8
  %and3.i65 = and i64 %73, %72
  store i64 %and3.i65, ptr %wptr.i, align 8
  %74 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load i32, ptr %count_dw.i, align 8
  %dec.i66 = add i32 %75, -1
  store i32 %dec.i66, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i66)
  %cmp.i69 = icmp slt i32 %dec.i66, 1
  br i1 %cmp.i69, label %if.then.i70, label %amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge

amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge: ; preds = %amdgpu_ring_write.exit67
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit80

if.then.i70:                                      ; preds = %amdgpu_ring_write.exit67
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit80

amdgpu_ring_write.exit80:                         ; preds = %if.then.i70, %amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge
  %76 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load ptr, ptr %ring1.i, align 4
  %78 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %78)
  %79 = load i64, ptr %wptr.i, align 8
  %inc.i73 = add i64 %79, 1
  store i64 %inc.i73, ptr %wptr.i, align 8
  %80 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load i32, ptr %buf_mask.i, align 8
  %82 = trunc i64 %79 to i32
  %idxprom.i75 = and i32 %81, %82
  %arrayidx.i76 = getelementptr i32, ptr %77, i32 %idxprom.i75
  %83 = ptrtoint ptr %arrayidx.i76 to i32
  call void @__asan_store4_noabort(i32 %83)
  store volatile i32 -1, ptr %arrayidx.i76, align 4
  %84 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %84)
  %85 = load i64, ptr %ptr_mask.i, align 8
  %86 = load i64, ptr %wptr.i, align 8
  %and3.i78 = and i64 %86, %85
  store i64 %and3.i78, ptr %wptr.i, align 8
  %87 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load i32, ptr %count_dw.i, align 8
  %dec.i79 = add i32 %88, -1
  store i32 %dec.i79, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i79)
  %cmp.i82 = icmp slt i32 %dec.i79, 1
  br i1 %cmp.i82, label %if.then.i83, label %amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge

amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge: ; preds = %amdgpu_ring_write.exit80
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit93

if.then.i83:                                      ; preds = %amdgpu_ring_write.exit80
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit93

amdgpu_ring_write.exit93:                         ; preds = %if.then.i83, %amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge
  %89 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load ptr, ptr %ring1.i, align 4
  %91 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %91)
  %92 = load i64, ptr %wptr.i, align 8
  %inc.i86 = add i64 %92, 1
  store i64 %inc.i86, ptr %wptr.i, align 8
  %93 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %buf_mask.i, align 8
  %95 = trunc i64 %92 to i32
  %idxprom.i88 = and i32 %94, %95
  %arrayidx.i89 = getelementptr i32, ptr %90, i32 %idxprom.i88
  %96 = ptrtoint ptr %arrayidx.i89 to i32
  call void @__asan_store4_noabort(i32 %96)
  store volatile i32 4, ptr %arrayidx.i89, align 4
  %97 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %97)
  %98 = load i64, ptr %ptr_mask.i, align 8
  %99 = load i64, ptr %wptr.i, align 8
  %and3.i91 = and i64 %99, %98
  store i64 %and3.i91, ptr %wptr.i, align 8
  %100 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %100)
  %101 = load i32, ptr %count_dw.i, align 8
  %dec.i92 = add i32 %101, -1
  store i32 %dec.i92, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_vm_flush(ptr noundef %ring, i32 noundef %vmid, i64 noundef %pd_addr) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %funcs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %0 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %funcs, align 4
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %1, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %cmp = icmp eq i32 %3, 0
  %4 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %ring, align 8
  %gmc_funcs = getelementptr inbounds %struct.amdgpu_device, ptr %5, i32 0, i32 62, i32 38
  %6 = ptrtoint ptr %gmc_funcs to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %gmc_funcs, align 4
  %emit_flush_gpu_tlb = getelementptr inbounds %struct.amdgpu_gmc_funcs, ptr %7, i32 0, i32 2
  %8 = ptrtoint ptr %emit_flush_gpu_tlb to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %emit_flush_gpu_tlb, align 4
  %call = tail call i64 %9(ptr noundef %ring, i32 noundef %vmid, i64 noundef %pd_addr) #12
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %10 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %11)
  %cmp.i = icmp slt i32 %11, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %12 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %14 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %14)
  %15 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %15, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %16 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %buf_mask.i, align 8
  %18 = trunc i64 %15 to i32
  %idxprom.i = and i32 %17, %18
  %arrayidx.i = getelementptr i32, ptr %13, i32 %idxprom.i
  %19 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %19)
  store volatile i32 -1073398784, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %20 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %20)
  %21 = load i64, ptr %ptr_mask.i, align 8
  %22 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %22, %21
  store i64 %and3.i, ptr %wptr.i, align 8
  %23 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %24, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i13 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i13, label %if.then.i14, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit24_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit24_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit24

if.then.i14:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit24

amdgpu_ring_write.exit24:                         ; preds = %if.then.i14, %amdgpu_ring_write.exit.amdgpu_ring_write.exit24_crit_edge
  %25 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %ring1.i, align 4
  %27 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %27)
  %28 = load i64, ptr %wptr.i, align 8
  %inc.i17 = add i64 %28, 1
  store i64 %inc.i17, ptr %wptr.i, align 8
  %29 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %buf_mask.i, align 8
  %31 = trunc i64 %28 to i32
  %idxprom.i19 = and i32 %30, %31
  %arrayidx.i20 = getelementptr i32, ptr %26, i32 %idxprom.i19
  %32 = ptrtoint ptr %arrayidx.i20 to i32
  call void @__asan_store4_noabort(i32 %32)
  store volatile i32 0, ptr %arrayidx.i20, align 4
  %33 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %33)
  %34 = load i64, ptr %ptr_mask.i, align 8
  %35 = load i64, ptr %wptr.i, align 8
  %and3.i22 = and i64 %35, %34
  store i64 %and3.i22, ptr %wptr.i, align 8
  %36 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %count_dw.i, align 8
  %dec.i23 = add i32 %37, -1
  store i32 %dec.i23, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i23)
  %cmp.i26 = icmp slt i32 %dec.i23, 1
  br i1 %cmp.i26, label %if.then.i27, label %amdgpu_ring_write.exit24.amdgpu_ring_write.exit37_crit_edge

amdgpu_ring_write.exit24.amdgpu_ring_write.exit37_crit_edge: ; preds = %amdgpu_ring_write.exit24
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit37

if.then.i27:                                      ; preds = %amdgpu_ring_write.exit24
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit37

amdgpu_ring_write.exit37:                         ; preds = %if.then.i27, %amdgpu_ring_write.exit24.amdgpu_ring_write.exit37_crit_edge
  %38 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %ring1.i, align 4
  %40 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %40)
  %41 = load i64, ptr %wptr.i, align 8
  %inc.i30 = add i64 %41, 1
  store i64 %inc.i30, ptr %wptr.i, align 8
  %42 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %buf_mask.i, align 8
  %44 = trunc i64 %41 to i32
  %idxprom.i32 = and i32 %43, %44
  %arrayidx.i33 = getelementptr i32, ptr %39, i32 %idxprom.i32
  %45 = ptrtoint ptr %arrayidx.i33 to i32
  call void @__asan_store4_noabort(i32 %45)
  store volatile i32 1310, ptr %arrayidx.i33, align 4
  %46 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %46)
  %47 = load i64, ptr %ptr_mask.i, align 8
  %48 = load i64, ptr %wptr.i, align 8
  %and3.i35 = and i64 %48, %47
  store i64 %and3.i35, ptr %wptr.i, align 8
  %49 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %count_dw.i, align 8
  %dec.i36 = add i32 %50, -1
  store i32 %dec.i36, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i36)
  %cmp.i39 = icmp slt i32 %dec.i36, 1
  br i1 %cmp.i39, label %if.then.i40, label %amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge

amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge: ; preds = %amdgpu_ring_write.exit37
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit50

if.then.i40:                                      ; preds = %amdgpu_ring_write.exit37
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit50

amdgpu_ring_write.exit50:                         ; preds = %if.then.i40, %amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge
  %51 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %ring1.i, align 4
  %53 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %53)
  %54 = load i64, ptr %wptr.i, align 8
  %inc.i43 = add i64 %54, 1
  store i64 %inc.i43, ptr %wptr.i, align 8
  %55 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %buf_mask.i, align 8
  %57 = trunc i64 %54 to i32
  %idxprom.i45 = and i32 %56, %57
  %arrayidx.i46 = getelementptr i32, ptr %52, i32 %idxprom.i45
  %58 = ptrtoint ptr %arrayidx.i46 to i32
  call void @__asan_store4_noabort(i32 %58)
  store volatile i32 0, ptr %arrayidx.i46, align 4
  %59 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %59)
  %60 = load i64, ptr %ptr_mask.i, align 8
  %61 = load i64, ptr %wptr.i, align 8
  %and3.i48 = and i64 %61, %60
  store i64 %and3.i48, ptr %wptr.i, align 8
  %62 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %count_dw.i, align 8
  %dec.i49 = add i32 %63, -1
  store i32 %dec.i49, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i49)
  %cmp.i52 = icmp slt i32 %dec.i49, 1
  br i1 %cmp.i52, label %if.then.i53, label %amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge

amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge: ; preds = %amdgpu_ring_write.exit50
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit63

if.then.i53:                                      ; preds = %amdgpu_ring_write.exit50
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit63

amdgpu_ring_write.exit63:                         ; preds = %if.then.i53, %amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge
  %64 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load ptr, ptr %ring1.i, align 4
  %66 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %66)
  %67 = load i64, ptr %wptr.i, align 8
  %inc.i56 = add i64 %67, 1
  store i64 %inc.i56, ptr %wptr.i, align 8
  %68 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load i32, ptr %buf_mask.i, align 8
  %70 = trunc i64 %67 to i32
  %idxprom.i58 = and i32 %69, %70
  %arrayidx.i59 = getelementptr i32, ptr %65, i32 %idxprom.i58
  %71 = ptrtoint ptr %arrayidx.i59 to i32
  call void @__asan_store4_noabort(i32 %71)
  store volatile i32 0, ptr %arrayidx.i59, align 4
  %72 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %72)
  %73 = load i64, ptr %ptr_mask.i, align 8
  %74 = load i64, ptr %wptr.i, align 8
  %and3.i61 = and i64 %74, %73
  store i64 %and3.i61, ptr %wptr.i, align 8
  %75 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %count_dw.i, align 8
  %dec.i62 = add i32 %76, -1
  store i32 %dec.i62, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i62)
  %cmp.i65 = icmp slt i32 %dec.i62, 1
  br i1 %cmp.i65, label %if.then.i66, label %amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge

amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge: ; preds = %amdgpu_ring_write.exit63
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit76

if.then.i66:                                      ; preds = %amdgpu_ring_write.exit63
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit76

amdgpu_ring_write.exit76:                         ; preds = %if.then.i66, %amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge
  %77 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load ptr, ptr %ring1.i, align 4
  %79 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %79)
  %80 = load i64, ptr %wptr.i, align 8
  %inc.i69 = add i64 %80, 1
  store i64 %inc.i69, ptr %wptr.i, align 8
  %81 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %buf_mask.i, align 8
  %83 = trunc i64 %80 to i32
  %idxprom.i71 = and i32 %82, %83
  %arrayidx.i72 = getelementptr i32, ptr %78, i32 %idxprom.i71
  %84 = ptrtoint ptr %arrayidx.i72 to i32
  call void @__asan_store4_noabort(i32 %84)
  store volatile i32 0, ptr %arrayidx.i72, align 4
  %85 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %85)
  %86 = load i64, ptr %ptr_mask.i, align 8
  %87 = load i64, ptr %wptr.i, align 8
  %and3.i74 = and i64 %87, %86
  store i64 %and3.i74, ptr %wptr.i, align 8
  %88 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load i32, ptr %count_dw.i, align 8
  %dec.i75 = add i32 %89, -1
  store i32 %dec.i75, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i75)
  %cmp.i78 = icmp slt i32 %dec.i75, 1
  br i1 %cmp.i78, label %if.then.i79, label %amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge

amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge: ; preds = %amdgpu_ring_write.exit76
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit89

if.then.i79:                                      ; preds = %amdgpu_ring_write.exit76
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit89

amdgpu_ring_write.exit89:                         ; preds = %if.then.i79, %amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge
  %90 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load ptr, ptr %ring1.i, align 4
  %92 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %92)
  %93 = load i64, ptr %wptr.i, align 8
  %inc.i82 = add i64 %93, 1
  store i64 %inc.i82, ptr %wptr.i, align 8
  %94 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load i32, ptr %buf_mask.i, align 8
  %96 = trunc i64 %93 to i32
  %idxprom.i84 = and i32 %95, %96
  %arrayidx.i85 = getelementptr i32, ptr %91, i32 %idxprom.i84
  %97 = ptrtoint ptr %arrayidx.i85 to i32
  call void @__asan_store4_noabort(i32 %97)
  store volatile i32 32, ptr %arrayidx.i85, align 4
  %98 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %98)
  %99 = load i64, ptr %ptr_mask.i, align 8
  %100 = load i64, ptr %wptr.i, align 8
  %and3.i87 = and i64 %100, %99
  store i64 %and3.i87, ptr %wptr.i, align 8
  %101 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load i32, ptr %count_dw.i, align 8
  %dec.i88 = add i32 %102, -1
  store i32 %dec.i88, ptr %count_dw.i, align 8
  br i1 %cmp, label %if.then, label %amdgpu_ring_write.exit89.if.end_crit_edge

amdgpu_ring_write.exit89.if.end_crit_edge:        ; preds = %amdgpu_ring_write.exit89
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %amdgpu_ring_write.exit89
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i88)
  %cmp.i91 = icmp slt i32 %dec.i88, 1
  br i1 %cmp.i91, label %if.then.i92, label %if.then.amdgpu_ring_write.exit102_crit_edge

if.then.amdgpu_ring_write.exit102_crit_edge:      ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit102

if.then.i92:                                      ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit102

amdgpu_ring_write.exit102:                        ; preds = %if.then.i92, %if.then.amdgpu_ring_write.exit102_crit_edge
  %103 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %103)
  %104 = load ptr, ptr %ring1.i, align 4
  %105 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %105)
  %106 = load i64, ptr %wptr.i, align 8
  %inc.i95 = add i64 %106, 1
  store i64 %inc.i95, ptr %wptr.i, align 8
  %107 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load i32, ptr %buf_mask.i, align 8
  %109 = trunc i64 %106 to i32
  %idxprom.i97 = and i32 %108, %109
  %arrayidx.i98 = getelementptr i32, ptr %104, i32 %idxprom.i97
  %110 = ptrtoint ptr %arrayidx.i98 to i32
  call void @__asan_store4_noabort(i32 %110)
  store volatile i32 -1073724928, ptr %arrayidx.i98, align 4
  %111 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %111)
  %112 = load i64, ptr %ptr_mask.i, align 8
  %113 = load i64, ptr %wptr.i, align 8
  %and3.i100 = and i64 %113, %112
  store i64 %and3.i100, ptr %wptr.i, align 8
  %114 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %114)
  %115 = load i32, ptr %count_dw.i, align 8
  %dec.i101 = add i32 %115, -1
  store i32 %dec.i101, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i101)
  %cmp.i104 = icmp slt i32 %dec.i101, 1
  br i1 %cmp.i104, label %if.then.i105, label %amdgpu_ring_write.exit102.amdgpu_ring_write.exit115_crit_edge

amdgpu_ring_write.exit102.amdgpu_ring_write.exit115_crit_edge: ; preds = %amdgpu_ring_write.exit102
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit115

if.then.i105:                                     ; preds = %amdgpu_ring_write.exit102
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit115

amdgpu_ring_write.exit115:                        ; preds = %if.then.i105, %amdgpu_ring_write.exit102.amdgpu_ring_write.exit115_crit_edge
  %116 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %116)
  %117 = load ptr, ptr %ring1.i, align 4
  %118 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %118)
  %119 = load i64, ptr %wptr.i, align 8
  %inc.i108 = add i64 %119, 1
  store i64 %inc.i108, ptr %wptr.i, align 8
  %120 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load i32, ptr %buf_mask.i, align 8
  %122 = trunc i64 %119 to i32
  %idxprom.i110 = and i32 %121, %122
  %arrayidx.i111 = getelementptr i32, ptr %117, i32 %idxprom.i110
  %123 = ptrtoint ptr %arrayidx.i111 to i32
  call void @__asan_store4_noabort(i32 %123)
  store volatile i32 0, ptr %arrayidx.i111, align 4
  %124 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %124)
  %125 = load i64, ptr %ptr_mask.i, align 8
  %126 = load i64, ptr %wptr.i, align 8
  %and3.i113 = and i64 %126, %125
  store i64 %and3.i113, ptr %wptr.i, align 8
  %127 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %127)
  %128 = load i32, ptr %count_dw.i, align 8
  %dec.i114 = add i32 %128, -1
  store i32 %dec.i114, ptr %count_dw.i, align 8
  br label %if.end

if.end:                                           ; preds = %amdgpu_ring_write.exit115, %amdgpu_ring_write.exit89.if.end_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_hdp_flush(ptr noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %funcs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %0 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %funcs, align 4
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %1, align 4
  %4 = zext i32 %3 to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.110)
  switch i32 %3, label %entry.if.end_crit_edge [
    i32 1, label %entry.if.then_crit_edge
    i32 9, label %entry.if.then_crit_edge99
  ]

entry.if.then_crit_edge99:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then

entry.if.then_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %entry.if.then_crit_edge, %entry.if.then_crit_edge99
  %me = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 16
  %5 = ptrtoint ptr %me to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %me, align 8
  %7 = zext i32 %6 to i64
  call void @__sanitizer_cov_trace_switch(i64 %7, ptr @__sancov_gen_cov_switch_values.111)
  switch i32 %6, label %if.then.cleanup_crit_edge [
    i32 1, label %if.then.if.end.sink.split_crit_edge
    i32 2, label %sw.bb4
  ]

if.then.if.end.sink.split_crit_edge:              ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.sink.split

if.then.cleanup_crit_edge:                        ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.bb4:                                           ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.sink.split

if.end.sink.split:                                ; preds = %sw.bb4, %if.then.if.end.sink.split_crit_edge
  %.sink = phi i32 [ 64, %sw.bb4 ], [ 4, %if.then.if.end.sink.split_crit_edge ]
  %pipe = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 17
  %8 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %pipe, align 4
  %shl = shl i32 %.sink, %9
  br label %if.end

if.end:                                           ; preds = %if.end.sink.split, %entry.if.end_crit_edge
  %ref_and_mask.1 = phi i32 [ 1, %entry.if.end_crit_edge ], [ %shl, %if.end.sink.split ]
  %reg_mem_engine.0 = phi i32 [ 323, %entry.if.end_crit_edge ], [ 67, %if.end.sink.split ]
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %10 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %11)
  %cmp.i = icmp slt i32 %11, 1
  br i1 %cmp.i, label %if.then.i, label %if.end.amdgpu_ring_write.exit_crit_edge

if.end.amdgpu_ring_write.exit_crit_edge:          ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %if.end.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %12 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %14 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %14)
  %15 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %15, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %16 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %buf_mask.i, align 8
  %18 = trunc i64 %15 to i32
  %idxprom.i = and i32 %17, %18
  %arrayidx.i = getelementptr i32, ptr %13, i32 %idxprom.i
  %19 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %19)
  store volatile i32 -1073398784, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %20 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %20)
  %21 = load i64, ptr %ptr_mask.i, align 8
  %22 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %22, %21
  store i64 %and3.i, ptr %wptr.i, align 8
  %23 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %24, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i21 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i21, label %if.then.i22, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit32_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit32_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit32

if.then.i22:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit32

amdgpu_ring_write.exit32:                         ; preds = %if.then.i22, %amdgpu_ring_write.exit.amdgpu_ring_write.exit32_crit_edge
  %25 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %ring1.i, align 4
  %27 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %27)
  %28 = load i64, ptr %wptr.i, align 8
  %inc.i25 = add i64 %28, 1
  store i64 %inc.i25, ptr %wptr.i, align 8
  %29 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %buf_mask.i, align 8
  %31 = trunc i64 %28 to i32
  %idxprom.i27 = and i32 %30, %31
  %arrayidx.i28 = getelementptr i32, ptr %26, i32 %idxprom.i27
  %32 = ptrtoint ptr %arrayidx.i28 to i32
  call void @__asan_store4_noabort(i32 %32)
  store volatile i32 %reg_mem_engine.0, ptr %arrayidx.i28, align 4
  %33 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %33)
  %34 = load i64, ptr %ptr_mask.i, align 8
  %35 = load i64, ptr %wptr.i, align 8
  %and3.i30 = and i64 %35, %34
  store i64 %and3.i30, ptr %wptr.i, align 8
  %36 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %count_dw.i, align 8
  %dec.i31 = add i32 %37, -1
  store i32 %dec.i31, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i31)
  %cmp.i34 = icmp slt i32 %dec.i31, 1
  br i1 %cmp.i34, label %if.then.i35, label %amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge

amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge: ; preds = %amdgpu_ring_write.exit32
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit45

if.then.i35:                                      ; preds = %amdgpu_ring_write.exit32
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit45

amdgpu_ring_write.exit45:                         ; preds = %if.then.i35, %amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge
  %38 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %ring1.i, align 4
  %40 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %40)
  %41 = load i64, ptr %wptr.i, align 8
  %inc.i38 = add i64 %41, 1
  store i64 %inc.i38, ptr %wptr.i, align 8
  %42 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %buf_mask.i, align 8
  %44 = trunc i64 %41 to i32
  %idxprom.i40 = and i32 %43, %44
  %arrayidx.i41 = getelementptr i32, ptr %39, i32 %idxprom.i40
  %45 = ptrtoint ptr %arrayidx.i41 to i32
  call void @__asan_store4_noabort(i32 %45)
  store volatile i32 5431, ptr %arrayidx.i41, align 4
  %46 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %46)
  %47 = load i64, ptr %ptr_mask.i, align 8
  %48 = load i64, ptr %wptr.i, align 8
  %and3.i43 = and i64 %48, %47
  store i64 %and3.i43, ptr %wptr.i, align 8
  %49 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %count_dw.i, align 8
  %dec.i44 = add i32 %50, -1
  store i32 %dec.i44, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i44)
  %cmp.i47 = icmp slt i32 %dec.i44, 1
  br i1 %cmp.i47, label %if.then.i48, label %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge

amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge: ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit58

if.then.i48:                                      ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit58

amdgpu_ring_write.exit58:                         ; preds = %if.then.i48, %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge
  %51 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %ring1.i, align 4
  %53 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %53)
  %54 = load i64, ptr %wptr.i, align 8
  %inc.i51 = add i64 %54, 1
  store i64 %inc.i51, ptr %wptr.i, align 8
  %55 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %buf_mask.i, align 8
  %57 = trunc i64 %54 to i32
  %idxprom.i53 = and i32 %56, %57
  %arrayidx.i54 = getelementptr i32, ptr %52, i32 %idxprom.i53
  %58 = ptrtoint ptr %arrayidx.i54 to i32
  call void @__asan_store4_noabort(i32 %58)
  store volatile i32 5432, ptr %arrayidx.i54, align 4
  %59 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %59)
  %60 = load i64, ptr %ptr_mask.i, align 8
  %61 = load i64, ptr %wptr.i, align 8
  %and3.i56 = and i64 %61, %60
  store i64 %and3.i56, ptr %wptr.i, align 8
  %62 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %count_dw.i, align 8
  %dec.i57 = add i32 %63, -1
  store i32 %dec.i57, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i57)
  %cmp.i60 = icmp slt i32 %dec.i57, 1
  br i1 %cmp.i60, label %if.then.i61, label %amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge

amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge: ; preds = %amdgpu_ring_write.exit58
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit71

if.then.i61:                                      ; preds = %amdgpu_ring_write.exit58
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit71

amdgpu_ring_write.exit71:                         ; preds = %if.then.i61, %amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge
  %64 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load ptr, ptr %ring1.i, align 4
  %66 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %66)
  %67 = load i64, ptr %wptr.i, align 8
  %inc.i64 = add i64 %67, 1
  store i64 %inc.i64, ptr %wptr.i, align 8
  %68 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load i32, ptr %buf_mask.i, align 8
  %70 = trunc i64 %67 to i32
  %idxprom.i66 = and i32 %69, %70
  %arrayidx.i67 = getelementptr i32, ptr %65, i32 %idxprom.i66
  %71 = ptrtoint ptr %arrayidx.i67 to i32
  call void @__asan_store4_noabort(i32 %71)
  store volatile i32 %ref_and_mask.1, ptr %arrayidx.i67, align 4
  %72 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %72)
  %73 = load i64, ptr %ptr_mask.i, align 8
  %74 = load i64, ptr %wptr.i, align 8
  %and3.i69 = and i64 %74, %73
  store i64 %and3.i69, ptr %wptr.i, align 8
  %75 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %count_dw.i, align 8
  %dec.i70 = add i32 %76, -1
  store i32 %dec.i70, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i70)
  %cmp.i73 = icmp slt i32 %dec.i70, 1
  br i1 %cmp.i73, label %if.then.i74, label %amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge

amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge: ; preds = %amdgpu_ring_write.exit71
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit84

if.then.i74:                                      ; preds = %amdgpu_ring_write.exit71
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit84

amdgpu_ring_write.exit84:                         ; preds = %if.then.i74, %amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge
  %77 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load ptr, ptr %ring1.i, align 4
  %79 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %79)
  %80 = load i64, ptr %wptr.i, align 8
  %inc.i77 = add i64 %80, 1
  store i64 %inc.i77, ptr %wptr.i, align 8
  %81 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %buf_mask.i, align 8
  %83 = trunc i64 %80 to i32
  %idxprom.i79 = and i32 %82, %83
  %arrayidx.i80 = getelementptr i32, ptr %78, i32 %idxprom.i79
  %84 = ptrtoint ptr %arrayidx.i80 to i32
  call void @__asan_store4_noabort(i32 %84)
  store volatile i32 %ref_and_mask.1, ptr %arrayidx.i80, align 4
  %85 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %85)
  %86 = load i64, ptr %ptr_mask.i, align 8
  %87 = load i64, ptr %wptr.i, align 8
  %and3.i82 = and i64 %87, %86
  store i64 %and3.i82, ptr %wptr.i, align 8
  %88 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load i32, ptr %count_dw.i, align 8
  %dec.i83 = add i32 %89, -1
  store i32 %dec.i83, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i83)
  %cmp.i86 = icmp slt i32 %dec.i83, 1
  br i1 %cmp.i86, label %if.then.i87, label %amdgpu_ring_write.exit84.amdgpu_ring_write.exit97_crit_edge

amdgpu_ring_write.exit84.amdgpu_ring_write.exit97_crit_edge: ; preds = %amdgpu_ring_write.exit84
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit97

if.then.i87:                                      ; preds = %amdgpu_ring_write.exit84
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit97

amdgpu_ring_write.exit97:                         ; preds = %if.then.i87, %amdgpu_ring_write.exit84.amdgpu_ring_write.exit97_crit_edge
  %90 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load ptr, ptr %ring1.i, align 4
  %92 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %92)
  %93 = load i64, ptr %wptr.i, align 8
  %inc.i90 = add i64 %93, 1
  store i64 %inc.i90, ptr %wptr.i, align 8
  %94 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load i32, ptr %buf_mask.i, align 8
  %96 = trunc i64 %93 to i32
  %idxprom.i92 = and i32 %95, %96
  %arrayidx.i93 = getelementptr i32, ptr %91, i32 %idxprom.i92
  %97 = ptrtoint ptr %arrayidx.i93 to i32
  call void @__asan_store4_noabort(i32 %97)
  store volatile i32 32, ptr %arrayidx.i93, align 4
  %98 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %98)
  %99 = load i64, ptr %ptr_mask.i, align 8
  %100 = load i64, ptr %wptr.i, align 8
  %and3.i95 = and i64 %100, %99
  store i64 %and3.i95, ptr %wptr.i, align 8
  %101 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load i32, ptr %count_dw.i, align 8
  %dec.i96 = add i32 %102, -1
  store i32 %dec.i96, ptr %count_dw.i, align 8
  br label %cleanup

cleanup:                                          ; preds = %amdgpu_ring_write.exit97, %if.then.cleanup_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_gds_switch(ptr noundef %ring, i32 noundef %vmid, i32 noundef %gds_base, i32 noundef %gds_size, i32 noundef %gws_base, i32 noundef %gws_size, i32 noundef %oa_base, i32 noundef %oa_size) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073531136, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i30 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i30, label %if.then.i31, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit41_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit41_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit41

if.then.i31:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit41

amdgpu_ring_write.exit41:                         ; preds = %if.then.i31, %amdgpu_ring_write.exit.amdgpu_ring_write.exit41_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i34 = add i64 %18, 1
  store i64 %inc.i34, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i36 = and i32 %20, %21
  %arrayidx.i37 = getelementptr i32, ptr %16, i32 %idxprom.i36
  %22 = ptrtoint ptr %arrayidx.i37 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 0, ptr %arrayidx.i37, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i39 = and i64 %25, %24
  store i64 %and3.i39, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i40 = add i32 %27, -1
  store i32 %dec.i40, ptr %count_dw.i, align 8
  %arrayidx = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid
  %28 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i40)
  %cmp.i43 = icmp slt i32 %dec.i40, 1
  br i1 %cmp.i43, label %if.then.i44, label %amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge

amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge: ; preds = %amdgpu_ring_write.exit41
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit54

if.then.i44:                                      ; preds = %amdgpu_ring_write.exit41
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit54

amdgpu_ring_write.exit54:                         ; preds = %if.then.i44, %amdgpu_ring_write.exit41.amdgpu_ring_write.exit54_crit_edge
  %30 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %ring1.i, align 4
  %32 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %32)
  %33 = load i64, ptr %wptr.i, align 8
  %inc.i47 = add i64 %33, 1
  store i64 %inc.i47, ptr %wptr.i, align 8
  %34 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %buf_mask.i, align 8
  %36 = trunc i64 %33 to i32
  %idxprom.i49 = and i32 %35, %36
  %arrayidx.i50 = getelementptr i32, ptr %31, i32 %idxprom.i49
  %37 = ptrtoint ptr %arrayidx.i50 to i32
  call void @__asan_store4_noabort(i32 %37)
  store volatile i32 %29, ptr %arrayidx.i50, align 4
  %38 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %38)
  %39 = load i64, ptr %ptr_mask.i, align 8
  %40 = load i64, ptr %wptr.i, align 8
  %and3.i52 = and i64 %40, %39
  store i64 %and3.i52, ptr %wptr.i, align 8
  %41 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %count_dw.i, align 8
  %dec.i53 = add i32 %42, -1
  store i32 %dec.i53, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i53)
  %cmp.i56 = icmp slt i32 %dec.i53, 1
  br i1 %cmp.i56, label %if.then.i57, label %amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge

amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge: ; preds = %amdgpu_ring_write.exit54
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit67

if.then.i57:                                      ; preds = %amdgpu_ring_write.exit54
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit67

amdgpu_ring_write.exit67:                         ; preds = %if.then.i57, %amdgpu_ring_write.exit54.amdgpu_ring_write.exit67_crit_edge
  %43 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %ring1.i, align 4
  %45 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %45)
  %46 = load i64, ptr %wptr.i, align 8
  %inc.i60 = add i64 %46, 1
  store i64 %inc.i60, ptr %wptr.i, align 8
  %47 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %buf_mask.i, align 8
  %49 = trunc i64 %46 to i32
  %idxprom.i62 = and i32 %48, %49
  %arrayidx.i63 = getelementptr i32, ptr %44, i32 %idxprom.i62
  %50 = ptrtoint ptr %arrayidx.i63 to i32
  call void @__asan_store4_noabort(i32 %50)
  store volatile i32 0, ptr %arrayidx.i63, align 4
  %51 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %51)
  %52 = load i64, ptr %ptr_mask.i, align 8
  %53 = load i64, ptr %wptr.i, align 8
  %and3.i65 = and i64 %53, %52
  store i64 %and3.i65, ptr %wptr.i, align 8
  %54 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %count_dw.i, align 8
  %dec.i66 = add i32 %55, -1
  store i32 %dec.i66, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i66)
  %cmp.i69 = icmp slt i32 %dec.i66, 1
  br i1 %cmp.i69, label %if.then.i70, label %amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge

amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge: ; preds = %amdgpu_ring_write.exit67
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit80

if.then.i70:                                      ; preds = %amdgpu_ring_write.exit67
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit80

amdgpu_ring_write.exit80:                         ; preds = %if.then.i70, %amdgpu_ring_write.exit67.amdgpu_ring_write.exit80_crit_edge
  %56 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %ring1.i, align 4
  %58 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %58)
  %59 = load i64, ptr %wptr.i, align 8
  %inc.i73 = add i64 %59, 1
  store i64 %inc.i73, ptr %wptr.i, align 8
  %60 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %buf_mask.i, align 8
  %62 = trunc i64 %59 to i32
  %idxprom.i75 = and i32 %61, %62
  %arrayidx.i76 = getelementptr i32, ptr %57, i32 %idxprom.i75
  %63 = ptrtoint ptr %arrayidx.i76 to i32
  call void @__asan_store4_noabort(i32 %63)
  store volatile i32 %gds_base, ptr %arrayidx.i76, align 4
  %64 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %64)
  %65 = load i64, ptr %ptr_mask.i, align 8
  %66 = load i64, ptr %wptr.i, align 8
  %and3.i78 = and i64 %66, %65
  store i64 %and3.i78, ptr %wptr.i, align 8
  %67 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %count_dw.i, align 8
  %dec.i79 = add i32 %68, -1
  store i32 %dec.i79, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i79)
  %cmp.i82 = icmp slt i32 %dec.i79, 1
  br i1 %cmp.i82, label %if.then.i83, label %amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge

amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge: ; preds = %amdgpu_ring_write.exit80
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit93

if.then.i83:                                      ; preds = %amdgpu_ring_write.exit80
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit93

amdgpu_ring_write.exit93:                         ; preds = %if.then.i83, %amdgpu_ring_write.exit80.amdgpu_ring_write.exit93_crit_edge
  %69 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %ring1.i, align 4
  %71 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %71)
  %72 = load i64, ptr %wptr.i, align 8
  %inc.i86 = add i64 %72, 1
  store i64 %inc.i86, ptr %wptr.i, align 8
  %73 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load i32, ptr %buf_mask.i, align 8
  %75 = trunc i64 %72 to i32
  %idxprom.i88 = and i32 %74, %75
  %arrayidx.i89 = getelementptr i32, ptr %70, i32 %idxprom.i88
  %76 = ptrtoint ptr %arrayidx.i89 to i32
  call void @__asan_store4_noabort(i32 %76)
  store volatile i32 -1073531136, ptr %arrayidx.i89, align 4
  %77 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %77)
  %78 = load i64, ptr %ptr_mask.i, align 8
  %79 = load i64, ptr %wptr.i, align 8
  %and3.i91 = and i64 %79, %78
  store i64 %and3.i91, ptr %wptr.i, align 8
  %80 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load i32, ptr %count_dw.i, align 8
  %dec.i92 = add i32 %81, -1
  store i32 %dec.i92, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i92)
  %cmp.i95 = icmp slt i32 %dec.i92, 1
  br i1 %cmp.i95, label %if.then.i96, label %amdgpu_ring_write.exit93.amdgpu_ring_write.exit106_crit_edge

amdgpu_ring_write.exit93.amdgpu_ring_write.exit106_crit_edge: ; preds = %amdgpu_ring_write.exit93
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit106

if.then.i96:                                      ; preds = %amdgpu_ring_write.exit93
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit106

amdgpu_ring_write.exit106:                        ; preds = %if.then.i96, %amdgpu_ring_write.exit93.amdgpu_ring_write.exit106_crit_edge
  %82 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load ptr, ptr %ring1.i, align 4
  %84 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %84)
  %85 = load i64, ptr %wptr.i, align 8
  %inc.i99 = add i64 %85, 1
  store i64 %inc.i99, ptr %wptr.i, align 8
  %86 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load i32, ptr %buf_mask.i, align 8
  %88 = trunc i64 %85 to i32
  %idxprom.i101 = and i32 %87, %88
  %arrayidx.i102 = getelementptr i32, ptr %83, i32 %idxprom.i101
  %89 = ptrtoint ptr %arrayidx.i102 to i32
  call void @__asan_store4_noabort(i32 %89)
  store volatile i32 0, ptr %arrayidx.i102, align 4
  %90 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %90)
  %91 = load i64, ptr %ptr_mask.i, align 8
  %92 = load i64, ptr %wptr.i, align 8
  %and3.i104 = and i64 %92, %91
  store i64 %and3.i104, ptr %wptr.i, align 8
  %93 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %count_dw.i, align 8
  %dec.i105 = add i32 %94, -1
  store i32 %dec.i105, ptr %count_dw.i, align 8
  %mem_size = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid, i32 1
  %95 = ptrtoint ptr %mem_size to i32
  call void @__asan_load4_noabort(i32 %95)
  %96 = load i32, ptr %mem_size, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i105)
  %cmp.i108 = icmp slt i32 %dec.i105, 1
  br i1 %cmp.i108, label %if.then.i109, label %amdgpu_ring_write.exit106.amdgpu_ring_write.exit119_crit_edge

amdgpu_ring_write.exit106.amdgpu_ring_write.exit119_crit_edge: ; preds = %amdgpu_ring_write.exit106
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit119

if.then.i109:                                     ; preds = %amdgpu_ring_write.exit106
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit119

amdgpu_ring_write.exit119:                        ; preds = %if.then.i109, %amdgpu_ring_write.exit106.amdgpu_ring_write.exit119_crit_edge
  %97 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %97)
  %98 = load ptr, ptr %ring1.i, align 4
  %99 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %99)
  %100 = load i64, ptr %wptr.i, align 8
  %inc.i112 = add i64 %100, 1
  store i64 %inc.i112, ptr %wptr.i, align 8
  %101 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load i32, ptr %buf_mask.i, align 8
  %103 = trunc i64 %100 to i32
  %idxprom.i114 = and i32 %102, %103
  %arrayidx.i115 = getelementptr i32, ptr %98, i32 %idxprom.i114
  %104 = ptrtoint ptr %arrayidx.i115 to i32
  call void @__asan_store4_noabort(i32 %104)
  store volatile i32 %96, ptr %arrayidx.i115, align 4
  %105 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %105)
  %106 = load i64, ptr %ptr_mask.i, align 8
  %107 = load i64, ptr %wptr.i, align 8
  %and3.i117 = and i64 %107, %106
  store i64 %and3.i117, ptr %wptr.i, align 8
  %108 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %108)
  %109 = load i32, ptr %count_dw.i, align 8
  %dec.i118 = add i32 %109, -1
  store i32 %dec.i118, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i118)
  %cmp.i121 = icmp slt i32 %dec.i118, 1
  br i1 %cmp.i121, label %if.then.i122, label %amdgpu_ring_write.exit119.amdgpu_ring_write.exit132_crit_edge

amdgpu_ring_write.exit119.amdgpu_ring_write.exit132_crit_edge: ; preds = %amdgpu_ring_write.exit119
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit132

if.then.i122:                                     ; preds = %amdgpu_ring_write.exit119
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit132

amdgpu_ring_write.exit132:                        ; preds = %if.then.i122, %amdgpu_ring_write.exit119.amdgpu_ring_write.exit132_crit_edge
  %110 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %110)
  %111 = load ptr, ptr %ring1.i, align 4
  %112 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %112)
  %113 = load i64, ptr %wptr.i, align 8
  %inc.i125 = add i64 %113, 1
  store i64 %inc.i125, ptr %wptr.i, align 8
  %114 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %114)
  %115 = load i32, ptr %buf_mask.i, align 8
  %116 = trunc i64 %113 to i32
  %idxprom.i127 = and i32 %115, %116
  %arrayidx.i128 = getelementptr i32, ptr %111, i32 %idxprom.i127
  %117 = ptrtoint ptr %arrayidx.i128 to i32
  call void @__asan_store4_noabort(i32 %117)
  store volatile i32 0, ptr %arrayidx.i128, align 4
  %118 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %118)
  %119 = load i64, ptr %ptr_mask.i, align 8
  %120 = load i64, ptr %wptr.i, align 8
  %and3.i130 = and i64 %120, %119
  store i64 %and3.i130, ptr %wptr.i, align 8
  %121 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %121)
  %122 = load i32, ptr %count_dw.i, align 8
  %dec.i131 = add i32 %122, -1
  store i32 %dec.i131, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i131)
  %cmp.i134 = icmp slt i32 %dec.i131, 1
  br i1 %cmp.i134, label %if.then.i135, label %amdgpu_ring_write.exit132.amdgpu_ring_write.exit145_crit_edge

amdgpu_ring_write.exit132.amdgpu_ring_write.exit145_crit_edge: ; preds = %amdgpu_ring_write.exit132
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit145

if.then.i135:                                     ; preds = %amdgpu_ring_write.exit132
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit145

amdgpu_ring_write.exit145:                        ; preds = %if.then.i135, %amdgpu_ring_write.exit132.amdgpu_ring_write.exit145_crit_edge
  %123 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %123)
  %124 = load ptr, ptr %ring1.i, align 4
  %125 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %125)
  %126 = load i64, ptr %wptr.i, align 8
  %inc.i138 = add i64 %126, 1
  store i64 %inc.i138, ptr %wptr.i, align 8
  %127 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %127)
  %128 = load i32, ptr %buf_mask.i, align 8
  %129 = trunc i64 %126 to i32
  %idxprom.i140 = and i32 %128, %129
  %arrayidx.i141 = getelementptr i32, ptr %124, i32 %idxprom.i140
  %130 = ptrtoint ptr %arrayidx.i141 to i32
  call void @__asan_store4_noabort(i32 %130)
  store volatile i32 %gds_size, ptr %arrayidx.i141, align 4
  %131 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %131)
  %132 = load i64, ptr %ptr_mask.i, align 8
  %133 = load i64, ptr %wptr.i, align 8
  %and3.i143 = and i64 %133, %132
  store i64 %and3.i143, ptr %wptr.i, align 8
  %134 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %134)
  %135 = load i32, ptr %count_dw.i, align 8
  %dec.i144 = add i32 %135, -1
  store i32 %dec.i144, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i144)
  %cmp.i147 = icmp slt i32 %dec.i144, 1
  br i1 %cmp.i147, label %if.then.i148, label %amdgpu_ring_write.exit145.amdgpu_ring_write.exit158_crit_edge

amdgpu_ring_write.exit145.amdgpu_ring_write.exit158_crit_edge: ; preds = %amdgpu_ring_write.exit145
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit158

if.then.i148:                                     ; preds = %amdgpu_ring_write.exit145
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit158

amdgpu_ring_write.exit158:                        ; preds = %if.then.i148, %amdgpu_ring_write.exit145.amdgpu_ring_write.exit158_crit_edge
  %136 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %136)
  %137 = load ptr, ptr %ring1.i, align 4
  %138 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %138)
  %139 = load i64, ptr %wptr.i, align 8
  %inc.i151 = add i64 %139, 1
  store i64 %inc.i151, ptr %wptr.i, align 8
  %140 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %140)
  %141 = load i32, ptr %buf_mask.i, align 8
  %142 = trunc i64 %139 to i32
  %idxprom.i153 = and i32 %141, %142
  %arrayidx.i154 = getelementptr i32, ptr %137, i32 %idxprom.i153
  %143 = ptrtoint ptr %arrayidx.i154 to i32
  call void @__asan_store4_noabort(i32 %143)
  store volatile i32 -1073531136, ptr %arrayidx.i154, align 4
  %144 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %144)
  %145 = load i64, ptr %ptr_mask.i, align 8
  %146 = load i64, ptr %wptr.i, align 8
  %and3.i156 = and i64 %146, %145
  store i64 %and3.i156, ptr %wptr.i, align 8
  %147 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %147)
  %148 = load i32, ptr %count_dw.i, align 8
  %dec.i157 = add i32 %148, -1
  store i32 %dec.i157, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i157)
  %cmp.i160 = icmp slt i32 %dec.i157, 1
  br i1 %cmp.i160, label %if.then.i161, label %amdgpu_ring_write.exit158.amdgpu_ring_write.exit171_crit_edge

amdgpu_ring_write.exit158.amdgpu_ring_write.exit171_crit_edge: ; preds = %amdgpu_ring_write.exit158
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit171

if.then.i161:                                     ; preds = %amdgpu_ring_write.exit158
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit171

amdgpu_ring_write.exit171:                        ; preds = %if.then.i161, %amdgpu_ring_write.exit158.amdgpu_ring_write.exit171_crit_edge
  %149 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %149)
  %150 = load ptr, ptr %ring1.i, align 4
  %151 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %151)
  %152 = load i64, ptr %wptr.i, align 8
  %inc.i164 = add i64 %152, 1
  store i64 %inc.i164, ptr %wptr.i, align 8
  %153 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %153)
  %154 = load i32, ptr %buf_mask.i, align 8
  %155 = trunc i64 %152 to i32
  %idxprom.i166 = and i32 %154, %155
  %arrayidx.i167 = getelementptr i32, ptr %150, i32 %idxprom.i166
  %156 = ptrtoint ptr %arrayidx.i167 to i32
  call void @__asan_store4_noabort(i32 %156)
  store volatile i32 0, ptr %arrayidx.i167, align 4
  %157 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %157)
  %158 = load i64, ptr %ptr_mask.i, align 8
  %159 = load i64, ptr %wptr.i, align 8
  %and3.i169 = and i64 %159, %158
  store i64 %and3.i169, ptr %wptr.i, align 8
  %160 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %160)
  %161 = load i32, ptr %count_dw.i, align 8
  %dec.i170 = add i32 %161, -1
  store i32 %dec.i170, ptr %count_dw.i, align 8
  %gws = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid, i32 2
  %162 = ptrtoint ptr %gws to i32
  call void @__asan_load4_noabort(i32 %162)
  %163 = load i32, ptr %gws, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i170)
  %cmp.i173 = icmp slt i32 %dec.i170, 1
  br i1 %cmp.i173, label %if.then.i174, label %amdgpu_ring_write.exit171.amdgpu_ring_write.exit184_crit_edge

amdgpu_ring_write.exit171.amdgpu_ring_write.exit184_crit_edge: ; preds = %amdgpu_ring_write.exit171
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit184

if.then.i174:                                     ; preds = %amdgpu_ring_write.exit171
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit184

amdgpu_ring_write.exit184:                        ; preds = %if.then.i174, %amdgpu_ring_write.exit171.amdgpu_ring_write.exit184_crit_edge
  %164 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %164)
  %165 = load ptr, ptr %ring1.i, align 4
  %166 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %166)
  %167 = load i64, ptr %wptr.i, align 8
  %inc.i177 = add i64 %167, 1
  store i64 %inc.i177, ptr %wptr.i, align 8
  %168 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %168)
  %169 = load i32, ptr %buf_mask.i, align 8
  %170 = trunc i64 %167 to i32
  %idxprom.i179 = and i32 %169, %170
  %arrayidx.i180 = getelementptr i32, ptr %165, i32 %idxprom.i179
  %171 = ptrtoint ptr %arrayidx.i180 to i32
  call void @__asan_store4_noabort(i32 %171)
  store volatile i32 %163, ptr %arrayidx.i180, align 4
  %172 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %172)
  %173 = load i64, ptr %ptr_mask.i, align 8
  %174 = load i64, ptr %wptr.i, align 8
  %and3.i182 = and i64 %174, %173
  store i64 %and3.i182, ptr %wptr.i, align 8
  %175 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %175)
  %176 = load i32, ptr %count_dw.i, align 8
  %dec.i183 = add i32 %176, -1
  store i32 %dec.i183, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i183)
  %cmp.i186 = icmp slt i32 %dec.i183, 1
  br i1 %cmp.i186, label %if.then.i187, label %amdgpu_ring_write.exit184.amdgpu_ring_write.exit197_crit_edge

amdgpu_ring_write.exit184.amdgpu_ring_write.exit197_crit_edge: ; preds = %amdgpu_ring_write.exit184
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit197

if.then.i187:                                     ; preds = %amdgpu_ring_write.exit184
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit197

amdgpu_ring_write.exit197:                        ; preds = %if.then.i187, %amdgpu_ring_write.exit184.amdgpu_ring_write.exit197_crit_edge
  %177 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %177)
  %178 = load ptr, ptr %ring1.i, align 4
  %179 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %179)
  %180 = load i64, ptr %wptr.i, align 8
  %inc.i190 = add i64 %180, 1
  store i64 %inc.i190, ptr %wptr.i, align 8
  %181 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %181)
  %182 = load i32, ptr %buf_mask.i, align 8
  %183 = trunc i64 %180 to i32
  %idxprom.i192 = and i32 %182, %183
  %arrayidx.i193 = getelementptr i32, ptr %178, i32 %idxprom.i192
  %184 = ptrtoint ptr %arrayidx.i193 to i32
  call void @__asan_store4_noabort(i32 %184)
  store volatile i32 0, ptr %arrayidx.i193, align 4
  %185 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %185)
  %186 = load i64, ptr %ptr_mask.i, align 8
  %187 = load i64, ptr %wptr.i, align 8
  %and3.i195 = and i64 %187, %186
  store i64 %and3.i195, ptr %wptr.i, align 8
  %188 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %188)
  %189 = load i32, ptr %count_dw.i, align 8
  %dec.i196 = add i32 %189, -1
  store i32 %dec.i196, ptr %count_dw.i, align 8
  %shl = shl i32 %gws_size, 16
  %or = or i32 %shl, %gws_base
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i196)
  %cmp.i199 = icmp slt i32 %dec.i196, 1
  br i1 %cmp.i199, label %if.then.i200, label %amdgpu_ring_write.exit197.amdgpu_ring_write.exit210_crit_edge

amdgpu_ring_write.exit197.amdgpu_ring_write.exit210_crit_edge: ; preds = %amdgpu_ring_write.exit197
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit210

if.then.i200:                                     ; preds = %amdgpu_ring_write.exit197
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit210

amdgpu_ring_write.exit210:                        ; preds = %if.then.i200, %amdgpu_ring_write.exit197.amdgpu_ring_write.exit210_crit_edge
  %190 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %190)
  %191 = load ptr, ptr %ring1.i, align 4
  %192 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %192)
  %193 = load i64, ptr %wptr.i, align 8
  %inc.i203 = add i64 %193, 1
  store i64 %inc.i203, ptr %wptr.i, align 8
  %194 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %194)
  %195 = load i32, ptr %buf_mask.i, align 8
  %196 = trunc i64 %193 to i32
  %idxprom.i205 = and i32 %195, %196
  %arrayidx.i206 = getelementptr i32, ptr %191, i32 %idxprom.i205
  %197 = ptrtoint ptr %arrayidx.i206 to i32
  call void @__asan_store4_noabort(i32 %197)
  store volatile i32 %or, ptr %arrayidx.i206, align 4
  %198 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %198)
  %199 = load i64, ptr %ptr_mask.i, align 8
  %200 = load i64, ptr %wptr.i, align 8
  %and3.i208 = and i64 %200, %199
  store i64 %and3.i208, ptr %wptr.i, align 8
  %201 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %201)
  %202 = load i32, ptr %count_dw.i, align 8
  %dec.i209 = add i32 %202, -1
  store i32 %dec.i209, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i209)
  %cmp.i212 = icmp slt i32 %dec.i209, 1
  br i1 %cmp.i212, label %if.then.i213, label %amdgpu_ring_write.exit210.amdgpu_ring_write.exit223_crit_edge

amdgpu_ring_write.exit210.amdgpu_ring_write.exit223_crit_edge: ; preds = %amdgpu_ring_write.exit210
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit223

if.then.i213:                                     ; preds = %amdgpu_ring_write.exit210
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit223

amdgpu_ring_write.exit223:                        ; preds = %if.then.i213, %amdgpu_ring_write.exit210.amdgpu_ring_write.exit223_crit_edge
  %203 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %203)
  %204 = load ptr, ptr %ring1.i, align 4
  %205 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %205)
  %206 = load i64, ptr %wptr.i, align 8
  %inc.i216 = add i64 %206, 1
  store i64 %inc.i216, ptr %wptr.i, align 8
  %207 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %207)
  %208 = load i32, ptr %buf_mask.i, align 8
  %209 = trunc i64 %206 to i32
  %idxprom.i218 = and i32 %208, %209
  %arrayidx.i219 = getelementptr i32, ptr %204, i32 %idxprom.i218
  %210 = ptrtoint ptr %arrayidx.i219 to i32
  call void @__asan_store4_noabort(i32 %210)
  store volatile i32 -1073531136, ptr %arrayidx.i219, align 4
  %211 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %211)
  %212 = load i64, ptr %ptr_mask.i, align 8
  %213 = load i64, ptr %wptr.i, align 8
  %and3.i221 = and i64 %213, %212
  store i64 %and3.i221, ptr %wptr.i, align 8
  %214 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %214)
  %215 = load i32, ptr %count_dw.i, align 8
  %dec.i222 = add i32 %215, -1
  store i32 %dec.i222, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i222)
  %cmp.i225 = icmp slt i32 %dec.i222, 1
  br i1 %cmp.i225, label %if.then.i226, label %amdgpu_ring_write.exit223.amdgpu_ring_write.exit236_crit_edge

amdgpu_ring_write.exit223.amdgpu_ring_write.exit236_crit_edge: ; preds = %amdgpu_ring_write.exit223
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit236

if.then.i226:                                     ; preds = %amdgpu_ring_write.exit223
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit236

amdgpu_ring_write.exit236:                        ; preds = %if.then.i226, %amdgpu_ring_write.exit223.amdgpu_ring_write.exit236_crit_edge
  %216 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %216)
  %217 = load ptr, ptr %ring1.i, align 4
  %218 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %218)
  %219 = load i64, ptr %wptr.i, align 8
  %inc.i229 = add i64 %219, 1
  store i64 %inc.i229, ptr %wptr.i, align 8
  %220 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %220)
  %221 = load i32, ptr %buf_mask.i, align 8
  %222 = trunc i64 %219 to i32
  %idxprom.i231 = and i32 %221, %222
  %arrayidx.i232 = getelementptr i32, ptr %217, i32 %idxprom.i231
  %223 = ptrtoint ptr %arrayidx.i232 to i32
  call void @__asan_store4_noabort(i32 %223)
  store volatile i32 0, ptr %arrayidx.i232, align 4
  %224 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %224)
  %225 = load i64, ptr %ptr_mask.i, align 8
  %226 = load i64, ptr %wptr.i, align 8
  %and3.i234 = and i64 %226, %225
  store i64 %and3.i234, ptr %wptr.i, align 8
  %227 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %227)
  %228 = load i32, ptr %count_dw.i, align 8
  %dec.i235 = add i32 %228, -1
  store i32 %dec.i235, ptr %count_dw.i, align 8
  %oa = getelementptr [16 x %struct.amdgpu_gds_reg_offset], ptr @amdgpu_gds_reg_offset, i32 0, i32 %vmid, i32 3
  %229 = ptrtoint ptr %oa to i32
  call void @__asan_load4_noabort(i32 %229)
  %230 = load i32, ptr %oa, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i235)
  %cmp.i238 = icmp slt i32 %dec.i235, 1
  br i1 %cmp.i238, label %if.then.i239, label %amdgpu_ring_write.exit236.amdgpu_ring_write.exit249_crit_edge

amdgpu_ring_write.exit236.amdgpu_ring_write.exit249_crit_edge: ; preds = %amdgpu_ring_write.exit236
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit249

if.then.i239:                                     ; preds = %amdgpu_ring_write.exit236
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit249

amdgpu_ring_write.exit249:                        ; preds = %if.then.i239, %amdgpu_ring_write.exit236.amdgpu_ring_write.exit249_crit_edge
  %231 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %231)
  %232 = load ptr, ptr %ring1.i, align 4
  %233 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %233)
  %234 = load i64, ptr %wptr.i, align 8
  %inc.i242 = add i64 %234, 1
  store i64 %inc.i242, ptr %wptr.i, align 8
  %235 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %235)
  %236 = load i32, ptr %buf_mask.i, align 8
  %237 = trunc i64 %234 to i32
  %idxprom.i244 = and i32 %236, %237
  %arrayidx.i245 = getelementptr i32, ptr %232, i32 %idxprom.i244
  %238 = ptrtoint ptr %arrayidx.i245 to i32
  call void @__asan_store4_noabort(i32 %238)
  store volatile i32 %230, ptr %arrayidx.i245, align 4
  %239 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %239)
  %240 = load i64, ptr %ptr_mask.i, align 8
  %241 = load i64, ptr %wptr.i, align 8
  %and3.i247 = and i64 %241, %240
  store i64 %and3.i247, ptr %wptr.i, align 8
  %242 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %242)
  %243 = load i32, ptr %count_dw.i, align 8
  %dec.i248 = add i32 %243, -1
  store i32 %dec.i248, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i248)
  %cmp.i251 = icmp slt i32 %dec.i248, 1
  br i1 %cmp.i251, label %if.then.i252, label %amdgpu_ring_write.exit249.amdgpu_ring_write.exit262_crit_edge

amdgpu_ring_write.exit249.amdgpu_ring_write.exit262_crit_edge: ; preds = %amdgpu_ring_write.exit249
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit262

if.then.i252:                                     ; preds = %amdgpu_ring_write.exit249
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit262

amdgpu_ring_write.exit262:                        ; preds = %if.then.i252, %amdgpu_ring_write.exit249.amdgpu_ring_write.exit262_crit_edge
  %244 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %244)
  %245 = load ptr, ptr %ring1.i, align 4
  %246 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %246)
  %247 = load i64, ptr %wptr.i, align 8
  %inc.i255 = add i64 %247, 1
  store i64 %inc.i255, ptr %wptr.i, align 8
  %248 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %248)
  %249 = load i32, ptr %buf_mask.i, align 8
  %250 = trunc i64 %247 to i32
  %idxprom.i257 = and i32 %249, %250
  %arrayidx.i258 = getelementptr i32, ptr %245, i32 %idxprom.i257
  %251 = ptrtoint ptr %arrayidx.i258 to i32
  call void @__asan_store4_noabort(i32 %251)
  store volatile i32 0, ptr %arrayidx.i258, align 4
  %252 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %252)
  %253 = load i64, ptr %ptr_mask.i, align 8
  %254 = load i64, ptr %wptr.i, align 8
  %and3.i260 = and i64 %254, %253
  store i64 %and3.i260, ptr %wptr.i, align 8
  %255 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %255)
  %256 = load i32, ptr %count_dw.i, align 8
  %dec.i261 = add i32 %256, -1
  store i32 %dec.i261, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i261)
  %cmp.i264 = icmp slt i32 %dec.i261, 1
  br i1 %cmp.i264, label %if.then.i265, label %amdgpu_ring_write.exit262.amdgpu_ring_write.exit275_crit_edge

amdgpu_ring_write.exit262.amdgpu_ring_write.exit275_crit_edge: ; preds = %amdgpu_ring_write.exit262
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit275

if.then.i265:                                     ; preds = %amdgpu_ring_write.exit262
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit275

amdgpu_ring_write.exit275:                        ; preds = %if.then.i265, %amdgpu_ring_write.exit262.amdgpu_ring_write.exit275_crit_edge
  %shl5.neg = shl nsw i32 -1, %oa_base
  %add = add i32 %oa_size, %oa_base
  %shl4 = shl nuw i32 1, %add
  %sub = add i32 %shl4, %shl5.neg
  %257 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %257)
  %258 = load ptr, ptr %ring1.i, align 4
  %259 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %259)
  %260 = load i64, ptr %wptr.i, align 8
  %inc.i268 = add i64 %260, 1
  store i64 %inc.i268, ptr %wptr.i, align 8
  %261 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %261)
  %262 = load i32, ptr %buf_mask.i, align 8
  %263 = trunc i64 %260 to i32
  %idxprom.i270 = and i32 %262, %263
  %arrayidx.i271 = getelementptr i32, ptr %258, i32 %idxprom.i270
  %264 = ptrtoint ptr %arrayidx.i271 to i32
  call void @__asan_store4_noabort(i32 %264)
  store volatile i32 %sub, ptr %arrayidx.i271, align 4
  %265 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %265)
  %266 = load i64, ptr %ptr_mask.i, align 8
  %267 = load i64, ptr %wptr.i, align 8
  %and3.i273 = and i64 %267, %266
  store i64 %and3.i273, ptr %wptr.i, align 8
  %268 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %268)
  %269 = load i32, ptr %count_dw.i, align 8
  %dec.i274 = add i32 %269, -1
  store i32 %dec.i274, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_ring_test_ib(ptr noundef %ring, i32 noundef %timeout) #0 align 64 {
entry:
  %ib = alloca %struct.amdgpu_ib, align 8
  %f = alloca ptr, align 4
  %index = alloca i32, align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %ib) #12
  %2 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 1
  %3 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 3
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %f) #12
  %4 = ptrtoint ptr %f to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr null, ptr %f, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %index) #12
  %5 = ptrtoint ptr %index to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %index, align 4, !annotation !441
  %call = call i32 @amdgpu_device_wb_get(ptr noundef %1, ptr noundef nonnull %index) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %gpu_addr2 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 2
  %6 = ptrtoint ptr %gpu_addr2 to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %gpu_addr2, align 8
  %8 = ptrtoint ptr %index to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %index, align 4
  %wb4 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 1
  %10 = ptrtoint ptr %wb4 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %wb4, align 4
  %arrayidx = getelementptr i32, ptr %11, i32 %9
  %12 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %12)
  store volatile i32 -1377894710, ptr %arrayidx, align 4
  %13 = call ptr @memset(ptr %ib, i32 0, i32 24)
  %call5 = call i32 @amdgpu_ib_get(ptr noundef %1, ptr noundef null, i32 noundef 16, i32 noundef 2, ptr noundef nonnull %ib) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call5)
  %tobool6.not = icmp eq i32 %call5, 0
  br i1 %tobool6.not, label %if.end8, label %if.end.err1_crit_edge

if.end.err1_crit_edge:                            ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %err1

if.end8:                                          ; preds = %if.end
  %mul = shl i32 %9, 2
  %conv = zext i32 %mul to i64
  %add = add i64 %7, %conv
  %14 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %3, align 8
  %16 = ptrtoint ptr %15 to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 -1073531136, ptr %15, align 4
  %17 = load ptr, ptr %3, align 8
  %arrayidx11 = getelementptr i32, ptr %17, i32 1
  %18 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 1049856, ptr %arrayidx11, align 4
  %conv12 = trunc i64 %add to i32
  %19 = load ptr, ptr %3, align 8
  %arrayidx14 = getelementptr i32, ptr %19, i32 2
  %20 = ptrtoint ptr %arrayidx14 to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %conv12, ptr %arrayidx14, align 4
  %shr = lshr i64 %add, 32
  %conv16 = trunc i64 %shr to i32
  %21 = load ptr, ptr %3, align 8
  %arrayidx18 = getelementptr i32, ptr %21, i32 3
  %22 = ptrtoint ptr %arrayidx18 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %conv16, ptr %arrayidx18, align 4
  %23 = load ptr, ptr %3, align 8
  %arrayidx20 = getelementptr i32, ptr %23, i32 4
  %24 = ptrtoint ptr %arrayidx20 to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 -559038737, ptr %arrayidx20, align 4
  %25 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 5, ptr %2, align 4
  %call21 = call i32 @amdgpu_ib_schedule(ptr noundef %ring, i32 noundef 1, ptr noundef nonnull %ib, ptr noundef null, ptr noundef nonnull %f) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call21)
  %tobool22.not = icmp eq i32 %call21, 0
  br i1 %tobool22.not, label %if.end24, label %if.end8.err2_crit_edge

if.end8.err2_crit_edge:                           ; preds = %if.end8
  call void @__sanitizer_cov_trace_pc() #14
  br label %err2

if.end24:                                         ; preds = %if.end8
  %26 = ptrtoint ptr %f to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %f, align 4
  %call25 = call i32 @dma_fence_wait_timeout(ptr noundef %27, i1 noundef zeroext false, i32 noundef %timeout) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call25)
  %cmp = icmp eq i32 %call25, 0
  br i1 %cmp, label %if.end24.err2_crit_edge, label %if.else

if.end24.err2_crit_edge:                          ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #14
  br label %err2

if.else:                                          ; preds = %if.end24
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call25)
  %cmp28 = icmp slt i32 %call25, 0
  br i1 %cmp28, label %if.else.err2_crit_edge, label %if.end32

if.else.err2_crit_edge:                           ; preds = %if.else
  call void @__sanitizer_cov_trace_pc() #14
  br label %err2

if.end32:                                         ; preds = %if.else
  call void @__sanitizer_cov_trace_pc() #14
  %28 = ptrtoint ptr %wb4 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %wb4, align 4
  %30 = ptrtoint ptr %index to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %index, align 4
  %arrayidx35 = getelementptr i32, ptr %29, i32 %31
  %32 = ptrtoint ptr %arrayidx35 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load volatile i32, ptr %arrayidx35, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 -559038737, i32 %33)
  %cmp36 = icmp eq i32 %33, -559038737
  %. = select i1 %cmp36, i32 0, i32 -22
  br label %err2

err2:                                             ; preds = %if.end32, %if.else.err2_crit_edge, %if.end24.err2_crit_edge, %if.end8.err2_crit_edge
  %r.0 = phi i32 [ %call21, %if.end8.err2_crit_edge ], [ %call25, %if.else.err2_crit_edge ], [ -110, %if.end24.err2_crit_edge ], [ %., %if.end32 ]
  call void @amdgpu_ib_free(ptr noundef %1, ptr noundef nonnull %ib, ptr noundef null) #12
  %34 = ptrtoint ptr %f to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %f, align 4
  %tobool.not.i = icmp eq ptr %35, null
  br i1 %tobool.not.i, label %err2.err1_crit_edge, label %if.then.i

err2.err1_crit_edge:                              ; preds = %err2
  call void @__sanitizer_cov_trace_pc() #14
  br label %err1

if.then.i:                                        ; preds = %err2
  %refcount.i = getelementptr inbounds %struct.dma_fence, ptr %35, i32 0, i32 6
  %call.i.i.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %refcount.i, i32 noundef 4) #12
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #12, !srcloc !433
  call void @llvm.prefetch.p0(ptr %refcount.i, i32 1, i32 3, i32 1) #12
  %36 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %refcount.i, ptr %refcount.i, i32 1, ptr elementtype(i32) %refcount.i) #12, !srcloc !434
  %asmresult.i.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %36, 0
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %asmresult.i.i.i.i.i.i.i.i)
  %cmp.i.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i.i, label %if.then.i.i, label %if.end5.i.i.i.i.i

if.end5.i.i.i.i.i:                                ; preds = %if.then.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %asmresult.i.i.i.i.i.i.i.i)
  %.not.i.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i.i, label %if.end5.i.i.i.i.i.err1_crit_edge, label %if.then10.i.i.i.i.i, !prof !435

if.end5.i.i.i.i.i.err1_crit_edge:                 ; preds = %if.end5.i.i.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %err1

if.then10.i.i.i.i.i:                              ; preds = %if.end5.i.i.i.i.i
  call void @__sanitizer_cov_trace_pc() #14
  call void @refcount_warn_saturate(ptr noundef %refcount.i, i32 noundef 3) #12
  br label %err1

if.then.i.i:                                      ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #12, !srcloc !436
  call void @dma_fence_release(ptr noundef %refcount.i) #12
  br label %err1

err1:                                             ; preds = %if.then.i.i, %if.then10.i.i.i.i.i, %if.end5.i.i.i.i.i.err1_crit_edge, %err2.err1_crit_edge, %if.end.err1_crit_edge
  %r.1 = phi i32 [ %call5, %if.end.err1_crit_edge ], [ %r.0, %err2.err1_crit_edge ], [ %r.0, %if.end5.i.i.i.i.i.err1_crit_edge ], [ %r.0, %if.then10.i.i.i.i.i ], [ %r.0, %if.then.i.i ]
  %37 = ptrtoint ptr %index to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %index, align 4
  call void @amdgpu_device_wb_free(ptr noundef %1, i32 noundef %38) #12
  br label %cleanup

cleanup:                                          ; preds = %err1, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ %r.1, %err1 ], [ %call, %entry.cleanup_crit_edge ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %index) #12
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %f) #12
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %ib) #12
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_ring_emit_init_cond_exec(ptr noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073536512, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  %cond_exe_gpu_addr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 35
  %15 = ptrtoint ptr %cond_exe_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %15)
  %16 = load i64, ptr %cond_exe_gpu_addr, align 8
  %conv = trunc i64 %16 to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i16 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i16, label %if.then.i17, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit27_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit27_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit27

if.then.i17:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit27

amdgpu_ring_write.exit27:                         ; preds = %if.then.i17, %amdgpu_ring_write.exit.amdgpu_ring_write.exit27_crit_edge
  %17 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %ring1.i, align 4
  %19 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %19)
  %20 = load i64, ptr %wptr.i, align 8
  %inc.i20 = add i64 %20, 1
  store i64 %inc.i20, ptr %wptr.i, align 8
  %21 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %buf_mask.i, align 8
  %23 = trunc i64 %20 to i32
  %idxprom.i22 = and i32 %22, %23
  %arrayidx.i23 = getelementptr i32, ptr %18, i32 %idxprom.i22
  %24 = ptrtoint ptr %arrayidx.i23 to i32
  call void @__asan_store4_noabort(i32 %24)
  store volatile i32 %conv, ptr %arrayidx.i23, align 4
  %25 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %25)
  %26 = load i64, ptr %ptr_mask.i, align 8
  %27 = load i64, ptr %wptr.i, align 8
  %and3.i25 = and i64 %27, %26
  store i64 %and3.i25, ptr %wptr.i, align 8
  %28 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %count_dw.i, align 8
  %dec.i26 = add i32 %29, -1
  store i32 %dec.i26, ptr %count_dw.i, align 8
  %30 = ptrtoint ptr %cond_exe_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %cond_exe_gpu_addr, align 8
  %shr = lshr i64 %31, 32
  %conv3 = trunc i64 %shr to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i26)
  %cmp.i29 = icmp slt i32 %dec.i26, 1
  br i1 %cmp.i29, label %if.then.i30, label %amdgpu_ring_write.exit27.amdgpu_ring_write.exit40_crit_edge

amdgpu_ring_write.exit27.amdgpu_ring_write.exit40_crit_edge: ; preds = %amdgpu_ring_write.exit27
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit40

if.then.i30:                                      ; preds = %amdgpu_ring_write.exit27
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit40

amdgpu_ring_write.exit40:                         ; preds = %if.then.i30, %amdgpu_ring_write.exit27.amdgpu_ring_write.exit40_crit_edge
  %32 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %ring1.i, align 4
  %34 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %34)
  %35 = load i64, ptr %wptr.i, align 8
  %inc.i33 = add i64 %35, 1
  store i64 %inc.i33, ptr %wptr.i, align 8
  %36 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %buf_mask.i, align 8
  %38 = trunc i64 %35 to i32
  %idxprom.i35 = and i32 %37, %38
  %arrayidx.i36 = getelementptr i32, ptr %33, i32 %idxprom.i35
  %39 = ptrtoint ptr %arrayidx.i36 to i32
  call void @__asan_store4_noabort(i32 %39)
  store volatile i32 %conv3, ptr %arrayidx.i36, align 4
  %40 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %40)
  %41 = load i64, ptr %ptr_mask.i, align 8
  %42 = load i64, ptr %wptr.i, align 8
  %and3.i38 = and i64 %42, %41
  store i64 %and3.i38, ptr %wptr.i, align 8
  %43 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %count_dw.i, align 8
  %dec.i39 = add i32 %44, -1
  store i32 %dec.i39, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i39)
  %cmp.i42 = icmp slt i32 %dec.i39, 1
  br i1 %cmp.i42, label %if.then.i43, label %amdgpu_ring_write.exit40.amdgpu_ring_write.exit53_crit_edge

amdgpu_ring_write.exit40.amdgpu_ring_write.exit53_crit_edge: ; preds = %amdgpu_ring_write.exit40
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit53

if.then.i43:                                      ; preds = %amdgpu_ring_write.exit40
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit53

amdgpu_ring_write.exit53:                         ; preds = %if.then.i43, %amdgpu_ring_write.exit40.amdgpu_ring_write.exit53_crit_edge
  %45 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %ring1.i, align 4
  %47 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %47)
  %48 = load i64, ptr %wptr.i, align 8
  %inc.i46 = add i64 %48, 1
  store i64 %inc.i46, ptr %wptr.i, align 8
  %49 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %buf_mask.i, align 8
  %51 = trunc i64 %48 to i32
  %idxprom.i48 = and i32 %50, %51
  %arrayidx.i49 = getelementptr i32, ptr %46, i32 %idxprom.i48
  %52 = ptrtoint ptr %arrayidx.i49 to i32
  call void @__asan_store4_noabort(i32 %52)
  store volatile i32 0, ptr %arrayidx.i49, align 4
  %53 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %53)
  %54 = load i64, ptr %ptr_mask.i, align 8
  %55 = load i64, ptr %wptr.i, align 8
  %and3.i51 = and i64 %55, %54
  store i64 %and3.i51, ptr %wptr.i, align 8
  %56 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %count_dw.i, align 8
  %dec.i52 = add i32 %57, -1
  store i32 %dec.i52, ptr %count_dw.i, align 8
  %58 = load i32, ptr %buf_mask.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i52)
  %cmp.i55 = icmp slt i32 %dec.i52, 1
  br i1 %cmp.i55, label %if.then.i56, label %amdgpu_ring_write.exit53.amdgpu_ring_write.exit66_crit_edge

amdgpu_ring_write.exit53.amdgpu_ring_write.exit66_crit_edge: ; preds = %amdgpu_ring_write.exit53
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit66

if.then.i56:                                      ; preds = %amdgpu_ring_write.exit53
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit66

amdgpu_ring_write.exit66:                         ; preds = %if.then.i56, %amdgpu_ring_write.exit53.amdgpu_ring_write.exit66_crit_edge
  %59 = trunc i64 %and3.i51 to i32
  %conv6 = and i32 %58, %59
  %60 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %ring1.i, align 4
  %62 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %wptr.i, align 8
  %inc.i59 = add i64 %63, 1
  store i64 %inc.i59, ptr %wptr.i, align 8
  %64 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %buf_mask.i, align 8
  %66 = trunc i64 %63 to i32
  %idxprom.i61 = and i32 %65, %66
  %arrayidx.i62 = getelementptr i32, ptr %61, i32 %idxprom.i61
  %67 = ptrtoint ptr %arrayidx.i62 to i32
  call void @__asan_store4_noabort(i32 %67)
  store volatile i32 1437226410, ptr %arrayidx.i62, align 4
  %68 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %68)
  %69 = load i64, ptr %ptr_mask.i, align 8
  %70 = load i64, ptr %wptr.i, align 8
  %and3.i64 = and i64 %70, %69
  store i64 %and3.i64, ptr %wptr.i, align 8
  %71 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %count_dw.i, align 8
  %dec.i65 = add i32 %72, -1
  store i32 %dec.i65, ptr %count_dw.i, align 8
  ret i32 %conv6
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_patch_cond_exec(ptr nocapture noundef readonly %ring, i32 noundef %offset) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %buf_mask = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %0 = ptrtoint ptr %buf_mask to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %buf_mask, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %1, i32 %offset)
  %cmp = icmp ult i32 %1, %offset
  br i1 %cmp, label %do.body2, label %do.body8, !prof !442

do.body2:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 6388, 0\0A.popsection", ""() #12, !srcloc !443
  unreachable

do.body8:                                         ; preds = %entry
  %ring9 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring9 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring9, align 4
  %arrayidx = getelementptr i32, ptr %3, i32 %offset
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %arrayidx, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1437226410, i32 %5)
  %cmp10.not = icmp eq i32 %5, 1437226410
  br i1 %cmp10.not, label %do.end26, label %do.body18, !prof !435

do.body18:                                        ; preds = %do.body8
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 6389, 0\0A.popsection", ""() #12, !srcloc !444
  unreachable

do.end26:                                         ; preds = %do.body8
  %wptr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %6 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %wptr, align 8
  %8 = trunc i64 %7 to i32
  %9 = and i32 %1, %8
  %conv28 = add i32 %9, -1
  call void @__sanitizer_cov_trace_cmp4(i32 %conv28, i32 %offset)
  %cmp29 = icmp ugt i32 %conv28, %offset
  br i1 %cmp29, label %if.then37, label %if.else, !prof !435

if.then37:                                        ; preds = %do.end26
  call void @__sanitizer_cov_trace_pc() #14
  %sub38 = sub i32 %conv28, %offset
  br label %if.end44

if.else:                                          ; preds = %do.end26
  call void @__sanitizer_cov_trace_pc() #14
  %ring_size = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 9
  %10 = ptrtoint ptr %ring_size to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %ring_size, align 8
  %shr = lshr i32 %11, 2
  %sub41 = sub i32 %conv28, %offset
  %add = add i32 %sub41, %shr
  br label %if.end44

if.end44:                                         ; preds = %if.else, %if.then37
  %add.sink = phi i32 [ %add, %if.else ], [ %sub38, %if.then37 ]
  %12 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %12)
  store volatile i32 %add.sink, ptr %arrayidx, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_ring_emit_sb(ptr nocapture noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073706240, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i3 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i3, label %if.then.i4, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit14_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit14_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit14

if.then.i4:                                       ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit14

amdgpu_ring_write.exit14:                         ; preds = %if.then.i4, %amdgpu_ring_write.exit.amdgpu_ring_write.exit14_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i7 = add i64 %18, 1
  store i64 %inc.i7, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i9 = and i32 %20, %21
  %arrayidx.i10 = getelementptr i32, ptr %16, i32 %idxprom.i9
  %22 = ptrtoint ptr %arrayidx.i10 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 0, ptr %arrayidx.i10, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i12 = and i64 %25, %24
  store i64 %and3.i12, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i13 = add i32 %27, -1
  store i32 %dec.i13, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_ring_emit_cntxcntl(ptr noundef %ring, i32 noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 132
  %2 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %virt, align 8
  %and = and i32 %3, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %if.then

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %entry
  %chained_ib_support.i = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 132, i32 3
  %4 = ptrtoint ptr %chained_ib_support.i to i32
  call void @__asan_load1_noabort(i32 %4)
  %5 = load i8, ptr %chained_ib_support.i, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %5)
  %tobool.not.i = icmp eq i8 %5, 0
  %call3.i = tail call i64 @amdgpu_csa_vaddr(ptr noundef %1) #12
  %extract.t17.i = trunc i64 %call3.i to i32
  %extract19.i = lshr i64 %call3.i, 32
  %extract.t20.i = trunc i64 %extract19.i to i32
  %..i = select i1 %tobool.not.i, i32 6, i32 12
  %shl.i = shl nuw nsw i32 %..i, 16
  %or.i = or i32 %shl.i, -1073727744
  %count_dw.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %6 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %7)
  %cmp.i.i = icmp slt i32 %7, 1
  br i1 %cmp.i.i, label %if.then.i.i, label %if.then.amdgpu_ring_write.exit.i_crit_edge

if.then.amdgpu_ring_write.exit.i_crit_edge:       ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i

if.then.i.i:                                      ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i

amdgpu_ring_write.exit.i:                         ; preds = %if.then.i.i, %if.then.amdgpu_ring_write.exit.i_crit_edge
  %ring1.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %8 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %ring1.i.i, align 4
  %wptr.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %10 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %wptr.i.i, align 8
  %inc.i.i = add i64 %11, 1
  store i64 %inc.i.i, ptr %wptr.i.i, align 8
  %buf_mask.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %12 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %buf_mask.i.i, align 8
  %14 = trunc i64 %11 to i32
  %idxprom.i.i = and i32 %13, %14
  %arrayidx.i.i = getelementptr i32, ptr %9, i32 %idxprom.i.i
  %15 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store volatile i32 %or.i, ptr %arrayidx.i.i, align 4
  %ptr_mask.i.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %16 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %16)
  %17 = load i64, ptr %ptr_mask.i.i, align 8
  %18 = load i64, ptr %wptr.i.i, align 8
  %and3.i.i = and i64 %18, %17
  store i64 %and3.i.i, ptr %wptr.i.i, align 8
  %19 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %count_dw.i.i, align 8
  %dec.i.i = add i32 %20, -1
  store i32 %dec.i.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i)
  %cmp.i22.i = icmp slt i32 %dec.i.i, 1
  br i1 %cmp.i22.i, label %if.then.i23.i, label %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit33.i_crit_edge

amdgpu_ring_write.exit.i.amdgpu_ring_write.exit33.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit33.i

if.then.i23.i:                                    ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit33.i

amdgpu_ring_write.exit33.i:                       ; preds = %if.then.i23.i, %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit33.i_crit_edge
  %21 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %ring1.i.i, align 4
  %23 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %wptr.i.i, align 8
  %inc.i26.i = add i64 %24, 1
  store i64 %inc.i26.i, ptr %wptr.i.i, align 8
  %25 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %buf_mask.i.i, align 8
  %27 = trunc i64 %24 to i32
  %idxprom.i28.i = and i32 %26, %27
  %arrayidx.i29.i = getelementptr i32, ptr %22, i32 %idxprom.i28.i
  %28 = ptrtoint ptr %arrayidx.i29.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store volatile i32 -2146433024, ptr %arrayidx.i29.i, align 4
  %29 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %29)
  %30 = load i64, ptr %ptr_mask.i.i, align 8
  %31 = load i64, ptr %wptr.i.i, align 8
  %and3.i31.i = and i64 %31, %30
  store i64 %and3.i31.i, ptr %wptr.i.i, align 8
  %32 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %count_dw.i.i, align 8
  %dec.i32.i = add i32 %33, -1
  store i32 %dec.i32.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i32.i)
  %cmp.i35.i = icmp slt i32 %dec.i32.i, 1
  br i1 %cmp.i35.i, label %if.then.i36.i, label %amdgpu_ring_write.exit33.i.amdgpu_ring_write.exit46.i_crit_edge

amdgpu_ring_write.exit33.i.amdgpu_ring_write.exit46.i_crit_edge: ; preds = %amdgpu_ring_write.exit33.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit46.i

if.then.i36.i:                                    ; preds = %amdgpu_ring_write.exit33.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit46.i

amdgpu_ring_write.exit46.i:                       ; preds = %if.then.i36.i, %amdgpu_ring_write.exit33.i.amdgpu_ring_write.exit46.i_crit_edge
  %34 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %ring1.i.i, align 4
  %36 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %wptr.i.i, align 8
  %inc.i39.i = add i64 %37, 1
  store i64 %inc.i39.i, ptr %wptr.i.i, align 8
  %38 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %buf_mask.i.i, align 8
  %40 = trunc i64 %37 to i32
  %idxprom.i41.i = and i32 %39, %40
  %arrayidx.i42.i = getelementptr i32, ptr %35, i32 %idxprom.i41.i
  %41 = ptrtoint ptr %arrayidx.i42.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store volatile i32 %extract.t17.i, ptr %arrayidx.i42.i, align 4
  %42 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %42)
  %43 = load i64, ptr %ptr_mask.i.i, align 8
  %44 = load i64, ptr %wptr.i.i, align 8
  %and3.i44.i = and i64 %44, %43
  store i64 %and3.i44.i, ptr %wptr.i.i, align 8
  %45 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %count_dw.i.i, align 8
  %dec.i45.i = add i32 %46, -1
  store i32 %dec.i45.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i45.i)
  %cmp.i48.i = icmp slt i32 %dec.i45.i, 1
  br i1 %cmp.i48.i, label %if.then.i49.i, label %amdgpu_ring_write.exit46.i.amdgpu_ring_write.exit59.i_crit_edge

amdgpu_ring_write.exit46.i.amdgpu_ring_write.exit59.i_crit_edge: ; preds = %amdgpu_ring_write.exit46.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit59.i

if.then.i49.i:                                    ; preds = %amdgpu_ring_write.exit46.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit59.i

amdgpu_ring_write.exit59.i:                       ; preds = %if.then.i49.i, %amdgpu_ring_write.exit46.i.amdgpu_ring_write.exit59.i_crit_edge
  %47 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %ring1.i.i, align 4
  %49 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %wptr.i.i, align 8
  %inc.i52.i = add i64 %50, 1
  store i64 %inc.i52.i, ptr %wptr.i.i, align 8
  %51 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %buf_mask.i.i, align 8
  %53 = trunc i64 %50 to i32
  %idxprom.i54.i = and i32 %52, %53
  %arrayidx.i55.i = getelementptr i32, ptr %48, i32 %idxprom.i54.i
  %54 = ptrtoint ptr %arrayidx.i55.i to i32
  call void @__asan_store4_noabort(i32 %54)
  store volatile i32 %extract.t20.i, ptr %arrayidx.i55.i, align 4
  %55 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %55)
  %56 = load i64, ptr %ptr_mask.i.i, align 8
  %57 = load i64, ptr %wptr.i.i, align 8
  %and3.i57.i = and i64 %57, %56
  store i64 %and3.i57.i, ptr %wptr.i.i, align 8
  %58 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %count_dw.i.i, align 8
  %dec.i58.i = add i32 %59, -1
  store i32 %dec.i58.i, ptr %count_dw.i.i, align 8
  %sub.i = add nsw i32 %..i, -2
  call void @__sanitizer_cov_trace_cmp4(i32 %dec.i58.i, i32 %sub.i)
  %cmp.i60.i = icmp slt i32 %dec.i58.i, %sub.i
  br i1 %cmp.i60.i, label %if.then.i61.i, label %amdgpu_ring_write.exit59.i.if.end.i.i_crit_edge, !prof !442

amdgpu_ring_write.exit59.i.if.end.i.i_crit_edge:  ; preds = %amdgpu_ring_write.exit59.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i.i

if.then.i61.i:                                    ; preds = %amdgpu_ring_write.exit59.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i61.i, %amdgpu_ring_write.exit59.i.if.end.i.i_crit_edge
  %60 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %60)
  %61 = load i64, ptr %wptr.i.i, align 8
  %62 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %buf_mask.i.i, align 8
  %64 = trunc i64 %61 to i32
  %conv3.i.i = and i32 %63, %64
  %add.i.i = add i32 %63, 1
  %sub.i.i = sub i32 %add.i.i, %conv3.i.i
  %65 = tail call i32 @llvm.umin.i32(i32 %sub.i.i, i32 %sub.i) #12
  %sub8.i.i = sub nsw i32 %sub.i, %65
  %shl.i.i = shl nuw nsw i32 %65, 2
  %shl9.i.i = shl nsw i32 %sub8.i.i, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %65)
  %tobool10.not.i.i = icmp eq i32 %65, 0
  br i1 %tobool10.not.i.i, label %if.end.i.i.if.end12.i.i_crit_edge, label %if.then11.i.i

if.end.i.i.if.end12.i.i_crit_edge:                ; preds = %if.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end12.i.i

if.then11.i.i:                                    ; preds = %if.end.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %66 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load ptr, ptr %ring1.i.i, align 4
  %arrayidx.i64.i = getelementptr i32, ptr %67, i32 %conv3.i.i
  %68 = call ptr @memcpy(ptr %arrayidx.i64.i, ptr @__const.gfx_v8_0_ring_emit_ce_meta.ce_payload, i32 %shl.i.i)
  br label %if.end12.i.i

if.end12.i.i:                                     ; preds = %if.then11.i.i, %if.end.i.i.if.end12.i.i_crit_edge
  call void @__sanitizer_cov_trace_cmp4(i32 %sub.i, i32 %sub.i.i)
  %tobool13.not.i.not.i = icmp ugt i32 %sub.i, %sub.i.i
  br i1 %tobool13.not.i.not.i, label %if.then14.i.i, label %if.end12.i.i.gfx_v8_0_ring_emit_ce_meta.exit_crit_edge

if.end12.i.i.gfx_v8_0_ring_emit_ce_meta.exit_crit_edge: ; preds = %if.end12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_ring_emit_ce_meta.exit

if.then14.i.i:                                    ; preds = %if.end12.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %add.ptr.i.i = getelementptr i8, ptr @__const.gfx_v8_0_ring_emit_ce_meta.ce_payload, i32 %shl.i.i
  %69 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %ring1.i.i, align 4
  %71 = call ptr @memcpy(ptr %70, ptr %add.ptr.i.i, i32 %shl9.i.i)
  br label %gfx_v8_0_ring_emit_ce_meta.exit

gfx_v8_0_ring_emit_ce_meta.exit:                  ; preds = %if.then14.i.i, %if.end12.i.i.gfx_v8_0_ring_emit_ce_meta.exit_crit_edge
  %72 = zext i32 %sub.i to i64
  %73 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %73)
  %74 = load i64, ptr %wptr.i.i, align 8
  %add19.i.i = add i64 %74, %72
  %75 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %75)
  %76 = load i64, ptr %ptr_mask.i.i, align 8
  %and21.i.i = and i64 %76, %add19.i.i
  store i64 %and21.i.i, ptr %wptr.i.i, align 8
  %77 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %count_dw.i.i, align 8
  %sub23.i.i = sub i32 %78, %sub.i
  store i32 %sub23.i.i, ptr %count_dw.i.i, align 8
  br label %if.end

if.end:                                           ; preds = %gfx_v8_0_ring_emit_ce_meta.exit, %entry.if.end_crit_edge
  %and1 = and i32 %flags, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and1)
  %tobool2.not = icmp eq i32 %and1, 0
  br i1 %tobool2.not, label %if.else, label %if.then3

if.then3:                                         ; preds = %if.end
  %count_dw.i.i32 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %79 = ptrtoint ptr %count_dw.i.i32 to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %count_dw.i.i32, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %80)
  %cmp.i.i33 = icmp slt i32 %80, 1
  br i1 %cmp.i.i33, label %if.then.i.i34, label %if.then3.amdgpu_ring_write.exit.i44_crit_edge

if.then3.amdgpu_ring_write.exit.i44_crit_edge:    ; preds = %if.then3
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i44

if.then.i.i34:                                    ; preds = %if.then3
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i44

amdgpu_ring_write.exit.i44:                       ; preds = %if.then.i.i34, %if.then3.amdgpu_ring_write.exit.i44_crit_edge
  %ring1.i.i35 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %81 = ptrtoint ptr %ring1.i.i35 to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load ptr, ptr %ring1.i.i35, align 4
  %wptr.i.i36 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %83 = ptrtoint ptr %wptr.i.i36 to i32
  call void @__asan_load8_noabort(i32 %83)
  %84 = load i64, ptr %wptr.i.i36, align 8
  %inc.i.i37 = add i64 %84, 1
  store i64 %inc.i.i37, ptr %wptr.i.i36, align 8
  %buf_mask.i.i38 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %85 = ptrtoint ptr %buf_mask.i.i38 to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %buf_mask.i.i38, align 8
  %87 = trunc i64 %84 to i32
  %idxprom.i.i39 = and i32 %86, %87
  %arrayidx.i.i40 = getelementptr i32, ptr %82, i32 %idxprom.i.i39
  %88 = ptrtoint ptr %arrayidx.i.i40 to i32
  call void @__asan_store4_noabort(i32 %88)
  store volatile i32 -1073723904, ptr %arrayidx.i.i40, align 4
  %ptr_mask.i.i41 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %89 = ptrtoint ptr %ptr_mask.i.i41 to i32
  call void @__asan_load8_noabort(i32 %89)
  %90 = load i64, ptr %ptr_mask.i.i41, align 8
  %91 = load i64, ptr %wptr.i.i36, align 8
  %and3.i.i42 = and i64 %91, %90
  store i64 %and3.i.i42, ptr %wptr.i.i36, align 8
  %92 = ptrtoint ptr %count_dw.i.i32 to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load i32, ptr %count_dw.i.i32, align 8
  %dec.i.i43 = add i32 %93, -1
  store i32 %dec.i.i43, ptr %count_dw.i.i32, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i43)
  %cmp.i5.i = icmp slt i32 %dec.i.i43, 1
  br i1 %cmp.i5.i, label %if.then.i6.i, label %amdgpu_ring_write.exit.i44.amdgpu_ring_write.exit16.i_crit_edge

amdgpu_ring_write.exit.i44.amdgpu_ring_write.exit16.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i44
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit16.i

if.then.i6.i:                                     ; preds = %amdgpu_ring_write.exit.i44
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit16.i

amdgpu_ring_write.exit16.i:                       ; preds = %if.then.i6.i, %amdgpu_ring_write.exit.i44.amdgpu_ring_write.exit16.i_crit_edge
  %94 = ptrtoint ptr %ring1.i.i35 to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %ring1.i.i35, align 4
  %96 = ptrtoint ptr %wptr.i.i36 to i32
  call void @__asan_load8_noabort(i32 %96)
  %97 = load i64, ptr %wptr.i.i36, align 8
  %inc.i9.i = add i64 %97, 1
  store i64 %inc.i9.i, ptr %wptr.i.i36, align 8
  %98 = ptrtoint ptr %buf_mask.i.i38 to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %buf_mask.i.i38, align 8
  %100 = trunc i64 %97 to i32
  %idxprom.i11.i = and i32 %99, %100
  %arrayidx.i12.i = getelementptr i32, ptr %95, i32 %idxprom.i11.i
  %101 = ptrtoint ptr %arrayidx.i12.i to i32
  call void @__asan_store4_noabort(i32 %101)
  store volatile i32 1039, ptr %arrayidx.i12.i, align 4
  %102 = ptrtoint ptr %ptr_mask.i.i41 to i32
  call void @__asan_load8_noabort(i32 %102)
  %103 = load i64, ptr %ptr_mask.i.i41, align 8
  %104 = load i64, ptr %wptr.i.i36, align 8
  %and3.i14.i = and i64 %104, %103
  store i64 %and3.i14.i, ptr %wptr.i.i36, align 8
  %105 = ptrtoint ptr %count_dw.i.i32 to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load i32, ptr %count_dw.i.i32, align 8
  %dec.i15.i = add i32 %106, -1
  store i32 %dec.i15.i, ptr %count_dw.i.i32, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i15.i)
  %cmp.i18.i = icmp slt i32 %dec.i15.i, 1
  br i1 %cmp.i18.i, label %if.then.i19.i, label %amdgpu_ring_write.exit16.i.amdgpu_ring_write.exit29.i_crit_edge

amdgpu_ring_write.exit16.i.amdgpu_ring_write.exit29.i_crit_edge: ; preds = %amdgpu_ring_write.exit16.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit29.i

if.then.i19.i:                                    ; preds = %amdgpu_ring_write.exit16.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit29.i

amdgpu_ring_write.exit29.i:                       ; preds = %if.then.i19.i, %amdgpu_ring_write.exit16.i.amdgpu_ring_write.exit29.i_crit_edge
  %107 = ptrtoint ptr %ring1.i.i35 to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load ptr, ptr %ring1.i.i35, align 4
  %109 = ptrtoint ptr %wptr.i.i36 to i32
  call void @__asan_load8_noabort(i32 %109)
  %110 = load i64, ptr %wptr.i.i36, align 8
  %inc.i22.i = add i64 %110, 1
  store i64 %inc.i22.i, ptr %wptr.i.i36, align 8
  %111 = ptrtoint ptr %buf_mask.i.i38 to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load i32, ptr %buf_mask.i.i38, align 8
  %113 = trunc i64 %110 to i32
  %idxprom.i24.i = and i32 %112, %113
  %arrayidx.i25.i = getelementptr i32, ptr %108, i32 %idxprom.i24.i
  %114 = ptrtoint ptr %arrayidx.i25.i to i32
  call void @__asan_store4_noabort(i32 %114)
  store volatile i32 -1073723904, ptr %arrayidx.i25.i, align 4
  %115 = ptrtoint ptr %ptr_mask.i.i41 to i32
  call void @__asan_load8_noabort(i32 %115)
  %116 = load i64, ptr %ptr_mask.i.i41, align 8
  %117 = load i64, ptr %wptr.i.i36, align 8
  %and3.i27.i = and i64 %117, %116
  store i64 %and3.i27.i, ptr %wptr.i.i36, align 8
  %118 = ptrtoint ptr %count_dw.i.i32 to i32
  call void @__asan_load4_noabort(i32 %118)
  %119 = load i32, ptr %count_dw.i.i32, align 8
  %dec.i28.i = add i32 %119, -1
  store i32 %dec.i28.i, ptr %count_dw.i.i32, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i28.i)
  %cmp.i31.i = icmp slt i32 %dec.i28.i, 1
  br i1 %cmp.i31.i, label %if.then.i32.i, label %amdgpu_ring_write.exit29.i.gfx_v8_0_ring_emit_vgt_flush.exit_crit_edge

amdgpu_ring_write.exit29.i.gfx_v8_0_ring_emit_vgt_flush.exit_crit_edge: ; preds = %amdgpu_ring_write.exit29.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_ring_emit_vgt_flush.exit

if.then.i32.i:                                    ; preds = %amdgpu_ring_write.exit29.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %gfx_v8_0_ring_emit_vgt_flush.exit

gfx_v8_0_ring_emit_vgt_flush.exit:                ; preds = %if.then.i32.i, %amdgpu_ring_write.exit29.i.gfx_v8_0_ring_emit_vgt_flush.exit_crit_edge
  %120 = ptrtoint ptr %ring1.i.i35 to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load ptr, ptr %ring1.i.i35, align 4
  %122 = ptrtoint ptr %wptr.i.i36 to i32
  call void @__asan_load8_noabort(i32 %122)
  %123 = load i64, ptr %wptr.i.i36, align 8
  %inc.i35.i = add i64 %123, 1
  store i64 %inc.i35.i, ptr %wptr.i.i36, align 8
  %124 = ptrtoint ptr %buf_mask.i.i38 to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %buf_mask.i.i38, align 8
  %126 = trunc i64 %123 to i32
  %idxprom.i37.i = and i32 %125, %126
  %arrayidx.i38.i = getelementptr i32, ptr %121, i32 %idxprom.i37.i
  %127 = ptrtoint ptr %arrayidx.i38.i to i32
  call void @__asan_store4_noabort(i32 %127)
  store volatile i32 36, ptr %arrayidx.i38.i, align 4
  %128 = ptrtoint ptr %ptr_mask.i.i41 to i32
  call void @__asan_load8_noabort(i32 %128)
  %129 = load i64, ptr %ptr_mask.i.i41, align 8
  %130 = load i64, ptr %wptr.i.i36, align 8
  %and3.i40.i = and i64 %130, %129
  store i64 %and3.i40.i, ptr %wptr.i.i36, align 8
  %131 = ptrtoint ptr %count_dw.i.i32 to i32
  call void @__asan_load4_noabort(i32 %131)
  %132 = load i32, ptr %count_dw.i.i32, align 8
  %dec.i41.i = add i32 %132, -1
  store i32 %dec.i41.i, ptr %count_dw.i.i32, align 8
  %and7 = and i32 %flags, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and7)
  %tobool8.not = icmp eq i32 %and7, 0
  %spec.select = select i1 %tobool8.not, i32 -2130608125, i32 -1862172669
  br label %if.end17

if.else:                                          ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %and12 = and i32 %flags, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and12)
  %tobool13.not = icmp eq i32 %and12, 0
  %spec.select31 = select i1 %tobool13.not, i32 -2147483648, i32 -1879048192
  br label %if.end17

if.end17:                                         ; preds = %if.else, %gfx_v8_0_ring_emit_vgt_flush.exit
  %dw2.0 = phi i32 [ %spec.select, %gfx_v8_0_ring_emit_vgt_flush.exit ], [ %spec.select31, %if.else ]
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %133 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %133)
  %134 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %134)
  %cmp.i = icmp slt i32 %134, 1
  br i1 %cmp.i, label %if.then.i, label %if.end17.amdgpu_ring_write.exit_crit_edge

if.end17.amdgpu_ring_write.exit_crit_edge:        ; preds = %if.end17
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %if.end17
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %if.end17.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %135 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %135)
  %136 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %137 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %137)
  %138 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %138, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %139 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %139)
  %140 = load i32, ptr %buf_mask.i, align 8
  %141 = trunc i64 %138 to i32
  %idxprom.i = and i32 %140, %141
  %arrayidx.i = getelementptr i32, ptr %136, i32 %idxprom.i
  %142 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %142)
  store volatile i32 -1073666048, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %143 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %143)
  %144 = load i64, ptr %ptr_mask.i, align 8
  %145 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %145, %144
  store i64 %and3.i, ptr %wptr.i, align 8
  %146 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %146)
  %147 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %147, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i46 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i46, label %if.then.i47, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit57_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit57_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit57

if.then.i47:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit57

amdgpu_ring_write.exit57:                         ; preds = %if.then.i47, %amdgpu_ring_write.exit.amdgpu_ring_write.exit57_crit_edge
  %148 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %148)
  %149 = load ptr, ptr %ring1.i, align 4
  %150 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %150)
  %151 = load i64, ptr %wptr.i, align 8
  %inc.i50 = add i64 %151, 1
  store i64 %inc.i50, ptr %wptr.i, align 8
  %152 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %152)
  %153 = load i32, ptr %buf_mask.i, align 8
  %154 = trunc i64 %151 to i32
  %idxprom.i52 = and i32 %153, %154
  %arrayidx.i53 = getelementptr i32, ptr %149, i32 %idxprom.i52
  %155 = ptrtoint ptr %arrayidx.i53 to i32
  call void @__asan_store4_noabort(i32 %155)
  store volatile i32 %dw2.0, ptr %arrayidx.i53, align 4
  %156 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %156)
  %157 = load i64, ptr %ptr_mask.i, align 8
  %158 = load i64, ptr %wptr.i, align 8
  %and3.i55 = and i64 %158, %157
  store i64 %and3.i55, ptr %wptr.i, align 8
  %159 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %159)
  %160 = load i32, ptr %count_dw.i, align 8
  %dec.i56 = add i32 %160, -1
  store i32 %dec.i56, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i56)
  %cmp.i59 = icmp slt i32 %dec.i56, 1
  br i1 %cmp.i59, label %if.then.i60, label %amdgpu_ring_write.exit57.amdgpu_ring_write.exit70_crit_edge

amdgpu_ring_write.exit57.amdgpu_ring_write.exit70_crit_edge: ; preds = %amdgpu_ring_write.exit57
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit70

if.then.i60:                                      ; preds = %amdgpu_ring_write.exit57
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit70

amdgpu_ring_write.exit70:                         ; preds = %if.then.i60, %amdgpu_ring_write.exit57.amdgpu_ring_write.exit70_crit_edge
  %161 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %161)
  %162 = load ptr, ptr %ring1.i, align 4
  %163 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %163)
  %164 = load i64, ptr %wptr.i, align 8
  %inc.i63 = add i64 %164, 1
  store i64 %inc.i63, ptr %wptr.i, align 8
  %165 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %165)
  %166 = load i32, ptr %buf_mask.i, align 8
  %167 = trunc i64 %164 to i32
  %idxprom.i65 = and i32 %166, %167
  %arrayidx.i66 = getelementptr i32, ptr %162, i32 %idxprom.i65
  %168 = ptrtoint ptr %arrayidx.i66 to i32
  call void @__asan_store4_noabort(i32 %168)
  store volatile i32 0, ptr %arrayidx.i66, align 4
  %169 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %169)
  %170 = load i64, ptr %ptr_mask.i, align 8
  %171 = load i64, ptr %wptr.i, align 8
  %and3.i68 = and i64 %171, %170
  store i64 %and3.i68, ptr %wptr.i, align 8
  %172 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %172)
  %173 = load i32, ptr %count_dw.i, align 8
  %dec.i69 = add i32 %173, -1
  store i32 %dec.i69, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_soft_recovery(ptr nocapture noundef readonly %ring, i32 noundef %vmid) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %shl = shl i32 %vmid, 28
  %or8 = or i32 %shl, 147
  tail call void @amdgpu_device_wreg(ptr noundef %1, i32 noundef 9083, i32 noundef %or8, i32 noundef 0) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_emit_mem_sync(ptr noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073528064, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i6 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i6, label %if.then.i7, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit17_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit17_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit17

if.then.i7:                                       ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit17

amdgpu_ring_write.exit17:                         ; preds = %if.then.i7, %amdgpu_ring_write.exit.amdgpu_ring_write.exit17_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i10 = add i64 %18, 1
  store i64 %inc.i10, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i12 = and i32 %20, %21
  %arrayidx.i13 = getelementptr i32, ptr %16, i32 %idxprom.i12
  %22 = ptrtoint ptr %arrayidx.i13 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 683933696, ptr %arrayidx.i13, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i15 = and i64 %25, %24
  store i64 %and3.i15, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i16 = add i32 %27, -1
  store i32 %dec.i16, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i16)
  %cmp.i19 = icmp slt i32 %dec.i16, 1
  br i1 %cmp.i19, label %if.then.i20, label %amdgpu_ring_write.exit17.amdgpu_ring_write.exit30_crit_edge

amdgpu_ring_write.exit17.amdgpu_ring_write.exit30_crit_edge: ; preds = %amdgpu_ring_write.exit17
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit30

if.then.i20:                                      ; preds = %amdgpu_ring_write.exit17
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit30

amdgpu_ring_write.exit30:                         ; preds = %if.then.i20, %amdgpu_ring_write.exit17.amdgpu_ring_write.exit30_crit_edge
  %28 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %ring1.i, align 4
  %30 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %wptr.i, align 8
  %inc.i23 = add i64 %31, 1
  store i64 %inc.i23, ptr %wptr.i, align 8
  %32 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %buf_mask.i, align 8
  %34 = trunc i64 %31 to i32
  %idxprom.i25 = and i32 %33, %34
  %arrayidx.i26 = getelementptr i32, ptr %29, i32 %idxprom.i25
  %35 = ptrtoint ptr %arrayidx.i26 to i32
  call void @__asan_store4_noabort(i32 %35)
  store volatile i32 -1, ptr %arrayidx.i26, align 4
  %36 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %ptr_mask.i, align 8
  %38 = load i64, ptr %wptr.i, align 8
  %and3.i28 = and i64 %38, %37
  store i64 %and3.i28, ptr %wptr.i, align 8
  %39 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %count_dw.i, align 8
  %dec.i29 = add i32 %40, -1
  store i32 %dec.i29, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i29)
  %cmp.i32 = icmp slt i32 %dec.i29, 1
  br i1 %cmp.i32, label %if.then.i33, label %amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge

amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge: ; preds = %amdgpu_ring_write.exit30
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit43

if.then.i33:                                      ; preds = %amdgpu_ring_write.exit30
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit43

amdgpu_ring_write.exit43:                         ; preds = %if.then.i33, %amdgpu_ring_write.exit30.amdgpu_ring_write.exit43_crit_edge
  %41 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %ring1.i, align 4
  %43 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %wptr.i, align 8
  %inc.i36 = add i64 %44, 1
  store i64 %inc.i36, ptr %wptr.i, align 8
  %45 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %buf_mask.i, align 8
  %47 = trunc i64 %44 to i32
  %idxprom.i38 = and i32 %46, %47
  %arrayidx.i39 = getelementptr i32, ptr %42, i32 %idxprom.i38
  %48 = ptrtoint ptr %arrayidx.i39 to i32
  call void @__asan_store4_noabort(i32 %48)
  store volatile i32 0, ptr %arrayidx.i39, align 4
  %49 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %ptr_mask.i, align 8
  %51 = load i64, ptr %wptr.i, align 8
  %and3.i41 = and i64 %51, %50
  store i64 %and3.i41, ptr %wptr.i, align 8
  %52 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %count_dw.i, align 8
  %dec.i42 = add i32 %53, -1
  store i32 %dec.i42, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i42)
  %cmp.i45 = icmp slt i32 %dec.i42, 1
  br i1 %cmp.i45, label %if.then.i46, label %amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge

amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge: ; preds = %amdgpu_ring_write.exit43
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit56

if.then.i46:                                      ; preds = %amdgpu_ring_write.exit43
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit56

amdgpu_ring_write.exit56:                         ; preds = %if.then.i46, %amdgpu_ring_write.exit43.amdgpu_ring_write.exit56_crit_edge
  %54 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %ring1.i, align 4
  %56 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %56)
  %57 = load i64, ptr %wptr.i, align 8
  %inc.i49 = add i64 %57, 1
  store i64 %inc.i49, ptr %wptr.i, align 8
  %58 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %buf_mask.i, align 8
  %60 = trunc i64 %57 to i32
  %idxprom.i51 = and i32 %59, %60
  %arrayidx.i52 = getelementptr i32, ptr %55, i32 %idxprom.i51
  %61 = ptrtoint ptr %arrayidx.i52 to i32
  call void @__asan_store4_noabort(i32 %61)
  store volatile i32 10, ptr %arrayidx.i52, align 4
  %62 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %ptr_mask.i, align 8
  %64 = load i64, ptr %wptr.i, align 8
  %and3.i54 = and i64 %64, %63
  store i64 %and3.i54, ptr %wptr.i, align 8
  %65 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %count_dw.i, align 8
  %dec.i55 = add i32 %66, -1
  store i32 %dec.i55, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i64 @amdgpu_csa_vaddr(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_device_wb_get(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ib_get(ptr noundef, ptr noundef, i32 noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ib_schedule(ptr noundef, i32 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @dma_fence_wait_timeout(ptr noundef, i1 noundef zeroext, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_ib_free(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_device_wb_free(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @dma_fence_release(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @refcount_warn_saturate(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__kasan_check_write(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.prefetch.p0(ptr nocapture readonly, i32 immarg, i32 immarg, i32) #4

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_ib_compute(ptr noundef %ring, ptr noundef readonly %job, ptr nocapture noundef readonly %ib, i32 noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %tobool.not = icmp eq ptr %job, null
  br i1 %tobool.not, label %entry.cond.end_crit_edge, label %cond.true

entry.cond.end_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cond.end

cond.true:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %vmid1 = getelementptr inbounds %struct.amdgpu_job, ptr %job, i32 0, i32 12
  %0 = ptrtoint ptr %vmid1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %vmid1, align 8
  %phi.bo = shl i32 %1, 24
  %phi.bo100 = or i32 %phi.bo, 8388608
  br label %cond.end

cond.end:                                         ; preds = %cond.true, %entry.cond.end_crit_edge
  %cond = phi i32 [ %phi.bo100, %cond.true ], [ 8388608, %entry.cond.end_crit_edge ]
  %length_dw = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 1
  %2 = ptrtoint ptr %length_dw to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %length_dw, align 4
  %flags3 = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 4
  %4 = ptrtoint ptr %flags3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %flags3, align 4
  %and = and i32 %5, 16
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool4.not = icmp eq i32 %and, 0
  br i1 %tobool4.not, label %cond.end.if.end_crit_edge, label %if.then

cond.end.if.end_crit_edge:                        ; preds = %cond.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %cond.end
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %6 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %7)
  %cmp.i = icmp slt i32 %7, 1
  br i1 %cmp.i, label %if.then.i, label %if.then.amdgpu_ring_write.exit_crit_edge

if.then.amdgpu_ring_write.exit_crit_edge:         ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %if.then.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %8 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %10 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %11, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %12 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %buf_mask.i, align 8
  %14 = trunc i64 %11 to i32
  %idxprom.i = and i32 %13, %14
  %arrayidx.i = getelementptr i32, ptr %9, i32 %idxprom.i
  %15 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store volatile i32 -1073649664, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %16 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %16)
  %17 = load i64, ptr %ptr_mask.i, align 8
  %18 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %18, %17
  store i64 %and3.i, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %20, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i23 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i23, label %if.then.i24, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit34_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit34_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit34

if.then.i24:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit34

amdgpu_ring_write.exit34:                         ; preds = %if.then.i24, %amdgpu_ring_write.exit.amdgpu_ring_write.exit34_crit_edge
  %21 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %ring1.i, align 4
  %23 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %wptr.i, align 8
  %inc.i27 = add i64 %24, 1
  store i64 %inc.i27, ptr %wptr.i, align 8
  %25 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %buf_mask.i, align 8
  %27 = trunc i64 %24 to i32
  %idxprom.i29 = and i32 %26, %27
  %arrayidx.i30 = getelementptr i32, ptr %22, i32 %idxprom.i29
  %28 = ptrtoint ptr %arrayidx.i30 to i32
  call void @__asan_store4_noabort(i32 %28)
  store volatile i32 4936, ptr %arrayidx.i30, align 4
  %29 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %29)
  %30 = load i64, ptr %ptr_mask.i, align 8
  %31 = load i64, ptr %wptr.i, align 8
  %and3.i32 = and i64 %31, %30
  store i64 %and3.i32, ptr %wptr.i, align 8
  %32 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %count_dw.i, align 8
  %dec.i33 = add i32 %33, -1
  store i32 %dec.i33, ptr %count_dw.i, align 8
  %34 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %ring, align 8
  %gds_compute_max_wave_id = getelementptr inbounds %struct.amdgpu_device, ptr %35, i32 0, i32 114, i32 3
  %36 = ptrtoint ptr %gds_compute_max_wave_id to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %gds_compute_max_wave_id, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i33)
  %cmp.i36 = icmp slt i32 %dec.i33, 1
  br i1 %cmp.i36, label %if.then.i37, label %amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge

amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge: ; preds = %amdgpu_ring_write.exit34
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit47

if.then.i37:                                      ; preds = %amdgpu_ring_write.exit34
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit47

amdgpu_ring_write.exit47:                         ; preds = %if.then.i37, %amdgpu_ring_write.exit34.amdgpu_ring_write.exit47_crit_edge
  %38 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %ring1.i, align 4
  %40 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %40)
  %41 = load i64, ptr %wptr.i, align 8
  %inc.i40 = add i64 %41, 1
  store i64 %inc.i40, ptr %wptr.i, align 8
  %42 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %buf_mask.i, align 8
  %44 = trunc i64 %41 to i32
  %idxprom.i42 = and i32 %43, %44
  %arrayidx.i43 = getelementptr i32, ptr %39, i32 %idxprom.i42
  %45 = ptrtoint ptr %arrayidx.i43 to i32
  call void @__asan_store4_noabort(i32 %45)
  store volatile i32 %37, ptr %arrayidx.i43, align 4
  %46 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %46)
  %47 = load i64, ptr %ptr_mask.i, align 8
  %48 = load i64, ptr %wptr.i, align 8
  %and3.i45 = and i64 %48, %47
  store i64 %and3.i45, ptr %wptr.i, align 8
  %49 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %count_dw.i, align 8
  %dec.i46 = add i32 %50, -1
  store i32 %dec.i46, ptr %count_dw.i, align 8
  br label %if.end

if.end:                                           ; preds = %amdgpu_ring_write.exit47, %cond.end.if.end_crit_edge
  %count_dw.i48 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %51 = ptrtoint ptr %count_dw.i48 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %count_dw.i48, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %52)
  %cmp.i49 = icmp slt i32 %52, 1
  br i1 %cmp.i49, label %if.then.i50, label %if.end.amdgpu_ring_write.exit60_crit_edge

if.end.amdgpu_ring_write.exit60_crit_edge:        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit60

if.then.i50:                                      ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit60

amdgpu_ring_write.exit60:                         ; preds = %if.then.i50, %if.end.amdgpu_ring_write.exit60_crit_edge
  %ring1.i51 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %53 = ptrtoint ptr %ring1.i51 to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %ring1.i51, align 4
  %wptr.i52 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %55 = ptrtoint ptr %wptr.i52 to i32
  call void @__asan_load8_noabort(i32 %55)
  %56 = load i64, ptr %wptr.i52, align 8
  %inc.i53 = add i64 %56, 1
  store i64 %inc.i53, ptr %wptr.i52, align 8
  %buf_mask.i54 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %57 = ptrtoint ptr %buf_mask.i54 to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %buf_mask.i54, align 8
  %59 = trunc i64 %56 to i32
  %idxprom.i55 = and i32 %58, %59
  %arrayidx.i56 = getelementptr i32, ptr %54, i32 %idxprom.i55
  %60 = ptrtoint ptr %arrayidx.i56 to i32
  call void @__asan_store4_noabort(i32 %60)
  store volatile i32 -1073594624, ptr %arrayidx.i56, align 4
  %ptr_mask.i57 = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %61 = ptrtoint ptr %ptr_mask.i57 to i32
  call void @__asan_load8_noabort(i32 %61)
  %62 = load i64, ptr %ptr_mask.i57, align 8
  %63 = load i64, ptr %wptr.i52, align 8
  %and3.i58 = and i64 %63, %62
  store i64 %and3.i58, ptr %wptr.i52, align 8
  %64 = ptrtoint ptr %count_dw.i48 to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %count_dw.i48, align 8
  %dec.i59 = add i32 %65, -1
  store i32 %dec.i59, ptr %count_dw.i48, align 8
  %gpu_addr = getelementptr inbounds %struct.amdgpu_ib, ptr %ib, i32 0, i32 2
  %66 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %66)
  %67 = load i64, ptr %gpu_addr, align 8
  %68 = trunc i64 %67 to i32
  %69 = and i32 %68, -4
  %conv = or i32 %69, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i59)
  %cmp.i62 = icmp slt i32 %dec.i59, 1
  br i1 %cmp.i62, label %if.then.i63, label %amdgpu_ring_write.exit60.amdgpu_ring_write.exit73_crit_edge

amdgpu_ring_write.exit60.amdgpu_ring_write.exit73_crit_edge: ; preds = %amdgpu_ring_write.exit60
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit73

if.then.i63:                                      ; preds = %amdgpu_ring_write.exit60
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit73

amdgpu_ring_write.exit73:                         ; preds = %if.then.i63, %amdgpu_ring_write.exit60.amdgpu_ring_write.exit73_crit_edge
  %70 = ptrtoint ptr %ring1.i51 to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load ptr, ptr %ring1.i51, align 4
  %72 = ptrtoint ptr %wptr.i52 to i32
  call void @__asan_load8_noabort(i32 %72)
  %73 = load i64, ptr %wptr.i52, align 8
  %inc.i66 = add i64 %73, 1
  store i64 %inc.i66, ptr %wptr.i52, align 8
  %74 = ptrtoint ptr %buf_mask.i54 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load i32, ptr %buf_mask.i54, align 8
  %76 = trunc i64 %73 to i32
  %idxprom.i68 = and i32 %75, %76
  %arrayidx.i69 = getelementptr i32, ptr %71, i32 %idxprom.i68
  %77 = ptrtoint ptr %arrayidx.i69 to i32
  call void @__asan_store4_noabort(i32 %77)
  store volatile i32 %conv, ptr %arrayidx.i69, align 4
  %78 = ptrtoint ptr %ptr_mask.i57 to i32
  call void @__asan_load8_noabort(i32 %78)
  %79 = load i64, ptr %ptr_mask.i57, align 8
  %80 = load i64, ptr %wptr.i52, align 8
  %and3.i71 = and i64 %80, %79
  store i64 %and3.i71, ptr %wptr.i52, align 8
  %81 = ptrtoint ptr %count_dw.i48 to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %count_dw.i48, align 8
  %dec.i72 = add i32 %82, -1
  store i32 %dec.i72, ptr %count_dw.i48, align 8
  %83 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %83)
  %84 = load i64, ptr %gpu_addr, align 8
  %shr = lshr i64 %84, 32
  %conv9 = trunc i64 %shr to i32
  %and10 = and i32 %conv9, 65535
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i72)
  %cmp.i75 = icmp slt i32 %dec.i72, 1
  br i1 %cmp.i75, label %if.then.i76, label %amdgpu_ring_write.exit73.amdgpu_ring_write.exit86_crit_edge

amdgpu_ring_write.exit73.amdgpu_ring_write.exit86_crit_edge: ; preds = %amdgpu_ring_write.exit73
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit86

if.then.i76:                                      ; preds = %amdgpu_ring_write.exit73
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit86

amdgpu_ring_write.exit86:                         ; preds = %if.then.i76, %amdgpu_ring_write.exit73.amdgpu_ring_write.exit86_crit_edge
  %85 = ptrtoint ptr %ring1.i51 to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load ptr, ptr %ring1.i51, align 4
  %87 = ptrtoint ptr %wptr.i52 to i32
  call void @__asan_load8_noabort(i32 %87)
  %88 = load i64, ptr %wptr.i52, align 8
  %inc.i79 = add i64 %88, 1
  store i64 %inc.i79, ptr %wptr.i52, align 8
  %89 = ptrtoint ptr %buf_mask.i54 to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load i32, ptr %buf_mask.i54, align 8
  %91 = trunc i64 %88 to i32
  %idxprom.i81 = and i32 %90, %91
  %arrayidx.i82 = getelementptr i32, ptr %86, i32 %idxprom.i81
  %92 = ptrtoint ptr %arrayidx.i82 to i32
  call void @__asan_store4_noabort(i32 %92)
  store volatile i32 %and10, ptr %arrayidx.i82, align 4
  %93 = ptrtoint ptr %ptr_mask.i57 to i32
  call void @__asan_load8_noabort(i32 %93)
  %94 = load i64, ptr %ptr_mask.i57, align 8
  %95 = load i64, ptr %wptr.i52, align 8
  %and3.i84 = and i64 %95, %94
  store i64 %and3.i84, ptr %wptr.i52, align 8
  %96 = ptrtoint ptr %count_dw.i48 to i32
  call void @__asan_load4_noabort(i32 %96)
  %97 = load i32, ptr %count_dw.i48, align 8
  %dec.i85 = add i32 %97, -1
  store i32 %dec.i85, ptr %count_dw.i48, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i85)
  %cmp.i88 = icmp slt i32 %dec.i85, 1
  br i1 %cmp.i88, label %if.then.i89, label %amdgpu_ring_write.exit86.amdgpu_ring_write.exit99_crit_edge

amdgpu_ring_write.exit86.amdgpu_ring_write.exit99_crit_edge: ; preds = %amdgpu_ring_write.exit86
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit99

if.then.i89:                                      ; preds = %amdgpu_ring_write.exit86
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit99

amdgpu_ring_write.exit99:                         ; preds = %if.then.i89, %amdgpu_ring_write.exit86.amdgpu_ring_write.exit99_crit_edge
  %or2 = or i32 %cond, %3
  %98 = ptrtoint ptr %ring1.i51 to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load ptr, ptr %ring1.i51, align 4
  %100 = ptrtoint ptr %wptr.i52 to i32
  call void @__asan_load8_noabort(i32 %100)
  %101 = load i64, ptr %wptr.i52, align 8
  %inc.i92 = add i64 %101, 1
  store i64 %inc.i92, ptr %wptr.i52, align 8
  %102 = ptrtoint ptr %buf_mask.i54 to i32
  call void @__asan_load4_noabort(i32 %102)
  %103 = load i32, ptr %buf_mask.i54, align 8
  %104 = trunc i64 %101 to i32
  %idxprom.i94 = and i32 %103, %104
  %arrayidx.i95 = getelementptr i32, ptr %99, i32 %idxprom.i94
  %105 = ptrtoint ptr %arrayidx.i95 to i32
  call void @__asan_store4_noabort(i32 %105)
  store volatile i32 %or2, ptr %arrayidx.i95, align 4
  %106 = ptrtoint ptr %ptr_mask.i57 to i32
  call void @__asan_load8_noabort(i32 %106)
  %107 = load i64, ptr %ptr_mask.i57, align 8
  %108 = load i64, ptr %wptr.i52, align 8
  %and3.i97 = and i64 %108, %107
  store i64 %and3.i97, ptr %wptr.i52, align 8
  %109 = ptrtoint ptr %count_dw.i48 to i32
  call void @__asan_load4_noabort(i32 %109)
  %110 = load i32, ptr %count_dw.i48, align 8
  %dec.i98 = add i32 %110, -1
  store i32 %dec.i98, ptr %count_dw.i48, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_ring_emit_fence_compute(ptr noundef %ring, i64 noundef %addr, i64 noundef %seq, i32 noundef %flags) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %and = and i32 %flags, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073395456, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i26 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i26, label %if.then.i27, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit37_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit37_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit37

if.then.i27:                                      ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit37

amdgpu_ring_write.exit37:                         ; preds = %if.then.i27, %amdgpu_ring_write.exit.amdgpu_ring_write.exit37_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i30 = add i64 %18, 1
  store i64 %inc.i30, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i32 = and i32 %20, %21
  %arrayidx.i33 = getelementptr i32, ptr %16, i32 %idxprom.i32
  %22 = ptrtoint ptr %arrayidx.i33 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 230676, ptr %arrayidx.i33, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i35 = and i64 %25, %24
  store i64 %and3.i35, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i36 = add i32 %27, -1
  store i32 %dec.i36, ptr %count_dw.i, align 8
  %cond = select i1 %tobool.not, i32 536870912, i32 1073741824
  %and1 = shl i32 %flags, 24
  %shl7 = and i32 %and1, 33554432
  %or = or i32 %cond, %shl7
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i36)
  %cmp.i39 = icmp slt i32 %dec.i36, 1
  br i1 %cmp.i39, label %if.then.i40, label %amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge

amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge: ; preds = %amdgpu_ring_write.exit37
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit50

if.then.i40:                                      ; preds = %amdgpu_ring_write.exit37
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit50

amdgpu_ring_write.exit50:                         ; preds = %if.then.i40, %amdgpu_ring_write.exit37.amdgpu_ring_write.exit50_crit_edge
  %28 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %ring1.i, align 4
  %30 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %wptr.i, align 8
  %inc.i43 = add i64 %31, 1
  store i64 %inc.i43, ptr %wptr.i, align 8
  %32 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %buf_mask.i, align 8
  %34 = trunc i64 %31 to i32
  %idxprom.i45 = and i32 %33, %34
  %arrayidx.i46 = getelementptr i32, ptr %29, i32 %idxprom.i45
  %35 = ptrtoint ptr %arrayidx.i46 to i32
  call void @__asan_store4_noabort(i32 %35)
  store volatile i32 %or, ptr %arrayidx.i46, align 4
  %36 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %ptr_mask.i, align 8
  %38 = load i64, ptr %wptr.i, align 8
  %and3.i48 = and i64 %38, %37
  store i64 %and3.i48, ptr %wptr.i, align 8
  %39 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %count_dw.i, align 8
  %dec.i49 = add i32 %40, -1
  store i32 %dec.i49, ptr %count_dw.i, align 8
  %41 = trunc i64 %addr to i32
  %conv = and i32 %41, -4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i49)
  %cmp.i52 = icmp slt i32 %dec.i49, 1
  br i1 %cmp.i52, label %if.then.i53, label %amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge

amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge: ; preds = %amdgpu_ring_write.exit50
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit63

if.then.i53:                                      ; preds = %amdgpu_ring_write.exit50
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit63

amdgpu_ring_write.exit63:                         ; preds = %if.then.i53, %amdgpu_ring_write.exit50.amdgpu_ring_write.exit63_crit_edge
  %42 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %ring1.i, align 4
  %44 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %44)
  %45 = load i64, ptr %wptr.i, align 8
  %inc.i56 = add i64 %45, 1
  store i64 %inc.i56, ptr %wptr.i, align 8
  %46 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %buf_mask.i, align 8
  %48 = trunc i64 %45 to i32
  %idxprom.i58 = and i32 %47, %48
  %arrayidx.i59 = getelementptr i32, ptr %43, i32 %idxprom.i58
  %49 = ptrtoint ptr %arrayidx.i59 to i32
  call void @__asan_store4_noabort(i32 %49)
  store volatile i32 %conv, ptr %arrayidx.i59, align 4
  %50 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %50)
  %51 = load i64, ptr %ptr_mask.i, align 8
  %52 = load i64, ptr %wptr.i, align 8
  %and3.i61 = and i64 %52, %51
  store i64 %and3.i61, ptr %wptr.i, align 8
  %53 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %count_dw.i, align 8
  %dec.i62 = add i32 %54, -1
  store i32 %dec.i62, ptr %count_dw.i, align 8
  %shr = lshr i64 %addr, 32
  %conv10 = trunc i64 %shr to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i62)
  %cmp.i65 = icmp slt i32 %dec.i62, 1
  br i1 %cmp.i65, label %if.then.i66, label %amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge

amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge: ; preds = %amdgpu_ring_write.exit63
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit76

if.then.i66:                                      ; preds = %amdgpu_ring_write.exit63
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit76

amdgpu_ring_write.exit76:                         ; preds = %if.then.i66, %amdgpu_ring_write.exit63.amdgpu_ring_write.exit76_crit_edge
  %55 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %ring1.i, align 4
  %57 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %57)
  %58 = load i64, ptr %wptr.i, align 8
  %inc.i69 = add i64 %58, 1
  store i64 %inc.i69, ptr %wptr.i, align 8
  %59 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load i32, ptr %buf_mask.i, align 8
  %61 = trunc i64 %58 to i32
  %idxprom.i71 = and i32 %60, %61
  %arrayidx.i72 = getelementptr i32, ptr %56, i32 %idxprom.i71
  %62 = ptrtoint ptr %arrayidx.i72 to i32
  call void @__asan_store4_noabort(i32 %62)
  store volatile i32 %conv10, ptr %arrayidx.i72, align 4
  %63 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %63)
  %64 = load i64, ptr %ptr_mask.i, align 8
  %65 = load i64, ptr %wptr.i, align 8
  %and3.i74 = and i64 %65, %64
  store i64 %and3.i74, ptr %wptr.i, align 8
  %66 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %count_dw.i, align 8
  %dec.i75 = add i32 %67, -1
  store i32 %dec.i75, ptr %count_dw.i, align 8
  %conv12 = trunc i64 %seq to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i75)
  %cmp.i78 = icmp slt i32 %dec.i75, 1
  br i1 %cmp.i78, label %if.then.i79, label %amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge

amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge: ; preds = %amdgpu_ring_write.exit76
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit89

if.then.i79:                                      ; preds = %amdgpu_ring_write.exit76
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit89

amdgpu_ring_write.exit89:                         ; preds = %if.then.i79, %amdgpu_ring_write.exit76.amdgpu_ring_write.exit89_crit_edge
  %68 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %ring1.i, align 4
  %70 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %70)
  %71 = load i64, ptr %wptr.i, align 8
  %inc.i82 = add i64 %71, 1
  store i64 %inc.i82, ptr %wptr.i, align 8
  %72 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load i32, ptr %buf_mask.i, align 8
  %74 = trunc i64 %71 to i32
  %idxprom.i84 = and i32 %73, %74
  %arrayidx.i85 = getelementptr i32, ptr %69, i32 %idxprom.i84
  %75 = ptrtoint ptr %arrayidx.i85 to i32
  call void @__asan_store4_noabort(i32 %75)
  store volatile i32 %conv12, ptr %arrayidx.i85, align 4
  %76 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %76)
  %77 = load i64, ptr %ptr_mask.i, align 8
  %78 = load i64, ptr %wptr.i, align 8
  %and3.i87 = and i64 %78, %77
  store i64 %and3.i87, ptr %wptr.i, align 8
  %79 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %count_dw.i, align 8
  %dec.i88 = add i32 %80, -1
  store i32 %dec.i88, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i88)
  %cmp.i91 = icmp slt i32 %dec.i88, 1
  br i1 %cmp.i91, label %if.then.i92, label %amdgpu_ring_write.exit89.amdgpu_ring_write.exit102_crit_edge

amdgpu_ring_write.exit89.amdgpu_ring_write.exit102_crit_edge: ; preds = %amdgpu_ring_write.exit89
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit102

if.then.i92:                                      ; preds = %amdgpu_ring_write.exit89
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit102

amdgpu_ring_write.exit102:                        ; preds = %if.then.i92, %amdgpu_ring_write.exit89.amdgpu_ring_write.exit102_crit_edge
  %shr13 = lshr i64 %seq, 32
  %conv15 = trunc i64 %shr13 to i32
  %81 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load ptr, ptr %ring1.i, align 4
  %83 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %83)
  %84 = load i64, ptr %wptr.i, align 8
  %inc.i95 = add i64 %84, 1
  store i64 %inc.i95, ptr %wptr.i, align 8
  %85 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %buf_mask.i, align 8
  %87 = trunc i64 %84 to i32
  %idxprom.i97 = and i32 %86, %87
  %arrayidx.i98 = getelementptr i32, ptr %82, i32 %idxprom.i97
  %88 = ptrtoint ptr %arrayidx.i98 to i32
  call void @__asan_store4_noabort(i32 %88)
  store volatile i32 %conv15, ptr %arrayidx.i98, align 4
  %89 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %89)
  %90 = load i64, ptr %ptr_mask.i, align 8
  %91 = load i64, ptr %wptr.i, align 8
  %and3.i100 = and i64 %91, %90
  store i64 %and3.i100, ptr %wptr.i, align 8
  %92 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load i32, ptr %count_dw.i, align 8
  %dec.i101 = add i32 %93, -1
  store i32 %dec.i101, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_emit_mem_sync_compute(ptr noundef %ring) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %count_dw.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 11
  %0 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %1)
  %cmp.i = icmp slt i32 %1, 1
  br i1 %cmp.i, label %if.then.i, label %entry.amdgpu_ring_write.exit_crit_edge

entry.amdgpu_ring_write.exit_crit_edge:           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit

if.then.i:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit

amdgpu_ring_write.exit:                           ; preds = %if.then.i, %entry.amdgpu_ring_write.exit_crit_edge
  %ring1.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 5
  %2 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %ring1.i, align 4
  %wptr.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %4 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %wptr.i, align 8
  %inc.i = add i64 %5, 1
  store i64 %inc.i, ptr %wptr.i, align 8
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 14
  %6 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %buf_mask.i, align 8
  %8 = trunc i64 %5 to i32
  %idxprom.i = and i32 %7, %8
  %arrayidx.i = getelementptr i32, ptr %3, i32 %idxprom.i
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile i32 -1073391616, ptr %arrayidx.i, align 4
  %ptr_mask.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 13
  %10 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %ptr_mask.i, align 8
  %12 = load i64, ptr %wptr.i, align 8
  %and3.i = and i64 %12, %11
  store i64 %and3.i, ptr %wptr.i, align 8
  %13 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %count_dw.i, align 8
  %dec.i = add i32 %14, -1
  store i32 %dec.i, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i)
  %cmp.i8 = icmp slt i32 %dec.i, 1
  br i1 %cmp.i8, label %if.then.i9, label %amdgpu_ring_write.exit.amdgpu_ring_write.exit19_crit_edge

amdgpu_ring_write.exit.amdgpu_ring_write.exit19_crit_edge: ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit19

if.then.i9:                                       ; preds = %amdgpu_ring_write.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit19

amdgpu_ring_write.exit19:                         ; preds = %if.then.i9, %amdgpu_ring_write.exit.amdgpu_ring_write.exit19_crit_edge
  %15 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %ring1.i, align 4
  %17 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %wptr.i, align 8
  %inc.i12 = add i64 %18, 1
  store i64 %inc.i12, ptr %wptr.i, align 8
  %19 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %buf_mask.i, align 8
  %21 = trunc i64 %18 to i32
  %idxprom.i14 = and i32 %20, %21
  %arrayidx.i15 = getelementptr i32, ptr %16, i32 %idxprom.i14
  %22 = ptrtoint ptr %arrayidx.i15 to i32
  call void @__asan_store4_noabort(i32 %22)
  store volatile i32 683933696, ptr %arrayidx.i15, align 4
  %23 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %23)
  %24 = load i64, ptr %ptr_mask.i, align 8
  %25 = load i64, ptr %wptr.i, align 8
  %and3.i17 = and i64 %25, %24
  store i64 %and3.i17, ptr %wptr.i, align 8
  %26 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %count_dw.i, align 8
  %dec.i18 = add i32 %27, -1
  store i32 %dec.i18, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i18)
  %cmp.i21 = icmp slt i32 %dec.i18, 1
  br i1 %cmp.i21, label %if.then.i22, label %amdgpu_ring_write.exit19.amdgpu_ring_write.exit32_crit_edge

amdgpu_ring_write.exit19.amdgpu_ring_write.exit32_crit_edge: ; preds = %amdgpu_ring_write.exit19
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit32

if.then.i22:                                      ; preds = %amdgpu_ring_write.exit19
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit32

amdgpu_ring_write.exit32:                         ; preds = %if.then.i22, %amdgpu_ring_write.exit19.amdgpu_ring_write.exit32_crit_edge
  %28 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %ring1.i, align 4
  %30 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %wptr.i, align 8
  %inc.i25 = add i64 %31, 1
  store i64 %inc.i25, ptr %wptr.i, align 8
  %32 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %buf_mask.i, align 8
  %34 = trunc i64 %31 to i32
  %idxprom.i27 = and i32 %33, %34
  %arrayidx.i28 = getelementptr i32, ptr %29, i32 %idxprom.i27
  %35 = ptrtoint ptr %arrayidx.i28 to i32
  call void @__asan_store4_noabort(i32 %35)
  store volatile i32 -1, ptr %arrayidx.i28, align 4
  %36 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %36)
  %37 = load i64, ptr %ptr_mask.i, align 8
  %38 = load i64, ptr %wptr.i, align 8
  %and3.i30 = and i64 %38, %37
  store i64 %and3.i30, ptr %wptr.i, align 8
  %39 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %count_dw.i, align 8
  %dec.i31 = add i32 %40, -1
  store i32 %dec.i31, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i31)
  %cmp.i34 = icmp slt i32 %dec.i31, 1
  br i1 %cmp.i34, label %if.then.i35, label %amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge

amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge: ; preds = %amdgpu_ring_write.exit32
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit45

if.then.i35:                                      ; preds = %amdgpu_ring_write.exit32
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit45

amdgpu_ring_write.exit45:                         ; preds = %if.then.i35, %amdgpu_ring_write.exit32.amdgpu_ring_write.exit45_crit_edge
  %41 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %ring1.i, align 4
  %43 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %wptr.i, align 8
  %inc.i38 = add i64 %44, 1
  store i64 %inc.i38, ptr %wptr.i, align 8
  %45 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %buf_mask.i, align 8
  %47 = trunc i64 %44 to i32
  %idxprom.i40 = and i32 %46, %47
  %arrayidx.i41 = getelementptr i32, ptr %42, i32 %idxprom.i40
  %48 = ptrtoint ptr %arrayidx.i41 to i32
  call void @__asan_store4_noabort(i32 %48)
  store volatile i32 255, ptr %arrayidx.i41, align 4
  %49 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %ptr_mask.i, align 8
  %51 = load i64, ptr %wptr.i, align 8
  %and3.i43 = and i64 %51, %50
  store i64 %and3.i43, ptr %wptr.i, align 8
  %52 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %count_dw.i, align 8
  %dec.i44 = add i32 %53, -1
  store i32 %dec.i44, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i44)
  %cmp.i47 = icmp slt i32 %dec.i44, 1
  br i1 %cmp.i47, label %if.then.i48, label %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge

amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge: ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit58

if.then.i48:                                      ; preds = %amdgpu_ring_write.exit45
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit58

amdgpu_ring_write.exit58:                         ; preds = %if.then.i48, %amdgpu_ring_write.exit45.amdgpu_ring_write.exit58_crit_edge
  %54 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %ring1.i, align 4
  %56 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %56)
  %57 = load i64, ptr %wptr.i, align 8
  %inc.i51 = add i64 %57, 1
  store i64 %inc.i51, ptr %wptr.i, align 8
  %58 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %buf_mask.i, align 8
  %60 = trunc i64 %57 to i32
  %idxprom.i53 = and i32 %59, %60
  %arrayidx.i54 = getelementptr i32, ptr %55, i32 %idxprom.i53
  %61 = ptrtoint ptr %arrayidx.i54 to i32
  call void @__asan_store4_noabort(i32 %61)
  store volatile i32 0, ptr %arrayidx.i54, align 4
  %62 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %62)
  %63 = load i64, ptr %ptr_mask.i, align 8
  %64 = load i64, ptr %wptr.i, align 8
  %and3.i56 = and i64 %64, %63
  store i64 %and3.i56, ptr %wptr.i, align 8
  %65 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %count_dw.i, align 8
  %dec.i57 = add i32 %66, -1
  store i32 %dec.i57, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i57)
  %cmp.i60 = icmp slt i32 %dec.i57, 1
  br i1 %cmp.i60, label %if.then.i61, label %amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge

amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge: ; preds = %amdgpu_ring_write.exit58
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit71

if.then.i61:                                      ; preds = %amdgpu_ring_write.exit58
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit71

amdgpu_ring_write.exit71:                         ; preds = %if.then.i61, %amdgpu_ring_write.exit58.amdgpu_ring_write.exit71_crit_edge
  %67 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %ring1.i, align 4
  %69 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %69)
  %70 = load i64, ptr %wptr.i, align 8
  %inc.i64 = add i64 %70, 1
  store i64 %inc.i64, ptr %wptr.i, align 8
  %71 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %buf_mask.i, align 8
  %73 = trunc i64 %70 to i32
  %idxprom.i66 = and i32 %72, %73
  %arrayidx.i67 = getelementptr i32, ptr %68, i32 %idxprom.i66
  %74 = ptrtoint ptr %arrayidx.i67 to i32
  call void @__asan_store4_noabort(i32 %74)
  store volatile i32 0, ptr %arrayidx.i67, align 4
  %75 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %75)
  %76 = load i64, ptr %ptr_mask.i, align 8
  %77 = load i64, ptr %wptr.i, align 8
  %and3.i69 = and i64 %77, %76
  store i64 %and3.i69, ptr %wptr.i, align 8
  %78 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load i32, ptr %count_dw.i, align 8
  %dec.i70 = add i32 %79, -1
  store i32 %dec.i70, ptr %count_dw.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i70)
  %cmp.i73 = icmp slt i32 %dec.i70, 1
  br i1 %cmp.i73, label %if.then.i74, label %amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge

amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge: ; preds = %amdgpu_ring_write.exit71
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit84

if.then.i74:                                      ; preds = %amdgpu_ring_write.exit71
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit84

amdgpu_ring_write.exit84:                         ; preds = %if.then.i74, %amdgpu_ring_write.exit71.amdgpu_ring_write.exit84_crit_edge
  %80 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load ptr, ptr %ring1.i, align 4
  %82 = ptrtoint ptr %wptr.i to i32
  call void @__asan_load8_noabort(i32 %82)
  %83 = load i64, ptr %wptr.i, align 8
  %inc.i77 = add i64 %83, 1
  store i64 %inc.i77, ptr %wptr.i, align 8
  %84 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load i32, ptr %buf_mask.i, align 8
  %86 = trunc i64 %83 to i32
  %idxprom.i79 = and i32 %85, %86
  %arrayidx.i80 = getelementptr i32, ptr %81, i32 %idxprom.i79
  %87 = ptrtoint ptr %arrayidx.i80 to i32
  call void @__asan_store4_noabort(i32 %87)
  store volatile i32 10, ptr %arrayidx.i80, align 4
  %88 = ptrtoint ptr %ptr_mask.i to i32
  call void @__asan_load8_noabort(i32 %88)
  %89 = load i64, ptr %ptr_mask.i, align 8
  %90 = load i64, ptr %wptr.i, align 8
  %and3.i82 = and i64 %90, %89
  store i64 %and3.i82, ptr %wptr.i, align 8
  %91 = ptrtoint ptr %count_dw.i to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %count_dw.i, align 8
  %dec.i83 = add i32 %92, -1
  store i32 %dec.i83, ptr %count_dw.i, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_emit_wave_limit(ptr noundef %ring, i1 noundef zeroext %enable) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %cond = select i1 %enable, i32 31, i32 134217727
  %funcs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %2 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %funcs, align 4
  %emit_wreg = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %3, i32 0, i32 33
  %4 = ptrtoint ptr %emit_wreg to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %emit_wreg, align 4
  tail call void %5(ptr noundef %ring, i32 noundef 12743, i32 noundef %cond) #12
  %num_pipe_per_mec = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 106, i32 6, i32 5
  %6 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %7)
  %cmp12.not = icmp eq i32 %7, 0
  br i1 %cmp12.not, label %entry.for.end_crit_edge, label %for.body.lr.ph

entry.for.end_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.lr.ph:                                   ; preds = %entry
  %pipe = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 17
  %cond.i = select i1 %enable, i32 1, i32 127
  %8 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %cmp2.not.peel = icmp eq i32 %9, 0
  br i1 %cmp2.not.peel, label %for.body.lr.ph.for.inc.peel_crit_edge, label %switch.lookup.peel

for.body.lr.ph.for.inc.peel_crit_edge:            ; preds = %for.body.lr.ph
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.peel

switch.lookup.peel:                               ; preds = %for.body.lr.ph
  call void @__sanitizer_cov_trace_pc() #14
  %10 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %funcs, align 4
  %emit_wreg.i.peel = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %11, i32 0, i32 33
  %12 = ptrtoint ptr %emit_wreg.i.peel to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %emit_wreg.i.peel, align 4
  tail call void %13(ptr noundef %ring, i32 noundef 12745, i32 noundef %cond.i) #12
  br label %for.inc.peel

for.inc.peel:                                     ; preds = %switch.lookup.peel, %for.body.lr.ph.for.inc.peel_crit_edge
  %14 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %15)
  %cmp.peel = icmp ugt i32 %15, 1
  br i1 %cmp.peel, label %for.body.peel16, label %for.inc.peel.for.end_crit_edge

for.inc.peel.for.end_crit_edge:                   ; preds = %for.inc.peel
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.peel16:                                  ; preds = %for.inc.peel
  %16 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %17)
  %cmp2.not.peel17 = icmp eq i32 %17, 1
  br i1 %cmp2.not.peel17, label %for.body.peel16.for.inc.peel23_crit_edge, label %switch.lookup.peel20

for.body.peel16.for.inc.peel23_crit_edge:         ; preds = %for.body.peel16
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.peel23

switch.lookup.peel20:                             ; preds = %for.body.peel16
  call void @__sanitizer_cov_trace_pc() #14
  %18 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %funcs, align 4
  %emit_wreg.i.peel22 = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %19, i32 0, i32 33
  %20 = ptrtoint ptr %emit_wreg.i.peel22 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %emit_wreg.i.peel22, align 4
  tail call void %21(ptr noundef %ring, i32 noundef 12746, i32 noundef %cond.i) #12
  br label %for.inc.peel23

for.inc.peel23:                                   ; preds = %switch.lookup.peel20, %for.body.peel16.for.inc.peel23_crit_edge
  %22 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %23)
  %cmp.peel25 = icmp ugt i32 %23, 2
  br i1 %cmp.peel25, label %for.body.peel27, label %for.inc.peel23.for.end_crit_edge

for.inc.peel23.for.end_crit_edge:                 ; preds = %for.inc.peel23
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.peel27:                                  ; preds = %for.inc.peel23
  %24 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %25)
  %cmp2.not.peel28 = icmp eq i32 %25, 2
  br i1 %cmp2.not.peel28, label %for.body.peel27.for.inc.peel34_crit_edge, label %switch.lookup.peel31

for.body.peel27.for.inc.peel34_crit_edge:         ; preds = %for.body.peel27
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.peel34

switch.lookup.peel31:                             ; preds = %for.body.peel27
  call void @__sanitizer_cov_trace_pc() #14
  %26 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %funcs, align 4
  %emit_wreg.i.peel33 = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %27, i32 0, i32 33
  %28 = ptrtoint ptr %emit_wreg.i.peel33 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %emit_wreg.i.peel33, align 4
  tail call void %29(ptr noundef %ring, i32 noundef 12747, i32 noundef %cond.i) #12
  br label %for.inc.peel34

for.inc.peel34:                                   ; preds = %switch.lookup.peel31, %for.body.peel27.for.inc.peel34_crit_edge
  %30 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %31)
  %cmp.peel36 = icmp ugt i32 %31, 3
  br i1 %cmp.peel36, label %for.body.peel38, label %for.inc.peel34.for.end_crit_edge

for.inc.peel34.for.end_crit_edge:                 ; preds = %for.inc.peel34
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.peel38:                                  ; preds = %for.inc.peel34
  %32 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %33)
  %cmp2.not.peel39 = icmp eq i32 %33, 3
  br i1 %cmp2.not.peel39, label %for.body.peel38.for.inc.peel45_crit_edge, label %switch.lookup.peel42

for.body.peel38.for.inc.peel45_crit_edge:         ; preds = %for.body.peel38
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.peel45

switch.lookup.peel42:                             ; preds = %for.body.peel38
  call void @__sanitizer_cov_trace_pc() #14
  %34 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %funcs, align 4
  %emit_wreg.i.peel44 = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %35, i32 0, i32 33
  %36 = ptrtoint ptr %emit_wreg.i.peel44 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %emit_wreg.i.peel44, align 4
  tail call void %37(ptr noundef %ring, i32 noundef 12748, i32 noundef %cond.i) #12
  br label %for.inc.peel45

for.inc.peel45:                                   ; preds = %switch.lookup.peel42, %for.body.peel38.for.inc.peel45_crit_edge
  %38 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %num_pipe_per_mec, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %39)
  %cmp.peel47 = icmp ugt i32 %39, 4
  br i1 %cmp.peel47, label %for.inc.peel45.for.body_crit_edge, label %for.inc.peel45.for.end_crit_edge

for.inc.peel45.for.end_crit_edge:                 ; preds = %for.inc.peel45
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.inc.peel45.for.body_crit_edge:                ; preds = %for.inc.peel45
  br label %for.body

for.body:                                         ; preds = %for.inc.for.body_crit_edge, %for.inc.peel45.for.body_crit_edge
  %i.013 = phi i32 [ %inc, %for.inc.for.body_crit_edge ], [ 4, %for.inc.peel45.for.body_crit_edge ]
  %40 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %i.013, i32 %41)
  %cmp2.not = icmp eq i32 %i.013, %41
  br i1 %cmp2.not, label %for.body.for.inc_crit_edge, label %sw.default.i

for.body.for.inc_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc

sw.default.i:                                     ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.2, i32 noundef %i.013) #12
  br label %for.inc

for.inc:                                          ; preds = %sw.default.i, %for.body.for.inc_crit_edge
  %inc = add nuw i32 %i.013, 1
  %42 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %num_pipe_per_mec, align 4
  %cmp = icmp ult i32 %inc, %43
  br i1 %cmp, label %for.inc.for.body_crit_edge, label %for.inc.for.end_crit_edge, !llvm.loop !445

for.inc.for.end_crit_edge:                        ; preds = %for.inc
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.inc.for.body_crit_edge:                       ; preds = %for.inc
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.inc.for.end_crit_edge, %for.inc.peel45.for.end_crit_edge, %for.inc.peel34.for.end_crit_edge, %for.inc.peel23.for.end_crit_edge, %for.inc.peel.for.end_crit_edge, %entry.for.end_crit_edge
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__drm_dbg(i32 noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_eop_interrupt_state(ptr noundef %adev, ptr nocapture noundef readnone %src, i32 noundef %type, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = zext i32 %type to i64
  call void @__sanitizer_cov_trace_switch(i64 %0, ptr @__sancov_gen_cov_switch_values.112)
  switch i32 %type, label %entry.sw.epilog_crit_edge [
    i32 0, label %sw.bb
    i32 2, label %sw.bb1
    i32 3, label %sw.bb2
    i32 4, label %sw.bb3
    i32 5, label %sw.bb4
    i32 6, label %sw.bb5
    i32 7, label %sw.bb6
    i32 8, label %sw.bb7
    i32 9, label %sw.bb8
  ]

entry.sw.epilog_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb:                                            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and.i = and i32 %call.i, -67108865
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %state)
  %cmp.not.i = icmp eq i32 %state, 0
  %shl.i = select i1 %cmp.not.i, i32 0, i32 67108864
  %or.i = or i32 %and.i, %shl.i
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or.i, i32 noundef 0) #12
  br label %sw.epilog

sw.bb1:                                           ; preds = %entry
  %1 = zext i32 %state to i64
  call void @__sanitizer_cov_trace_switch(i64 %1, ptr @__sancov_gen_cov_switch_values.113)
  switch i32 %state, label %sw.bb1.sw.epilog_crit_edge [
    i32 0, label %sw.bb4.i
    i32 1, label %sw.bb5.i
  ]

sw.bb1.sw.epilog_crit_edge:                       ; preds = %sw.bb1
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb4.i:                                         ; preds = %sw.bb1
  call void @__sanitizer_cov_trace_pc() #14
  %call.i25 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12421, i32 noundef 0) #12
  %and.i26 = and i32 %call.i25, -67108865
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12421, i32 noundef %and.i26, i32 noundef 0) #12
  br label %sw.epilog

sw.bb5.i:                                         ; preds = %sw.bb1
  call void @__sanitizer_cov_trace_pc() #14
  %call6.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12421, i32 noundef 0) #12
  %or.i27 = or i32 %call6.i, 67108864
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12421, i32 noundef %or.i27, i32 noundef 0) #12
  br label %sw.epilog

sw.bb2:                                           ; preds = %entry
  %2 = zext i32 %state to i64
  call void @__sanitizer_cov_trace_switch(i64 %2, ptr @__sancov_gen_cov_switch_values.114)
  switch i32 %state, label %sw.bb2.sw.epilog_crit_edge [
    i32 0, label %sw.bb4.i30
    i32 1, label %sw.bb5.i33
  ]

sw.bb2.sw.epilog_crit_edge:                       ; preds = %sw.bb2
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb4.i30:                                       ; preds = %sw.bb2
  call void @__sanitizer_cov_trace_pc() #14
  %call.i28 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12422, i32 noundef 0) #12
  %and.i29 = and i32 %call.i28, -67108865
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12422, i32 noundef %and.i29, i32 noundef 0) #12
  br label %sw.epilog

sw.bb5.i33:                                       ; preds = %sw.bb2
  call void @__sanitizer_cov_trace_pc() #14
  %call6.i31 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12422, i32 noundef 0) #12
  %or.i32 = or i32 %call6.i31, 67108864
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12422, i32 noundef %or.i32, i32 noundef 0) #12
  br label %sw.epilog

sw.bb3:                                           ; preds = %entry
  %3 = zext i32 %state to i64
  call void @__sanitizer_cov_trace_switch(i64 %3, ptr @__sancov_gen_cov_switch_values.115)
  switch i32 %state, label %sw.bb3.sw.epilog_crit_edge [
    i32 0, label %sw.bb4.i37
    i32 1, label %sw.bb5.i40
  ]

sw.bb3.sw.epilog_crit_edge:                       ; preds = %sw.bb3
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb4.i37:                                       ; preds = %sw.bb3
  call void @__sanitizer_cov_trace_pc() #14
  %call.i35 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12423, i32 noundef 0) #12
  %and.i36 = and i32 %call.i35, -67108865
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12423, i32 noundef %and.i36, i32 noundef 0) #12
  br label %sw.epilog

sw.bb5.i40:                                       ; preds = %sw.bb3
  call void @__sanitizer_cov_trace_pc() #14
  %call6.i38 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12423, i32 noundef 0) #12
  %or.i39 = or i32 %call6.i38, 67108864
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12423, i32 noundef %or.i39, i32 noundef 0) #12
  br label %sw.epilog

sw.bb4:                                           ; preds = %entry
  %4 = zext i32 %state to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.116)
  switch i32 %state, label %sw.bb4.sw.epilog_crit_edge [
    i32 0, label %sw.bb4.i44
    i32 1, label %sw.bb5.i47
  ]

sw.bb4.sw.epilog_crit_edge:                       ; preds = %sw.bb4
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb4.i44:                                       ; preds = %sw.bb4
  call void @__sanitizer_cov_trace_pc() #14
  %call.i42 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12424, i32 noundef 0) #12
  %and.i43 = and i32 %call.i42, -67108865
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12424, i32 noundef %and.i43, i32 noundef 0) #12
  br label %sw.epilog

sw.bb5.i47:                                       ; preds = %sw.bb4
  call void @__sanitizer_cov_trace_pc() #14
  %call6.i45 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12424, i32 noundef 0) #12
  %or.i46 = or i32 %call6.i45, 67108864
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12424, i32 noundef %or.i46, i32 noundef 0) #12
  br label %sw.epilog

sw.bb5:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.3, i32 noundef 2) #12
  br label %sw.epilog

sw.bb6:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.3, i32 noundef 2) #12
  br label %sw.epilog

sw.bb7:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.3, i32 noundef 2) #12
  br label %sw.epilog

sw.bb8:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.3, i32 noundef 2) #12
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.bb8, %sw.bb7, %sw.bb6, %sw.bb5, %sw.bb5.i47, %sw.bb4.i44, %sw.bb4.sw.epilog_crit_edge, %sw.bb5.i40, %sw.bb4.i37, %sw.bb3.sw.epilog_crit_edge, %sw.bb5.i33, %sw.bb4.i30, %sw.bb2.sw.epilog_crit_edge, %sw.bb5.i, %sw.bb4.i, %sw.bb1.sw.epilog_crit_edge, %sw.bb, %entry.sw.epilog_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_eop_irq(ptr noundef %adev, ptr nocapture noundef readnone %source, ptr nocapture noundef readonly %entry1) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.4) #12
  %ring_id = getelementptr inbounds %struct.amdgpu_iv_entry, ptr %entry1, i32 0, i32 3
  %0 = ptrtoint ptr %ring_id to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %ring_id, align 4
  %2 = lshr i32 %1, 2
  %conv = and i32 %2, 3
  %conv5 = and i32 %1, 3
  %3 = lshr i32 %1, 4
  %conv9 = and i32 %3, 7
  %4 = zext i32 %conv to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.117)
  switch i32 %conv, label %entry.sw.epilog_crit_edge [
    i32 0, label %sw.bb
    i32 1, label %entry.sw.bb11_crit_edge
    i32 2, label %entry.sw.bb11_crit_edge40
  ]

entry.sw.bb11_crit_edge40:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11

entry.sw.bb11_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11

entry.sw.epilog_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb:                                            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %gfx_ring = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36
  %call = tail call zeroext i1 @amdgpu_fence_process(ptr noundef %gfx_ring) #12
  br label %sw.epilog

sw.bb11:                                          ; preds = %entry.sw.bb11_crit_edge, %entry.sw.bb11_crit_edge40
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 39
  %5 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %6)
  %cmp37.not = icmp eq i32 %6, 0
  br i1 %cmp37.not, label %sw.bb11.sw.epilog_crit_edge, label %sw.bb11.for.body_crit_edge

sw.bb11.for.body_crit_edge:                       ; preds = %sw.bb11
  br label %for.body

sw.bb11.sw.epilog_crit_edge:                      ; preds = %sw.bb11
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

for.body:                                         ; preds = %for.inc.for.body_crit_edge, %sw.bb11.for.body_crit_edge
  %i.038 = phi i32 [ %inc, %for.inc.for.body_crit_edge ], [ 0, %sw.bb11.for.body_crit_edge ]
  %arrayidx15 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038
  %me = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038, i32 16
  %7 = ptrtoint ptr %me to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %me, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %8, i32 %conv)
  %cmp17 = icmp eq i32 %8, %conv
  br i1 %cmp17, label %land.lhs.true, label %for.body.for.inc_crit_edge

for.body.for.inc_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc

land.lhs.true:                                    ; preds = %for.body
  %pipe = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038, i32 17
  %9 = ptrtoint ptr %pipe to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %pipe, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %10, i32 %conv5)
  %cmp20 = icmp eq i32 %10, %conv5
  br i1 %cmp20, label %land.lhs.true22, label %land.lhs.true.for.inc_crit_edge

land.lhs.true.for.inc_crit_edge:                  ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc

land.lhs.true22:                                  ; preds = %land.lhs.true
  %queue = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038, i32 18
  %11 = ptrtoint ptr %queue to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %queue, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %12, i32 %conv9)
  %cmp24 = icmp eq i32 %12, %conv9
  br i1 %cmp24, label %if.then, label %land.lhs.true22.for.inc_crit_edge

land.lhs.true22.for.inc_crit_edge:                ; preds = %land.lhs.true22
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc

if.then:                                          ; preds = %land.lhs.true22
  call void @__sanitizer_cov_trace_pc() #14
  %call26 = tail call zeroext i1 @amdgpu_fence_process(ptr noundef %arrayidx15) #12
  br label %for.inc

for.inc:                                          ; preds = %if.then, %land.lhs.true22.for.inc_crit_edge, %land.lhs.true.for.inc_crit_edge, %for.body.for.inc_crit_edge
  %inc = add nuw i32 %i.038, 1
  %13 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %num_compute_rings, align 8
  %cmp = icmp ult i32 %inc, %14
  br i1 %cmp, label %for.inc.for.body_crit_edge, label %for.inc.sw.epilog_crit_edge

for.inc.sw.epilog_crit_edge:                      ; preds = %for.inc
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

for.inc.for.body_crit_edge:                       ; preds = %for.inc
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

sw.epilog:                                        ; preds = %for.inc.sw.epilog_crit_edge, %sw.bb11.sw.epilog_crit_edge, %sw.bb, %entry.sw.epilog_crit_edge
  ret i32 0
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @amdgpu_fence_process(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_priv_reg_fault_state(ptr noundef %adev, ptr nocapture noundef readnone %source, i32 noundef %type, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and = and i32 %call, -8388609
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %state)
  %cmp.not = icmp eq i32 %state, 0
  %shl = select i1 %cmp.not, i32 0, i32 8388608
  %or = or i32 %and, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or, i32 noundef 0) #12
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_priv_reg_irq(ptr noundef %adev, ptr nocapture noundef readnone %source, ptr nocapture noundef readonly %entry1) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.5) #12
  %ring_id.i = getelementptr inbounds %struct.amdgpu_iv_entry, ptr %entry1, i32 0, i32 3
  %0 = ptrtoint ptr %ring_id.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %ring_id.i, align 4
  %2 = lshr i32 %1, 2
  %conv.i = and i32 %2, 3
  %conv5.i = and i32 %1, 3
  %3 = lshr i32 %1, 4
  %conv9.i = and i32 %3, 7
  %4 = zext i32 %conv.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.118)
  switch i32 %conv.i, label %entry.gfx_v8_0_fault.exit_crit_edge [
    i32 0, label %sw.bb.i
    i32 1, label %entry.sw.bb11.i_crit_edge
    i32 2, label %entry.sw.bb11.i_crit_edge2
  ]

entry.sw.bb11.i_crit_edge2:                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11.i

entry.sw.bb11.i_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11.i

entry.gfx_v8_0_fault.exit_crit_edge:              ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

sw.bb.i:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %sched.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 3
  tail call void @drm_sched_fault(ptr noundef %sched.i) #12
  br label %gfx_v8_0_fault.exit

sw.bb11.i:                                        ; preds = %entry.sw.bb11.i_crit_edge, %entry.sw.bb11.i_crit_edge2
  %num_compute_rings.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 39
  %5 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %num_compute_rings.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %6)
  %cmp37.not.i = icmp eq i32 %6, 0
  br i1 %cmp37.not.i, label %sw.bb11.i.gfx_v8_0_fault.exit_crit_edge, label %sw.bb11.i.for.body.i_crit_edge

sw.bb11.i.for.body.i_crit_edge:                   ; preds = %sw.bb11.i
  br label %for.body.i

sw.bb11.i.gfx_v8_0_fault.exit_crit_edge:          ; preds = %sw.bb11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

for.body.i:                                       ; preds = %for.inc.i.for.body.i_crit_edge, %sw.bb11.i.for.body.i_crit_edge
  %i.038.i = phi i32 [ %inc.i, %for.inc.i.for.body.i_crit_edge ], [ 0, %sw.bb11.i.for.body.i_crit_edge ]
  %me.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 16
  %7 = ptrtoint ptr %me.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %me.i, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %8, i32 %conv.i)
  %cmp17.i = icmp eq i32 %8, %conv.i
  br i1 %cmp17.i, label %land.lhs.true.i, label %for.body.i.for.inc.i_crit_edge

for.body.i.for.inc.i_crit_edge:                   ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

land.lhs.true.i:                                  ; preds = %for.body.i
  %pipe.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 17
  %9 = ptrtoint ptr %pipe.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %pipe.i, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %10, i32 %conv5.i)
  %cmp20.i = icmp eq i32 %10, %conv5.i
  br i1 %cmp20.i, label %land.lhs.true22.i, label %land.lhs.true.i.for.inc.i_crit_edge

land.lhs.true.i.for.inc.i_crit_edge:              ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

land.lhs.true22.i:                                ; preds = %land.lhs.true.i
  %queue.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 18
  %11 = ptrtoint ptr %queue.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %queue.i, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %12, i32 %conv9.i)
  %cmp24.i = icmp eq i32 %12, %conv9.i
  br i1 %cmp24.i, label %if.then.i, label %land.lhs.true22.i.for.inc.i_crit_edge

land.lhs.true22.i.for.inc.i_crit_edge:            ; preds = %land.lhs.true22.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

if.then.i:                                        ; preds = %land.lhs.true22.i
  call void @__sanitizer_cov_trace_pc() #14
  %sched26.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 3
  tail call void @drm_sched_fault(ptr noundef %sched26.i) #12
  br label %for.inc.i

for.inc.i:                                        ; preds = %if.then.i, %land.lhs.true22.i.for.inc.i_crit_edge, %land.lhs.true.i.for.inc.i_crit_edge, %for.body.i.for.inc.i_crit_edge
  %inc.i = add nuw i32 %i.038.i, 1
  %13 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %num_compute_rings.i, align 8
  %cmp.i = icmp ult i32 %inc.i, %14
  br i1 %cmp.i, label %for.inc.i.for.body.i_crit_edge, label %for.inc.i.gfx_v8_0_fault.exit_crit_edge

for.inc.i.gfx_v8_0_fault.exit_crit_edge:          ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

for.inc.i.for.body.i_crit_edge:                   ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

gfx_v8_0_fault.exit:                              ; preds = %for.inc.i.gfx_v8_0_fault.exit_crit_edge, %sw.bb11.i.gfx_v8_0_fault.exit_crit_edge, %sw.bb.i, %entry.gfx_v8_0_fault.exit_crit_edge
  ret i32 0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @drm_sched_fault(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_priv_inst_fault_state(ptr noundef %adev, ptr nocapture noundef readnone %source, i32 noundef %type, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and = and i32 %call, -4194305
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %state)
  %cmp.not = icmp eq i32 %state, 0
  %shl = select i1 %cmp.not, i32 0, i32 4194304
  %or = or i32 %and, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or, i32 noundef 0) #12
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_priv_inst_irq(ptr noundef %adev, ptr nocapture noundef readnone %source, ptr nocapture noundef readonly %entry1) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.6) #12
  %ring_id.i = getelementptr inbounds %struct.amdgpu_iv_entry, ptr %entry1, i32 0, i32 3
  %0 = ptrtoint ptr %ring_id.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %ring_id.i, align 4
  %2 = lshr i32 %1, 2
  %conv.i = and i32 %2, 3
  %conv5.i = and i32 %1, 3
  %3 = lshr i32 %1, 4
  %conv9.i = and i32 %3, 7
  %4 = zext i32 %conv.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %4, ptr @__sancov_gen_cov_switch_values.119)
  switch i32 %conv.i, label %entry.gfx_v8_0_fault.exit_crit_edge [
    i32 0, label %sw.bb.i
    i32 1, label %entry.sw.bb11.i_crit_edge
    i32 2, label %entry.sw.bb11.i_crit_edge2
  ]

entry.sw.bb11.i_crit_edge2:                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11.i

entry.sw.bb11.i_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb11.i

entry.gfx_v8_0_fault.exit_crit_edge:              ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

sw.bb.i:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %sched.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 3
  tail call void @drm_sched_fault(ptr noundef %sched.i) #12
  br label %gfx_v8_0_fault.exit

sw.bb11.i:                                        ; preds = %entry.sw.bb11.i_crit_edge, %entry.sw.bb11.i_crit_edge2
  %num_compute_rings.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 39
  %5 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %num_compute_rings.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %6)
  %cmp37.not.i = icmp eq i32 %6, 0
  br i1 %cmp37.not.i, label %sw.bb11.i.gfx_v8_0_fault.exit_crit_edge, label %sw.bb11.i.for.body.i_crit_edge

sw.bb11.i.for.body.i_crit_edge:                   ; preds = %sw.bb11.i
  br label %for.body.i

sw.bb11.i.gfx_v8_0_fault.exit_crit_edge:          ; preds = %sw.bb11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

for.body.i:                                       ; preds = %for.inc.i.for.body.i_crit_edge, %sw.bb11.i.for.body.i_crit_edge
  %i.038.i = phi i32 [ %inc.i, %for.inc.i.for.body.i_crit_edge ], [ 0, %sw.bb11.i.for.body.i_crit_edge ]
  %me.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 16
  %7 = ptrtoint ptr %me.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %me.i, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %8, i32 %conv.i)
  %cmp17.i = icmp eq i32 %8, %conv.i
  br i1 %cmp17.i, label %land.lhs.true.i, label %for.body.i.for.inc.i_crit_edge

for.body.i.for.inc.i_crit_edge:                   ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

land.lhs.true.i:                                  ; preds = %for.body.i
  %pipe.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 17
  %9 = ptrtoint ptr %pipe.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %pipe.i, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %10, i32 %conv5.i)
  %cmp20.i = icmp eq i32 %10, %conv5.i
  br i1 %cmp20.i, label %land.lhs.true22.i, label %land.lhs.true.i.for.inc.i_crit_edge

land.lhs.true.i.for.inc.i_crit_edge:              ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

land.lhs.true22.i:                                ; preds = %land.lhs.true.i
  %queue.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 18
  %11 = ptrtoint ptr %queue.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %queue.i, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %12, i32 %conv9.i)
  %cmp24.i = icmp eq i32 %12, %conv9.i
  br i1 %cmp24.i, label %if.then.i, label %land.lhs.true22.i.for.inc.i_crit_edge

land.lhs.true22.i.for.inc.i_crit_edge:            ; preds = %land.lhs.true22.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

if.then.i:                                        ; preds = %land.lhs.true22.i
  call void @__sanitizer_cov_trace_pc() #14
  %sched26.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.038.i, i32 3
  tail call void @drm_sched_fault(ptr noundef %sched26.i) #12
  br label %for.inc.i

for.inc.i:                                        ; preds = %if.then.i, %land.lhs.true22.i.for.inc.i_crit_edge, %land.lhs.true.i.for.inc.i_crit_edge, %for.body.i.for.inc.i_crit_edge
  %inc.i = add nuw i32 %i.038.i, 1
  %13 = ptrtoint ptr %num_compute_rings.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %num_compute_rings.i, align 8
  %cmp.i = icmp ult i32 %inc.i, %14
  br i1 %cmp.i, label %for.inc.i.for.body.i_crit_edge, label %for.inc.i.gfx_v8_0_fault.exit_crit_edge

for.inc.i.gfx_v8_0_fault.exit_crit_edge:          ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_fault.exit

for.inc.i.for.body.i_crit_edge:                   ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

gfx_v8_0_fault.exit:                              ; preds = %for.inc.i.gfx_v8_0_fault.exit_crit_edge, %sw.bb11.i.gfx_v8_0_fault.exit_crit_edge, %sw.bb.i, %entry.gfx_v8_0_fault.exit_crit_edge
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_cp_ecc_int_state(ptr noundef %adev, ptr nocapture noundef readnone %source, i32 noundef %type, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %state)
  %switch = icmp ult i32 %state, 2
  br i1 %switch, label %sw.epilog, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.epilog:                                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12361, i32 noundef 0) #12
  %and = and i32 %call, -16385
  %shl = shl nuw nsw i32 %state, 14
  %or = or i32 %and, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12361, i32 noundef %or, i32 noundef 0) #12
  %call2 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and3 = and i32 %call2, -16385
  %or5 = or i32 %and3, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or5, i32 noundef 0) #12
  %call6 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12395, i32 noundef 0) #12
  %and7 = and i32 %call6, -16385
  %or9 = or i32 %and7, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12395, i32 noundef %or9, i32 noundef 0) #12
  %call10 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12396, i32 noundef 0) #12
  %and11 = and i32 %call10, -16385
  %or13 = or i32 %and11, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12396, i32 noundef %or13, i32 noundef 0) #12
  %call14 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12468, i32 noundef 0) #12
  %and15 = and i32 %call14, -16385
  %or17 = or i32 %and15, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12468, i32 noundef %or17, i32 noundef 0) #12
  %call18 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12421, i32 noundef 0) #12
  %and19 = and i32 %call18, -16385
  %or21 = or i32 %and19, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12421, i32 noundef %or21, i32 noundef 0) #12
  %call22 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12422, i32 noundef 0) #12
  %and23 = and i32 %call22, -16385
  %or25 = or i32 %and23, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12422, i32 noundef %or25, i32 noundef 0) #12
  %call26 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12423, i32 noundef 0) #12
  %and27 = and i32 %call26, -16385
  %or29 = or i32 %and27, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12423, i32 noundef %or29, i32 noundef 0) #12
  %call30 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12424, i32 noundef 0) #12
  %and31 = and i32 %call30, -16385
  %or33 = or i32 %and31, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12424, i32 noundef %or33, i32 noundef 0) #12
  %call34 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12425, i32 noundef 0) #12
  %and35 = and i32 %call34, -16385
  %or37 = or i32 %and35, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12425, i32 noundef %or37, i32 noundef 0) #12
  %call38 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12426, i32 noundef 0) #12
  %and39 = and i32 %call38, -16385
  %or41 = or i32 %and39, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12426, i32 noundef %or41, i32 noundef 0) #12
  %call42 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12427, i32 noundef 0) #12
  %and43 = and i32 %call42, -16385
  %or45 = or i32 %and43, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12427, i32 noundef %or45, i32 noundef 0) #12
  %call46 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12428, i32 noundef 0) #12
  %and47 = and i32 %call46, -16385
  %or49 = or i32 %and47, %shl
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12428, i32 noundef %or49, i32 noundef 0) #12
  br label %cleanup

cleanup:                                          ; preds = %sw.epilog, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ 0, %sw.epilog ], [ -22, %entry.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_cp_ecc_error_irq(ptr nocapture noundef readnone %adev, ptr nocapture noundef readnone %source, ptr nocapture noundef readnone %entry1) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.7) #12
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_set_sq_int_state(ptr noundef %adev, ptr nocapture noundef readnone %source, i32 noundef %type, i32 noundef %state) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = zext i32 %state to i64
  call void @__sanitizer_cov_trace_switch(i64 %0, ptr @__sancov_gen_cov_switch_values.120)
  switch i32 %state, label %entry.cleanup_crit_edge [
    i32 0, label %entry.sw.epilog_crit_edge
    i32 1, label %sw.bb1
  ]

entry.sw.epilog_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.bb1:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.bb1, %entry.sw.epilog_crit_edge
  %enable_flag.0 = phi i32 [ 0, %sw.bb1 ], [ 1, %entry.sw.epilog_crit_edge ]
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8981, i32 noundef 0) #12
  %and = and i32 %call, -2
  %or = or i32 %and, %enable_flag.0
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8981, i32 noundef %or, i32 noundef 0) #12
  br label %cleanup

cleanup:                                          ; preds = %sw.epilog, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ 0, %sw.epilog ], [ -22, %entry.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_sq_irq(ptr noundef %adev, ptr nocapture noundef readnone %source, ptr nocapture noundef readonly %entry1) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %src_data = getelementptr inbounds %struct.amdgpu_iv_entry, ptr %entry1, i32 0, i32 10
  %0 = ptrtoint ptr %src_data to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %src_data, align 4
  %sq_work = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 45
  %2 = ptrtoint ptr %sq_work to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %sq_work, align 4
  %and1.i = and i32 %3, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and1.i)
  %tobool.not = icmp eq i32 %and1.i, 0
  br i1 %tobool.not, label %if.else, label %if.then

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call fastcc void @gfx_v8_0_parse_sq_irq(ptr noundef %adev, i32 noundef %1, i1 noundef zeroext false)
  br label %if.end

if.else:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %ih_data4 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 45, i32 1
  %4 = ptrtoint ptr %ih_data4 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %1, ptr %ih_data4, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @system_wq to i32))
  %5 = load ptr, ptr @system_wq, align 4
  %call.i.i = tail call zeroext i1 @queue_work_on(i32 noundef 4, ptr noundef %5, ptr noundef %sq_work) #12
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_parse_sq_irq(ptr noundef %adev, i32 noundef %ih_data, i1 noundef zeroext %from_wq) unnamed_addr #0 align 64 {
entry:
  %type = alloca [20 x i8], align 1
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @llvm.lifetime.start.p0(i64 20, ptr nonnull %type) #12
  %and = lshr i32 %ih_data, 26
  %shr = and i32 %and, 3
  %and1 = lshr i32 %ih_data, 24
  %shr2 = and i32 %and1, 3
  %0 = call ptr @memset(ptr %type, i32 255, i32 20)
  %1 = zext i32 %shr to i64
  call void @__sanitizer_cov_trace_switch(i64 %1, ptr @__sancov_gen_cov_switch_values.121)
  switch i32 %shr, label %sw.default [
    i32 0, label %do.end
    i32 1, label %entry.sw.bb19_crit_edge
    i32 2, label %entry.sw.bb19_crit_edge75
  ]

entry.sw.bb19_crit_edge75:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb19

entry.sw.bb19_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb19

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %and3 = lshr i32 %ih_data, 7
  %shr4 = and i32 %and3, 1
  %and5 = lshr i32 %ih_data, 6
  %shr6 = and i32 %and5, 1
  %and7 = lshr i32 %ih_data, 5
  %shr8 = and i32 %and7, 1
  %and9 = lshr i32 %ih_data, 4
  %shr10 = and i32 %and9, 1
  %and11 = lshr i32 %ih_data, 3
  %shr12 = and i32 %and11, 1
  %and13 = lshr i32 %ih_data, 2
  %shr14 = and i32 %and13, 1
  %and15 = lshr i32 %ih_data, 1
  %shr16 = and i32 %and15, 1
  %and17 = and i32 %ih_data, 1
  %call = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.8, i32 noundef %shr2, i32 noundef %shr4, i32 noundef %shr6, i32 noundef %shr8, i32 noundef %shr10, i32 noundef %shr12, i32 noundef %shr14, i32 noundef %shr16, i32 noundef %and17) #15
  br label %sw.epilog

sw.bb19:                                          ; preds = %entry.sw.bb19_crit_edge, %entry.sw.bb19_crit_edge75
  %and20 = lshr i32 %ih_data, 20
  %shr21 = and i32 %and20, 15
  %and22 = lshr i32 %ih_data, 8
  %shr23 = and i32 %and22, 1
  br i1 %from_wq, label %if.then, label %sw.bb19.if.end_crit_edge

sw.bb19.if.end_crit_edge:                         ; preds = %sw.bb19
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %sw.bb19
  call void @__sanitizer_cov_trace_pc() #14
  %grbm_idx_mutex = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 21
  tail call void @mutex_lock_nested(ptr noundef %grbm_idx_mutex, i32 noundef 0) #12
  %shl7.i = shl nuw nsw i32 %shr2, 16
  %data.1.i = or i32 %shl7.i, %shr21
  %shl17.i = shl nuw nsw i32 %shr23, 8
  %data.2.i = or i32 %data.1.i, %shl17.i
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef %data.2.i, i32 noundef 0) #12
  %call24 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 9123, i32 noundef 0) #12
  %and25 = lshr i32 %call24, 6
  %shr26 = and i32 %and25, 7
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %grbm_idx_mutex) #12
  br label %if.end

if.end:                                           ; preds = %if.then, %sw.bb19.if.end_crit_edge
  %sq_edc_source.0 = phi i32 [ %shr26, %if.then ], [ -1, %sw.bb19.if.end_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %shr)
  %cmp = icmp eq i32 %shr, 1
  br i1 %cmp, label %if.then28, label %if.else

if.then28:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %2 = call ptr @memcpy(ptr %type, ptr @.str.11, i32 17)
  br label %do.end35

if.else:                                          ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %3 = call ptr @memcpy(ptr %type, ptr @.str.12, i32 14)
  br label %do.end35

do.end35:                                         ; preds = %if.else, %if.then28
  %and38 = lshr i32 %ih_data, 18
  %shr39 = and i32 %and38, 3
  %and40 = lshr i32 %ih_data, 14
  %shr41 = and i32 %and40, 15
  %and42 = lshr i32 %ih_data, 10
  %shr43 = and i32 %and42, 15
  %4 = and i32 %ih_data, 512
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %4)
  %tobool46.not = icmp eq i32 %4, 0
  %cond = select i1 %tobool46.not, ptr @.str.17, ptr @.str.16
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %sq_edc_source.0)
  %cmp47.not = icmp eq i32 %sq_edc_source.0, -1
  br i1 %cmp47.not, label %do.end35.cond.end_crit_edge, label %cond.true

do.end35.cond.end_crit_edge:                      ; preds = %do.end35
  call void @__sanitizer_cov_trace_pc() #14
  br label %cond.end

cond.true:                                        ; preds = %do.end35
  call void @__sanitizer_cov_trace_pc() #14
  %arrayidx = getelementptr [7 x ptr], ptr @sq_edc_source_names, i32 0, i32 %sq_edc_source.0
  %5 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %arrayidx, align 4
  br label %cond.end

cond.end:                                         ; preds = %cond.true, %do.end35.cond.end_crit_edge
  %cond48 = phi ptr [ %6, %cond.true ], [ @.str.18, %do.end35.cond.end_crit_edge ]
  %call49 = call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.14, ptr noundef nonnull %type, i32 noundef %shr2, i32 noundef %shr23, i32 noundef %shr21, i32 noundef %shr39, i32 noundef %shr41, i32 noundef %shr43, ptr noundef nonnull %cond, ptr noundef %cond48) #15
  br label %sw.epilog

sw.default:                                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.19) #12
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.default, %cond.end, %do.end
  call void @llvm.lifetime.end.p0(i64 20, ptr nonnull %type) #12
  ret void
}

; Function Attrs: cold null_pointer_is_valid
declare dso_local i32 @_printk(ptr noundef, ...) local_unnamed_addr #5

; Function Attrs: nofree nounwind null_pointer_is_valid
declare dso_local noundef i32 @sprintf(ptr noalias nocapture noundef writeonly, ptr nocapture noundef readonly, ...) local_unnamed_addr #6

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @queue_work_on(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal zeroext i1 @gfx_v8_0_is_rlc_enabled(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60416, i32 noundef 0) #12
  %and = and i32 %call, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp ne i32 %and, 0
  ret i1 %tobool.not
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_set_safe_mode(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60416, i32 noundef 0) #12
  %or = and i32 %call, -32
  %or1 = or i32 %or, 3
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60421, i32 noundef %or1, i32 noundef 0) #12
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 11
  %0 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp27.not = icmp eq i32 %1, 0
  br i1 %cmp27.not, label %entry.for.end15_crit_edge, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  br label %for.body

entry.for.end15_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end15

for.body:                                         ; preds = %if.end.for.body_crit_edge, %entry.for.body_crit_edge
  %i.028 = phi i32 [ %inc, %if.end.for.body_crit_edge ], [ 0, %entry.for.body_crit_edge ]
  %call2 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60480, i32 noundef 0) #12
  %and3 = and i32 %call2, 6
  call void @__sanitizer_cov_trace_const_cmp4(i32 6, i32 %and3)
  %cmp4 = icmp eq i32 %and3, 6
  br i1 %cmp4, label %for.endthread-pre-split, label %if.end

if.end:                                           ; preds = %for.body
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %2 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %2(i32 noundef 214748) #12
  %inc = add nuw i32 %i.028, 1
  %3 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %usec_timeout, align 8
  %cmp = icmp ult i32 %inc, %4
  br i1 %cmp, label %if.end.for.body_crit_edge, label %if.end.for.end_crit_edge

if.end.for.end_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end.for.body_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.endthread-pre-split:                          ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  %5 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %5)
  %.pr = load i32, ptr %usec_timeout, align 8
  br label %for.end

for.end:                                          ; preds = %for.endthread-pre-split, %if.end.for.end_crit_edge
  %6 = phi i32 [ %.pr, %for.endthread-pre-split ], [ %4, %if.end.for.end_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %6)
  %cmp729.not = icmp eq i32 %6, 0
  br i1 %cmp729.not, label %for.end.for.end15_crit_edge, label %for.end.for.body8_crit_edge

for.end.for.body8_crit_edge:                      ; preds = %for.end
  br label %for.body8

for.end.for.end15_crit_edge:                      ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end15

for.body8:                                        ; preds = %if.end12.for.body8_crit_edge, %for.end.for.body8_crit_edge
  %i.130 = phi i32 [ %inc14, %if.end12.for.body8_crit_edge ], [ 0, %for.end.for.body8_crit_edge ]
  %call9 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60421, i32 noundef 0) #12
  %and10 = and i32 %call9, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and10)
  %tobool.not = icmp eq i32 %and10, 0
  br i1 %tobool.not, label %for.body8.for.end15_crit_edge, label %if.end12

for.body8.for.end15_crit_edge:                    ; preds = %for.body8
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end15

if.end12:                                         ; preds = %for.body8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %7 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %7(i32 noundef 214748) #12
  %inc14 = add nuw i32 %i.130, 1
  %8 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %usec_timeout, align 8
  %cmp7 = icmp ult i32 %inc14, %9
  br i1 %cmp7, label %if.end12.for.body8_crit_edge, label %if.end12.for.end15_crit_edge

if.end12.for.end15_crit_edge:                     ; preds = %if.end12
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end15

if.end12.for.body8_crit_edge:                     ; preds = %if.end12
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body8

for.end15:                                        ; preds = %if.end12.for.end15_crit_edge, %for.body8.for.end15_crit_edge, %for.end.for.end15_crit_edge, %entry.for.end15_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_unset_safe_mode(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60416, i32 noundef 0) #12
  %or = and i32 %call, -32
  %and = or i32 %or, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60421, i32 noundef %and, i32 noundef 0) #12
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 11
  %0 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp9.not = icmp eq i32 %1, 0
  br i1 %cmp9.not, label %entry.for.end_crit_edge, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  br label %for.body

entry.for.end_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body:                                         ; preds = %if.end.for.body_crit_edge, %entry.for.body_crit_edge
  %i.010 = phi i32 [ %inc, %if.end.for.body_crit_edge ], [ 0, %entry.for.body_crit_edge ]
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60421, i32 noundef 0) #12
  %and2 = and i32 %call1, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and2)
  %tobool.not = icmp eq i32 %and2, 0
  br i1 %tobool.not, label %for.body.for.end_crit_edge, label %if.end

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end:                                           ; preds = %for.body
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %2 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %2(i32 noundef 214748) #12
  %inc = add nuw i32 %i.010, 1
  %3 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %usec_timeout, align 8
  %cmp = icmp ult i32 %inc, %4
  br i1 %cmp, label %if.end.for.body_crit_edge, label %if.end.for.end_crit_edge

if.end.for.end_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end.for.body_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %if.end.for.end_crit_edge, %for.body.for.end_crit_edge, %entry.for.end_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_rlc_init(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %cs_data1 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 8
  %0 = ptrtoint ptr %cs_data1 to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr @vi_cs_data, ptr %cs_data1, align 4
  %call = tail call i32 @amdgpu_gfx_rlc_init_csb(ptr noundef %adev) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool5.not = icmp eq i32 %call, 0
  br i1 %tobool5.not, label %if.end7, label %entry.cleanup_crit_edge

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end7:                                          ; preds = %entry
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %1 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %asic_type, align 8
  %.off = add i32 %2, -13
  call void @__sanitizer_cov_trace_const_cmp4(i32 2, i32 %.off)
  %switch = icmp ult i32 %.off, 2
  br i1 %switch, label %if.then10, label %if.end7.if.end17_crit_edge

if.end7.if.end17_crit_edge:                       ; preds = %if.end7
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end17

if.then10:                                        ; preds = %if.end7
  %cp_table_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 13
  %3 = ptrtoint ptr %cp_table_size to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 67584, ptr %cp_table_size, align 4
  %call13 = tail call i32 @amdgpu_gfx_rlc_init_cpt(ptr noundef %adev) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call13)
  %tobool14.not = icmp eq i32 %call13, 0
  br i1 %tobool14.not, label %if.then10.if.end17_crit_edge, label %if.then10.cleanup_crit_edge

if.then10.cleanup_crit_edge:                      ; preds = %if.then10
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then10.if.end17_crit_edge:                     ; preds = %if.then10
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end17

if.end17:                                         ; preds = %if.then10.if.end17_crit_edge, %if.end7.if.end17_crit_edge
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 15
  %4 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %funcs, align 4
  %update_spm_vmid = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %5, i32 0, i32 11
  %6 = ptrtoint ptr %update_spm_vmid to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %update_spm_vmid, align 4
  %tobool20.not = icmp eq ptr %7, null
  br i1 %tobool20.not, label %if.end17.cleanup_crit_edge, label %if.then21

if.end17.cleanup_crit_edge:                       ; preds = %if.end17
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then21:                                        ; preds = %if.end17
  call void @__sanitizer_cov_trace_pc() #14
  tail call void %7(ptr noundef %adev, i32 noundef 15) #12
  br label %cleanup

cleanup:                                          ; preds = %if.then21, %if.end17.cleanup_crit_edge, %if.then10.cleanup_crit_edge, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ %call, %entry.cleanup_crit_edge ], [ %call13, %if.then10.cleanup_crit_edge ], [ 0, %if.then21 ], [ 0, %if.end17.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_get_csb_size(ptr nocapture noundef readnone %adev) #7 align 64 {
for.body5.preheader:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  ret i32 912
}

; Function Attrs: nofree nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_get_csb_buffer(ptr nocapture noundef readonly %adev, ptr noundef %buffer) #8 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %cs_data = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 8
  %0 = ptrtoint ptr %cs_data to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %cs_data, align 4
  %cmp = icmp eq ptr %1, null
  %cmp1 = icmp eq ptr %buffer, null
  %or.cond = or i1 %cmp1, %cmp
  br i1 %or.cond, label %entry.cleanup_crit_edge, label %if.end3

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end3:                                          ; preds = %entry
  %2 = ptrtoint ptr %buffer to i32
  call void @__asan_store4_noabort(i32 %2)
  store volatile i32 4849856, ptr %buffer, align 4
  %arrayidx5 = getelementptr i32, ptr %buffer, i32 1
  %3 = ptrtoint ptr %arrayidx5 to i32
  call void @__asan_store4_noabort(i32 %3)
  store volatile i32 32, ptr %arrayidx5, align 4
  %arrayidx7 = getelementptr i32, ptr %buffer, i32 2
  %4 = ptrtoint ptr %arrayidx7 to i32
  call void @__asan_store4_noabort(i32 %4)
  store volatile i32 2621888, ptr %arrayidx7, align 4
  %arrayidx9 = getelementptr i32, ptr %buffer, i32 3
  %5 = ptrtoint ptr %arrayidx9 to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile i32 128, ptr %arrayidx9, align 4
  %arrayidx11 = getelementptr i32, ptr %buffer, i32 4
  %6 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_store4_noabort(i32 %6)
  store volatile i32 128, ptr %arrayidx11, align 4
  %7 = ptrtoint ptr %cs_data to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %cs_data, align 4
  %9 = ptrtoint ptr %8 to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %8, align 4
  %cmp15.not122 = icmp eq ptr %10, null
  br i1 %cmp15.not122, label %if.end3.for.end40_crit_edge, label %if.end3.for.cond17.preheader_crit_edge

if.end3.for.cond17.preheader_crit_edge:           ; preds = %if.end3
  br label %for.cond17.preheader

if.end3.for.end40_crit_edge:                      ; preds = %if.end3
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end40

for.cond17.preheader:                             ; preds = %for.inc38.for.cond17.preheader_crit_edge, %if.end3.for.cond17.preheader_crit_edge
  %11 = phi ptr [ %37, %for.inc38.for.cond17.preheader_crit_edge ], [ %10, %if.end3.for.cond17.preheader_crit_edge ]
  %sect.0124 = phi ptr [ %incdec.ptr39, %for.inc38.for.cond17.preheader_crit_edge ], [ %8, %if.end3.for.cond17.preheader_crit_edge ]
  %count.0123 = phi i32 [ %count.1.lcssa, %for.inc38.for.cond17.preheader_crit_edge ], [ 5, %if.end3.for.cond17.preheader_crit_edge ]
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %11, align 4
  %cmp18.not117 = icmp eq ptr %13, null
  br i1 %cmp18.not117, label %for.cond17.preheader.for.inc38_crit_edge, label %for.body19.lr.ph

for.cond17.preheader.for.inc38_crit_edge:         ; preds = %for.cond17.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc38

for.body19.lr.ph:                                 ; preds = %for.cond17.preheader
  %id = getelementptr inbounds %struct.cs_section_def, ptr %sect.0124, i32 0, i32 1
  br label %for.body19

for.body19:                                       ; preds = %for.inc36.for.body19_crit_edge, %for.body19.lr.ph
  %ext.0119 = phi ptr [ %11, %for.body19.lr.ph ], [ %incdec.ptr, %for.inc36.for.body19_crit_edge ]
  %count.1118 = phi i32 [ %count.0123, %for.body19.lr.ph ], [ %count.2.lcssa, %for.inc36.for.body19_crit_edge ]
  %14 = ptrtoint ptr %id to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %id, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %15)
  %cmp20 = icmp eq i32 %15, 1
  br i1 %cmp20, label %if.then21, label %for.body19.cleanup_crit_edge

for.body19.cleanup_crit_edge:                     ; preds = %for.body19
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then21:                                        ; preds = %for.body19
  %reg_count = getelementptr inbounds %struct.cs_extent_def, ptr %ext.0119, i32 0, i32 2
  %16 = ptrtoint ptr %reg_count to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %reg_count, align 4
  %and = shl i32 %17, 16
  %or = or i32 %and, -1073714944
  %18 = tail call i32 @llvm.bswap.i32(i32 %or)
  %inc22 = add i32 %count.1118, 1
  %arrayidx23 = getelementptr i32, ptr %buffer, i32 %count.1118
  %19 = ptrtoint ptr %arrayidx23 to i32
  call void @__asan_store4_noabort(i32 %19)
  store volatile i32 %18, ptr %arrayidx23, align 4
  %reg_index = getelementptr inbounds %struct.cs_extent_def, ptr %ext.0119, i32 0, i32 1
  %20 = ptrtoint ptr %reg_index to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %reg_index, align 4
  %sub = add i32 %21, -40960
  %22 = tail call i32 @llvm.bswap.i32(i32 %sub)
  %inc24 = add i32 %count.1118, 2
  %arrayidx25 = getelementptr i32, ptr %buffer, i32 %inc22
  %23 = ptrtoint ptr %arrayidx25 to i32
  call void @__asan_store4_noabort(i32 %23)
  store volatile i32 %22, ptr %arrayidx25, align 4
  %24 = ptrtoint ptr %reg_count to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %reg_count, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %25)
  %cmp28114.not = icmp eq i32 %25, 0
  br i1 %cmp28114.not, label %if.then21.for.inc36_crit_edge, label %if.then21.for.body29_crit_edge

if.then21.for.body29_crit_edge:                   ; preds = %if.then21
  br label %for.body29

if.then21.for.inc36_crit_edge:                    ; preds = %if.then21
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc36

for.body29:                                       ; preds = %for.body29.for.body29_crit_edge, %if.then21.for.body29_crit_edge
  %i.0116 = phi i32 [ %inc34, %for.body29.for.body29_crit_edge ], [ 0, %if.then21.for.body29_crit_edge ]
  %count.2115 = phi i32 [ %inc32, %for.body29.for.body29_crit_edge ], [ %inc24, %if.then21.for.body29_crit_edge ]
  %26 = ptrtoint ptr %ext.0119 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %ext.0119, align 4
  %arrayidx31 = getelementptr i32, ptr %27, i32 %i.0116
  %28 = ptrtoint ptr %arrayidx31 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx31, align 4
  %30 = tail call i32 @llvm.bswap.i32(i32 %29)
  %inc32 = add i32 %count.2115, 1
  %arrayidx33 = getelementptr i32, ptr %buffer, i32 %count.2115
  %31 = ptrtoint ptr %arrayidx33 to i32
  call void @__asan_store4_noabort(i32 %31)
  store volatile i32 %30, ptr %arrayidx33, align 4
  %inc34 = add nuw i32 %i.0116, 1
  %32 = ptrtoint ptr %reg_count to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %reg_count, align 4
  %cmp28 = icmp ult i32 %inc34, %33
  br i1 %cmp28, label %for.body29.for.body29_crit_edge, label %for.body29.for.inc36_crit_edge

for.body29.for.inc36_crit_edge:                   ; preds = %for.body29
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc36

for.body29.for.body29_crit_edge:                  ; preds = %for.body29
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body29

for.inc36:                                        ; preds = %for.body29.for.inc36_crit_edge, %if.then21.for.inc36_crit_edge
  %count.2.lcssa = phi i32 [ %inc24, %if.then21.for.inc36_crit_edge ], [ %inc32, %for.body29.for.inc36_crit_edge ]
  %incdec.ptr = getelementptr %struct.cs_extent_def, ptr %ext.0119, i32 1
  %34 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %incdec.ptr, align 4
  %cmp18.not = icmp eq ptr %35, null
  br i1 %cmp18.not, label %for.inc36.for.inc38_crit_edge, label %for.inc36.for.body19_crit_edge

for.inc36.for.body19_crit_edge:                   ; preds = %for.inc36
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body19

for.inc36.for.inc38_crit_edge:                    ; preds = %for.inc36
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc38

for.inc38:                                        ; preds = %for.inc36.for.inc38_crit_edge, %for.cond17.preheader.for.inc38_crit_edge
  %count.1.lcssa = phi i32 [ %count.0123, %for.cond17.preheader.for.inc38_crit_edge ], [ %count.2.lcssa, %for.inc36.for.inc38_crit_edge ]
  %incdec.ptr39 = getelementptr %struct.cs_section_def, ptr %sect.0124, i32 1
  %36 = ptrtoint ptr %incdec.ptr39 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %incdec.ptr39, align 4
  %cmp15.not = icmp eq ptr %37, null
  br i1 %cmp15.not, label %for.inc38.for.end40_crit_edge, label %for.inc38.for.cond17.preheader_crit_edge

for.inc38.for.cond17.preheader_crit_edge:         ; preds = %for.inc38
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond17.preheader

for.inc38.for.end40_crit_edge:                    ; preds = %for.inc38
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end40

for.end40:                                        ; preds = %for.inc38.for.end40_crit_edge, %if.end3.for.end40_crit_edge
  %count.0.lcssa = phi i32 [ 5, %if.end3.for.end40_crit_edge ], [ %count.1.lcssa, %for.inc38.for.end40_crit_edge ]
  %inc41 = add i32 %count.0.lcssa, 1
  %arrayidx42 = getelementptr i32, ptr %buffer, i32 %count.0.lcssa
  %38 = ptrtoint ptr %arrayidx42 to i32
  call void @__asan_store4_noabort(i32 %38)
  store volatile i32 6881984, ptr %arrayidx42, align 4
  %inc43 = add i32 %count.0.lcssa, 2
  %arrayidx44 = getelementptr i32, ptr %buffer, i32 %inc41
  %39 = ptrtoint ptr %arrayidx44 to i32
  call void @__asan_store4_noabort(i32 %39)
  store volatile i32 -738197504, ptr %arrayidx44, align 4
  %raster_config = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 30, i32 0, i32 0, i32 2
  %40 = ptrtoint ptr %raster_config to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %raster_config, align 4
  %42 = tail call i32 @llvm.bswap.i32(i32 %41)
  %inc48 = add i32 %count.0.lcssa, 3
  %arrayidx49 = getelementptr i32, ptr %buffer, i32 %inc43
  %43 = ptrtoint ptr %arrayidx49 to i32
  call void @__asan_store4_noabort(i32 %43)
  store volatile i32 %42, ptr %arrayidx49, align 4
  %raster_config_1 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 30, i32 0, i32 0, i32 3
  %44 = ptrtoint ptr %raster_config_1 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %raster_config_1, align 4
  %46 = tail call i32 @llvm.bswap.i32(i32 %45)
  %inc55 = add i32 %count.0.lcssa, 4
  %arrayidx56 = getelementptr i32, ptr %buffer, i32 %inc48
  %47 = ptrtoint ptr %arrayidx56 to i32
  call void @__asan_store4_noabort(i32 %47)
  store volatile i32 %46, ptr %arrayidx56, align 4
  %inc57 = add i32 %count.0.lcssa, 5
  %arrayidx58 = getelementptr i32, ptr %buffer, i32 %inc55
  %48 = ptrtoint ptr %arrayidx58 to i32
  call void @__asan_store4_noabort(i32 %48)
  store volatile i32 4849856, ptr %arrayidx58, align 4
  %inc59 = add i32 %count.0.lcssa, 6
  %arrayidx60 = getelementptr i32, ptr %buffer, i32 %inc57
  %49 = ptrtoint ptr %arrayidx60 to i32
  call void @__asan_store4_noabort(i32 %49)
  store volatile i32 48, ptr %arrayidx60, align 4
  %inc61 = add i32 %count.0.lcssa, 7
  %arrayidx62 = getelementptr i32, ptr %buffer, i32 %inc59
  %50 = ptrtoint ptr %arrayidx62 to i32
  call void @__asan_store4_noabort(i32 %50)
  store volatile i32 1179840, ptr %arrayidx62, align 4
  %arrayidx64 = getelementptr i32, ptr %buffer, i32 %inc61
  %51 = ptrtoint ptr %arrayidx64 to i32
  call void @__asan_store4_noabort(i32 %51)
  store volatile i32 0, ptr %arrayidx64, align 4
  br label %cleanup

cleanup:                                          ; preds = %for.end40, %for.body19.cleanup_crit_edge, %entry.cleanup_crit_edge
  ret void
}

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define internal i32 @gfx_v8_0_cp_jump_table_num(ptr nocapture noundef readonly %adev) #9 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %0 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %asic_type, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 13, i32 %1)
  %cmp = icmp eq i32 %1, 13
  %. = select i1 %cmp, i32 5, i32 4
  ret i32 %.
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @gfx_v8_0_rlc_resume(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %virt = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 132
  %0 = ptrtoint ptr %virt to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %virt, align 8
  %and = and i32 %1, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  %funcs = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 15
  %2 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %funcs, align 4
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %get_csb_buffer.i = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %3, i32 0, i32 5
  %4 = ptrtoint ptr %get_csb_buffer.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %get_csb_buffer.i, align 4
  %cs_ptr.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 7
  %6 = ptrtoint ptr %cs_ptr.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %cs_ptr.i, align 8
  tail call void %5(ptr noundef %adev, ptr noundef %7) #12
  %clear_state_gpu_addr.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 6
  %8 = ptrtoint ptr %clear_state_gpu_addr.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %clear_state_gpu_addr.i, align 8
  %shr.i = lshr i64 %9, 32
  %conv.i = trunc i64 %shr.i to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60579, i32 noundef %conv.i, i32 noundef 0) #12
  %10 = ptrtoint ptr %clear_state_gpu_addr.i to i32
  call void @__asan_load8_noabort(i32 %10)
  %11 = load i64, ptr %clear_state_gpu_addr.i, align 8
  %12 = trunc i64 %11 to i32
  %conv8.i = and i32 %12, -4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60578, i32 noundef %conv8.i, i32 noundef 0) #12
  %clear_state_size.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 9
  %13 = ptrtoint ptr %clear_state_size.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %clear_state_size.i, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60580, i32 noundef %14, i32 noundef 0) #12
  br label %return

if.end:                                           ; preds = %entry
  %stop = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %3, i32 0, i32 8
  %15 = ptrtoint ptr %stop to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %stop, align 4
  tail call void %16(ptr noundef %adev) #12
  %17 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %funcs, align 4
  %reset = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %18, i32 0, i32 9
  %19 = ptrtoint ptr %reset to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %reset, align 4
  tail call void %20(ptr noundef %adev) #12
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %21 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %asic_type.i, align 8
  %23 = zext i32 %22 to i64
  call void @__sanitizer_cov_trace_switch(i64 %23, ptr @__sancov_gen_cov_switch_values.122)
  switch i32 %22, label %if.end.gfx_v8_0_init_pg.exit_crit_edge [
    i32 13, label %if.end.if.then.i_crit_edge
    i32 14, label %if.end.if.then.i_crit_edge17
    i32 16, label %if.end.if.then15.i_crit_edge
    i32 17, label %if.end.if.then15.i_crit_edge18
    i32 18, label %if.end.if.then15.i_crit_edge19
  ]

if.end.if.then15.i_crit_edge19:                   ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then15.i

if.end.if.then15.i_crit_edge18:                   ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then15.i

if.end.if.then15.i_crit_edge:                     ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then15.i

if.end.if.then.i_crit_edge17:                     ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i

if.end.if.then.i_crit_edge:                       ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then.i

if.end.gfx_v8_0_init_pg.exit_crit_edge:           ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_init_pg.exit

if.then.i:                                        ; preds = %if.end.if.then.i_crit_edge, %if.end.if.then.i_crit_edge17
  %24 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %funcs, align 4
  %get_csb_buffer.i.i = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %25, i32 0, i32 5
  %26 = ptrtoint ptr %get_csb_buffer.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %get_csb_buffer.i.i, align 4
  %cs_ptr.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 7
  %28 = ptrtoint ptr %cs_ptr.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %cs_ptr.i.i, align 8
  tail call void %27(ptr noundef %adev, ptr noundef %29) #12
  %clear_state_gpu_addr.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 6
  %30 = ptrtoint ptr %clear_state_gpu_addr.i.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %clear_state_gpu_addr.i.i, align 8
  %shr.i.i = lshr i64 %31, 32
  %conv.i.i = trunc i64 %shr.i.i to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60579, i32 noundef %conv.i.i, i32 noundef 0) #12
  %32 = ptrtoint ptr %clear_state_gpu_addr.i.i to i32
  call void @__asan_load8_noabort(i32 %32)
  %33 = load i64, ptr %clear_state_gpu_addr.i.i, align 8
  %34 = trunc i64 %33 to i32
  %conv8.i.i = and i32 %34, -4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60578, i32 noundef %conv8.i.i, i32 noundef 0) #12
  %clear_state_size.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 9
  %35 = ptrtoint ptr %clear_state_size.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %clear_state_size.i.i, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60580, i32 noundef %36, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_init_save_restore_list(ptr noundef %adev) #12
  %call.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60544, i32 noundef 0) #12
  %or.i.i = or i32 %call.i.i, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60544, i32 noundef %or.i.i, i32 noundef 0) #12
  %cp_table_gpu_addr.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 11
  %37 = ptrtoint ptr %cp_table_gpu_addr.i to i32
  call void @__asan_load8_noabort(i32 %37)
  %38 = load i64, ptr %cp_table_gpu_addr.i, align 8
  %shr.i15 = lshr i64 %38, 8
  %conv.i16 = trunc i64 %shr.i15 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60446, i32 noundef %conv.i16, i32 noundef 0) #12
  %call.i34.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8642, i32 noundef 0) #12
  %and.i.i = and i32 %call.i34.i, 65535
  %or.i35.i = or i32 %and.i.i, 6291456
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8642, i32 noundef %or.i35.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60493, i32 noundef 269488144, i32 noundef 0) #12
  %call7.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60447, i32 noundef 0) #12
  %and8.i.i = and i32 %call7.i.i, -65281
  %or9.i.i = or i32 %and8.i.i, 768
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60447, i32 noundef %or9.i.i, i32 noundef 0) #12
  %call10.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60501, i32 noundef 0) #12
  %and11.i.i = and i32 %call10.i.i, -524281
  %or12.i.i = or i32 %and11.i.i, 176000
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60501, i32 noundef %or12.i.i, i32 noundef 0) #12
  %ao_cu_mask.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 48, i32 6
  %39 = ptrtoint ptr %ao_cu_mask.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %ao_cu_mask.i, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60499, i32 noundef %40, i32 noundef 0) #12
  br label %gfx_v8_0_init_pg.exit

if.then15.i:                                      ; preds = %if.end.if.then15.i_crit_edge, %if.end.if.then15.i_crit_edge18, %if.end.if.then15.i_crit_edge19
  %41 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %funcs, align 4
  %get_csb_buffer.i37.i = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %42, i32 0, i32 5
  %43 = ptrtoint ptr %get_csb_buffer.i37.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %get_csb_buffer.i37.i, align 4
  %cs_ptr.i38.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 7
  %45 = ptrtoint ptr %cs_ptr.i38.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %cs_ptr.i38.i, align 8
  tail call void %44(ptr noundef %adev, ptr noundef %46) #12
  %clear_state_gpu_addr.i39.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 6
  %47 = ptrtoint ptr %clear_state_gpu_addr.i39.i to i32
  call void @__asan_load8_noabort(i32 %47)
  %48 = load i64, ptr %clear_state_gpu_addr.i39.i, align 8
  %shr.i40.i = lshr i64 %48, 32
  %conv.i41.i = trunc i64 %shr.i40.i to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60579, i32 noundef %conv.i41.i, i32 noundef 0) #12
  %49 = ptrtoint ptr %clear_state_gpu_addr.i39.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %clear_state_gpu_addr.i39.i, align 8
  %51 = trunc i64 %50 to i32
  %conv8.i42.i = and i32 %51, -4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60578, i32 noundef %conv8.i42.i, i32 noundef 0) #12
  %clear_state_size.i43.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 9
  %52 = ptrtoint ptr %clear_state_size.i43.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %clear_state_size.i43.i, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60580, i32 noundef %53, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_init_save_restore_list(ptr noundef %adev) #12
  %call.i44.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60544, i32 noundef 0) #12
  %or.i45.i = or i32 %call.i44.i, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60544, i32 noundef %or.i45.i, i32 noundef 0) #12
  %call.i46.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8642, i32 noundef 0) #12
  %and.i47.i = and i32 %call.i46.i, 65535
  %or.i48.i = or i32 %and.i47.i, 6291456
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8642, i32 noundef %or.i48.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60493, i32 noundef 269488144, i32 noundef 0) #12
  %call7.i49.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60447, i32 noundef 0) #12
  %and8.i50.i = and i32 %call7.i49.i, -65281
  %or9.i51.i = or i32 %and8.i50.i, 768
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60447, i32 noundef %or9.i51.i, i32 noundef 0) #12
  %call10.i52.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60501, i32 noundef 0) #12
  %and11.i53.i = and i32 %call10.i52.i, -524281
  %or12.i54.i = or i32 %and11.i53.i, 176000
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60501, i32 noundef %or12.i54.i, i32 noundef 0) #12
  br label %gfx_v8_0_init_pg.exit

gfx_v8_0_init_pg.exit:                            ; preds = %if.then15.i, %if.then.i, %if.end.gfx_v8_0_init_pg.exit_crit_edge
  %54 = ptrtoint ptr %funcs to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %funcs, align 4
  %start = getelementptr inbounds %struct.amdgpu_rlc_funcs, ptr %55, i32 0, i32 10
  %56 = ptrtoint ptr %start to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %start, align 4
  tail call void %57(ptr noundef %adev) #12
  br label %return

return:                                           ; preds = %gfx_v8_0_init_pg.exit, %if.then
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_rlc_stop(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60416, i32 noundef 0) #12
  %and = and i32 %call, -2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60416, i32 noundef %and, i32 noundef 0) #12
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and.i = and i32 %call.i, -3932161
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %and.i, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_rlc_reset(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8200, i32 noundef 0) #12
  %or = or i32 %call, 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8200, i32 noundef %or, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %0 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %0(i32 noundef 10737400) #12
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8200, i32 noundef 0) #12
  %and2 = and i32 %call1, -5
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8200, i32 noundef %and2, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %1 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %1(i32 noundef 10737400) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_rlc_start(ptr noundef %adev) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60416, i32 noundef 0) #12
  %or = or i32 %call, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60416, i32 noundef %or, i32 noundef 0) #12
  %flags = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 9
  %0 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %flags, align 8
  %and1 = and i32 %1, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and1)
  %tobool.not = icmp eq i32 %and1, 0
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %or19.i = or i32 %call.i, 3932160
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or19.i, i32 noundef 0) #12
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %2 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %2(i32 noundef 10737400) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_update_spm_vmid(ptr noundef %adev, i32 noundef %vmid) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @amdgpu_gfx_off_ctrl(ptr noundef %adev, i1 noundef zeroext false) #12
  %gim_feature = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 132, i32 12
  %0 = ptrtoint ptr %gim_feature to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %gim_feature, align 4
  %and = lshr i32 %1, 3
  %2 = and i32 %and, 2
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60529, i32 noundef %2) #12
  %and2 = and i32 %call1, -16
  %and3 = and i32 %vmid, 15
  %or = or i32 %and2, %and3
  %3 = ptrtoint ptr %gim_feature to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %gim_feature, align 4
  %and6 = lshr i32 %4, 3
  %5 = and i32 %and6, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60529, i32 noundef %or, i32 noundef %5) #12
  tail call void @amdgpu_gfx_off_ctrl(ptr noundef %adev, i1 noundef zeroext true) #12
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_rlc_init_csb(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_rlc_init_cpt(ptr noundef) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.bswap.i32(i32) #10

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_init_save_restore_list(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  %unique_indices = alloca [8 x i32], align 4
  %indirect_start_offsets = alloca [10 x i32], align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @llvm.lifetime.start.p0(i64 32, ptr nonnull %unique_indices) #12
  %0 = call ptr @memset(ptr %unique_indices, i32 0, i32 32)
  call void @llvm.lifetime.start.p0(i64 40, ptr nonnull %indirect_start_offsets) #12
  %1 = call ptr @memset(ptr %indirect_start_offsets, i32 0, i32 40)
  %register_list_format1 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 31
  %2 = ptrtoint ptr %register_list_format1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %register_list_format1, align 4
  %reg_list_format_size_bytes = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 23
  %4 = ptrtoint ptr %reg_list_format_size_bytes to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %reg_list_format_size_bytes, align 4
  %call = tail call ptr @kmemdup(ptr noundef %3, i32 noundef %5, i32 noundef 3264) #12
  %tobool.not = icmp eq ptr %call, null
  br i1 %tobool.not, label %entry.cleanup_crit_edge, label %if.end

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end:                                           ; preds = %entry
  %6 = ptrtoint ptr %reg_list_format_size_bytes to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %reg_list_format_size_bytes, align 4
  %shr = lshr i32 %7, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 59, i32 %7)
  %cmp7.i = icmp ugt i32 %7, 59
  br i1 %cmp7.i, label %if.end.for.body.i_crit_edge, label %if.end.gfx_v8_0_parse_ind_reg_list.exit_crit_edge

if.end.gfx_v8_0_parse_ind_reg_list.exit_crit_edge: ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_parse_ind_reg_list.exit

if.end.for.body.i_crit_edge:                      ; preds = %if.end
  br label %for.body.i

for.body.i:                                       ; preds = %for.inc50.i.for.body.i_crit_edge, %if.end.for.body.i_crit_edge
  %indices_count.0 = phi i32 [ %indices_count.2, %for.inc50.i.for.body.i_crit_edge ], [ 0, %if.end.for.body.i_crit_edge ]
  %offset_count.0 = phi i32 [ %offset_count.1, %for.inc50.i.for.body.i_crit_edge ], [ 0, %if.end.for.body.i_crit_edge ]
  %new_entry.0.off09.i = phi i1 [ %cmp13.i, %for.inc50.i.for.body.i_crit_edge ], [ true, %if.end.for.body.i_crit_edge ]
  %ind_offset.addr.08.i = phi i32 [ %inc51.i, %for.inc50.i.for.body.i_crit_edge ], [ 14, %if.end.for.body.i_crit_edge ]
  br i1 %new_entry.0.off09.i, label %if.then.i, label %for.body.i.if.end11.i_crit_edge

for.body.i.if.end11.i_crit_edge:                  ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11.i

if.then.i:                                        ; preds = %for.body.i
  %arrayidx.i = getelementptr i32, ptr %indirect_start_offsets, i32 %offset_count.0
  %8 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 %ind_offset.addr.08.i, ptr %arrayidx.i, align 4
  %add.i = add i32 %offset_count.0, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 9, i32 %add.i)
  %cmp1.i = icmp sgt i32 %add.i, 9
  br i1 %cmp1.i, label %do.body5.i, label %if.then.i.if.end11.i_crit_edge, !prof !442

if.then.i.if.end11.i_crit_edge:                   ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11.i

do.body5.i:                                       ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 3938, 0\0A.popsection", ""() #12, !srcloc !447
  unreachable

if.end11.i:                                       ; preds = %if.then.i.if.end11.i_crit_edge, %for.body.i.if.end11.i_crit_edge
  %offset_count.1 = phi i32 [ %add.i, %if.then.i.if.end11.i_crit_edge ], [ %offset_count.0, %for.body.i.if.end11.i_crit_edge ]
  %arrayidx12.i = getelementptr i32, ptr %call, i32 %ind_offset.addr.08.i
  %9 = ptrtoint ptr %arrayidx12.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx12.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 -1, i32 %10)
  %cmp13.i = icmp eq i32 %10, -1
  br i1 %cmp13.i, label %if.end11.i.for.inc50.i_crit_edge, label %if.end15.i

if.end11.i.for.inc50.i_crit_edge:                 ; preds = %if.end11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc50.i

if.end15.i:                                       ; preds = %if.end11.i
  %add16.i = add i32 %ind_offset.addr.08.i, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %indices_count.0)
  %cmp185.i = icmp sgt i32 %indices_count.0, 0
  %arrayidx21.i = getelementptr i32, ptr %call, i32 %add16.i
  %11 = ptrtoint ptr %arrayidx21.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %arrayidx21.i, align 4
  br i1 %cmp185.i, label %if.end15.i.for.body19.i_crit_edge, label %if.then26.i.thread

if.end15.i.for.body19.i_crit_edge:                ; preds = %if.end15.i
  br label %for.body19.i

if.then26.i.thread:                               ; preds = %if.end15.i
  call void @__sanitizer_cov_trace_pc() #14
  %arrayidx28.i4 = getelementptr i32, ptr %unique_indices, i32 %indices_count.0
  %13 = ptrtoint ptr %arrayidx28.i4 to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 %12, ptr %arrayidx28.i4, align 4
  %add29.i5 = add nsw i32 %indices_count.0, 1
  br label %if.end48.i

for.body19.i:                                     ; preds = %for.inc.i.for.body19.i_crit_edge, %if.end15.i.for.body19.i_crit_edge
  %indices.06.i = phi i32 [ %inc.i, %for.inc.i.for.body19.i_crit_edge ], [ 0, %if.end15.i.for.body19.i_crit_edge ]
  %arrayidx20.i = getelementptr i32, ptr %unique_indices, i32 %indices.06.i
  %14 = ptrtoint ptr %arrayidx20.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx20.i, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %15, i32 %12)
  %cmp22.i = icmp eq i32 %15, %12
  br i1 %cmp22.i, label %for.body19.i.if.end48.i_crit_edge, label %for.inc.i

for.body19.i.if.end48.i_crit_edge:                ; preds = %for.body19.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end48.i

for.inc.i:                                        ; preds = %for.body19.i
  %inc.i = add nuw nsw i32 %indices.06.i, 1
  %exitcond.not.i = icmp eq i32 %inc.i, %indices_count.0
  br i1 %exitcond.not.i, label %if.then26.i, label %for.inc.i.for.body19.i_crit_edge

for.inc.i.for.body19.i_crit_edge:                 ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body19.i

if.then26.i:                                      ; preds = %for.inc.i
  %16 = ptrtoint ptr %arrayidx21.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %arrayidx21.i, align 4
  %arrayidx28.i = getelementptr i32, ptr %unique_indices, i32 %indices_count.0
  %18 = ptrtoint ptr %arrayidx28.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %17, ptr %arrayidx28.i, align 4
  %add29.i = add i32 %indices_count.0, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %add29.i)
  %cmp31.i = icmp sgt i32 %add29.i, 7
  br i1 %cmp31.i, label %do.body39.i, label %if.then26.i.if.end48.i_crit_edge, !prof !442

if.then26.i.if.end48.i_crit_edge:                 ; preds = %if.then26.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end48.i

do.body39.i:                                      ; preds = %if.then26.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 3962, 0\0A.popsection", ""() #12, !srcloc !448
  unreachable

if.end48.i:                                       ; preds = %if.then26.i.if.end48.i_crit_edge, %for.body19.i.if.end48.i_crit_edge, %if.then26.i.thread
  %indices_count.1 = phi i32 [ %add29.i, %if.then26.i.if.end48.i_crit_edge ], [ %add29.i5, %if.then26.i.thread ], [ %indices_count.0, %for.body19.i.if.end48.i_crit_edge ]
  %indices.1.i = phi i32 [ %indices_count.0, %if.then26.i.if.end48.i_crit_edge ], [ %indices_count.0, %if.then26.i.thread ], [ %indices.06.i, %for.body19.i.if.end48.i_crit_edge ]
  %arrayidx49.i = getelementptr i32, ptr %call, i32 %add16.i
  %19 = ptrtoint ptr %arrayidx49.i to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %indices.1.i, ptr %arrayidx49.i, align 4
  br label %for.inc50.i

for.inc50.i:                                      ; preds = %if.end48.i, %if.end11.i.for.inc50.i_crit_edge
  %indices_count.2 = phi i32 [ %indices_count.0, %if.end11.i.for.inc50.i_crit_edge ], [ %indices_count.1, %if.end48.i ]
  %ind_offset.addr.1.i = phi i32 [ %ind_offset.addr.08.i, %if.end11.i.for.inc50.i_crit_edge ], [ %add16.i, %if.end48.i ]
  %inc51.i = add i32 %ind_offset.addr.1.i, 1
  %cmp.i = icmp slt i32 %inc51.i, %shr
  br i1 %cmp.i, label %for.inc50.i.for.body.i_crit_edge, label %for.inc50.i.gfx_v8_0_parse_ind_reg_list.exit_crit_edge

for.inc50.i.gfx_v8_0_parse_ind_reg_list.exit_crit_edge: ; preds = %for.inc50.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_parse_ind_reg_list.exit

for.inc50.i.for.body.i_crit_edge:                 ; preds = %for.inc50.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

gfx_v8_0_parse_ind_reg_list.exit:                 ; preds = %for.inc50.i.gfx_v8_0_parse_ind_reg_list.exit_crit_edge, %if.end.gfx_v8_0_parse_ind_reg_list.exit_crit_edge
  %call8 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60544, i32 noundef 0) #12
  %or = or i32 %call8, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60544, i32 noundef %or, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60547, i32 noundef 0, i32 noundef 0) #12
  %reg_list_size_bytes = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 24
  %20 = ptrtoint ptr %reg_list_size_bytes to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %reg_list_size_bytes, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %21)
  %cmp9.not = icmp ult i32 %21, 4
  br i1 %cmp9.not, label %gfx_v8_0_parse_ind_reg_list.exit.for.end_crit_edge, label %for.body.lr.ph

gfx_v8_0_parse_ind_reg_list.exit.for.end_crit_edge: ; preds = %gfx_v8_0_parse_ind_reg_list.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.lr.ph:                                   ; preds = %gfx_v8_0_parse_ind_reg_list.exit
  %register_restore = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 32
  br label %for.body

for.body:                                         ; preds = %for.body.for.body_crit_edge, %for.body.lr.ph
  %i.010 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body.for.body_crit_edge ]
  %22 = ptrtoint ptr %register_restore to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %register_restore, align 8
  %arrayidx = getelementptr i32, ptr %23, i32 %i.010
  %24 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %arrayidx, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60548, i32 noundef %25, i32 noundef 0) #12
  %inc = add nuw nsw i32 %i.010, 1
  %26 = ptrtoint ptr %reg_list_size_bytes to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %reg_list_size_bytes, align 8
  %shr11 = lshr i32 %27, 2
  %cmp = icmp ult i32 %inc, %shr11
  br i1 %cmp, label %for.body.for.body_crit_edge, label %for.body.for.end_crit_edge

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.body.for.end_crit_edge, %gfx_v8_0_parse_ind_reg_list.exit.for.end_crit_edge
  %reg_list_format_start = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 20
  %28 = ptrtoint ptr %reg_list_format_start to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %reg_list_format_start, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60524, i32 noundef %29, i32 noundef 0) #12
  %30 = ptrtoint ptr %reg_list_format_size_bytes to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %reg_list_format_size_bytes, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %31)
  %cmp2112.not = icmp ult i32 %31, 4
  br i1 %cmp2112.not, label %for.end.for.end26_crit_edge, label %for.end.for.body22_crit_edge

for.end.for.body22_crit_edge:                     ; preds = %for.end
  br label %for.body22

for.end.for.end26_crit_edge:                      ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end26

for.body22:                                       ; preds = %for.body22.for.body22_crit_edge, %for.end.for.body22_crit_edge
  %i.113 = phi i32 [ %inc25, %for.body22.for.body22_crit_edge ], [ 0, %for.end.for.body22_crit_edge ]
  %arrayidx23 = getelementptr i32, ptr %call, i32 %i.113
  %32 = ptrtoint ptr %arrayidx23 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %arrayidx23, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %33, i32 noundef 0) #12
  %inc25 = add nuw nsw i32 %i.113, 1
  %34 = ptrtoint ptr %reg_list_format_size_bytes to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %reg_list_format_size_bytes, align 4
  %shr20 = lshr i32 %35, 2
  %cmp21 = icmp ult i32 %inc25, %shr20
  br i1 %cmp21, label %for.body22.for.body22_crit_edge, label %for.body22.for.end26_crit_edge

for.body22.for.end26_crit_edge:                   ; preds = %for.body22
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end26

for.body22.for.body22_crit_edge:                  ; preds = %for.body22
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body22

for.end26:                                        ; preds = %for.body22.for.end26_crit_edge, %for.end.for.end26_crit_edge
  %36 = ptrtoint ptr %reg_list_size_bytes to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %reg_list_size_bytes, align 8
  %shr30 = lshr i32 %37, 3
  %reg_restore_list_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 19
  %38 = ptrtoint ptr %reg_restore_list_size to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %reg_restore_list_size, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60524, i32 noundef %39, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %shr30, i32 noundef 0) #12
  %starting_offsets_start = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 22
  %40 = ptrtoint ptr %starting_offsets_start to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %starting_offsets_start, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60524, i32 noundef %41, i32 noundef 0) #12
  %42 = ptrtoint ptr %indirect_start_offsets to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %indirect_start_offsets, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %43, i32 noundef 0) #12
  %arrayidx39.1 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 1
  %44 = ptrtoint ptr %arrayidx39.1 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %arrayidx39.1, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %45, i32 noundef 0) #12
  %arrayidx39.2 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 2
  %46 = ptrtoint ptr %arrayidx39.2 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %arrayidx39.2, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %47, i32 noundef 0) #12
  %arrayidx39.3 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 3
  %48 = ptrtoint ptr %arrayidx39.3 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx39.3, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %49, i32 noundef 0) #12
  %arrayidx39.4 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 4
  %50 = ptrtoint ptr %arrayidx39.4 to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %arrayidx39.4, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %51, i32 noundef 0) #12
  %arrayidx39.5 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 5
  %52 = ptrtoint ptr %arrayidx39.5 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %arrayidx39.5, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %53, i32 noundef 0) #12
  %arrayidx39.6 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 6
  %54 = ptrtoint ptr %arrayidx39.6 to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %arrayidx39.6, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %55, i32 noundef 0) #12
  %arrayidx39.7 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 7
  %56 = ptrtoint ptr %arrayidx39.7 to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %arrayidx39.7, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %57, i32 noundef 0) #12
  %arrayidx39.8 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 8
  %58 = ptrtoint ptr %arrayidx39.8 to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %arrayidx39.8, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %59, i32 noundef 0) #12
  %arrayidx39.9 = getelementptr inbounds [10 x i32], ptr %indirect_start_offsets, i32 0, i32 9
  %60 = ptrtoint ptr %arrayidx39.9 to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %arrayidx39.9, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60525, i32 noundef %61, i32 noundef 0) #12
  br label %for.body45

for.body45:                                       ; preds = %for.inc55.for.body45_crit_edge, %for.end26
  %i.315 = phi i32 [ %inc56, %for.inc55.for.body45_crit_edge ], [ 0, %for.end26 ]
  %arrayidx46 = getelementptr [8 x i32], ptr %unique_indices, i32 0, i32 %i.315
  %62 = ptrtoint ptr %arrayidx46 to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %arrayidx46, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %63)
  %cmp47.not = icmp eq i32 %63, 0
  br i1 %cmp47.not, label %for.body45.for.inc55_crit_edge, label %if.then48

for.body45.for.inc55_crit_edge:                   ; preds = %for.body45
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc55

if.then48:                                        ; preds = %for.body45
  call void @__sanitizer_cov_trace_pc() #14
  %add = add nuw nsw i32 %i.315, 60555
  %and50 = and i32 %63, 262143
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef %add, i32 noundef %and50, i32 noundef 0) #12
  %add51 = add nuw nsw i32 %i.315, 60563
  %shr53 = ashr i32 %63, 20
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef %add51, i32 noundef %shr53, i32 noundef 0) #12
  br label %for.inc55

for.inc55:                                        ; preds = %if.then48, %for.body45.for.inc55_crit_edge
  %inc56 = add nuw nsw i32 %i.315, 1
  %exitcond.not = icmp eq i32 %inc56, 8
  br i1 %exitcond.not, label %for.end57, label %for.inc55.for.body45_crit_edge

for.inc55.for.body45_crit_edge:                   ; preds = %for.inc55
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body45

for.end57:                                        ; preds = %for.inc55
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @kfree(ptr noundef nonnull %call) #12
  br label %cleanup

cleanup:                                          ; preds = %for.end57, %entry.cleanup_crit_edge
  call void @llvm.lifetime.end.p0(i64 40, ptr nonnull %indirect_start_offsets) #12
  call void @llvm.lifetime.end.p0(i64 32, ptr nonnull %unique_indices) #12
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @kmemdup(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @kfree(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %grbm_idx_mutex = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 21
  tail call void @mutex_lock_nested(ptr noundef %grbm_idx_mutex, i32 noundef 0) #12
  %config = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %0 = ptrtoint ptr %config to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %config, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp66.not = icmp eq i32 %1, 0
  br i1 %cmp66.not, label %entry.for.end21_crit_edge, label %for.cond1.preheader.lr.ph

entry.for.end21_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end21

for.cond1.preheader.lr.ph:                        ; preds = %entry
  %max_sh_per_se = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 11
  br label %for.cond1.preheader

for.cond1.preheader:                              ; preds = %for.inc19.for.cond1.preheader_crit_edge, %for.cond1.preheader.lr.ph
  %i.067 = phi i32 [ 0, %for.cond1.preheader.lr.ph ], [ %inc20, %for.inc19.for.cond1.preheader_crit_edge ]
  %2 = ptrtoint ptr %max_sh_per_se to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %max_sh_per_se, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %cmp464.not = icmp eq i32 %3, 0
  br i1 %cmp464.not, label %for.cond1.preheader.for.inc19_crit_edge, label %for.body5.lr.ph

for.cond1.preheader.for.inc19_crit_edge:          ; preds = %for.cond1.preheader
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc19

for.body5.lr.ph:                                  ; preds = %for.cond1.preheader
  %shl7.i = shl i32 %i.067, 16
  %and8.i = and i32 %shl7.i, 16711680
  %and8.i.op = or i32 %and8.i, 1073741824
  br label %for.body5

for.body5:                                        ; preds = %for.inc16.for.body5_crit_edge, %for.body5.lr.ph
  %j.065 = phi i32 [ 0, %for.body5.lr.ph ], [ %inc17, %for.inc16.for.body5_crit_edge ]
  %shl17.i = shl i32 %j.065, 8
  %and18.i = and i32 %shl17.i, 65280
  %data.2.i = or i32 %and18.i, %and8.i.op
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef %data.2.i, i32 noundef 0) #12
  %4 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %5)
  %cmp761.not = icmp eq i32 %5, 0
  br i1 %cmp761.not, label %for.body5.for.end_crit_edge, label %for.body5.for.body8_crit_edge

for.body5.for.body8_crit_edge:                    ; preds = %for.body5
  br label %for.body8

for.body5.for.end_crit_edge:                      ; preds = %for.body5
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body8:                                        ; preds = %if.end.for.body8_crit_edge, %for.body5.for.body8_crit_edge
  %k.062 = phi i32 [ %inc, %if.end.for.body8_crit_edge ], [ 0, %for.body5.for.body8_crit_edge ]
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60513, i32 noundef 0) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %cmp9 = icmp eq i32 %call, 0
  br i1 %cmp9, label %for.body8.for.end_crit_edge, label %if.end

for.body8.for.end_crit_edge:                      ; preds = %for.body8
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end:                                           ; preds = %for.body8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %6 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %6(i32 noundef 214748) #12
  %inc = add nuw i32 %k.062, 1
  %7 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %usec_timeout, align 8
  %cmp7 = icmp ult i32 %inc, %8
  br i1 %cmp7, label %if.end.for.body8_crit_edge, label %if.end.for.end_crit_edge

if.end.for.end_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

if.end.for.body8_crit_edge:                       ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body8

for.end:                                          ; preds = %if.end.for.end_crit_edge, %for.body8.for.end_crit_edge, %for.body5.for.end_crit_edge
  %k.0.lcssa = phi i32 [ 0, %for.body5.for.end_crit_edge ], [ %k.062, %for.body8.for.end_crit_edge ], [ %inc, %if.end.for.end_crit_edge ]
  %9 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_cmp4(i32 %k.0.lcssa, i32 %10)
  %cmp11 = icmp eq i32 %k.0.lcssa, %10
  br i1 %cmp11, label %if.then12, label %for.inc16

if.then12:                                        ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %grbm_idx_mutex) #12
  %call14 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.29, i32 noundef %i.067, i32 noundef %j.065) #15
  br label %cleanup

for.inc16:                                        ; preds = %for.end
  %inc17 = add nuw i32 %j.065, 1
  %11 = ptrtoint ptr %max_sh_per_se to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %max_sh_per_se, align 4
  %cmp4 = icmp ult i32 %inc17, %12
  br i1 %cmp4, label %for.inc16.for.body5_crit_edge, label %for.inc16.for.inc19_crit_edge

for.inc16.for.inc19_crit_edge:                    ; preds = %for.inc16
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc19

for.inc16.for.body5_crit_edge:                    ; preds = %for.inc16
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body5

for.inc19:                                        ; preds = %for.inc16.for.inc19_crit_edge, %for.cond1.preheader.for.inc19_crit_edge
  %inc20 = add nuw i32 %i.067, 1
  %13 = ptrtoint ptr %config to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %config, align 8
  %cmp = icmp ult i32 %inc20, %14
  br i1 %cmp, label %for.inc19.for.cond1.preheader_crit_edge, label %for.inc19.for.end21_crit_edge

for.inc19.for.end21_crit_edge:                    ; preds = %for.inc19
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end21

for.inc19.for.cond1.preheader_crit_edge:          ; preds = %for.inc19
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.cond1.preheader

for.end21:                                        ; preds = %for.inc19.for.end21_crit_edge, %entry.for.end21_crit_edge
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %grbm_idx_mutex) #12
  %usec_timeout24 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 11
  %15 = ptrtoint ptr %usec_timeout24 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %usec_timeout24, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %16)
  %cmp2569.not = icmp eq i32 %16, 0
  br i1 %cmp2569.not, label %for.end21.cleanup_crit_edge, label %for.end21.for.body26_crit_edge

for.end21.for.body26_crit_edge:                   ; preds = %for.end21
  br label %for.body26

for.end21.cleanup_crit_edge:                      ; preds = %for.end21
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

for.body26:                                       ; preds = %if.end30.for.body26_crit_edge, %for.end21.for.body26_crit_edge
  %k.170 = phi i32 [ %inc32, %if.end30.for.body26_crit_edge ], [ 0, %for.end21.for.body26_crit_edge ]
  %call27 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60514, i32 noundef 0) #12
  %and = and i32 %call27, 917503
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %cmp28 = icmp eq i32 %and, 0
  br i1 %cmp28, label %for.body26.cleanup_crit_edge, label %if.end30

for.body26.cleanup_crit_edge:                     ; preds = %for.body26
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end30:                                         ; preds = %for.body26
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %17 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %17(i32 noundef 214748) #12
  %inc32 = add nuw i32 %k.170, 1
  %18 = ptrtoint ptr %usec_timeout24 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %usec_timeout24, align 8
  %cmp25 = icmp ult i32 %inc32, %19
  br i1 %cmp25, label %if.end30.for.body26_crit_edge, label %if.end30.cleanup_crit_edge

if.end30.cleanup_crit_edge:                       ; preds = %if.end30
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end30.for.body26_crit_edge:                    ; preds = %if.end30
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body26

cleanup:                                          ; preds = %if.end30.cleanup_crit_edge, %for.body26.cleanup_crit_edge, %for.end21.cleanup_crit_edge, %if.then12
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_off_ctrl(ptr noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_irq_get(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_irq_add_id(ptr noundef, i32 noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__init_work(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @gfx_v8_0_sq_irq_work_func(ptr noundef %work) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %add.ptr = getelementptr i8, ptr %work, i32 -44008
  %ih_data = getelementptr inbounds %struct.sq_work, ptr %work, i32 0, i32 1
  %0 = ptrtoint ptr %ih_data to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %ih_data, align 4
  tail call fastcc void @gfx_v8_0_parse_sq_irq(ptr noundef %add.ptr, i32 noundef %1, i1 noundef zeroext true)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_init_microcode(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  %fw_name = alloca [30 x i8], align 1
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @llvm.lifetime.start.p0(i64 30, ptr nonnull %fw_name) #12
  %0 = call ptr @memset(ptr %fw_name, i32 255, i32 30)
  tail call void (i32, ptr, ...) @__drm_dbg(i32 noundef 1, ptr noundef nonnull @.str.43) #12
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %1 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %asic_type, align 8
  %3 = zext i32 %2 to i64
  call void @__sanitizer_cov_trace_switch(i64 %3, ptr @__sancov_gen_cov_switch_values.123)
  switch i32 %2, label %do.body [
    i32 10, label %entry.if.else_crit_edge
    i32 11, label %sw.bb1
    i32 13, label %sw.bb2
    i32 12, label %sw.bb3
    i32 14, label %sw.bb4
    i32 15, label %entry.if.then_crit_edge
    i32 16, label %sw.bb6
    i32 17, label %sw.bb7
    i32 18, label %sw.bb8
  ]

entry.if.then_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then

entry.if.else_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

sw.bb1:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

sw.bb2:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

sw.bb3:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

sw.bb4:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

sw.bb6:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then

sw.bb7:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then

sw.bb8:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else

do.body:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 1001, 0\0A.popsection", ""() #12, !srcloc !449
  unreachable

if.then:                                          ; preds = %sw.bb7, %sw.bb6, %entry.if.then_crit_edge
  %chip_name.0 = phi ptr [ @.str.51, %sw.bb7 ], [ @.str.50, %sw.bb6 ], [ @.str.49, %entry.if.then_crit_edge ]
  %call = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.53, ptr noundef nonnull %chip_name.0)
  %pfp_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 11
  %4 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %adev, align 8
  %call16 = call i32 @request_firmware(ptr noundef %pfp_fw, ptr noundef nonnull %fw_name, ptr noundef %5) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %call16)
  %cmp17 = icmp eq i32 %call16, -2
  br i1 %cmp17, label %if.then18, label %if.then.if.end33_crit_edge

if.then.if.end33_crit_edge:                       ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end33

if.then18:                                        ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  %call20 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.54, ptr noundef nonnull %chip_name.0)
  br label %if.end33.sink.split

if.else:                                          ; preds = %sw.bb8, %sw.bb4, %sw.bb3, %sw.bb2, %sw.bb1, %entry.if.else_crit_edge
  %chip_name.0732 = phi ptr [ @.str.44, %entry.if.else_crit_edge ], [ @.str.45, %sw.bb1 ], [ @.str.46, %sw.bb2 ], [ @.str.47, %sw.bb3 ], [ @.str.48, %sw.bb4 ], [ @.str.52, %sw.bb8 ]
  %call27 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.54, ptr noundef nonnull %chip_name.0732)
  %pfp_fw29 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 11
  br label %if.end33.sink.split

if.end33.sink.split:                              ; preds = %if.else, %if.then18
  %pfp_fw.sink = phi ptr [ %pfp_fw, %if.then18 ], [ %pfp_fw29, %if.else ]
  %chip_name.0731.ph = phi ptr [ %chip_name.0, %if.then18 ], [ %chip_name.0732, %if.else ]
  %6 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %adev, align 8
  %call25 = call i32 @request_firmware(ptr noundef %pfp_fw.sink, ptr noundef nonnull %fw_name, ptr noundef %7) #12
  br label %if.end33

if.end33:                                         ; preds = %if.end33.sink.split, %if.then.if.end33_crit_edge
  %chip_name.0731 = phi ptr [ %chip_name.0, %if.then.if.end33_crit_edge ], [ %chip_name.0731.ph, %if.end33.sink.split ]
  %err.0 = phi i32 [ %call16, %if.then.if.end33_crit_edge ], [ %call25, %if.end33.sink.split ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %err.0)
  %tobool.not = icmp eq i32 %err.0, 0
  br i1 %tobool.not, label %if.end35, label %if.end33.do.end472_crit_edge

if.end33.do.end472_crit_edge:                     ; preds = %if.end33
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end35:                                         ; preds = %if.end33
  %pfp_fw37 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 11
  %8 = ptrtoint ptr %pfp_fw37 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %pfp_fw37, align 4
  %call38 = call i32 @amdgpu_ucode_validate(ptr noundef %9) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call38)
  %tobool39.not = icmp eq i32 %call38, 0
  br i1 %tobool39.not, label %if.end41, label %if.end35.do.end472_crit_edge

if.end35.do.end472_crit_edge:                     ; preds = %if.end35
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end41:                                         ; preds = %if.end35
  %10 = ptrtoint ptr %pfp_fw37 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %pfp_fw37, align 4
  %data = getelementptr inbounds %struct.firmware, ptr %11, i32 0, i32 1
  %12 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %data, align 4
  %ucode_version = getelementptr inbounds %struct.common_firmware_header, ptr %13, i32 0, i32 6
  %14 = ptrtoint ptr %ucode_version to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %ucode_version, align 4
  %16 = call i32 @llvm.bswap.i32(i32 %15)
  %pfp_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 12
  %17 = ptrtoint ptr %pfp_fw_version to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 %16, ptr %pfp_fw_version, align 8
  %ucode_feature_version = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %13, i32 0, i32 1
  %18 = ptrtoint ptr %ucode_feature_version to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %ucode_feature_version, align 4
  %20 = call i32 @llvm.bswap.i32(i32 %19)
  %pfp_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 23
  %21 = ptrtoint ptr %pfp_feature_version to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %20, ptr %pfp_feature_version, align 4
  %22 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %asic_type, align 8
  %24 = add i32 %23, -15
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %24)
  %25 = icmp ult i32 %24, 3
  br i1 %25, label %if.then52, label %if.else69

if.then52:                                        ; preds = %if.end41
  %call54 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.55, ptr noundef nonnull %chip_name.0731)
  %me_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 9
  %26 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %adev, align 8
  %call58 = call i32 @request_firmware(ptr noundef %me_fw, ptr noundef nonnull %fw_name, ptr noundef %27) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %call58)
  %cmp59 = icmp eq i32 %call58, -2
  br i1 %cmp59, label %if.then60, label %if.then52.if.end77_crit_edge

if.then52.if.end77_crit_edge:                     ; preds = %if.then52
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end77

if.then60:                                        ; preds = %if.then52
  call void @__sanitizer_cov_trace_pc() #14
  %call62 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.56, ptr noundef nonnull %chip_name.0731)
  br label %if.end77.sink.split

if.else69:                                        ; preds = %if.end41
  call void @__sanitizer_cov_trace_pc() #14
  %call71 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.56, ptr noundef nonnull %chip_name.0731)
  %me_fw73 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 9
  br label %if.end77.sink.split

if.end77.sink.split:                              ; preds = %if.else69, %if.then60
  %me_fw.sink = phi ptr [ %me_fw, %if.then60 ], [ %me_fw73, %if.else69 ]
  %28 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %adev, align 8
  %call67 = call i32 @request_firmware(ptr noundef %me_fw.sink, ptr noundef nonnull %fw_name, ptr noundef %29) #12
  br label %if.end77

if.end77:                                         ; preds = %if.end77.sink.split, %if.then52.if.end77_crit_edge
  %err.1 = phi i32 [ %call58, %if.then52.if.end77_crit_edge ], [ %call67, %if.end77.sink.split ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %err.1)
  %tobool78.not = icmp eq i32 %err.1, 0
  br i1 %tobool78.not, label %if.end80, label %if.end77.do.end472_crit_edge

if.end77.do.end472_crit_edge:                     ; preds = %if.end77
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end80:                                         ; preds = %if.end77
  %me_fw82 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 9
  %30 = ptrtoint ptr %me_fw82 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %me_fw82, align 4
  %call83 = call i32 @amdgpu_ucode_validate(ptr noundef %31) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call83)
  %tobool84.not = icmp eq i32 %call83, 0
  br i1 %tobool84.not, label %if.end86, label %if.end80.do.end472_crit_edge

if.end80.do.end472_crit_edge:                     ; preds = %if.end80
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end86:                                         ; preds = %if.end80
  %32 = ptrtoint ptr %me_fw82 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %me_fw82, align 4
  %data89 = getelementptr inbounds %struct.firmware, ptr %33, i32 0, i32 1
  %34 = ptrtoint ptr %data89 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %data89, align 4
  %ucode_version91 = getelementptr inbounds %struct.common_firmware_header, ptr %35, i32 0, i32 6
  %36 = ptrtoint ptr %ucode_version91 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %ucode_version91, align 4
  %38 = call i32 @llvm.bswap.i32(i32 %37)
  %me_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 10
  %39 = ptrtoint ptr %me_fw_version to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 %38, ptr %me_fw_version, align 8
  %ucode_feature_version93 = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %35, i32 0, i32 1
  %40 = ptrtoint ptr %ucode_feature_version93 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %ucode_feature_version93, align 4
  %42 = call i32 @llvm.bswap.i32(i32 %41)
  %me_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 21
  %43 = ptrtoint ptr %me_feature_version to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 %42, ptr %me_feature_version, align 4
  %44 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %asic_type, align 8
  %46 = add i32 %45, -15
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %46)
  %47 = icmp ult i32 %46, 3
  br i1 %47, label %if.then100, label %if.else117

if.then100:                                       ; preds = %if.end86
  %call102 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.57, ptr noundef nonnull %chip_name.0731)
  %ce_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 13
  %48 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %adev, align 8
  %call106 = call i32 @request_firmware(ptr noundef %ce_fw, ptr noundef nonnull %fw_name, ptr noundef %49) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %call106)
  %cmp107 = icmp eq i32 %call106, -2
  br i1 %cmp107, label %if.then108, label %if.then100.if.end125_crit_edge

if.then100.if.end125_crit_edge:                   ; preds = %if.then100
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end125

if.then108:                                       ; preds = %if.then100
  call void @__sanitizer_cov_trace_pc() #14
  %call110 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.58, ptr noundef nonnull %chip_name.0731)
  br label %if.end125.sink.split

if.else117:                                       ; preds = %if.end86
  call void @__sanitizer_cov_trace_pc() #14
  %call119 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.58, ptr noundef nonnull %chip_name.0731)
  %ce_fw121 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 13
  br label %if.end125.sink.split

if.end125.sink.split:                             ; preds = %if.else117, %if.then108
  %ce_fw.sink = phi ptr [ %ce_fw, %if.then108 ], [ %ce_fw121, %if.else117 ]
  %50 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %adev, align 8
  %call115 = call i32 @request_firmware(ptr noundef %ce_fw.sink, ptr noundef nonnull %fw_name, ptr noundef %51) #12
  br label %if.end125

if.end125:                                        ; preds = %if.end125.sink.split, %if.then100.if.end125_crit_edge
  %err.2 = phi i32 [ %call106, %if.then100.if.end125_crit_edge ], [ %call115, %if.end125.sink.split ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %err.2)
  %tobool126.not = icmp eq i32 %err.2, 0
  br i1 %tobool126.not, label %if.end128, label %if.end125.do.end472_crit_edge

if.end125.do.end472_crit_edge:                    ; preds = %if.end125
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end128:                                        ; preds = %if.end125
  %ce_fw130 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 13
  %52 = ptrtoint ptr %ce_fw130 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %ce_fw130, align 4
  %call131 = call i32 @amdgpu_ucode_validate(ptr noundef %53) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call131)
  %tobool132.not = icmp eq i32 %call131, 0
  br i1 %tobool132.not, label %if.end134, label %if.end128.do.end472_crit_edge

if.end128.do.end472_crit_edge:                    ; preds = %if.end128
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end134:                                        ; preds = %if.end128
  %54 = ptrtoint ptr %ce_fw130 to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %ce_fw130, align 4
  %data137 = getelementptr inbounds %struct.firmware, ptr %55, i32 0, i32 1
  %56 = ptrtoint ptr %data137 to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %data137, align 4
  %ucode_version139 = getelementptr inbounds %struct.common_firmware_header, ptr %57, i32 0, i32 6
  %58 = ptrtoint ptr %ucode_version139 to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %ucode_version139, align 4
  %60 = call i32 @llvm.bswap.i32(i32 %59)
  %ce_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 14
  %61 = ptrtoint ptr %ce_fw_version to i32
  call void @__asan_store4_noabort(i32 %61)
  store i32 %60, ptr %ce_fw_version, align 8
  %ucode_feature_version141 = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %57, i32 0, i32 1
  %62 = ptrtoint ptr %ucode_feature_version141 to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %ucode_feature_version141, align 4
  %64 = call i32 @llvm.bswap.i32(i32 %63)
  %ce_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 22
  %65 = ptrtoint ptr %ce_feature_version to i32
  call void @__asan_store4_noabort(i32 %65)
  store i32 %64, ptr %ce_feature_version, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 45, i32 %64)
  %cmp145 = icmp ugt i32 %64, 45
  br i1 %cmp145, label %land.lhs.true146, label %if.end134.if.else156_crit_edge

if.end134.if.else156_crit_edge:                   ; preds = %if.end134
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else156

land.lhs.true146:                                 ; preds = %if.end134
  %66 = ptrtoint ptr %pfp_feature_version to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %pfp_feature_version, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 45, i32 %67)
  %cmp149 = icmp ugt i32 %67, 45
  br i1 %cmp149, label %if.then150, label %land.lhs.true146.if.else156_crit_edge

land.lhs.true146.if.else156_crit_edge:            ; preds = %land.lhs.true146
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else156

if.then150:                                       ; preds = %land.lhs.true146
  call void @__sanitizer_cov_trace_pc() #14
  %chained_ib_support = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 132, i32 3
  %68 = ptrtoint ptr %chained_ib_support to i32
  call void @__asan_store1_noabort(i32 %68)
  store i8 1, ptr %chained_ib_support, align 4
  %call155 = call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.59) #15
  br label %if.end159

if.else156:                                       ; preds = %land.lhs.true146.if.else156_crit_edge, %if.end134.if.else156_crit_edge
  %chained_ib_support158 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 132, i32 3
  %69 = ptrtoint ptr %chained_ib_support158 to i32
  call void @__asan_store1_noabort(i32 %69)
  store i8 0, ptr %chained_ib_support158, align 4
  br label %if.end159

if.end159:                                        ; preds = %if.else156, %if.then150
  %call161 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.61, ptr noundef nonnull %chip_name.0731)
  %rlc_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 15
  %70 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load ptr, ptr %adev, align 8
  %call165 = call i32 @request_firmware(ptr noundef %rlc_fw, ptr noundef nonnull %fw_name, ptr noundef %71) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call165)
  %tobool166.not = icmp eq i32 %call165, 0
  br i1 %tobool166.not, label %if.end168, label %if.end159.do.end472_crit_edge

if.end159.do.end472_crit_edge:                    ; preds = %if.end159
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end168:                                        ; preds = %if.end159
  %72 = ptrtoint ptr %rlc_fw to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load ptr, ptr %rlc_fw, align 4
  %call171 = call i32 @amdgpu_ucode_validate(ptr noundef %73) #12
  %74 = ptrtoint ptr %rlc_fw to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load ptr, ptr %rlc_fw, align 4
  %data174 = getelementptr inbounds %struct.firmware, ptr %75, i32 0, i32 1
  %76 = ptrtoint ptr %data174 to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load ptr, ptr %data174, align 4
  %ucode_version176 = getelementptr inbounds %struct.common_firmware_header, ptr %77, i32 0, i32 6
  %78 = ptrtoint ptr %ucode_version176 to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load i32, ptr %ucode_version176, align 4
  %80 = call i32 @llvm.bswap.i32(i32 %79)
  %rlc_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 16
  %81 = ptrtoint ptr %rlc_fw_version to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 %80, ptr %rlc_fw_version, align 8
  %ucode_feature_version178 = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 1
  %82 = ptrtoint ptr %ucode_feature_version178 to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load i32, ptr %ucode_feature_version178, align 4
  %84 = call i32 @llvm.bswap.i32(i32 %83)
  %rlc_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 24
  %85 = ptrtoint ptr %rlc_feature_version to i32
  call void @__asan_store4_noabort(i32 %85)
  store i32 %84, ptr %rlc_feature_version, align 8
  %save_and_restore_offset = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 4
  %86 = ptrtoint ptr %save_and_restore_offset to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load i32, ptr %save_and_restore_offset, align 4
  %88 = call i32 @llvm.bswap.i32(i32 %87)
  %save_and_restore_offset181 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 16
  %89 = ptrtoint ptr %save_and_restore_offset181 to i32
  call void @__asan_store4_noabort(i32 %89)
  store i32 %88, ptr %save_and_restore_offset181, align 8
  %clear_state_descriptor_offset = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 5
  %90 = ptrtoint ptr %clear_state_descriptor_offset to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load i32, ptr %clear_state_descriptor_offset, align 4
  %92 = call i32 @llvm.bswap.i32(i32 %91)
  %clear_state_descriptor_offset184 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 17
  %93 = ptrtoint ptr %clear_state_descriptor_offset184 to i32
  call void @__asan_store4_noabort(i32 %93)
  store i32 %92, ptr %clear_state_descriptor_offset184, align 4
  %avail_scratch_ram_locations = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 6
  %94 = ptrtoint ptr %avail_scratch_ram_locations to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load i32, ptr %avail_scratch_ram_locations, align 4
  %96 = call i32 @llvm.bswap.i32(i32 %95)
  %avail_scratch_ram_locations187 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 18
  %97 = ptrtoint ptr %avail_scratch_ram_locations187 to i32
  call void @__asan_store4_noabort(i32 %97)
  store i32 %96, ptr %avail_scratch_ram_locations187, align 8
  %reg_restore_list_size = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 7
  %98 = ptrtoint ptr %reg_restore_list_size to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %reg_restore_list_size, align 4
  %100 = call i32 @llvm.bswap.i32(i32 %99)
  %reg_restore_list_size190 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 19
  %101 = ptrtoint ptr %reg_restore_list_size190 to i32
  call void @__asan_store4_noabort(i32 %101)
  store i32 %100, ptr %reg_restore_list_size190, align 4
  %reg_list_format_start = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 8
  %102 = ptrtoint ptr %reg_list_format_start to i32
  call void @__asan_load4_noabort(i32 %102)
  %103 = load i32, ptr %reg_list_format_start, align 4
  %104 = call i32 @llvm.bswap.i32(i32 %103)
  %reg_list_format_start193 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 20
  %105 = ptrtoint ptr %reg_list_format_start193 to i32
  call void @__asan_store4_noabort(i32 %105)
  store i32 %104, ptr %reg_list_format_start193, align 8
  %reg_list_format_separate_start = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 9
  %106 = ptrtoint ptr %reg_list_format_separate_start to i32
  call void @__asan_load4_noabort(i32 %106)
  %107 = load i32, ptr %reg_list_format_separate_start, align 4
  %108 = call i32 @llvm.bswap.i32(i32 %107)
  %reg_list_format_separate_start196 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 21
  %109 = ptrtoint ptr %reg_list_format_separate_start196 to i32
  call void @__asan_store4_noabort(i32 %109)
  store i32 %108, ptr %reg_list_format_separate_start196, align 4
  %starting_offsets_start = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 10
  %110 = ptrtoint ptr %starting_offsets_start to i32
  call void @__asan_load4_noabort(i32 %110)
  %111 = load i32, ptr %starting_offsets_start, align 4
  %112 = call i32 @llvm.bswap.i32(i32 %111)
  %starting_offsets_start199 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 22
  %113 = ptrtoint ptr %starting_offsets_start199 to i32
  call void @__asan_store4_noabort(i32 %113)
  store i32 %112, ptr %starting_offsets_start199, align 8
  %reg_list_format_size_bytes = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 11
  %114 = ptrtoint ptr %reg_list_format_size_bytes to i32
  call void @__asan_load4_noabort(i32 %114)
  %115 = load i32, ptr %reg_list_format_size_bytes, align 4
  %116 = call i32 @llvm.bswap.i32(i32 %115)
  %reg_list_format_size_bytes202 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 23
  %117 = ptrtoint ptr %reg_list_format_size_bytes202 to i32
  call void @__asan_store4_noabort(i32 %117)
  store i32 %116, ptr %reg_list_format_size_bytes202, align 4
  %reg_list_size_bytes = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 13
  %118 = ptrtoint ptr %reg_list_size_bytes to i32
  call void @__asan_load4_noabort(i32 %118)
  %119 = load i32, ptr %reg_list_size_bytes, align 4
  %120 = call i32 @llvm.bswap.i32(i32 %119)
  %reg_list_size_bytes205 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 24
  %121 = ptrtoint ptr %reg_list_size_bytes205 to i32
  call void @__asan_store4_noabort(i32 %121)
  store i32 %120, ptr %reg_list_size_bytes205, align 8
  %add = add i32 %120, %116
  %call9.i = call noalias align 128 ptr @__kmalloc(i32 noundef %add, i32 noundef 3264) #16
  %register_list_format = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 31
  %122 = ptrtoint ptr %register_list_format to i32
  call void @__asan_store4_noabort(i32 %122)
  store ptr %call9.i, ptr %register_list_format, align 4
  %tobool218.not = icmp eq ptr %call9.i, null
  br i1 %tobool218.not, label %if.end168.do.end472_crit_edge, label %if.end220

if.end168.do.end472_crit_edge:                    ; preds = %if.end168
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end220:                                        ; preds = %if.end168
  %123 = ptrtoint ptr %77 to i32
  %reg_list_format_array_offset_bytes = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 12
  %124 = ptrtoint ptr %reg_list_format_array_offset_bytes to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %reg_list_format_array_offset_bytes, align 4
  %126 = call i32 @llvm.bswap.i32(i32 %125)
  %add221 = add i32 %126, %123
  %127 = inttoptr i32 %add221 to ptr
  %128 = ptrtoint ptr %reg_list_format_size_bytes202 to i32
  call void @__asan_load4_noabort(i32 %128)
  %129 = load i32, ptr %reg_list_format_size_bytes202, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %129)
  %cmp225745.not = icmp ult i32 %129, 4
  br i1 %cmp225745.not, label %if.end220.for.end_crit_edge, label %if.end220.for.body_crit_edge

if.end220.for.body_crit_edge:                     ; preds = %if.end220
  br label %for.body

if.end220.for.end_crit_edge:                      ; preds = %if.end220
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body:                                         ; preds = %for.body.for.body_crit_edge, %if.end220.for.body_crit_edge
  %i.0746 = phi i32 [ %inc, %for.body.for.body_crit_edge ], [ 0, %if.end220.for.body_crit_edge ]
  %arrayidx = getelementptr i32, ptr %127, i32 %i.0746
  %130 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load i32, ptr %arrayidx, align 4
  %132 = call i32 @llvm.bswap.i32(i32 %131)
  %133 = ptrtoint ptr %register_list_format to i32
  call void @__asan_load4_noabort(i32 %133)
  %134 = load ptr, ptr %register_list_format, align 4
  %arrayidx229 = getelementptr i32, ptr %134, i32 %i.0746
  %135 = ptrtoint ptr %arrayidx229 to i32
  call void @__asan_store4_noabort(i32 %135)
  store i32 %132, ptr %arrayidx229, align 4
  %inc = add nuw nsw i32 %i.0746, 1
  %136 = ptrtoint ptr %reg_list_format_size_bytes202 to i32
  call void @__asan_load4_noabort(i32 %136)
  %137 = load i32, ptr %reg_list_format_size_bytes202, align 4
  %shr = lshr i32 %137, 2
  %cmp225 = icmp ult i32 %inc, %shr
  br i1 %cmp225, label %for.body.for.body_crit_edge, label %for.body.for.end_crit_edge

for.body.for.end_crit_edge:                       ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.body.for.end_crit_edge, %if.end220.for.end_crit_edge
  %i.0.lcssa = phi i32 [ 0, %if.end220.for.end_crit_edge ], [ %inc, %for.body.for.end_crit_edge ]
  %138 = ptrtoint ptr %register_list_format to i32
  call void @__asan_load4_noabort(i32 %138)
  %139 = load ptr, ptr %register_list_format, align 4
  %add.ptr = getelementptr i32, ptr %139, i32 %i.0.lcssa
  %register_restore = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 2, i32 32
  %140 = ptrtoint ptr %register_restore to i32
  call void @__asan_store4_noabort(i32 %140)
  store ptr %add.ptr, ptr %register_restore, align 8
  %reg_list_array_offset_bytes = getelementptr inbounds %struct.rlc_firmware_header_v2_0, ptr %77, i32 0, i32 14
  %141 = ptrtoint ptr %reg_list_array_offset_bytes to i32
  call void @__asan_load4_noabort(i32 %141)
  %142 = load i32, ptr %reg_list_array_offset_bytes, align 4
  %143 = call i32 @llvm.bswap.i32(i32 %142)
  %add235 = add i32 %143, %123
  %144 = inttoptr i32 %add235 to ptr
  %145 = ptrtoint ptr %reg_list_size_bytes205 to i32
  call void @__asan_load4_noabort(i32 %145)
  %146 = load i32, ptr %reg_list_size_bytes205, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 4, i32 %146)
  %cmp241748.not = icmp ult i32 %146, 4
  br i1 %cmp241748.not, label %for.end.for.end250_crit_edge, label %for.end.for.body242_crit_edge

for.end.for.body242_crit_edge:                    ; preds = %for.end
  br label %for.body242

for.end.for.end250_crit_edge:                     ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end250

for.body242:                                      ; preds = %for.body242.for.body242_crit_edge, %for.end.for.body242_crit_edge
  %i.1749 = phi i32 [ %inc249, %for.body242.for.body242_crit_edge ], [ 0, %for.end.for.body242_crit_edge ]
  %arrayidx243 = getelementptr i32, ptr %144, i32 %i.1749
  %147 = ptrtoint ptr %arrayidx243 to i32
  call void @__asan_load4_noabort(i32 %147)
  %148 = load i32, ptr %arrayidx243, align 4
  %149 = call i32 @llvm.bswap.i32(i32 %148)
  %150 = ptrtoint ptr %register_restore to i32
  call void @__asan_load4_noabort(i32 %150)
  %151 = load ptr, ptr %register_restore, align 8
  %arrayidx247 = getelementptr i32, ptr %151, i32 %i.1749
  %152 = ptrtoint ptr %arrayidx247 to i32
  call void @__asan_store4_noabort(i32 %152)
  store i32 %149, ptr %arrayidx247, align 4
  %inc249 = add nuw nsw i32 %i.1749, 1
  %153 = ptrtoint ptr %reg_list_size_bytes205 to i32
  call void @__asan_load4_noabort(i32 %153)
  %154 = load i32, ptr %reg_list_size_bytes205, align 8
  %shr240 = lshr i32 %154, 2
  %cmp241 = icmp ult i32 %inc249, %shr240
  br i1 %cmp241, label %for.body242.for.body242_crit_edge, label %for.body242.for.end250_crit_edge

for.body242.for.end250_crit_edge:                 ; preds = %for.body242
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end250

for.body242.for.body242_crit_edge:                ; preds = %for.body242
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body242

for.end250:                                       ; preds = %for.body242.for.end250_crit_edge, %for.end.for.end250_crit_edge
  %155 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %155)
  %156 = load i32, ptr %asic_type, align 8
  %157 = add i32 %156, -15
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %157)
  %158 = icmp ult i32 %157, 3
  br i1 %158, label %if.then256, label %if.else273

if.then256:                                       ; preds = %for.end250
  %call258 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.62, ptr noundef nonnull %chip_name.0731)
  %mec_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 17
  %159 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %159)
  %160 = load ptr, ptr %adev, align 8
  %call262 = call i32 @request_firmware(ptr noundef %mec_fw, ptr noundef nonnull %fw_name, ptr noundef %160) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %call262)
  %cmp263 = icmp eq i32 %call262, -2
  br i1 %cmp263, label %if.then264, label %if.then256.if.end281_crit_edge

if.then256.if.end281_crit_edge:                   ; preds = %if.then256
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end281

if.then264:                                       ; preds = %if.then256
  call void @__sanitizer_cov_trace_pc() #14
  %call266 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.63, ptr noundef nonnull %chip_name.0731)
  br label %if.end281.sink.split

if.else273:                                       ; preds = %for.end250
  call void @__sanitizer_cov_trace_pc() #14
  %call275 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.63, ptr noundef nonnull %chip_name.0731)
  %mec_fw277 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 17
  br label %if.end281.sink.split

if.end281.sink.split:                             ; preds = %if.else273, %if.then264
  %mec_fw.sink = phi ptr [ %mec_fw, %if.then264 ], [ %mec_fw277, %if.else273 ]
  %161 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %161)
  %162 = load ptr, ptr %adev, align 8
  %call271 = call i32 @request_firmware(ptr noundef %mec_fw.sink, ptr noundef nonnull %fw_name, ptr noundef %162) #12
  br label %if.end281

if.end281:                                        ; preds = %if.end281.sink.split, %if.then256.if.end281_crit_edge
  %err.3 = phi i32 [ %call262, %if.then256.if.end281_crit_edge ], [ %call271, %if.end281.sink.split ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %err.3)
  %tobool282.not = icmp eq i32 %err.3, 0
  br i1 %tobool282.not, label %if.end284, label %if.end281.do.end472_crit_edge

if.end281.do.end472_crit_edge:                    ; preds = %if.end281
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end284:                                        ; preds = %if.end281
  %mec_fw286 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 17
  %163 = ptrtoint ptr %mec_fw286 to i32
  call void @__asan_load4_noabort(i32 %163)
  %164 = load ptr, ptr %mec_fw286, align 4
  %call287 = call i32 @amdgpu_ucode_validate(ptr noundef %164) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call287)
  %tobool288.not = icmp eq i32 %call287, 0
  br i1 %tobool288.not, label %if.end290, label %if.end284.do.end472_crit_edge

if.end284.do.end472_crit_edge:                    ; preds = %if.end284
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end290:                                        ; preds = %if.end284
  %165 = ptrtoint ptr %mec_fw286 to i32
  call void @__asan_load4_noabort(i32 %165)
  %166 = load ptr, ptr %mec_fw286, align 4
  %data293 = getelementptr inbounds %struct.firmware, ptr %166, i32 0, i32 1
  %167 = ptrtoint ptr %data293 to i32
  call void @__asan_load4_noabort(i32 %167)
  %168 = load ptr, ptr %data293, align 4
  %ucode_version295 = getelementptr inbounds %struct.common_firmware_header, ptr %168, i32 0, i32 6
  %169 = ptrtoint ptr %ucode_version295 to i32
  call void @__asan_load4_noabort(i32 %169)
  %170 = load i32, ptr %ucode_version295, align 4
  %171 = call i32 @llvm.bswap.i32(i32 %170)
  %mec_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 18
  %172 = ptrtoint ptr %mec_fw_version to i32
  call void @__asan_store4_noabort(i32 %172)
  store i32 %171, ptr %mec_fw_version, align 8
  %ucode_feature_version297 = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %168, i32 0, i32 1
  %173 = ptrtoint ptr %ucode_feature_version297 to i32
  call void @__asan_load4_noabort(i32 %173)
  %174 = load i32, ptr %ucode_feature_version297, align 4
  %175 = call i32 @llvm.bswap.i32(i32 %174)
  %mec_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 31
  %176 = ptrtoint ptr %mec_feature_version to i32
  call void @__asan_store4_noabort(i32 %176)
  store i32 %175, ptr %mec_feature_version, align 4
  %177 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %177)
  %178 = load i32, ptr %asic_type, align 8
  %179 = zext i32 %178 to i64
  call void @__sanitizer_cov_trace_switch(i64 %179, ptr @__sancov_gen_cov_switch_values.124)
  switch i32 %178, label %if.then304 [
    i32 14, label %if.end290.if.end356_crit_edge
    i32 10, label %if.end290.if.end356_crit_edge750
  ]

if.end290.if.end356_crit_edge750:                 ; preds = %if.end290
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end356

if.end290.if.end356_crit_edge:                    ; preds = %if.end290
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end356

if.then304:                                       ; preds = %if.end290
  %180 = add i32 %178, -15
  call void @__sanitizer_cov_trace_const_cmp4(i32 3, i32 %180)
  %181 = icmp ult i32 %180, 3
  br i1 %181, label %if.then310, label %if.else327

if.then310:                                       ; preds = %if.then304
  %call312 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.64, ptr noundef nonnull %chip_name.0731)
  %mec2_fw = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 19
  %182 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %182)
  %183 = load ptr, ptr %adev, align 8
  %call316 = call i32 @request_firmware(ptr noundef %mec2_fw, ptr noundef nonnull %fw_name, ptr noundef %183) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -2, i32 %call316)
  %cmp317 = icmp eq i32 %call316, -2
  br i1 %cmp317, label %if.then318, label %if.then310.if.end335_crit_edge

if.then310.if.end335_crit_edge:                   ; preds = %if.then310
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end335

if.then318:                                       ; preds = %if.then310
  call void @__sanitizer_cov_trace_pc() #14
  %call320 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.65, ptr noundef nonnull %chip_name.0731)
  br label %if.end335.sink.split

if.else327:                                       ; preds = %if.then304
  call void @__sanitizer_cov_trace_pc() #14
  %call329 = call i32 (ptr, i32, ptr, ...) @snprintf(ptr noundef nonnull %fw_name, i32 noundef 30, ptr noundef nonnull @.str.65, ptr noundef nonnull %chip_name.0731)
  %mec2_fw331 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 19
  br label %if.end335.sink.split

if.end335.sink.split:                             ; preds = %if.else327, %if.then318
  %mec2_fw.sink = phi ptr [ %mec2_fw, %if.then318 ], [ %mec2_fw331, %if.else327 ]
  %184 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %184)
  %185 = load ptr, ptr %adev, align 8
  %call325 = call i32 @request_firmware(ptr noundef %mec2_fw.sink, ptr noundef nonnull %fw_name, ptr noundef %185) #12
  br label %if.end335

if.end335:                                        ; preds = %if.end335.sink.split, %if.then310.if.end335_crit_edge
  %err.4 = phi i32 [ %call316, %if.then310.if.end335_crit_edge ], [ %call325, %if.end335.sink.split ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %err.4)
  %tobool336.not = icmp eq i32 %err.4, 0
  %mec2_fw339 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 19
  br i1 %tobool336.not, label %if.then337, label %if.else352

if.then337:                                       ; preds = %if.end335
  %186 = ptrtoint ptr %mec2_fw339 to i32
  call void @__asan_load4_noabort(i32 %186)
  %187 = load ptr, ptr %mec2_fw339, align 4
  %call340 = call i32 @amdgpu_ucode_validate(ptr noundef %187) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call340)
  %tobool341.not = icmp eq i32 %call340, 0
  br i1 %tobool341.not, label %if.end343, label %if.then337.do.end472_crit_edge

if.then337.do.end472_crit_edge:                   ; preds = %if.then337
  call void @__sanitizer_cov_trace_pc() #14
  br label %do.end472

if.end343:                                        ; preds = %if.then337
  call void @__sanitizer_cov_trace_pc() #14
  %188 = ptrtoint ptr %mec2_fw339 to i32
  call void @__asan_load4_noabort(i32 %188)
  %189 = load ptr, ptr %mec2_fw339, align 4
  %data346 = getelementptr inbounds %struct.firmware, ptr %189, i32 0, i32 1
  %190 = ptrtoint ptr %data346 to i32
  call void @__asan_load4_noabort(i32 %190)
  %191 = load ptr, ptr %data346, align 4
  %ucode_version348 = getelementptr inbounds %struct.common_firmware_header, ptr %191, i32 0, i32 6
  %192 = ptrtoint ptr %ucode_version348 to i32
  call void @__asan_load4_noabort(i32 %192)
  %193 = load i32, ptr %ucode_version348, align 4
  %194 = call i32 @llvm.bswap.i32(i32 %193)
  %mec2_fw_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 20
  %195 = ptrtoint ptr %mec2_fw_version to i32
  call void @__asan_store4_noabort(i32 %195)
  store i32 %194, ptr %mec2_fw_version, align 8
  %ucode_feature_version350 = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %191, i32 0, i32 1
  %196 = ptrtoint ptr %ucode_feature_version350 to i32
  call void @__asan_load4_noabort(i32 %196)
  %197 = load i32, ptr %ucode_feature_version350, align 4
  %198 = call i32 @llvm.bswap.i32(i32 %197)
  %mec2_feature_version = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 32
  %199 = ptrtoint ptr %mec2_feature_version to i32
  call void @__asan_store4_noabort(i32 %199)
  store i32 %198, ptr %mec2_feature_version, align 8
  br label %if.end356

if.else352:                                       ; preds = %if.end335
  call void @__sanitizer_cov_trace_pc() #14
  %200 = ptrtoint ptr %mec2_fw339 to i32
  call void @__asan_store4_noabort(i32 %200)
  store ptr null, ptr %mec2_fw339, align 4
  br label %if.end356

if.end356:                                        ; preds = %if.else352, %if.end343, %if.end290.if.end356_crit_edge, %if.end290.if.end356_crit_edge750
  %arrayidx357 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 9
  %201 = ptrtoint ptr %arrayidx357 to i32
  call void @__asan_store4_noabort(i32 %201)
  store i32 9, ptr %arrayidx357, align 8
  %202 = ptrtoint ptr %pfp_fw37 to i32
  call void @__asan_load4_noabort(i32 %202)
  %203 = load ptr, ptr %pfp_fw37, align 4
  %fw = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 9, i32 1
  %204 = ptrtoint ptr %fw to i32
  call void @__asan_store4_noabort(i32 %204)
  store ptr %203, ptr %fw, align 4
  %data361 = getelementptr inbounds %struct.firmware, ptr %203, i32 0, i32 1
  %205 = ptrtoint ptr %data361 to i32
  call void @__asan_load4_noabort(i32 %205)
  %206 = load ptr, ptr %data361, align 4
  %ucode_size_bytes = getelementptr inbounds %struct.common_firmware_header, ptr %206, i32 0, i32 7
  %207 = ptrtoint ptr %ucode_size_bytes to i32
  call void @__asan_load4_noabort(i32 %207)
  %208 = load i32, ptr %ucode_size_bytes, align 4
  %209 = call i32 @llvm.bswap.i32(i32 %208)
  %add362 = add i32 %209, 4095
  %and = and i32 %add362, -4096
  %fw_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 3
  %210 = ptrtoint ptr %fw_size to i32
  call void @__asan_load4_noabort(i32 %210)
  %211 = load i32, ptr %fw_size, align 8
  %add364 = add i32 %and, %211
  store i32 %add364, ptr %fw_size, align 8
  %arrayidx367 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 10
  %212 = ptrtoint ptr %arrayidx367 to i32
  call void @__asan_store4_noabort(i32 %212)
  store i32 10, ptr %arrayidx367, align 8
  %213 = ptrtoint ptr %me_fw82 to i32
  call void @__asan_load4_noabort(i32 %213)
  %214 = load ptr, ptr %me_fw82, align 4
  %fw371 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 10, i32 1
  %215 = ptrtoint ptr %fw371 to i32
  call void @__asan_store4_noabort(i32 %215)
  store ptr %214, ptr %fw371, align 4
  %data373 = getelementptr inbounds %struct.firmware, ptr %214, i32 0, i32 1
  %216 = ptrtoint ptr %data373 to i32
  call void @__asan_load4_noabort(i32 %216)
  %217 = load ptr, ptr %data373, align 4
  %ucode_size_bytes374 = getelementptr inbounds %struct.common_firmware_header, ptr %217, i32 0, i32 7
  %218 = ptrtoint ptr %ucode_size_bytes374 to i32
  call void @__asan_load4_noabort(i32 %218)
  %219 = load i32, ptr %ucode_size_bytes374, align 4
  %220 = call i32 @llvm.bswap.i32(i32 %219)
  %add375 = add i32 %220, 4095
  %and376 = and i32 %add375, -4096
  %add379 = add i32 %and376, %add364
  %221 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %221)
  store i32 %add379, ptr %fw_size, align 8
  %arrayidx382 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 8
  %222 = ptrtoint ptr %arrayidx382 to i32
  call void @__asan_store4_noabort(i32 %222)
  store i32 8, ptr %arrayidx382, align 8
  %223 = ptrtoint ptr %ce_fw130 to i32
  call void @__asan_load4_noabort(i32 %223)
  %224 = load ptr, ptr %ce_fw130, align 4
  %fw386 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 8, i32 1
  %225 = ptrtoint ptr %fw386 to i32
  call void @__asan_store4_noabort(i32 %225)
  store ptr %224, ptr %fw386, align 4
  %data388 = getelementptr inbounds %struct.firmware, ptr %224, i32 0, i32 1
  %226 = ptrtoint ptr %data388 to i32
  call void @__asan_load4_noabort(i32 %226)
  %227 = load ptr, ptr %data388, align 4
  %ucode_size_bytes389 = getelementptr inbounds %struct.common_firmware_header, ptr %227, i32 0, i32 7
  %228 = ptrtoint ptr %ucode_size_bytes389 to i32
  call void @__asan_load4_noabort(i32 %228)
  %229 = load i32, ptr %ucode_size_bytes389, align 4
  %230 = call i32 @llvm.bswap.i32(i32 %229)
  %add390 = add i32 %230, 4095
  %and391 = and i32 %add390, -4096
  %add394 = add i32 %and391, %add379
  %231 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %231)
  store i32 %add394, ptr %fw_size, align 8
  %arrayidx397 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 22
  %232 = ptrtoint ptr %arrayidx397 to i32
  call void @__asan_store4_noabort(i32 %232)
  store i32 22, ptr %arrayidx397, align 8
  %233 = ptrtoint ptr %rlc_fw to i32
  call void @__asan_load4_noabort(i32 %233)
  %234 = load ptr, ptr %rlc_fw, align 4
  %fw401 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 22, i32 1
  %235 = ptrtoint ptr %fw401 to i32
  call void @__asan_store4_noabort(i32 %235)
  store ptr %234, ptr %fw401, align 4
  %data403 = getelementptr inbounds %struct.firmware, ptr %234, i32 0, i32 1
  %236 = ptrtoint ptr %data403 to i32
  call void @__asan_load4_noabort(i32 %236)
  %237 = load ptr, ptr %data403, align 4
  %ucode_size_bytes404 = getelementptr inbounds %struct.common_firmware_header, ptr %237, i32 0, i32 7
  %238 = ptrtoint ptr %ucode_size_bytes404 to i32
  call void @__asan_load4_noabort(i32 %238)
  %239 = load i32, ptr %ucode_size_bytes404, align 4
  %240 = call i32 @llvm.bswap.i32(i32 %239)
  %add405 = add i32 %240, 4095
  %and406 = and i32 %add405, -4096
  %add409 = add i32 %and406, %add394
  %241 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %241)
  store i32 %add409, ptr %fw_size, align 8
  %arrayidx412 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 11
  %242 = ptrtoint ptr %arrayidx412 to i32
  call void @__asan_store4_noabort(i32 %242)
  store i32 11, ptr %arrayidx412, align 8
  %243 = ptrtoint ptr %mec_fw286 to i32
  call void @__asan_load4_noabort(i32 %243)
  %244 = load ptr, ptr %mec_fw286, align 4
  %fw416 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 11, i32 1
  %245 = ptrtoint ptr %fw416 to i32
  call void @__asan_store4_noabort(i32 %245)
  store ptr %244, ptr %fw416, align 4
  %data418 = getelementptr inbounds %struct.firmware, ptr %244, i32 0, i32 1
  %246 = ptrtoint ptr %data418 to i32
  call void @__asan_load4_noabort(i32 %246)
  %247 = load ptr, ptr %data418, align 4
  %ucode_size_bytes419 = getelementptr inbounds %struct.common_firmware_header, ptr %247, i32 0, i32 7
  %248 = ptrtoint ptr %ucode_size_bytes419 to i32
  call void @__asan_load4_noabort(i32 %248)
  %249 = load i32, ptr %ucode_size_bytes419, align 4
  %250 = call i32 @llvm.bswap.i32(i32 %249)
  %add420 = add i32 %250, 4095
  %and421 = and i32 %add420, -4096
  %add424 = add i32 %and421, %add409
  %251 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %251)
  store i32 %add424, ptr %fw_size, align 8
  %252 = ptrtoint ptr %data418 to i32
  call void @__asan_load4_noabort(i32 %252)
  %253 = load ptr, ptr %data418, align 4
  %jt_size = getelementptr inbounds %struct.gfx_firmware_header_v1_0, ptr %253, i32 0, i32 3
  %254 = ptrtoint ptr %jt_size to i32
  call void @__asan_load4_noabort(i32 %254)
  %255 = load i32, ptr %jt_size, align 4
  %256 = call i32 @llvm.bswap.i32(i32 %255)
  %shl = shl i32 %256, 2
  %add428 = add i32 %shl, 4095
  %and429 = and i32 %add428, -4096
  %add432 = add i32 %and429, %add424
  %257 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %257)
  store i32 %add432, ptr %fw_size, align 8
  %virt433 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 132
  %258 = ptrtoint ptr %virt433 to i32
  call void @__asan_load4_noabort(i32 %258)
  %259 = load i32, ptr %virt433, align 8
  %and434 = and i32 %259, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and434)
  %tobool435.not = icmp eq i32 %and434, 0
  br i1 %tobool435.not, label %if.end356.if.end447_crit_edge, label %if.then436

if.end356.if.end447_crit_edge:                    ; preds = %if.end356
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end447

if.then436:                                       ; preds = %if.end356
  call void @__sanitizer_cov_trace_pc() #14
  %arrayidx439 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 23
  %260 = ptrtoint ptr %arrayidx439 to i32
  call void @__asan_store4_noabort(i32 %260)
  store i32 23, ptr %arrayidx439, align 8
  %fw443 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 23, i32 1
  %261 = ptrtoint ptr %fw443 to i32
  call void @__asan_store4_noabort(i32 %261)
  store ptr %244, ptr %fw443, align 4
  %add446 = add i32 %add432, 4096
  %262 = ptrtoint ptr %fw_size to i32
  call void @__asan_store4_noabort(i32 %262)
  store i32 %add446, ptr %fw_size, align 8
  br label %if.end447

if.end447:                                        ; preds = %if.then436, %if.end356.if.end447_crit_edge
  %mec2_fw449 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 19
  %263 = ptrtoint ptr %mec2_fw449 to i32
  call void @__asan_load4_noabort(i32 %263)
  %264 = load ptr, ptr %mec2_fw449, align 4
  %tobool450.not = icmp eq ptr %264, null
  br i1 %tobool450.not, label %if.end447.if.end499_crit_edge, label %if.then451

if.end447.if.end499_crit_edge:                    ; preds = %if.end447
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end499

if.then451:                                       ; preds = %if.end447
  call void @__sanitizer_cov_trace_pc() #14
  %arrayidx454 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 13
  %265 = ptrtoint ptr %arrayidx454 to i32
  call void @__asan_store4_noabort(i32 %265)
  store i32 13, ptr %arrayidx454, align 8
  %fw458 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 112, i32 0, i32 13, i32 1
  %266 = ptrtoint ptr %fw458 to i32
  call void @__asan_store4_noabort(i32 %266)
  store ptr %264, ptr %fw458, align 4
  %data460 = getelementptr inbounds %struct.firmware, ptr %264, i32 0, i32 1
  %267 = ptrtoint ptr %data460 to i32
  call void @__asan_load4_noabort(i32 %267)
  %268 = load ptr, ptr %data460, align 4
  %ucode_size_bytes461 = getelementptr inbounds %struct.common_firmware_header, ptr %268, i32 0, i32 7
  %269 = ptrtoint ptr %ucode_size_bytes461 to i32
  call void @__asan_load4_noabort(i32 %269)
  %270 = load i32, ptr %ucode_size_bytes461, align 4
  %271 = call i32 @llvm.bswap.i32(i32 %270)
  %add462 = add i32 %271, 4095
  %and463 = and i32 %add462, -4096
  %272 = ptrtoint ptr %fw_size to i32
  call void @__asan_load4_noabort(i32 %272)
  %273 = load i32, ptr %fw_size, align 8
  %add466 = add i32 %and463, %273
  store i32 %add466, ptr %fw_size, align 8
  br label %if.end499

do.end472:                                        ; preds = %if.then337.do.end472_crit_edge, %if.end284.do.end472_crit_edge, %if.end281.do.end472_crit_edge, %if.end168.do.end472_crit_edge, %if.end159.do.end472_crit_edge, %if.end128.do.end472_crit_edge, %if.end125.do.end472_crit_edge, %if.end80.do.end472_crit_edge, %if.end77.do.end472_crit_edge, %if.end35.do.end472_crit_edge, %if.end33.do.end472_crit_edge
  %err.6.ph = phi i32 [ -12, %if.end168.do.end472_crit_edge ], [ %call340, %if.then337.do.end472_crit_edge ], [ %call287, %if.end284.do.end472_crit_edge ], [ %err.3, %if.end281.do.end472_crit_edge ], [ %call165, %if.end159.do.end472_crit_edge ], [ %call131, %if.end128.do.end472_crit_edge ], [ %err.2, %if.end125.do.end472_crit_edge ], [ %call83, %if.end80.do.end472_crit_edge ], [ %err.1, %if.end77.do.end472_crit_edge ], [ %call38, %if.end35.do.end472_crit_edge ], [ %err.0, %if.end33.do.end472_crit_edge ]
  %274 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %274)
  %275 = load ptr, ptr %adev, align 8
  call void (ptr, ptr, ...) @_dev_err(ptr noundef %275, ptr noundef nonnull @.str.67, ptr noundef nonnull %fw_name) #15
  %pfp_fw476 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 11
  %276 = ptrtoint ptr %pfp_fw476 to i32
  call void @__asan_load4_noabort(i32 %276)
  %277 = load ptr, ptr %pfp_fw476, align 4
  call void @release_firmware(ptr noundef %277) #12
  %278 = ptrtoint ptr %pfp_fw476 to i32
  call void @__asan_store4_noabort(i32 %278)
  store ptr null, ptr %pfp_fw476, align 4
  %me_fw480 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 9
  %279 = ptrtoint ptr %me_fw480 to i32
  call void @__asan_load4_noabort(i32 %279)
  %280 = load ptr, ptr %me_fw480, align 4
  call void @release_firmware(ptr noundef %280) #12
  %281 = ptrtoint ptr %me_fw480 to i32
  call void @__asan_store4_noabort(i32 %281)
  store ptr null, ptr %me_fw480, align 4
  %ce_fw484 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 13
  %282 = ptrtoint ptr %ce_fw484 to i32
  call void @__asan_load4_noabort(i32 %282)
  %283 = load ptr, ptr %ce_fw484, align 4
  call void @release_firmware(ptr noundef %283) #12
  %284 = ptrtoint ptr %ce_fw484 to i32
  call void @__asan_store4_noabort(i32 %284)
  store ptr null, ptr %ce_fw484, align 4
  %rlc_fw488 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 15
  %285 = ptrtoint ptr %rlc_fw488 to i32
  call void @__asan_load4_noabort(i32 %285)
  %286 = load ptr, ptr %rlc_fw488, align 4
  call void @release_firmware(ptr noundef %286) #12
  %287 = ptrtoint ptr %rlc_fw488 to i32
  call void @__asan_store4_noabort(i32 %287)
  store ptr null, ptr %rlc_fw488, align 4
  %mec_fw492 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 17
  %288 = ptrtoint ptr %mec_fw492 to i32
  call void @__asan_load4_noabort(i32 %288)
  %289 = load ptr, ptr %mec_fw492, align 4
  call void @release_firmware(ptr noundef %289) #12
  %290 = ptrtoint ptr %mec_fw492 to i32
  call void @__asan_store4_noabort(i32 %290)
  store ptr null, ptr %mec_fw492, align 4
  %mec2_fw496 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 19
  %291 = ptrtoint ptr %mec2_fw496 to i32
  call void @__asan_load4_noabort(i32 %291)
  %292 = load ptr, ptr %mec2_fw496, align 4
  call void @release_firmware(ptr noundef %292) #12
  %293 = ptrtoint ptr %mec2_fw496 to i32
  call void @__asan_store4_noabort(i32 %293)
  store ptr null, ptr %mec2_fw496, align 4
  br label %if.end499

if.end499:                                        ; preds = %do.end472, %if.then451, %if.end447.if.end499_crit_edge
  %err.6743 = phi i32 [ %err.6.ph, %do.end472 ], [ 0, %if.then451 ], [ 0, %if.end447.if.end499_crit_edge ]
  call void @llvm.lifetime.end.p0(i64 30, ptr nonnull %fw_name) #12
  ret i32 %err.6743
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_mec_init(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  %hpd = alloca ptr, align 4
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %hpd) #12
  %0 = ptrtoint ptr %hpd to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %hpd, align 4, !annotation !441
  %mec = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6
  %queue_bitmap = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6, i32 8
  %1 = call ptr @memset(ptr %queue_bitmap, i32 0, i32 16)
  tail call void @amdgpu_gfx_compute_queue_acquire(ptr noundef %adev) #12
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 39
  %2 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %num_compute_rings, align 8
  %mul = shl i32 %3, 12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %mul)
  %tobool.not = icmp eq i32 %mul, 0
  br i1 %tobool.not, label %entry.cleanup_crit_edge, label %if.then

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.then:                                          ; preds = %entry
  %hpd_eop_gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6, i32 1
  %call = call i32 @amdgpu_bo_create_reserved(ptr noundef %adev, i32 noundef %mul, i32 noundef 4096, i32 noundef 4, ptr noundef %mec, ptr noundef %hpd_eop_gpu_addr, ptr noundef nonnull %hpd) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool6.not = icmp eq i32 %call, 0
  br i1 %tobool6.not, label %if.end, label %do.end

do.end:                                           ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  %4 = ptrtoint ptr %adev to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %adev, align 8
  call void (ptr, ptr, ...) @_dev_warn(ptr noundef %5, ptr noundef nonnull @.str.71, i32 noundef %call) #15
  br label %cleanup

if.end:                                           ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  %6 = ptrtoint ptr %hpd to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %hpd, align 4
  %8 = call ptr @memset(ptr %7, i32 0, i32 %mul)
  %9 = ptrtoint ptr %mec to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %mec, align 8
  call void @amdgpu_bo_kunmap(ptr noundef %10) #12
  %11 = ptrtoint ptr %mec to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %mec, align 8
  %tbo.i = getelementptr inbounds %struct.amdgpu_bo, ptr %12, i32 0, i32 4
  %bdev.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %12, i32 0, i32 4, i32 1
  %13 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %14, i32 0, i32 6
  call void @_raw_spin_lock(ptr noundef %lru_lock.i.i.i) #12
  %resource.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %12, i32 0, i32 4, i32 6
  %15 = ptrtoint ptr %resource.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %resource.i.i.i, align 4
  call void @ttm_bo_move_to_lru_tail(ptr noundef %tbo.i, ptr noundef %16, ptr noundef null) #12
  %17 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock2.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %18, i32 0, i32 6
  call void @_raw_spin_unlock(ptr noundef %lru_lock2.i.i.i) #12
  %resv.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %12, i32 0, i32 4, i32 0, i32 9
  %19 = ptrtoint ptr %resv.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %resv.i.i, align 8
  call void @dma_resv_reset_shared_max(ptr noundef %20) #12
  call void @ww_mutex_unlock(ptr noundef %20) #12
  br label %cleanup

cleanup:                                          ; preds = %if.end, %do.end, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ %call, %do.end ], [ 0, %if.end ], [ 0, %entry.cleanup_crit_edge ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %hpd) #12
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ring_init(ptr noundef, ptr noundef, i32 noundef, ptr noundef, i32 noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @amdgpu_gfx_is_mec_queue_enabled(ptr noundef, i32 noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_compute_ring_init(ptr noundef %adev, i32 noundef %ring_id, i32 noundef %mec, i32 noundef %pipe, i32 noundef %queue) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx3 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id
  %add = add i32 %mec, 1
  %me = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 16
  %0 = ptrtoint ptr %me to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 %add, ptr %me, align 8
  %pipe4 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 17
  %1 = ptrtoint ptr %pipe4 to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 %pipe, ptr %pipe4, align 4
  %queue5 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 18
  %2 = ptrtoint ptr %queue5 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 %queue, ptr %queue5, align 8
  %ring_obj = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 4
  %3 = ptrtoint ptr %ring_obj to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr null, ptr %ring_obj, align 8
  %use_doorbell = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 24
  %4 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_store1_noabort(i32 %4)
  store i8 1, ptr %use_doorbell, align 4
  %mec_ring0 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 144, i32 1
  %5 = ptrtoint ptr %mec_ring0 to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %mec_ring0, align 4
  %add6 = add i32 %6, %ring_id
  %doorbell_index7 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 23
  %7 = ptrtoint ptr %doorbell_index7 to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 %add6, ptr %doorbell_index7, align 8
  %hpd_eop_gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6, i32 1
  %8 = ptrtoint ptr %hpd_eop_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %hpd_eop_gpu_addr, align 8
  %mul = shl i32 %ring_id, 12
  %conv = sext i32 %mul to i64
  %add10 = add i64 %9, %conv
  %eop_gpu_addr = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 22
  %10 = ptrtoint ptr %eop_gpu_addr to i32
  call void @__asan_store8_noabort(i32 %10)
  store i64 %add10, ptr %eop_gpu_addr, align 8
  %name = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %ring_id, i32 29
  %call = tail call i32 (ptr, ptr, ...) @sprintf(ptr noundef %name, ptr noundef nonnull @.str.74, i32 noundef %add, i32 noundef %pipe, i32 noundef %queue)
  %11 = ptrtoint ptr %me to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %me, align 8
  %sub = add i32 %12, -1
  %num_pipe_per_mec = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6, i32 5
  %13 = ptrtoint ptr %num_pipe_per_mec to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %num_pipe_per_mec, align 4
  %mul17 = mul i32 %sub, %14
  %add18 = add i32 %mul17, 2
  %15 = ptrtoint ptr %pipe4 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %pipe4, align 4
  %add20 = add i32 %add18, %16
  %call21 = tail call zeroext i1 @amdgpu_gfx_is_high_priority_compute_queue(ptr noundef %adev, ptr noundef %arrayidx3) #12
  %cond = select i1 %call21, i32 2, i32 1
  %eop_irq = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 40
  %call24 = tail call i32 @amdgpu_ring_init(ptr noundef %adev, ptr noundef %arrayidx3, i32 noundef 1024, ptr noundef %eop_irq, i32 noundef %add20, i32 noundef %cond, ptr noundef null) #12
  ret i32 %call24
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_kiq_init(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_kiq_init_ring(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_gfx_mqd_sw_init(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_gpu_early_init(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %0 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %asic_type, align 8
  %2 = zext i32 %1 to i64
  call void @__sanitizer_cov_trace_switch(i64 %2, ptr @__sancov_gen_cov_switch_values.125)
  switch i32 %1, label %sw.default [
    i32 10, label %sw.bb
    i32 12, label %sw.bb25
    i32 16, label %entry.sw.bb65_crit_edge
    i32 17, label %entry.sw.bb65_crit_edge545
    i32 15, label %entry.sw.bb87_crit_edge
    i32 18, label %entry.sw.bb87_crit_edge546
    i32 11, label %sw.bb113
    i32 13, label %sw.bb153
    i32 14, label %sw.bb193
  ]

entry.sw.bb87_crit_edge546:                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb87

entry.sw.bb87_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb87

entry.sw.bb65_crit_edge545:                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb65

entry.sw.bb65_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.bb65

sw.bb:                                            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %3 = ptrtoint ptr %config to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 1, ptr %config, align 8
  %max_tile_pipes = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %4 = ptrtoint ptr %max_tile_pipes to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 2, ptr %max_tile_pipes, align 4
  %max_cu_per_sh = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %5 = ptrtoint ptr %max_cu_per_sh to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 6, ptr %max_cu_per_sh, align 8
  %max_sh_per_se = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %6 = ptrtoint ptr %max_sh_per_se to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 1, ptr %max_sh_per_se, align 4
  %max_backends_per_se = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %7 = ptrtoint ptr %max_backends_per_se to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 2, ptr %max_backends_per_se, align 8
  br label %sw.epilog.sink.split

sw.bb25:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config27 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %8 = ptrtoint ptr %config27 to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 4, ptr %config27, align 8
  %max_tile_pipes31 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %9 = ptrtoint ptr %max_tile_pipes31 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 16, ptr %max_tile_pipes31, align 4
  %max_cu_per_sh34 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %10 = ptrtoint ptr %max_cu_per_sh34 to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 16, ptr %max_cu_per_sh34, align 8
  %max_sh_per_se37 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %11 = ptrtoint ptr %max_sh_per_se37 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 1, ptr %max_sh_per_se37, align 4
  %max_backends_per_se40 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %12 = ptrtoint ptr %max_backends_per_se40 to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 4, ptr %max_backends_per_se40, align 8
  br label %sw.epilog.sink.split

sw.bb65:                                          ; preds = %entry.sw.bb65_crit_edge, %entry.sw.bb65_crit_edge545
  %call = tail call i32 @amdgpu_atombios_get_gfx_info(ptr noundef %adev) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %sw.bb65.sw.epilog_crit_edge, label %sw.bb65.cleanup_crit_edge

sw.bb65.cleanup_crit_edge:                        ; preds = %sw.bb65
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.bb65.sw.epilog_crit_edge:                      ; preds = %sw.bb65
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb87:                                          ; preds = %entry.sw.bb87_crit_edge, %entry.sw.bb87_crit_edge546
  %call88 = tail call i32 @amdgpu_atombios_get_gfx_info(ptr noundef %adev) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call88)
  %tobool89.not = icmp eq i32 %call88, 0
  br i1 %tobool89.not, label %sw.bb87.sw.epilog_crit_edge, label %sw.bb87.cleanup_crit_edge

sw.bb87.cleanup_crit_edge:                        ; preds = %sw.bb87
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

sw.bb87.sw.epilog_crit_edge:                      ; preds = %sw.bb87
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog

sw.bb113:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config115 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %13 = ptrtoint ptr %config115 to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 4, ptr %config115, align 8
  %max_tile_pipes119 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %14 = ptrtoint ptr %max_tile_pipes119 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 8, ptr %max_tile_pipes119, align 4
  %max_cu_per_sh122 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %15 = ptrtoint ptr %max_cu_per_sh122 to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 8, ptr %max_cu_per_sh122, align 8
  %max_sh_per_se125 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %16 = ptrtoint ptr %max_sh_per_se125 to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 1, ptr %max_sh_per_se125, align 4
  %max_backends_per_se128 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %17 = ptrtoint ptr %max_backends_per_se128 to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 2, ptr %max_backends_per_se128, align 8
  br label %sw.epilog.sink.split

sw.bb153:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config155 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %18 = ptrtoint ptr %config155 to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 1, ptr %config155, align 8
  %max_tile_pipes159 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %19 = ptrtoint ptr %max_tile_pipes159 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 2, ptr %max_tile_pipes159, align 4
  %max_sh_per_se162 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %20 = ptrtoint ptr %max_sh_per_se162 to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 1, ptr %max_sh_per_se162, align 4
  %max_backends_per_se165 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %21 = ptrtoint ptr %max_backends_per_se165 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 2, ptr %max_backends_per_se165, align 8
  %max_cu_per_sh168 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %22 = ptrtoint ptr %max_cu_per_sh168 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 8, ptr %max_cu_per_sh168, align 8
  br label %sw.epilog.sink.split

sw.bb193:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config195 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %23 = ptrtoint ptr %config195 to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 1, ptr %config195, align 8
  %max_tile_pipes199 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %24 = ptrtoint ptr %max_tile_pipes199 to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 2, ptr %max_tile_pipes199, align 4
  %max_sh_per_se202 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %25 = ptrtoint ptr %max_sh_per_se202 to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 1, ptr %max_sh_per_se202, align 4
  %max_backends_per_se205 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %26 = ptrtoint ptr %max_backends_per_se205 to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 1, ptr %max_backends_per_se205, align 8
  %max_cu_per_sh208 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %27 = ptrtoint ptr %max_cu_per_sh208 to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 3, ptr %max_cu_per_sh208, align 8
  br label %sw.epilog.sink.split

sw.default:                                       ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %config234 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1
  %28 = ptrtoint ptr %config234 to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 2, ptr %config234, align 8
  %max_tile_pipes238 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %29 = ptrtoint ptr %max_tile_pipes238 to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 4, ptr %max_tile_pipes238, align 4
  %max_cu_per_sh241 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 2
  %30 = ptrtoint ptr %max_cu_per_sh241 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 2, ptr %max_cu_per_sh241, align 8
  %max_sh_per_se244 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 3
  %31 = ptrtoint ptr %max_sh_per_se244 to i32
  call void @__asan_store4_noabort(i32 %31)
  store i32 1, ptr %max_sh_per_se244, align 4
  %max_backends_per_se247 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 4
  %32 = ptrtoint ptr %max_backends_per_se247 to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 2, ptr %max_backends_per_se247, align 8
  br label %sw.epilog.sink.split

sw.epilog.sink.split:                             ; preds = %sw.default, %sw.bb193, %sw.bb153, %sw.bb113, %sw.bb25, %sw.bb
  %.sink544 = phi i32 [ 4, %sw.default ], [ 2, %sw.bb193 ], [ 2, %sw.bb153 ], [ 8, %sw.bb113 ], [ 16, %sw.bb25 ], [ 2, %sw.bb ]
  %.sink.ph = phi i32 [ 32, %sw.default ], [ 16, %sw.bb193 ], [ 32, %sw.bb153 ], [ 32, %sw.bb113 ], [ 32, %sw.bb25 ], [ 32, %sw.bb ]
  %gb_addr_config.0.ph = phi i32 [ 570494979, %sw.default ], [ 570490881, %sw.bb193 ], [ 570490881, %sw.bb153 ], [ 570494979, %sw.bb113 ], [ 570494979, %sw.bb25 ], [ 570490881, %sw.bb ]
  %max_texture_channel_caches250 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 5
  %33 = ptrtoint ptr %max_texture_channel_caches250 to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %.sink544, ptr %max_texture_channel_caches250, align 4
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.epilog.sink.split, %sw.bb87.sw.epilog_crit_edge, %sw.bb65.sw.epilog_crit_edge
  %.sink = phi i32 [ 32, %sw.bb65.sw.epilog_crit_edge ], [ 32, %sw.bb87.sw.epilog_crit_edge ], [ %.sink.ph, %sw.epilog.sink.split ]
  %gb_addr_config.0 = phi i32 [ 570494978, %sw.bb65.sw.epilog_crit_edge ], [ 570494979, %sw.bb87.sw.epilog_crit_edge ], [ %gb_addr_config.0.ph, %sw.epilog.sink.split ]
  %max_gprs253 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 6
  %34 = ptrtoint ptr %max_gprs253 to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 256, ptr %max_gprs253, align 8
  %max_gs_threads256 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 7
  %35 = ptrtoint ptr %max_gs_threads256 to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 %.sink, ptr %max_gs_threads256, align 4
  %max_hw_contexts259 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 8
  %36 = ptrtoint ptr %max_hw_contexts259 to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 8, ptr %max_hw_contexts259, align 8
  %sc_prim_fifo_size_frontend262 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 9
  %37 = ptrtoint ptr %sc_prim_fifo_size_frontend262 to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 32, ptr %sc_prim_fifo_size_frontend262, align 4
  %sc_prim_fifo_size_backend265 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 10
  %38 = ptrtoint ptr %sc_prim_fifo_size_backend265 to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 256, ptr %sc_prim_fifo_size_backend265, align 8
  %sc_hiz_tile_fifo_size268 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 11
  %39 = ptrtoint ptr %sc_hiz_tile_fifo_size268 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 48, ptr %sc_hiz_tile_fifo_size268, align 4
  %sc_earlyz_tile_fifo_size271 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 12
  %40 = ptrtoint ptr %sc_earlyz_tile_fifo_size271 to i32
  call void @__asan_store4_noabort(i32 %40)
  store i32 304, ptr %sc_earlyz_tile_fifo_size271, align 8
  %call272 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 2520, i32 noundef 0) #12
  %mc_arb_ramcfg275 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 20
  %41 = ptrtoint ptr %mc_arb_ramcfg275 to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 %call272, ptr %mc_arb_ramcfg275, align 8
  %and = and i32 %call272, 3
  %num_banks = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 21
  %42 = ptrtoint ptr %num_banks to i32
  call void @__asan_store4_noabort(i32 %42)
  store i32 %and, ptr %num_banks, align 4
  %and281 = lshr i32 %call272, 2
  %shr282 = and i32 %and281, 1
  %num_ranks = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 22
  %43 = ptrtoint ptr %num_ranks to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 %shr282, ptr %num_ranks, align 8
  %max_tile_pipes287 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 1
  %44 = ptrtoint ptr %max_tile_pipes287 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %max_tile_pipes287, align 4
  %num_tile_pipes = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 13
  %46 = ptrtoint ptr %num_tile_pipes to i32
  call void @__asan_store4_noabort(i32 %46)
  store i32 %45, ptr %num_tile_pipes, align 4
  %mem_max_burst_length_bytes = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 15
  %47 = ptrtoint ptr %mem_max_burst_length_bytes to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 256, ptr %mem_max_burst_length_bytes, align 4
  %flags = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 9
  %48 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %flags, align 8
  %and292 = and i32 %49, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and292)
  %tobool293.not = icmp eq i32 %and292, 0
  br i1 %tobool293.not, label %if.else353, label %if.then294

if.then294:                                       ; preds = %sw.epilog
  %call295 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 2577, i32 noundef 0) #12
  %and296 = and i32 %call295, 15
  %and298 = lshr i32 %call295, 4
  %shr299 = and i32 %and298, 15
  %call300 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 2578, i32 noundef 0) #12
  %and301 = and i32 %call300, 15
  %and303 = lshr i32 %call300, 4
  %shr304 = and i32 %and303, 15
  %50 = zext i32 %and296 to i64
  call void @__sanitizer_cov_trace_switch(i64 %50, ptr @__sancov_gen_cov_switch_values.126)
  switch i32 %and296, label %lor.lhs.false308 [
    i32 0, label %if.then294.if.then310_crit_edge
    i32 3, label %if.then294.if.then310_crit_edge547
    i32 4, label %if.then294.if.then310_crit_edge548
  ]

if.then294.if.then310_crit_edge548:               ; preds = %if.then294
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then310

if.then294.if.then310_crit_edge547:               ; preds = %if.then294
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then310

if.then294.if.then310_crit_edge:                  ; preds = %if.then294
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then310

lor.lhs.false308:                                 ; preds = %if.then294
  call void @__sanitizer_cov_trace_const_cmp4(i32 12, i32 %and296)
  %cmp309 = icmp ugt i32 %and296, 12
  br i1 %cmp309, label %lor.lhs.false308.if.then310_crit_edge, label %lor.lhs.false308.if.end311_crit_edge

lor.lhs.false308.if.end311_crit_edge:             ; preds = %lor.lhs.false308
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end311

lor.lhs.false308.if.then310_crit_edge:            ; preds = %lor.lhs.false308
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then310

if.then310:                                       ; preds = %lor.lhs.false308.if.then310_crit_edge, %if.then294.if.then310_crit_edge, %if.then294.if.then310_crit_edge547, %if.then294.if.then310_crit_edge548
  br label %if.end311

if.end311:                                        ; preds = %if.then310, %lor.lhs.false308.if.end311_crit_edge
  %dimm00_addr_map.0 = phi i32 [ 0, %if.then310 ], [ %and296, %lor.lhs.false308.if.end311_crit_edge ]
  %51 = zext i32 %shr299 to i64
  call void @__sanitizer_cov_trace_switch(i64 %51, ptr @__sancov_gen_cov_switch_values.127)
  switch i32 %shr299, label %lor.lhs.false317 [
    i32 0, label %if.end311.if.then319_crit_edge
    i32 3, label %if.end311.if.then319_crit_edge549
    i32 4, label %if.end311.if.then319_crit_edge550
  ]

if.end311.if.then319_crit_edge550:                ; preds = %if.end311
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then319

if.end311.if.then319_crit_edge549:                ; preds = %if.end311
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then319

if.end311.if.then319_crit_edge:                   ; preds = %if.end311
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then319

lor.lhs.false317:                                 ; preds = %if.end311
  call void @__sanitizer_cov_trace_const_cmp4(i32 12, i32 %shr299)
  %cmp318 = icmp ugt i32 %shr299, 12
  br i1 %cmp318, label %lor.lhs.false317.if.then319_crit_edge, label %lor.lhs.false317.if.end320_crit_edge

lor.lhs.false317.if.end320_crit_edge:             ; preds = %lor.lhs.false317
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end320

lor.lhs.false317.if.then319_crit_edge:            ; preds = %lor.lhs.false317
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then319

if.then319:                                       ; preds = %lor.lhs.false317.if.then319_crit_edge, %if.end311.if.then319_crit_edge, %if.end311.if.then319_crit_edge549, %if.end311.if.then319_crit_edge550
  br label %if.end320

if.end320:                                        ; preds = %if.then319, %lor.lhs.false317.if.end320_crit_edge
  %dimm01_addr_map.0 = phi i32 [ 0, %if.then319 ], [ %shr299, %lor.lhs.false317.if.end320_crit_edge ]
  %52 = zext i32 %and301 to i64
  call void @__sanitizer_cov_trace_switch(i64 %52, ptr @__sancov_gen_cov_switch_values.128)
  switch i32 %and301, label %lor.lhs.false326 [
    i32 0, label %if.end320.if.then328_crit_edge
    i32 3, label %if.end320.if.then328_crit_edge551
    i32 4, label %if.end320.if.then328_crit_edge552
  ]

if.end320.if.then328_crit_edge552:                ; preds = %if.end320
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then328

if.end320.if.then328_crit_edge551:                ; preds = %if.end320
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then328

if.end320.if.then328_crit_edge:                   ; preds = %if.end320
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then328

lor.lhs.false326:                                 ; preds = %if.end320
  call void @__sanitizer_cov_trace_const_cmp4(i32 12, i32 %and301)
  %cmp327 = icmp ugt i32 %and301, 12
  br i1 %cmp327, label %lor.lhs.false326.if.then328_crit_edge, label %lor.lhs.false326.if.end329_crit_edge

lor.lhs.false326.if.end329_crit_edge:             ; preds = %lor.lhs.false326
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end329

lor.lhs.false326.if.then328_crit_edge:            ; preds = %lor.lhs.false326
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then328

if.then328:                                       ; preds = %lor.lhs.false326.if.then328_crit_edge, %if.end320.if.then328_crit_edge, %if.end320.if.then328_crit_edge551, %if.end320.if.then328_crit_edge552
  br label %if.end329

if.end329:                                        ; preds = %if.then328, %lor.lhs.false326.if.end329_crit_edge
  %dimm10_addr_map.0 = phi i32 [ 0, %if.then328 ], [ %and301, %lor.lhs.false326.if.end329_crit_edge ]
  %53 = zext i32 %shr304 to i64
  call void @__sanitizer_cov_trace_switch(i64 %53, ptr @__sancov_gen_cov_switch_values.129)
  switch i32 %shr304, label %lor.lhs.false335 [
    i32 0, label %if.end329.if.then337_crit_edge
    i32 3, label %if.end329.if.then337_crit_edge553
    i32 4, label %if.end329.if.then337_crit_edge554
  ]

if.end329.if.then337_crit_edge554:                ; preds = %if.end329
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then337

if.end329.if.then337_crit_edge553:                ; preds = %if.end329
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then337

if.end329.if.then337_crit_edge:                   ; preds = %if.end329
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then337

lor.lhs.false335:                                 ; preds = %if.end329
  call void @__sanitizer_cov_trace_const_cmp4(i32 12, i32 %shr304)
  %cmp336 = icmp ugt i32 %shr304, 12
  br i1 %cmp336, label %lor.lhs.false335.if.then337_crit_edge, label %lor.lhs.false335.if.end338_crit_edge

lor.lhs.false335.if.end338_crit_edge:             ; preds = %lor.lhs.false335
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end338

lor.lhs.false335.if.then337_crit_edge:            ; preds = %lor.lhs.false335
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then337

if.then337:                                       ; preds = %lor.lhs.false335.if.then337_crit_edge, %if.end329.if.then337_crit_edge, %if.end329.if.then337_crit_edge553, %if.end329.if.then337_crit_edge554
  br label %if.end338

if.end338:                                        ; preds = %if.then337, %lor.lhs.false335.if.end338_crit_edge
  %dimm11_addr_map.0 = phi i32 [ 0, %if.then337 ], [ %shr304, %lor.lhs.false335.if.end338_crit_edge ]
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %dimm00_addr_map.0)
  %cmp339 = icmp eq i32 %dimm00_addr_map.0, 11
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %dimm01_addr_map.0)
  %cmp341 = icmp eq i32 %dimm01_addr_map.0, 11
  %or.cond = select i1 %cmp339, i1 true, i1 %cmp341
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %dimm10_addr_map.0)
  %cmp343 = icmp eq i32 %dimm10_addr_map.0, 11
  %or.cond542 = select i1 %or.cond, i1 true, i1 %cmp343
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %dimm11_addr_map.0)
  %cmp345 = icmp eq i32 %dimm11_addr_map.0, 11
  %or.cond543 = select i1 %or.cond542, i1 true, i1 %cmp345
  %mem_row_size_in_kb = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 16
  br i1 %or.cond543, label %if.then346, label %if.else

if.then346:                                       ; preds = %if.end338
  call void @__sanitizer_cov_trace_pc() #14
  %54 = ptrtoint ptr %mem_row_size_in_kb to i32
  call void @__asan_store4_noabort(i32 %54)
  store i32 2, ptr %mem_row_size_in_kb, align 8
  br label %if.end368

if.else:                                          ; preds = %if.end338
  call void @__sanitizer_cov_trace_pc() #14
  %55 = ptrtoint ptr %mem_row_size_in_kb to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 1, ptr %mem_row_size_in_kb, align 8
  br label %if.end368

if.else353:                                       ; preds = %sw.epilog
  call void @__sanitizer_cov_trace_pc() #14
  %and354 = lshr i32 %call272, 6
  %shr355 = and i32 %and354, 3
  %add = or i32 %shr355, 8
  %mul = shl i32 4, %add
  %div541 = lshr exact i32 %mul, 10
  %mem_row_size_in_kb358 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 16
  call void @__sanitizer_cov_trace_const_cmp4(i32 4096, i32 %mul)
  %cmp362 = icmp ugt i32 %mul, 4096
  %spec.store.select = select i1 %cmp362, i32 4, i32 %div541
  %56 = ptrtoint ptr %mem_row_size_in_kb358 to i32
  call void @__asan_store4_noabort(i32 %56)
  store i32 %spec.store.select, ptr %mem_row_size_in_kb358, align 8
  br label %if.end368

if.end368:                                        ; preds = %if.else353, %if.else, %if.then346
  %shader_engine_tile_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 17
  %57 = ptrtoint ptr %shader_engine_tile_size to i32
  call void @__asan_store4_noabort(i32 %57)
  store i32 32, ptr %shader_engine_tile_size, align 4
  %num_gpus = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 18
  %58 = ptrtoint ptr %num_gpus to i32
  call void @__asan_store4_noabort(i32 %58)
  store i32 1, ptr %num_gpus, align 8
  %multi_gpu_tile_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 19
  %59 = ptrtoint ptr %multi_gpu_tile_size to i32
  call void @__asan_store4_noabort(i32 %59)
  store i32 64, ptr %multi_gpu_tile_size, align 4
  %mem_row_size_in_kb377 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 16
  %60 = ptrtoint ptr %mem_row_size_in_kb377 to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %mem_row_size_in_kb377, align 8
  %62 = zext i32 %61 to i64
  call void @__sanitizer_cov_trace_switch(i64 %62, ptr @__sancov_gen_cov_switch_values.130)
  switch i32 %61, label %sw.default379 [
    i32 4, label %if.end368.sw.epilog387_crit_edge
    i32 2, label %sw.bb381
  ]

if.end368.sw.epilog387_crit_edge:                 ; preds = %if.end368
  call void @__sanitizer_cov_trace_pc() #14
  br label %sw.epilog387

sw.default379:                                    ; preds = %if.end368
  call void @__sanitizer_cov_trace_pc() #14
  %and380 = and i32 %gb_addr_config.0, 33624067
  br label %sw.epilog387

sw.bb381:                                         ; preds = %if.end368
  call void @__sanitizer_cov_trace_pc() #14
  %and382 = and i32 %gb_addr_config.0, 33624067
  %or383 = or i32 %and382, 268435456
  br label %sw.epilog387

sw.epilog387:                                     ; preds = %sw.bb381, %sw.default379, %if.end368.sw.epilog387_crit_edge
  %gb_addr_config.1 = phi i32 [ %and380, %sw.default379 ], [ %or383, %sw.bb381 ], [ %gb_addr_config.0, %if.end368.sw.epilog387_crit_edge ]
  %gb_addr_config390 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 23
  %63 = ptrtoint ptr %gb_addr_config390 to i32
  call void @__asan_store4_noabort(i32 %63)
  store i32 %gb_addr_config.1, ptr %gb_addr_config390, align 4
  br label %cleanup

cleanup:                                          ; preds = %sw.epilog387, %sw.bb87.cleanup_crit_edge, %sw.bb65.cleanup_crit_edge
  %retval.0 = phi i32 [ 0, %sw.epilog387 ], [ %call, %sw.bb65.cleanup_crit_edge ], [ %call88, %sw.bb87.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_init_map_type(ptr noundef, ptr noundef, ptr noundef, i32 noundef, i8 noundef zeroext, i8 noundef zeroext, i8 noundef zeroext) local_unnamed_addr #2

; Function Attrs: nofree nounwind null_pointer_is_valid
declare dso_local noundef i32 @snprintf(ptr noalias nocapture noundef writeonly, i32 noundef, ptr nocapture noundef readonly, ...) local_unnamed_addr #6

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @request_firmware(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ucode_validate(ptr noundef) local_unnamed_addr #2

; Function Attrs: cold null_pointer_is_valid
declare dso_local void @_dev_err(ptr noundef, ptr noundef, ...) local_unnamed_addr #5

; Function Attrs: null_pointer_is_valid
declare dso_local void @release_firmware(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid allocsize(0)
declare dso_local noalias ptr @__kmalloc(i32 noundef, i32 noundef) local_unnamed_addr #11

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #10

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_compute_queue_acquire(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_bo_create_reserved(ptr noundef, i32 noundef, i32 noundef, i32 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: cold null_pointer_is_valid
declare dso_local void @_dev_warn(ptr noundef, ptr noundef, ...) local_unnamed_addr #5

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_bo_kunmap(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @ttm_bo_move_to_lru_tail(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @dma_resv_reset_shared_max(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @ww_mutex_unlock(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @amdgpu_gfx_is_high_priority_compute_queue(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_atombios_get_gfx_info(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_ring_fini(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_mqd_sw_fini(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_kiq_free_ring(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_kiq_fini(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_rlc_fini(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_bo_free_kernel(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_device_program_register_sequence(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_atombios_i2c_channel_trans(ptr noundef, i8 noundef zeroext, i8 noundef zeroext, i8 noundef zeroext, i8 noundef zeroext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__sw_hweight32(i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @warn_slowpath_fmt(ptr noundef, i32 noundef, i32 noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_parse_disable_cu(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_kiq_resume(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %ring1 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3
  %mqd_obj = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 19
  %0 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %mqd_obj, align 4
  %bdev.i = getelementptr inbounds %struct.amdgpu_bo, ptr %1, i32 0, i32 4, i32 1
  %2 = ptrtoint ptr %bdev.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %bdev.i, align 8
  %resv32.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %1, i32 0, i32 4, i32 0, i32 9
  %4 = ptrtoint ptr %resv32.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %resv32.i.i, align 8
  %call.i.i.i = tail call i32 @ww_mutex_lock_interruptible(ptr noundef %5, ptr noundef null) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -4, i32 %call.i.i.i)
  %cmp.i.i = icmp eq i32 %call.i.i.i, -4
  %retval.1.i.i = select i1 %cmp.i.i, i32 -512, i32 %call.i.i.i
  %6 = zext i32 %retval.1.i.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %6, ptr @__sancov_gen_cov_switch_values.131)
  switch i32 %retval.1.i.i, label %do.end.i [
    i32 0, label %if.end
    i32 -512, label %entry.cleanup_crit_edge
  ], !prof !450

entry.cleanup_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

do.end.i:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %add.ptr.i.i = getelementptr i8, ptr %3, i32 -17736
  %7 = ptrtoint ptr %add.ptr.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %add.ptr.i.i, align 8
  tail call void (ptr, ptr, ...) @_dev_err(ptr noundef %8, ptr noundef nonnull @.str.78, ptr noundef %1) #15
  br label %cleanup

if.end:                                           ; preds = %entry
  %9 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %mqd_obj, align 4
  %mqd_ptr = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 21
  %call4 = tail call i32 @amdgpu_bo_kmap(ptr noundef %10, ptr noundef %mqd_ptr) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call4)
  %cmp5.not = icmp eq i32 %call4, 0
  br i1 %cmp5.not, label %if.end13, label %if.end.cleanup_crit_edge, !prof !435

if.end.cleanup_crit_edge:                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %cleanup

if.end13:                                         ; preds = %if.end
  %11 = ptrtoint ptr %ring1 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %ring1, align 8
  %13 = ptrtoint ptr %mqd_ptr to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %mqd_ptr, align 8
  %call.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %12, i32 noundef 60586, i32 noundef 0) #12
  %and.i.i = and i32 %call.i.i, -256
  %me.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 16
  %15 = ptrtoint ptr %me.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %me.i.i, align 8
  %shl.i.i = shl i32 %16, 5
  %pipe.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 17
  %17 = ptrtoint ptr %pipe.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %pipe.i.i, align 4
  %shl2.i.i = shl i32 %18, 3
  %queue.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 18
  %19 = ptrtoint ptr %queue.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %queue.i.i, align 8
  %or.i.i = or i32 %shl.i.i, %and.i.i
  %or3.i.i = or i32 %or.i.i, %shl2.i.i
  %or4.i.i = or i32 %or3.i.i, %20
  tail call void @amdgpu_device_wreg(ptr noundef %12, i32 noundef 60586, i32 noundef %or4.i.i, i32 noundef 0) #12
  %or5.i.i = or i32 %or4.i.i, 128
  tail call void @amdgpu_device_wreg(ptr noundef %12, i32 noundef 60586, i32 noundef %or5.i.i, i32 noundef 0) #12
  %in_gpu_reset.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %12, i32 0, i32 141
  %call.i.i.i.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %in_gpu_reset.i.i, i32 noundef 4) #12
  %21 = ptrtoint ptr %in_gpu_reset.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %in_gpu_reset.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %22)
  %tobool.not.i = icmp eq i32 %22, 0
  br i1 %tobool.not.i, label %if.else.i, label %if.then.i

if.then.i:                                        ; preds = %if.end13
  %arrayidx.i = getelementptr %struct.amdgpu_device, ptr %12, i32 0, i32 106, i32 6, i32 7, i32 8
  %23 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %arrayidx.i, align 4
  %tobool2.not.i = icmp eq ptr %24, null
  br i1 %tobool2.not.i, label %if.then.i.if.end.i_crit_edge, label %if.then3.i

if.then.i.if.end.i_crit_edge:                     ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end.i

if.then3.i:                                       ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  %25 = call ptr @memcpy(ptr %14, ptr %24, i32 2064)
  br label %if.end.i

if.end.i:                                         ; preds = %if.then3.i, %if.then.i.if.end.i_crit_edge
  %wptr.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 7
  %26 = ptrtoint ptr %wptr.i to i32
  call void @__asan_store8_noabort(i32 %26)
  store i64 0, ptr %wptr.i, align 8
  %buf_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 14
  %funcs.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 1
  %ring1.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 5
  br label %while.body.i.i

while.body.i.i:                                   ; preds = %while.body.i.i.while.body.i.i_crit_edge, %if.end.i
  %i.05.i.i = phi i32 [ 0, %if.end.i ], [ %inc.i.i, %while.body.i.i.while.body.i.i_crit_edge ]
  %27 = ptrtoint ptr %funcs.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %funcs.i.i, align 4
  %nop.i.i = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %28, i32 0, i32 2
  %29 = ptrtoint ptr %nop.i.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %nop.i.i, align 4
  %31 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %ring1.i.i, align 4
  %inc.i.i = add i32 %i.05.i.i, 1
  %arrayidx.i.i = getelementptr i32, ptr %32, i32 %i.05.i.i
  %33 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %33)
  store volatile i32 %30, ptr %arrayidx.i.i, align 4
  %34 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %buf_mask.i.i, align 8
  %cmp.not.i.i = icmp ugt i32 %inc.i.i, %35
  br i1 %cmp.not.i.i, label %amdgpu_ring_clear_ring.exit.i, label %while.body.i.i.while.body.i.i_crit_edge

while.body.i.i.while.body.i.i_crit_edge:          ; preds = %while.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %while.body.i.i

amdgpu_ring_clear_ring.exit.i:                    ; preds = %while.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  %srbm_mutex.i = getelementptr inbounds %struct.amdgpu_device, ptr %12, i32 0, i32 20
  tail call void @mutex_lock_nested(ptr noundef %srbm_mutex.i, i32 noundef 0) #12
  %36 = ptrtoint ptr %me.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %me.i.i, align 8
  %38 = ptrtoint ptr %pipe.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %pipe.i.i, align 4
  %40 = ptrtoint ptr %queue.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %queue.i.i, align 8
  tail call void @vi_srbm_select(ptr noundef %12, i32 noundef %37, i32 noundef %39, i32 noundef %41, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_mqd_commit(ptr noundef %12, ptr noundef %14) #12
  tail call void @vi_srbm_select(ptr noundef %12, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %srbm_mutex.i) #12
  br label %gfx_v8_0_kiq_init_queue.exit

if.else.i:                                        ; preds = %if.end13
  %42 = call ptr @memset(ptr %14, i32 0, i32 2056)
  %dynamic_cu_mask.i = getelementptr inbounds %struct.vi_mqd_allocation, ptr %14, i32 0, i32 3
  %43 = ptrtoint ptr %dynamic_cu_mask.i to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 -1, ptr %dynamic_cu_mask.i, align 4
  %dynamic_rb_mask.i = getelementptr inbounds %struct.vi_mqd_allocation, ptr %14, i32 0, i32 4
  %44 = ptrtoint ptr %dynamic_rb_mask.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 -1, ptr %dynamic_rb_mask.i, align 4
  %srbm_mutex10.i = getelementptr inbounds %struct.amdgpu_device, ptr %12, i32 0, i32 20
  tail call void @mutex_lock_nested(ptr noundef %srbm_mutex10.i, i32 noundef 0) #12
  %45 = ptrtoint ptr %me.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %me.i.i, align 8
  %47 = ptrtoint ptr %pipe.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %pipe.i.i, align 4
  %49 = ptrtoint ptr %queue.i.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %queue.i.i, align 8
  tail call void @vi_srbm_select(ptr noundef %12, i32 noundef %46, i32 noundef %48, i32 noundef %50, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_mqd_init(ptr noundef %ring1) #12
  tail call fastcc void @gfx_v8_0_mqd_commit(ptr noundef %12, ptr noundef %14) #12
  tail call void @vi_srbm_select(ptr noundef %12, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %srbm_mutex10.i) #12
  %arrayidx20.i = getelementptr %struct.amdgpu_device, ptr %12, i32 0, i32 106, i32 6, i32 7, i32 8
  %51 = ptrtoint ptr %arrayidx20.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %arrayidx20.i, align 4
  %tobool21.not.i = icmp eq ptr %52, null
  br i1 %tobool21.not.i, label %if.else.i.gfx_v8_0_kiq_init_queue.exit_crit_edge, label %if.then22.i

if.else.i.gfx_v8_0_kiq_init_queue.exit_crit_edge: ; preds = %if.else.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_kiq_init_queue.exit

if.then22.i:                                      ; preds = %if.else.i
  call void @__sanitizer_cov_trace_pc() #14
  %53 = call ptr @memcpy(ptr %52, ptr %14, i32 2064)
  br label %gfx_v8_0_kiq_init_queue.exit

gfx_v8_0_kiq_init_queue.exit:                     ; preds = %if.then22.i, %if.else.i.gfx_v8_0_kiq_init_queue.exit_crit_edge, %amdgpu_ring_clear_ring.exit.i
  %54 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %mqd_obj, align 4
  tail call void @amdgpu_bo_kunmap(ptr noundef %55) #12
  %56 = ptrtoint ptr %mqd_ptr to i32
  call void @__asan_store4_noabort(i32 %56)
  store ptr null, ptr %mqd_ptr, align 8
  %57 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load ptr, ptr %mqd_obj, align 4
  %tbo.i = getelementptr inbounds %struct.amdgpu_bo, ptr %58, i32 0, i32 4
  %bdev.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %58, i32 0, i32 4, i32 1
  %59 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %60, i32 0, i32 6
  tail call void @_raw_spin_lock(ptr noundef %lru_lock.i.i.i) #12
  %resource.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %58, i32 0, i32 4, i32 6
  %61 = ptrtoint ptr %resource.i.i.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load ptr, ptr %resource.i.i.i, align 4
  tail call void @ttm_bo_move_to_lru_tail(ptr noundef %tbo.i, ptr noundef %62, ptr noundef null) #12
  %63 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock2.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %64, i32 0, i32 6
  tail call void @_raw_spin_unlock(ptr noundef %lru_lock2.i.i.i) #12
  %resv.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %58, i32 0, i32 4, i32 0, i32 9
  %65 = ptrtoint ptr %resv.i.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %resv.i.i, align 8
  tail call void @dma_resv_reset_shared_max(ptr noundef %66) #12
  tail call void @ww_mutex_unlock(ptr noundef %66) #12
  %ready = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 3, i32 17
  %67 = ptrtoint ptr %ready to i32
  call void @__asan_store1_noabort(i32 %67)
  store i8 1, ptr %ready, align 4
  br label %cleanup

cleanup:                                          ; preds = %gfx_v8_0_kiq_init_queue.exit, %if.end.cleanup_crit_edge, %do.end.i, %entry.cleanup_crit_edge
  %retval.0 = phi i32 [ 0, %gfx_v8_0_kiq_init_queue.exit ], [ %retval.1.i.i, %do.end.i ], [ %call4, %if.end.cleanup_crit_edge ], [ %retval.1.i.i, %entry.cleanup_crit_edge ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_cp_gfx_resume(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8641, i32 noundef 0, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12369, i32 noundef 0, i32 noundef 0) #12
  %ring_size = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 9
  %0 = ptrtoint ptr %ring_size to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %ring_size, align 8
  %div1 = lshr i32 %1, 3
  call void @__sanitizer_cov_trace_const_cmp4(i32 15, i32 %1)
  %cmp.i = icmp ugt i32 %1, 15
  %sub.i2 = add nsw i32 %div1, -1
  %2 = tail call i32 @llvm.ctlz.i32(i32 %sub.i2, i1 false) #12, !range !451
  %add.i = sub nuw nsw i32 32, %2
  %cond33 = select i1 %cmp.i, i32 %add.i, i32 0
  %gfx_ring = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36
  %and = and i32 %cond33, 63
  %sub35 = shl nsw i32 %cond33, 8
  %shl36 = add nsw i32 %sub35, 15872
  %and37 = and i32 %shl36, 16128
  %or38 = or i32 %and37, %and
  %or44 = or i32 %or38, 4423680
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12353, i32 noundef %or44, i32 noundef 0) #12
  %or45 = or i32 %or38, -2143059968
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12353, i32 noundef %or45, i32 noundef 0) #12
  %wptr = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 7
  %3 = ptrtoint ptr %wptr to i32
  call void @__asan_store8_noabort(i32 %3)
  store i64 0, ptr %wptr, align 8
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12357, i32 noundef 0, i32 noundef 0) #12
  %gpu_addr = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 70, i32 2
  %4 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %gpu_addr, align 8
  %rptr_offs = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 6
  %6 = ptrtoint ptr %rptr_offs to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %rptr_offs, align 8
  %mul = shl i32 %7, 2
  %conv49 = zext i32 %mul to i64
  %add50 = add i64 %5, %conv49
  %conv52 = trunc i64 %add50 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12355, i32 noundef %conv52, i32 noundef 0) #12
  %shr = lshr i64 %add50, 32
  %conv54 = trunc i64 %shr to i32
  %and55 = and i32 %conv54, 255
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12356, i32 noundef %and55, i32 noundef 0) #12
  %8 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %gpu_addr, align 8
  %wptr_offs = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 26
  %10 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %wptr_offs, align 8
  %mul58 = shl i32 %11, 2
  %conv59 = zext i32 %mul58 to i64
  %add60 = add i64 %9, %conv59
  %conv62 = trunc i64 %add60 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12358, i32 noundef %conv62, i32 noundef 0) #12
  %shr63 = lshr i64 %add60, 32
  %conv65 = trunc i64 %shr63 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12359, i32 noundef %conv65, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %12 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %12(i32 noundef 214748000) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12353, i32 noundef %or44, i32 noundef 0) #12
  %gpu_addr66 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 12
  %13 = ptrtoint ptr %gpu_addr66 to i32
  call void @__asan_load8_noabort(i32 %13)
  %14 = load i64, ptr %gpu_addr66, align 8
  %shr67 = lshr i64 %14, 8
  %conv68 = trunc i64 %shr67 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12352, i32 noundef %conv68, i32 noundef 0) #12
  %shr69 = lshr i64 %14, 40
  %conv71 = trunc i64 %shr69 to i32
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12465, i32 noundef %conv71, i32 noundef 0) #12
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %15 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 10, i32 %16)
  %cmp.i3 = icmp eq i32 %16, 10
  br i1 %cmp.i3, label %entry.gfx_v8_0_set_cpg_door_bell.exit_crit_edge, label %if.end.i

entry.gfx_v8_0_set_cpg_door_bell.exit_crit_edge:  ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_set_cpg_door_bell.exit

if.end.i:                                         ; preds = %entry
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12377, i32 noundef 0) #12
  %use_doorbell.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 24
  %17 = ptrtoint ptr %use_doorbell.i to i32
  call void @__asan_load1_noabort(i32 %17)
  %18 = load i8, ptr %use_doorbell.i, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %18)
  %tobool.not.i = icmp eq i8 %18, 0
  br i1 %tobool.not.i, label %if.else.i, label %if.then1.i

if.then1.i:                                       ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  %and.i = and i32 %call.i, 1065353219
  %doorbell_index.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 23
  %19 = ptrtoint ptr %doorbell_index.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %doorbell_index.i, align 8
  %shl.i = shl i32 %20, 2
  %and2.i = and i32 %shl.i, 8388604
  %or.i = or i32 %and.i, %and2.i
  %or6.i = or i32 %or.i, 1073741824
  br label %if.end9.i

if.else.i:                                        ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  %and7.i = and i32 %call.i, -1073741825
  br label %if.end9.i

if.end9.i:                                        ; preds = %if.else.i, %if.then1.i
  %tmp.0.i = phi i32 [ %or6.i, %if.then1.i ], [ %and7.i, %if.else.i ]
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12377, i32 noundef %tmp.0.i, i32 noundef 0) #12
  %flags.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 9
  %21 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %flags.i, align 8
  %and10.i = and i32 %22, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and10.i)
  %tobool11.not.i = icmp eq i32 %and10.i, 0
  br i1 %tobool11.not.i, label %if.end13.i, label %if.end9.i.gfx_v8_0_set_cpg_door_bell.exit_crit_edge

if.end9.i.gfx_v8_0_set_cpg_door_bell.exit_crit_edge: ; preds = %if.end9.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_set_cpg_door_bell.exit

if.end13.i:                                       ; preds = %if.end9.i
  call void @__sanitizer_cov_trace_pc() #14
  %gfx_ring0.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 144, i32 11
  %23 = ptrtoint ptr %gfx_ring0.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %gfx_ring0.i, align 4
  %shl15.i = shl i32 %24, 2
  %and16.i = and i32 %shl15.i, 8388604
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12378, i32 noundef %and16.i, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12379, i32 noundef 8388604, i32 noundef 0) #12
  br label %gfx_v8_0_set_cpg_door_bell.exit

gfx_v8_0_set_cpg_door_bell.exit:                  ; preds = %if.end13.i, %if.end9.i.gfx_v8_0_set_cpg_door_bell.exit_crit_edge, %entry.gfx_v8_0_set_cpg_door_bell.exit_crit_edge
  %buf_mask.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 14
  %funcs.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 1
  %ring1.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 5
  br label %while.body.i

while.body.i:                                     ; preds = %while.body.i.while.body.i_crit_edge, %gfx_v8_0_set_cpg_door_bell.exit
  %i.05.i = phi i32 [ 0, %gfx_v8_0_set_cpg_door_bell.exit ], [ %inc.i, %while.body.i.while.body.i_crit_edge ]
  %25 = ptrtoint ptr %funcs.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %funcs.i, align 4
  %nop.i = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %26, i32 0, i32 2
  %27 = ptrtoint ptr %nop.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %nop.i, align 4
  %29 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %ring1.i, align 4
  %inc.i = add i32 %i.05.i, 1
  %arrayidx.i = getelementptr i32, ptr %30, i32 %i.05.i
  %31 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %31)
  store volatile i32 %28, ptr %arrayidx.i, align 4
  %32 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %buf_mask.i, align 8
  %cmp.not.i = icmp ugt i32 %inc.i, %33
  br i1 %cmp.not.i, label %amdgpu_ring_clear_ring.exit, label %while.body.i.while.body.i_crit_edge

while.body.i.while.body.i_crit_edge:              ; preds = %while.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %while.body.i

amdgpu_ring_clear_ring.exit:                      ; preds = %while.body.i
  %max_hw_contexts.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 8
  %34 = ptrtoint ptr %max_hw_contexts.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %max_hw_contexts.i, align 8
  %sub.i4 = add i32 %35, -1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12462, i32 noundef %sub.i4, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12368, i32 noundef 0, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12363, i32 noundef 1, i32 noundef 0) #12
  %call.i.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 8630, i32 noundef 0) #12
  %and3.i.i = and i32 %call.i.i, -352321537
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8630, i32 noundef %and3.i.i, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %36 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %36(i32 noundef 10737400) #12
  %call2.i = tail call i32 @amdgpu_ring_alloc(ptr noundef %gfx_ring, i32 noundef 916) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2.i)
  %tobool.not.i5 = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i5, label %if.end.i6, label %if.then.i

if.then.i:                                        ; preds = %amdgpu_ring_clear_ring.exit
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.82, i32 noundef %call2.i) #12
  br label %gfx_v8_0_cp_gfx_start.exit

if.end.i6:                                        ; preds = %amdgpu_ring_clear_ring.exit
  %count_dw.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 11
  %37 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %38)
  %cmp.i.i = icmp slt i32 %38, 1
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i6.amdgpu_ring_write.exit.i_crit_edge

if.end.i6.amdgpu_ring_write.exit.i_crit_edge:     ; preds = %if.end.i6
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i

if.then.i.i:                                      ; preds = %if.end.i6
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i

amdgpu_ring_write.exit.i:                         ; preds = %if.then.i.i, %if.end.i6.amdgpu_ring_write.exit.i_crit_edge
  %39 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %ring1.i, align 4
  %41 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %41)
  %42 = load i64, ptr %wptr, align 8
  %inc.i.i = add i64 %42, 1
  store i64 %inc.i.i, ptr %wptr, align 8
  %43 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %buf_mask.i, align 8
  %45 = trunc i64 %42 to i32
  %idxprom.i.i = and i32 %44, %45
  %arrayidx.i.i = getelementptr i32, ptr %40, i32 %idxprom.i.i
  %46 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %46)
  store volatile i32 -1073722880, ptr %arrayidx.i.i, align 4
  %ptr_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 13
  %47 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %47)
  %48 = load i64, ptr %ptr_mask.i.i, align 8
  %49 = load i64, ptr %wptr, align 8
  %and3.i1.i = and i64 %49, %48
  store i64 %and3.i1.i, ptr %wptr, align 8
  %50 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %count_dw.i.i, align 8
  %dec.i.i = add i32 %51, -1
  store i32 %dec.i.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i)
  %cmp.i3.i = icmp slt i32 %dec.i.i, 1
  br i1 %cmp.i3.i, label %if.then.i4.i, label %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit14.i_crit_edge

amdgpu_ring_write.exit.i.amdgpu_ring_write.exit14.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit14.i

if.then.i4.i:                                     ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit14.i

amdgpu_ring_write.exit14.i:                       ; preds = %if.then.i4.i, %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit14.i_crit_edge
  %52 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %ring1.i, align 4
  %54 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %54)
  %55 = load i64, ptr %wptr, align 8
  %inc.i7.i = add i64 %55, 1
  store i64 %inc.i7.i, ptr %wptr, align 8
  %56 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %buf_mask.i, align 8
  %58 = trunc i64 %55 to i32
  %idxprom.i9.i = and i32 %57, %58
  %arrayidx.i10.i = getelementptr i32, ptr %53, i32 %idxprom.i9.i
  %59 = ptrtoint ptr %arrayidx.i10.i to i32
  call void @__asan_store4_noabort(i32 %59)
  store volatile i32 536870912, ptr %arrayidx.i10.i, align 4
  %60 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %60)
  %61 = load i64, ptr %ptr_mask.i.i, align 8
  %62 = load i64, ptr %wptr, align 8
  %and3.i12.i = and i64 %62, %61
  store i64 %and3.i12.i, ptr %wptr, align 8
  %63 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load i32, ptr %count_dw.i.i, align 8
  %dec.i13.i = add i32 %64, -1
  store i32 %dec.i13.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i13.i)
  %cmp.i16.i = icmp slt i32 %dec.i13.i, 1
  br i1 %cmp.i16.i, label %if.then.i17.i, label %amdgpu_ring_write.exit14.i.amdgpu_ring_write.exit27.i_crit_edge

amdgpu_ring_write.exit14.i.amdgpu_ring_write.exit27.i_crit_edge: ; preds = %amdgpu_ring_write.exit14.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit27.i

if.then.i17.i:                                    ; preds = %amdgpu_ring_write.exit14.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit27.i

amdgpu_ring_write.exit27.i:                       ; preds = %if.then.i17.i, %amdgpu_ring_write.exit14.i.amdgpu_ring_write.exit27.i_crit_edge
  %65 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %ring1.i, align 4
  %67 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %67)
  %68 = load i64, ptr %wptr, align 8
  %inc.i20.i = add i64 %68, 1
  store i64 %inc.i20.i, ptr %wptr, align 8
  %69 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %buf_mask.i, align 8
  %71 = trunc i64 %68 to i32
  %idxprom.i22.i = and i32 %70, %71
  %arrayidx.i23.i = getelementptr i32, ptr %66, i32 %idxprom.i22.i
  %72 = ptrtoint ptr %arrayidx.i23.i to i32
  call void @__asan_store4_noabort(i32 %72)
  store volatile i32 -1073666048, ptr %arrayidx.i23.i, align 4
  %73 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %73)
  %74 = load i64, ptr %ptr_mask.i.i, align 8
  %75 = load i64, ptr %wptr, align 8
  %and3.i25.i = and i64 %75, %74
  store i64 %and3.i25.i, ptr %wptr, align 8
  %76 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load i32, ptr %count_dw.i.i, align 8
  %dec.i26.i = add i32 %77, -1
  store i32 %dec.i26.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i26.i)
  %cmp.i29.i = icmp slt i32 %dec.i26.i, 1
  br i1 %cmp.i29.i, label %if.then.i30.i, label %amdgpu_ring_write.exit27.i.amdgpu_ring_write.exit40.i_crit_edge

amdgpu_ring_write.exit27.i.amdgpu_ring_write.exit40.i_crit_edge: ; preds = %amdgpu_ring_write.exit27.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit40.i

if.then.i30.i:                                    ; preds = %amdgpu_ring_write.exit27.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit40.i

amdgpu_ring_write.exit40.i:                       ; preds = %if.then.i30.i, %amdgpu_ring_write.exit27.i.amdgpu_ring_write.exit40.i_crit_edge
  %78 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load ptr, ptr %ring1.i, align 4
  %80 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %80)
  %81 = load i64, ptr %wptr, align 8
  %inc.i33.i = add i64 %81, 1
  store i64 %inc.i33.i, ptr %wptr, align 8
  %82 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load i32, ptr %buf_mask.i, align 8
  %84 = trunc i64 %81 to i32
  %idxprom.i35.i = and i32 %83, %84
  %arrayidx.i36.i = getelementptr i32, ptr %79, i32 %idxprom.i35.i
  %85 = ptrtoint ptr %arrayidx.i36.i to i32
  call void @__asan_store4_noabort(i32 %85)
  store volatile i32 -2147483648, ptr %arrayidx.i36.i, align 4
  %86 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %86)
  %87 = load i64, ptr %ptr_mask.i.i, align 8
  %88 = load i64, ptr %wptr, align 8
  %and3.i38.i = and i64 %88, %87
  store i64 %and3.i38.i, ptr %wptr, align 8
  %89 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load i32, ptr %count_dw.i.i, align 8
  %dec.i39.i = add i32 %90, -1
  store i32 %dec.i39.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i39.i)
  %cmp.i42.i = icmp slt i32 %dec.i39.i, 1
  br i1 %cmp.i42.i, label %if.then.i43.i, label %amdgpu_ring_write.exit40.i.for.body6.lr.ph.i_crit_edge

amdgpu_ring_write.exit40.i.for.body6.lr.ph.i_crit_edge: ; preds = %amdgpu_ring_write.exit40.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body6.lr.ph.i

if.then.i43.i:                                    ; preds = %amdgpu_ring_write.exit40.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %for.body6.lr.ph.i

for.body6.lr.ph.i:                                ; preds = %if.then.i43.i, %amdgpu_ring_write.exit40.i.for.body6.lr.ph.i_crit_edge
  %91 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load ptr, ptr %ring1.i, align 4
  %93 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %93)
  %94 = load i64, ptr %wptr, align 8
  %inc.i46.i = add i64 %94, 1
  store i64 %inc.i46.i, ptr %wptr, align 8
  %95 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %95)
  %96 = load i32, ptr %buf_mask.i, align 8
  %97 = trunc i64 %94 to i32
  %idxprom.i48.i = and i32 %96, %97
  %arrayidx.i49.i = getelementptr i32, ptr %92, i32 %idxprom.i48.i
  %98 = ptrtoint ptr %arrayidx.i49.i to i32
  call void @__asan_store4_noabort(i32 %98)
  store volatile i32 -2147483648, ptr %arrayidx.i49.i, align 4
  %99 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %99)
  %100 = load i64, ptr %ptr_mask.i.i, align 8
  %101 = load i64, ptr %wptr, align 8
  %and3.i51.i = and i64 %101, %100
  store i64 %and3.i51.i, ptr %wptr, align 8
  %102 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %102)
  %103 = load i32, ptr %count_dw.i.i, align 8
  %dec.i52.i = add i32 %103, -1
  store i32 %dec.i52.i, ptr %count_dw.i.i, align 8
  br label %if.then8.i

if.then8.i:                                       ; preds = %for.inc17.i.if.then8.i_crit_edge, %for.body6.lr.ph.i
  %104 = phi i32 [ %dec.i52.i, %for.body6.lr.ph.i ], [ %157, %for.inc17.i.if.then8.i_crit_edge ]
  %ext.0252.i = phi ptr [ @vi_SECT_CONTEXT_defs, %for.body6.lr.ph.i ], [ %incdec.ptr.i, %for.inc17.i.if.then8.i_crit_edge ]
  %reg_count.i = getelementptr inbounds %struct.cs_extent_def, ptr %ext.0252.i, i32 0, i32 2
  %105 = ptrtoint ptr %reg_count.i to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load i32, ptr %reg_count.i, align 4
  %and.i7 = shl i32 %106, 16
  %or.i8 = or i32 %and.i7, -1073714944
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %104)
  %cmp.i55.i = icmp slt i32 %104, 1
  br i1 %cmp.i55.i, label %if.then.i56.i, label %if.then8.i.amdgpu_ring_write.exit66.i_crit_edge

if.then8.i.amdgpu_ring_write.exit66.i_crit_edge:  ; preds = %if.then8.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit66.i

if.then.i56.i:                                    ; preds = %if.then8.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit66.i

amdgpu_ring_write.exit66.i:                       ; preds = %if.then.i56.i, %if.then8.i.amdgpu_ring_write.exit66.i_crit_edge
  %107 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load ptr, ptr %ring1.i, align 4
  %109 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %109)
  %110 = load i64, ptr %wptr, align 8
  %inc.i59.i = add i64 %110, 1
  store i64 %inc.i59.i, ptr %wptr, align 8
  %111 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load i32, ptr %buf_mask.i, align 8
  %113 = trunc i64 %110 to i32
  %idxprom.i61.i = and i32 %112, %113
  %arrayidx.i62.i = getelementptr i32, ptr %108, i32 %idxprom.i61.i
  %114 = ptrtoint ptr %arrayidx.i62.i to i32
  call void @__asan_store4_noabort(i32 %114)
  store volatile i32 %or.i8, ptr %arrayidx.i62.i, align 4
  %115 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %115)
  %116 = load i64, ptr %ptr_mask.i.i, align 8
  %117 = load i64, ptr %wptr, align 8
  %and3.i64.i = and i64 %117, %116
  store i64 %and3.i64.i, ptr %wptr, align 8
  %118 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %118)
  %119 = load i32, ptr %count_dw.i.i, align 8
  %dec.i65.i = add i32 %119, -1
  store i32 %dec.i65.i, ptr %count_dw.i.i, align 8
  %reg_index.i = getelementptr inbounds %struct.cs_extent_def, ptr %ext.0252.i, i32 0, i32 1
  %120 = ptrtoint ptr %reg_index.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load i32, ptr %reg_index.i, align 4
  %sub9.i = add i32 %121, -40960
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i65.i)
  %cmp.i68.i = icmp slt i32 %dec.i65.i, 1
  br i1 %cmp.i68.i, label %if.then.i69.i, label %amdgpu_ring_write.exit66.i.amdgpu_ring_write.exit79.i_crit_edge

amdgpu_ring_write.exit66.i.amdgpu_ring_write.exit79.i_crit_edge: ; preds = %amdgpu_ring_write.exit66.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit79.i

if.then.i69.i:                                    ; preds = %amdgpu_ring_write.exit66.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit79.i

amdgpu_ring_write.exit79.i:                       ; preds = %if.then.i69.i, %amdgpu_ring_write.exit66.i.amdgpu_ring_write.exit79.i_crit_edge
  %122 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load ptr, ptr %ring1.i, align 4
  %124 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %124)
  %125 = load i64, ptr %wptr, align 8
  %inc.i72.i = add i64 %125, 1
  store i64 %inc.i72.i, ptr %wptr, align 8
  %126 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load i32, ptr %buf_mask.i, align 8
  %128 = trunc i64 %125 to i32
  %idxprom.i74.i = and i32 %127, %128
  %arrayidx.i75.i = getelementptr i32, ptr %123, i32 %idxprom.i74.i
  %129 = ptrtoint ptr %arrayidx.i75.i to i32
  call void @__asan_store4_noabort(i32 %129)
  store volatile i32 %sub9.i, ptr %arrayidx.i75.i, align 4
  %130 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %130)
  %131 = load i64, ptr %ptr_mask.i.i, align 8
  %132 = load i64, ptr %wptr, align 8
  %and3.i77.i = and i64 %132, %131
  store i64 %and3.i77.i, ptr %wptr, align 8
  %133 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %133)
  %134 = load i32, ptr %count_dw.i.i, align 8
  %dec.i78.i = add i32 %134, -1
  store i32 %dec.i78.i, ptr %count_dw.i.i, align 8
  %135 = ptrtoint ptr %reg_count.i to i32
  call void @__asan_load4_noabort(i32 %135)
  %136 = load i32, ptr %reg_count.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %136)
  %cmp12249.not.i = icmp eq i32 %136, 0
  br i1 %cmp12249.not.i, label %amdgpu_ring_write.exit79.i.for.inc17.i_crit_edge, label %amdgpu_ring_write.exit79.i.for.body13.i_crit_edge

amdgpu_ring_write.exit79.i.for.body13.i_crit_edge: ; preds = %amdgpu_ring_write.exit79.i
  br label %for.body13.i

amdgpu_ring_write.exit79.i.for.inc17.i_crit_edge: ; preds = %amdgpu_ring_write.exit79.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc17.i

for.body13.i:                                     ; preds = %amdgpu_ring_write.exit92.i.for.body13.i_crit_edge, %amdgpu_ring_write.exit79.i.for.body13.i_crit_edge
  %137 = phi i32 [ %dec.i91.i, %amdgpu_ring_write.exit92.i.for.body13.i_crit_edge ], [ %dec.i78.i, %amdgpu_ring_write.exit79.i.for.body13.i_crit_edge ]
  %i.0250.i = phi i32 [ %inc.i9, %amdgpu_ring_write.exit92.i.for.body13.i_crit_edge ], [ 0, %amdgpu_ring_write.exit79.i.for.body13.i_crit_edge ]
  %138 = ptrtoint ptr %ext.0252.i to i32
  call void @__asan_load4_noabort(i32 %138)
  %139 = load ptr, ptr %ext.0252.i, align 4
  %arrayidx15.i = getelementptr i32, ptr %139, i32 %i.0250.i
  %140 = ptrtoint ptr %arrayidx15.i to i32
  call void @__asan_load4_noabort(i32 %140)
  %141 = load i32, ptr %arrayidx15.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %137)
  %cmp.i81.i = icmp slt i32 %137, 1
  br i1 %cmp.i81.i, label %if.then.i82.i, label %for.body13.i.amdgpu_ring_write.exit92.i_crit_edge

for.body13.i.amdgpu_ring_write.exit92.i_crit_edge: ; preds = %for.body13.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit92.i

if.then.i82.i:                                    ; preds = %for.body13.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit92.i

amdgpu_ring_write.exit92.i:                       ; preds = %if.then.i82.i, %for.body13.i.amdgpu_ring_write.exit92.i_crit_edge
  %142 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %142)
  %143 = load ptr, ptr %ring1.i, align 4
  %144 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %144)
  %145 = load i64, ptr %wptr, align 8
  %inc.i85.i = add i64 %145, 1
  store i64 %inc.i85.i, ptr %wptr, align 8
  %146 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %146)
  %147 = load i32, ptr %buf_mask.i, align 8
  %148 = trunc i64 %145 to i32
  %idxprom.i87.i = and i32 %147, %148
  %arrayidx.i88.i = getelementptr i32, ptr %143, i32 %idxprom.i87.i
  %149 = ptrtoint ptr %arrayidx.i88.i to i32
  call void @__asan_store4_noabort(i32 %149)
  store volatile i32 %141, ptr %arrayidx.i88.i, align 4
  %150 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %150)
  %151 = load i64, ptr %ptr_mask.i.i, align 8
  %152 = load i64, ptr %wptr, align 8
  %and3.i90.i = and i64 %152, %151
  store i64 %and3.i90.i, ptr %wptr, align 8
  %153 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %153)
  %154 = load i32, ptr %count_dw.i.i, align 8
  %dec.i91.i = add i32 %154, -1
  store i32 %dec.i91.i, ptr %count_dw.i.i, align 8
  %inc.i9 = add nuw i32 %i.0250.i, 1
  %155 = ptrtoint ptr %reg_count.i to i32
  call void @__asan_load4_noabort(i32 %155)
  %156 = load i32, ptr %reg_count.i, align 4
  %cmp12.i = icmp ult i32 %inc.i9, %156
  br i1 %cmp12.i, label %amdgpu_ring_write.exit92.i.for.body13.i_crit_edge, label %amdgpu_ring_write.exit92.i.for.inc17.i_crit_edge

amdgpu_ring_write.exit92.i.for.inc17.i_crit_edge: ; preds = %amdgpu_ring_write.exit92.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc17.i

amdgpu_ring_write.exit92.i.for.body13.i_crit_edge: ; preds = %amdgpu_ring_write.exit92.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body13.i

for.inc17.i:                                      ; preds = %amdgpu_ring_write.exit92.i.for.inc17.i_crit_edge, %amdgpu_ring_write.exit79.i.for.inc17.i_crit_edge
  %157 = phi i32 [ %dec.i78.i, %amdgpu_ring_write.exit79.i.for.inc17.i_crit_edge ], [ %dec.i91.i, %amdgpu_ring_write.exit92.i.for.inc17.i_crit_edge ]
  %incdec.ptr.i = getelementptr %struct.cs_extent_def, ptr %ext.0252.i, i32 1
  %158 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %158)
  %159 = load ptr, ptr %incdec.ptr.i, align 4
  %cmp5.not.i = icmp eq ptr %159, null
  br i1 %cmp5.not.i, label %for.inc19.i, label %for.inc17.i.if.then8.i_crit_edge

for.inc17.i.if.then8.i_crit_edge:                 ; preds = %for.inc17.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.then8.i

for.inc19.i:                                      ; preds = %for.inc17.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %157)
  %cmp.i94.i = icmp slt i32 %157, 1
  br i1 %cmp.i94.i, label %if.then.i95.i, label %for.inc19.i.amdgpu_ring_write.exit105.i_crit_edge

for.inc19.i.amdgpu_ring_write.exit105.i_crit_edge: ; preds = %for.inc19.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit105.i

if.then.i95.i:                                    ; preds = %for.inc19.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit105.i

amdgpu_ring_write.exit105.i:                      ; preds = %if.then.i95.i, %for.inc19.i.amdgpu_ring_write.exit105.i_crit_edge
  %160 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %160)
  %161 = load ptr, ptr %ring1.i, align 4
  %162 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %162)
  %163 = load i64, ptr %wptr, align 8
  %inc.i98.i = add i64 %163, 1
  store i64 %inc.i98.i, ptr %wptr, align 8
  %164 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %164)
  %165 = load i32, ptr %buf_mask.i, align 8
  %166 = trunc i64 %163 to i32
  %idxprom.i100.i = and i32 %165, %166
  %arrayidx.i101.i = getelementptr i32, ptr %161, i32 %idxprom.i100.i
  %167 = ptrtoint ptr %arrayidx.i101.i to i32
  call void @__asan_store4_noabort(i32 %167)
  store volatile i32 -1073583872, ptr %arrayidx.i101.i, align 4
  %168 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %168)
  %169 = load i64, ptr %ptr_mask.i.i, align 8
  %170 = load i64, ptr %wptr, align 8
  %and3.i103.i = and i64 %170, %169
  store i64 %and3.i103.i, ptr %wptr, align 8
  %171 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %171)
  %172 = load i32, ptr %count_dw.i.i, align 8
  %dec.i104.i = add i32 %172, -1
  store i32 %dec.i104.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i104.i)
  %cmp.i107.i = icmp slt i32 %dec.i104.i, 1
  br i1 %cmp.i107.i, label %if.then.i108.i, label %amdgpu_ring_write.exit105.i.amdgpu_ring_write.exit118.i_crit_edge

amdgpu_ring_write.exit105.i.amdgpu_ring_write.exit118.i_crit_edge: ; preds = %amdgpu_ring_write.exit105.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit118.i

if.then.i108.i:                                   ; preds = %amdgpu_ring_write.exit105.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit118.i

amdgpu_ring_write.exit118.i:                      ; preds = %if.then.i108.i, %amdgpu_ring_write.exit105.i.amdgpu_ring_write.exit118.i_crit_edge
  %173 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %173)
  %174 = load ptr, ptr %ring1.i, align 4
  %175 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %175)
  %176 = load i64, ptr %wptr, align 8
  %inc.i111.i = add i64 %176, 1
  store i64 %inc.i111.i, ptr %wptr, align 8
  %177 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %177)
  %178 = load i32, ptr %buf_mask.i, align 8
  %179 = trunc i64 %176 to i32
  %idxprom.i113.i = and i32 %178, %179
  %arrayidx.i114.i = getelementptr i32, ptr %174, i32 %idxprom.i113.i
  %180 = ptrtoint ptr %arrayidx.i114.i to i32
  call void @__asan_store4_noabort(i32 %180)
  store volatile i32 212, ptr %arrayidx.i114.i, align 4
  %181 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %181)
  %182 = load i64, ptr %ptr_mask.i.i, align 8
  %183 = load i64, ptr %wptr, align 8
  %and3.i116.i = and i64 %183, %182
  store i64 %and3.i116.i, ptr %wptr, align 8
  %184 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %184)
  %185 = load i32, ptr %count_dw.i.i, align 8
  %dec.i117.i = add i32 %185, -1
  store i32 %dec.i117.i, ptr %count_dw.i.i, align 8
  %raster_config.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 30, i32 0, i32 0, i32 2
  %186 = ptrtoint ptr %raster_config.i to i32
  call void @__asan_load4_noabort(i32 %186)
  %187 = load i32, ptr %raster_config.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i117.i)
  %cmp.i120.i = icmp slt i32 %dec.i117.i, 1
  br i1 %cmp.i120.i, label %if.then.i121.i, label %amdgpu_ring_write.exit118.i.amdgpu_ring_write.exit131.i_crit_edge

amdgpu_ring_write.exit118.i.amdgpu_ring_write.exit131.i_crit_edge: ; preds = %amdgpu_ring_write.exit118.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit131.i

if.then.i121.i:                                   ; preds = %amdgpu_ring_write.exit118.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit131.i

amdgpu_ring_write.exit131.i:                      ; preds = %if.then.i121.i, %amdgpu_ring_write.exit118.i.amdgpu_ring_write.exit131.i_crit_edge
  %188 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %188)
  %189 = load ptr, ptr %ring1.i, align 4
  %190 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %190)
  %191 = load i64, ptr %wptr, align 8
  %inc.i124.i = add i64 %191, 1
  store i64 %inc.i124.i, ptr %wptr, align 8
  %192 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %192)
  %193 = load i32, ptr %buf_mask.i, align 8
  %194 = trunc i64 %191 to i32
  %idxprom.i126.i = and i32 %193, %194
  %arrayidx.i127.i = getelementptr i32, ptr %189, i32 %idxprom.i126.i
  %195 = ptrtoint ptr %arrayidx.i127.i to i32
  call void @__asan_store4_noabort(i32 %195)
  store volatile i32 %187, ptr %arrayidx.i127.i, align 4
  %196 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %196)
  %197 = load i64, ptr %ptr_mask.i.i, align 8
  %198 = load i64, ptr %wptr, align 8
  %and3.i129.i = and i64 %198, %197
  store i64 %and3.i129.i, ptr %wptr, align 8
  %199 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %199)
  %200 = load i32, ptr %count_dw.i.i, align 8
  %dec.i130.i = add i32 %200, -1
  store i32 %dec.i130.i, ptr %count_dw.i.i, align 8
  %raster_config_1.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 1, i32 30, i32 0, i32 0, i32 3
  %201 = ptrtoint ptr %raster_config_1.i to i32
  call void @__asan_load4_noabort(i32 %201)
  %202 = load i32, ptr %raster_config_1.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i130.i)
  %cmp.i133.i = icmp slt i32 %dec.i130.i, 1
  br i1 %cmp.i133.i, label %if.then.i134.i, label %amdgpu_ring_write.exit131.i.amdgpu_ring_write.exit144.i_crit_edge

amdgpu_ring_write.exit131.i.amdgpu_ring_write.exit144.i_crit_edge: ; preds = %amdgpu_ring_write.exit131.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit144.i

if.then.i134.i:                                   ; preds = %amdgpu_ring_write.exit131.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit144.i

amdgpu_ring_write.exit144.i:                      ; preds = %if.then.i134.i, %amdgpu_ring_write.exit131.i.amdgpu_ring_write.exit144.i_crit_edge
  %203 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %203)
  %204 = load ptr, ptr %ring1.i, align 4
  %205 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %205)
  %206 = load i64, ptr %wptr, align 8
  %inc.i137.i = add i64 %206, 1
  store i64 %inc.i137.i, ptr %wptr, align 8
  %207 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %207)
  %208 = load i32, ptr %buf_mask.i, align 8
  %209 = trunc i64 %206 to i32
  %idxprom.i139.i = and i32 %208, %209
  %arrayidx.i140.i = getelementptr i32, ptr %204, i32 %idxprom.i139.i
  %210 = ptrtoint ptr %arrayidx.i140.i to i32
  call void @__asan_store4_noabort(i32 %210)
  store volatile i32 %202, ptr %arrayidx.i140.i, align 4
  %211 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %211)
  %212 = load i64, ptr %ptr_mask.i.i, align 8
  %213 = load i64, ptr %wptr, align 8
  %and3.i142.i = and i64 %213, %212
  store i64 %and3.i142.i, ptr %wptr, align 8
  %214 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %214)
  %215 = load i32, ptr %count_dw.i.i, align 8
  %dec.i143.i = add i32 %215, -1
  store i32 %dec.i143.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i143.i)
  %cmp.i146.i = icmp slt i32 %dec.i143.i, 1
  br i1 %cmp.i146.i, label %if.then.i147.i, label %amdgpu_ring_write.exit144.i.amdgpu_ring_write.exit157.i_crit_edge

amdgpu_ring_write.exit144.i.amdgpu_ring_write.exit157.i_crit_edge: ; preds = %amdgpu_ring_write.exit144.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit157.i

if.then.i147.i:                                   ; preds = %amdgpu_ring_write.exit144.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit157.i

amdgpu_ring_write.exit157.i:                      ; preds = %if.then.i147.i, %amdgpu_ring_write.exit144.i.amdgpu_ring_write.exit157.i_crit_edge
  %216 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %216)
  %217 = load ptr, ptr %ring1.i, align 4
  %218 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %218)
  %219 = load i64, ptr %wptr, align 8
  %inc.i150.i = add i64 %219, 1
  store i64 %inc.i150.i, ptr %wptr, align 8
  %220 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %220)
  %221 = load i32, ptr %buf_mask.i, align 8
  %222 = trunc i64 %219 to i32
  %idxprom.i152.i = and i32 %221, %222
  %arrayidx.i153.i = getelementptr i32, ptr %217, i32 %idxprom.i152.i
  %223 = ptrtoint ptr %arrayidx.i153.i to i32
  call void @__asan_store4_noabort(i32 %223)
  store volatile i32 -1073722880, ptr %arrayidx.i153.i, align 4
  %224 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %224)
  %225 = load i64, ptr %ptr_mask.i.i, align 8
  %226 = load i64, ptr %wptr, align 8
  %and3.i155.i = and i64 %226, %225
  store i64 %and3.i155.i, ptr %wptr, align 8
  %227 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %227)
  %228 = load i32, ptr %count_dw.i.i, align 8
  %dec.i156.i = add i32 %228, -1
  store i32 %dec.i156.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i156.i)
  %cmp.i159.i = icmp slt i32 %dec.i156.i, 1
  br i1 %cmp.i159.i, label %if.then.i160.i, label %amdgpu_ring_write.exit157.i.amdgpu_ring_write.exit170.i_crit_edge

amdgpu_ring_write.exit157.i.amdgpu_ring_write.exit170.i_crit_edge: ; preds = %amdgpu_ring_write.exit157.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit170.i

if.then.i160.i:                                   ; preds = %amdgpu_ring_write.exit157.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit170.i

amdgpu_ring_write.exit170.i:                      ; preds = %if.then.i160.i, %amdgpu_ring_write.exit157.i.amdgpu_ring_write.exit170.i_crit_edge
  %229 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %229)
  %230 = load ptr, ptr %ring1.i, align 4
  %231 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %231)
  %232 = load i64, ptr %wptr, align 8
  %inc.i163.i = add i64 %232, 1
  store i64 %inc.i163.i, ptr %wptr, align 8
  %233 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %233)
  %234 = load i32, ptr %buf_mask.i, align 8
  %235 = trunc i64 %232 to i32
  %idxprom.i165.i = and i32 %234, %235
  %arrayidx.i166.i = getelementptr i32, ptr %230, i32 %idxprom.i165.i
  %236 = ptrtoint ptr %arrayidx.i166.i to i32
  call void @__asan_store4_noabort(i32 %236)
  store volatile i32 805306368, ptr %arrayidx.i166.i, align 4
  %237 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %237)
  %238 = load i64, ptr %ptr_mask.i.i, align 8
  %239 = load i64, ptr %wptr, align 8
  %and3.i168.i = and i64 %239, %238
  store i64 %and3.i168.i, ptr %wptr, align 8
  %240 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %240)
  %241 = load i32, ptr %count_dw.i.i, align 8
  %dec.i169.i = add i32 %241, -1
  store i32 %dec.i169.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i169.i)
  %cmp.i172.i = icmp slt i32 %dec.i169.i, 1
  br i1 %cmp.i172.i, label %if.then.i173.i, label %amdgpu_ring_write.exit170.i.amdgpu_ring_write.exit183.i_crit_edge

amdgpu_ring_write.exit170.i.amdgpu_ring_write.exit183.i_crit_edge: ; preds = %amdgpu_ring_write.exit170.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit183.i

if.then.i173.i:                                   ; preds = %amdgpu_ring_write.exit170.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit183.i

amdgpu_ring_write.exit183.i:                      ; preds = %if.then.i173.i, %amdgpu_ring_write.exit170.i.amdgpu_ring_write.exit183.i_crit_edge
  %242 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %242)
  %243 = load ptr, ptr %ring1.i, align 4
  %244 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %244)
  %245 = load i64, ptr %wptr, align 8
  %inc.i176.i = add i64 %245, 1
  store i64 %inc.i176.i, ptr %wptr, align 8
  %246 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %246)
  %247 = load i32, ptr %buf_mask.i, align 8
  %248 = trunc i64 %245 to i32
  %idxprom.i178.i = and i32 %247, %248
  %arrayidx.i179.i = getelementptr i32, ptr %243, i32 %idxprom.i178.i
  %249 = ptrtoint ptr %arrayidx.i179.i to i32
  call void @__asan_store4_noabort(i32 %249)
  store volatile i32 -1073737216, ptr %arrayidx.i179.i, align 4
  %250 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %250)
  %251 = load i64, ptr %ptr_mask.i.i, align 8
  %252 = load i64, ptr %wptr, align 8
  %and3.i181.i = and i64 %252, %251
  store i64 %and3.i181.i, ptr %wptr, align 8
  %253 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %253)
  %254 = load i32, ptr %count_dw.i.i, align 8
  %dec.i182.i = add i32 %254, -1
  store i32 %dec.i182.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i182.i)
  %cmp.i185.i = icmp slt i32 %dec.i182.i, 1
  br i1 %cmp.i185.i, label %if.then.i186.i, label %amdgpu_ring_write.exit183.i.amdgpu_ring_write.exit196.i_crit_edge

amdgpu_ring_write.exit183.i.amdgpu_ring_write.exit196.i_crit_edge: ; preds = %amdgpu_ring_write.exit183.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit196.i

if.then.i186.i:                                   ; preds = %amdgpu_ring_write.exit183.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit196.i

amdgpu_ring_write.exit196.i:                      ; preds = %if.then.i186.i, %amdgpu_ring_write.exit183.i.amdgpu_ring_write.exit196.i_crit_edge
  %255 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %255)
  %256 = load ptr, ptr %ring1.i, align 4
  %257 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %257)
  %258 = load i64, ptr %wptr, align 8
  %inc.i189.i = add i64 %258, 1
  store i64 %inc.i189.i, ptr %wptr, align 8
  %259 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %259)
  %260 = load i32, ptr %buf_mask.i, align 8
  %261 = trunc i64 %258 to i32
  %idxprom.i191.i = and i32 %260, %261
  %arrayidx.i192.i = getelementptr i32, ptr %256, i32 %idxprom.i191.i
  %262 = ptrtoint ptr %arrayidx.i192.i to i32
  call void @__asan_store4_noabort(i32 %262)
  store volatile i32 0, ptr %arrayidx.i192.i, align 4
  %263 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %263)
  %264 = load i64, ptr %ptr_mask.i.i, align 8
  %265 = load i64, ptr %wptr, align 8
  %and3.i194.i = and i64 %265, %264
  store i64 %and3.i194.i, ptr %wptr, align 8
  %266 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %266)
  %267 = load i32, ptr %count_dw.i.i, align 8
  %dec.i195.i = add i32 %267, -1
  store i32 %dec.i195.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i195.i)
  %cmp.i198.i = icmp slt i32 %dec.i195.i, 1
  br i1 %cmp.i198.i, label %if.then.i199.i, label %amdgpu_ring_write.exit196.i.amdgpu_ring_write.exit209.i_crit_edge

amdgpu_ring_write.exit196.i.amdgpu_ring_write.exit209.i_crit_edge: ; preds = %amdgpu_ring_write.exit196.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit209.i

if.then.i199.i:                                   ; preds = %amdgpu_ring_write.exit196.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit209.i

amdgpu_ring_write.exit209.i:                      ; preds = %if.then.i199.i, %amdgpu_ring_write.exit196.i.amdgpu_ring_write.exit209.i_crit_edge
  %268 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %268)
  %269 = load ptr, ptr %ring1.i, align 4
  %270 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %270)
  %271 = load i64, ptr %wptr, align 8
  %inc.i202.i = add i64 %271, 1
  store i64 %inc.i202.i, ptr %wptr, align 8
  %272 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %272)
  %273 = load i32, ptr %buf_mask.i, align 8
  %274 = trunc i64 %271 to i32
  %idxprom.i204.i = and i32 %273, %274
  %arrayidx.i205.i = getelementptr i32, ptr %269, i32 %idxprom.i204.i
  %275 = ptrtoint ptr %arrayidx.i205.i to i32
  call void @__asan_store4_noabort(i32 %275)
  store volatile i32 -1073606400, ptr %arrayidx.i205.i, align 4
  %276 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %276)
  %277 = load i64, ptr %ptr_mask.i.i, align 8
  %278 = load i64, ptr %wptr, align 8
  %and3.i207.i = and i64 %278, %277
  store i64 %and3.i207.i, ptr %wptr, align 8
  %279 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %279)
  %280 = load i32, ptr %count_dw.i.i, align 8
  %dec.i208.i = add i32 %280, -1
  store i32 %dec.i208.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i208.i)
  %cmp.i211.i = icmp slt i32 %dec.i208.i, 1
  br i1 %cmp.i211.i, label %if.then.i212.i, label %amdgpu_ring_write.exit209.i.amdgpu_ring_write.exit222.i_crit_edge

amdgpu_ring_write.exit209.i.amdgpu_ring_write.exit222.i_crit_edge: ; preds = %amdgpu_ring_write.exit209.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit222.i

if.then.i212.i:                                   ; preds = %amdgpu_ring_write.exit209.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit222.i

amdgpu_ring_write.exit222.i:                      ; preds = %if.then.i212.i, %amdgpu_ring_write.exit209.i.amdgpu_ring_write.exit222.i_crit_edge
  %281 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %281)
  %282 = load ptr, ptr %ring1.i, align 4
  %283 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %283)
  %284 = load i64, ptr %wptr, align 8
  %inc.i215.i = add i64 %284, 1
  store i64 %inc.i215.i, ptr %wptr, align 8
  %285 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %285)
  %286 = load i32, ptr %buf_mask.i, align 8
  %287 = trunc i64 %284 to i32
  %idxprom.i217.i = and i32 %286, %287
  %arrayidx.i218.i = getelementptr i32, ptr %282, i32 %idxprom.i217.i
  %288 = ptrtoint ptr %arrayidx.i218.i to i32
  call void @__asan_store4_noabort(i32 %288)
  store volatile i32 3, ptr %arrayidx.i218.i, align 4
  %289 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %289)
  %290 = load i64, ptr %ptr_mask.i.i, align 8
  %291 = load i64, ptr %wptr, align 8
  %and3.i220.i = and i64 %291, %290
  store i64 %and3.i220.i, ptr %wptr, align 8
  %292 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %292)
  %293 = load i32, ptr %count_dw.i.i, align 8
  %dec.i221.i = add i32 %293, -1
  store i32 %dec.i221.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i221.i)
  %cmp.i224.i = icmp slt i32 %dec.i221.i, 1
  br i1 %cmp.i224.i, label %if.then.i225.i, label %amdgpu_ring_write.exit222.i.amdgpu_ring_write.exit235.i_crit_edge

amdgpu_ring_write.exit222.i.amdgpu_ring_write.exit235.i_crit_edge: ; preds = %amdgpu_ring_write.exit222.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit235.i

if.then.i225.i:                                   ; preds = %amdgpu_ring_write.exit222.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit235.i

amdgpu_ring_write.exit235.i:                      ; preds = %if.then.i225.i, %amdgpu_ring_write.exit222.i.amdgpu_ring_write.exit235.i_crit_edge
  %294 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %294)
  %295 = load ptr, ptr %ring1.i, align 4
  %296 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %296)
  %297 = load i64, ptr %wptr, align 8
  %inc.i228.i = add i64 %297, 1
  store i64 %inc.i228.i, ptr %wptr, align 8
  %298 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %298)
  %299 = load i32, ptr %buf_mask.i, align 8
  %300 = trunc i64 %297 to i32
  %idxprom.i230.i = and i32 %299, %300
  %arrayidx.i231.i = getelementptr i32, ptr %295, i32 %idxprom.i230.i
  %301 = ptrtoint ptr %arrayidx.i231.i to i32
  call void @__asan_store4_noabort(i32 %301)
  store volatile i32 32768, ptr %arrayidx.i231.i, align 4
  %302 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %302)
  %303 = load i64, ptr %ptr_mask.i.i, align 8
  %304 = load i64, ptr %wptr, align 8
  %and3.i233.i = and i64 %304, %303
  store i64 %and3.i233.i, ptr %wptr, align 8
  %305 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %305)
  %306 = load i32, ptr %count_dw.i.i, align 8
  %dec.i234.i = add i32 %306, -1
  store i32 %dec.i234.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i234.i)
  %cmp.i237.i = icmp slt i32 %dec.i234.i, 1
  br i1 %cmp.i237.i, label %if.then.i238.i, label %amdgpu_ring_write.exit235.i.amdgpu_ring_write.exit248.i_crit_edge

amdgpu_ring_write.exit235.i.amdgpu_ring_write.exit248.i_crit_edge: ; preds = %amdgpu_ring_write.exit235.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit248.i

if.then.i238.i:                                   ; preds = %amdgpu_ring_write.exit235.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit248.i

amdgpu_ring_write.exit248.i:                      ; preds = %if.then.i238.i, %amdgpu_ring_write.exit235.i.amdgpu_ring_write.exit248.i_crit_edge
  %307 = ptrtoint ptr %ring1.i to i32
  call void @__asan_load4_noabort(i32 %307)
  %308 = load ptr, ptr %ring1.i, align 4
  %309 = ptrtoint ptr %wptr to i32
  call void @__asan_load8_noabort(i32 %309)
  %310 = load i64, ptr %wptr, align 8
  %inc.i241.i = add i64 %310, 1
  store i64 %inc.i241.i, ptr %wptr, align 8
  %311 = ptrtoint ptr %buf_mask.i to i32
  call void @__asan_load4_noabort(i32 %311)
  %312 = load i32, ptr %buf_mask.i, align 8
  %313 = trunc i64 %310 to i32
  %idxprom.i243.i = and i32 %312, %313
  %arrayidx.i244.i = getelementptr i32, ptr %308, i32 %idxprom.i243.i
  %314 = ptrtoint ptr %arrayidx.i244.i to i32
  call void @__asan_store4_noabort(i32 %314)
  store volatile i32 32768, ptr %arrayidx.i244.i, align 4
  %315 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %315)
  %316 = load i64, ptr %ptr_mask.i.i, align 8
  %317 = load i64, ptr %wptr, align 8
  %and3.i246.i = and i64 %317, %316
  store i64 %and3.i246.i, ptr %wptr, align 8
  %318 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %318)
  %319 = load i32, ptr %count_dw.i.i, align 8
  %dec.i247.i = add i32 %319, -1
  store i32 %dec.i247.i, ptr %count_dw.i.i, align 8
  tail call void @amdgpu_ring_commit(ptr noundef %gfx_ring) #12
  br label %gfx_v8_0_cp_gfx_start.exit

gfx_v8_0_cp_gfx_start.exit:                       ; preds = %amdgpu_ring_write.exit248.i, %if.then.i
  %ready = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 36, i32 0, i32 3, i32 17
  %320 = ptrtoint ptr %ready to i32
  call void @__asan_store1_noabort(i32 %320)
  store i8 1, ptr %ready, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @gfx_v8_0_kcq_resume(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 8333, i32 noundef 0, i32 noundef 0) #12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %0 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %0(i32 noundef 10737400) #12
  %num_compute_rings = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 39
  %1 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %2)
  %cmp59.not = icmp eq i32 %2, 0
  br i1 %cmp59.not, label %entry.for.end_crit_edge, label %entry.for.body_crit_edge

entry.for.body_crit_edge:                         ; preds = %entry
  br label %for.body

entry.for.end_crit_edge:                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.cond:                                         ; preds = %if.end11
  %inc = add nuw i32 %i.060, 1
  %3 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %num_compute_rings, align 8
  %cmp = icmp ult i32 %inc, %4
  br i1 %cmp, label %for.cond.for.body_crit_edge, label %for.cond.for.end_crit_edge

for.cond.for.end_crit_edge:                       ; preds = %for.cond
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end

for.cond.for.body_crit_edge:                      ; preds = %for.cond
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.body:                                         ; preds = %for.cond.for.body_crit_edge, %entry.for.body_crit_edge
  %i.060 = phi i32 [ %inc, %for.cond.for.body_crit_edge ], [ 0, %entry.for.body_crit_edge ]
  %arrayidx = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060
  %mqd_obj = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 19
  %5 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %mqd_obj, align 4
  %bdev.i = getelementptr inbounds %struct.amdgpu_bo, ptr %6, i32 0, i32 4, i32 1
  %7 = ptrtoint ptr %bdev.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %bdev.i, align 8
  %resv32.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %6, i32 0, i32 4, i32 0, i32 9
  %9 = ptrtoint ptr %resv32.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %resv32.i.i, align 8
  %call.i.i.i = tail call i32 @ww_mutex_lock_interruptible(ptr noundef %10, ptr noundef null) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 -4, i32 %call.i.i.i)
  %cmp.i.i = icmp eq i32 %call.i.i.i, -4
  %retval.1.i.i = select i1 %cmp.i.i, i32 -512, i32 %call.i.i.i
  %11 = zext i32 %retval.1.i.i to i64
  call void @__sanitizer_cov_trace_switch(i64 %11, ptr @__sancov_gen_cov_switch_values.132)
  switch i32 %retval.1.i.i, label %do.end.i [
    i32 0, label %if.end
    i32 -512, label %for.body.done_crit_edge
  ], !prof !450

for.body.done_crit_edge:                          ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %done

do.end.i:                                         ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  %add.ptr.i.i = getelementptr i8, ptr %8, i32 -17736
  %12 = ptrtoint ptr %add.ptr.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %add.ptr.i.i, align 8
  tail call void (ptr, ptr, ...) @_dev_err(ptr noundef %13, ptr noundef nonnull @.str.78, ptr noundef %6) #15
  br label %done

if.end:                                           ; preds = %for.body
  %14 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %mqd_obj, align 4
  %mqd_ptr = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 21
  %call5 = tail call i32 @amdgpu_bo_kmap(ptr noundef %15, ptr noundef %mqd_ptr) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call5)
  %tobool6.not = icmp eq i32 %call5, 0
  br i1 %tobool6.not, label %if.then7, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11

if.then7:                                         ; preds = %if.end
  %16 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %arrayidx, align 8
  %18 = ptrtoint ptr %mqd_ptr to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %mqd_ptr, align 8
  %compute_ring.i = getelementptr inbounds %struct.amdgpu_device, ptr %17, i32 0, i32 106, i32 38
  %sub.ptr.lhs.cast.i = ptrtoint ptr %arrayidx to i32
  %sub.ptr.rhs.cast.i = ptrtoint ptr %compute_ring.i to i32
  %sub.ptr.sub.i = sub i32 %sub.ptr.lhs.cast.i, %sub.ptr.rhs.cast.i
  %sub.ptr.div.i = sdiv exact i32 %sub.ptr.sub.i, 904
  %in_gpu_reset.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %17, i32 0, i32 141
  %call.i.i.i.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %in_gpu_reset.i.i, i32 noundef 4) #12
  %20 = ptrtoint ptr %in_gpu_reset.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load volatile i32, ptr %in_gpu_reset.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %21)
  %tobool.not.i = icmp eq i32 %21, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %if.then7.if.else.i_crit_edge

if.then7.if.else.i_crit_edge:                     ; preds = %if.then7
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else.i

land.lhs.true.i:                                  ; preds = %if.then7
  %in_suspend.i = getelementptr inbounds %struct.amdgpu_device, ptr %17, i32 0, i32 137
  %22 = ptrtoint ptr %in_suspend.i to i32
  call void @__asan_load1_noabort(i32 %22)
  %23 = load i8, ptr %in_suspend.i, align 1, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %23)
  %tobool2.not.i = icmp eq i8 %23, 0
  br i1 %tobool2.not.i, label %if.then.i, label %land.lhs.true.i.if.else.i_crit_edge

land.lhs.true.i.if.else.i_crit_edge:              ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else.i

if.then.i:                                        ; preds = %land.lhs.true.i
  %24 = call ptr @memset(ptr %19, i32 0, i32 2056)
  %dynamic_cu_mask.i = getelementptr inbounds %struct.vi_mqd_allocation, ptr %19, i32 0, i32 3
  %25 = ptrtoint ptr %dynamic_cu_mask.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 -1, ptr %dynamic_cu_mask.i, align 4
  %dynamic_rb_mask.i = getelementptr inbounds %struct.vi_mqd_allocation, ptr %19, i32 0, i32 4
  %26 = ptrtoint ptr %dynamic_rb_mask.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 -1, ptr %dynamic_rb_mask.i, align 4
  %srbm_mutex.i = getelementptr inbounds %struct.amdgpu_device, ptr %17, i32 0, i32 20
  tail call void @mutex_lock_nested(ptr noundef %srbm_mutex.i, i32 noundef 0) #12
  %me.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 16
  %27 = ptrtoint ptr %me.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %me.i, align 8
  %pipe.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 17
  %29 = ptrtoint ptr %pipe.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %pipe.i, align 4
  %queue.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 18
  %31 = ptrtoint ptr %queue.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %queue.i, align 8
  tail call void @vi_srbm_select(ptr noundef %17, i32 noundef %28, i32 noundef %30, i32 noundef %32, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_mqd_init(ptr noundef %arrayidx) #12
  tail call void @vi_srbm_select(ptr noundef %17, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 0) #12
  tail call void @mutex_unlock(ptr noundef %srbm_mutex.i) #12
  %arrayidx6.i = getelementptr %struct.amdgpu_device, ptr %17, i32 0, i32 106, i32 6, i32 7, i32 %sub.ptr.div.i
  %33 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %arrayidx6.i, align 4
  %tobool7.not.i = icmp eq ptr %34, null
  br i1 %tobool7.not.i, label %if.then.i.gfx_v8_0_kcq_init_queue.exit_crit_edge, label %if.then8.i

if.then.i.gfx_v8_0_kcq_init_queue.exit_crit_edge: ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_kcq_init_queue.exit

if.then8.i:                                       ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  %35 = call ptr @memcpy(ptr %34, ptr %19, i32 2064)
  br label %gfx_v8_0_kcq_init_queue.exit

if.else.i:                                        ; preds = %land.lhs.true.i.if.else.i_crit_edge, %if.then7.if.else.i_crit_edge
  %call.i.i.i2.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %in_gpu_reset.i.i, i32 noundef 4) #12
  %36 = ptrtoint ptr %in_gpu_reset.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %in_gpu_reset.i.i, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %37)
  %tobool14.not.i = icmp eq i32 %37, 0
  br i1 %tobool14.not.i, label %if.else27.i, label %if.then15.i

if.then15.i:                                      ; preds = %if.else.i
  %arrayidx19.i = getelementptr %struct.amdgpu_device, ptr %17, i32 0, i32 106, i32 6, i32 7, i32 %sub.ptr.div.i
  %38 = ptrtoint ptr %arrayidx19.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %arrayidx19.i, align 4
  %tobool20.not.i = icmp eq ptr %39, null
  br i1 %tobool20.not.i, label %if.then15.i.if.end26.i_crit_edge, label %if.then21.i

if.then15.i.if.end26.i_crit_edge:                 ; preds = %if.then15.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end26.i

if.then21.i:                                      ; preds = %if.then15.i
  call void @__sanitizer_cov_trace_pc() #14
  %40 = call ptr @memcpy(ptr %19, ptr %39, i32 2064)
  br label %if.end26.i

if.end26.i:                                       ; preds = %if.then21.i, %if.then15.i.if.end26.i_crit_edge
  %wptr.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 7
  %41 = ptrtoint ptr %wptr.i to i32
  call void @__asan_store8_noabort(i32 %41)
  store i64 0, ptr %wptr.i, align 8
  %buf_mask.i.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 14
  %funcs.i.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 1
  %ring1.i.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 5
  br label %while.body.i.i

while.body.i.i:                                   ; preds = %while.body.i.i.while.body.i.i_crit_edge, %if.end26.i
  %i.05.i.i = phi i32 [ 0, %if.end26.i ], [ %inc.i.i, %while.body.i.i.while.body.i.i_crit_edge ]
  %42 = ptrtoint ptr %funcs.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %funcs.i.i, align 4
  %nop.i.i = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %43, i32 0, i32 2
  %44 = ptrtoint ptr %nop.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %nop.i.i, align 4
  %46 = ptrtoint ptr %ring1.i.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %ring1.i.i, align 4
  %inc.i.i = add i32 %i.05.i.i, 1
  %arrayidx.i.i = getelementptr i32, ptr %47, i32 %i.05.i.i
  %48 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %48)
  store volatile i32 %45, ptr %arrayidx.i.i, align 4
  %49 = ptrtoint ptr %buf_mask.i.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %buf_mask.i.i, align 8
  %cmp.not.i.i = icmp ugt i32 %inc.i.i, %50
  br i1 %cmp.not.i.i, label %while.body.i.i.gfx_v8_0_kcq_init_queue.exit_crit_edge, label %while.body.i.i.while.body.i.i_crit_edge

while.body.i.i.while.body.i.i_crit_edge:          ; preds = %while.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %while.body.i.i

while.body.i.i.gfx_v8_0_kcq_init_queue.exit_crit_edge: ; preds = %while.body.i.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_kcq_init_queue.exit

if.else27.i:                                      ; preds = %if.else.i
  %buf_mask.i3.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 14
  %funcs.i4.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 1
  %ring1.i5.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.060, i32 5
  br label %while.body.i11.i

while.body.i11.i:                                 ; preds = %while.body.i11.i.while.body.i11.i_crit_edge, %if.else27.i
  %i.05.i6.i = phi i32 [ 0, %if.else27.i ], [ %inc.i8.i, %while.body.i11.i.while.body.i11.i_crit_edge ]
  %51 = ptrtoint ptr %funcs.i4.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %funcs.i4.i, align 4
  %nop.i7.i = getelementptr inbounds %struct.amdgpu_ring_funcs, ptr %52, i32 0, i32 2
  %53 = ptrtoint ptr %nop.i7.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %nop.i7.i, align 4
  %55 = ptrtoint ptr %ring1.i5.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %ring1.i5.i, align 4
  %inc.i8.i = add i32 %i.05.i6.i, 1
  %arrayidx.i9.i = getelementptr i32, ptr %56, i32 %i.05.i6.i
  %57 = ptrtoint ptr %arrayidx.i9.i to i32
  call void @__asan_store4_noabort(i32 %57)
  store volatile i32 %54, ptr %arrayidx.i9.i, align 4
  %58 = ptrtoint ptr %buf_mask.i3.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %buf_mask.i3.i, align 8
  %cmp.not.i10.i = icmp ugt i32 %inc.i8.i, %59
  br i1 %cmp.not.i10.i, label %while.body.i11.i.gfx_v8_0_kcq_init_queue.exit_crit_edge, label %while.body.i11.i.while.body.i11.i_crit_edge

while.body.i11.i.while.body.i11.i_crit_edge:      ; preds = %while.body.i11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %while.body.i11.i

while.body.i11.i.gfx_v8_0_kcq_init_queue.exit_crit_edge: ; preds = %while.body.i11.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_kcq_init_queue.exit

gfx_v8_0_kcq_init_queue.exit:                     ; preds = %while.body.i11.i.gfx_v8_0_kcq_init_queue.exit_crit_edge, %while.body.i.i.gfx_v8_0_kcq_init_queue.exit_crit_edge, %if.then8.i, %if.then.i.gfx_v8_0_kcq_init_queue.exit_crit_edge
  %60 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %mqd_obj, align 4
  tail call void @amdgpu_bo_kunmap(ptr noundef %61) #12
  %62 = ptrtoint ptr %mqd_ptr to i32
  call void @__asan_store4_noabort(i32 %62)
  store ptr null, ptr %mqd_ptr, align 8
  br label %if.end11

if.end11:                                         ; preds = %gfx_v8_0_kcq_init_queue.exit, %if.end.if.end11_crit_edge
  %r.0 = phi i32 [ %call5, %if.end.if.end11_crit_edge ], [ 0, %gfx_v8_0_kcq_init_queue.exit ]
  %63 = ptrtoint ptr %mqd_obj to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %mqd_obj, align 4
  %tbo.i = getelementptr inbounds %struct.amdgpu_bo, ptr %64, i32 0, i32 4
  %bdev.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %64, i32 0, i32 4, i32 1
  %65 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %66, i32 0, i32 6
  tail call void @_raw_spin_lock(ptr noundef %lru_lock.i.i.i) #12
  %resource.i.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %64, i32 0, i32 4, i32 6
  %67 = ptrtoint ptr %resource.i.i.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %resource.i.i.i, align 4
  tail call void @ttm_bo_move_to_lru_tail(ptr noundef %tbo.i, ptr noundef %68, ptr noundef null) #12
  %69 = ptrtoint ptr %bdev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %bdev.i.i.i, align 8
  %lru_lock2.i.i.i = getelementptr inbounds %struct.ttm_device, ptr %70, i32 0, i32 6
  tail call void @_raw_spin_unlock(ptr noundef %lru_lock2.i.i.i) #12
  %resv.i.i = getelementptr inbounds %struct.amdgpu_bo, ptr %64, i32 0, i32 4, i32 0, i32 9
  %71 = ptrtoint ptr %resv.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load ptr, ptr %resv.i.i, align 8
  tail call void @dma_resv_reset_shared_max(ptr noundef %72) #12
  tail call void @ww_mutex_unlock(ptr noundef %72) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %r.0)
  %tobool13.not = icmp eq i32 %r.0, 0
  br i1 %tobool13.not, label %for.cond, label %if.end11.done_crit_edge

if.end11.done_crit_edge:                          ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #14
  br label %done

for.end:                                          ; preds = %for.cond.for.end_crit_edge, %entry.for.end_crit_edge
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %73 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %74)
  %cmp.i = icmp ugt i32 %74, 11
  br i1 %cmp.i, label %if.then.i35, label %for.end.gfx_v8_0_set_mec_doorbell_range.exit_crit_edge

for.end.gfx_v8_0_set_mec_doorbell_range.exit_crit_edge: ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_set_mec_doorbell_range.exit

if.then.i35:                                      ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  %doorbell_index.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 144
  %75 = ptrtoint ptr %doorbell_index.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %doorbell_index.i, align 4
  %shl.i = shl i32 %76, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12380, i32 noundef %shl.i, i32 noundef 0) #12
  %mec_ring7.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 144, i32 8
  %77 = ptrtoint ptr %mec_ring7.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %mec_ring7.i, align 4
  %shl2.i = shl i32 %78, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12381, i32 noundef %shl2.i, i32 noundef 0) #12
  br label %gfx_v8_0_set_mec_doorbell_range.exit

gfx_v8_0_set_mec_doorbell_range.exit:             ; preds = %if.then.i35, %for.end.gfx_v8_0_set_mec_doorbell_range.exit_crit_edge
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12472, i32 noundef 0) #12
  %or.i = or i32 %call.i, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12472, i32 noundef %or.i, i32 noundef 0) #12
  %ring.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3
  %queue_bitmap.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 6, i32 8
  br label %for.body.i

for.body.i:                                       ; preds = %for.inc.i.for.body.i_crit_edge, %gfx_v8_0_set_mec_doorbell_range.exit
  %queue_mask.0300.i = phi i64 [ 0, %gfx_v8_0_set_mec_doorbell_range.exit ], [ %queue_mask.1.i, %for.inc.i.for.body.i_crit_edge ]
  %i.0298.i = phi i32 [ 0, %gfx_v8_0_set_mec_doorbell_range.exit ], [ %inc.i, %for.inc.i.for.body.i_crit_edge ]
  %div3.i.i = lshr i32 %i.0298.i, 5
  %arrayidx.i.i36 = getelementptr i32, ptr %queue_bitmap.i, i32 %div3.i.i
  %79 = ptrtoint ptr %arrayidx.i.i36 to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load volatile i32, ptr %arrayidx.i.i36, align 4
  %and.i.i = and i32 %i.0298.i, 31
  %81 = shl nuw i32 1, %and.i.i
  %82 = and i32 %81, %80
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %82)
  %tobool.not.i37 = icmp eq i32 %82, 0
  br i1 %tobool.not.i37, label %for.body.i.for.inc.i_crit_edge, label %if.end.i

for.body.i.for.inc.i_crit_edge:                   ; preds = %for.body.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.inc.i

if.end.i:                                         ; preds = %for.body.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 63, i32 %i.0298.i)
  %cmp2.i = icmp ugt i32 %i.0298.i, 63
  br i1 %cmp2.i, label %do.end.i38, label %if.end26.i41, !prof !442

do.end.i38:                                       ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.10, i32 noundef 4371, i32 noundef 9, ptr noundef null) #12
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.83, i32 noundef %i.0298.i) #12
  %extract.t.i = trunc i64 %queue_mask.0300.i to i32
  %extract.i = lshr i64 %queue_mask.0300.i, 32
  %extract.t304.i = trunc i64 %extract.i to i32
  br label %for.end.i

if.end26.i41:                                     ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #14
  %sh_prom.i = zext i32 %i.0298.i to i64
  %shl.i39 = shl nuw i64 1, %sh_prom.i
  %or.i40 = or i64 %shl.i39, %queue_mask.0300.i
  br label %for.inc.i

for.inc.i:                                        ; preds = %if.end26.i41, %for.body.i.for.inc.i_crit_edge
  %queue_mask.1.i = phi i64 [ %or.i40, %if.end26.i41 ], [ %queue_mask.0300.i, %for.body.i.for.inc.i_crit_edge ]
  %inc.i = add nuw nsw i32 %i.0298.i, 1
  %exitcond.not.i = icmp eq i32 %inc.i, 128
  br i1 %exitcond.not.i, label %for.end.loopexit.i, label %for.inc.i.for.body.i_crit_edge

for.inc.i.for.body.i_crit_edge:                   ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body.i

for.end.loopexit.i:                               ; preds = %for.inc.i
  call void @__sanitizer_cov_trace_pc() #14
  %extract305.i = lshr i64 %queue_mask.1.i, 32
  %extract.t306.i = trunc i64 %extract305.i to i32
  %extract.t303.i = trunc i64 %queue_mask.1.i to i32
  br label %for.end.i

for.end.i:                                        ; preds = %for.end.loopexit.i, %do.end.i38
  %queue_mask.0296.off0.i = phi i32 [ %extract.t.i, %do.end.i38 ], [ %extract.t303.i, %for.end.loopexit.i ]
  %queue_mask.0296.off32.i = phi i32 [ %extract.t304.i, %do.end.i38 ], [ %extract.t306.i, %for.end.loopexit.i ]
  %83 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %83)
  %84 = load i32, ptr %num_compute_rings, align 8
  %mul.i = shl i32 %84, 3
  %add.i = add i32 %mul.i, 8
  %call28.i = tail call i32 @amdgpu_ring_alloc(ptr noundef %ring.i, i32 noundef %add.i) #12
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call28.i)
  %tobool29.not.i = icmp eq i32 %call28.i, 0
  br i1 %tobool29.not.i, label %if.end31.i, label %if.then30.i

if.then30.i:                                      ; preds = %for.end.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.84, i32 noundef %call28.i) #12
  br label %done

if.end31.i:                                       ; preds = %for.end.i
  %count_dw.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 11
  %85 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %86)
  %cmp.i.i42 = icmp slt i32 %86, 1
  br i1 %cmp.i.i42, label %if.then.i.i, label %if.end31.i.amdgpu_ring_write.exit.i_crit_edge

if.end31.i.amdgpu_ring_write.exit.i_crit_edge:    ; preds = %if.end31.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit.i

if.then.i.i:                                      ; preds = %if.end31.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit.i

amdgpu_ring_write.exit.i:                         ; preds = %if.then.i.i, %if.end31.i.amdgpu_ring_write.exit.i_crit_edge
  %ring1.i.i43 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 5
  %87 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load ptr, ptr %ring1.i.i43, align 4
  %wptr.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 7
  %89 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %89)
  %90 = load i64, ptr %wptr.i.i, align 8
  %inc.i.i44 = add i64 %90, 1
  store i64 %inc.i.i44, ptr %wptr.i.i, align 8
  %buf_mask.i.i45 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 14
  %91 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %buf_mask.i.i45, align 8
  %93 = trunc i64 %90 to i32
  %idxprom.i.i = and i32 %92, %93
  %arrayidx.i112.i = getelementptr i32, ptr %88, i32 %idxprom.i.i
  %94 = ptrtoint ptr %arrayidx.i112.i to i32
  call void @__asan_store4_noabort(i32 %94)
  store volatile i32 -1073307648, ptr %arrayidx.i112.i, align 4
  %ptr_mask.i.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 7, i32 3, i32 13
  %95 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %95)
  %96 = load i64, ptr %ptr_mask.i.i, align 8
  %97 = load i64, ptr %wptr.i.i, align 8
  %and3.i.i = and i64 %97, %96
  store i64 %and3.i.i, ptr %wptr.i.i, align 8
  %98 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load i32, ptr %count_dw.i.i, align 8
  %dec.i.i = add i32 %99, -1
  store i32 %dec.i.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i.i)
  %cmp.i114.i = icmp slt i32 %dec.i.i, 1
  br i1 %cmp.i114.i, label %if.then.i115.i, label %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit125.i_crit_edge

amdgpu_ring_write.exit.i.amdgpu_ring_write.exit125.i_crit_edge: ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit125.i

if.then.i115.i:                                   ; preds = %amdgpu_ring_write.exit.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit125.i

amdgpu_ring_write.exit125.i:                      ; preds = %if.then.i115.i, %amdgpu_ring_write.exit.i.amdgpu_ring_write.exit125.i_crit_edge
  %100 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %100)
  %101 = load ptr, ptr %ring1.i.i43, align 4
  %102 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %102)
  %103 = load i64, ptr %wptr.i.i, align 8
  %inc.i118.i = add i64 %103, 1
  store i64 %inc.i118.i, ptr %wptr.i.i, align 8
  %104 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %104)
  %105 = load i32, ptr %buf_mask.i.i45, align 8
  %106 = trunc i64 %103 to i32
  %idxprom.i120.i = and i32 %105, %106
  %arrayidx.i121.i = getelementptr i32, ptr %101, i32 %idxprom.i120.i
  %107 = ptrtoint ptr %arrayidx.i121.i to i32
  call void @__asan_store4_noabort(i32 %107)
  store volatile i32 0, ptr %arrayidx.i121.i, align 4
  %108 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %108)
  %109 = load i64, ptr %ptr_mask.i.i, align 8
  %110 = load i64, ptr %wptr.i.i, align 8
  %and3.i123.i = and i64 %110, %109
  store i64 %and3.i123.i, ptr %wptr.i.i, align 8
  %111 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load i32, ptr %count_dw.i.i, align 8
  %dec.i124.i = add i32 %112, -1
  store i32 %dec.i124.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i124.i)
  %cmp.i127.i = icmp slt i32 %dec.i124.i, 1
  br i1 %cmp.i127.i, label %if.then.i128.i, label %amdgpu_ring_write.exit125.i.amdgpu_ring_write.exit138.i_crit_edge

amdgpu_ring_write.exit125.i.amdgpu_ring_write.exit138.i_crit_edge: ; preds = %amdgpu_ring_write.exit125.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit138.i

if.then.i128.i:                                   ; preds = %amdgpu_ring_write.exit125.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit138.i

amdgpu_ring_write.exit138.i:                      ; preds = %if.then.i128.i, %amdgpu_ring_write.exit125.i.amdgpu_ring_write.exit138.i_crit_edge
  %113 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %113)
  %114 = load ptr, ptr %ring1.i.i43, align 4
  %115 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %115)
  %116 = load i64, ptr %wptr.i.i, align 8
  %inc.i131.i = add i64 %116, 1
  store i64 %inc.i131.i, ptr %wptr.i.i, align 8
  %117 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %117)
  %118 = load i32, ptr %buf_mask.i.i45, align 8
  %119 = trunc i64 %116 to i32
  %idxprom.i133.i = and i32 %118, %119
  %arrayidx.i134.i = getelementptr i32, ptr %114, i32 %idxprom.i133.i
  %120 = ptrtoint ptr %arrayidx.i134.i to i32
  call void @__asan_store4_noabort(i32 %120)
  store volatile i32 %queue_mask.0296.off0.i, ptr %arrayidx.i134.i, align 4
  %121 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %121)
  %122 = load i64, ptr %ptr_mask.i.i, align 8
  %123 = load i64, ptr %wptr.i.i, align 8
  %and3.i136.i = and i64 %123, %122
  store i64 %and3.i136.i, ptr %wptr.i.i, align 8
  %124 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %count_dw.i.i, align 8
  %dec.i137.i = add i32 %125, -1
  store i32 %dec.i137.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i137.i)
  %cmp.i140.i = icmp slt i32 %dec.i137.i, 1
  br i1 %cmp.i140.i, label %if.then.i141.i, label %amdgpu_ring_write.exit138.i.amdgpu_ring_write.exit151.i_crit_edge

amdgpu_ring_write.exit138.i.amdgpu_ring_write.exit151.i_crit_edge: ; preds = %amdgpu_ring_write.exit138.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit151.i

if.then.i141.i:                                   ; preds = %amdgpu_ring_write.exit138.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit151.i

amdgpu_ring_write.exit151.i:                      ; preds = %if.then.i141.i, %amdgpu_ring_write.exit138.i.amdgpu_ring_write.exit151.i_crit_edge
  %126 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load ptr, ptr %ring1.i.i43, align 4
  %128 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %128)
  %129 = load i64, ptr %wptr.i.i, align 8
  %inc.i144.i = add i64 %129, 1
  store i64 %inc.i144.i, ptr %wptr.i.i, align 8
  %130 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load i32, ptr %buf_mask.i.i45, align 8
  %132 = trunc i64 %129 to i32
  %idxprom.i146.i = and i32 %131, %132
  %arrayidx.i147.i = getelementptr i32, ptr %127, i32 %idxprom.i146.i
  %133 = ptrtoint ptr %arrayidx.i147.i to i32
  call void @__asan_store4_noabort(i32 %133)
  store volatile i32 %queue_mask.0296.off32.i, ptr %arrayidx.i147.i, align 4
  %134 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %134)
  %135 = load i64, ptr %ptr_mask.i.i, align 8
  %136 = load i64, ptr %wptr.i.i, align 8
  %and3.i149.i = and i64 %136, %135
  store i64 %and3.i149.i, ptr %wptr.i.i, align 8
  %137 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %137)
  %138 = load i32, ptr %count_dw.i.i, align 8
  %dec.i150.i = add i32 %138, -1
  store i32 %dec.i150.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i150.i)
  %cmp.i153.i = icmp slt i32 %dec.i150.i, 1
  br i1 %cmp.i153.i, label %if.then.i154.i, label %amdgpu_ring_write.exit151.i.amdgpu_ring_write.exit164.i_crit_edge

amdgpu_ring_write.exit151.i.amdgpu_ring_write.exit164.i_crit_edge: ; preds = %amdgpu_ring_write.exit151.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit164.i

if.then.i154.i:                                   ; preds = %amdgpu_ring_write.exit151.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit164.i

amdgpu_ring_write.exit164.i:                      ; preds = %if.then.i154.i, %amdgpu_ring_write.exit151.i.amdgpu_ring_write.exit164.i_crit_edge
  %139 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %139)
  %140 = load ptr, ptr %ring1.i.i43, align 4
  %141 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %141)
  %142 = load i64, ptr %wptr.i.i, align 8
  %inc.i157.i = add i64 %142, 1
  store i64 %inc.i157.i, ptr %wptr.i.i, align 8
  %143 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %143)
  %144 = load i32, ptr %buf_mask.i.i45, align 8
  %145 = trunc i64 %142 to i32
  %idxprom.i159.i = and i32 %144, %145
  %arrayidx.i160.i = getelementptr i32, ptr %140, i32 %idxprom.i159.i
  %146 = ptrtoint ptr %arrayidx.i160.i to i32
  call void @__asan_store4_noabort(i32 %146)
  store volatile i32 0, ptr %arrayidx.i160.i, align 4
  %147 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %147)
  %148 = load i64, ptr %ptr_mask.i.i, align 8
  %149 = load i64, ptr %wptr.i.i, align 8
  %and3.i162.i = and i64 %149, %148
  store i64 %and3.i162.i, ptr %wptr.i.i, align 8
  %150 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %150)
  %151 = load i32, ptr %count_dw.i.i, align 8
  %dec.i163.i = add i32 %151, -1
  store i32 %dec.i163.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i163.i)
  %cmp.i166.i = icmp slt i32 %dec.i163.i, 1
  br i1 %cmp.i166.i, label %if.then.i167.i, label %amdgpu_ring_write.exit164.i.amdgpu_ring_write.exit177.i_crit_edge

amdgpu_ring_write.exit164.i.amdgpu_ring_write.exit177.i_crit_edge: ; preds = %amdgpu_ring_write.exit164.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit177.i

if.then.i167.i:                                   ; preds = %amdgpu_ring_write.exit164.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit177.i

amdgpu_ring_write.exit177.i:                      ; preds = %if.then.i167.i, %amdgpu_ring_write.exit164.i.amdgpu_ring_write.exit177.i_crit_edge
  %152 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %152)
  %153 = load ptr, ptr %ring1.i.i43, align 4
  %154 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %154)
  %155 = load i64, ptr %wptr.i.i, align 8
  %inc.i170.i = add i64 %155, 1
  store i64 %inc.i170.i, ptr %wptr.i.i, align 8
  %156 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %156)
  %157 = load i32, ptr %buf_mask.i.i45, align 8
  %158 = trunc i64 %155 to i32
  %idxprom.i172.i = and i32 %157, %158
  %arrayidx.i173.i = getelementptr i32, ptr %153, i32 %idxprom.i172.i
  %159 = ptrtoint ptr %arrayidx.i173.i to i32
  call void @__asan_store4_noabort(i32 %159)
  store volatile i32 0, ptr %arrayidx.i173.i, align 4
  %160 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %160)
  %161 = load i64, ptr %ptr_mask.i.i, align 8
  %162 = load i64, ptr %wptr.i.i, align 8
  %and3.i175.i = and i64 %162, %161
  store i64 %and3.i175.i, ptr %wptr.i.i, align 8
  %163 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %163)
  %164 = load i32, ptr %count_dw.i.i, align 8
  %dec.i176.i = add i32 %164, -1
  store i32 %dec.i176.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i176.i)
  %cmp.i179.i = icmp slt i32 %dec.i176.i, 1
  br i1 %cmp.i179.i, label %if.then.i180.i, label %amdgpu_ring_write.exit177.i.amdgpu_ring_write.exit190.i_crit_edge

amdgpu_ring_write.exit177.i.amdgpu_ring_write.exit190.i_crit_edge: ; preds = %amdgpu_ring_write.exit177.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit190.i

if.then.i180.i:                                   ; preds = %amdgpu_ring_write.exit177.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit190.i

amdgpu_ring_write.exit190.i:                      ; preds = %if.then.i180.i, %amdgpu_ring_write.exit177.i.amdgpu_ring_write.exit190.i_crit_edge
  %165 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %165)
  %166 = load ptr, ptr %ring1.i.i43, align 4
  %167 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %167)
  %168 = load i64, ptr %wptr.i.i, align 8
  %inc.i183.i = add i64 %168, 1
  store i64 %inc.i183.i, ptr %wptr.i.i, align 8
  %169 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %169)
  %170 = load i32, ptr %buf_mask.i.i45, align 8
  %171 = trunc i64 %168 to i32
  %idxprom.i185.i = and i32 %170, %171
  %arrayidx.i186.i = getelementptr i32, ptr %166, i32 %idxprom.i185.i
  %172 = ptrtoint ptr %arrayidx.i186.i to i32
  call void @__asan_store4_noabort(i32 %172)
  store volatile i32 0, ptr %arrayidx.i186.i, align 4
  %173 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %173)
  %174 = load i64, ptr %ptr_mask.i.i, align 8
  %175 = load i64, ptr %wptr.i.i, align 8
  %and3.i188.i = and i64 %175, %174
  store i64 %and3.i188.i, ptr %wptr.i.i, align 8
  %176 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %176)
  %177 = load i32, ptr %count_dw.i.i, align 8
  %dec.i189.i = add i32 %177, -1
  store i32 %dec.i189.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i189.i)
  %cmp.i192.i = icmp slt i32 %dec.i189.i, 1
  br i1 %cmp.i192.i, label %if.then.i193.i, label %amdgpu_ring_write.exit190.i.amdgpu_ring_write.exit203.i_crit_edge

amdgpu_ring_write.exit190.i.amdgpu_ring_write.exit203.i_crit_edge: ; preds = %amdgpu_ring_write.exit190.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit203.i

if.then.i193.i:                                   ; preds = %amdgpu_ring_write.exit190.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit203.i

amdgpu_ring_write.exit203.i:                      ; preds = %if.then.i193.i, %amdgpu_ring_write.exit190.i.amdgpu_ring_write.exit203.i_crit_edge
  %178 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %178)
  %179 = load ptr, ptr %ring1.i.i43, align 4
  %180 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %180)
  %181 = load i64, ptr %wptr.i.i, align 8
  %inc.i196.i = add i64 %181, 1
  store i64 %inc.i196.i, ptr %wptr.i.i, align 8
  %182 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %182)
  %183 = load i32, ptr %buf_mask.i.i45, align 8
  %184 = trunc i64 %181 to i32
  %idxprom.i198.i = and i32 %183, %184
  %arrayidx.i199.i = getelementptr i32, ptr %179, i32 %idxprom.i198.i
  %185 = ptrtoint ptr %arrayidx.i199.i to i32
  call void @__asan_store4_noabort(i32 %185)
  store volatile i32 0, ptr %arrayidx.i199.i, align 4
  %186 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %186)
  %187 = load i64, ptr %ptr_mask.i.i, align 8
  %188 = load i64, ptr %wptr.i.i, align 8
  %and3.i201.i = and i64 %188, %187
  store i64 %and3.i201.i, ptr %wptr.i.i, align 8
  %189 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %189)
  %190 = load i32, ptr %count_dw.i.i, align 8
  %dec.i202.i = add i32 %190, -1
  store i32 %dec.i202.i, ptr %count_dw.i.i, align 8
  %191 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %191)
  %192 = load i32, ptr %num_compute_rings, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %192)
  %cmp37301.not.i = icmp eq i32 %192, 0
  br i1 %cmp37301.not.i, label %amdgpu_ring_write.exit203.i.for.end67.i_crit_edge, label %for.body39.lr.ph.i

amdgpu_ring_write.exit203.i.for.end67.i_crit_edge: ; preds = %amdgpu_ring_write.exit203.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end67.i

for.body39.lr.ph.i:                               ; preds = %amdgpu_ring_write.exit203.i
  %gpu_addr.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 70, i32 2
  br label %for.body39.i

for.body39.i:                                     ; preds = %amdgpu_ring_write.exit294.i.for.body39.i_crit_edge, %for.body39.lr.ph.i
  %i.1302.i = phi i32 [ 0, %for.body39.lr.ph.i ], [ %inc66.i, %amdgpu_ring_write.exit294.i.for.body39.i_crit_edge ]
  %mqd_obj.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 19
  %193 = ptrtoint ptr %mqd_obj.i to i32
  call void @__asan_load4_noabort(i32 %193)
  %194 = load ptr, ptr %mqd_obj.i, align 4
  %call42.i = tail call i64 @amdgpu_bo_gpu_offset(ptr noundef %194) #12
  %195 = ptrtoint ptr %gpu_addr.i to i32
  call void @__asan_load8_noabort(i32 %195)
  %196 = load i64, ptr %gpu_addr.i, align 8
  %wptr_offs.i = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 26
  %197 = ptrtoint ptr %wptr_offs.i to i32
  call void @__asan_load4_noabort(i32 %197)
  %198 = load i32, ptr %wptr_offs.i, align 8
  %mul43.i = shl i32 %198, 2
  %conv44.i = zext i32 %mul43.i to i64
  %add45.i = add i64 %196, %conv44.i
  %199 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %199)
  %200 = load i32, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %200)
  %cmp.i205.i = icmp slt i32 %200, 1
  br i1 %cmp.i205.i, label %if.then.i206.i, label %for.body39.i.amdgpu_ring_write.exit216.i_crit_edge

for.body39.i.amdgpu_ring_write.exit216.i_crit_edge: ; preds = %for.body39.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit216.i

if.then.i206.i:                                   ; preds = %for.body39.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit216.i

amdgpu_ring_write.exit216.i:                      ; preds = %if.then.i206.i, %for.body39.i.amdgpu_ring_write.exit216.i_crit_edge
  %201 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %201)
  %202 = load ptr, ptr %ring1.i.i43, align 4
  %203 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %203)
  %204 = load i64, ptr %wptr.i.i, align 8
  %inc.i209.i = add i64 %204, 1
  store i64 %inc.i209.i, ptr %wptr.i.i, align 8
  %205 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %205)
  %206 = load i32, ptr %buf_mask.i.i45, align 8
  %207 = trunc i64 %204 to i32
  %idxprom.i211.i = and i32 %206, %207
  %arrayidx.i212.i = getelementptr i32, ptr %202, i32 %idxprom.i211.i
  %208 = ptrtoint ptr %arrayidx.i212.i to i32
  call void @__asan_store4_noabort(i32 %208)
  store volatile i32 -1073372672, ptr %arrayidx.i212.i, align 4
  %209 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %209)
  %210 = load i64, ptr %ptr_mask.i.i, align 8
  %211 = load i64, ptr %wptr.i.i, align 8
  %and3.i214.i = and i64 %211, %210
  store i64 %and3.i214.i, ptr %wptr.i.i, align 8
  %212 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %212)
  %213 = load i32, ptr %count_dw.i.i, align 8
  %dec.i215.i = add i32 %213, -1
  store i32 %dec.i215.i, ptr %count_dw.i.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i215.i)
  %cmp.i218.i = icmp slt i32 %dec.i215.i, 1
  br i1 %cmp.i218.i, label %if.then.i219.i, label %amdgpu_ring_write.exit216.i.amdgpu_ring_write.exit229.i_crit_edge

amdgpu_ring_write.exit216.i.amdgpu_ring_write.exit229.i_crit_edge: ; preds = %amdgpu_ring_write.exit216.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit229.i

if.then.i219.i:                                   ; preds = %amdgpu_ring_write.exit216.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit229.i

amdgpu_ring_write.exit229.i:                      ; preds = %if.then.i219.i, %amdgpu_ring_write.exit216.i.amdgpu_ring_write.exit229.i_crit_edge
  %214 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %214)
  %215 = load ptr, ptr %ring1.i.i43, align 4
  %216 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %216)
  %217 = load i64, ptr %wptr.i.i, align 8
  %inc.i222.i = add i64 %217, 1
  store i64 %inc.i222.i, ptr %wptr.i.i, align 8
  %218 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %218)
  %219 = load i32, ptr %buf_mask.i.i45, align 8
  %220 = trunc i64 %217 to i32
  %idxprom.i224.i = and i32 %219, %220
  %arrayidx.i225.i = getelementptr i32, ptr %215, i32 %idxprom.i224.i
  %221 = ptrtoint ptr %arrayidx.i225.i to i32
  call void @__asan_store4_noabort(i32 %221)
  store volatile i32 536870912, ptr %arrayidx.i225.i, align 4
  %222 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %222)
  %223 = load i64, ptr %ptr_mask.i.i, align 8
  %224 = load i64, ptr %wptr.i.i, align 8
  %and3.i227.i = and i64 %224, %223
  store i64 %and3.i227.i, ptr %wptr.i.i, align 8
  %225 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %225)
  %226 = load i32, ptr %count_dw.i.i, align 8
  %dec.i228.i = add i32 %226, -1
  store i32 %dec.i228.i, ptr %count_dw.i.i, align 8
  %doorbell_index.i46 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 23
  %227 = ptrtoint ptr %doorbell_index.i46 to i32
  call void @__asan_load4_noabort(i32 %227)
  %228 = load i32, ptr %doorbell_index.i46, align 8
  %shl46.i = shl i32 %228, 2
  %queue.i47 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 18
  %229 = ptrtoint ptr %queue.i47 to i32
  call void @__asan_load4_noabort(i32 %229)
  %230 = load i32, ptr %queue.i47, align 8
  %shl47.i = shl i32 %230, 26
  %or48.i = or i32 %shl47.i, %shl46.i
  %pipe.i48 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 17
  %231 = ptrtoint ptr %pipe.i48 to i32
  call void @__asan_load4_noabort(i32 %231)
  %232 = load i32, ptr %pipe.i48, align 4
  %shl49.i = shl i32 %232, 29
  %or50.i = or i32 %or48.i, %shl49.i
  %me.i49 = getelementptr %struct.amdgpu_device, ptr %adev, i32 0, i32 106, i32 38, i32 %i.1302.i, i32 16
  %233 = ptrtoint ptr %me.i49 to i32
  call void @__asan_load4_noabort(i32 %233)
  %234 = load i32, ptr %me.i49, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %234)
  %cmp51.not.i = icmp eq i32 %234, 1
  %shl53.i = select i1 %cmp51.not.i, i32 0, i32 -2147483648
  %or54.i = or i32 %or50.i, %shl53.i
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i228.i)
  %cmp.i231.i = icmp slt i32 %dec.i228.i, 1
  br i1 %cmp.i231.i, label %if.then.i232.i, label %amdgpu_ring_write.exit229.i.amdgpu_ring_write.exit242.i_crit_edge

amdgpu_ring_write.exit229.i.amdgpu_ring_write.exit242.i_crit_edge: ; preds = %amdgpu_ring_write.exit229.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit242.i

if.then.i232.i:                                   ; preds = %amdgpu_ring_write.exit229.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit242.i

amdgpu_ring_write.exit242.i:                      ; preds = %if.then.i232.i, %amdgpu_ring_write.exit229.i.amdgpu_ring_write.exit242.i_crit_edge
  %235 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %235)
  %236 = load ptr, ptr %ring1.i.i43, align 4
  %237 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %237)
  %238 = load i64, ptr %wptr.i.i, align 8
  %inc.i235.i = add i64 %238, 1
  store i64 %inc.i235.i, ptr %wptr.i.i, align 8
  %239 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %239)
  %240 = load i32, ptr %buf_mask.i.i45, align 8
  %241 = trunc i64 %238 to i32
  %idxprom.i237.i = and i32 %240, %241
  %arrayidx.i238.i = getelementptr i32, ptr %236, i32 %idxprom.i237.i
  %242 = ptrtoint ptr %arrayidx.i238.i to i32
  call void @__asan_store4_noabort(i32 %242)
  store volatile i32 %or54.i, ptr %arrayidx.i238.i, align 4
  %243 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %243)
  %244 = load i64, ptr %ptr_mask.i.i, align 8
  %245 = load i64, ptr %wptr.i.i, align 8
  %and3.i240.i = and i64 %245, %244
  store i64 %and3.i240.i, ptr %wptr.i.i, align 8
  %246 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %246)
  %247 = load i32, ptr %count_dw.i.i, align 8
  %dec.i241.i = add i32 %247, -1
  store i32 %dec.i241.i, ptr %count_dw.i.i, align 8
  %conv56.i = trunc i64 %call42.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i241.i)
  %cmp.i244.i = icmp slt i32 %dec.i241.i, 1
  br i1 %cmp.i244.i, label %if.then.i245.i, label %amdgpu_ring_write.exit242.i.amdgpu_ring_write.exit255.i_crit_edge

amdgpu_ring_write.exit242.i.amdgpu_ring_write.exit255.i_crit_edge: ; preds = %amdgpu_ring_write.exit242.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit255.i

if.then.i245.i:                                   ; preds = %amdgpu_ring_write.exit242.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit255.i

amdgpu_ring_write.exit255.i:                      ; preds = %if.then.i245.i, %amdgpu_ring_write.exit242.i.amdgpu_ring_write.exit255.i_crit_edge
  %248 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %248)
  %249 = load ptr, ptr %ring1.i.i43, align 4
  %250 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %250)
  %251 = load i64, ptr %wptr.i.i, align 8
  %inc.i248.i = add i64 %251, 1
  store i64 %inc.i248.i, ptr %wptr.i.i, align 8
  %252 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %252)
  %253 = load i32, ptr %buf_mask.i.i45, align 8
  %254 = trunc i64 %251 to i32
  %idxprom.i250.i = and i32 %253, %254
  %arrayidx.i251.i = getelementptr i32, ptr %249, i32 %idxprom.i250.i
  %255 = ptrtoint ptr %arrayidx.i251.i to i32
  call void @__asan_store4_noabort(i32 %255)
  store volatile i32 %conv56.i, ptr %arrayidx.i251.i, align 4
  %256 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %256)
  %257 = load i64, ptr %ptr_mask.i.i, align 8
  %258 = load i64, ptr %wptr.i.i, align 8
  %and3.i253.i = and i64 %258, %257
  store i64 %and3.i253.i, ptr %wptr.i.i, align 8
  %259 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %259)
  %260 = load i32, ptr %count_dw.i.i, align 8
  %dec.i254.i = add i32 %260, -1
  store i32 %dec.i254.i, ptr %count_dw.i.i, align 8
  %shr57.i = lshr i64 %call42.i, 32
  %conv59.i = trunc i64 %shr57.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i254.i)
  %cmp.i257.i = icmp slt i32 %dec.i254.i, 1
  br i1 %cmp.i257.i, label %if.then.i258.i, label %amdgpu_ring_write.exit255.i.amdgpu_ring_write.exit268.i_crit_edge

amdgpu_ring_write.exit255.i.amdgpu_ring_write.exit268.i_crit_edge: ; preds = %amdgpu_ring_write.exit255.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit268.i

if.then.i258.i:                                   ; preds = %amdgpu_ring_write.exit255.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit268.i

amdgpu_ring_write.exit268.i:                      ; preds = %if.then.i258.i, %amdgpu_ring_write.exit255.i.amdgpu_ring_write.exit268.i_crit_edge
  %261 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %261)
  %262 = load ptr, ptr %ring1.i.i43, align 4
  %263 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %263)
  %264 = load i64, ptr %wptr.i.i, align 8
  %inc.i261.i = add i64 %264, 1
  store i64 %inc.i261.i, ptr %wptr.i.i, align 8
  %265 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %265)
  %266 = load i32, ptr %buf_mask.i.i45, align 8
  %267 = trunc i64 %264 to i32
  %idxprom.i263.i = and i32 %266, %267
  %arrayidx.i264.i = getelementptr i32, ptr %262, i32 %idxprom.i263.i
  %268 = ptrtoint ptr %arrayidx.i264.i to i32
  call void @__asan_store4_noabort(i32 %268)
  store volatile i32 %conv59.i, ptr %arrayidx.i264.i, align 4
  %269 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %269)
  %270 = load i64, ptr %ptr_mask.i.i, align 8
  %271 = load i64, ptr %wptr.i.i, align 8
  %and3.i266.i = and i64 %271, %270
  store i64 %and3.i266.i, ptr %wptr.i.i, align 8
  %272 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %272)
  %273 = load i32, ptr %count_dw.i.i, align 8
  %dec.i267.i = add i32 %273, -1
  store i32 %dec.i267.i, ptr %count_dw.i.i, align 8
  %conv61.i = trunc i64 %add45.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i267.i)
  %cmp.i270.i = icmp slt i32 %dec.i267.i, 1
  br i1 %cmp.i270.i, label %if.then.i271.i, label %amdgpu_ring_write.exit268.i.amdgpu_ring_write.exit281.i_crit_edge

amdgpu_ring_write.exit268.i.amdgpu_ring_write.exit281.i_crit_edge: ; preds = %amdgpu_ring_write.exit268.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit281.i

if.then.i271.i:                                   ; preds = %amdgpu_ring_write.exit268.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit281.i

amdgpu_ring_write.exit281.i:                      ; preds = %if.then.i271.i, %amdgpu_ring_write.exit268.i.amdgpu_ring_write.exit281.i_crit_edge
  %274 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %274)
  %275 = load ptr, ptr %ring1.i.i43, align 4
  %276 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %276)
  %277 = load i64, ptr %wptr.i.i, align 8
  %inc.i274.i = add i64 %277, 1
  store i64 %inc.i274.i, ptr %wptr.i.i, align 8
  %278 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %278)
  %279 = load i32, ptr %buf_mask.i.i45, align 8
  %280 = trunc i64 %277 to i32
  %idxprom.i276.i = and i32 %279, %280
  %arrayidx.i277.i = getelementptr i32, ptr %275, i32 %idxprom.i276.i
  %281 = ptrtoint ptr %arrayidx.i277.i to i32
  call void @__asan_store4_noabort(i32 %281)
  store volatile i32 %conv61.i, ptr %arrayidx.i277.i, align 4
  %282 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %282)
  %283 = load i64, ptr %ptr_mask.i.i, align 8
  %284 = load i64, ptr %wptr.i.i, align 8
  %and3.i279.i = and i64 %284, %283
  store i64 %and3.i279.i, ptr %wptr.i.i, align 8
  %285 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %285)
  %286 = load i32, ptr %count_dw.i.i, align 8
  %dec.i280.i = add i32 %286, -1
  store i32 %dec.i280.i, ptr %count_dw.i.i, align 8
  %shr62.i = lshr i64 %add45.i, 32
  %conv64.i = trunc i64 %shr62.i to i32
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %dec.i280.i)
  %cmp.i283.i = icmp slt i32 %dec.i280.i, 1
  br i1 %cmp.i283.i, label %if.then.i284.i, label %amdgpu_ring_write.exit281.i.amdgpu_ring_write.exit294.i_crit_edge

amdgpu_ring_write.exit281.i.amdgpu_ring_write.exit294.i_crit_edge: ; preds = %amdgpu_ring_write.exit281.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %amdgpu_ring_write.exit294.i

if.then.i284.i:                                   ; preds = %amdgpu_ring_write.exit281.i
  call void @__sanitizer_cov_trace_pc() #14
  tail call void (ptr, ...) @__drm_err(ptr noundef nonnull @.str.1) #12
  br label %amdgpu_ring_write.exit294.i

amdgpu_ring_write.exit294.i:                      ; preds = %if.then.i284.i, %amdgpu_ring_write.exit281.i.amdgpu_ring_write.exit294.i_crit_edge
  %287 = ptrtoint ptr %ring1.i.i43 to i32
  call void @__asan_load4_noabort(i32 %287)
  %288 = load ptr, ptr %ring1.i.i43, align 4
  %289 = ptrtoint ptr %wptr.i.i to i32
  call void @__asan_load8_noabort(i32 %289)
  %290 = load i64, ptr %wptr.i.i, align 8
  %inc.i287.i = add i64 %290, 1
  store i64 %inc.i287.i, ptr %wptr.i.i, align 8
  %291 = ptrtoint ptr %buf_mask.i.i45 to i32
  call void @__asan_load4_noabort(i32 %291)
  %292 = load i32, ptr %buf_mask.i.i45, align 8
  %293 = trunc i64 %290 to i32
  %idxprom.i289.i = and i32 %292, %293
  %arrayidx.i290.i = getelementptr i32, ptr %288, i32 %idxprom.i289.i
  %294 = ptrtoint ptr %arrayidx.i290.i to i32
  call void @__asan_store4_noabort(i32 %294)
  store volatile i32 %conv64.i, ptr %arrayidx.i290.i, align 4
  %295 = ptrtoint ptr %ptr_mask.i.i to i32
  call void @__asan_load8_noabort(i32 %295)
  %296 = load i64, ptr %ptr_mask.i.i, align 8
  %297 = load i64, ptr %wptr.i.i, align 8
  %and3.i292.i = and i64 %297, %296
  store i64 %and3.i292.i, ptr %wptr.i.i, align 8
  %298 = ptrtoint ptr %count_dw.i.i to i32
  call void @__asan_load4_noabort(i32 %298)
  %299 = load i32, ptr %count_dw.i.i, align 8
  %dec.i293.i = add i32 %299, -1
  store i32 %dec.i293.i, ptr %count_dw.i.i, align 8
  %inc66.i = add nuw i32 %i.1302.i, 1
  %300 = ptrtoint ptr %num_compute_rings to i32
  call void @__asan_load4_noabort(i32 %300)
  %301 = load i32, ptr %num_compute_rings, align 8
  %cmp37.i = icmp ult i32 %inc66.i, %301
  br i1 %cmp37.i, label %amdgpu_ring_write.exit294.i.for.body39.i_crit_edge, label %amdgpu_ring_write.exit294.i.for.end67.i_crit_edge

amdgpu_ring_write.exit294.i.for.end67.i_crit_edge: ; preds = %amdgpu_ring_write.exit294.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.end67.i

amdgpu_ring_write.exit294.i.for.body39.i_crit_edge: ; preds = %amdgpu_ring_write.exit294.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body39.i

for.end67.i:                                      ; preds = %amdgpu_ring_write.exit294.i.for.end67.i_crit_edge, %amdgpu_ring_write.exit203.i.for.end67.i_crit_edge
  tail call void @amdgpu_ring_commit(ptr noundef %ring.i) #12
  br label %done

done:                                             ; preds = %for.end67.i, %if.then30.i, %if.end11.done_crit_edge, %do.end.i, %for.body.done_crit_edge
  %r.1 = phi i32 [ %retval.1.i.i, %do.end.i ], [ %call28.i, %if.then30.i ], [ 0, %for.end67.i ], [ %retval.1.i.i, %for.body.done_crit_edge ], [ %r.0, %if.end11.done_crit_edge ]
  ret i32 %r.1
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_bo_kmap(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @ww_mutex_lock_interruptible(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_mqd_commit(ptr noundef %adev, ptr nocapture noundef readonly %mqd) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %cp_mqd_base_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %mqd, i32 0, i32 128
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12419, i32 noundef 0) #12
  %and = and i32 %call, 2147483647
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12419, i32 noundef %and, i32 noundef 0) #12
  br label %for.body

for.body:                                         ; preds = %for.body.for.body_crit_edge, %entry
  %mqd_reg.01 = phi i32 [ 12872, %entry ], [ %inc, %for.body.for.body_crit_edge ]
  %sub = add nsw i32 %mqd_reg.01, -12869
  %arrayidx = getelementptr i32, ptr %cp_mqd_base_addr_lo, i32 %sub
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef %mqd_reg.01, i32 noundef %1, i32 noundef 0) #12
  %inc = add nuw nsw i32 %mqd_reg.01, 1
  %exitcond.not = icmp eq i32 %inc, 12909
  br i1 %exitcond.not, label %for.end, label %for.body.for.body_crit_edge

for.body.for.body_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

for.end:                                          ; preds = %for.body
  %asic_type = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %2 = ptrtoint ptr %asic_type to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %asic_type, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 11, i32 %3)
  %cmp1.not = icmp eq i32 %3, 11
  br i1 %cmp1.not, label %for.end.if.end_crit_edge, label %if.then

for.end.if.end_crit_edge:                         ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %for.end
  call void @__sanitizer_cov_trace_pc() #14
  %cp_hqd_eop_rptr = getelementptr inbounds %struct.vi_mqd, ptr %mqd, i32 0, i32 168
  %4 = ptrtoint ptr %cp_hqd_eop_rptr to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %cp_hqd_eop_rptr, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12909, i32 noundef %5, i32 noundef 0) #12
  %cp_hqd_eop_wptr = getelementptr inbounds %struct.vi_mqd, ptr %mqd, i32 0, i32 169
  %6 = ptrtoint ptr %cp_hqd_eop_wptr to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cp_hqd_eop_wptr, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12910, i32 noundef %7, i32 noundef 0) #12
  %cp_hqd_eop_wptr_mem = getelementptr inbounds %struct.vi_mqd, ptr %mqd, i32 0, i32 180
  %8 = ptrtoint ptr %cp_hqd_eop_wptr_mem to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cp_hqd_eop_wptr_mem, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12921, i32 noundef %9, i32 noundef 0) #12
  br label %if.end

if.end:                                           ; preds = %if.then, %for.end.if.end_crit_edge
  %arrayidx6 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 170
  %10 = ptrtoint ptr %arrayidx6 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx6, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12911, i32 noundef %11, i32 noundef 0) #12
  %arrayidx6.1 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 171
  %12 = ptrtoint ptr %arrayidx6.1 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %arrayidx6.1, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12912, i32 noundef %13, i32 noundef 0) #12
  %arrayidx6.2 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 172
  %14 = ptrtoint ptr %arrayidx6.2 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx6.2, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12913, i32 noundef %15, i32 noundef 0) #12
  %arrayidx6.3 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 173
  %16 = ptrtoint ptr %arrayidx6.3 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %arrayidx6.3, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12914, i32 noundef %17, i32 noundef 0) #12
  %arrayidx6.4 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 174
  %18 = ptrtoint ptr %arrayidx6.4 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %arrayidx6.4, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12915, i32 noundef %19, i32 noundef 0) #12
  %arrayidx6.5 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 175
  %20 = ptrtoint ptr %arrayidx6.5 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %arrayidx6.5, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12916, i32 noundef %21, i32 noundef 0) #12
  %arrayidx6.6 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 176
  %22 = ptrtoint ptr %arrayidx6.6 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %arrayidx6.6, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12917, i32 noundef %23, i32 noundef 0) #12
  %arrayidx6.7 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 177
  %24 = ptrtoint ptr %arrayidx6.7 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %arrayidx6.7, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12918, i32 noundef %25, i32 noundef 0) #12
  %arrayidx6.8 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 178
  %26 = ptrtoint ptr %arrayidx6.8 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %arrayidx6.8, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12919, i32 noundef %27, i32 noundef 0) #12
  %arrayidx6.9 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 179
  %28 = ptrtoint ptr %arrayidx6.9 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx6.9, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12920, i32 noundef %29, i32 noundef 0) #12
  %30 = ptrtoint ptr %cp_mqd_base_addr_lo to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %cp_mqd_base_addr_lo, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12869, i32 noundef %31, i32 noundef 0) #12
  %arrayidx14.1 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 129
  %32 = ptrtoint ptr %arrayidx14.1 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %arrayidx14.1, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12870, i32 noundef %33, i32 noundef 0) #12
  %arrayidx14.2 = getelementptr %struct.vi_mqd, ptr %mqd, i32 0, i32 130
  %34 = ptrtoint ptr %arrayidx14.2 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %arrayidx14.2, align 4
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12871, i32 noundef %35, i32 noundef 0) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_mqd_init(ptr noundef %ring) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ring, align 8
  %mqd_ptr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 21
  %2 = ptrtoint ptr %mqd_ptr to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %mqd_ptr, align 8
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1070528512, ptr %3, align 4
  %compute_pipelinestat_enable = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 11
  %5 = ptrtoint ptr %compute_pipelinestat_enable to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 1, ptr %compute_pipelinestat_enable, align 4
  %compute_static_thread_mgmt_se0 = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 23
  %6 = ptrtoint ptr %compute_static_thread_mgmt_se0 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 -1, ptr %compute_static_thread_mgmt_se0, align 4
  %compute_static_thread_mgmt_se1 = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 24
  %7 = ptrtoint ptr %compute_static_thread_mgmt_se1 to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %compute_static_thread_mgmt_se1, align 4
  %compute_static_thread_mgmt_se2 = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 26
  %8 = ptrtoint ptr %compute_static_thread_mgmt_se2 to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 -1, ptr %compute_static_thread_mgmt_se2, align 4
  %compute_static_thread_mgmt_se3 = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 27
  %9 = ptrtoint ptr %compute_static_thread_mgmt_se3 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 -1, ptr %compute_static_thread_mgmt_se3, align 4
  %compute_misc_reserved = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 32
  %10 = ptrtoint ptr %compute_misc_reserved to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 3, ptr %compute_misc_reserved, align 4
  %mqd_gpu_addr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 20
  %11 = ptrtoint ptr %mqd_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %11)
  %12 = load i64, ptr %mqd_gpu_addr, align 8
  %13 = trunc i64 %12 to i32
  %conv = add i32 %13, 2056
  %dynamic_cu_mask_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 126
  %14 = ptrtoint ptr %dynamic_cu_mask_addr_lo to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %conv, ptr %dynamic_cu_mask_addr_lo, align 4
  %15 = load i64, ptr %mqd_gpu_addr, align 8
  %add3 = add i64 %15, 2056
  %shr = lshr i64 %add3, 32
  %conv5 = trunc i64 %shr to i32
  %dynamic_cu_mask_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 127
  %16 = ptrtoint ptr %dynamic_cu_mask_addr_hi to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 %conv5, ptr %dynamic_cu_mask_addr_hi, align 4
  %eop_gpu_addr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 22
  %17 = ptrtoint ptr %eop_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %eop_gpu_addr, align 8
  %shr6 = lshr i64 %18, 8
  %conv7 = trunc i64 %shr6 to i32
  %cp_hqd_eop_base_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 165
  %19 = ptrtoint ptr %cp_hqd_eop_base_addr_lo to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %conv7, ptr %cp_hqd_eop_base_addr_lo, align 4
  %shr8 = lshr i64 %18, 40
  %conv10 = trunc i64 %shr8 to i32
  %cp_hqd_eop_base_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 166
  %20 = ptrtoint ptr %cp_hqd_eop_base_addr_hi to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %conv10, ptr %cp_hqd_eop_base_addr_hi, align 4
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12908, i32 noundef 0) #12
  %and11 = and i32 %call, -64
  %or = or i32 %and11, 9
  %cp_hqd_eop_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 167
  %21 = ptrtoint ptr %cp_hqd_eop_control to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %or, ptr %cp_hqd_eop_control, align 4
  %call12 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12884, i32 noundef 0) #12
  %and13 = and i32 %call12, -1073741825
  %use_doorbell = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 24
  %22 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_load1_noabort(i32 %22)
  %23 = load i8, ptr %use_doorbell, align 4, !range !432
  %24 = zext i8 %23 to i32
  %shl = shl nuw nsw i32 %24, 30
  %or16 = or i32 %shl, %and13
  %cp_hqd_pq_doorbell_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 143
  %25 = ptrtoint ptr %cp_hqd_pq_doorbell_control to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %or16, ptr %cp_hqd_pq_doorbell_control, align 4
  %26 = ptrtoint ptr %mqd_gpu_addr to i32
  call void @__asan_load8_noabort(i32 %26)
  %27 = load i64, ptr %mqd_gpu_addr, align 8
  %28 = trunc i64 %27 to i32
  %conv19 = and i32 %28, -4
  %cp_mqd_base_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 128
  %29 = ptrtoint ptr %cp_mqd_base_addr_lo to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %conv19, ptr %cp_mqd_base_addr_lo, align 4
  %30 = load i64, ptr %mqd_gpu_addr, align 8
  %shr21 = lshr i64 %30, 32
  %conv23 = trunc i64 %shr21 to i32
  %cp_mqd_base_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 129
  %31 = ptrtoint ptr %cp_mqd_base_addr_hi to i32
  call void @__asan_store4_noabort(i32 %31)
  store i32 %conv23, ptr %cp_mqd_base_addr_hi, align 4
  %call24 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12903, i32 noundef 0) #12
  %and25 = and i32 %call24, -16
  %cp_mqd_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 162
  %32 = ptrtoint ptr %cp_mqd_control to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %and25, ptr %cp_mqd_control, align 4
  %gpu_addr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 12
  %33 = ptrtoint ptr %gpu_addr to i32
  call void @__asan_load8_noabort(i32 %33)
  %34 = load i64, ptr %gpu_addr, align 8
  %shr27 = lshr i64 %34, 8
  %conv28 = trunc i64 %shr27 to i32
  %cp_hqd_pq_base_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 136
  %35 = ptrtoint ptr %cp_hqd_pq_base_lo to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 %conv28, ptr %cp_hqd_pq_base_lo, align 4
  %shr29 = lshr i64 %34, 40
  %conv31 = trunc i64 %shr29 to i32
  %cp_hqd_pq_base_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 137
  %36 = ptrtoint ptr %cp_hqd_pq_base_hi to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 %conv31, ptr %cp_hqd_pq_base_hi, align 4
  %call32 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12886, i32 noundef 0) #12
  %and33 = and i32 %call32, 268026048
  %ring_size = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 9
  %37 = ptrtoint ptr %ring_size to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %ring_size, align 8
  %div1 = lshr i32 %38, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 7, i32 %38)
  %cmp.i = icmp ugt i32 %38, 7
  %sub.i2 = add nsw i32 %div1, -1
  %39 = tail call i32 @llvm.ctlz.i32(i32 %sub.i2, i1 false) #12, !range !451
  %phi.bo = sub nsw i32 31, %39
  %phi.bo4 = and i32 %phi.bo, 63
  %cond73 = select i1 %cmp.i, i32 %phi.bo4, i32 63
  %or77 = or i32 %and33, %cond73
  %or89 = or i32 %or77, -1073610752
  %cp_hqd_pq_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 145
  %40 = ptrtoint ptr %cp_hqd_pq_control to i32
  call void @__asan_store4_noabort(i32 %40)
  store i32 %or89, ptr %cp_hqd_pq_control, align 4
  %gpu_addr90 = getelementptr inbounds %struct.amdgpu_device, ptr %1, i32 0, i32 70, i32 2
  %41 = ptrtoint ptr %gpu_addr90 to i32
  call void @__asan_load8_noabort(i32 %41)
  %42 = load i64, ptr %gpu_addr90, align 8
  %rptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 6
  %43 = ptrtoint ptr %rptr_offs to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %rptr_offs, align 8
  %mul = shl i32 %44, 2
  %conv91 = zext i32 %mul to i64
  %add92 = add i64 %42, %conv91
  %45 = trunc i64 %add92 to i32
  %conv94 = and i32 %45, -4
  %cp_hqd_pq_rptr_report_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 139
  %46 = ptrtoint ptr %cp_hqd_pq_rptr_report_addr_lo to i32
  call void @__asan_store4_noabort(i32 %46)
  store i32 %conv94, ptr %cp_hqd_pq_rptr_report_addr_lo, align 4
  %shr95 = lshr i64 %add92, 32
  %conv97 = trunc i64 %shr95 to i32
  %and98 = and i32 %conv97, 65535
  %cp_hqd_pq_rptr_report_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 140
  %47 = ptrtoint ptr %cp_hqd_pq_rptr_report_addr_hi to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 %and98, ptr %cp_hqd_pq_rptr_report_addr_hi, align 4
  %48 = load i64, ptr %gpu_addr90, align 8
  %wptr_offs = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 26
  %49 = ptrtoint ptr %wptr_offs to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %wptr_offs, align 8
  %mul101 = shl i32 %50, 2
  %conv102 = zext i32 %mul101 to i64
  %add103 = add i64 %48, %conv102
  %51 = trunc i64 %add103 to i32
  %conv105 = and i32 %51, -4
  %cp_hqd_pq_wptr_poll_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 141
  %52 = ptrtoint ptr %cp_hqd_pq_wptr_poll_addr_lo to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 %conv105, ptr %cp_hqd_pq_wptr_poll_addr_lo, align 4
  %shr106 = lshr i64 %add103, 32
  %conv108 = trunc i64 %shr106 to i32
  %and109 = and i32 %conv108, 65535
  %cp_hqd_pq_wptr_poll_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 142
  %53 = ptrtoint ptr %cp_hqd_pq_wptr_poll_addr_hi to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %and109, ptr %cp_hqd_pq_wptr_poll_addr_hi, align 4
  %54 = ptrtoint ptr %use_doorbell to i32
  call void @__asan_load1_noabort(i32 %54)
  %55 = load i8, ptr %use_doorbell, align 4, !range !432
  call void @__sanitizer_cov_trace_const_cmp1(i8 0, i8 %55)
  %tobool111.not = icmp eq i8 %55, 0
  br i1 %tobool111.not, label %entry.if.end_crit_edge, label %if.then

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  %call112 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12884, i32 noundef 0) #12
  %and113 = and i32 %call112, 796917763
  %doorbell_index = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 23
  %56 = ptrtoint ptr %doorbell_index to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %doorbell_index, align 8
  %shl114 = shl i32 %57, 2
  %and115 = and i32 %shl114, 8388604
  %or116 = or i32 %and113, %and115
  %or118 = or i32 %or116, 1073741824
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %tmp.0 = phi i32 [ %or118, %if.then ], [ 0, %entry.if.end_crit_edge ]
  %58 = ptrtoint ptr %cp_hqd_pq_doorbell_control to i32
  call void @__asan_store4_noabort(i32 %58)
  store i32 %tmp.0, ptr %cp_hqd_pq_doorbell_control, align 4
  %wptr = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 7
  %59 = ptrtoint ptr %wptr to i32
  call void @__asan_store8_noabort(i32 %59)
  store i64 0, ptr %wptr, align 8
  %cp_hqd_pq_wptr = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 144
  %60 = ptrtoint ptr %cp_hqd_pq_wptr to i32
  call void @__asan_store4_noabort(i32 %60)
  store i32 0, ptr %cp_hqd_pq_wptr, align 4
  %call126 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12879, i32 noundef 0) #12
  %cp_hqd_pq_rptr = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 138
  %61 = ptrtoint ptr %cp_hqd_pq_rptr to i32
  call void @__asan_store4_noabort(i32 %61)
  store i32 %call126, ptr %cp_hqd_pq_rptr, align 4
  %cp_hqd_vmid = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 131
  %62 = ptrtoint ptr %cp_hqd_vmid to i32
  call void @__asan_store4_noabort(i32 %62)
  store i32 0, ptr %cp_hqd_vmid, align 4
  %call127 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12873, i32 noundef 0) #12
  %and128 = and i32 %call127, -261889
  %or129 = or i32 %and128, 21248
  %cp_hqd_persistent_state = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 132
  %63 = ptrtoint ptr %cp_hqd_persistent_state to i32
  call void @__asan_store4_noabort(i32 %63)
  store i32 %or129, ptr %cp_hqd_persistent_state, align 4
  %call130 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12890, i32 noundef 0) #12
  %or134 = or i32 %call130, 405798912
  %cp_hqd_ib_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 149
  %64 = ptrtoint ptr %cp_hqd_ib_control to i32
  call void @__asan_store4_noabort(i32 %64)
  store i32 %or134, ptr %cp_hqd_ib_control, align 4
  %call135 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12891, i32 noundef 0) #12
  %or137 = or i32 %call135, 402653184
  %cp_hqd_iq_timer = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 150
  %65 = ptrtoint ptr %cp_hqd_iq_timer to i32
  call void @__asan_store4_noabort(i32 %65)
  store i32 %or137, ptr %cp_hqd_iq_timer, align 4
  %call138 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12914, i32 noundef 0) #12
  %or140 = or i32 %call138, 6
  %cp_hqd_ctx_save_control = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 173
  %66 = ptrtoint ptr %cp_hqd_ctx_save_control to i32
  call void @__asan_store4_noabort(i32 %66)
  store i32 %or140, ptr %cp_hqd_ctx_save_control, align 4
  %call141 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12909, i32 noundef 0) #12
  %cp_hqd_eop_rptr = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 168
  %67 = ptrtoint ptr %cp_hqd_eop_rptr to i32
  call void @__asan_store4_noabort(i32 %67)
  store i32 %call141, ptr %cp_hqd_eop_rptr, align 4
  %call142 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12910, i32 noundef 0) #12
  %cp_hqd_eop_wptr = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 169
  %68 = ptrtoint ptr %cp_hqd_eop_wptr to i32
  call void @__asan_store4_noabort(i32 %68)
  store i32 %call142, ptr %cp_hqd_eop_wptr, align 4
  %call143 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12912, i32 noundef 0) #12
  %cp_hqd_ctx_save_base_addr_lo = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 171
  %69 = ptrtoint ptr %cp_hqd_ctx_save_base_addr_lo to i32
  call void @__asan_store4_noabort(i32 %69)
  store i32 %call143, ptr %cp_hqd_ctx_save_base_addr_lo, align 4
  %call144 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12913, i32 noundef 0) #12
  %cp_hqd_ctx_save_base_addr_hi = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 172
  %70 = ptrtoint ptr %cp_hqd_ctx_save_base_addr_hi to i32
  call void @__asan_store4_noabort(i32 %70)
  store i32 %call144, ptr %cp_hqd_ctx_save_base_addr_hi, align 4
  %call145 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12915, i32 noundef 0) #12
  %cp_hqd_cntl_stack_offset = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 174
  %71 = ptrtoint ptr %cp_hqd_cntl_stack_offset to i32
  call void @__asan_store4_noabort(i32 %71)
  store i32 %call145, ptr %cp_hqd_cntl_stack_offset, align 4
  %call146 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12916, i32 noundef 0) #12
  %cp_hqd_cntl_stack_size = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 175
  %72 = ptrtoint ptr %cp_hqd_cntl_stack_size to i32
  call void @__asan_store4_noabort(i32 %72)
  store i32 %call146, ptr %cp_hqd_cntl_stack_size, align 4
  %call147 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12917, i32 noundef 0) #12
  %cp_hqd_wg_state_offset = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 176
  %73 = ptrtoint ptr %cp_hqd_wg_state_offset to i32
  call void @__asan_store4_noabort(i32 %73)
  store i32 %call147, ptr %cp_hqd_wg_state_offset, align 4
  %call148 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12918, i32 noundef 0) #12
  %cp_hqd_ctx_save_size = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 177
  %74 = ptrtoint ptr %cp_hqd_ctx_save_size to i32
  call void @__asan_store4_noabort(i32 %74)
  store i32 %call148, ptr %cp_hqd_ctx_save_size, align 4
  %call149 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12911, i32 noundef 0) #12
  %cp_hqd_eop_done_events = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 170
  %75 = ptrtoint ptr %cp_hqd_eop_done_events to i32
  call void @__asan_store4_noabort(i32 %75)
  store i32 %call149, ptr %cp_hqd_eop_done_events, align 4
  %call150 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12920, i32 noundef 0) #12
  %cp_hqd_error = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 179
  %76 = ptrtoint ptr %cp_hqd_error to i32
  call void @__asan_store4_noabort(i32 %76)
  store i32 %call150, ptr %cp_hqd_error, align 4
  %call151 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12921, i32 noundef 0) #12
  %cp_hqd_eop_wptr_mem = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 180
  %77 = ptrtoint ptr %cp_hqd_eop_wptr_mem to i32
  call void @__asan_store4_noabort(i32 %77)
  store i32 %call151, ptr %cp_hqd_eop_wptr_mem, align 4
  %call152 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12922, i32 noundef 0) #12
  %cp_hqd_eop_dones = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 181
  %78 = ptrtoint ptr %cp_hqd_eop_dones to i32
  call void @__asan_store4_noabort(i32 %78)
  store i32 %call152, ptr %cp_hqd_eop_dones, align 4
  %funcs.i = getelementptr inbounds %struct.amdgpu_ring, ptr %ring, i32 0, i32 1
  %79 = ptrtoint ptr %funcs.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load ptr, ptr %funcs.i, align 4
  %81 = ptrtoint ptr %80 to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %80, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 1, i32 %82)
  %cmp.i3 = icmp eq i32 %82, 1
  br i1 %cmp.i3, label %if.then.i, label %if.end.gfx_v8_0_mqd_set_priority.exit_crit_edge

if.end.gfx_v8_0_mqd_set_priority.exit_crit_edge:  ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_mqd_set_priority.exit

if.then.i:                                        ; preds = %if.end
  %83 = ptrtoint ptr %ring to i32
  call void @__asan_load4_noabort(i32 %83)
  %84 = load ptr, ptr %ring, align 8
  %call.i = tail call zeroext i1 @amdgpu_gfx_is_high_priority_compute_queue(ptr noundef %84, ptr noundef %ring) #12
  br i1 %call.i, label %if.then2.i, label %if.then.i.gfx_v8_0_mqd_set_priority.exit_crit_edge

if.then.i.gfx_v8_0_mqd_set_priority.exit_crit_edge: ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  br label %gfx_v8_0_mqd_set_priority.exit

if.then2.i:                                       ; preds = %if.then.i
  call void @__sanitizer_cov_trace_pc() #14
  %cp_hqd_pipe_priority.i = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 133
  %85 = ptrtoint ptr %cp_hqd_pipe_priority.i to i32
  call void @__asan_store4_noabort(i32 %85)
  store i32 2, ptr %cp_hqd_pipe_priority.i, align 4
  %cp_hqd_queue_priority.i = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 134
  %86 = ptrtoint ptr %cp_hqd_queue_priority.i to i32
  call void @__asan_store4_noabort(i32 %86)
  store i32 15, ptr %cp_hqd_queue_priority.i, align 4
  br label %gfx_v8_0_mqd_set_priority.exit

gfx_v8_0_mqd_set_priority.exit:                   ; preds = %if.then2.i, %if.then.i.gfx_v8_0_mqd_set_priority.exit_crit_edge, %if.end.gfx_v8_0_mqd_set_priority.exit_crit_edge
  %call153 = tail call i32 @amdgpu_device_rreg(ptr noundef %1, i32 noundef 12876, i32 noundef 0) #12
  %cp_hqd_quantum = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 135
  %87 = ptrtoint ptr %cp_hqd_quantum to i32
  call void @__asan_store4_noabort(i32 %87)
  store i32 %call153, ptr %cp_hqd_quantum, align 4
  %88 = ptrtoint ptr %funcs.i to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load ptr, ptr %funcs.i, align 4
  %90 = ptrtoint ptr %89 to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load i32, ptr %89, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 9, i32 %91)
  %cmp154 = icmp eq i32 %91, 9
  br i1 %cmp154, label %if.then156, label %gfx_v8_0_mqd_set_priority.exit.if.end157_crit_edge

gfx_v8_0_mqd_set_priority.exit.if.end157_crit_edge: ; preds = %gfx_v8_0_mqd_set_priority.exit
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end157

if.then156:                                       ; preds = %gfx_v8_0_mqd_set_priority.exit
  call void @__sanitizer_cov_trace_pc() #14
  %cp_hqd_active = getelementptr inbounds %struct.vi_mqd, ptr %3, i32 0, i32 130
  %92 = ptrtoint ptr %cp_hqd_active to i32
  call void @__asan_store4_noabort(i32 %92)
  store i32 1, ptr %cp_hqd_active, align 4
  br label %if.end157

if.end157:                                        ; preds = %if.then156, %gfx_v8_0_mqd_set_priority.exit.if.end157_crit_edge
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__kasan_check_read(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i64 @amdgpu_bo_gpu_offset(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_ring_test_helper(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_irq_put(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__dynamic_pr_debug(ptr noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_rlc_enter_safe_mode(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @amdgpu_gfx_rlc_exit_safe_mode(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_deactivate_hqd(ptr noundef %adev) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12871, i32 noundef 0) #12
  %and = and i32 %call, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %entry.if.end11_crit_edge, label %if.then

entry.if.end11_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11

if.then:                                          ; preds = %entry
  %call1 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12893, i32 noundef 0) #12
  %and2 = and i32 %call1, -8
  %or = or i32 %and2, 2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12893, i32 noundef %or, i32 noundef 0) #12
  %usec_timeout = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 11
  %0 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %usec_timeout, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %cmp1 = icmp sgt i32 %1, 0
  br i1 %cmp1, label %if.then.for.body_crit_edge, label %if.then.if.end11_crit_edge

if.then.if.end11_crit_edge:                       ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11

if.then.for.body_crit_edge:                       ; preds = %if.then
  br label %for.body

for.body:                                         ; preds = %if.end.for.body_crit_edge, %if.then.for.body_crit_edge
  %i.02 = phi i32 [ %inc, %if.end.for.body_crit_edge ], [ 0, %if.then.for.body_crit_edge ]
  %call3 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12871, i32 noundef 0) #12
  %and4 = and i32 %call3, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and4)
  %tobool5.not = icmp eq i32 %and4, 0
  br i1 %tobool5.not, label %for.body.if.end11_crit_edge, label %if.end

for.body.if.end11_crit_edge:                      ; preds = %for.body
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11

if.end:                                           ; preds = %for.body
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %2 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %2(i32 noundef 214748) #12
  %inc = add nuw nsw i32 %i.02, 1
  %3 = ptrtoint ptr %usec_timeout to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %usec_timeout, align 8
  %cmp = icmp slt i32 %inc, %4
  br i1 %cmp, label %if.end.for.body_crit_edge, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end11

if.end.for.body_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %for.body

if.end11:                                         ; preds = %if.end.if.end11_crit_edge, %for.body.if.end11_crit_edge, %if.then.if.end11_crit_edge, %entry.if.end11_crit_edge
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12893, i32 noundef 0, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12879, i32 noundef 0, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12885, i32 noundef 0, i32 noundef 0) #12
  ret void
}

; Function Attrs: cold null_pointer_is_valid
declare dso_local void @_dev_info(ptr noundef, ptr noundef, ...) local_unnamed_addr #5

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_update_medium_grain_clock_gating(ptr noundef %adev, i1 noundef zeroext %enable) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @amdgpu_gfx_rlc_enter_safe_mode(ptr noundef %adev) #12
  br i1 %enable, label %land.lhs.true, label %entry.if.else54_crit_edge

entry.if.else54_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else54

land.lhs.true:                                    ; preds = %entry
  %cg_flags = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 99
  %0 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %cg_flags, align 8
  %and = and i32 %1, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool1.not = icmp eq i32 %and, 0
  br i1 %tobool1.not, label %land.lhs.true.if.else54_crit_edge, label %if.then

land.lhs.true.if.else54_crit_edge:                ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else54

if.then:                                          ; preds = %land.lhs.true
  %and3 = and i32 %1, 2
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and3)
  %tobool4.not = icmp eq i32 %and3, 0
  br i1 %tobool4.not, label %if.then.if.end19_crit_edge, label %if.then5

if.then.if.end19_crit_edge:                       ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end19

if.then5:                                         ; preds = %if.then
  %and7 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and7)
  %tobool8.not = icmp eq i32 %and7, 0
  br i1 %tobool8.not, label %if.then5.if.end_crit_edge, label %if.then9

if.then5.if.end_crit_edge:                        ; preds = %if.then5
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then9:                                         ; preds = %if.then5
  call void @__sanitizer_cov_trace_pc() #14
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60422, i32 noundef 0) #12
  %or = or i32 %call, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60422, i32 noundef %or, i32 noundef 0) #12
  br label %if.end

if.end:                                           ; preds = %if.then9, %if.then5.if.end_crit_edge
  %2 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cg_flags, align 8
  %and12 = and i32 %3, 64
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and12)
  %tobool13.not = icmp eq i32 %and12, 0
  br i1 %tobool13.not, label %if.end.if.end19_crit_edge, label %if.then14

if.end.if.end19_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end19

if.then14:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %call15 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12409, i32 noundef 0) #12
  %or17 = or i32 %call15, 1
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12409, i32 noundef %or17, i32 noundef 0) #12
  br label %if.end19

if.end19:                                         ; preds = %if.then14, %if.end.if.end19_crit_edge, %if.then.if.end19_crit_edge
  %call20 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60488, i32 noundef 0) #12
  %flags = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 9
  %4 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %flags, align 8
  %and21 = and i32 %5, 131072
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and21)
  %tobool22.not = icmp eq i32 %and21, 0
  %data.0.v = select i1 %tobool22.not, i32 -40, i32 -8
  %data.0 = and i32 %data.0.v, %call20
  call void @__sanitizer_cov_trace_cmp4(i32 %call20, i32 %data.0)
  %cmp.not = icmp eq i32 %call20, %data.0
  br i1 %cmp.not, label %if.end19.if.end28_crit_edge, label %if.then27

if.end19.if.end28_crit_edge:                      ; preds = %if.end19
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end28

if.then27:                                        ; preds = %if.end19
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60488, i32 noundef %data.0, i32 noundef 0) #12
  br label %if.end28

if.end28:                                         ; preds = %if.then27, %if.end19.if.end28_crit_edge
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %6 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %7)
  %cmp.i = icmp eq i32 %7, 14
  %data.0.v.i = select i1 %cmp.i, i32 -1006698496, i32 14
  %data.0.i = and i32 %data.0.v.i, %call.i
  %or5.i = or i32 %data.0.i, 939524351
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i, i32 noundef 0) #12
  %8 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cg_flags, align 8
  %and30 = and i32 %9, 16
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and30)
  %tobool31.not = icmp eq i32 %and30, 0
  br i1 %tobool31.not, label %if.end28.if.end77_crit_edge, label %if.then32

if.end28.if.end77_crit_edge:                      ; preds = %if.end28
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end77

if.then32:                                        ; preds = %if.end28
  %call33 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61440, i32 noundef 0) #12
  %and34 = and i32 %call33, -4063233
  %or36 = or i32 %and34, 1310720
  %10 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %cg_flags, align 8
  %12 = and i32 %11, 34
  call void @__sanitizer_cov_trace_const_cmp4(i32 34, i32 %12)
  %.not = icmp eq i32 %12, 34
  %and46 = and i32 %or36, 1763049471
  %data.1 = select i1 %.not, i32 %and46, i32 %or36
  %or49 = or i32 %data.1, -1769996288
  call void @__sanitizer_cov_trace_cmp4(i32 %call33, i32 %or49)
  %cmp50.not = icmp eq i32 %call33, %or49
  br i1 %cmp50.not, label %if.then32.if.end77_crit_edge, label %if.then51

if.then32.if.end77_crit_edge:                     ; preds = %if.then32
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end77

if.then51:                                        ; preds = %if.then32
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 61440, i32 noundef %or49, i32 noundef 0) #12
  br label %if.end77

if.else54:                                        ; preds = %land.lhs.true.if.else54_crit_edge, %entry.if.else54_crit_edge
  %call55 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60488, i32 noundef 0) #12
  %or56 = or i32 %call55, 39
  call void @__sanitizer_cov_trace_cmp4(i32 %call55, i32 %or56)
  %cmp57.not = icmp eq i32 %call55, %or56
  br i1 %cmp57.not, label %if.else54.if.end59_crit_edge, label %if.then58

if.else54.if.end59_crit_edge:                     ; preds = %if.else54
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end59

if.then58:                                        ; preds = %if.else54
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60488, i32 noundef %or56, i32 noundef 0) #12
  br label %if.end59

if.end59:                                         ; preds = %if.then58, %if.else54.if.end59_crit_edge
  %call60 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60422, i32 noundef 0) #12
  %and61 = and i32 %call60, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and61)
  %tobool62.not = icmp eq i32 %and61, 0
  br i1 %tobool62.not, label %if.end59.if.end65_crit_edge, label %if.then63

if.end59.if.end65_crit_edge:                      ; preds = %if.end59
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end65

if.then63:                                        ; preds = %if.end59
  call void @__sanitizer_cov_trace_pc() #14
  %and64 = and i32 %call60, -2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60422, i32 noundef %and64, i32 noundef 0) #12
  br label %if.end65

if.end65:                                         ; preds = %if.then63, %if.end59.if.end65_crit_edge
  %call66 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12409, i32 noundef 0) #12
  %and67 = and i32 %call66, 1
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and67)
  %tobool68.not = icmp eq i32 %and67, 0
  br i1 %tobool68.not, label %if.end65.if.end71_crit_edge, label %if.then69

if.end65.if.end71_crit_edge:                      ; preds = %if.end65
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end71

if.then69:                                        ; preds = %if.end65
  call void @__sanitizer_cov_trace_pc() #14
  %and70 = and i32 %call66, -2
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12409, i32 noundef %and70, i32 noundef 0) #12
  br label %if.end71

if.end71:                                         ; preds = %if.then69, %if.end65.if.end71_crit_edge
  %call72 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61440, i32 noundef 0) #12
  %or73 = or i32 %call72, 6291456
  call void @__sanitizer_cov_trace_cmp4(i32 %call72, i32 %or73)
  %cmp74.not = icmp eq i32 %call72, %or73
  br i1 %cmp74.not, label %if.end71.if.end76_crit_edge, label %if.then75

if.end71.if.end76_crit_edge:                      ; preds = %if.end71
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end76

if.then75:                                        ; preds = %if.end71
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 61440, i32 noundef %or73, i32 noundef 0) #12
  br label %if.end76

if.end76:                                         ; preds = %if.then75, %if.end71.if.end76_crit_edge
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i136 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %asic_type.i137 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %13 = ptrtoint ptr %asic_type.i137 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %asic_type.i137, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %14)
  %cmp.i138 = icmp eq i32 %14, 14
  %data.0.v.i139 = select i1 %cmp.i138, i32 -1006764032, i32 14
  %data.0.i140 = and i32 %data.0.v.i139, %call.i136
  %or5.i142 = or i32 %data.0.i140, 939589887
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i142, i32 noundef 0) #12
  br label %if.end77

if.end77:                                         ; preds = %if.end76, %if.then51, %if.then32.if.end77_crit_edge, %if.end28.if.end77_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1) to i32))
  %15 = load ptr, ptr getelementptr inbounds (%struct.arm_delay_ops, ptr @arm_delay_ops, i32 0, i32 1), align 4
  tail call void %15(i32 noundef 10737400) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_gfx_rlc_exit_safe_mode(ptr noundef %adev) #12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @gfx_v8_0_update_coarse_grain_clock_gating(ptr noundef %adev, i1 noundef zeroext %enable) unnamed_addr #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #14
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60489, i32 noundef 0) #12
  tail call void @amdgpu_gfx_rlc_enter_safe_mode(ptr noundef %adev) #12
  br i1 %enable, label %land.lhs.true, label %entry.if.else20_crit_edge

entry.if.else20_crit_edge:                        ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else20

land.lhs.true:                                    ; preds = %entry
  %cg_flags = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 99
  %0 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %cg_flags, align 8
  %and = and i32 %1, 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool1.not = icmp eq i32 %and, 0
  br i1 %tobool1.not, label %land.lhs.true.if.else20_crit_edge, label %if.then

land.lhs.true.if.else20_crit_edge:                ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.else20

if.then:                                          ; preds = %land.lhs.true
  %call2 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60488, i32 noundef 0) #12
  %and3 = and i32 %call2, -9
  call void @__sanitizer_cov_trace_cmp4(i32 %call2, i32 %and3)
  %cmp.not = icmp eq i32 %call2, %and3
  br i1 %cmp.not, label %if.then.if.end_crit_edge, label %if.then4

if.then.if.end_crit_edge:                         ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end

if.then4:                                         ; preds = %if.then
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60488, i32 noundef %and3, i32 noundef 0) #12
  br label %if.end

if.end:                                           ; preds = %if.then4, %if.then.if.end_crit_edge
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %asic_type.i = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %2 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %3)
  %cmp.i = icmp eq i32 %3, 14
  %data.0.v.i = select i1 %cmp.i, i32 -738263040, i32 14
  %data.0.i = and i32 %data.0.v.i, %call.i
  %or5.i = or i32 %data.0.i, 671088895
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i81 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %4 = ptrtoint ptr %asic_type.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %asic_type.i, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %5)
  %cmp.i83 = icmp eq i32 %5, 14
  %data.0.v.i84 = select i1 %cmp.i83, i32 -201457664, i32 14
  %data.0.i85 = and i32 %data.0.v.i84, %call.i81
  %or5.i87 = or i32 %data.0.i85, 134283519
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i87, i32 noundef 0) #12
  %6 = ptrtoint ptr %cg_flags to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cg_flags, align 8
  %and6 = and i32 %7, 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and6)
  %tobool7.not = icmp eq i32 %and6, 0
  br i1 %tobool7.not, label %if.else, label %if.then8

if.then8:                                         ; preds = %if.end
  %or9 = or i32 %call, 3
  %call10 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60488, i32 noundef 0) #12
  %and11 = and i32 %call10, -17
  call void @__sanitizer_cov_trace_cmp4(i32 %call10, i32 %and11)
  %cmp12.not = icmp eq i32 %call10, %and11
  br i1 %cmp12.not, label %if.then8.if.end16_crit_edge, label %if.then13

if.then8.if.end16_crit_edge:                      ; preds = %if.then8
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end16

if.then13:                                        ; preds = %if.then8
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60488, i32 noundef %and11, i32 noundef 0) #12
  br label %if.end16

if.else:                                          ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #14
  %or = and i32 %call, -4
  %and15 = or i32 %or, 1
  br label %if.end16

if.end16:                                         ; preds = %if.else, %if.then13, %if.then8.if.end16_crit_edge
  %data.0 = phi i32 [ %or9, %if.then13 ], [ %or9, %if.then8.if.end16_crit_edge ], [ %and15, %if.else ]
  call void @__sanitizer_cov_trace_cmp4(i32 %call, i32 %data.0)
  %cmp17.not = icmp eq i32 %call, %data.0
  br i1 %cmp17.not, label %if.end16.if.end34_crit_edge, label %if.end16.if.end34.sink.split_crit_edge

if.end16.if.end34.sink.split_crit_edge:           ; preds = %if.end16
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34.sink.split

if.end16.if.end34_crit_edge:                      ; preds = %if.end16
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34

if.else20:                                        ; preds = %land.lhs.true.if.else20_crit_edge, %entry.if.else20_crit_edge
  %call.i89 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %and.i90 = and i32 %call.i89, -3932161
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %and.i90, i32 noundef 0) #12
  %call21 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60488, i32 noundef 0) #12
  %or22 = or i32 %call21, 24
  call void @__sanitizer_cov_trace_cmp4(i32 %call21, i32 %or22)
  %cmp23.not = icmp eq i32 %call21, %or22
  br i1 %cmp23.not, label %if.else20.if.end25_crit_edge, label %if.then24

if.else20.if.end25_crit_edge:                     ; preds = %if.else20
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end25

if.then24:                                        ; preds = %if.else20
  call void @__sanitizer_cov_trace_pc() #14
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60488, i32 noundef %or22, i32 noundef 0) #12
  br label %if.end25

if.end25:                                         ; preds = %if.then24, %if.else20.if.end25_crit_edge
  %call26 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61608, i32 noundef 0) #12
  %call27 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61608, i32 noundef 0) #12
  %call28 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61608, i32 noundef 0) #12
  %call29 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 61608, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i91 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %asic_type.i92 = getelementptr inbounds %struct.amdgpu_device, ptr %adev, i32 0, i32 5
  %8 = ptrtoint ptr %asic_type.i92 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %asic_type.i92, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %9)
  %cmp.i93 = icmp eq i32 %9, 14
  %data.0.v.i94 = select i1 %cmp.i93, i32 -738328576, i32 14
  %data.0.i95 = and i32 %data.0.v.i94, %call.i91
  %or5.i97 = or i32 %data.0.i95, 671154431
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i97, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 49664, i32 noundef -536870912, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60509, i32 noundef -1, i32 noundef 0) #12
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60510, i32 noundef -1, i32 noundef 0) #12
  %call.i98 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 60511, i32 noundef 0) #12
  %10 = ptrtoint ptr %asic_type.i92 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %asic_type.i92, align 8
  call void @__sanitizer_cov_trace_const_cmp4(i32 14, i32 %11)
  %cmp.i100 = icmp eq i32 %11, 14
  %data.0.v.i101 = select i1 %cmp.i100, i32 -201392128, i32 14
  %data.0.i102 = and i32 %data.0.v.i101, %call.i98
  %or5.i103 = or i32 %data.0.i102, 134217983
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60511, i32 noundef %or5.i103, i32 noundef 0) #12
  %and30 = and i32 %call, -4
  call void @__sanitizer_cov_trace_cmp4(i32 %call, i32 %and30)
  %cmp31.not = icmp eq i32 %call, %and30
  br i1 %cmp31.not, label %if.end25.if.end34_crit_edge, label %if.end25.if.end34.sink.split_crit_edge

if.end25.if.end34.sink.split_crit_edge:           ; preds = %if.end25
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34.sink.split

if.end25.if.end34_crit_edge:                      ; preds = %if.end25
  call void @__sanitizer_cov_trace_pc() #14
  br label %if.end34

if.end34.sink.split:                              ; preds = %if.end25.if.end34.sink.split_crit_edge, %if.end16.if.end34.sink.split_crit_edge
  %and30.sink = phi i32 [ %data.0, %if.end16.if.end34.sink.split_crit_edge ], [ %and30, %if.end25.if.end34.sink.split_crit_edge ]
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 60489, i32 noundef %and30.sink, i32 noundef 0) #12
  br label %if.end34

if.end34:                                         ; preds = %if.end34.sink.split, %if.end25.if.end34_crit_edge, %if.end16.if.end34_crit_edge
  %call.i104 = tail call i32 @amdgpu_device_rreg(ptr noundef %adev, i32 noundef 12394, i32 noundef 0) #12
  %or19.i106 = or i32 %call.i104, 3932160
  tail call void @amdgpu_device_wreg(ptr noundef %adev, i32 noundef 12394, i32 noundef %or19.i106, i32 noundef 0) #12
  tail call fastcc void @gfx_v8_0_wait_for_rlc_serdes(ptr noundef %adev)
  tail call void @amdgpu_gfx_rlc_exit_safe_mode(ptr noundef %adev) #12
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_dpm_set_clockgating_by_smu(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @amdgpu_dpm_set_powergating_by_smu(ptr noundef, i32 noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.umin.i32(i32, i32) #10

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.umax.i32(i32, i32) #10

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.smin.i32(i32, i32) #10

; Function Attrs: nounwind
declare void @llvm.arm.gnu.eabi.mcount() #12

declare void @__sanitizer_cov_trace_cmp4(i32 zeroext, i32 zeroext)

declare void @__sanitizer_cov_trace_const_cmp1(i8 zeroext, i8 zeroext)

declare void @__sanitizer_cov_trace_const_cmp2(i16 zeroext, i16 zeroext)

declare void @__sanitizer_cov_trace_const_cmp4(i32 zeroext, i32 zeroext)

declare void @__sanitizer_cov_trace_switch(i64, ptr)

declare void @__sanitizer_cov_trace_pc()

declare void @__asan_load1_noabort(i32)

declare void @__asan_load2_noabort(i32)

declare void @__asan_load4_noabort(i32)

declare void @__asan_load8_noabort(i32)

declare void @__asan_storeN_noabort(i32, i32)

declare void @__asan_store1_noabort(i32)

declare void @__asan_store4_noabort(i32)

declare void @__asan_store8_noabort(i32)

declare ptr @memcpy(ptr, ptr, i32)

declare ptr @memset(ptr, i32, i32)

declare void @__asan_register_globals(i32, i32)

declare void @__asan_unregister_globals(i32, i32)

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_ctor() #13 {
  call void @__asan_register_globals(i32 ptrtoint (ptr @0 to i32), i32 155)
  ret void
}

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_dtor() #13 {
  call void @__asan_unregister_globals(i32 ptrtoint (ptr @0 to i32), i32 155)
  ret void
}

attributes #0 = { nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #1 = { argmemonly nocallback nofree nosync nounwind willreturn }
attributes #2 = { null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #3 = { mustprogress nofree norecurse nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #4 = { inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn }
attributes #5 = { cold null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #6 = { nofree nounwind null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #7 = { nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #8 = { nofree nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #9 = { argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #10 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
attributes #11 = { null_pointer_is_valid allocsize(0) "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #12 = { nounwind }
attributes #13 = { nounwind uwtable(sync) "frame-pointer"="all" }
attributes #14 = { nomerge }
attributes #15 = { cold nounwind }
attributes #16 = { nounwind allocsize(0) }

!llvm.asan.globals = !{!0, !2, !4, !6, !8, !10, !12, !14, !16, !18, !20, !22, !24, !26, !28, !30, !32, !34, !36, !38, !40, !42, !44, !46, !48, !50, !52, !54, !56, !58, !60, !62, !64, !66, !68, !70, !72, !74, !76, !78, !80, !82, !84, !86, !88, !90, !92, !94, !96, !98, !100, !102, !104, !106, !108, !110, !112, !114, !116, !118, !120, !122, !124, !126, !128, !130, !132, !134, !136, !138, !140, !142, !144, !146, !148, !150, !152, !154, !156, !158, !160, !162, !164, !166, !168, !170, !172, !174, !176, !178, !179, !180, !181, !182, !184, !186, !188, !189, !190, !191, !192, !193, !195, !197, !199, !201, !203, !205, !207, !209, !211, !213, !215, !217, !219, !221, !223, !225, !227, !229, !231, !233, !234, !235, !236, !238, !240, !242, !244, !246, !248, !250, !252, !254, !256, !258, !260, !262, !263, !265, !267, !269, !271, !273, !275, !277, !279, !281, !283, !285, !287, !289, !291, !293, !295, !297, !299, !301, !303, !305, !307, !308, !309, !310, !312, !314, !316, !318, !320, !322, !323, !324, !325, !326, !328, !329, !330, !331, !332, !334, !336, !338, !340, !342, !344, !346, !348, !350, !352, !354, !356, !358, !360, !362, !364, !366, !368, !370, !372, !374, !376, !378, !379, !380, !381, !383, !385, !386, !387, !388, !389, !391, !393, !395, !397, !399, !400, !401, !402, !403, !405, !406, !407, !409, !410, !411, !413, !415, !416, !417, !418, !419, !421, !422}
!llvm.module.flags = !{!423, !424, !425, !426, !427, !428, !429, !430}
!llvm.ident = !{!431}

!0 = !{ptr @__UNIQUE_ID_firmware343, !1, !"__UNIQUE_ID_firmware343", i1 false, i1 false}
!1 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 101, i32 1}
!2 = !{ptr @__UNIQUE_ID_firmware344, !3, !"__UNIQUE_ID_firmware344", i1 false, i1 false}
!3 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 102, i32 1}
!4 = !{ptr @__UNIQUE_ID_firmware345, !5, !"__UNIQUE_ID_firmware345", i1 false, i1 false}
!5 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 103, i32 1}
!6 = !{ptr @__UNIQUE_ID_firmware346, !7, !"__UNIQUE_ID_firmware346", i1 false, i1 false}
!7 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 104, i32 1}
!8 = !{ptr @__UNIQUE_ID_firmware347, !9, !"__UNIQUE_ID_firmware347", i1 false, i1 false}
!9 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 105, i32 1}
!10 = !{ptr @__UNIQUE_ID_firmware348, !11, !"__UNIQUE_ID_firmware348", i1 false, i1 false}
!11 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 106, i32 1}
!12 = !{ptr @__UNIQUE_ID_firmware349, !13, !"__UNIQUE_ID_firmware349", i1 false, i1 false}
!13 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 108, i32 1}
!14 = !{ptr @__UNIQUE_ID_firmware350, !15, !"__UNIQUE_ID_firmware350", i1 false, i1 false}
!15 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 109, i32 1}
!16 = !{ptr @__UNIQUE_ID_firmware351, !17, !"__UNIQUE_ID_firmware351", i1 false, i1 false}
!17 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 110, i32 1}
!18 = !{ptr @__UNIQUE_ID_firmware352, !19, !"__UNIQUE_ID_firmware352", i1 false, i1 false}
!19 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 111, i32 1}
!20 = !{ptr @__UNIQUE_ID_firmware353, !21, !"__UNIQUE_ID_firmware353", i1 false, i1 false}
!21 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 112, i32 1}
!22 = !{ptr @__UNIQUE_ID_firmware354, !23, !"__UNIQUE_ID_firmware354", i1 false, i1 false}
!23 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 114, i32 1}
!24 = !{ptr @__UNIQUE_ID_firmware355, !25, !"__UNIQUE_ID_firmware355", i1 false, i1 false}
!25 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 115, i32 1}
!26 = !{ptr @__UNIQUE_ID_firmware356, !27, !"__UNIQUE_ID_firmware356", i1 false, i1 false}
!27 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 116, i32 1}
!28 = !{ptr @__UNIQUE_ID_firmware357, !29, !"__UNIQUE_ID_firmware357", i1 false, i1 false}
!29 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 117, i32 1}
!30 = !{ptr @__UNIQUE_ID_firmware358, !31, !"__UNIQUE_ID_firmware358", i1 false, i1 false}
!31 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 118, i32 1}
!32 = !{ptr @__UNIQUE_ID_firmware359, !33, !"__UNIQUE_ID_firmware359", i1 false, i1 false}
!33 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 119, i32 1}
!34 = !{ptr @__UNIQUE_ID_firmware360, !35, !"__UNIQUE_ID_firmware360", i1 false, i1 false}
!35 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 121, i32 1}
!36 = !{ptr @__UNIQUE_ID_firmware361, !37, !"__UNIQUE_ID_firmware361", i1 false, i1 false}
!37 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 122, i32 1}
!38 = !{ptr @__UNIQUE_ID_firmware362, !39, !"__UNIQUE_ID_firmware362", i1 false, i1 false}
!39 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 123, i32 1}
!40 = !{ptr @__UNIQUE_ID_firmware363, !41, !"__UNIQUE_ID_firmware363", i1 false, i1 false}
!41 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 124, i32 1}
!42 = !{ptr @__UNIQUE_ID_firmware364, !43, !"__UNIQUE_ID_firmware364", i1 false, i1 false}
!43 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 125, i32 1}
!44 = !{ptr @__UNIQUE_ID_firmware365, !45, !"__UNIQUE_ID_firmware365", i1 false, i1 false}
!45 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 127, i32 1}
!46 = !{ptr @__UNIQUE_ID_firmware366, !47, !"__UNIQUE_ID_firmware366", i1 false, i1 false}
!47 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 128, i32 1}
!48 = !{ptr @__UNIQUE_ID_firmware367, !49, !"__UNIQUE_ID_firmware367", i1 false, i1 false}
!49 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 129, i32 1}
!50 = !{ptr @__UNIQUE_ID_firmware368, !51, !"__UNIQUE_ID_firmware368", i1 false, i1 false}
!51 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 130, i32 1}
!52 = !{ptr @__UNIQUE_ID_firmware369, !53, !"__UNIQUE_ID_firmware369", i1 false, i1 false}
!53 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 131, i32 1}
!54 = !{ptr @__UNIQUE_ID_firmware370, !55, !"__UNIQUE_ID_firmware370", i1 false, i1 false}
!55 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 132, i32 1}
!56 = !{ptr @__UNIQUE_ID_firmware371, !57, !"__UNIQUE_ID_firmware371", i1 false, i1 false}
!57 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 134, i32 1}
!58 = !{ptr @__UNIQUE_ID_firmware372, !59, !"__UNIQUE_ID_firmware372", i1 false, i1 false}
!59 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 135, i32 1}
!60 = !{ptr @__UNIQUE_ID_firmware373, !61, !"__UNIQUE_ID_firmware373", i1 false, i1 false}
!61 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 136, i32 1}
!62 = !{ptr @__UNIQUE_ID_firmware374, !63, !"__UNIQUE_ID_firmware374", i1 false, i1 false}
!63 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 137, i32 1}
!64 = !{ptr @__UNIQUE_ID_firmware375, !65, !"__UNIQUE_ID_firmware375", i1 false, i1 false}
!65 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 138, i32 1}
!66 = !{ptr @__UNIQUE_ID_firmware376, !67, !"__UNIQUE_ID_firmware376", i1 false, i1 false}
!67 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 139, i32 1}
!68 = !{ptr @__UNIQUE_ID_firmware377, !69, !"__UNIQUE_ID_firmware377", i1 false, i1 false}
!69 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 140, i32 1}
!70 = !{ptr @__UNIQUE_ID_firmware378, !71, !"__UNIQUE_ID_firmware378", i1 false, i1 false}
!71 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 141, i32 1}
!72 = !{ptr @__UNIQUE_ID_firmware379, !73, !"__UNIQUE_ID_firmware379", i1 false, i1 false}
!73 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 142, i32 1}
!74 = !{ptr @__UNIQUE_ID_firmware380, !75, !"__UNIQUE_ID_firmware380", i1 false, i1 false}
!75 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 143, i32 1}
!76 = !{ptr @__UNIQUE_ID_firmware381, !77, !"__UNIQUE_ID_firmware381", i1 false, i1 false}
!77 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 144, i32 1}
!78 = !{ptr @__UNIQUE_ID_firmware382, !79, !"__UNIQUE_ID_firmware382", i1 false, i1 false}
!79 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 146, i32 1}
!80 = !{ptr @__UNIQUE_ID_firmware383, !81, !"__UNIQUE_ID_firmware383", i1 false, i1 false}
!81 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 147, i32 1}
!82 = !{ptr @__UNIQUE_ID_firmware384, !83, !"__UNIQUE_ID_firmware384", i1 false, i1 false}
!83 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 148, i32 1}
!84 = !{ptr @__UNIQUE_ID_firmware385, !85, !"__UNIQUE_ID_firmware385", i1 false, i1 false}
!85 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 149, i32 1}
!86 = !{ptr @__UNIQUE_ID_firmware386, !87, !"__UNIQUE_ID_firmware386", i1 false, i1 false}
!87 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 150, i32 1}
!88 = !{ptr @__UNIQUE_ID_firmware387, !89, !"__UNIQUE_ID_firmware387", i1 false, i1 false}
!89 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 151, i32 1}
!90 = !{ptr @__UNIQUE_ID_firmware388, !91, !"__UNIQUE_ID_firmware388", i1 false, i1 false}
!91 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 152, i32 1}
!92 = !{ptr @__UNIQUE_ID_firmware389, !93, !"__UNIQUE_ID_firmware389", i1 false, i1 false}
!93 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 153, i32 1}
!94 = !{ptr @__UNIQUE_ID_firmware390, !95, !"__UNIQUE_ID_firmware390", i1 false, i1 false}
!95 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 154, i32 1}
!96 = !{ptr @__UNIQUE_ID_firmware391, !97, !"__UNIQUE_ID_firmware391", i1 false, i1 false}
!97 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 155, i32 1}
!98 = !{ptr @__UNIQUE_ID_firmware392, !99, !"__UNIQUE_ID_firmware392", i1 false, i1 false}
!99 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 156, i32 1}
!100 = !{ptr @__UNIQUE_ID_firmware393, !101, !"__UNIQUE_ID_firmware393", i1 false, i1 false}
!101 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 158, i32 1}
!102 = !{ptr @__UNIQUE_ID_firmware394, !103, !"__UNIQUE_ID_firmware394", i1 false, i1 false}
!103 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 159, i32 1}
!104 = !{ptr @__UNIQUE_ID_firmware395, !105, !"__UNIQUE_ID_firmware395", i1 false, i1 false}
!105 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 160, i32 1}
!106 = !{ptr @__UNIQUE_ID_firmware396, !107, !"__UNIQUE_ID_firmware396", i1 false, i1 false}
!107 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 161, i32 1}
!108 = !{ptr @__UNIQUE_ID_firmware397, !109, !"__UNIQUE_ID_firmware397", i1 false, i1 false}
!109 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 162, i32 1}
!110 = !{ptr @__UNIQUE_ID_firmware398, !111, !"__UNIQUE_ID_firmware398", i1 false, i1 false}
!111 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 163, i32 1}
!112 = !{ptr @__UNIQUE_ID_firmware399, !113, !"__UNIQUE_ID_firmware399", i1 false, i1 false}
!113 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 164, i32 1}
!114 = !{ptr @__UNIQUE_ID_firmware400, !115, !"__UNIQUE_ID_firmware400", i1 false, i1 false}
!115 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 165, i32 1}
!116 = !{ptr @__UNIQUE_ID_firmware401, !117, !"__UNIQUE_ID_firmware401", i1 false, i1 false}
!117 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 166, i32 1}
!118 = !{ptr @__UNIQUE_ID_firmware402, !119, !"__UNIQUE_ID_firmware402", i1 false, i1 false}
!119 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 167, i32 1}
!120 = !{ptr @__UNIQUE_ID_firmware403, !121, !"__UNIQUE_ID_firmware403", i1 false, i1 false}
!121 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 168, i32 1}
!122 = !{ptr @__UNIQUE_ID_firmware404, !123, !"__UNIQUE_ID_firmware404", i1 false, i1 false}
!123 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 170, i32 1}
!124 = !{ptr @__UNIQUE_ID_firmware405, !125, !"__UNIQUE_ID_firmware405", i1 false, i1 false}
!125 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 171, i32 1}
!126 = !{ptr @__UNIQUE_ID_firmware406, !127, !"__UNIQUE_ID_firmware406", i1 false, i1 false}
!127 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 172, i32 1}
!128 = !{ptr @__UNIQUE_ID_firmware407, !129, !"__UNIQUE_ID_firmware407", i1 false, i1 false}
!129 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 173, i32 1}
!130 = !{ptr @__UNIQUE_ID_firmware408, !131, !"__UNIQUE_ID_firmware408", i1 false, i1 false}
!131 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 174, i32 1}
!132 = !{ptr @__UNIQUE_ID_firmware409, !133, !"__UNIQUE_ID_firmware409", i1 false, i1 false}
!133 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 175, i32 1}
!134 = !{ptr @gfx_v8_0_ip_block, !135, !"gfx_v8_0_ip_block", i1 false, i1 false}
!135 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7193, i32 38}
!136 = !{ptr @gfx_v8_1_ip_block, !137, !"gfx_v8_1_ip_block", i1 false, i1 false}
!137 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7202, i32 38}
!138 = !{ptr @.str, !139, !"<string literal>", i1 false, i1 false}
!139 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6916, i32 10}
!140 = !{ptr @gfx_v8_0_ip_funcs, !141, !"gfx_v8_0_ip_funcs", i1 false, i1 false}
!141 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6915, i32 34}
!142 = !{ptr @gfx_v8_0_gfx_funcs, !143, !"gfx_v8_0_gfx_funcs", i1 false, i1 false}
!143 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5295, i32 38}
!144 = !{ptr @gfx_v8_0_ring_funcs_kiq, !145, !"gfx_v8_0_ring_funcs_kiq", i1 false, i1 false}
!145 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7017, i32 39}
!146 = !{ptr @.str.1, !147, !"<string literal>", i1 false, i1 false}
!147 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/amdgpu_ring.h", i32 314, i32 3}
!148 = !{ptr @gfx_v8_0_ring_funcs_gfx, !149, !"gfx_v8_0_ring_funcs_gfx", i1 false, i1 false}
!149 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6936, i32 39}
!150 = !{ptr @amdgpu_gds_reg_offset, !151, !"amdgpu_gds_reg_offset", i1 false, i1 false}
!151 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 177, i32 43}
!152 = !{ptr @gfx_v8_0_ring_funcs_compute, !153, !"gfx_v8_0_ring_funcs_compute", i1 false, i1 false}
!153 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6983, i32 39}
!154 = !{ptr @.str.2, !155, !"<string literal>", i1 false, i1 false}
!155 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6880, i32 3}
!156 = !{ptr @gfx_v8_0_eop_irq_funcs, !157, !"gfx_v8_0_eop_irq_funcs", i1 false, i1 false}
!157 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7054, i32 42}
!158 = !{ptr @.str.3, !159, !"<string literal>", i1 false, i1 false}
!159 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6489, i32 3}
!160 = !{ptr @.str.4, !161, !"<string literal>", i1 false, i1 false}
!161 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6649, i32 2}
!162 = !{ptr @gfx_v8_0_priv_reg_irq_funcs, !163, !"gfx_v8_0_priv_reg_irq_funcs", i1 false, i1 false}
!163 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7059, i32 42}
!164 = !{ptr @.str.5, !165, !"<string literal>", i1 false, i1 false}
!165 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6704, i32 2}
!166 = !{ptr @gfx_v8_0_priv_inst_irq_funcs, !167, !"gfx_v8_0_priv_inst_irq_funcs", i1 false, i1 false}
!167 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7064, i32 42}
!168 = !{ptr @.str.6, !169, !"<string literal>", i1 false, i1 false}
!169 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6713, i32 2}
!170 = !{ptr @gfx_v8_0_cp_ecc_error_irq_funcs, !171, !"gfx_v8_0_cp_ecc_error_irq_funcs", i1 false, i1 false}
!171 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7069, i32 42}
!172 = !{ptr @.str.7, !173, !"<string literal>", i1 false, i1 false}
!173 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6722, i32 2}
!174 = !{ptr @gfx_v8_0_sq_irq_funcs, !175, !"gfx_v8_0_sq_irq_funcs", i1 false, i1 false}
!175 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 7074, i32 42}
!176 = !{ptr @.str.8, !177, !"<string literal>", i1 false, i1 false}
!177 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6738, i32 4}
!178 = !{ptr @.str.9, !177, !"<string literal>", i1 false, i1 false}
!179 = !{ptr @.str.10, !177, !"<string literal>", i1 false, i1 false}
!180 = !{ptr @gfx_v8_0_parse_sq_irq._entry, !177, !"_entry", i1 false, i1 false}
!181 = !{ptr @gfx_v8_0_parse_sq_irq._entry_ptr, !177, !"_entry_ptr", i1 false, i1 false}
!182 = !{ptr @.str.11, !183, !"<string literal>", i1 false, i1 false}
!183 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6776, i32 19}
!184 = !{ptr @.str.12, !185, !"<string literal>", i1 false, i1 false}
!185 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6778, i32 19}
!186 = !{ptr @.str.14, !187, !"<string literal>", i1 false, i1 false}
!187 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6780, i32 4}
!188 = !{ptr @gfx_v8_0_parse_sq_irq._entry.13, !187, !"_entry", i1 false, i1 false}
!189 = !{ptr @gfx_v8_0_parse_sq_irq._entry_ptr.15, !187, !"_entry_ptr", i1 false, i1 false}
!190 = !{ptr @.str.16, !187, !"<string literal>", i1 false, i1 false}
!191 = !{ptr @.str.17, !187, !"<string literal>", i1 false, i1 false}
!192 = !{ptr @.str.18, !187, !"<string literal>", i1 false, i1 false}
!193 = !{ptr @.str.19, !194, !"<string literal>", i1 false, i1 false}
!194 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 6793, i32 4}
!195 = !{ptr @.str.20, !196, !"<string literal>", i1 false, i1 false}
!196 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 715, i32 2}
!197 = !{ptr @.str.21, !198, !"<string literal>", i1 false, i1 false}
!198 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 716, i32 2}
!199 = !{ptr @.str.22, !200, !"<string literal>", i1 false, i1 false}
!200 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 717, i32 2}
!201 = !{ptr @.str.23, !202, !"<string literal>", i1 false, i1 false}
!202 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 718, i32 2}
!203 = !{ptr @.str.24, !204, !"<string literal>", i1 false, i1 false}
!204 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 719, i32 2}
!205 = !{ptr @.str.25, !206, !"<string literal>", i1 false, i1 false}
!206 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 720, i32 2}
!207 = !{ptr @.str.26, !208, !"<string literal>", i1 false, i1 false}
!208 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 721, i32 2}
!209 = !{ptr @sq_edc_source_names, !210, !"sq_edc_source_names", i1 false, i1 false}
!210 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 714, i32 27}
!211 = !{ptr @iceland_rlc_funcs, !212, !"iceland_rlc_funcs", i1 false, i1 false}
!212 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5645, i32 38}
!213 = !{ptr @vi_cs_data, !214, !"vi_cs_data", i1 false, i1 false}
!214 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 941, i32 36}
!215 = !{ptr @vi_SECT_CONTEXT_defs, !216, !"vi_SECT_CONTEXT_defs", i1 false, i1 false}
!216 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 930, i32 35}
!217 = !{ptr @vi_SECT_CONTEXT_def_1, !218, !"vi_SECT_CONTEXT_def_1", i1 false, i1 false}
!218 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 24, i32 27}
!219 = !{ptr @vi_SECT_CONTEXT_def_2, !220, !"vi_SECT_CONTEXT_def_2", i1 false, i1 false}
!220 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 239, i32 27}
!221 = !{ptr @vi_SECT_CONTEXT_def_3, !222, !"vi_SECT_CONTEXT_def_3", i1 false, i1 false}
!222 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 516, i32 27}
!223 = !{ptr @vi_SECT_CONTEXT_def_4, !224, !"vi_SECT_CONTEXT_def_4", i1 false, i1 false}
!224 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 525, i32 27}
!225 = !{ptr @vi_SECT_CONTEXT_def_5, !226, !"vi_SECT_CONTEXT_def_5", i1 false, i1 false}
!226 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 685, i32 27}
!227 = !{ptr @vi_SECT_CONTEXT_def_6, !228, !"vi_SECT_CONTEXT_def_6", i1 false, i1 false}
!228 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 690, i32 27}
!229 = !{ptr @vi_SECT_CONTEXT_def_7, !230, !"vi_SECT_CONTEXT_def_7", i1 false, i1 false}
!230 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/clearstate_vi.h", i32 694, i32 27}
!231 = !{ptr @.str.29, !232, !"<string literal>", i1 false, i1 false}
!232 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 3874, i32 5}
!233 = !{ptr @.str.30, !232, !"<string literal>", i1 false, i1 false}
!234 = !{ptr @gfx_v8_0_wait_for_rlc_serdes._entry, !232, !"_entry", i1 false, i1 false}
!235 = !{ptr @gfx_v8_0_wait_for_rlc_serdes._entry_ptr, !232, !"_entry_ptr", i1 false, i1 false}
!236 = !{ptr @.str.31, !237, !"<string literal>", i1 false, i1 false}
!237 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5339, i32 3}
!238 = !{ptr @.str.32, !239, !"<string literal>", i1 false, i1 false}
!239 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5345, i32 3}
!240 = !{ptr @.str.33, !241, !"<string literal>", i1 false, i1 false}
!241 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1567, i32 3}
!242 = !{ptr @.str.34, !243, !"<string literal>", i1 false, i1 false}
!243 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1662, i32 3}
!244 = !{ptr @.str.35, !245, !"<string literal>", i1 false, i1 false}
!245 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1669, i32 3}
!246 = !{ptr @vgpr_init_compute_shader, !247, !"vgpr_init_compute_shader", i1 false, i1 false}
!247 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1375, i32 18}
!248 = !{ptr @sgpr_init_compute_shader, !249, !"sgpr_init_compute_shader", i1 false, i1 false}
!249 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1412, i32 18}
!250 = !{ptr @vgpr_init_regs, !251, !"vgpr_init_regs", i1 false, i1 false}
!251 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1437, i32 18}
!252 = !{ptr @sgpr1_init_regs, !253, !"sgpr1_init_regs", i1 false, i1 false}
!253 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1458, i32 18}
!254 = !{ptr @sgpr2_init_regs, !255, !"sgpr2_init_regs", i1 false, i1 false}
!255 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1479, i32 18}
!256 = !{ptr @sec_ded_counter_registers, !257, !"sec_ded_counter_registers", i1 false, i1 false}
!257 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1500, i32 18}
!258 = !{ptr @.str.36, !259, !"<string literal>", i1 false, i1 false}
!259 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1995, i32 3}
!260 = !{ptr @gfx_v8_0_sw_init.__key, !261, !"__key", i1 false, i1 false}
!261 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1999, i32 2}
!262 = !{ptr @.str.37, !261, !"<string literal>", i1 false, i1 false}
!263 = !{ptr @.str.38, !264, !"<string literal>", i1 false, i1 false}
!264 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 2007, i32 3}
!265 = !{ptr @.str.39, !266, !"<string literal>", i1 false, i1 false}
!266 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 2013, i32 3}
!267 = !{ptr @.str.40, !268, !"<string literal>", i1 false, i1 false}
!268 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 2019, i32 3}
!269 = distinct !{null, !270, !"<string literal>", i1 false, i1 false}
!270 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 2027, i32 23}
!271 = !{ptr @.str.42, !272, !"<string literal>", i1 false, i1 false}
!272 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 2063, i32 3}
!273 = !{ptr @.str.43, !274, !"<string literal>", i1 false, i1 false}
!274 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 970, i32 2}
!275 = !{ptr @.str.44, !276, !"<string literal>", i1 false, i1 false}
!276 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 974, i32 15}
!277 = !{ptr @.str.45, !278, !"<string literal>", i1 false, i1 false}
!278 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 977, i32 15}
!279 = !{ptr @.str.46, !280, !"<string literal>", i1 false, i1 false}
!280 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 980, i32 15}
!281 = !{ptr @.str.47, !282, !"<string literal>", i1 false, i1 false}
!282 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 983, i32 15}
!283 = !{ptr @.str.48, !284, !"<string literal>", i1 false, i1 false}
!284 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 986, i32 15}
!285 = !{ptr @.str.49, !286, !"<string literal>", i1 false, i1 false}
!286 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 989, i32 15}
!287 = !{ptr @.str.50, !288, !"<string literal>", i1 false, i1 false}
!288 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 992, i32 15}
!289 = !{ptr @.str.51, !290, !"<string literal>", i1 false, i1 false}
!290 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 995, i32 15}
!291 = !{ptr @.str.52, !292, !"<string literal>", i1 false, i1 false}
!292 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 998, i32 15}
!293 = !{ptr @.str.53, !294, !"<string literal>", i1 false, i1 false}
!294 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1005, i32 38}
!295 = !{ptr @.str.54, !296, !"<string literal>", i1 false, i1 false}
!296 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1008, i32 39}
!297 = !{ptr @.str.55, !298, !"<string literal>", i1 false, i1 false}
!298 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1025, i32 38}
!299 = !{ptr @.str.56, !300, !"<string literal>", i1 false, i1 false}
!300 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1028, i32 39}
!301 = !{ptr @.str.57, !302, !"<string literal>", i1 false, i1 false}
!302 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1046, i32 38}
!303 = !{ptr @.str.58, !304, !"<string literal>", i1 false, i1 false}
!304 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1049, i32 39}
!305 = !{ptr @.str.59, !306, !"<string literal>", i1 false, i1 false}
!306 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1072, i32 3}
!307 = !{ptr @.str.60, !306, !"<string literal>", i1 false, i1 false}
!308 = !{ptr @gfx_v8_0_init_microcode._entry, !306, !"_entry", i1 false, i1 false}
!309 = !{ptr @gfx_v8_0_init_microcode._entry_ptr, !306, !"_entry_ptr", i1 false, i1 false}
!310 = !{ptr @.str.61, !311, !"<string literal>", i1 false, i1 false}
!311 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1076, i32 37}
!312 = !{ptr @.str.62, !313, !"<string literal>", i1 false, i1 false}
!313 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1126, i32 38}
!314 = !{ptr @.str.63, !315, !"<string literal>", i1 false, i1 false}
!315 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1129, i32 39}
!316 = !{ptr @.str.64, !317, !"<string literal>", i1 false, i1 false}
!317 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1148, i32 39}
!318 = !{ptr @.str.65, !319, !"<string literal>", i1 false, i1 false}
!319 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1151, i32 40}
!320 = !{ptr @.str.67, !321, !"<string literal>", i1 false, i1 false}
!321 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1233, i32 3}
!322 = !{ptr @.str.68, !321, !"<string literal>", i1 false, i1 false}
!323 = !{ptr @.str.69, !321, !"<string literal>", i1 false, i1 false}
!324 = !{ptr @gfx_v8_0_init_microcode._entry.66, !321, !"_entry", i1 false, i1 false}
!325 = !{ptr @gfx_v8_0_init_microcode._entry_ptr.70, !321, !"_entry_ptr", i1 false, i1 false}
!326 = !{ptr @.str.71, !327, !"<string literal>", i1 false, i1 false}
!327 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1362, i32 4}
!328 = !{ptr @.str.72, !327, !"<string literal>", i1 false, i1 false}
!329 = !{ptr @.str.73, !327, !"<string literal>", i1 false, i1 false}
!330 = !{ptr @gfx_v8_0_mec_init._entry, !327, !"_entry", i1 false, i1 false}
!331 = !{ptr @gfx_v8_0_mec_init._entry_ptr, !327, !"_entry_ptr", i1 false, i1 false}
!332 = !{ptr @.str.74, !333, !"<string literal>", i1 false, i1 false}
!333 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 1921, i32 22}
!334 = !{ptr @iceland_mgcg_cgcg_init, !335, !"iceland_mgcg_cgcg_init", i1 false, i1 false}
!335 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 503, i32 18}
!336 = !{ptr @golden_settings_iceland_a11, !337, !"golden_settings_iceland_a11", i1 false, i1 false}
!337 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 471, i32 18}
!338 = !{ptr @iceland_golden_common_all, !339, !"iceland_golden_common_all", i1 false, i1 false}
!339 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 491, i32 18}
!340 = !{ptr @fiji_mgcg_cgcg_init, !341, !"fiji_mgcg_cgcg_init", i1 false, i1 false}
!341 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 432, i32 18}
!342 = !{ptr @golden_settings_fiji_a10, !343, !"golden_settings_fiji_a10", i1 false, i1 false}
!343 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 417, i32 18}
!344 = !{ptr @fiji_golden_common_all, !345, !"fiji_golden_common_all", i1 false, i1 false}
!345 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 403, i32 18}
!346 = !{ptr @tonga_mgcg_cgcg_init, !347, !"tonga_mgcg_cgcg_init", i1 false, i1 false}
!347 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 229, i32 18}
!348 = !{ptr @golden_settings_tonga_a11, !349, !"golden_settings_tonga_a11", i1 false, i1 false}
!349 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 197, i32 18}
!350 = !{ptr @tonga_golden_common_all, !351, !"tonga_golden_common_all", i1 false, i1 false}
!351 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 217, i32 18}
!352 = !{ptr @golden_settings_vegam_a11, !353, !"golden_settings_vegam_a11", i1 false, i1 false}
!353 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 308, i32 18}
!354 = !{ptr @vegam_golden_common_all, !355, !"vegam_golden_common_all", i1 false, i1 false}
!355 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 329, i32 18}
!356 = !{ptr @golden_settings_polaris11_a11, !357, !"golden_settings_polaris11_a11", i1 false, i1 false}
!357 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 339, i32 18}
!358 = !{ptr @polaris11_golden_common_all, !359, !"polaris11_golden_common_all", i1 false, i1 false}
!359 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 360, i32 18}
!360 = !{ptr @golden_settings_polaris10_a11, !361, !"golden_settings_polaris10_a11", i1 false, i1 false}
!361 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 370, i32 18}
!362 = !{ptr @polaris10_golden_common_all, !363, !"polaris10_golden_common_all", i1 false, i1 false}
!363 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 391, i32 18}
!364 = !{ptr @cz_mgcg_cgcg_init, !365, !"cz_mgcg_cgcg_init", i1 false, i1 false}
!365 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 599, i32 18}
!366 = !{ptr @cz_golden_settings_a11, !367, !"cz_golden_settings_a11", i1 false, i1 false}
!367 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 571, i32 18}
!368 = !{ptr @cz_golden_common_all, !369, !"cz_golden_common_all", i1 false, i1 false}
!369 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 587, i32 18}
!370 = !{ptr @stoney_mgcg_cgcg_init, !371, !"stoney_mgcg_cgcg_init", i1 false, i1 false}
!371 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 704, i32 18}
!372 = !{ptr @stoney_golden_settings_a11, !373, !"stoney_golden_settings_a11", i1 false, i1 false}
!373 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 678, i32 18}
!374 = !{ptr @stoney_golden_common_all, !375, !"stoney_golden_common_all", i1 false, i1 false}
!375 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 692, i32 18}
!376 = !{ptr @.str.75, !377, !"<string literal>", i1 false, i1 false}
!377 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 3260, i32 3}
!378 = !{ptr @.str.76, !377, !"<string literal>", i1 false, i1 false}
!379 = !{ptr @gfx_v8_0_tiling_mode_table_init._entry, !377, !"_entry", i1 false, i1 false}
!380 = !{ptr @gfx_v8_0_tiling_mode_table_init._entry_ptr, !377, !"_entry_ptr", i1 false, i1 false}
!381 = !{ptr @.str.77, !382, !"<string literal>", i1 false, i1 false}
!382 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 3519, i32 3}
!383 = !{ptr @.str.78, !384, !"<string literal>", i1 false, i1 false}
!384 = !{!"../drivers/gpu/drm/amd/amdgpu/../amdgpu/amdgpu_object.h", i32 179, i32 4}
!385 = !{ptr @.str.79, !384, !"<string literal>", i1 false, i1 false}
!386 = !{ptr @.str.80, !384, !"<string literal>", i1 false, i1 false}
!387 = !{ptr @amdgpu_bo_reserve._entry, !384, !"_entry", i1 false, i1 false}
!388 = !{ptr @amdgpu_bo_reserve._entry_ptr, !384, !"_entry_ptr", i1 false, i1 false}
!389 = distinct !{null, !390, !"<string literal>", i1 false, i1 false}
!390 = !{!"../include/drm/ttm/ttm_bo_driver.h", i32 140, i32 7}
!391 = !{ptr @.str.82, !392, !"<string literal>", i1 false, i1 false}
!392 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4197, i32 3}
!393 = !{ptr @.str.83, !394, !"<string literal>", i1 false, i1 false}
!394 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4372, i32 4}
!395 = !{ptr @.str.84, !396, !"<string literal>", i1 false, i1 false}
!396 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4381, i32 3}
!397 = !{ptr @.str.85, !398, !"<string literal>", i1 false, i1 false}
!398 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4943, i32 3}
!399 = !{ptr @.str.86, !398, !"<string literal>", i1 false, i1 false}
!400 = !{ptr @.str.87, !398, !"<string literal>", i1 false, i1 false}
!401 = !{ptr @gfx_v8_0_hw_fini.__UNIQUE_ID_ddebug418, !398, !"__UNIQUE_ID_ddebug418", i1 false, i1 false}
!402 = !{ptr @.str.88, !398, !"<string literal>", i1 false, i1 false}
!403 = !{ptr @.str.89, !404, !"<string literal>", i1 false, i1 false}
!404 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4950, i32 3}
!405 = !{ptr @gfx_v8_0_hw_fini._entry, !404, !"_entry", i1 false, i1 false}
!406 = !{ptr @gfx_v8_0_hw_fini._entry_ptr, !404, !"_entry_ptr", i1 false, i1 false}
!407 = !{ptr @.str.91, !408, !"<string literal>", i1 false, i1 false}
!408 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4954, i32 3}
!409 = !{ptr @gfx_v8_0_hw_fini._entry.90, !408, !"_entry", i1 false, i1 false}
!410 = !{ptr @gfx_v8_0_hw_fini._entry_ptr.92, !408, !"_entry_ptr", i1 false, i1 false}
!411 = !{ptr @.str.93, !412, !"<string literal>", i1 false, i1 false}
!412 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 4874, i32 3}
!413 = !{ptr @.str.94, !414, !"<string literal>", i1 false, i1 false}
!414 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5097, i32 3}
!415 = !{ptr @.str.95, !414, !"<string literal>", i1 false, i1 false}
!416 = !{ptr @.str.96, !414, !"<string literal>", i1 false, i1 false}
!417 = !{ptr @gfx_v8_0_soft_reset._entry, !414, !"_entry", i1 false, i1 false}
!418 = !{ptr @gfx_v8_0_soft_reset._entry_ptr, !414, !"_entry_ptr", i1 false, i1 false}
!419 = !{ptr @.str.98, !420, !"<string literal>", i1 false, i1 false}
!420 = !{!"../drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c", i32 5111, i32 3}
!421 = !{ptr @gfx_v8_0_soft_reset._entry.97, !420, !"_entry", i1 false, i1 false}
!422 = !{ptr @gfx_v8_0_soft_reset._entry_ptr.99, !420, !"_entry_ptr", i1 false, i1 false}
!423 = !{i32 1, !"wchar_size", i32 2}
!424 = !{i32 1, !"min_enum_size", i32 4}
!425 = !{i32 8, !"branch-target-enforcement", i32 0}
!426 = !{i32 8, !"sign-return-address", i32 0}
!427 = !{i32 8, !"sign-return-address-all", i32 0}
!428 = !{i32 8, !"sign-return-address-with-bkey", i32 0}
!429 = !{i32 7, !"uwtable", i32 1}
!430 = !{i32 7, !"frame-pointer", i32 2}
!431 = !{!"clang version 15.0.0 (git@github.com:linkeLi0421/llvm-project15-IRDumperPass.git 23ab625cb005cd08da083f9b643a7feed9af8abe)"}
!432 = !{i8 0, i8 2}
!433 = !{i64 2148525933}
!434 = !{i64 2148440397, i64 2148440429, i64 2148440458, i64 2148440492, i64 2148440523, i64 2148440546}
!435 = !{!"branch_weights", i32 2000, i32 1}
!436 = !{i64 2149804651}
!437 = distinct !{!437, !438}
!438 = !{!"llvm.loop.peeled.count", i32 1}
!439 = !{i64 2149004067, i64 2149004072, i64 2149004085, i64 2149004129, i64 2149004163, i64 2149004184}
!440 = !{i64 2164603615, i64 2164604118, i64 2164603652, i64 2164603708, i64 2164603742, i64 2164603766, i64 2164603807, i64 2164603828, i64 2164603856, i64 2164603890}
!441 = !{!"auto-init"}
!442 = !{!"branch_weights", i32 1, i32 2000}
!443 = !{i64 2164606158, i64 2164606661, i64 2164606195, i64 2164606251, i64 2164606285, i64 2164606309, i64 2164606350, i64 2164606371, i64 2164606399, i64 2164606433}
!444 = !{i64 2164607835, i64 2164608338, i64 2164607872, i64 2164607928, i64 2164607962, i64 2164607986, i64 2164608027, i64 2164608048, i64 2164608076, i64 2164608110}
!445 = distinct !{!445, !446}
!446 = !{!"llvm.loop.peeled.count", i32 4}
!447 = !{i64 2164482143, i64 2164486707, i64 2164482180, i64 2164482236, i64 2164482270, i64 2164482294, i64 2164482335, i64 2164482356, i64 2164482384, i64 2164482418}
!448 = !{i64 2164487875, i64 2164488378, i64 2164487912, i64 2164487968, i64 2164488002, i64 2164488026, i64 2164488067, i64 2164488088, i64 2164488116, i64 2164488150}
!449 = !{i64 2164309485, i64 2164309988, i64 2164309522, i64 2164309578, i64 2164309612, i64 2164309636, i64 2164309677, i64 2164309698, i64 2164309726, i64 2164309760}
!450 = !{!"branch_weights", i32 1, i32 4000, i32 1}
!451 = !{i32 0, i32 33}
