; ModuleID = '/llk/IR_all_yes/kernel/sched/core.c_pt.bc'
source_filename = "../kernel/sched/core.c"
target datalayout = "E-m:e-p:32:32-Fi8-i64:64-v128:64:128-a:0:32-n32-S64"
target triple = "armebv6k-unknown-linux-gnueabi"

module asm ".syntax unified"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_pelt_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_pelt_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_pelt_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_pelt_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_pelt_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_pelt_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_pelt_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_pelt_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_pelt_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_pelt_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_pelt_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_pelt_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_pelt_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_pelt_rt_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_pelt_rt_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_pelt_rt_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_pelt_rt_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_pelt_rt_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_pelt_rt_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_pelt_rt_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_pelt_rt_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_pelt_rt_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_pelt_rt_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_pelt_rt_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_pelt_rt_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_pelt_rt_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_pelt_dl_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_pelt_dl_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_pelt_dl_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_pelt_dl_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_pelt_dl_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_pelt_dl_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_pelt_dl_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_pelt_dl_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_pelt_dl_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_pelt_dl_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_pelt_dl_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_pelt_dl_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_pelt_dl_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_pelt_irq_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_pelt_irq_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_pelt_irq_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_pelt_irq_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_pelt_irq_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_pelt_irq_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_pelt_irq_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_pelt_irq_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_pelt_irq_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_pelt_irq_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_pelt_irq_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_pelt_irq_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_pelt_irq_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_pelt_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_pelt_se_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_pelt_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_pelt_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_pelt_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_pelt_se_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_pelt_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_pelt_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_pelt_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_pelt_se_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_pelt_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_pelt_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_pelt_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_sched_cpu_capacity_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_sched_cpu_capacity_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_sched_cpu_capacity_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_sched_cpu_capacity_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_sched_cpu_capacity_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_sched_cpu_capacity_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_sched_cpu_capacity_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_sched_cpu_capacity_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_sched_overutilized_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_sched_overutilized_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_sched_overutilized_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_sched_overutilized_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_sched_overutilized_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_sched_overutilized_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_sched_overutilized_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_sched_overutilized_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_sched_overutilized_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_sched_overutilized_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_sched_overutilized_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_sched_overutilized_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_sched_overutilized_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_sched_util_est_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_sched_util_est_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_sched_util_est_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_sched_util_est_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_sched_util_est_cfs_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_sched_util_est_cfs_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_sched_util_est_cfs_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_sched_util_est_cfs_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_sched_util_est_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_sched_util_est_se_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_sched_util_est_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_sched_util_est_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_sched_util_est_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_sched_util_est_se_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_sched_util_est_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_sched_util_est_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_sched_util_est_se_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_sched_util_est_se_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_sched_util_est_se_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_sched_util_est_se_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_sched_util_est_se_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__tracepoint_sched_update_nr_running_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___tracepoint_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.long\09__crc___tracepoint_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___tracepoint_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__tracepoint_sched_update_nr_running_tp\22\09\09\09\09\09"
module asm "__kstrtabns___tracepoint_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__traceiter_sched_update_nr_running_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___traceiter_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.long\09__crc___traceiter_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___traceiter_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__traceiter_sched_update_nr_running_tp\22\09\09\09\09\09"
module asm "__kstrtabns___traceiter_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__SCK__tp_func_sched_update_nr_running_tp\22, \22a\22\09"
module asm "\09.weak\09__crc___SCK__tp_func_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.long\09__crc___SCK__tp_func_sched_update_nr_running_tp\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___SCK__tp_func_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22__SCK__tp_func_sched_update_nr_running_tp\22\09\09\09\09\09"
module asm "__kstrtabns___SCK__tp_func_sched_update_nr_running_tp:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+migrate_disable\22, \22a\22\09"
module asm "\09.weak\09__crc_migrate_disable\09\09\09\09"
module asm "\09.long\09__crc_migrate_disable\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_migrate_disable:\09\09\09\09\09"
module asm "\09.asciz \09\22migrate_disable\22\09\09\09\09\09"
module asm "__kstrtabns_migrate_disable:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+migrate_enable\22, \22a\22\09"
module asm "\09.weak\09__crc_migrate_enable\09\09\09\09"
module asm "\09.long\09__crc_migrate_enable\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_migrate_enable:\09\09\09\09\09"
module asm "\09.asciz \09\22migrate_enable\22\09\09\09\09\09"
module asm "__kstrtabns_migrate_enable:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+set_cpus_allowed_ptr\22, \22a\22\09"
module asm "\09.weak\09__crc_set_cpus_allowed_ptr\09\09\09\09"
module asm "\09.long\09__crc_set_cpus_allowed_ptr\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_set_cpus_allowed_ptr:\09\09\09\09\09"
module asm "\09.asciz \09\22set_cpus_allowed_ptr\22\09\09\09\09\09"
module asm "__kstrtabns_set_cpus_allowed_ptr:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+kick_process\22, \22a\22\09"
module asm "\09.weak\09__crc_kick_process\09\09\09\09"
module asm "\09.long\09__crc_kick_process\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_kick_process:\09\09\09\09\09"
module asm "\09.asciz \09\22kick_process\22\09\09\09\09\09"
module asm "__kstrtabns_kick_process:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+wake_up_process\22, \22a\22\09"
module asm "\09.weak\09__crc_wake_up_process\09\09\09\09"
module asm "\09.long\09__crc_wake_up_process\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_wake_up_process:\09\09\09\09\09"
module asm "\09.asciz \09\22wake_up_process\22\09\09\09\09\09"
module asm "__kstrtabns_wake_up_process:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+single_task_running\22, \22a\22\09"
module asm "\09.weak\09__crc_single_task_running\09\09\09\09"
module asm "\09.long\09__crc_single_task_running\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_single_task_running:\09\09\09\09\09"
module asm "\09.asciz \09\22single_task_running\22\09\09\09\09\09"
module asm "__kstrtabns_single_task_running:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+kstat\22, \22a\22\09"
module asm "\09.weak\09__crc_kstat\09\09\09\09"
module asm "\09.long\09__crc_kstat\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_kstat:\09\09\09\09\09"
module asm "\09.asciz \09\22kstat\22\09\09\09\09\09"
module asm "__kstrtabns_kstat:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+kernel_cpustat\22, \22a\22\09"
module asm "\09.weak\09__crc_kernel_cpustat\09\09\09\09"
module asm "\09.long\09__crc_kernel_cpustat\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_kernel_cpustat:\09\09\09\09\09"
module asm "\09.asciz \09\22kernel_cpustat\22\09\09\09\09\09"
module asm "__kstrtabns_kernel_cpustat:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+schedule\22, \22a\22\09"
module asm "\09.weak\09__crc_schedule\09\09\09\09"
module asm "\09.long\09__crc_schedule\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_schedule:\09\09\09\09\09"
module asm "\09.asciz \09\22schedule\22\09\09\09\09\09"
module asm "__kstrtabns_schedule:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+default_wake_function\22, \22a\22\09"
module asm "\09.weak\09__crc_default_wake_function\09\09\09\09"
module asm "\09.long\09__crc_default_wake_function\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_default_wake_function:\09\09\09\09\09"
module asm "\09.asciz \09\22default_wake_function\22\09\09\09\09\09"
module asm "__kstrtabns_default_wake_function:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+set_user_nice\22, \22a\22\09"
module asm "\09.weak\09__crc_set_user_nice\09\09\09\09"
module asm "\09.long\09__crc_set_user_nice\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_set_user_nice:\09\09\09\09\09"
module asm "\09.asciz \09\22set_user_nice\22\09\09\09\09\09"
module asm "__kstrtabns_set_user_nice:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+sched_setattr_nocheck\22, \22a\22\09"
module asm "\09.weak\09__crc_sched_setattr_nocheck\09\09\09\09"
module asm "\09.long\09__crc_sched_setattr_nocheck\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_sched_setattr_nocheck:\09\09\09\09\09"
module asm "\09.asciz \09\22sched_setattr_nocheck\22\09\09\09\09\09"
module asm "__kstrtabns_sched_setattr_nocheck:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+sched_set_fifo\22, \22a\22\09"
module asm "\09.weak\09__crc_sched_set_fifo\09\09\09\09"
module asm "\09.long\09__crc_sched_set_fifo\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_sched_set_fifo:\09\09\09\09\09"
module asm "\09.asciz \09\22sched_set_fifo\22\09\09\09\09\09"
module asm "__kstrtabns_sched_set_fifo:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+sched_set_fifo_low\22, \22a\22\09"
module asm "\09.weak\09__crc_sched_set_fifo_low\09\09\09\09"
module asm "\09.long\09__crc_sched_set_fifo_low\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_sched_set_fifo_low:\09\09\09\09\09"
module asm "\09.asciz \09\22sched_set_fifo_low\22\09\09\09\09\09"
module asm "__kstrtabns_sched_set_fifo_low:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+sched_set_normal\22, \22a\22\09"
module asm "\09.weak\09__crc_sched_set_normal\09\09\09\09"
module asm "\09.long\09__crc_sched_set_normal\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_sched_set_normal:\09\09\09\09\09"
module asm "\09.asciz \09\22sched_set_normal\22\09\09\09\09\09"
module asm "__kstrtabns_sched_set_normal:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__cond_resched\22, \22a\22\09"
module asm "\09.weak\09__crc___cond_resched\09\09\09\09"
module asm "\09.long\09__crc___cond_resched\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cond_resched:\09\09\09\09\09"
module asm "\09.asciz \09\22__cond_resched\22\09\09\09\09\09"
module asm "__kstrtabns___cond_resched:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__cond_resched_lock\22, \22a\22\09"
module asm "\09.weak\09__crc___cond_resched_lock\09\09\09\09"
module asm "\09.long\09__crc___cond_resched_lock\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cond_resched_lock:\09\09\09\09\09"
module asm "\09.asciz \09\22__cond_resched_lock\22\09\09\09\09\09"
module asm "__kstrtabns___cond_resched_lock:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__cond_resched_rwlock_read\22, \22a\22\09"
module asm "\09.weak\09__crc___cond_resched_rwlock_read\09\09\09\09"
module asm "\09.long\09__crc___cond_resched_rwlock_read\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cond_resched_rwlock_read:\09\09\09\09\09"
module asm "\09.asciz \09\22__cond_resched_rwlock_read\22\09\09\09\09\09"
module asm "__kstrtabns___cond_resched_rwlock_read:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__cond_resched_rwlock_write\22, \22a\22\09"
module asm "\09.weak\09__crc___cond_resched_rwlock_write\09\09\09\09"
module asm "\09.long\09__crc___cond_resched_rwlock_write\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cond_resched_rwlock_write:\09\09\09\09\09"
module asm "\09.asciz \09\22__cond_resched_rwlock_write\22\09\09\09\09\09"
module asm "__kstrtabns___cond_resched_rwlock_write:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+yield\22, \22a\22\09"
module asm "\09.weak\09__crc_yield\09\09\09\09"
module asm "\09.long\09__crc_yield\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_yield:\09\09\09\09\09"
module asm "\09.asciz \09\22yield\22\09\09\09\09\09"
module asm "__kstrtabns_yield:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+yield_to\22, \22a\22\09"
module asm "\09.weak\09__crc_yield_to\09\09\09\09"
module asm "\09.long\09__crc_yield_to\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_yield_to:\09\09\09\09\09"
module asm "\09.asciz \09\22yield_to\22\09\09\09\09\09"
module asm "__kstrtabns_yield_to:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+io_schedule_timeout\22, \22a\22\09"
module asm "\09.weak\09__crc_io_schedule_timeout\09\09\09\09"
module asm "\09.long\09__crc_io_schedule_timeout\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_io_schedule_timeout:\09\09\09\09\09"
module asm "\09.asciz \09\22io_schedule_timeout\22\09\09\09\09\09"
module asm "__kstrtabns_io_schedule_timeout:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+io_schedule\22, \22a\22\09"
module asm "\09.weak\09__crc_io_schedule\09\09\09\09"
module asm "\09.long\09__crc_io_schedule\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_io_schedule:\09\09\09\09\09"
module asm "\09.asciz \09\22io_schedule\22\09\09\09\09\09"
module asm "__kstrtabns_io_schedule:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+sched_show_task\22, \22a\22\09"
module asm "\09.weak\09__crc_sched_show_task\09\09\09\09"
module asm "\09.long\09__crc_sched_show_task\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_sched_show_task:\09\09\09\09\09"
module asm "\09.asciz \09\22sched_show_task\22\09\09\09\09\09"
module asm "__kstrtabns_sched_show_task:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__might_sleep\22, \22a\22\09"
module asm "\09.weak\09__crc___might_sleep\09\09\09\09"
module asm "\09.long\09__crc___might_sleep\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___might_sleep:\09\09\09\09\09"
module asm "\09.asciz \09\22__might_sleep\22\09\09\09\09\09"
module asm "__kstrtabns___might_sleep:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+__might_resched\22, \22a\22\09"
module asm "\09.weak\09__crc___might_resched\09\09\09\09"
module asm "\09.long\09__crc___might_resched\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___might_resched:\09\09\09\09\09"
module asm "\09.asciz \09\22__might_resched\22\09\09\09\09\09"
module asm "__kstrtabns___might_resched:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__cant_sleep\22, \22a\22\09"
module asm "\09.weak\09__crc___cant_sleep\09\09\09\09"
module asm "\09.long\09__crc___cant_sleep\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cant_sleep:\09\09\09\09\09"
module asm "\09.asciz \09\22__cant_sleep\22\09\09\09\09\09"
module asm "__kstrtabns___cant_sleep:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab_gpl+__cant_migrate\22, \22a\22\09"
module asm "\09.weak\09__crc___cant_migrate\09\09\09\09"
module asm "\09.long\09__crc___cant_migrate\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab___cant_migrate:\09\09\09\09\09"
module asm "\09.asciz \09\22__cant_migrate\22\09\09\09\09\09"
module asm "__kstrtabns___cant_migrate:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"

%struct.static_call_key = type { ptr }
%struct.atomic_t = type { i32 }
%struct.trace_event_fields = type { ptr, %union.anon.95 }
%union.anon.95 = type { %struct.anon.96 }
%struct.anon.96 = type { ptr, i32, i32, i32, i32 }
%struct.trace_event_class = type { ptr, ptr, ptr, ptr, ptr, ptr, %struct.list_head, ptr }
%struct.list_head = type { ptr, ptr }
%struct.trace_event_functions = type { ptr, ptr, ptr, ptr }
%struct.trace_event_call = type { %struct.list_head, ptr, %union.anon.97, %struct.trace_event, ptr, ptr, %union.anon.98, ptr, i32, i32, ptr, ptr, ptr }
%union.anon.97 = type { ptr }
%struct.trace_event = type { %struct.hlist_node, %struct.list_head, i32, ptr }
%struct.hlist_node = type { ptr, ptr }
%union.anon.98 = type { ptr }
%union.anon.99 = type { %struct.bpf_raw_event_map }
%struct.bpf_raw_event_map = type { ptr, ptr, i32, i32, [16 x i8] }
%union.anon.100 = type { %struct.bpf_raw_event_map }
%union.anon.101 = type { %struct.bpf_raw_event_map }
%union.anon.102 = type { %struct.bpf_raw_event_map }
%union.anon.103 = type { %struct.bpf_raw_event_map }
%union.anon.104 = type { %struct.bpf_raw_event_map }
%union.anon.105 = type { %struct.bpf_raw_event_map }
%union.anon.106 = type { %struct.bpf_raw_event_map }
%union.anon.107 = type { %struct.bpf_raw_event_map }
%union.anon.108 = type { %struct.bpf_raw_event_map }
%union.anon.109 = type { %struct.bpf_raw_event_map }
%union.anon.110 = type { %struct.bpf_raw_event_map }
%union.anon.111 = type { %struct.bpf_raw_event_map }
%union.anon.112 = type { %struct.bpf_raw_event_map }
%union.anon.113 = type { %struct.bpf_raw_event_map }
%union.anon.114 = type { %struct.bpf_raw_event_map }
%union.anon.115 = type { %struct.bpf_raw_event_map }
%union.anon.116 = type { %struct.bpf_raw_event_map }
%union.anon.117 = type { %struct.bpf_raw_event_map }
%union.anon.118 = type { %struct.bpf_raw_event_map }
%union.anon.119 = type { %struct.bpf_raw_event_map }
%union.anon.120 = type { %struct.bpf_raw_event_map }
%union.anon.121 = type { %struct.bpf_raw_event_map }
%union.anon.122 = type { %struct.bpf_raw_event_map }
%union.anon.123 = type { %struct.bpf_raw_event_map }
%union.anon.124 = type { %struct.bpf_raw_event_map }
%union.anon.125 = type { %struct.bpf_raw_event_map }
%union.anon.126 = type { %struct.bpf_raw_event_map }
%union.anon.127 = type { %struct.bpf_raw_event_map }
%union.anon.128 = type { %struct.bpf_raw_event_map }
%union.anon.129 = type { %struct.bpf_raw_event_map }
%union.anon.130 = type { %struct.bpf_raw_event_map }
%union.anon.131 = type { %struct.bpf_raw_event_map }
%union.anon.132 = type { %struct.bpf_raw_event_map }
%union.anon.133 = type { %struct.bpf_raw_event_map }
%union.anon.134 = type { %struct.bpf_raw_event_map }
%union.anon.135 = type { %struct.bpf_raw_event_map }
%union.anon.136 = type { %struct.bpf_raw_event_map }
%struct.kernel_symbol = type { i32, ptr, ptr }
%struct.mutex = type { %struct.atomic_t, %struct.raw_spinlock, %struct.optimistic_spin_queue, %struct.list_head, ptr, %struct.lockdep_map }
%struct.raw_spinlock = type { %struct.arch_spinlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_spinlock_t = type { %union.anon.2 }
%union.anon.2 = type { i32 }
%struct.optimistic_spin_queue = type { %struct.atomic_t }
%struct.lockdep_map = type { ptr, [2 x ptr], ptr, i8, i8, i8, i32, i32 }
%struct.work_struct = type { %struct.atomic_t, %struct.list_head, ptr, %struct.lockdep_map }
%struct.rq = type { %struct.raw_spinlock, i32, i32, i32, [8 x i8], %struct.__call_single_data, i32, %struct.atomic_t, i32, i64, [24 x i8], [2 x %struct.uclamp_rq], i32, [76 x i8], %struct.cfs_rq, %struct.rt_rq, %struct.dl_rq, %struct.list_head, ptr, i32, ptr, ptr, ptr, i32, ptr, i32, i64, [88 x i8], i64, i64, i32, %struct.atomic_t, i64, i32, i32, ptr, ptr, i32, i32, ptr, i8, i8, i32, i32, i32, %struct.cpu_stop_work, i32, i32, %struct.list_head, [12 x i8], %struct.sched_avg, %struct.sched_avg, %struct.sched_avg, %struct.sched_avg, i64, i64, i32, i64, i64, %struct.rcuwait, i64, i64, i64, i32, i32, %struct.__call_single_data, %struct.hrtimer, i64, %struct.sched_info, i64, i32, i32, i32, i32, i32, ptr, i32, i32, %struct.cpu_stop_work, ptr, ptr, i32, i32, %struct.rb_root, i32, i32, i32, i32, i32, i32, i64, [80 x i8] }
%struct.uclamp_rq = type { i32, [5 x %struct.uclamp_bucket] }
%struct.uclamp_bucket = type { i32 }
%struct.cfs_rq = type { %struct.load_weight, i32, i32, i32, i32, i64, i64, i32, i64, i64, %struct.rb_root_cached, ptr, ptr, ptr, ptr, i32, [36 x i8], %struct.sched_avg, i64, [120 x i8], %struct.anon.172, i32, i32, i32, i32, i64, ptr, ptr, i32, %struct.list_head, ptr, i32, i32, i64, i64, i64, i64, i32, i32, %struct.list_head, [24 x i8] }
%struct.load_weight = type { i32, i32 }
%struct.rb_root_cached = type { %struct.rb_root, ptr }
%struct.anon.172 = type { %struct.raw_spinlock, i32, i32, i32, i32, [68 x i8] }
%struct.rt_rq = type { %struct.rt_prio_array, i32, i32, %struct.anon.173, i32, i32, i32, %struct.plist_head, i32, i32, i64, i64, %struct.raw_spinlock, i32, ptr, ptr }
%struct.rt_prio_array = type { [4 x i32], [100 x %struct.list_head] }
%struct.anon.173 = type { i32, i32 }
%struct.plist_head = type { %struct.list_head }
%struct.dl_rq = type { %struct.rb_root_cached, i32, %struct.anon.174, i32, i32, %struct.rb_root_cached, i64, i64, i64, i64 }
%struct.anon.174 = type { i64, i64 }
%struct.sched_avg = type { i64, i64, i64, i32, i32, i32, i32, i32, [4 x i8], %struct.util_est, [72 x i8] }
%struct.util_est = type { i32, i32 }
%struct.rcuwait = type { ptr }
%struct.__call_single_data = type { %struct.__call_single_node, ptr, ptr }
%struct.__call_single_node = type { %struct.llist_node, %union.anon.0 }
%struct.llist_node = type { ptr }
%union.anon.0 = type { i32 }
%struct.hrtimer = type { %struct.timerqueue_node, i64, ptr, ptr, i8, i8, i8, i8 }
%struct.timerqueue_node = type { %struct.rb_node, i64 }
%struct.rb_node = type { i32, ptr, ptr }
%struct.sched_info = type { i32, i64, i64, i64 }
%struct.cpu_stop_work = type { %struct.list_head, ptr, i32, ptr, ptr }
%struct.rb_root = type { ptr }
%struct.static_key = type { %struct.atomic_t, %union.anon }
%union.anon = type { i32 }
%struct.uclamp_se = type { i16, [2 x i8] }
%struct.cpumask = type { [1 x i32] }
%struct.pi_entry = type { ptr, ptr, ptr, i32, ptr, ptr }
%struct.sched_class = type { i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.lock_class_key = type { %union.anon.1 }
%union.anon.1 = type { %struct.hlist_node }
%struct.obs_kernel_param = type { ptr, ptr, i32 }
%struct.callback_head = type { ptr, ptr }
%struct.kernel_stat = type { i32, [10 x i32] }
%struct.kernel_cpustat = type { [10 x i64] }
%struct.syscall_metadata = type { ptr, i32, i32, ptr, ptr, %struct.list_head, ptr, ptr }
%struct.task_struct = type { i32, ptr, %struct.refcount_struct, i32, i32, i32, %struct.__call_single_node, i32, i32, ptr, i32, i32, i32, i32, i32, i32, i32, [56 x i8], %struct.sched_entity, %struct.sched_rt_entity, %struct.sched_dl_entity, ptr, %struct.rb_node, i32, i32, ptr, [2 x %struct.uclamp_se], [2 x %struct.uclamp_se], [116 x i8], %struct.sched_statistics, i32, i32, i32, ptr, ptr, %struct.cpumask, ptr, i16, i16, i32, i8, i8, i32, %struct.list_head, i32, i32, %union.rcu_special, i8, %struct.list_head, %struct.sched_info, %struct.list_head, %struct.plist_node, %struct.rb_node, ptr, ptr, %struct.vmacache, %struct.task_rss_stat, i32, i32, i32, i32, i32, i32, i8, [3 x i8], i16, i32, %struct.restart_block, i32, i32, i32, ptr, ptr, %struct.list_head, %struct.list_head, ptr, %struct.list_head, %struct.list_head, ptr, [4 x %struct.hlist_node], %struct.list_head, %struct.list_head, ptr, ptr, ptr, ptr, i64, i64, i64, %struct.prev_cputime, i32, i32, i64, i64, i32, i32, %struct.posix_cputimers, ptr, ptr, ptr, ptr, [16 x i8], ptr, %struct.sysv_sem, %struct.sysv_shm, i32, i32, ptr, ptr, ptr, ptr, ptr, ptr, %struct.sigset_t, %struct.sigset_t, %struct.sigset_t, %struct.sigpending, i32, i32, i32, ptr, %struct.kuid_t, i32, %struct.seccomp, %struct.syscall_user_dispatch, i64, i64, %struct.spinlock, %struct.raw_spinlock, %struct.wake_q_node, %struct.rb_root_cached, ptr, ptr, ptr, i32, %struct.irqtrace_events, i32, i64, i32, i32, i32, i64, i32, i32, [48 x %struct.held_lock], i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i32, ptr, %struct.task_io_accounting, i32, i64, i64, i64, %struct.nodemask_t, %struct.seqcount_spinlock, i32, i32, ptr, %struct.list_head, ptr, %struct.list_head, ptr, %struct.mutex, i32, [2 x ptr], %struct.mutex, %struct.list_head, ptr, i32, i32, %struct.tlbflush_unmap_batch, %union.anon.29, ptr, %struct.page_frag, ptr, i32, i32, i32, i32, i32, i32, [32 x %struct.latency_record], i64, i64, i32, ptr, i32, i32, i32, i32, ptr, ptr, i64, i32, i32, ptr, i32, i32, i32, ptr, ptr, ptr, i32, i32, %struct.kmap_ctrl, i32, i32, ptr, ptr, ptr, ptr, %struct.llist_head, %struct.thread_struct, [84 x i8] }
%struct.refcount_struct = type { %struct.atomic_t }
%struct.sched_entity = type { %struct.load_weight, %struct.rb_node, %struct.list_head, i32, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, [36 x i8], %struct.sched_avg }
%struct.sched_rt_entity = type { %struct.list_head, i32, i32, i32, i16, i16, ptr, ptr, ptr, ptr }
%struct.sched_dl_entity = type { %struct.rb_node, i64, i64, i64, i64, i64, i64, i64, i32, i8, %struct.hrtimer, %struct.hrtimer, ptr }
%struct.sched_statistics = type { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, [24 x i8] }
%union.rcu_special = type { i32 }
%struct.plist_node = type { i32, %struct.list_head, %struct.list_head }
%struct.vmacache = type { i64, [4 x ptr] }
%struct.task_rss_stat = type { i32, [4 x i32] }
%struct.restart_block = type { i32, ptr, %union.anon.22 }
%union.anon.22 = type { %struct.anon.23 }
%struct.anon.23 = type { ptr, i32, i32, i32, i64, ptr }
%struct.prev_cputime = type { i64, i64, %struct.raw_spinlock }
%struct.posix_cputimers = type { [3 x %struct.posix_cputimer_base], i32, i32 }
%struct.posix_cputimer_base = type { i64, %struct.timerqueue_head }
%struct.timerqueue_head = type { %struct.rb_root_cached }
%struct.sysv_sem = type { ptr }
%struct.sysv_shm = type { %struct.list_head }
%struct.sigset_t = type { [2 x i32] }
%struct.sigpending = type { %struct.list_head, %struct.sigset_t }
%struct.kuid_t = type { i32 }
%struct.seccomp = type { i32, %struct.atomic_t, ptr }
%struct.syscall_user_dispatch = type {}
%struct.spinlock = type { %union.anon.6 }
%union.anon.6 = type { %struct.raw_spinlock }
%struct.wake_q_node = type { ptr }
%struct.irqtrace_events = type { i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.held_lock = type { i64, i32, ptr, ptr, i64, i64, i32, i32 }
%struct.task_io_accounting = type { i64, i64, i64, i64, i64, i64, i64 }
%struct.nodemask_t = type { [1 x i32] }
%struct.seqcount_spinlock = type { %struct.seqcount, ptr }
%struct.seqcount = type { i32, %struct.lockdep_map }
%struct.tlbflush_unmap_batch = type {}
%union.anon.29 = type { %struct.callback_head }
%struct.page_frag = type { ptr, i16, i16 }
%struct.latency_record = type { [12 x i32], i32, i32, i32 }
%struct.kmap_ctrl = type { i32, [33 x i32] }
%struct.llist_head = type { ptr }
%struct.thread_struct = type { i32, i32, i32, %struct.debug_info }
%struct.debug_info = type { [32 x ptr] }
%struct.mm_struct = type { %struct.anon.3, [0 x i32] }
%struct.anon.3 = type { ptr, %struct.rb_root, i64, ptr, i32, i32, i32, i32, ptr, %struct.atomic_t, %struct.atomic_t, %struct.atomic_t, %struct.atomic_t, i32, %struct.spinlock, %struct.rw_semaphore, %struct.list_head, i32, i32, i32, i32, %struct.atomic64_t, i32, i32, i32, i32, %struct.seqcount, %struct.spinlock, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [42 x i32], %struct.mm_rss_stat, ptr, %struct.mm_context_t, i32, %struct.spinlock, ptr, ptr, ptr, ptr, ptr, %struct.atomic_t, %struct.uprobes_state, %struct.work_struct, i32 }
%struct.rw_semaphore = type { %struct.atomic_t, %struct.atomic_t, %struct.optimistic_spin_queue, %struct.raw_spinlock, %struct.list_head, ptr, %struct.lockdep_map }
%struct.atomic64_t = type { i64 }
%struct.mm_rss_stat = type { [4 x %struct.atomic_t] }
%struct.mm_context_t = type { %struct.atomic64_t, i32, i32, i32, i32, i32 }
%struct.uprobes_state = type { ptr }
%struct.static_key_false = type { %struct.static_key }
%struct.task_group = type { %struct.cgroup_subsys_state, ptr, ptr, i32, i32, [72 x i8], %struct.atomic_t, ptr, ptr, %struct.rt_bandwidth, %struct.callback_head, %struct.list_head, ptr, %struct.list_head, %struct.list_head, ptr, %struct.cfs_bandwidth, [2 x i32], [2 x %struct.uclamp_se], [2 x %struct.uclamp_se], [72 x i8] }
%struct.cgroup_subsys_state = type { ptr, ptr, %struct.percpu_ref, %struct.list_head, %struct.list_head, %struct.list_head, i32, i32, i64, %struct.atomic_t, %struct.work_struct, %struct.rcu_work, ptr }
%struct.percpu_ref = type { i32, ptr }
%struct.rcu_work = type { %struct.work_struct, %struct.callback_head, ptr }
%struct.rt_bandwidth = type { %struct.raw_spinlock, i64, i64, %struct.hrtimer, i32 }
%struct.cfs_bandwidth = type { %struct.raw_spinlock, i64, i64, i64, i64, i64, i64, i8, i8, i8, %struct.hrtimer, %struct.hrtimer, %struct.list_head, i32, i32, i32, i64, i64 }
%struct.dl_bandwidth = type { %struct.raw_spinlock, i64, i64 }
%struct.root_domain = type { %struct.atomic_t, %struct.atomic_t, %struct.callback_head, ptr, ptr, i32, i32, ptr, %struct.atomic_t, %struct.dl_bw, %struct.cpudl, i64, %struct.irq_work, %struct.raw_spinlock, i32, i32, %struct.atomic_t, %struct.atomic_t, ptr, %struct.cpupri, i32, ptr }
%struct.dl_bw = type { %struct.raw_spinlock, i64, i64 }
%struct.cpudl = type { %struct.raw_spinlock, i32, ptr, ptr }
%struct.irq_work = type { %struct.__call_single_node, ptr, %struct.rcuwait }
%struct.cpupri = type { [101 x %struct.cpupri_vec], ptr }
%struct.cpupri_vec = type { %struct.atomic_t, ptr }
%struct.rwlock_t = type { %struct.arch_rwlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_rwlock_t = type { i32 }
%struct.cftype = type { [64 x i8], i32, i32, i32, i32, ptr, %struct.list_head, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, %struct.lock_class_key }
%struct.cgroup_subsys = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i8, i32, ptr, ptr, ptr, %struct.idr, %struct.list_head, ptr, ptr, i32 }
%struct.idr = type { %struct.xarray, i32, i32 }
%struct.xarray = type { %struct.spinlock, i32, ptr }
%struct.trace_print_flags = type { i32, ptr }
%struct.irqtime = type { i64, i64, i64, %struct.u64_stats_sync }
%struct.u64_stats_sync = type { %struct.seqcount }
%struct.pt_regs = type { [18 x i32] }
%struct.cpu_cache_fns = type { ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr }
%struct.cpu_topology = type { i32, i32, i32, i32, i32, %struct.cpumask, %struct.cpumask, %struct.cpumask, %struct.cpumask }
%struct.static_key_true = type { %struct.static_key }
%struct.tracepoint_func = type { ptr, ptr, i32 }
%struct.trace_event_buffer = type { ptr, ptr, ptr, ptr, i32, ptr }
%struct.trace_event_file = type { %struct.list_head, ptr, ptr, ptr, ptr, ptr, %struct.list_head, i32, %struct.atomic_t, %struct.atomic_t }
%struct.trace_event_raw_sched_kthread_stop = type { %struct.trace_entry, [16 x i8], i32, [0 x i8] }
%struct.trace_entry = type { i16, i8, i8, i32 }
%struct.thread_info = type { i32, i32, ptr, i32, i32, %struct.cpu_context_save, i32, [16 x i8], [2 x i32], %union.fp_state, %union.vfp_state, i32 }
%struct.cpu_context_save = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [2 x i32] }
%union.fp_state = type { %struct.iwmmxt_struct }
%struct.iwmmxt_struct = type { [38 x i32] }
%union.vfp_state = type { %struct.vfp_hard_struct }
%struct.vfp_hard_struct = type { [32 x i64], i32, i32, i32, i32, i32 }
%struct.trace_event_raw_sched_kthread_stop_ret = type { %struct.trace_entry, i32, [0 x i8] }
%struct.trace_event_raw_sched_kthread_work_queue_work = type { %struct.trace_entry, ptr, ptr, ptr, [0 x i8] }
%struct.kthread_work = type { %struct.list_head, ptr, ptr, i32 }
%struct.trace_event_raw_sched_kthread_work_execute_start = type { %struct.trace_entry, ptr, ptr, [0 x i8] }
%struct.trace_event_raw_sched_kthread_work_execute_end = type { %struct.trace_entry, ptr, ptr, [0 x i8] }
%struct.trace_event_raw_sched_wakeup_template = type { %struct.trace_entry, [16 x i8], i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_switch = type { %struct.trace_entry, [16 x i8], i32, i32, i32, [16 x i8], i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_migrate_task = type { %struct.trace_entry, [16 x i8], i32, i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_process_template = type { %struct.trace_entry, [16 x i8], i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_process_wait = type { %struct.trace_entry, [16 x i8], i32, i32, [0 x i8] }
%struct.pid = type { %struct.refcount_struct, i32, %struct.spinlock, [4 x %struct.hlist_head], %struct.hlist_head, %struct.wait_queue_head, %struct.callback_head, [1 x %struct.upid] }
%struct.hlist_head = type { ptr }
%struct.wait_queue_head = type { %struct.spinlock, %struct.list_head }
%struct.upid = type { i32, ptr }
%struct.trace_event_raw_sched_process_fork = type { %struct.trace_entry, [16 x i8], i32, [16 x i8], i32, [0 x i8] }
%struct.linux_binprm = type { ptr, i32, ptr, i32, i32, i8, ptr, ptr, ptr, ptr, i32, i32, i32, i32, ptr, ptr, ptr, i32, i32, i32, i32, %struct.rlimit, [256 x i8] }
%struct.rlimit = type { i32, i32 }
%struct.trace_event_raw_sched_process_exec = type { %struct.trace_entry, i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_stat_template = type { %struct.trace_entry, [16 x i8], i32, i64, [0 x i8] }
%struct.trace_event_raw_sched_stat_runtime = type { %struct.trace_entry, [16 x i8], i32, i64, i64, [0 x i8] }
%struct.trace_event_raw_sched_pi_setprio = type { %struct.trace_entry, [16 x i8], i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_process_hang = type { %struct.trace_entry, [16 x i8], i32, [0 x i8] }
%struct.trace_event_raw_sched_move_numa = type { %struct.trace_entry, i32, i32, i32, i32, i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_numa_pair_template = type { %struct.trace_entry, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [0 x i8] }
%struct.trace_event_raw_sched_wake_idle_without_ipi = type { %struct.trace_entry, i32, [0 x i8] }
%struct.rq_flags = type { i32, %struct.pin_cookie, i32 }
%struct.pin_cookie = type { i32 }
%struct.hrtimer_clock_base = type { ptr, i32, i32, %struct.seqcount_raw_spinlock, ptr, %struct.timerqueue_head, ptr, i64 }
%struct.seqcount_raw_spinlock = type { %struct.seqcount, ptr }
%struct.wake_q_head = type { ptr, ptr }
%struct.sched_domain = type { ptr, ptr, ptr, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i64, i32, i64, [3 x i32], [3 x i32], [3 x i32], [3 x i32], [3 x i32], [3 x i32], [3 x i32], [3 x i32], i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, ptr, %union.anon.175, ptr, i32, [0 x i32] }
%union.anon.175 = type { %struct.callback_head }
%struct.signal_struct = type { %struct.refcount_struct, %struct.atomic_t, i32, %struct.list_head, %struct.wait_queue_head, ptr, %struct.sigpending, %struct.hlist_head, i32, i32, ptr, i32, i32, ptr, i8, i32, %struct.list_head, %struct.hrtimer, i64, [2 x %struct.cpu_itimer], %struct.thread_group_cputimer, %struct.posix_cputimers, [4 x ptr], ptr, i32, ptr, ptr, %struct.seqlock_t, i64, i64, i64, i64, i64, i64, %struct.prev_cputime, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, %struct.task_io_accounting, i64, [16 x %struct.rlimit], %struct.pacct_struct, ptr, i32, ptr, i8, i16, i16, ptr, %struct.mutex, %struct.rw_semaphore }
%struct.cpu_itimer = type { i64, i64 }
%struct.thread_group_cputimer = type { %struct.task_cputime_atomic }
%struct.task_cputime_atomic = type { %struct.atomic64_t, %struct.atomic64_t, %struct.atomic64_t }
%struct.seqlock_t = type { %struct.seqcount_spinlock, %struct.spinlock }
%struct.pacct_struct = type { i32, i32, i32, i64, i64, i32, i32 }
%struct.sched_attr = type { i32, i32, i64, i32, i32, i64, i64, i64, i32, i32 }
%struct.ctl_table = type { ptr, ptr, i32, i16, ptr, ptr, ptr, ptr, ptr }
%struct.kernel_clone_args = type { i64, ptr, ptr, ptr, i32, i32, i32, i32, ptr, i32, i32, i32, ptr, ptr }
%struct.autogroup = type { %struct.kref, ptr, %struct.rw_semaphore, i32, i32 }
%struct.kref = type { %struct.refcount_struct }
%struct.migration_arg = type { ptr, i32, ptr }
%struct.set_affinity_pending = type { %struct.refcount_struct, i32, %struct.completion, %struct.cpu_stop_work, %struct.migration_arg }
%struct.completion = type { i32, %struct.swait_queue_head }
%struct.swait_queue_head = type { %struct.raw_spinlock, %struct.list_head }
%struct.blk_plug = type { ptr, ptr, i16, i16, i8, i8, i8, %struct.list_head }
%struct.wait_queue_entry = type { i32, ptr, ptr, %struct.list_head }
%struct.sched_param = type { i32 }
%struct.cred = type { %struct.atomic_t, %struct.atomic_t, ptr, i32, %struct.kuid_t, %struct.kgid_t, %struct.kuid_t, %struct.kgid_t, %struct.kuid_t, %struct.kgid_t, %struct.kuid_t, %struct.kgid_t, i32, %struct.kernel_cap_struct, %struct.kernel_cap_struct, %struct.kernel_cap_struct, %struct.kernel_cap_struct, %struct.kernel_cap_struct, i8, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, %union.anon.54 }
%struct.kgid_t = type { i32 }
%struct.kernel_cap_struct = type { [2 x i32] }
%union.anon.54 = type { %struct.callback_head }
%struct.anon.7 = type { [16 x i8], %struct.lockdep_map }
%struct.timespec64 = type { i64, i32 }
%struct.trace_iterator = type { ptr, ptr, ptr, ptr, i32, %struct.mutex, ptr, i32, ptr, i32, ptr, i32, %struct.trace_seq, ptr, i8, %struct.trace_seq, ptr, i32, i32, i32, i32, i64, i64, i32 }
%struct.trace_seq = type { [4096 x i8], %struct.seq_buf, i32 }
%struct.seq_buf = type { ptr, i32, i32, i64 }
%struct.css_task_iter = type { ptr, i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, ptr, %struct.list_head }
%struct.wait_bit_queue_entry = type { %struct.wait_bit_key, %struct.wait_queue_entry }
%struct.wait_bit_key = type { ptr, i32, i32 }
%struct.seq_file = type { ptr, i32, i32, i32, i32, i64, i64, %struct.mutex, ptr, i32, ptr, ptr }
%struct.cfs_schedulable_data = type { ptr, i64, i64 }
%struct.uclamp_request = type { i64, i64, i32 }
%struct.sched_entity_stats = type { %struct.sched_entity, %struct.sched_statistics }

@__tpstrtab_sched_kthread_stop = internal constant [19 x i8] c"sched_kthread_stop\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_kthread_stop = dso_local global %struct.static_call_key { ptr @__traceiter_sched_kthread_stop }, align 4
@__tracepoint_sched_kthread_stop = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_kthread_stop, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_kthread_stop, ptr null, ptr @__traceiter_sched_kthread_stop, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_kthread_stop = internal constant ptr @__tracepoint_sched_kthread_stop, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_kthread_stop_ret = internal constant [23 x i8] c"sched_kthread_stop_ret\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_kthread_stop_ret = dso_local global %struct.static_call_key { ptr @__traceiter_sched_kthread_stop_ret }, align 4
@__tracepoint_sched_kthread_stop_ret = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_kthread_stop_ret, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_kthread_stop_ret, ptr null, ptr @__traceiter_sched_kthread_stop_ret, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_kthread_stop_ret = internal constant ptr @__tracepoint_sched_kthread_stop_ret, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_kthread_work_queue_work = internal constant [30 x i8] c"sched_kthread_work_queue_work\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_kthread_work_queue_work = dso_local global %struct.static_call_key { ptr @__traceiter_sched_kthread_work_queue_work }, align 4
@__tracepoint_sched_kthread_work_queue_work = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_kthread_work_queue_work, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_kthread_work_queue_work, ptr null, ptr @__traceiter_sched_kthread_work_queue_work, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_kthread_work_queue_work = internal constant ptr @__tracepoint_sched_kthread_work_queue_work, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_kthread_work_execute_start = internal constant [33 x i8] c"sched_kthread_work_execute_start\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_kthread_work_execute_start = dso_local global %struct.static_call_key { ptr @__traceiter_sched_kthread_work_execute_start }, align 4
@__tracepoint_sched_kthread_work_execute_start = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_kthread_work_execute_start, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_kthread_work_execute_start, ptr null, ptr @__traceiter_sched_kthread_work_execute_start, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_kthread_work_execute_start = internal constant ptr @__tracepoint_sched_kthread_work_execute_start, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_kthread_work_execute_end = internal constant [31 x i8] c"sched_kthread_work_execute_end\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_kthread_work_execute_end = dso_local global %struct.static_call_key { ptr @__traceiter_sched_kthread_work_execute_end }, align 4
@__tracepoint_sched_kthread_work_execute_end = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_kthread_work_execute_end, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_kthread_work_execute_end, ptr null, ptr @__traceiter_sched_kthread_work_execute_end, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_kthread_work_execute_end = internal constant ptr @__tracepoint_sched_kthread_work_execute_end, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_waking = internal constant [13 x i8] c"sched_waking\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_waking = dso_local global %struct.static_call_key { ptr @__traceiter_sched_waking }, align 4
@__tracepoint_sched_waking = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_waking, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_waking, ptr null, ptr @__traceiter_sched_waking, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_waking = internal constant ptr @__tracepoint_sched_waking, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_wakeup = internal constant [13 x i8] c"sched_wakeup\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_wakeup = dso_local global %struct.static_call_key { ptr @__traceiter_sched_wakeup }, align 4
@__tracepoint_sched_wakeup = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_wakeup, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_wakeup, ptr null, ptr @__traceiter_sched_wakeup, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_wakeup = internal constant ptr @__tracepoint_sched_wakeup, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_wakeup_new = internal constant [17 x i8] c"sched_wakeup_new\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_wakeup_new = dso_local global %struct.static_call_key { ptr @__traceiter_sched_wakeup_new }, align 4
@__tracepoint_sched_wakeup_new = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_wakeup_new, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_wakeup_new, ptr null, ptr @__traceiter_sched_wakeup_new, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_wakeup_new = internal constant ptr @__tracepoint_sched_wakeup_new, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_switch = internal constant [13 x i8] c"sched_switch\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_switch = dso_local global %struct.static_call_key { ptr @__traceiter_sched_switch }, align 4
@__tracepoint_sched_switch = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_switch, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_switch, ptr null, ptr @__traceiter_sched_switch, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_switch = internal constant ptr @__tracepoint_sched_switch, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_migrate_task = internal constant [19 x i8] c"sched_migrate_task\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_migrate_task = dso_local global %struct.static_call_key { ptr @__traceiter_sched_migrate_task }, align 4
@__tracepoint_sched_migrate_task = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_migrate_task, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_migrate_task, ptr null, ptr @__traceiter_sched_migrate_task, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_migrate_task = internal constant ptr @__tracepoint_sched_migrate_task, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_free = internal constant [19 x i8] c"sched_process_free\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_free = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_free }, align 4
@__tracepoint_sched_process_free = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_free, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_free, ptr null, ptr @__traceiter_sched_process_free, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_free = internal constant ptr @__tracepoint_sched_process_free, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_exit = internal constant [19 x i8] c"sched_process_exit\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_exit = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_exit }, align 4
@__tracepoint_sched_process_exit = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_exit, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_exit, ptr null, ptr @__traceiter_sched_process_exit, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_exit = internal constant ptr @__tracepoint_sched_process_exit, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_wait_task = internal constant [16 x i8] c"sched_wait_task\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_wait_task = dso_local global %struct.static_call_key { ptr @__traceiter_sched_wait_task }, align 4
@__tracepoint_sched_wait_task = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_wait_task, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_wait_task, ptr null, ptr @__traceiter_sched_wait_task, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_wait_task = internal constant ptr @__tracepoint_sched_wait_task, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_wait = internal constant [19 x i8] c"sched_process_wait\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_wait = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_wait }, align 4
@__tracepoint_sched_process_wait = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_wait, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_wait, ptr null, ptr @__traceiter_sched_process_wait, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_wait = internal constant ptr @__tracepoint_sched_process_wait, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_fork = internal constant [19 x i8] c"sched_process_fork\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_fork = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_fork }, align 4
@__tracepoint_sched_process_fork = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_fork, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_fork, ptr null, ptr @__traceiter_sched_process_fork, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_fork = internal constant ptr @__tracepoint_sched_process_fork, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_exec = internal constant [19 x i8] c"sched_process_exec\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_exec = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_exec }, align 4
@__tracepoint_sched_process_exec = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_exec, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_exec, ptr null, ptr @__traceiter_sched_process_exec, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_exec = internal constant ptr @__tracepoint_sched_process_exec, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stat_wait = internal constant [16 x i8] c"sched_stat_wait\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stat_wait = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stat_wait }, align 4
@__tracepoint_sched_stat_wait = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stat_wait, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stat_wait, ptr null, ptr @__traceiter_sched_stat_wait, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stat_wait = internal constant ptr @__tracepoint_sched_stat_wait, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stat_sleep = internal constant [17 x i8] c"sched_stat_sleep\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stat_sleep = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stat_sleep }, align 4
@__tracepoint_sched_stat_sleep = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stat_sleep, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stat_sleep, ptr null, ptr @__traceiter_sched_stat_sleep, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stat_sleep = internal constant ptr @__tracepoint_sched_stat_sleep, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stat_iowait = internal constant [18 x i8] c"sched_stat_iowait\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stat_iowait = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stat_iowait }, align 4
@__tracepoint_sched_stat_iowait = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stat_iowait, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stat_iowait, ptr null, ptr @__traceiter_sched_stat_iowait, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stat_iowait = internal constant ptr @__tracepoint_sched_stat_iowait, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stat_blocked = internal constant [19 x i8] c"sched_stat_blocked\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stat_blocked = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stat_blocked }, align 4
@__tracepoint_sched_stat_blocked = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stat_blocked, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stat_blocked, ptr null, ptr @__traceiter_sched_stat_blocked, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stat_blocked = internal constant ptr @__tracepoint_sched_stat_blocked, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stat_runtime = internal constant [19 x i8] c"sched_stat_runtime\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stat_runtime = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stat_runtime }, align 4
@__tracepoint_sched_stat_runtime = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stat_runtime, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stat_runtime, ptr null, ptr @__traceiter_sched_stat_runtime, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stat_runtime = internal constant ptr @__tracepoint_sched_stat_runtime, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_pi_setprio = internal constant [17 x i8] c"sched_pi_setprio\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_pi_setprio = dso_local global %struct.static_call_key { ptr @__traceiter_sched_pi_setprio }, align 4
@__tracepoint_sched_pi_setprio = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_pi_setprio, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_pi_setprio, ptr null, ptr @__traceiter_sched_pi_setprio, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_pi_setprio = internal constant ptr @__tracepoint_sched_pi_setprio, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_process_hang = internal constant [19 x i8] c"sched_process_hang\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_process_hang = dso_local global %struct.static_call_key { ptr @__traceiter_sched_process_hang }, align 4
@__tracepoint_sched_process_hang = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_process_hang, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_process_hang, ptr null, ptr @__traceiter_sched_process_hang, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_process_hang = internal constant ptr @__tracepoint_sched_process_hang, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_move_numa = internal constant [16 x i8] c"sched_move_numa\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_move_numa = dso_local global %struct.static_call_key { ptr @__traceiter_sched_move_numa }, align 4
@__tracepoint_sched_move_numa = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_move_numa, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_move_numa, ptr null, ptr @__traceiter_sched_move_numa, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_move_numa = internal constant ptr @__tracepoint_sched_move_numa, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_stick_numa = internal constant [17 x i8] c"sched_stick_numa\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_stick_numa = dso_local global %struct.static_call_key { ptr @__traceiter_sched_stick_numa }, align 4
@__tracepoint_sched_stick_numa = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_stick_numa, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_stick_numa, ptr null, ptr @__traceiter_sched_stick_numa, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_stick_numa = internal constant ptr @__tracepoint_sched_stick_numa, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_swap_numa = internal constant [16 x i8] c"sched_swap_numa\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_swap_numa = dso_local global %struct.static_call_key { ptr @__traceiter_sched_swap_numa }, align 4
@__tracepoint_sched_swap_numa = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_swap_numa, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_swap_numa, ptr null, ptr @__traceiter_sched_swap_numa, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_swap_numa = internal constant ptr @__tracepoint_sched_swap_numa, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_wake_idle_without_ipi = internal constant [28 x i8] c"sched_wake_idle_without_ipi\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_wake_idle_without_ipi = dso_local global %struct.static_call_key { ptr @__traceiter_sched_wake_idle_without_ipi }, align 4
@__tracepoint_sched_wake_idle_without_ipi = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_wake_idle_without_ipi, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_wake_idle_without_ipi, ptr null, ptr @__traceiter_sched_wake_idle_without_ipi, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_wake_idle_without_ipi = internal constant ptr @__tracepoint_sched_wake_idle_without_ipi, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_cfs_tp = internal constant [12 x i8] c"pelt_cfs_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_cfs_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_cfs_tp }, align 4
@__tracepoint_pelt_cfs_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_cfs_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_cfs_tp, ptr null, ptr @__traceiter_pelt_cfs_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_cfs_tp = internal constant ptr @__tracepoint_pelt_cfs_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_rt_tp = internal constant [11 x i8] c"pelt_rt_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_rt_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_rt_tp }, align 4
@__tracepoint_pelt_rt_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_rt_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_rt_tp, ptr null, ptr @__traceiter_pelt_rt_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_rt_tp = internal constant ptr @__tracepoint_pelt_rt_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_dl_tp = internal constant [11 x i8] c"pelt_dl_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_dl_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_dl_tp }, align 4
@__tracepoint_pelt_dl_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_dl_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_dl_tp, ptr null, ptr @__traceiter_pelt_dl_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_dl_tp = internal constant ptr @__tracepoint_pelt_dl_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_thermal_tp = internal constant [16 x i8] c"pelt_thermal_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_thermal_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_thermal_tp }, align 4
@__tracepoint_pelt_thermal_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_thermal_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_thermal_tp, ptr null, ptr @__traceiter_pelt_thermal_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_thermal_tp = internal constant ptr @__tracepoint_pelt_thermal_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_irq_tp = internal constant [12 x i8] c"pelt_irq_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_irq_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_irq_tp }, align 4
@__tracepoint_pelt_irq_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_irq_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_irq_tp, ptr null, ptr @__traceiter_pelt_irq_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_irq_tp = internal constant ptr @__tracepoint_pelt_irq_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_pelt_se_tp = internal constant [11 x i8] c"pelt_se_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_pelt_se_tp = dso_local global %struct.static_call_key { ptr @__traceiter_pelt_se_tp }, align 4
@__tracepoint_pelt_se_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_pelt_se_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_pelt_se_tp, ptr null, ptr @__traceiter_pelt_se_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_pelt_se_tp = internal constant ptr @__tracepoint_pelt_se_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_cpu_capacity_tp = internal constant [22 x i8] c"sched_cpu_capacity_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_cpu_capacity_tp = dso_local global %struct.static_call_key { ptr @__traceiter_sched_cpu_capacity_tp }, align 4
@__tracepoint_sched_cpu_capacity_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_cpu_capacity_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_cpu_capacity_tp, ptr null, ptr @__traceiter_sched_cpu_capacity_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_cpu_capacity_tp = internal constant ptr @__tracepoint_sched_cpu_capacity_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_overutilized_tp = internal constant [22 x i8] c"sched_overutilized_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_overutilized_tp = dso_local global %struct.static_call_key { ptr @__traceiter_sched_overutilized_tp }, align 4
@__tracepoint_sched_overutilized_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_overutilized_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_overutilized_tp, ptr null, ptr @__traceiter_sched_overutilized_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_overutilized_tp = internal constant ptr @__tracepoint_sched_overutilized_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_util_est_cfs_tp = internal constant [22 x i8] c"sched_util_est_cfs_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_util_est_cfs_tp = dso_local global %struct.static_call_key { ptr @__traceiter_sched_util_est_cfs_tp }, align 4
@__tracepoint_sched_util_est_cfs_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_util_est_cfs_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_util_est_cfs_tp, ptr null, ptr @__traceiter_sched_util_est_cfs_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_util_est_cfs_tp = internal constant ptr @__tracepoint_sched_util_est_cfs_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_util_est_se_tp = internal constant [21 x i8] c"sched_util_est_se_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_util_est_se_tp = dso_local global %struct.static_call_key { ptr @__traceiter_sched_util_est_se_tp }, align 4
@__tracepoint_sched_util_est_se_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_util_est_se_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_util_est_se_tp, ptr null, ptr @__traceiter_sched_util_est_se_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_util_est_se_tp = internal constant ptr @__tracepoint_sched_util_est_se_tp, section "__tracepoints_ptrs", align 4
@__tpstrtab_sched_update_nr_running_tp = internal constant [27 x i8] c"sched_update_nr_running_tp\00", section "__tracepoints_strings", align 1
@__SCK__tp_func_sched_update_nr_running_tp = dso_local global %struct.static_call_key { ptr @__traceiter_sched_update_nr_running_tp }, align 4
@__tracepoint_sched_update_nr_running_tp = dso_local global { ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr } { ptr @__tpstrtab_sched_update_nr_running_tp, { %struct.atomic_t, { ptr } } zeroinitializer, ptr @__SCK__tp_func_sched_update_nr_running_tp, ptr null, ptr @__traceiter_sched_update_nr_running_tp, ptr null, ptr null, ptr null }, section "__tracepoints", align 4
@__tracepoint_ptr_sched_update_nr_running_tp = internal constant ptr @__tracepoint_sched_update_nr_running_tp, section "__tracepoints_ptrs", align 4
@str__sched__trace_system_name = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"sched\00", [26 x i8] zeroinitializer }, align 32
@trace_event_fields_sched_kthread_stop = internal global { [3 x %struct.trace_event_fields], [56 x i8] } { [3 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [56 x i8] zeroinitializer }, align 32
@event_class_sched_kthread_stop = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_kthread_stop, ptr @perf_trace_sched_kthread_stop, ptr @trace_event_reg, ptr @trace_event_fields_sched_kthread_stop, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_kthread_stop, i64 24), ptr getelementptr (i8, ptr @event_class_sched_kthread_stop, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_kthread_stop = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_kthread_stop, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_kthread_stop = internal global { [38 x i8], [58 x i8] } { [38 x i8] c"\22comm=%s pid=%d\22, REC->comm, REC->pid\00", [58 x i8] zeroinitializer }, align 32
@event_sched_kthread_stop = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_kthread_stop, %union.anon.97 { ptr @__tracepoint_sched_kthread_stop }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_kthread_stop }, ptr @print_fmt_sched_kthread_stop, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_kthread_stop = internal global ptr @event_sched_kthread_stop, section "_ftrace_events", align 4
@trace_event_fields_sched_kthread_stop_ret = internal global { [2 x %struct.trace_event_fields], [48 x i8] } { [2 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.104, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [48 x i8] zeroinitializer }, align 32
@event_class_sched_kthread_stop_ret = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_kthread_stop_ret, ptr @perf_trace_sched_kthread_stop_ret, ptr @trace_event_reg, ptr @trace_event_fields_sched_kthread_stop_ret, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_kthread_stop_ret, i64 24), ptr getelementptr (i8, ptr @event_class_sched_kthread_stop_ret, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_kthread_stop_ret = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_kthread_stop_ret, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_kthread_stop_ret = internal global { [19 x i8], [45 x i8] } { [19 x i8] c"\22ret=%d\22, REC->ret\00", [45 x i8] zeroinitializer }, align 32
@event_sched_kthread_stop_ret = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_kthread_stop_ret, %union.anon.97 { ptr @__tracepoint_sched_kthread_stop_ret }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_kthread_stop_ret }, ptr @print_fmt_sched_kthread_stop_ret, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_kthread_stop_ret = internal global ptr @event_sched_kthread_stop_ret, section "_ftrace_events", align 4
@trace_event_fields_sched_kthread_work_queue_work = internal global { [4 x %struct.trace_event_fields], [32 x i8] } { [4 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.107, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.108, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.109, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_kthread_work_queue_work = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_kthread_work_queue_work, ptr @perf_trace_sched_kthread_work_queue_work, ptr @trace_event_reg, ptr @trace_event_fields_sched_kthread_work_queue_work, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_kthread_work_queue_work, i64 24), ptr getelementptr (i8, ptr @event_class_sched_kthread_work_queue_work, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_kthread_work_queue_work = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_kthread_work_queue_work, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_kthread_work_queue_work = internal global { [79 x i8], [49 x i8] } { [79 x i8] c"\22work struct=%p function=%ps worker=%p\22, REC->work, REC->function, REC->worker\00", [49 x i8] zeroinitializer }, align 32
@event_sched_kthread_work_queue_work = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_kthread_work_queue_work, %union.anon.97 { ptr @__tracepoint_sched_kthread_work_queue_work }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_kthread_work_queue_work }, ptr @print_fmt_sched_kthread_work_queue_work, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_kthread_work_queue_work = internal global ptr @event_sched_kthread_work_queue_work, section "_ftrace_events", align 4
@trace_event_fields_sched_kthread_work_execute_start = internal global { [3 x %struct.trace_event_fields], [56 x i8] } { [3 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.107, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.108, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [56 x i8] zeroinitializer }, align 32
@event_class_sched_kthread_work_execute_start = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_kthread_work_execute_start, ptr @perf_trace_sched_kthread_work_execute_start, ptr @trace_event_reg, ptr @trace_event_fields_sched_kthread_work_execute_start, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_kthread_work_execute_start, i64 24), ptr getelementptr (i8, ptr @event_class_sched_kthread_work_execute_start, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_kthread_work_execute_start = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_kthread_work_execute_start, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_kthread_work_execute_start = internal global { [57 x i8], [39 x i8] } { [57 x i8] c"\22work struct %p: function %ps\22, REC->work, REC->function\00", [39 x i8] zeroinitializer }, align 32
@event_sched_kthread_work_execute_start = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_kthread_work_execute_start, %union.anon.97 { ptr @__tracepoint_sched_kthread_work_execute_start }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_kthread_work_execute_start }, ptr @print_fmt_sched_kthread_work_execute_start, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_kthread_work_execute_start = internal global ptr @event_sched_kthread_work_execute_start, section "_ftrace_events", align 4
@trace_event_fields_sched_kthread_work_execute_end = internal global { [3 x %struct.trace_event_fields], [56 x i8] } { [3 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.107, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.106, %union.anon.95 { %struct.anon.96 { ptr @.str.108, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [56 x i8] zeroinitializer }, align 32
@event_class_sched_kthread_work_execute_end = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_kthread_work_execute_end, ptr @perf_trace_sched_kthread_work_execute_end, ptr @trace_event_reg, ptr @trace_event_fields_sched_kthread_work_execute_end, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_kthread_work_execute_end, i64 24), ptr getelementptr (i8, ptr @event_class_sched_kthread_work_execute_end, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_kthread_work_execute_end = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_kthread_work_execute_end, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_kthread_work_execute_end = internal global { [57 x i8], [39 x i8] } { [57 x i8] c"\22work struct %p: function %ps\22, REC->work, REC->function\00", [39 x i8] zeroinitializer }, align 32
@event_sched_kthread_work_execute_end = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_kthread_work_execute_end, %union.anon.97 { ptr @__tracepoint_sched_kthread_work_execute_end }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_kthread_work_execute_end }, ptr @print_fmt_sched_kthread_work_execute_end, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_kthread_work_execute_end = internal global ptr @event_sched_kthread_work_execute_end, section "_ftrace_events", align 4
@trace_event_fields_sched_wakeup_template = internal global { [5 x %struct.trace_event_fields], [40 x i8] } { [5 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.112, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.113, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [40 x i8] zeroinitializer }, align 32
@event_class_sched_wakeup_template = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_wakeup_template, ptr @perf_trace_sched_wakeup_template, ptr @trace_event_reg, ptr @trace_event_fields_sched_wakeup_template, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_wakeup_template, i64 24), ptr getelementptr (i8, ptr @event_class_sched_wakeup_template, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_wakeup_template = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_wakeup_template, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_wakeup_template = internal global { [90 x i8], [38 x i8] } { [90 x i8] c"\22comm=%s pid=%d prio=%d target_cpu=%03d\22, REC->comm, REC->pid, REC->prio, REC->target_cpu\00", [38 x i8] zeroinitializer }, align 32
@event_sched_waking = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_wakeup_template, %union.anon.97 { ptr @__tracepoint_sched_waking }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_wakeup_template }, ptr @print_fmt_sched_wakeup_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_waking = internal global ptr @event_sched_waking, section "_ftrace_events", align 4
@event_sched_wakeup = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_wakeup_template, %union.anon.97 { ptr @__tracepoint_sched_wakeup }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_wakeup_template }, ptr @print_fmt_sched_wakeup_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_wakeup = internal global ptr @event_sched_wakeup, section "_ftrace_events", align 4
@event_sched_wakeup_new = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_wakeup_template, %union.anon.97 { ptr @__tracepoint_sched_wakeup_new }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_wakeup_template }, ptr @print_fmt_sched_wakeup_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_wakeup_new = internal global ptr @event_sched_wakeup_new, section "_ftrace_events", align 4
@trace_event_fields_sched_switch = internal global { [8 x %struct.trace_event_fields], [32 x i8] } { [8 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.115, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.116, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.117, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.118, %union.anon.95 { %struct.anon.96 { ptr @.str.119, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.120, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.121, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.122, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_switch = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_switch, ptr @perf_trace_sched_switch, ptr @trace_event_reg, ptr @trace_event_fields_sched_switch, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_switch, i64 24), ptr getelementptr (i8, ptr @event_class_sched_switch, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_switch = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_switch, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_switch = internal global { [692 x i8], [172 x i8] } { [692 x i8] c"\22prev_comm=%s prev_pid=%d prev_prio=%d prev_state=%s%s ==> next_comm=%s next_pid=%d next_prio=%d\22, REC->prev_comm, REC->prev_pid, REC->prev_prio, (REC->prev_state & ((((0x0000 | 0x0001 | 0x0002 | 0x0004 | 0x0008 | 0x0010 | 0x0020 | 0x0040) + 1) << 1) - 1)) ? __print_flags(REC->prev_state & ((((0x0000 | 0x0001 | 0x0002 | 0x0004 | 0x0008 | 0x0010 | 0x0020 | 0x0040) + 1) << 1) - 1), \22|\22, { 0x0001, \22S\22 }, { 0x0002, \22D\22 }, { 0x0004, \22T\22 }, { 0x0008, \22t\22 }, { 0x0010, \22X\22 }, { 0x0020, \22Z\22 }, { 0x0040, \22P\22 }, { 0x0080, \22I\22 }) : \22R\22, REC->prev_state & (((0x0000 | 0x0001 | 0x0002 | 0x0004 | 0x0008 | 0x0010 | 0x0020 | 0x0040) + 1) << 1) ? \22+\22 : \22\22, REC->next_comm, REC->next_pid, REC->next_prio\00", [172 x i8] zeroinitializer }, align 32
@event_sched_switch = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_switch, %union.anon.97 { ptr @__tracepoint_sched_switch }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_switch }, ptr @print_fmt_sched_switch, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_switch = internal global ptr @event_sched_switch, section "_ftrace_events", align 4
@trace_event_fields_sched_migrate_task = internal global { [6 x %struct.trace_event_fields], [48 x i8] } { [6 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.112, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.136, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.137, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [48 x i8] zeroinitializer }, align 32
@event_class_sched_migrate_task = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_migrate_task, ptr @perf_trace_sched_migrate_task, ptr @trace_event_reg, ptr @trace_event_fields_sched_migrate_task, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_migrate_task, i64 24), ptr getelementptr (i8, ptr @event_class_sched_migrate_task, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_migrate_task = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_migrate_task, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_migrate_task = internal global { [111 x i8], [49 x i8] } { [111 x i8] c"\22comm=%s pid=%d prio=%d orig_cpu=%d dest_cpu=%d\22, REC->comm, REC->pid, REC->prio, REC->orig_cpu, REC->dest_cpu\00", [49 x i8] zeroinitializer }, align 32
@event_sched_migrate_task = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_migrate_task, %union.anon.97 { ptr @__tracepoint_sched_migrate_task }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_migrate_task }, ptr @print_fmt_sched_migrate_task, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_migrate_task = internal global ptr @event_sched_migrate_task, section "_ftrace_events", align 4
@trace_event_fields_sched_process_template = internal global { [4 x %struct.trace_event_fields], [32 x i8] } { [4 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.112, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_process_template = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_process_template, ptr @perf_trace_sched_process_template, ptr @trace_event_reg, ptr @trace_event_fields_sched_process_template, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_process_template, i64 24), ptr getelementptr (i8, ptr @event_class_sched_process_template, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_process_template = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_process_template, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_process_template = internal global { [57 x i8], [39 x i8] } { [57 x i8] c"\22comm=%s pid=%d prio=%d\22, REC->comm, REC->pid, REC->prio\00", [39 x i8] zeroinitializer }, align 32
@event_sched_process_free = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_template, %union.anon.97 { ptr @__tracepoint_sched_process_free }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_template }, ptr @print_fmt_sched_process_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_free = internal global ptr @event_sched_process_free, section "_ftrace_events", align 4
@event_sched_process_exit = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_template, %union.anon.97 { ptr @__tracepoint_sched_process_exit }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_template }, ptr @print_fmt_sched_process_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_exit = internal global ptr @event_sched_process_exit, section "_ftrace_events", align 4
@event_sched_wait_task = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_template, %union.anon.97 { ptr @__tracepoint_sched_wait_task }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_template }, ptr @print_fmt_sched_process_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_wait_task = internal global ptr @event_sched_wait_task, section "_ftrace_events", align 4
@trace_event_fields_sched_process_wait = internal global { [4 x %struct.trace_event_fields], [32 x i8] } { [4 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.112, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_process_wait = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_process_wait, ptr @perf_trace_sched_process_wait, ptr @trace_event_reg, ptr @trace_event_fields_sched_process_wait, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_process_wait, i64 24), ptr getelementptr (i8, ptr @event_class_sched_process_wait, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_process_wait = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_process_wait, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_process_wait = internal global { [57 x i8], [39 x i8] } { [57 x i8] c"\22comm=%s pid=%d prio=%d\22, REC->comm, REC->pid, REC->prio\00", [39 x i8] zeroinitializer }, align 32
@event_sched_process_wait = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_wait, %union.anon.97 { ptr @__tracepoint_sched_process_wait }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_wait }, ptr @print_fmt_sched_process_wait, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_wait = internal global ptr @event_sched_process_wait, section "_ftrace_events", align 4
@trace_event_fields_sched_process_fork = internal global { [5 x %struct.trace_event_fields], [40 x i8] } { [5 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.140, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.141, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.142, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.143, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [40 x i8] zeroinitializer }, align 32
@event_class_sched_process_fork = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_process_fork, ptr @perf_trace_sched_process_fork, ptr @trace_event_reg, ptr @trace_event_fields_sched_process_fork, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_process_fork, i64 24), ptr getelementptr (i8, ptr @event_class_sched_process_fork, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_process_fork = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_process_fork, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_process_fork = internal global { [112 x i8], [48 x i8] } { [112 x i8] c"\22comm=%s pid=%d child_comm=%s child_pid=%d\22, REC->parent_comm, REC->parent_pid, REC->child_comm, REC->child_pid\00", [48 x i8] zeroinitializer }, align 32
@event_sched_process_fork = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_fork, %union.anon.97 { ptr @__tracepoint_sched_process_fork }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_fork }, ptr @print_fmt_sched_process_fork, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_fork = internal global ptr @event_sched_process_fork, section "_ftrace_events", align 4
@trace_event_fields_sched_process_exec = internal global { [4 x %struct.trace_event_fields], [32 x i8] } { [4 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.146, %union.anon.95 { %struct.anon.96 { ptr @.str.147, i32 4, i32 4, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.148, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_process_exec = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_process_exec, ptr @perf_trace_sched_process_exec, ptr @trace_event_reg, ptr @trace_event_fields_sched_process_exec, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_process_exec, i64 24), ptr getelementptr (i8, ptr @event_class_sched_process_exec, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_process_exec = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_process_exec, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_process_exec = internal global { [77 x i8], [51 x i8] } { [77 x i8] c"\22filename=%s pid=%d old_pid=%d\22, __get_str(filename), REC->pid, REC->old_pid\00", [51 x i8] zeroinitializer }, align 32
@event_sched_process_exec = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_exec, %union.anon.97 { ptr @__tracepoint_sched_process_exec }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_exec }, ptr @print_fmt_sched_process_exec, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_exec = internal global ptr @event_sched_process_exec, section "_ftrace_events", align 4
@trace_event_fields_sched_stat_template = internal global { [4 x %struct.trace_event_fields], [32 x i8] } { [4 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.150, %union.anon.95 { %struct.anon.96 { ptr @.str.151, i32 8, i32 8, i32 0, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_stat_template = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_stat_template, ptr @perf_trace_sched_stat_template, ptr @trace_event_reg, ptr @trace_event_fields_sched_stat_template, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_stat_template, i64 24), ptr getelementptr (i8, ptr @event_class_sched_stat_template, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_stat_template = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_stat_template, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_stat_template = internal global { [85 x i8], [43 x i8] } { [85 x i8] c"\22comm=%s pid=%d delay=%Lu [ns]\22, REC->comm, REC->pid, (unsigned long long)REC->delay\00", [43 x i8] zeroinitializer }, align 32
@event_sched_stat_wait = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_stat_template, %union.anon.97 { ptr @__tracepoint_sched_stat_wait }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_stat_template }, ptr @print_fmt_sched_stat_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stat_wait = internal global ptr @event_sched_stat_wait, section "_ftrace_events", align 4
@event_sched_stat_sleep = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_stat_template, %union.anon.97 { ptr @__tracepoint_sched_stat_sleep }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_stat_template }, ptr @print_fmt_sched_stat_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stat_sleep = internal global ptr @event_sched_stat_sleep, section "_ftrace_events", align 4
@event_sched_stat_iowait = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_stat_template, %union.anon.97 { ptr @__tracepoint_sched_stat_iowait }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_stat_template }, ptr @print_fmt_sched_stat_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stat_iowait = internal global ptr @event_sched_stat_iowait, section "_ftrace_events", align 4
@event_sched_stat_blocked = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_stat_template, %union.anon.97 { ptr @__tracepoint_sched_stat_blocked }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_stat_template }, ptr @print_fmt_sched_stat_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stat_blocked = internal global ptr @event_sched_stat_blocked, section "_ftrace_events", align 4
@trace_event_fields_sched_stat_runtime = internal global { [5 x %struct.trace_event_fields], [40 x i8] } { [5 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.150, %union.anon.95 { %struct.anon.96 { ptr @.str.153, i32 8, i32 8, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.150, %union.anon.95 { %struct.anon.96 { ptr @.str.154, i32 8, i32 8, i32 0, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [40 x i8] zeroinitializer }, align 32
@event_class_sched_stat_runtime = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_stat_runtime, ptr @perf_trace_sched_stat_runtime, ptr @trace_event_reg, ptr @trace_event_fields_sched_stat_runtime, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_stat_runtime, i64 24), ptr getelementptr (i8, ptr @event_class_sched_stat_runtime, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_stat_runtime = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_stat_runtime, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_stat_runtime = internal global { [142 x i8], [50 x i8] } { [142 x i8] c"\22comm=%s pid=%d runtime=%Lu [ns] vruntime=%Lu [ns]\22, REC->comm, REC->pid, (unsigned long long)REC->runtime, (unsigned long long)REC->vruntime\00", [50 x i8] zeroinitializer }, align 32
@event_sched_stat_runtime = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_stat_runtime, %union.anon.97 { ptr @__tracepoint_sched_stat_runtime }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_stat_runtime }, ptr @print_fmt_sched_stat_runtime, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stat_runtime = internal global ptr @event_sched_stat_runtime, section "_ftrace_events", align 4
@trace_event_fields_sched_pi_setprio = internal global { [5 x %struct.trace_event_fields], [40 x i8] } { [5 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.156, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.157, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [40 x i8] zeroinitializer }, align 32
@event_class_sched_pi_setprio = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_pi_setprio, ptr @perf_trace_sched_pi_setprio, ptr @trace_event_reg, ptr @trace_event_fields_sched_pi_setprio, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_pi_setprio, i64 24), ptr getelementptr (i8, ptr @event_class_sched_pi_setprio, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_pi_setprio = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_pi_setprio, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_pi_setprio = internal global { [88 x i8], [40 x i8] } { [88 x i8] c"\22comm=%s pid=%d oldprio=%d newprio=%d\22, REC->comm, REC->pid, REC->oldprio, REC->newprio\00", [40 x i8] zeroinitializer }, align 32
@event_sched_pi_setprio = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_pi_setprio, %union.anon.97 { ptr @__tracepoint_sched_pi_setprio }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_pi_setprio }, ptr @print_fmt_sched_pi_setprio, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_pi_setprio = internal global ptr @event_sched_pi_setprio, section "_ftrace_events", align 4
@trace_event_fields_sched_process_hang = internal global { [3 x %struct.trace_event_fields], [56 x i8] } { [3 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.98, %union.anon.95 { %struct.anon.96 { ptr @.str.99, i32 16, i32 1, i32 0, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [56 x i8] zeroinitializer }, align 32
@event_class_sched_process_hang = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_process_hang, ptr @perf_trace_sched_process_hang, ptr @trace_event_reg, ptr @trace_event_fields_sched_process_hang, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_process_hang, i64 24), ptr getelementptr (i8, ptr @event_class_sched_process_hang, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_process_hang = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_process_hang, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_process_hang = internal global { [38 x i8], [58 x i8] } { [38 x i8] c"\22comm=%s pid=%d\22, REC->comm, REC->pid\00", [58 x i8] zeroinitializer }, align 32
@event_sched_process_hang = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_process_hang, %union.anon.97 { ptr @__tracepoint_sched_process_hang }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_process_hang }, ptr @print_fmt_sched_process_hang, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_process_hang = internal global ptr @event_sched_process_hang, section "_ftrace_events", align 4
@trace_event_fields_sched_move_numa = internal global { [8 x %struct.trace_event_fields], [32 x i8] } { [8 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.101, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.159, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.160, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.161, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.162, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.163, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.164, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [32 x i8] zeroinitializer }, align 32
@event_class_sched_move_numa = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_move_numa, ptr @perf_trace_sched_move_numa, ptr @trace_event_reg, ptr @trace_event_fields_sched_move_numa, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_move_numa, i64 24), ptr getelementptr (i8, ptr @event_class_sched_move_numa, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_move_numa = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_move_numa, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_move_numa = internal global { [157 x i8], [35 x i8] } { [157 x i8] c"\22pid=%d tgid=%d ngid=%d src_cpu=%d src_nid=%d dst_cpu=%d dst_nid=%d\22, REC->pid, REC->tgid, REC->ngid, REC->src_cpu, REC->src_nid, REC->dst_cpu, REC->dst_nid\00", [35 x i8] zeroinitializer }, align 32
@event_sched_move_numa = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_move_numa, %union.anon.97 { ptr @__tracepoint_sched_move_numa }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_move_numa }, ptr @print_fmt_sched_move_numa, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_move_numa = internal global ptr @event_sched_move_numa, section "_ftrace_events", align 4
@trace_event_fields_sched_numa_pair_template = internal global { [11 x %struct.trace_event_fields], [88 x i8] } { [11 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.166, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.167, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.168, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.161, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.162, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.169, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.170, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.100, %union.anon.95 { %struct.anon.96 { ptr @.str.171, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.163, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.164, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [88 x i8] zeroinitializer }, align 32
@event_class_sched_numa_pair_template = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_numa_pair_template, ptr @perf_trace_sched_numa_pair_template, ptr @trace_event_reg, ptr @trace_event_fields_sched_numa_pair_template, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_numa_pair_template, i64 24), ptr getelementptr (i8, ptr @event_class_sched_numa_pair_template, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_numa_pair_template = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_numa_pair_template, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_numa_pair_template = internal global { [260 x i8], [92 x i8] } { [260 x i8] c"\22src_pid=%d src_tgid=%d src_ngid=%d src_cpu=%d src_nid=%d dst_pid=%d dst_tgid=%d dst_ngid=%d dst_cpu=%d dst_nid=%d\22, REC->src_pid, REC->src_tgid, REC->src_ngid, REC->src_cpu, REC->src_nid, REC->dst_pid, REC->dst_tgid, REC->dst_ngid, REC->dst_cpu, REC->dst_nid\00", [92 x i8] zeroinitializer }, align 32
@event_sched_stick_numa = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_numa_pair_template, %union.anon.97 { ptr @__tracepoint_sched_stick_numa }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_numa_pair_template }, ptr @print_fmt_sched_numa_pair_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_stick_numa = internal global ptr @event_sched_stick_numa, section "_ftrace_events", align 4
@event_sched_swap_numa = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_numa_pair_template, %union.anon.97 { ptr @__tracepoint_sched_swap_numa }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_numa_pair_template }, ptr @print_fmt_sched_numa_pair_template, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_swap_numa = internal global ptr @event_sched_swap_numa, section "_ftrace_events", align 4
@trace_event_fields_sched_wake_idle_without_ipi = internal global { [2 x %struct.trace_event_fields], [48 x i8] } { [2 x %struct.trace_event_fields] [%struct.trace_event_fields { ptr @.str.103, %union.anon.95 { %struct.anon.96 { ptr @.str.173, i32 4, i32 4, i32 1, i32 0 } } }, %struct.trace_event_fields zeroinitializer], [48 x i8] zeroinitializer }, align 32
@event_class_sched_wake_idle_without_ipi = internal global %struct.trace_event_class { ptr @str__sched__trace_system_name, ptr @trace_event_raw_event_sched_wake_idle_without_ipi, ptr @perf_trace_sched_wake_idle_without_ipi, ptr @trace_event_reg, ptr @trace_event_fields_sched_wake_idle_without_ipi, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @event_class_sched_wake_idle_without_ipi, i64 24), ptr getelementptr (i8, ptr @event_class_sched_wake_idle_without_ipi, i64 24) }, ptr @trace_event_raw_init }, section ".ref.data", align 4
@trace_event_type_funcs_sched_wake_idle_without_ipi = internal global { %struct.trace_event_functions, [16 x i8] } { %struct.trace_event_functions { ptr @trace_raw_output_sched_wake_idle_without_ipi, ptr null, ptr null, ptr null }, [16 x i8] zeroinitializer }, align 32
@print_fmt_sched_wake_idle_without_ipi = internal global { [19 x i8], [45 x i8] } { [19 x i8] c"\22cpu=%d\22, REC->cpu\00", [45 x i8] zeroinitializer }, align 32
@event_sched_wake_idle_without_ipi = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_sched_wake_idle_without_ipi, %union.anon.97 { ptr @__tracepoint_sched_wake_idle_without_ipi }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @trace_event_type_funcs_sched_wake_idle_without_ipi }, ptr @print_fmt_sched_wake_idle_without_ipi, ptr null, %union.anon.98 zeroinitializer, ptr null, i32 16, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_sched_wake_idle_without_ipi = internal global ptr @event_sched_wake_idle_without_ipi, section "_ftrace_events", align 4
@__bpf_trace_tp_map_sched_kthread_stop = internal global %union.anon.99 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_kthread_stop, ptr @__bpf_trace_sched_kthread_stop, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_kthread_stop_ret = internal global %union.anon.100 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_kthread_stop_ret, ptr @__bpf_trace_sched_kthread_stop_ret, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_kthread_work_queue_work = internal global %union.anon.101 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_kthread_work_queue_work, ptr @__bpf_trace_sched_kthread_work_queue_work, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_kthread_work_execute_start = internal global %union.anon.102 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_kthread_work_execute_start, ptr @__bpf_trace_sched_kthread_work_execute_start, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_kthread_work_execute_end = internal global %union.anon.103 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_kthread_work_execute_end, ptr @__bpf_trace_sched_kthread_work_execute_end, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_waking = internal global %union.anon.104 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_waking, ptr @__bpf_trace_sched_wakeup_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_wakeup = internal global %union.anon.105 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_wakeup, ptr @__bpf_trace_sched_wakeup_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_wakeup_new = internal global %union.anon.106 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_wakeup_new, ptr @__bpf_trace_sched_wakeup_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_switch = internal global %union.anon.107 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_switch, ptr @__bpf_trace_sched_switch, i32 3, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_migrate_task = internal global %union.anon.108 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_migrate_task, ptr @__bpf_trace_sched_migrate_task, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_free = internal global %union.anon.109 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_free, ptr @__bpf_trace_sched_process_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_exit = internal global %union.anon.110 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_exit, ptr @__bpf_trace_sched_process_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_wait_task = internal global %union.anon.111 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_wait_task, ptr @__bpf_trace_sched_process_template, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_wait = internal global %union.anon.112 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_wait, ptr @__bpf_trace_sched_process_wait, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_fork = internal global %union.anon.113 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_fork, ptr @__bpf_trace_sched_process_fork, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_exec = internal global %union.anon.114 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_exec, ptr @__bpf_trace_sched_process_exec, i32 3, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stat_wait = internal global %union.anon.115 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stat_wait, ptr @__bpf_trace_sched_stat_template, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stat_sleep = internal global %union.anon.116 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stat_sleep, ptr @__bpf_trace_sched_stat_template, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stat_iowait = internal global %union.anon.117 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stat_iowait, ptr @__bpf_trace_sched_stat_template, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stat_blocked = internal global %union.anon.118 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stat_blocked, ptr @__bpf_trace_sched_stat_template, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stat_runtime = internal global %union.anon.119 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stat_runtime, ptr @__bpf_trace_sched_stat_runtime, i32 3, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_pi_setprio = internal global %union.anon.120 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_pi_setprio, ptr @__bpf_trace_sched_pi_setprio, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_process_hang = internal global %union.anon.121 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_process_hang, ptr @__bpf_trace_sched_process_hang, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_move_numa = internal global %union.anon.122 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_move_numa, ptr @__bpf_trace_sched_move_numa, i32 3, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_stick_numa = internal global %union.anon.123 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_stick_numa, ptr @__bpf_trace_sched_numa_pair_template, i32 4, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_swap_numa = internal global %union.anon.124 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_swap_numa, ptr @__bpf_trace_sched_numa_pair_template, i32 4, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_wake_idle_without_ipi = internal global %union.anon.125 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_wake_idle_without_ipi, ptr @__bpf_trace_sched_wake_idle_without_ipi, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_cfs_tp = internal global %union.anon.126 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_cfs_tp, ptr @__bpf_trace_pelt_cfs_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_rt_tp = internal global %union.anon.127 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_rt_tp, ptr @__bpf_trace_pelt_rt_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_dl_tp = internal global %union.anon.128 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_dl_tp, ptr @__bpf_trace_pelt_dl_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_thermal_tp = internal global %union.anon.129 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_thermal_tp, ptr @__bpf_trace_pelt_thermal_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_irq_tp = internal global %union.anon.130 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_irq_tp, ptr @__bpf_trace_pelt_irq_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_pelt_se_tp = internal global %union.anon.131 { %struct.bpf_raw_event_map { ptr @__tracepoint_pelt_se_tp, ptr @__bpf_trace_pelt_se_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_cpu_capacity_tp = internal global %union.anon.132 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_cpu_capacity_tp, ptr @__bpf_trace_sched_cpu_capacity_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_overutilized_tp = internal global %union.anon.133 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_overutilized_tp, ptr @__bpf_trace_sched_overutilized_tp, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_util_est_cfs_tp = internal global %union.anon.134 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_util_est_cfs_tp, ptr @__bpf_trace_sched_util_est_cfs_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_util_est_se_tp = internal global %union.anon.135 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_util_est_se_tp, ptr @__bpf_trace_sched_util_est_se_tp, i32 1, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__bpf_trace_tp_map_sched_update_nr_running_tp = internal global %union.anon.136 { %struct.bpf_raw_event_map { ptr @__tracepoint_sched_update_nr_running_tp, ptr @__bpf_trace_sched_update_nr_running_tp, i32 2, i32 0, [16 x i8] undef } }, section "__bpf_raw_tp_map", align 32
@__kstrtab___tracepoint_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_pelt_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_pelt_cfs_tp to i32), ptr @__kstrtab___tracepoint_pelt_cfs_tp, ptr @__kstrtabns___tracepoint_pelt_cfs_tp }, section "___ksymtab_gpl+__tracepoint_pelt_cfs_tp", align 4
@__kstrtab___traceiter_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_pelt_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_pelt_cfs_tp to i32), ptr @__kstrtab___traceiter_pelt_cfs_tp, ptr @__kstrtabns___traceiter_pelt_cfs_tp }, section "___ksymtab_gpl+__traceiter_pelt_cfs_tp", align 4
@__kstrtab___SCK__tp_func_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_pelt_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_pelt_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_pelt_cfs_tp to i32), ptr @__kstrtab___SCK__tp_func_pelt_cfs_tp, ptr @__kstrtabns___SCK__tp_func_pelt_cfs_tp }, section "___ksymtab_gpl+__SCK__tp_func_pelt_cfs_tp", align 4
@__kstrtab___tracepoint_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_pelt_rt_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_pelt_rt_tp to i32), ptr @__kstrtab___tracepoint_pelt_rt_tp, ptr @__kstrtabns___tracepoint_pelt_rt_tp }, section "___ksymtab_gpl+__tracepoint_pelt_rt_tp", align 4
@__kstrtab___traceiter_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_pelt_rt_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_pelt_rt_tp to i32), ptr @__kstrtab___traceiter_pelt_rt_tp, ptr @__kstrtabns___traceiter_pelt_rt_tp }, section "___ksymtab_gpl+__traceiter_pelt_rt_tp", align 4
@__kstrtab___SCK__tp_func_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_pelt_rt_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_pelt_rt_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_pelt_rt_tp to i32), ptr @__kstrtab___SCK__tp_func_pelt_rt_tp, ptr @__kstrtabns___SCK__tp_func_pelt_rt_tp }, section "___ksymtab_gpl+__SCK__tp_func_pelt_rt_tp", align 4
@__kstrtab___tracepoint_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_pelt_dl_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_pelt_dl_tp to i32), ptr @__kstrtab___tracepoint_pelt_dl_tp, ptr @__kstrtabns___tracepoint_pelt_dl_tp }, section "___ksymtab_gpl+__tracepoint_pelt_dl_tp", align 4
@__kstrtab___traceiter_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_pelt_dl_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_pelt_dl_tp to i32), ptr @__kstrtab___traceiter_pelt_dl_tp, ptr @__kstrtabns___traceiter_pelt_dl_tp }, section "___ksymtab_gpl+__traceiter_pelt_dl_tp", align 4
@__kstrtab___SCK__tp_func_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_pelt_dl_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_pelt_dl_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_pelt_dl_tp to i32), ptr @__kstrtab___SCK__tp_func_pelt_dl_tp, ptr @__kstrtabns___SCK__tp_func_pelt_dl_tp }, section "___ksymtab_gpl+__SCK__tp_func_pelt_dl_tp", align 4
@__kstrtab___tracepoint_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_pelt_irq_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_pelt_irq_tp to i32), ptr @__kstrtab___tracepoint_pelt_irq_tp, ptr @__kstrtabns___tracepoint_pelt_irq_tp }, section "___ksymtab_gpl+__tracepoint_pelt_irq_tp", align 4
@__kstrtab___traceiter_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_pelt_irq_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_pelt_irq_tp to i32), ptr @__kstrtab___traceiter_pelt_irq_tp, ptr @__kstrtabns___traceiter_pelt_irq_tp }, section "___ksymtab_gpl+__traceiter_pelt_irq_tp", align 4
@__kstrtab___SCK__tp_func_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_pelt_irq_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_pelt_irq_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_pelt_irq_tp to i32), ptr @__kstrtab___SCK__tp_func_pelt_irq_tp, ptr @__kstrtabns___SCK__tp_func_pelt_irq_tp }, section "___ksymtab_gpl+__SCK__tp_func_pelt_irq_tp", align 4
@__kstrtab___tracepoint_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_pelt_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_pelt_se_tp to i32), ptr @__kstrtab___tracepoint_pelt_se_tp, ptr @__kstrtabns___tracepoint_pelt_se_tp }, section "___ksymtab_gpl+__tracepoint_pelt_se_tp", align 4
@__kstrtab___traceiter_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_pelt_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_pelt_se_tp to i32), ptr @__kstrtab___traceiter_pelt_se_tp, ptr @__kstrtabns___traceiter_pelt_se_tp }, section "___ksymtab_gpl+__traceiter_pelt_se_tp", align 4
@__kstrtab___SCK__tp_func_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_pelt_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_pelt_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_pelt_se_tp to i32), ptr @__kstrtab___SCK__tp_func_pelt_se_tp, ptr @__kstrtabns___SCK__tp_func_pelt_se_tp }, section "___ksymtab_gpl+__SCK__tp_func_pelt_se_tp", align 4
@__kstrtab___tracepoint_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_sched_cpu_capacity_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_sched_cpu_capacity_tp to i32), ptr @__kstrtab___tracepoint_sched_cpu_capacity_tp, ptr @__kstrtabns___tracepoint_sched_cpu_capacity_tp }, section "___ksymtab_gpl+__tracepoint_sched_cpu_capacity_tp", align 4
@__kstrtab___traceiter_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_sched_cpu_capacity_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_sched_cpu_capacity_tp to i32), ptr @__kstrtab___traceiter_sched_cpu_capacity_tp, ptr @__kstrtabns___traceiter_sched_cpu_capacity_tp }, section "___ksymtab_gpl+__traceiter_sched_cpu_capacity_tp", align 4
@__kstrtab___SCK__tp_func_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_sched_cpu_capacity_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_sched_cpu_capacity_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_sched_cpu_capacity_tp to i32), ptr @__kstrtab___SCK__tp_func_sched_cpu_capacity_tp, ptr @__kstrtabns___SCK__tp_func_sched_cpu_capacity_tp }, section "___ksymtab_gpl+__SCK__tp_func_sched_cpu_capacity_tp", align 4
@__kstrtab___tracepoint_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_sched_overutilized_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_sched_overutilized_tp to i32), ptr @__kstrtab___tracepoint_sched_overutilized_tp, ptr @__kstrtabns___tracepoint_sched_overutilized_tp }, section "___ksymtab_gpl+__tracepoint_sched_overutilized_tp", align 4
@__kstrtab___traceiter_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_sched_overutilized_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_sched_overutilized_tp to i32), ptr @__kstrtab___traceiter_sched_overutilized_tp, ptr @__kstrtabns___traceiter_sched_overutilized_tp }, section "___ksymtab_gpl+__traceiter_sched_overutilized_tp", align 4
@__kstrtab___SCK__tp_func_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_sched_overutilized_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_sched_overutilized_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_sched_overutilized_tp to i32), ptr @__kstrtab___SCK__tp_func_sched_overutilized_tp, ptr @__kstrtabns___SCK__tp_func_sched_overutilized_tp }, section "___ksymtab_gpl+__SCK__tp_func_sched_overutilized_tp", align 4
@__kstrtab___tracepoint_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_sched_util_est_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_sched_util_est_cfs_tp to i32), ptr @__kstrtab___tracepoint_sched_util_est_cfs_tp, ptr @__kstrtabns___tracepoint_sched_util_est_cfs_tp }, section "___ksymtab_gpl+__tracepoint_sched_util_est_cfs_tp", align 4
@__kstrtab___traceiter_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_sched_util_est_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_sched_util_est_cfs_tp to i32), ptr @__kstrtab___traceiter_sched_util_est_cfs_tp, ptr @__kstrtabns___traceiter_sched_util_est_cfs_tp }, section "___ksymtab_gpl+__traceiter_sched_util_est_cfs_tp", align 4
@__kstrtab___SCK__tp_func_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_sched_util_est_cfs_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_sched_util_est_cfs_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_sched_util_est_cfs_tp to i32), ptr @__kstrtab___SCK__tp_func_sched_util_est_cfs_tp, ptr @__kstrtabns___SCK__tp_func_sched_util_est_cfs_tp }, section "___ksymtab_gpl+__SCK__tp_func_sched_util_est_cfs_tp", align 4
@__kstrtab___tracepoint_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_sched_util_est_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_sched_util_est_se_tp to i32), ptr @__kstrtab___tracepoint_sched_util_est_se_tp, ptr @__kstrtabns___tracepoint_sched_util_est_se_tp }, section "___ksymtab_gpl+__tracepoint_sched_util_est_se_tp", align 4
@__kstrtab___traceiter_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_sched_util_est_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_sched_util_est_se_tp to i32), ptr @__kstrtab___traceiter_sched_util_est_se_tp, ptr @__kstrtabns___traceiter_sched_util_est_se_tp }, section "___ksymtab_gpl+__traceiter_sched_util_est_se_tp", align 4
@__kstrtab___SCK__tp_func_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_sched_util_est_se_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_sched_util_est_se_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_sched_util_est_se_tp to i32), ptr @__kstrtab___SCK__tp_func_sched_util_est_se_tp, ptr @__kstrtabns___SCK__tp_func_sched_util_est_se_tp }, section "___ksymtab_gpl+__SCK__tp_func_sched_util_est_se_tp", align 4
@__kstrtab___tracepoint_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___tracepoint_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___tracepoint_sched_update_nr_running_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__tracepoint_sched_update_nr_running_tp to i32), ptr @__kstrtab___tracepoint_sched_update_nr_running_tp, ptr @__kstrtabns___tracepoint_sched_update_nr_running_tp }, section "___ksymtab_gpl+__tracepoint_sched_update_nr_running_tp", align 4
@__kstrtab___traceiter_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___traceiter_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___traceiter_sched_update_nr_running_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__traceiter_sched_update_nr_running_tp to i32), ptr @__kstrtab___traceiter_sched_update_nr_running_tp, ptr @__kstrtabns___traceiter_sched_update_nr_running_tp }, section "___ksymtab_gpl+__traceiter_sched_update_nr_running_tp", align 4
@__kstrtab___SCK__tp_func_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__kstrtabns___SCK__tp_func_sched_update_nr_running_tp = external dso_local constant [0 x i8], align 1
@__ksymtab___SCK__tp_func_sched_update_nr_running_tp = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__SCK__tp_func_sched_update_nr_running_tp to i32), ptr @__kstrtab___SCK__tp_func_sched_update_nr_running_tp, ptr @__kstrtabns___SCK__tp_func_sched_update_nr_running_tp }, section "___ksymtab_gpl+__SCK__tp_func_sched_update_nr_running_tp", align 4
@sysctl_sched_features = dso_local local_unnamed_addr global i32 29306427, section ".data..read_mostly", align 4
@sysctl_resched_latency_warn_ms = dso_local global i32 100, section ".data..read_mostly", align 4
@sysctl_resched_latency_warn_once = dso_local local_unnamed_addr global i32 1, section ".data..read_mostly", align 4
@sysctl_sched_nr_migrate = dso_local local_unnamed_addr global i32 32, section ".data..read_mostly", align 4
@sysctl_sched_rt_period = dso_local global { i32, [28 x i8] } { i32 1000000, [28 x i8] zeroinitializer }, align 32
@__sched_core_enabled = dso_local global { { %struct.atomic_t, { ptr } } } zeroinitializer, align 4
@sched_core_count = internal global { %struct.atomic_t, [28 x i8] } zeroinitializer, align 32
@sched_core_mutex = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.175, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @sched_core_mutex, i64 52), ptr getelementptr (i8, ptr @sched_core_mutex, i64 52) }, ptr @sched_core_mutex, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.176, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@sched_core_put._work = internal global { %struct.work_struct, [52 x i8] } { %struct.work_struct { %struct.atomic_t { i32 -48 }, %struct.list_head { ptr getelementptr (i8, ptr @sched_core_put._work, i64 4), ptr getelementptr (i8, ptr @sched_core_put._work, i64 4) }, ptr @__sched_core_put, %struct.lockdep_map { ptr @sched_core_put._work, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 0, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@.str = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"_work\00", [26 x i8] zeroinitializer }, align 32
@sysctl_sched_rt_runtime = dso_local global { i32, [28 x i8] } { i32 950000, [28 x i8] zeroinitializer }, align 32
@double_rq_lock.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@debug_locks = external dso_local local_unnamed_addr global i32, section ".data..read_mostly", align 4
@lockdep_recursion = external dso_local global i32, section ".data..percpu", align 4
@__per_cpu_offset = external dso_local local_unnamed_addr global [4 x i32], align 4
@hardirqs_enabled = external dso_local global i32, section ".data..percpu", align 4
@.str.1 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"kernel/sched/core.c\00", [44 x i8] zeroinitializer }, align 32
@runqueues = weak dso_local global %struct.rq zeroinitializer, section ".data..percpu..shared_aligned", align 128
@sched_feat_keys = external dso_local global [25 x %struct.static_key], align 4
@update_rq_clock.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.2 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"rq->clock_update_flags & RQCF_UPDATED\00", [58 x i8] zeroinitializer }, align 32
@get_nohz_timer_target.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@sched_domains_mutex = external dso_local global %struct.mutex, align 4
@.str.3 = internal constant { [41 x i8], [55 x i8] } { [41 x i8] c"suspicious rcu_dereference_check() usage\00", [55 x i8] zeroinitializer }, align 32
@nr_cpu_ids = external dso_local local_unnamed_addr global i32, align 4
@walk_tg_tree_from.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.4 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"RCU-list traversed in non-reader section!\00", [54 x i8] zeroinitializer }, align 32
@sysctl_sched_uclamp_util_min = dso_local global { i32, [28 x i8] } { i32 1024, [28 x i8] zeroinitializer }, align 32
@sysctl_sched_uclamp_util_max = dso_local global { i32, [28 x i8] } { i32 1024, [28 x i8] zeroinitializer }, align 32
@sysctl_sched_uclamp_util_min_rt_default = dso_local global { i32, [28 x i8] } { i32 1024, [28 x i8] zeroinitializer }, align 32
@sched_uclamp_used = dso_local global { { { %struct.atomic_t, { ptr } } }, [24 x i8] } zeroinitializer, align 32
@uclamp_mutex = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.184, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @uclamp_mutex, i64 52), ptr getelementptr (i8, ptr @uclamp_mutex, i64 52) }, ptr @uclamp_mutex, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.185, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@uclamp_default = internal global { [2 x %struct.uclamp_se], [24 x i8] } zeroinitializer, align 32
@__kstrtab_migrate_disable = external dso_local constant [0 x i8], align 1
@__kstrtabns_migrate_disable = external dso_local constant [0 x i8], align 1
@__ksymtab_migrate_disable = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @migrate_disable to i32), ptr @__kstrtab_migrate_disable, ptr @__kstrtabns_migrate_disable }, section "___ksymtab_gpl+migrate_disable", align 4
@migrate_enable.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_migrate_enable = external dso_local constant [0 x i8], align 1
@__kstrtabns_migrate_enable = external dso_local constant [0 x i8], align 1
@__ksymtab_migrate_enable = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @migrate_enable to i32), ptr @__kstrtab_migrate_enable, ptr @__kstrtabns_migrate_enable }, section "___ksymtab_gpl+migrate_enable", align 4
@__kstrtab_set_cpus_allowed_ptr = external dso_local constant [0 x i8], align 1
@__kstrtabns_set_cpus_allowed_ptr = external dso_local constant [0 x i8], align 1
@__ksymtab_set_cpus_allowed_ptr = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @set_cpus_allowed_ptr to i32), ptr @__kstrtab_set_cpus_allowed_ptr, ptr @__kstrtabns_set_cpus_allowed_ptr }, section "___ksymtab_gpl+set_cpus_allowed_ptr", align 4
@__cpu_possible_mask = external dso_local global %struct.cpumask, align 4
@__func__.force_compatible_cpus_allowed_ptr = private unnamed_addr constant [34 x i8] c"force_compatible_cpus_allowed_ptr\00", align 1
@force_compatible_cpus_allowed_ptr._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.5, ptr @__func__.force_compatible_cpus_allowed_ptr, ptr @.str.1, i32 2986, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.5 = internal constant { [55 x i8], [41 x i8] } { [55 x i8] c"Overriding affinity for process %d (%s) to CPUs %*pbl\0A\00", [41 x i8] zeroinitializer }, align 32
@force_compatible_cpus_allowed_ptr._entry_ptr = internal global ptr @force_compatible_cpus_allowed_ptr._entry, section ".printk_index", align 4
@set_task_cpu.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@set_task_cpu.__already_done.6 = internal unnamed_addr global i1 false, section ".data.once", align 1
@fair_sched_class = external dso_local constant %struct.sched_class, align 4
@set_task_cpu.__already_done.7 = internal unnamed_addr global i1 false, section ".data.once", align 1
@set_task_cpu.__already_done.8 = internal unnamed_addr global i1 false, section ".data.once", align 1
@set_task_cpu.__already_done.9 = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_kick_process = external dso_local constant [0 x i8], align 1
@__kstrtabns_kick_process = external dso_local constant [0 x i8], align 1
@__ksymtab_kick_process = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @kick_process to i32), ptr @__kstrtab_kick_process, ptr @__kstrtabns_kick_process }, section "___ksymtab_gpl+kick_process", align 4
@sched_set_stop_task.stop_pi_lock = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@stop_sched_class = external dso_local constant %struct.sched_class, align 4
@.str.10 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"&stop_pi_lock\00", [18 x i8] zeroinitializer }, align 32
@rt_sched_class = external dso_local constant %struct.sched_class, align 4
@sched_ttwu_pending.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@sched_ttwu_pending.__already_done.11 = internal unnamed_addr global i1 false, section ".data.once", align 1
@wake_up_if_idle.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@sd_llc_id = external dso_local global i32, section ".data..percpu", align 4
@__kstrtab_wake_up_process = external dso_local constant [0 x i8], align 1
@__kstrtabns_wake_up_process = external dso_local constant [0 x i8], align 1
@__ksymtab_wake_up_process = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @wake_up_process to i32), ptr @__kstrtab_wake_up_process, ptr @__kstrtabns_wake_up_process }, section "___ksymtab+wake_up_process", align 4
@sched_numa_balancing = dso_local global { { { %struct.atomic_t, { ptr } } }, [24 x i8] } zeroinitializer, align 32
@sched_schedstats = dso_local global { { { %struct.atomic_t, { ptr } } }, [24 x i8] } zeroinitializer, align 32
@force_schedstat_enabled._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.12, ptr @.str.13, ptr @.str.1, i32 4328, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.12 = internal constant { [77 x i8], [51 x i8] } { [77 x i8] c"\016kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\0A\00", [51 x i8] zeroinitializer }, align 32
@.str.13 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"force_schedstat_enabled\00", [40 x i8] zeroinitializer }, align 32
@force_schedstat_enabled._entry_ptr = internal global ptr @force_schedstat_enabled._entry, section ".printk_index", align 4
@__setup_str_setup_schedstats = internal constant [12 x i8] c"schedstats=\00", section ".init.rodata", align 1
@__setup_setup_schedstats = internal global %struct.obs_kernel_param { ptr @__setup_str_setup_schedstats, ptr @setup_schedstats, i32 0 }, section ".init.setup", align 4
@balance_push_callback = dso_local global { %struct.callback_head, [24 x i8] } { %struct.callback_head { ptr null, ptr @balance_push }, [24 x i8] zeroinitializer }, align 32
@__cpu_online_mask = external dso_local global %struct.cpumask, align 4
@__kstrtab_single_task_running = external dso_local constant [0 x i8], align 1
@__kstrtabns_single_task_running = external dso_local constant [0 x i8], align 1
@__ksymtab_single_task_running = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @single_task_running to i32), ptr @__kstrtab_single_task_running, ptr @__kstrtabns_single_task_running }, section "___ksymtab+single_task_running", align 4
@kstat = weak dso_local global %struct.kernel_stat zeroinitializer, section ".data..percpu", align 4
@__kstrtab_kstat = external dso_local constant [0 x i8], align 1
@__kstrtabns_kstat = external dso_local constant [0 x i8], align 1
@__ksymtab_kstat = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @kstat to i32), ptr @__kstrtab_kstat, ptr @__kstrtabns_kstat }, section "___ksymtab+kstat", align 4
@kernel_cpustat = weak dso_local global %struct.kernel_cpustat zeroinitializer, section ".data..percpu", align 8
@__kstrtab_kernel_cpustat = external dso_local constant [0 x i8], align 1
@__kstrtabns_kernel_cpustat = external dso_local constant [0 x i8], align 1
@__ksymtab_kernel_cpustat = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @kernel_cpustat to i32), ptr @__kstrtab_kernel_cpustat, ptr @__kstrtabns_kernel_cpustat }, section "___ksymtab+kernel_cpustat", align 4
@__setup_str_setup_resched_latency_warn_ms = internal constant [25 x i8] c"resched_latency_warn_ms=\00", section ".init.rodata", align 1
@__setup_setup_resched_latency_warn_ms = internal global %struct.obs_kernel_param { ptr @__setup_str_setup_resched_latency_warn_ms, ptr @setup_resched_latency_warn_ms, i32 0 }, section ".init.setup", align 4
@core_balance_head = weak dso_local global %struct.callback_head zeroinitializer, section ".data..percpu", align 4
@__kstrtab_schedule = external dso_local constant [0 x i8], align 1
@__kstrtabns_schedule = external dso_local constant [0 x i8], align 1
@__ksymtab_schedule = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @schedule to i32), ptr @__kstrtab_schedule, ptr @__kstrtabns_schedule }, section "___ksymtab+schedule", align 4
@schedule_idle.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@default_wake_function.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_default_wake_function = external dso_local constant [0 x i8], align 1
@__kstrtabns_default_wake_function = external dso_local constant [0 x i8], align 1
@__ksymtab_default_wake_function = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @default_wake_function to i32), ptr @__kstrtab_default_wake_function, ptr @__kstrtabns_default_wake_function }, section "___ksymtab+default_wake_function", align 4
@__kstrtab_set_user_nice = external dso_local constant [0 x i8], align 1
@__kstrtabns_set_user_nice = external dso_local constant [0 x i8], align 1
@__ksymtab_set_user_nice = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @set_user_nice to i32), ptr @__kstrtab_set_user_nice, ptr @__kstrtabns_set_user_nice }, section "___ksymtab+set_user_nice", align 4
@event_class_syscall_enter = external dso_local global %struct.trace_event_class, align 4
@.str.14 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"sys_enter_nice\00", [17 x i8] zeroinitializer }, align 32
@enter_syscall_print_funcs = external dso_local global %struct.trace_event_functions, align 4
@__syscall_meta__nice = internal global %struct.syscall_metadata { ptr @.str.16, i32 -1, i32 1, ptr @types__nice, ptr @args__nice, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__nice, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__nice, i64 20) }, ptr @event_enter__nice, ptr @event_exit__nice }, align 4
@event_enter__nice = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.14 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__nice, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__nice = internal global ptr @event_enter__nice, section "_ftrace_events", align 4
@event_class_syscall_exit = external dso_local global %struct.trace_event_class, align 4
@.str.15 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"sys_exit_nice\00", [18 x i8] zeroinitializer }, align 32
@exit_syscall_print_funcs = external dso_local global %struct.trace_event_functions, align 4
@event_exit__nice = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.15 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__nice, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__nice = internal global ptr @event_exit__nice, section "_ftrace_events", align 4
@.str.16 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"sys_nice\00", [23 x i8] zeroinitializer }, align 32
@types__nice = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.103], [28 x i8] zeroinitializer }, align 32
@args__nice = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.214], [28 x i8] zeroinitializer }, align 32
@__p_syscall_meta__nice = internal global ptr @__syscall_meta__nice, section "__syscalls_metadata", align 4
@__kstrtab_sched_setattr_nocheck = external dso_local constant [0 x i8], align 1
@__kstrtabns_sched_setattr_nocheck = external dso_local constant [0 x i8], align 1
@__ksymtab_sched_setattr_nocheck = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @sched_setattr_nocheck to i32), ptr @__kstrtab_sched_setattr_nocheck, ptr @__kstrtabns_sched_setattr_nocheck }, section "___ksymtab_gpl+sched_setattr_nocheck", align 4
@sched_set_fifo.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_sched_set_fifo = external dso_local constant [0 x i8], align 1
@__kstrtabns_sched_set_fifo = external dso_local constant [0 x i8], align 1
@__ksymtab_sched_set_fifo = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @sched_set_fifo to i32), ptr @__kstrtab_sched_set_fifo, ptr @__kstrtabns_sched_set_fifo }, section "___ksymtab_gpl+sched_set_fifo", align 4
@sched_set_fifo_low.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_sched_set_fifo_low = external dso_local constant [0 x i8], align 1
@__kstrtabns_sched_set_fifo_low = external dso_local constant [0 x i8], align 1
@__ksymtab_sched_set_fifo_low = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @sched_set_fifo_low to i32), ptr @__kstrtab_sched_set_fifo_low, ptr @__kstrtabns_sched_set_fifo_low }, section "___ksymtab_gpl+sched_set_fifo_low", align 4
@sched_set_normal.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@__kstrtab_sched_set_normal = external dso_local constant [0 x i8], align 1
@__kstrtabns_sched_set_normal = external dso_local constant [0 x i8], align 1
@__ksymtab_sched_set_normal = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @sched_set_normal to i32), ptr @__kstrtab_sched_set_normal, ptr @__kstrtabns_sched_set_normal }, section "___ksymtab_gpl+sched_set_normal", align 4
@.str.17 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"sys_enter_sched_setscheduler\00", [35 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_setscheduler = internal global %struct.syscall_metadata { ptr @.str.19, i32 -1, i32 3, ptr @types__sched_setscheduler, ptr @args__sched_setscheduler, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_setscheduler, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_setscheduler, i64 20) }, ptr @event_enter__sched_setscheduler, ptr @event_exit__sched_setscheduler }, align 4
@event_enter__sched_setscheduler = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.17 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setscheduler, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_setscheduler = internal global ptr @event_enter__sched_setscheduler, section "_ftrace_events", align 4
@.str.18 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"sys_exit_sched_setscheduler\00", [36 x i8] zeroinitializer }, align 32
@event_exit__sched_setscheduler = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.18 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setscheduler, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_setscheduler = internal global ptr @event_exit__sched_setscheduler, section "_ftrace_events", align 4
@.str.19 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"sys_sched_setscheduler\00", [41 x i8] zeroinitializer }, align 32
@types__sched_setscheduler = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.100, ptr @.str.103, ptr @.str.215], [20 x i8] zeroinitializer }, align 32
@args__sched_setscheduler = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.101, ptr @.str.216, ptr @.str.217], [20 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_setscheduler = internal global ptr @__syscall_meta__sched_setscheduler, section "__syscalls_metadata", align 4
@.str.20 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"sys_enter_sched_setparam\00", [39 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_setparam = internal global %struct.syscall_metadata { ptr @.str.22, i32 -1, i32 2, ptr @types__sched_setparam, ptr @args__sched_setparam, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_setparam, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_setparam, i64 20) }, ptr @event_enter__sched_setparam, ptr @event_exit__sched_setparam }, align 4
@event_enter__sched_setparam = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.20 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setparam, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_setparam = internal global ptr @event_enter__sched_setparam, section "_ftrace_events", align 4
@.str.21 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"sys_exit_sched_setparam\00", [40 x i8] zeroinitializer }, align 32
@event_exit__sched_setparam = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.21 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setparam, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_setparam = internal global ptr @event_exit__sched_setparam, section "_ftrace_events", align 4
@.str.22 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"sys_sched_setparam\00", [45 x i8] zeroinitializer }, align 32
@types__sched_setparam = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.100, ptr @.str.215], [24 x i8] zeroinitializer }, align 32
@args__sched_setparam = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.101, ptr @.str.217], [24 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_setparam = internal global ptr @__syscall_meta__sched_setparam, section "__syscalls_metadata", align 4
@.str.23 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"sys_enter_sched_setattr\00", [40 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_setattr = internal global %struct.syscall_metadata { ptr @.str.25, i32 -1, i32 3, ptr @types__sched_setattr, ptr @args__sched_setattr, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_setattr, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_setattr, i64 20) }, ptr @event_enter__sched_setattr, ptr @event_exit__sched_setattr }, align 4
@event_enter__sched_setattr = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.23 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setattr, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_setattr = internal global ptr @event_enter__sched_setattr, section "_ftrace_events", align 4
@.str.24 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"sys_exit_sched_setattr\00", [41 x i8] zeroinitializer }, align 32
@event_exit__sched_setattr = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.24 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setattr, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_setattr = internal global ptr @event_exit__sched_setattr, section "_ftrace_events", align 4
@.str.25 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"sys_sched_setattr\00", [46 x i8] zeroinitializer }, align 32
@types__sched_setattr = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.100, ptr @.str.221, ptr @.str.222], [20 x i8] zeroinitializer }, align 32
@args__sched_setattr = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.101, ptr @.str.223, ptr @.str.224], [20 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_setattr = internal global ptr @__syscall_meta__sched_setattr, section "__syscalls_metadata", align 4
@.str.26 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"sys_enter_sched_getscheduler\00", [35 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_getscheduler = internal global %struct.syscall_metadata { ptr @.str.28, i32 -1, i32 1, ptr @types__sched_getscheduler, ptr @args__sched_getscheduler, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_getscheduler, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_getscheduler, i64 20) }, ptr @event_enter__sched_getscheduler, ptr @event_exit__sched_getscheduler }, align 4
@event_enter__sched_getscheduler = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.26 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getscheduler, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_getscheduler = internal global ptr @event_enter__sched_getscheduler, section "_ftrace_events", align 4
@.str.27 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"sys_exit_sched_getscheduler\00", [36 x i8] zeroinitializer }, align 32
@event_exit__sched_getscheduler = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.27 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getscheduler, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_getscheduler = internal global ptr @event_exit__sched_getscheduler, section "_ftrace_events", align 4
@.str.28 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"sys_sched_getscheduler\00", [41 x i8] zeroinitializer }, align 32
@types__sched_getscheduler = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.100], [28 x i8] zeroinitializer }, align 32
@args__sched_getscheduler = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.101], [28 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_getscheduler = internal global ptr @__syscall_meta__sched_getscheduler, section "__syscalls_metadata", align 4
@.str.29 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"sys_enter_sched_getparam\00", [39 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_getparam = internal global %struct.syscall_metadata { ptr @.str.31, i32 -1, i32 2, ptr @types__sched_getparam, ptr @args__sched_getparam, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_getparam, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_getparam, i64 20) }, ptr @event_enter__sched_getparam, ptr @event_exit__sched_getparam }, align 4
@event_enter__sched_getparam = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.29 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getparam, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_getparam = internal global ptr @event_enter__sched_getparam, section "_ftrace_events", align 4
@.str.30 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"sys_exit_sched_getparam\00", [40 x i8] zeroinitializer }, align 32
@event_exit__sched_getparam = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.30 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getparam, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_getparam = internal global ptr @event_exit__sched_getparam, section "_ftrace_events", align 4
@.str.31 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"sys_sched_getparam\00", [45 x i8] zeroinitializer }, align 32
@types__sched_getparam = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.100, ptr @.str.215], [24 x i8] zeroinitializer }, align 32
@args__sched_getparam = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.101, ptr @.str.217], [24 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_getparam = internal global ptr @__syscall_meta__sched_getparam, section "__syscalls_metadata", align 4
@.str.32 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"sys_enter_sched_getattr\00", [40 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_getattr = internal global %struct.syscall_metadata { ptr @.str.34, i32 -1, i32 4, ptr @types__sched_getattr, ptr @args__sched_getattr, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_getattr, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_getattr, i64 20) }, ptr @event_enter__sched_getattr, ptr @event_exit__sched_getattr }, align 4
@event_enter__sched_getattr = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.32 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getattr, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_getattr = internal global ptr @event_enter__sched_getattr, section "_ftrace_events", align 4
@.str.33 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"sys_exit_sched_getattr\00", [41 x i8] zeroinitializer }, align 32
@event_exit__sched_getattr = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.33 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getattr, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_getattr = internal global ptr @event_exit__sched_getattr, section "_ftrace_events", align 4
@.str.34 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"sys_sched_getattr\00", [46 x i8] zeroinitializer }, align 32
@types__sched_getattr = internal global { [4 x ptr], [16 x i8] } { [4 x ptr] [ptr @.str.100, ptr @.str.221, ptr @.str.222, ptr @.str.222], [16 x i8] zeroinitializer }, align 32
@args__sched_getattr = internal global { [4 x ptr], [16 x i8] } { [4 x ptr] [ptr @.str.101, ptr @.str.223, ptr @.str.225, ptr @.str.224], [16 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_getattr = internal global ptr @__syscall_meta__sched_getattr, section "__syscalls_metadata", align 4
@sched_setaffinity.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.35 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"sys_enter_sched_setaffinity\00", [36 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_setaffinity = internal global %struct.syscall_metadata { ptr @.str.37, i32 -1, i32 3, ptr @types__sched_setaffinity, ptr @args__sched_setaffinity, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_setaffinity, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_setaffinity, i64 20) }, ptr @event_enter__sched_setaffinity, ptr @event_exit__sched_setaffinity }, align 4
@event_enter__sched_setaffinity = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.35 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setaffinity, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_setaffinity = internal global ptr @event_enter__sched_setaffinity, section "_ftrace_events", align 4
@.str.36 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sys_exit_sched_setaffinity\00", [37 x i8] zeroinitializer }, align 32
@event_exit__sched_setaffinity = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.36 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_setaffinity, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_setaffinity = internal global ptr @event_exit__sched_setaffinity, section "_ftrace_events", align 4
@.str.37 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"sys_sched_setaffinity\00", [42 x i8] zeroinitializer }, align 32
@types__sched_setaffinity = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.100, ptr @.str.222, ptr @.str.227], [20 x i8] zeroinitializer }, align 32
@args__sched_setaffinity = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.101, ptr @.str.228, ptr @.str.229], [20 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_setaffinity = internal global ptr @__syscall_meta__sched_setaffinity, section "__syscalls_metadata", align 4
@__cpu_active_mask = external dso_local global %struct.cpumask, align 4
@.str.38 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"sys_enter_sched_getaffinity\00", [36 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_getaffinity = internal global %struct.syscall_metadata { ptr @.str.40, i32 -1, i32 3, ptr @types__sched_getaffinity, ptr @args__sched_getaffinity, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_getaffinity, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_getaffinity, i64 20) }, ptr @event_enter__sched_getaffinity, ptr @event_exit__sched_getaffinity }, align 4
@event_enter__sched_getaffinity = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.38 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getaffinity, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_getaffinity = internal global ptr @event_enter__sched_getaffinity, section "_ftrace_events", align 4
@.str.39 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sys_exit_sched_getaffinity\00", [37 x i8] zeroinitializer }, align 32
@event_exit__sched_getaffinity = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.39 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_getaffinity, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_getaffinity = internal global ptr @event_exit__sched_getaffinity, section "_ftrace_events", align 4
@.str.40 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"sys_sched_getaffinity\00", [42 x i8] zeroinitializer }, align 32
@types__sched_getaffinity = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.100, ptr @.str.222, ptr @.str.227], [20 x i8] zeroinitializer }, align 32
@args__sched_getaffinity = internal global { [3 x ptr], [20 x i8] } { [3 x ptr] [ptr @.str.101, ptr @.str.228, ptr @.str.229], [20 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_getaffinity = internal global ptr @__syscall_meta__sched_getaffinity, section "__syscalls_metadata", align 4
@.str.41 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"sys_enter_sched_yield\00", [42 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_yield = internal global %struct.syscall_metadata { ptr @.str.43, i32 -1, i32 0, ptr null, ptr null, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_yield, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_yield, i64 20) }, ptr @event_enter__sched_yield, ptr @event_exit__sched_yield }, align 4
@event_enter__sched_yield = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.41 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_yield, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_yield = internal global ptr @event_enter__sched_yield, section "_ftrace_events", align 4
@.str.42 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"sys_exit_sched_yield\00", [43 x i8] zeroinitializer }, align 32
@event_exit__sched_yield = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.42 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_yield, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_yield = internal global ptr @event_exit__sched_yield, section "_ftrace_events", align 4
@.str.43 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"sys_sched_yield\00", [16 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_yield = internal global ptr @__syscall_meta__sched_yield, section "__syscalls_metadata", align 4
@__kstrtab___cond_resched = external dso_local constant [0 x i8], align 1
@__kstrtabns___cond_resched = external dso_local constant [0 x i8], align 1
@__ksymtab___cond_resched = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cond_resched to i32), ptr @__kstrtab___cond_resched, ptr @__kstrtabns___cond_resched }, section "___ksymtab+__cond_resched", align 4
@__kstrtab___cond_resched_lock = external dso_local constant [0 x i8], align 1
@__kstrtabns___cond_resched_lock = external dso_local constant [0 x i8], align 1
@__ksymtab___cond_resched_lock = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cond_resched_lock to i32), ptr @__kstrtab___cond_resched_lock, ptr @__kstrtabns___cond_resched_lock }, section "___ksymtab+__cond_resched_lock", align 4
@__kstrtab___cond_resched_rwlock_read = external dso_local constant [0 x i8], align 1
@__kstrtabns___cond_resched_rwlock_read = external dso_local constant [0 x i8], align 1
@__ksymtab___cond_resched_rwlock_read = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cond_resched_rwlock_read to i32), ptr @__kstrtab___cond_resched_rwlock_read, ptr @__kstrtabns___cond_resched_rwlock_read }, section "___ksymtab+__cond_resched_rwlock_read", align 4
@__kstrtab___cond_resched_rwlock_write = external dso_local constant [0 x i8], align 1
@__kstrtabns___cond_resched_rwlock_write = external dso_local constant [0 x i8], align 1
@__ksymtab___cond_resched_rwlock_write = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cond_resched_rwlock_write to i32), ptr @__kstrtab___cond_resched_rwlock_write, ptr @__kstrtabns___cond_resched_rwlock_write }, section "___ksymtab+__cond_resched_rwlock_write", align 4
@__kstrtab_yield = external dso_local constant [0 x i8], align 1
@__kstrtabns_yield = external dso_local constant [0 x i8], align 1
@__ksymtab_yield = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @yield to i32), ptr @__kstrtab_yield, ptr @__kstrtabns_yield }, section "___ksymtab+yield", align 4
@__kstrtab_yield_to = external dso_local constant [0 x i8], align 1
@__kstrtabns_yield_to = external dso_local constant [0 x i8], align 1
@__ksymtab_yield_to = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @yield_to to i32), ptr @__kstrtab_yield_to, ptr @__kstrtabns_yield_to }, section "___ksymtab_gpl+yield_to", align 4
@__kstrtab_io_schedule_timeout = external dso_local constant [0 x i8], align 1
@__kstrtabns_io_schedule_timeout = external dso_local constant [0 x i8], align 1
@__ksymtab_io_schedule_timeout = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @io_schedule_timeout to i32), ptr @__kstrtab_io_schedule_timeout, ptr @__kstrtabns_io_schedule_timeout }, section "___ksymtab+io_schedule_timeout", align 4
@__kstrtab_io_schedule = external dso_local constant [0 x i8], align 1
@__kstrtabns_io_schedule = external dso_local constant [0 x i8], align 1
@__ksymtab_io_schedule = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @io_schedule to i32), ptr @__kstrtab_io_schedule, ptr @__kstrtabns_io_schedule }, section "___ksymtab+io_schedule", align 4
@.str.44 = internal constant { [33 x i8], [63 x i8] } { [33 x i8] c"sys_enter_sched_get_priority_max\00", [63 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_get_priority_max = internal global %struct.syscall_metadata { ptr @.str.46, i32 -1, i32 1, ptr @types__sched_get_priority_max, ptr @args__sched_get_priority_max, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_get_priority_max, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_get_priority_max, i64 20) }, ptr @event_enter__sched_get_priority_max, ptr @event_exit__sched_get_priority_max }, align 4
@event_enter__sched_get_priority_max = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.44 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_get_priority_max, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_get_priority_max = internal global ptr @event_enter__sched_get_priority_max, section "_ftrace_events", align 4
@.str.45 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"sys_exit_sched_get_priority_max\00", [32 x i8] zeroinitializer }, align 32
@event_exit__sched_get_priority_max = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.45 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_get_priority_max, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_get_priority_max = internal global ptr @event_exit__sched_get_priority_max, section "_ftrace_events", align 4
@.str.46 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sys_sched_get_priority_max\00", [37 x i8] zeroinitializer }, align 32
@types__sched_get_priority_max = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.103], [28 x i8] zeroinitializer }, align 32
@args__sched_get_priority_max = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.216], [28 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_get_priority_max = internal global ptr @__syscall_meta__sched_get_priority_max, section "__syscalls_metadata", align 4
@.str.47 = internal constant { [33 x i8], [63 x i8] } { [33 x i8] c"sys_enter_sched_get_priority_min\00", [63 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_get_priority_min = internal global %struct.syscall_metadata { ptr @.str.49, i32 -1, i32 1, ptr @types__sched_get_priority_min, ptr @args__sched_get_priority_min, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_get_priority_min, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_get_priority_min, i64 20) }, ptr @event_enter__sched_get_priority_min, ptr @event_exit__sched_get_priority_min }, align 4
@event_enter__sched_get_priority_min = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.47 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_get_priority_min, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_get_priority_min = internal global ptr @event_enter__sched_get_priority_min, section "_ftrace_events", align 4
@.str.48 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"sys_exit_sched_get_priority_min\00", [32 x i8] zeroinitializer }, align 32
@event_exit__sched_get_priority_min = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.48 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_get_priority_min, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_get_priority_min = internal global ptr @event_exit__sched_get_priority_min, section "_ftrace_events", align 4
@.str.49 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sys_sched_get_priority_min\00", [37 x i8] zeroinitializer }, align 32
@types__sched_get_priority_min = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.103], [28 x i8] zeroinitializer }, align 32
@args__sched_get_priority_min = internal global { [1 x ptr], [28 x i8] } { [1 x ptr] [ptr @.str.216], [28 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_get_priority_min = internal global ptr @__syscall_meta__sched_get_priority_min, section "__syscalls_metadata", align 4
@.str.50 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"sys_enter_sched_rr_get_interval\00", [32 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_rr_get_interval = internal global %struct.syscall_metadata { ptr @.str.52, i32 -1, i32 2, ptr @types__sched_rr_get_interval, ptr @args__sched_rr_get_interval, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_rr_get_interval, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_rr_get_interval, i64 20) }, ptr @event_enter__sched_rr_get_interval, ptr @event_exit__sched_rr_get_interval }, align 4
@event_enter__sched_rr_get_interval = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.50 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_rr_get_interval, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_rr_get_interval = internal global ptr @event_enter__sched_rr_get_interval, section "_ftrace_events", align 4
@.str.51 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"sys_exit_sched_rr_get_interval\00", [33 x i8] zeroinitializer }, align 32
@event_exit__sched_rr_get_interval = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.51 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_rr_get_interval, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_rr_get_interval = internal global ptr @event_exit__sched_rr_get_interval, section "_ftrace_events", align 4
@.str.52 = internal constant { [26 x i8], [38 x i8] } { [26 x i8] c"sys_sched_rr_get_interval\00", [38 x i8] zeroinitializer }, align 32
@types__sched_rr_get_interval = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.100, ptr @.str.230], [24 x i8] zeroinitializer }, align 32
@args__sched_rr_get_interval = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.101, ptr @.str.231], [24 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_rr_get_interval = internal global ptr @__syscall_meta__sched_rr_get_interval, section "__syscalls_metadata", align 4
@.str.53 = internal constant { [39 x i8], [57 x i8] } { [39 x i8] c"sys_enter_sched_rr_get_interval_time32\00", [57 x i8] zeroinitializer }, align 32
@__syscall_meta__sched_rr_get_interval_time32 = internal global %struct.syscall_metadata { ptr @.str.55, i32 -1, i32 2, ptr @types__sched_rr_get_interval_time32, ptr @args__sched_rr_get_interval_time32, %struct.list_head { ptr getelementptr (i8, ptr @__syscall_meta__sched_rr_get_interval_time32, i64 20), ptr getelementptr (i8, ptr @__syscall_meta__sched_rr_get_interval_time32, i64 20) }, ptr @event_enter__sched_rr_get_interval_time32, ptr @event_exit__sched_rr_get_interval_time32 }, align 4
@event_enter__sched_rr_get_interval_time32 = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_enter, %union.anon.97 { ptr @.str.53 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @enter_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_rr_get_interval_time32, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_enter__sched_rr_get_interval_time32 = internal global ptr @event_enter__sched_rr_get_interval_time32, section "_ftrace_events", align 4
@.str.54 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"sys_exit_sched_rr_get_interval_time32\00", [58 x i8] zeroinitializer }, align 32
@event_exit__sched_rr_get_interval_time32 = internal global { %struct.trace_event_call, [52 x i8] } { %struct.trace_event_call { %struct.list_head zeroinitializer, ptr @event_class_syscall_exit, %union.anon.97 { ptr @.str.54 }, %struct.trace_event { %struct.hlist_node zeroinitializer, %struct.list_head zeroinitializer, i32 0, ptr @exit_syscall_print_funcs }, ptr null, ptr null, %union.anon.98 zeroinitializer, ptr @__syscall_meta__sched_rr_get_interval_time32, i32 2, i32 0, ptr null, ptr null, ptr null }, [52 x i8] zeroinitializer }, align 32
@__event_exit__sched_rr_get_interval_time32 = internal global ptr @event_exit__sched_rr_get_interval_time32, section "_ftrace_events", align 4
@.str.55 = internal constant { [33 x i8], [63 x i8] } { [33 x i8] c"sys_sched_rr_get_interval_time32\00", [63 x i8] zeroinitializer }, align 32
@types__sched_rr_get_interval_time32 = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.100, ptr @.str.232], [24 x i8] zeroinitializer }, align 32
@args__sched_rr_get_interval_time32 = internal global { [2 x ptr], [24 x i8] } { [2 x ptr] [ptr @.str.101, ptr @.str.231], [24 x i8] zeroinitializer }, align 32
@__p_syscall_meta__sched_rr_get_interval_time32 = internal global ptr @__syscall_meta__sched_rr_get_interval_time32, section "__syscalls_metadata", align 4
@sched_show_task._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.56, ptr @.str.57, ptr @.str.1, i32 8554, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.56 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"\016task:%-15.15s state:%c\00", [39 x i8] zeroinitializer }, align 32
@.str.57 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"sched_show_task\00", [16 x i8] zeroinitializer }, align 32
@sched_show_task._entry_ptr = internal global ptr @sched_show_task._entry, section ".printk_index", align 4
@sched_show_task._entry.58 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.59, ptr @.str.57, ptr @.str.1, i32 8557, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.59 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"\01c  running task    \00", [43 x i8] zeroinitializer }, align 32
@sched_show_task._entry_ptr.60 = internal global ptr @sched_show_task._entry.58, section ".printk_index", align 4
@sched_show_task.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@sched_show_task._entry.61 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.62, ptr @.str.57, ptr @.str.1, i32 8568, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.62 = internal constant { [46 x i8], [50 x i8] } { [46 x i8] c"\01c stack:%5lu pid:%5d ppid:%6d flags:0x%08lx\0A\00", [50 x i8] zeroinitializer }, align 32
@sched_show_task._entry_ptr.63 = internal global ptr @sched_show_task._entry.61, section ".printk_index", align 4
@.str.64 = internal constant { [3 x i8], [29 x i8] } { [3 x i8] c"\016\00", [29 x i8] zeroinitializer }, align 32
@__kstrtab_sched_show_task = external dso_local constant [0 x i8], align 1
@__kstrtabns_sched_show_task = external dso_local constant [0 x i8], align 1
@__ksymtab_sched_show_task = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @sched_show_task to i32), ptr @__kstrtab_sched_show_task, ptr @__kstrtabns_sched_show_task }, section "___ksymtab_gpl+sched_show_task", align 4
@init_task = external dso_local global %struct.task_struct, align 128
@show_state_filter.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@idle_sched_class = external dso_local constant %struct.sched_class, align 4
@.str.65 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"%s/%d\00", [26 x i8] zeroinitializer }, align 32
@.str.66 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"swapper\00", [24 x i8] zeroinitializer }, align 32
@init_mm = external dso_local global %struct.mm_struct, align 8
@__end_sched_classes = external dso_local global [0 x %struct.sched_class], align 4
@__begin_sched_classes = external dso_local global [0 x %struct.sched_class], align 4
@sched_smt_present = external dso_local global %struct.static_key_false, align 4
@sched_smp_initialized = dso_local local_unnamed_addr global i8 0, section ".data..read_mostly", align 1
@.str.67 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"Dying CPU not properly vacated!\00", [32 x i8] zeroinitializer }, align 32
@.str.68 = internal constant { [3 x i8], [29 x i8] } { [3 x i8] c"\014\00", [29 x i8] zeroinitializer }, align 32
@__initcall__kmod_core__743_9268_migration_initearly = internal global ptr @migration_init, section ".initcallearly.init", align 4
@__sched_text_start = external dso_local global [0 x i8], align 1
@__sched_text_end = external dso_local global [0 x i8], align 1
@task_groups = dso_local global { %struct.list_head, [24 x i8] } { %struct.list_head { ptr @task_groups, ptr @task_groups }, [24 x i8] zeroinitializer }, align 32
@dl_sched_class = external dso_local constant %struct.sched_class, align 4
@root_task_group = dso_local global %struct.task_group zeroinitializer, align 128
@load_balance_mask = external dso_local global ptr, section ".data..percpu", align 4
@select_idle_mask = external dso_local global ptr, section ".data..percpu", align 4
@def_rt_bandwidth = external dso_local global %struct.rt_bandwidth, align 8
@def_dl_bandwidth = external dso_local global %struct.dl_bandwidth, align 8
@.str.69 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"task_group\00", [21 x i8] zeroinitializer }, align 32
@task_group_cache = internal unnamed_addr global ptr null, section ".data..read_mostly", align 4
@sched_init.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.70 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"&rq->__lock\00", [20 x i8] zeroinitializer }, align 32
@jiffies = external dso_local global i32, section ".data..cacheline_aligned", align 128
@sysctl_sched_migration_cost = external dso_local local_unnamed_addr global i32, section ".data..read_mostly", align 4
@def_root_domain = external dso_local global %struct.root_domain, align 8
@calc_load_update = external dso_local local_unnamed_addr global i32, align 4
@scheduler_running = dso_local local_unnamed_addr global i32 0, section ".data..read_mostly", align 4
@__might_sleep.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.71 = internal constant { [73 x i8], [55 x i8] } { [73 x i8] c"do not call blocking ops when !TASK_RUNNING; state=%x set at [<%p>] %pS\0A\00", [55 x i8] zeroinitializer }, align 32
@__kstrtab___might_sleep = external dso_local constant [0 x i8], align 1
@__kstrtabns___might_sleep = external dso_local constant [0 x i8], align 1
@__ksymtab___might_sleep = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__might_sleep to i32), ptr @__kstrtab___might_sleep, ptr @__kstrtabns___might_sleep }, section "___ksymtab+__might_sleep", align 4
@__might_resched.prev_jiffy = internal unnamed_addr global i32 0, align 4
@__might_resched.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@rcu_bh_lock_map = external dso_local global %struct.lockdep_map, align 4
@.str.72 = internal constant { [60 x i8], [36 x i8] } { [60 x i8] c"Illegal context switch in RCU-bh read-side critical section\00", [36 x i8] zeroinitializer }, align 32
@__might_resched.__warned.73 = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@rcu_sched_lock_map = external dso_local global %struct.lockdep_map, align 4
@.str.74 = internal constant { [63 x i8], [33 x i8] } { [63 x i8] c"Illegal context switch in RCU-sched read-side critical section\00", [33 x i8] zeroinitializer }, align 32
@system_state = external dso_local local_unnamed_addr global i32, align 4
@oops_in_progress = external dso_local local_unnamed_addr global i32, align 4
@__might_resched._entry = internal constant %struct.pi_entry { ptr @.str.75, ptr @.str.76, ptr @.str.1, i32 9563, ptr null, ptr null }, align 1
@.str.75 = internal constant { [63 x i8], [33 x i8] } { [63 x i8] c"\013BUG: sleeping function called from invalid context at %s:%d\0A\00", [33 x i8] zeroinitializer }, align 32
@.str.76 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"__might_resched\00", [16 x i8] zeroinitializer }, align 32
@__might_resched._entry_ptr = internal global ptr @__might_resched._entry, section ".printk_index", align 4
@__might_resched._entry.77 = internal constant %struct.pi_entry { ptr @.str.78, ptr @.str.76, ptr @.str.1, i32 9566, ptr null, ptr null }, align 1
@.str.78 = internal constant { [74 x i8], [54 x i8] } { [74 x i8] c"\013in_atomic(): %d, irqs_disabled(): %d, non_block: %d, pid: %d, name: %s\0A\00", [54 x i8] zeroinitializer }, align 32
@__might_resched._entry_ptr.79 = internal global ptr @__might_resched._entry.77, section ".printk_index", align 4
@__might_resched._entry.80 = internal constant %struct.pi_entry { ptr @.str.81, ptr @.str.76, ptr @.str.1, i32 9568, ptr null, ptr null }, align 1
@.str.81 = internal constant { [35 x i8], [61 x i8] } { [35 x i8] c"\013preempt_count: %x, expected: %x\0A\00", [61 x i8] zeroinitializer }, align 32
@__might_resched._entry_ptr.82 = internal global ptr @__might_resched._entry.80, section ".printk_index", align 4
@__might_resched._entry.83 = internal constant %struct.pi_entry { ptr @.str.84, ptr @.str.76, ptr @.str.1, i32 9576, ptr null, ptr null }, align 1
@.str.84 = internal constant { [44 x i8], [52 x i8] } { [44 x i8] c"\010Thread overran stack, or stack corrupted\0A\00", [52 x i8] zeroinitializer }, align 32
@__might_resched._entry_ptr.85 = internal global ptr @__might_resched._entry.83, section ".printk_index", align 4
@__kstrtab___might_resched = external dso_local constant [0 x i8], align 1
@__kstrtabns___might_resched = external dso_local constant [0 x i8], align 1
@__ksymtab___might_resched = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__might_resched to i32), ptr @__kstrtab___might_resched, ptr @__kstrtabns___might_resched }, section "___ksymtab+__might_resched", align 4
@__cant_sleep.prev_jiffy = internal unnamed_addr global i32 0, align 4
@__cant_sleep._entry = internal constant %struct.pi_entry { ptr @.str.86, ptr @.str.87, ptr @.str.1, i32 9607, ptr null, ptr null }, align 1
@.str.86 = internal constant { [41 x i8], [55 x i8] } { [41 x i8] c"\013BUG: assuming atomic context at %s:%d\0A\00", [55 x i8] zeroinitializer }, align 32
@.str.87 = internal constant { [13 x i8], [19 x i8] } { [13 x i8] c"__cant_sleep\00", [19 x i8] zeroinitializer }, align 32
@__cant_sleep._entry_ptr = internal global ptr @__cant_sleep._entry, section ".printk_index", align 4
@__cant_sleep._entry.88 = internal constant %struct.pi_entry { ptr @.str.89, ptr @.str.87, ptr @.str.1, i32 9610, ptr null, ptr null }, align 1
@.str.89 = internal constant { [59 x i8], [37 x i8] } { [59 x i8] c"\013in_atomic(): %d, irqs_disabled(): %d, pid: %d, name: %s\0A\00", [37 x i8] zeroinitializer }, align 32
@__cant_sleep._entry_ptr.90 = internal global ptr @__cant_sleep._entry.88, section ".printk_index", align 4
@__kstrtab___cant_sleep = external dso_local constant [0 x i8], align 1
@__kstrtabns___cant_sleep = external dso_local constant [0 x i8], align 1
@__ksymtab___cant_sleep = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cant_sleep to i32), ptr @__kstrtab___cant_sleep, ptr @__kstrtabns___cant_sleep }, section "___ksymtab_gpl+__cant_sleep", align 4
@__cant_migrate.prev_jiffy = internal unnamed_addr global i32 0, align 4
@__cant_migrate._entry = internal constant %struct.pi_entry { ptr @.str.91, ptr @.str.92, ptr @.str.1, i32 9639, ptr null, ptr null }, align 1
@.str.91 = internal constant { [49 x i8], [47 x i8] } { [49 x i8] c"\013BUG: assuming non migratable context at %s:%d\0A\00", [47 x i8] zeroinitializer }, align 32
@.str.92 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"__cant_migrate\00", [17 x i8] zeroinitializer }, align 32
@__cant_migrate._entry_ptr = internal global ptr @__cant_migrate._entry, section ".printk_index", align 4
@__cant_migrate._entry.93 = internal constant %struct.pi_entry { ptr @.str.94, ptr @.str.92, ptr @.str.1, i32 9642, ptr null, ptr null }, align 1
@.str.94 = internal constant { [83 x i8], [45 x i8] } { [83 x i8] c"\013in_atomic(): %d, irqs_disabled(): %d, migration_disabled() %u pid: %d, name: %s\0A\00", [45 x i8] zeroinitializer }, align 32
@__cant_migrate._entry_ptr.95 = internal global ptr @__cant_migrate._entry.93, section ".printk_index", align 4
@__kstrtab___cant_migrate = external dso_local constant [0 x i8], align 1
@__kstrtabns___cant_migrate = external dso_local constant [0 x i8], align 1
@__ksymtab___cant_migrate = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @__cant_migrate to i32), ptr @__kstrtab___cant_migrate, ptr @__kstrtabns___cant_migrate }, section "___ksymtab_gpl+__cant_migrate", align 4
@tasklist_lock = external dso_local global %struct.rwlock_t, align 4
@normalize_rt_tasks.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@task_group_lock = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.6 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.244, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@max_cfs_quota_period = dso_local constant { i64, [24 x i8] } { i64 1000000000, [24 x i8] zeroinitializer }, align 32
@cpu_files = internal global { [8 x %struct.cftype], [288 x i8] } { [8 x %struct.cftype] [%struct.cftype { [64 x i8] c"weight\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_weight_read_u64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_weight_write_u64, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"weight.nice\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr @cpu_weight_nice_read_s64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_weight_nice_write_s64, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"idle\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr @cpu_idle_read_s64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_idle_write_s64, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"max\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_max_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_max_write, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"max.burst\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_cfs_burst_read_u64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_burst_write_u64, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"uclamp.min\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_min_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_min_write, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"uclamp.max\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_max_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_max_write, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype zeroinitializer], [288 x i8] zeroinitializer }, align 32
@cpu_legacy_files = internal global { [11 x %struct.cftype], [440 x i8] } { [11 x %struct.cftype] [%struct.cftype { [64 x i8] c"shares\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_shares_read_u64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_shares_write_u64, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"idle\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr @cpu_idle_read_s64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_idle_write_s64, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"cfs_quota_us\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_quota_read_s64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_quota_write_s64, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"cfs_period_us\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_cfs_period_read_u64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_period_write_u64, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"cfs_burst_us\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_cfs_burst_read_u64, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_burst_write_u64, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"stat\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_cfs_stat_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"rt_runtime_us\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr @cpu_rt_runtime_read, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_rt_runtime_write, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"rt_period_us\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 0, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr @cpu_rt_period_read_uint, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_rt_period_write_uint, ptr null, ptr null, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"uclamp.min\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_min_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_min_write, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype { [64 x i8] c"uclamp.max\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", i32 0, i32 0, i32 2, i32 0, ptr null, %struct.list_head zeroinitializer, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_max_show, ptr null, ptr null, ptr null, ptr null, ptr null, ptr @cpu_uclamp_max_write, ptr null, %struct.lock_class_key zeroinitializer }, %struct.cftype zeroinitializer], [440 x i8] zeroinitializer }, align 32
@cpu_cgrp_subsys = dso_local global { %struct.cgroup_subsys, [52 x i8] } { %struct.cgroup_subsys { ptr @cpu_cgroup_css_alloc, ptr @cpu_cgroup_css_online, ptr null, ptr @cpu_cgroup_css_released, ptr @cpu_cgroup_css_free, ptr null, ptr null, ptr @cpu_extra_stat_show, ptr @cpu_cgroup_can_attach, ptr null, ptr @cpu_cgroup_attach, ptr null, ptr null, ptr null, ptr @cpu_cgroup_fork, ptr null, ptr null, ptr null, i8 -96, i32 0, ptr null, ptr null, ptr null, %struct.idr zeroinitializer, %struct.list_head zeroinitializer, ptr @cpu_files, ptr @cpu_legacy_files, i32 0 }, [52 x i8] zeroinitializer }, align 32
@dump_cpu_task._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.96, ptr @.str.97, ptr @.str.1, i32 10879, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.96 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"\016Task dump for CPU %d:\0A\00", [39 x i8] zeroinitializer }, align 32
@.str.97 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"dump_cpu_task\00", [18 x i8] zeroinitializer }, align 32
@dump_cpu_task._entry_ptr = internal global ptr @dump_cpu_task._entry, section ".printk_index", align 4
@sched_prio_to_weight = dso_local constant { [40 x i32], [32 x i8] } { [40 x i32] [i32 88761, i32 71755, i32 56483, i32 46273, i32 36291, i32 29154, i32 23254, i32 18705, i32 14949, i32 11916, i32 9548, i32 7620, i32 6100, i32 4904, i32 3906, i32 3121, i32 2501, i32 1991, i32 1586, i32 1277, i32 1024, i32 820, i32 655, i32 526, i32 423, i32 335, i32 272, i32 215, i32 172, i32 137, i32 110, i32 87, i32 70, i32 56, i32 45, i32 36, i32 29, i32 23, i32 18, i32 15], [32 x i8] zeroinitializer }, align 32
@sched_prio_to_wmult = dso_local constant { [40 x i32], [32 x i8] } { [40 x i32] [i32 48388, i32 59856, i32 76040, i32 92818, i32 118348, i32 147320, i32 184698, i32 229616, i32 287308, i32 360437, i32 449829, i32 563644, i32 704093, i32 875809, i32 1099582, i32 1376151, i32 1717300, i32 2157191, i32 2708050, i32 3363326, i32 4194304, i32 5237765, i32 6557202, i32 8165337, i32 10153587, i32 12820798, i32 15790321, i32 19976592, i32 24970740, i32 31350126, i32 39045157, i32 49367440, i32 61356676, i32 76695844, i32 95443717, i32 119304647, i32 148102320, i32 186737708, i32 238609294, i32 286331153], [32 x i8] zeroinitializer }, align 32
@__pcpu_scope_runqueues = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_unique_runqueues = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_scope_kstat = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_unique_kstat = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_scope_kernel_cpustat = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_unique_kernel_cpustat = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_unique_core_balance_head = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@__pcpu_unique_push_work = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@push_work = weak dso_local global %struct.cpu_stop_work zeroinitializer, section ".data..percpu", align 4
@.str.98 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"char[TASK_COMM_LEN]\00", [44 x i8] zeroinitializer }, align 32
@.str.99 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"comm\00", [27 x i8] zeroinitializer }, align 32
@.str.100 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"pid_t\00", [26 x i8] zeroinitializer }, align 32
@.str.101 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"pid\00", [28 x i8] zeroinitializer }, align 32
@.str.102 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"comm=%s pid=%d\0A\00", [16 x i8] zeroinitializer }, align 32
@.str.103 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"int\00", [28 x i8] zeroinitializer }, align 32
@.str.104 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"ret\00", [28 x i8] zeroinitializer }, align 32
@.str.105 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"ret=%d\0A\00", [24 x i8] zeroinitializer }, align 32
@.str.106 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"void *\00", [25 x i8] zeroinitializer }, align 32
@.str.107 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"work\00", [27 x i8] zeroinitializer }, align 32
@.str.108 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"function\00", [23 x i8] zeroinitializer }, align 32
@.str.109 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"worker\00", [25 x i8] zeroinitializer }, align 32
@.str.110 = internal constant { [39 x i8], [57 x i8] } { [39 x i8] c"work struct=%p function=%ps worker=%p\0A\00", [57 x i8] zeroinitializer }, align 32
@.str.111 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"work struct %p: function %ps\0A\00", [34 x i8] zeroinitializer }, align 32
@.str.112 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"prio\00", [27 x i8] zeroinitializer }, align 32
@.str.113 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"target_cpu\00", [21 x i8] zeroinitializer }, align 32
@.str.114 = internal constant { [40 x i8], [56 x i8] } { [40 x i8] c"comm=%s pid=%d prio=%d target_cpu=%03d\0A\00", [56 x i8] zeroinitializer }, align 32
@.str.115 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"prev_comm\00", [22 x i8] zeroinitializer }, align 32
@.str.116 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"prev_pid\00", [23 x i8] zeroinitializer }, align 32
@.str.117 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"prev_prio\00", [22 x i8] zeroinitializer }, align 32
@.str.118 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"long\00", [27 x i8] zeroinitializer }, align 32
@.str.119 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"prev_state\00", [21 x i8] zeroinitializer }, align 32
@.str.120 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"next_comm\00", [22 x i8] zeroinitializer }, align 32
@.str.121 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"next_pid\00", [23 x i8] zeroinitializer }, align 32
@.str.122 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"next_prio\00", [22 x i8] zeroinitializer }, align 32
@.str.123 = internal constant { [97 x i8], [63 x i8] } { [97 x i8] c"prev_comm=%s prev_pid=%d prev_prio=%d prev_state=%s%s ==> next_comm=%s next_pid=%d next_prio=%d\0A\00", [63 x i8] zeroinitializer }, align 32
@trace_raw_output_sched_switch.__flags = internal constant { [9 x %struct.trace_print_flags], [56 x i8] } { [9 x %struct.trace_print_flags] [%struct.trace_print_flags { i32 1, ptr @.str.124 }, %struct.trace_print_flags { i32 2, ptr @.str.125 }, %struct.trace_print_flags { i32 4, ptr @.str.126 }, %struct.trace_print_flags { i32 8, ptr @.str.127 }, %struct.trace_print_flags { i32 16, ptr @.str.128 }, %struct.trace_print_flags { i32 32, ptr @.str.129 }, %struct.trace_print_flags { i32 64, ptr @.str.130 }, %struct.trace_print_flags { i32 128, ptr @.str.131 }, %struct.trace_print_flags { i32 -1, ptr null }], [56 x i8] zeroinitializer }, align 32
@.str.124 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"S\00", [30 x i8] zeroinitializer }, align 32
@.str.125 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"D\00", [30 x i8] zeroinitializer }, align 32
@.str.126 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"T\00", [30 x i8] zeroinitializer }, align 32
@.str.127 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"t\00", [30 x i8] zeroinitializer }, align 32
@.str.128 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"X\00", [30 x i8] zeroinitializer }, align 32
@.str.129 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"Z\00", [30 x i8] zeroinitializer }, align 32
@.str.130 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"P\00", [30 x i8] zeroinitializer }, align 32
@.str.131 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"I\00", [30 x i8] zeroinitializer }, align 32
@.str.132 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"|\00", [30 x i8] zeroinitializer }, align 32
@.str.133 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"R\00", [30 x i8] zeroinitializer }, align 32
@.str.134 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"+\00", [30 x i8] zeroinitializer }, align 32
@.str.135 = internal constant { [1 x i8], [31 x i8] } zeroinitializer, align 32
@.str.136 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"orig_cpu\00", [23 x i8] zeroinitializer }, align 32
@.str.137 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"dest_cpu\00", [23 x i8] zeroinitializer }, align 32
@.str.138 = internal constant { [48 x i8], [48 x i8] } { [48 x i8] c"comm=%s pid=%d prio=%d orig_cpu=%d dest_cpu=%d\0A\00", [48 x i8] zeroinitializer }, align 32
@.str.139 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"comm=%s pid=%d prio=%d\0A\00", [40 x i8] zeroinitializer }, align 32
@.str.140 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"parent_comm\00", [20 x i8] zeroinitializer }, align 32
@.str.141 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"parent_pid\00", [21 x i8] zeroinitializer }, align 32
@.str.142 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"child_comm\00", [21 x i8] zeroinitializer }, align 32
@.str.143 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"child_pid\00", [22 x i8] zeroinitializer }, align 32
@.str.144 = internal constant { [43 x i8], [53 x i8] } { [43 x i8] c"comm=%s pid=%d child_comm=%s child_pid=%d\0A\00", [53 x i8] zeroinitializer }, align 32
@.str.145 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"(null)\00", [25 x i8] zeroinitializer }, align 32
@.str.146 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"__data_loc char[]\00", [46 x i8] zeroinitializer }, align 32
@.str.147 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"filename\00", [23 x i8] zeroinitializer }, align 32
@.str.148 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"old_pid\00", [24 x i8] zeroinitializer }, align 32
@.str.149 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"filename=%s pid=%d old_pid=%d\0A\00", [33 x i8] zeroinitializer }, align 32
@.str.150 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"u64\00", [28 x i8] zeroinitializer }, align 32
@.str.151 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"delay\00", [26 x i8] zeroinitializer }, align 32
@.str.152 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"comm=%s pid=%d delay=%Lu [ns]\0A\00", [33 x i8] zeroinitializer }, align 32
@.str.153 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"runtime\00", [24 x i8] zeroinitializer }, align 32
@.str.154 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"vruntime\00", [23 x i8] zeroinitializer }, align 32
@.str.155 = internal constant { [51 x i8], [45 x i8] } { [51 x i8] c"comm=%s pid=%d runtime=%Lu [ns] vruntime=%Lu [ns]\0A\00", [45 x i8] zeroinitializer }, align 32
@.str.156 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"oldprio\00", [24 x i8] zeroinitializer }, align 32
@.str.157 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"newprio\00", [24 x i8] zeroinitializer }, align 32
@.str.158 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"comm=%s pid=%d oldprio=%d newprio=%d\0A\00", [58 x i8] zeroinitializer }, align 32
@.str.159 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"tgid\00", [27 x i8] zeroinitializer }, align 32
@.str.160 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"ngid\00", [27 x i8] zeroinitializer }, align 32
@.str.161 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"src_cpu\00", [24 x i8] zeroinitializer }, align 32
@.str.162 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"src_nid\00", [24 x i8] zeroinitializer }, align 32
@.str.163 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"dst_cpu\00", [24 x i8] zeroinitializer }, align 32
@.str.164 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"dst_nid\00", [24 x i8] zeroinitializer }, align 32
@.str.165 = internal constant { [68 x i8], [60 x i8] } { [68 x i8] c"pid=%d tgid=%d ngid=%d src_cpu=%d src_nid=%d dst_cpu=%d dst_nid=%d\0A\00", [60 x i8] zeroinitializer }, align 32
@.str.166 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"src_pid\00", [24 x i8] zeroinitializer }, align 32
@.str.167 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"src_tgid\00", [23 x i8] zeroinitializer }, align 32
@.str.168 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"src_ngid\00", [23 x i8] zeroinitializer }, align 32
@.str.169 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"dst_pid\00", [24 x i8] zeroinitializer }, align 32
@.str.170 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"dst_tgid\00", [23 x i8] zeroinitializer }, align 32
@.str.171 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"dst_ngid\00", [23 x i8] zeroinitializer }, align 32
@.str.172 = internal constant { [115 x i8], [45 x i8] } { [115 x i8] c"src_pid=%d src_tgid=%d src_ngid=%d src_cpu=%d src_nid=%d dst_pid=%d dst_tgid=%d dst_ngid=%d dst_cpu=%d dst_nid=%d\0A\00", [45 x i8] zeroinitializer }, align 32
@.str.173 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"cpu\00", [28 x i8] zeroinitializer }, align 32
@.str.174 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"cpu=%d\0A\00", [24 x i8] zeroinitializer }, align 32
@.str.175 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sched_core_mutex.wait_lock\00", [37 x i8] zeroinitializer }, align 32
@.str.176 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"sched_core_mutex\00", [47 x i8] zeroinitializer }, align 32
@sched_core_mask = internal global { %struct.cpumask, [28 x i8] } zeroinitializer, align 32
@sched_core_assert_empty.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@system_wq = external dso_local local_unnamed_addr global ptr, align 4
@rq_pin_lock.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.177 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"kernel/sched/sched.h\00", [43 x i8] zeroinitializer }, align 32
@.str.178 = internal constant { [71 x i8], [57 x i8] } { [71 x i8] c"rq->balance_callback && rq->balance_callback != &balance_push_callback\00", [57 x i8] zeroinitializer }, align 32
@paravirt_steal_rq_enabled = external dso_local global %struct.static_key, align 4
@cpu_irqtime = external dso_local global %struct.irqtime, section ".data..percpu", align 8
@__SCK__pv_steal_clock = external dso_local local_unnamed_addr global %struct.static_call_key, align 4
@assert_clock_updated.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.179 = internal constant { [39 x i8], [57 x i8] } { [39 x i8] c"rq->clock_update_flags < RQCF_ACT_SKIP\00", [57 x i8] zeroinitializer }, align 32
@cpu_scale = external dso_local global i32, section ".data..percpu", align 4
@.str.180 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"include/trace/events/sched.h\00", [35 x i8] zeroinitializer }, align 32
@housekeeping_overridden = external dso_local global %struct.static_key_false, align 4
@rcu_lock_map = external dso_local global %struct.lockdep_map, align 4
@rcu_read_lock.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.181 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"include/linux/rcupdate.h\00", [39 x i8] zeroinitializer }, align 32
@.str.182 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"rcu_read_lock() used illegally while idle\00", [54 x i8] zeroinitializer }, align 32
@rcu_read_unlock.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.183 = internal constant { [44 x i8], [52 x i8] } { [44 x i8] c"rcu_read_unlock() used illegally while idle\00", [52 x i8] zeroinitializer }, align 32
@.str.184 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"uclamp_mutex.wait_lock\00", [41 x i8] zeroinitializer }, align 32
@.str.185 = internal constant { [13 x i8], [19 x i8] } { [13 x i8] c"uclamp_mutex\00", [19 x i8] zeroinitializer }, align 32
@cpu_util_update_eff.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.186 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"!rcu_read_lock_held()\00", [42 x i8] zeroinitializer }, align 32
@uclamp_rq_dec_id.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.187 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"!bucket->tasks\00", [17 x i8] zeroinitializer }, align 32
@uclamp_rq_dec_id.__already_done.188 = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.189 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"bucket->value > rq_clamp\00", [39 x i8] zeroinitializer }, align 32
@uclamp_sync_util_min_rt_default.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@psi_disabled = external dso_local global %struct.static_key_false, align 4
@__do_set_cpus_allowed.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.190 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"!p->on_cpu\00", [21 x i8] zeroinitializer }, align 32
@__set_cpus_allowed_ptr_locked.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@affine_move_task.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@affine_move_task.__already_done.191 = internal unnamed_addr global i1 false, section ".data.once", align 1
@init_completion.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.192 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&x->wait\00", [23 x i8] zeroinitializer }, align 32
@trace_sched_migrate_task.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@perf_swevent_enabled = external dso_local global [12 x %struct.static_key], align 4
@trace_sched_wait_task.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@delayacct_key = external dso_local global %struct.static_key_false, align 4
@trace_sched_wakeup.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@trace_sched_waking.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@ttwu_queue_wakelist.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@ttwu_stat.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.193 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"enable\00", [25 x i8] zeroinitializer }, align 32
@.str.194 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"disable\00", [24 x i8] zeroinitializer }, align 32
@setup_schedstats._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.195, ptr @.str.196, ptr @.str.1, i32 4348, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.195 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"\014Unable to parse schedstats=\0A\00", [33 x i8] zeroinitializer }, align 32
@.str.196 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"setup_schedstats\00", [47 x i8] zeroinitializer }, align 32
@setup_schedstats._entry_ptr = internal global ptr @setup_schedstats._entry, section ".printk_index", align 4
@sched_rr_timeslice = external dso_local local_unnamed_addr global i32, align 4
@sysctl_sched_autogroup_enabled = external dso_local global i32, align 4
@__cpu_dying_mask = external dso_local global %struct.cpumask, align 4
@__func__.select_fallback_rq = private unnamed_addr constant [19 x i8] c"select_fallback_rq\00", align 1
@select_fallback_rq._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.197, ptr @__func__.select_fallback_rq, ptr @.str.1, i32 3417, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.197 = internal constant { [43 x i8], [53 x i8] } { [43 x i8] c"process %d (%s) no longer affine to cpu%d\0A\00", [53 x i8] zeroinitializer }, align 32
@select_fallback_rq._entry_ptr = internal global ptr @select_fallback_rq._entry, section ".printk_index", align 4
@trace_sched_wakeup_new.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@finish_task_switch.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.198 = internal constant { [37 x i8], [59 x i8] } { [37 x i8] c"corrupted preempt_count: %s/%d/0x%x\0A\00", [59 x i8] zeroinitializer }, align 32
@perf_sched_events = external dso_local global %struct.static_key_false, align 4
@__perf_regs = external dso_local global [4 x %struct.pt_regs], section ".data..percpu", align 4
@migration_cpu_stop.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@migration_cpu_stop.__already_done.199 = internal unnamed_addr global i1 false, section ".data.once", align 1
@setup_resched_latency_warn_ms._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.200, ptr @.str.201, ptr @.str.1, i32 5233, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.200 = internal constant { [41 x i8], [55 x i8] } { [41 x i8] c"\014Unable to set resched_latency_warn_ms\0A\00", [55 x i8] zeroinitializer }, align 32
@.str.201 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"setup_resched_latency_warn_ms\00", [34 x i8] zeroinitializer }, align 32
@setup_resched_latency_warn_ms._entry_ptr = internal global ptr @setup_resched_latency_warn_ms._entry, section ".printk_index", align 4
@thermal_pressure = external dso_local global i32, section ".data..percpu", align 4
@sched_thermal_decay_shift = external dso_local local_unnamed_addr global i32, align 4
@cpu_resched_latency.warned_once = internal global { i1, [31 x i8] } zeroinitializer, align 32
@sched_core_balance.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.202 = internal constant { [47 x i8], [49 x i8] } { [47 x i8] c"corrupted stack end detected inside scheduler\0A\00", [49 x i8] zeroinitializer }, align 32
@schedule_debug._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.204, ptr @.str.205, ptr @.str.1, i32 5559, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.204 = internal constant { [55 x i8], [41 x i8] } { [55 x i8] c"\013BUG: scheduling in a non-blocking section: %s/%d/%i\0A\00", [41 x i8] zeroinitializer }, align 32
@.str.205 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"schedule_debug\00", [17 x i8] zeroinitializer }, align 32
@schedule_debug._entry_ptr = internal global ptr @schedule_debug._entry, section ".printk_index", align 4
@schedule_debug.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@schedule_debug.__warned.206 = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@__schedule_bug._entry = internal constant %struct.pi_entry { ptr @.str.208, ptr @.str.209, ptr @.str.1, i32 5525, ptr null, ptr null }, align 1
@.str.208 = internal constant { [46 x i8], [50 x i8] } { [46 x i8] c"\013BUG: scheduling while atomic: %s/%d/0x%08x\0A\00", [50 x i8] zeroinitializer }, align 32
@.str.209 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"__schedule_bug\00", [17 x i8] zeroinitializer }, align 32
@__schedule_bug._entry_ptr = internal global ptr @__schedule_bug._entry, section ".printk_index", align 4
@panic_on_warn = external dso_local local_unnamed_addr global i32, align 4
@.str.210 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"scheduling while atomic\0A\00", [39 x i8] zeroinitializer }, align 32
@prof_on = external dso_local local_unnamed_addr global i32, section ".data..read_mostly", align 4
@pick_next_task.__already_done.211 = internal unnamed_addr global i1 false, section ".data.once", align 1
@pick_next_task.__already_done.212 = internal unnamed_addr global i1 false, section ".data.once", align 1
@trace_sched_switch.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@cgroup_mutex = external dso_local global %struct.mutex, align 4
@css_set_lock = external dso_local global %struct.spinlock, align 4
@trace_sched_pi_setprio.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@put_prev_task.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.214 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"increment\00", [22 x i8] zeroinitializer }, align 32
@.str.215 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"struct sched_param *\00", [43 x i8] zeroinitializer }, align 32
@.str.216 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"policy\00", [25 x i8] zeroinitializer }, align 32
@.str.217 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"param\00", [26 x i8] zeroinitializer }, align 32
@.str.218 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"include/linux/thread_info.h\00", [36 x i8] zeroinitializer }, align 32
@.str.219 = internal constant { [38 x i8], [58 x i8] } { [38 x i8] c"Buffer overflow detected (%d < %lu)!\0A\00", [58 x i8] zeroinitializer }, align 32
@.str.220 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"include/linux/uaccess.h\00", [40 x i8] zeroinitializer }, align 32
@.str.221 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"struct sched_attr *\00", [44 x i8] zeroinitializer }, align 32
@.str.222 = internal constant { [13 x i8], [19 x i8] } { [13 x i8] c"unsigned int\00", [19 x i8] zeroinitializer }, align 32
@.str.223 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"uattr\00", [26 x i8] zeroinitializer }, align 32
@.str.224 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"flags\00", [26 x i8] zeroinitializer }, align 32
@.str.225 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"usize\00", [26 x i8] zeroinitializer }, align 32
@check_same_owner.__warned.226 = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.227 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"unsigned long *\00", [16 x i8] zeroinitializer }, align 32
@.str.228 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"len\00", [28 x i8] zeroinitializer }, align 32
@.str.229 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"user_mask_ptr\00", [18 x i8] zeroinitializer }, align 32
@.str.230 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"struct __kernel_timespec *\00", [37 x i8] zeroinitializer }, align 32
@.str.231 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"interval\00", [23 x i8] zeroinitializer }, align 32
@.str.232 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"struct old_timespec32 *\00", [40 x i8] zeroinitializer }, align 32
@task_index_to_char.state_char = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"RSDTtXZPI\00", [22 x i8] zeroinitializer }, align 32
@cpu_bit_bitmap = external dso_local constant [33 x [1 x i32]], align 4
@smp_on_up = external dso_local local_unnamed_addr global i32, align 4
@cpu_cache = external dso_local local_unnamed_addr global %struct.cpu_cache_fns, align 4
@cpu_max_bits_warn.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@.str.233 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"include/linux/cpumask.h\00", [40 x i8] zeroinitializer }, align 32
@balance_push_set.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@cpu_topology = external dso_local global [4 x %struct.cpu_topology], align 4
@cpuhp_tasks_frozen = external dso_local local_unnamed_addr global i8, align 1
@num_cpus_frozen = internal global { i32, [28 x i8] } zeroinitializer, align 32
@sched_core_cpu_deactivate.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@sched_core_cpu_deactivate.__already_done.234 = internal unnamed_addr global i1 false, section ".data.once", align 1
@sched_core_cpu_starting.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@sched_core_cpu_starting.__already_done.235 = internal unnamed_addr global i1 false, section ".data.once", align 1
@sched_core_cpu_starting.__already_done.236 = internal unnamed_addr global i1 false, section ".data.once", align 1
@dump_rq_tasks._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.238, ptr @.str.239, ptr @.str.1, i32 9203, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.238 = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"%sCPU%d enqueued tasks (%u total):\0A\00", [60 x i8] zeroinitializer }, align 32
@.str.239 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"dump_rq_tasks\00", [18 x i8] zeroinitializer }, align 32
@dump_rq_tasks._entry_ptr = internal global ptr @dump_rq_tasks._entry, section ".printk_index", align 4
@dump_rq_tasks.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@dump_rq_tasks._entry.240 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.241, ptr @.str.239, ptr @.str.1, i32 9211, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.241 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"%s\09pid: %d, name: %s\0A\00", [42 x i8] zeroinitializer }, align 32
@dump_rq_tasks._entry_ptr.242 = internal global ptr @dump_rq_tasks._entry.240, section ".printk_index", align 4
@calc_load_tasks = external dso_local global %struct.atomic_t, align 4
@hrtick.__already_done = internal unnamed_addr global i1 false, section ".data.once", align 1
@rcu_preempt_sleep_check.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.243 = internal constant { [57 x i8], [39 x i8] } { [57 x i8] c"Illegal context switch in RCU read-side critical section\00", [39 x i8] zeroinitializer }, align 32
@.str.244 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"task_group_lock\00", [16 x i8] zeroinitializer }, align 32
@.str.245 = internal constant { [80 x i8], [48 x i8] } { [80 x i8] c"nr_periods %d\0Anr_throttled %d\0Athrottled_usec %llu\0Anr_bursts %d\0Aburst_usec %llu\0A\00", [48 x i8] zeroinitializer }, align 32
@.str.246 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"max\00", [28 x i8] zeroinitializer }, align 32
@.str.247 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"%ld\00", [28 x i8] zeroinitializer }, align 32
@.str.248 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c" %ld\0A\00", [26 x i8] zeroinitializer }, align 32
@.str.249 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"%20s %llu\00", [22 x i8] zeroinitializer }, align 32
@.str.250 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"%llu\00", [27 x i8] zeroinitializer }, align 32
@cfs_constraints_mutex = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.251, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @cfs_constraints_mutex, i64 52), ptr getelementptr (i8, ptr @cfs_constraints_mutex, i64 52) }, ptr @cfs_constraints_mutex, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.252, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@.str.251 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"cfs_constraints_mutex.wait_lock\00", [32 x i8] zeroinitializer }, align 32
@.str.252 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"cfs_constraints_mutex\00", [42 x i8] zeroinitializer }, align 32
@cpu_cgrp_subsys_on_dfl_key = external dso_local global %struct.static_key_true, align 4
@.str.253 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"max\0A\00", [27 x i8] zeroinitializer }, align 32
@.str.254 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"%llu.%0*u\0A\00", [21 x i8] zeroinitializer }, align 32
@__const.capacity_from_percent.req = private unnamed_addr constant { i64, i64, i32, [4 x i8] } { i64 10000, i64 1024, i32 0, [4 x i8] zeroinitializer }, align 8
@.str.255 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"nr_periods %d\0A\00", [17 x i8] zeroinitializer }, align 32
@.str.256 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"nr_throttled %d\0A\00", [47 x i8] zeroinitializer }, align 32
@.str.257 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"throttled_time %llu\0A\00", [43 x i8] zeroinitializer }, align 32
@.str.258 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"wait_sum %llu\0A\00", [17 x i8] zeroinitializer }, align 32
@.str.259 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"nr_bursts %d\0A\00", [18 x i8] zeroinitializer }, align 32
@.str.260 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"burst_time %llu\0A\00", [47 x i8] zeroinitializer }, align 32
@trace_sched_update_nr_running_tp.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@switch.table.__se_sys_sched_get_priority_max = internal constant { [7 x i32], [36 x i8] } { [7 x i32] [i32 0, i32 99, i32 99, i32 0, i32 -22, i32 0, i32 0], [36 x i8] zeroinitializer }, align 32
@switch.table.__se_sys_sched_get_priority_min = internal constant { [7 x i32], [36 x i8] } { [7 x i32] [i32 0, i32 1, i32 1, i32 0, i32 -22, i32 0, i32 0], [36 x i8] zeroinitializer }, align 32
@___asan_gen_.262 = private unnamed_addr constant [30 x i8] c"str__sched__trace_system_name\00", align 1
@___asan_gen_.263 = private unnamed_addr constant [32 x i8] c"../include/trace/trace_events.h\00", align 1
@___asan_gen_.264 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.263, i32 36, i32 1 }
@___asan_gen_.265 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_kthread_stop\00", align 1
@___asan_gen_.268 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_kthread_stop\00", align 1
@___asan_gen_.271 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_kthread_stop\00", align 1
@___asan_gen_.274 = private unnamed_addr constant [25 x i8] c"event_sched_kthread_stop\00", align 1
@___asan_gen_.277 = private unnamed_addr constant [42 x i8] c"trace_event_fields_sched_kthread_stop_ret\00", align 1
@___asan_gen_.280 = private unnamed_addr constant [46 x i8] c"trace_event_type_funcs_sched_kthread_stop_ret\00", align 1
@___asan_gen_.283 = private unnamed_addr constant [33 x i8] c"print_fmt_sched_kthread_stop_ret\00", align 1
@___asan_gen_.286 = private unnamed_addr constant [29 x i8] c"event_sched_kthread_stop_ret\00", align 1
@___asan_gen_.289 = private unnamed_addr constant [49 x i8] c"trace_event_fields_sched_kthread_work_queue_work\00", align 1
@___asan_gen_.292 = private unnamed_addr constant [53 x i8] c"trace_event_type_funcs_sched_kthread_work_queue_work\00", align 1
@___asan_gen_.295 = private unnamed_addr constant [40 x i8] c"print_fmt_sched_kthread_work_queue_work\00", align 1
@___asan_gen_.298 = private unnamed_addr constant [36 x i8] c"event_sched_kthread_work_queue_work\00", align 1
@___asan_gen_.301 = private unnamed_addr constant [52 x i8] c"trace_event_fields_sched_kthread_work_execute_start\00", align 1
@___asan_gen_.304 = private unnamed_addr constant [56 x i8] c"trace_event_type_funcs_sched_kthread_work_execute_start\00", align 1
@___asan_gen_.307 = private unnamed_addr constant [43 x i8] c"print_fmt_sched_kthread_work_execute_start\00", align 1
@___asan_gen_.310 = private unnamed_addr constant [39 x i8] c"event_sched_kthread_work_execute_start\00", align 1
@___asan_gen_.313 = private unnamed_addr constant [50 x i8] c"trace_event_fields_sched_kthread_work_execute_end\00", align 1
@___asan_gen_.316 = private unnamed_addr constant [54 x i8] c"trace_event_type_funcs_sched_kthread_work_execute_end\00", align 1
@___asan_gen_.319 = private unnamed_addr constant [41 x i8] c"print_fmt_sched_kthread_work_execute_end\00", align 1
@___asan_gen_.322 = private unnamed_addr constant [37 x i8] c"event_sched_kthread_work_execute_end\00", align 1
@___asan_gen_.324 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 119, i32 1 }
@___asan_gen_.325 = private unnamed_addr constant [41 x i8] c"trace_event_fields_sched_wakeup_template\00", align 1
@___asan_gen_.328 = private unnamed_addr constant [45 x i8] c"trace_event_type_funcs_sched_wakeup_template\00", align 1
@___asan_gen_.331 = private unnamed_addr constant [32 x i8] c"print_fmt_sched_wakeup_template\00", align 1
@___asan_gen_.334 = private unnamed_addr constant [19 x i8] c"event_sched_waking\00", align 1
@___asan_gen_.336 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 170, i32 1 }
@___asan_gen_.337 = private unnamed_addr constant [19 x i8] c"event_sched_wakeup\00", align 1
@___asan_gen_.339 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 178, i32 1 }
@___asan_gen_.340 = private unnamed_addr constant [23 x i8] c"event_sched_wakeup_new\00", align 1
@___asan_gen_.342 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 185, i32 1 }
@___asan_gen_.343 = private unnamed_addr constant [32 x i8] c"trace_event_fields_sched_switch\00", align 1
@___asan_gen_.346 = private unnamed_addr constant [36 x i8] c"trace_event_type_funcs_sched_switch\00", align 1
@___asan_gen_.349 = private unnamed_addr constant [23 x i8] c"print_fmt_sched_switch\00", align 1
@___asan_gen_.352 = private unnamed_addr constant [19 x i8] c"event_sched_switch\00", align 1
@___asan_gen_.355 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_migrate_task\00", align 1
@___asan_gen_.358 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_migrate_task\00", align 1
@___asan_gen_.361 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_migrate_task\00", align 1
@___asan_gen_.364 = private unnamed_addr constant [25 x i8] c"event_sched_migrate_task\00", align 1
@___asan_gen_.367 = private unnamed_addr constant [42 x i8] c"trace_event_fields_sched_process_template\00", align 1
@___asan_gen_.370 = private unnamed_addr constant [46 x i8] c"trace_event_type_funcs_sched_process_template\00", align 1
@___asan_gen_.373 = private unnamed_addr constant [33 x i8] c"print_fmt_sched_process_template\00", align 1
@___asan_gen_.376 = private unnamed_addr constant [25 x i8] c"event_sched_process_free\00", align 1
@___asan_gen_.378 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 323, i32 1 }
@___asan_gen_.379 = private unnamed_addr constant [25 x i8] c"event_sched_process_exit\00", align 1
@___asan_gen_.381 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 330, i32 1 }
@___asan_gen_.382 = private unnamed_addr constant [22 x i8] c"event_sched_wait_task\00", align 1
@___asan_gen_.384 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 337, i32 1 }
@___asan_gen_.385 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_process_wait\00", align 1
@___asan_gen_.388 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_process_wait\00", align 1
@___asan_gen_.391 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_process_wait\00", align 1
@___asan_gen_.394 = private unnamed_addr constant [25 x i8] c"event_sched_process_wait\00", align 1
@___asan_gen_.396 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 344, i32 1 }
@___asan_gen_.397 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_process_fork\00", align 1
@___asan_gen_.400 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_process_fork\00", align 1
@___asan_gen_.403 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_process_fork\00", align 1
@___asan_gen_.406 = private unnamed_addr constant [25 x i8] c"event_sched_process_fork\00", align 1
@___asan_gen_.409 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_process_exec\00", align 1
@___asan_gen_.412 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_process_exec\00", align 1
@___asan_gen_.415 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_process_exec\00", align 1
@___asan_gen_.418 = private unnamed_addr constant [25 x i8] c"event_sched_process_exec\00", align 1
@___asan_gen_.421 = private unnamed_addr constant [39 x i8] c"trace_event_fields_sched_stat_template\00", align 1
@___asan_gen_.424 = private unnamed_addr constant [43 x i8] c"trace_event_type_funcs_sched_stat_template\00", align 1
@___asan_gen_.427 = private unnamed_addr constant [30 x i8] c"print_fmt_sched_stat_template\00", align 1
@___asan_gen_.430 = private unnamed_addr constant [22 x i8] c"event_sched_stat_wait\00", align 1
@___asan_gen_.432 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 460, i32 1 }
@___asan_gen_.433 = private unnamed_addr constant [23 x i8] c"event_sched_stat_sleep\00", align 1
@___asan_gen_.435 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 468, i32 1 }
@___asan_gen_.436 = private unnamed_addr constant [24 x i8] c"event_sched_stat_iowait\00", align 1
@___asan_gen_.438 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 476, i32 1 }
@___asan_gen_.439 = private unnamed_addr constant [25 x i8] c"event_sched_stat_blocked\00", align 1
@___asan_gen_.441 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 483, i32 1 }
@___asan_gen_.442 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_stat_runtime\00", align 1
@___asan_gen_.445 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_stat_runtime\00", align 1
@___asan_gen_.448 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_stat_runtime\00", align 1
@___asan_gen_.451 = private unnamed_addr constant [25 x i8] c"event_sched_stat_runtime\00", align 1
@___asan_gen_.453 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 517, i32 1 }
@___asan_gen_.454 = private unnamed_addr constant [36 x i8] c"trace_event_fields_sched_pi_setprio\00", align 1
@___asan_gen_.457 = private unnamed_addr constant [40 x i8] c"trace_event_type_funcs_sched_pi_setprio\00", align 1
@___asan_gen_.460 = private unnamed_addr constant [27 x i8] c"print_fmt_sched_pi_setprio\00", align 1
@___asan_gen_.463 = private unnamed_addr constant [23 x i8] c"event_sched_pi_setprio\00", align 1
@___asan_gen_.466 = private unnamed_addr constant [38 x i8] c"trace_event_fields_sched_process_hang\00", align 1
@___asan_gen_.469 = private unnamed_addr constant [42 x i8] c"trace_event_type_funcs_sched_process_hang\00", align 1
@___asan_gen_.472 = private unnamed_addr constant [29 x i8] c"print_fmt_sched_process_hang\00", align 1
@___asan_gen_.475 = private unnamed_addr constant [25 x i8] c"event_sched_process_hang\00", align 1
@___asan_gen_.477 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 554, i32 1 }
@___asan_gen_.478 = private unnamed_addr constant [35 x i8] c"trace_event_fields_sched_move_numa\00", align 1
@___asan_gen_.481 = private unnamed_addr constant [39 x i8] c"trace_event_type_funcs_sched_move_numa\00", align 1
@___asan_gen_.484 = private unnamed_addr constant [26 x i8] c"print_fmt_sched_move_numa\00", align 1
@___asan_gen_.487 = private unnamed_addr constant [22 x i8] c"event_sched_move_numa\00", align 1
@___asan_gen_.490 = private unnamed_addr constant [44 x i8] c"trace_event_fields_sched_numa_pair_template\00", align 1
@___asan_gen_.493 = private unnamed_addr constant [48 x i8] c"trace_event_type_funcs_sched_numa_pair_template\00", align 1
@___asan_gen_.496 = private unnamed_addr constant [35 x i8] c"print_fmt_sched_numa_pair_template\00", align 1
@___asan_gen_.499 = private unnamed_addr constant [23 x i8] c"event_sched_stick_numa\00", align 1
@___asan_gen_.501 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 648, i32 1 }
@___asan_gen_.502 = private unnamed_addr constant [22 x i8] c"event_sched_swap_numa\00", align 1
@___asan_gen_.504 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 656, i32 1 }
@___asan_gen_.505 = private unnamed_addr constant [47 x i8] c"trace_event_fields_sched_wake_idle_without_ipi\00", align 1
@___asan_gen_.508 = private unnamed_addr constant [51 x i8] c"trace_event_type_funcs_sched_wake_idle_without_ipi\00", align 1
@___asan_gen_.511 = private unnamed_addr constant [38 x i8] c"print_fmt_sched_wake_idle_without_ipi\00", align 1
@___asan_gen_.514 = private unnamed_addr constant [34 x i8] c"event_sched_wake_idle_without_ipi\00", align 1
@___asan_gen_.517 = private unnamed_addr constant [23 x i8] c"sysctl_sched_rt_period\00", align 1
@___asan_gen_.519 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 87, i32 14 }
@___asan_gen_.520 = private unnamed_addr constant [17 x i8] c"sched_core_count\00", align 1
@___asan_gen_.522 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 249, i32 17 }
@___asan_gen_.523 = private unnamed_addr constant [17 x i8] c"sched_core_mutex\00", align 1
@___asan_gen_.526 = private unnamed_addr constant [6 x i8] c"_work\00", align 1
@___asan_gen_.531 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 361, i32 9 }
@___asan_gen_.532 = private unnamed_addr constant [24 x i8] c"sysctl_sched_rt_runtime\00", align 1
@___asan_gen_.534 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 386, i32 5 }
@___asan_gen_.537 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 542, i32 2 }
@___asan_gen_.540 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 690, i32 3 }
@___asan_gen_.543 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1036, i32 2 }
@___asan_gen_.546 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1192, i32 2 }
@___asan_gen_.547 = private unnamed_addr constant [29 x i8] c"sysctl_sched_uclamp_util_min\00", align 1
@___asan_gen_.549 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1257, i32 14 }
@___asan_gen_.550 = private unnamed_addr constant [29 x i8] c"sysctl_sched_uclamp_util_max\00", align 1
@___asan_gen_.552 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1260, i32 14 }
@___asan_gen_.553 = private unnamed_addr constant [40 x i8] c"sysctl_sched_uclamp_util_min_rt_default\00", align 1
@___asan_gen_.555 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1277, i32 14 }
@___asan_gen_.556 = private unnamed_addr constant [18 x i8] c"sched_uclamp_used\00", align 1
@___asan_gen_.558 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1300, i32 1 }
@___asan_gen_.559 = private unnamed_addr constant [13 x i8] c"uclamp_mutex\00", align 1
@___asan_gen_.562 = private unnamed_addr constant [15 x i8] c"uclamp_default\00", align 1
@___asan_gen_.564 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1280, i32 25 }
@___asan_gen_.570 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 2984, i32 3 }
@___asan_gen_.571 = private unnamed_addr constant [13 x i8] c"stop_pi_lock\00", align 1
@___asan_gen_.573 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 3455, i32 31 }
@___asan_gen_.576 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 3484, i32 3 }
@___asan_gen_.577 = private unnamed_addr constant [21 x i8] c"sched_numa_balancing\00", align 1
@___asan_gen_.579 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4278, i32 1 }
@___asan_gen_.580 = private unnamed_addr constant [17 x i8] c"sched_schedstats\00", align 1
@___asan_gen_.582 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4315, i32 1 }
@___asan_gen_.591 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4328, i32 3 }
@___asan_gen_.592 = private unnamed_addr constant [22 x i8] c"balance_push_callback\00", align 1
@___asan_gen_.594 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4680, i32 22 }
@___asan_gen_.598 = private unnamed_addr constant [18 x i8] c"event_enter__nice\00", align 1
@___asan_gen_.604 = private unnamed_addr constant [17 x i8] c"event_exit__nice\00", align 1
@___asan_gen_.610 = private unnamed_addr constant [12 x i8] c"types__nice\00", align 1
@___asan_gen_.613 = private unnamed_addr constant [11 x i8] c"args__nice\00", align 1
@___asan_gen_.619 = private unnamed_addr constant [32 x i8] c"event_enter__sched_setscheduler\00", align 1
@___asan_gen_.625 = private unnamed_addr constant [31 x i8] c"event_exit__sched_setscheduler\00", align 1
@___asan_gen_.631 = private unnamed_addr constant [26 x i8] c"types__sched_setscheduler\00", align 1
@___asan_gen_.634 = private unnamed_addr constant [25 x i8] c"args__sched_setscheduler\00", align 1
@___asan_gen_.640 = private unnamed_addr constant [28 x i8] c"event_enter__sched_setparam\00", align 1
@___asan_gen_.646 = private unnamed_addr constant [27 x i8] c"event_exit__sched_setparam\00", align 1
@___asan_gen_.652 = private unnamed_addr constant [22 x i8] c"types__sched_setparam\00", align 1
@___asan_gen_.655 = private unnamed_addr constant [21 x i8] c"args__sched_setparam\00", align 1
@___asan_gen_.657 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7729, i32 1 }
@___asan_gen_.661 = private unnamed_addr constant [27 x i8] c"event_enter__sched_setattr\00", align 1
@___asan_gen_.667 = private unnamed_addr constant [26 x i8] c"event_exit__sched_setattr\00", align 1
@___asan_gen_.673 = private unnamed_addr constant [21 x i8] c"types__sched_setattr\00", align 1
@___asan_gen_.676 = private unnamed_addr constant [20 x i8] c"args__sched_setattr\00", align 1
@___asan_gen_.682 = private unnamed_addr constant [32 x i8] c"event_enter__sched_getscheduler\00", align 1
@___asan_gen_.688 = private unnamed_addr constant [31 x i8] c"event_exit__sched_getscheduler\00", align 1
@___asan_gen_.694 = private unnamed_addr constant [26 x i8] c"types__sched_getscheduler\00", align 1
@___asan_gen_.697 = private unnamed_addr constant [25 x i8] c"args__sched_getscheduler\00", align 1
@___asan_gen_.699 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7783, i32 1 }
@___asan_gen_.703 = private unnamed_addr constant [28 x i8] c"event_enter__sched_getparam\00", align 1
@___asan_gen_.709 = private unnamed_addr constant [27 x i8] c"event_exit__sched_getparam\00", align 1
@___asan_gen_.715 = private unnamed_addr constant [22 x i8] c"types__sched_getparam\00", align 1
@___asan_gen_.718 = private unnamed_addr constant [21 x i8] c"args__sched_getparam\00", align 1
@___asan_gen_.720 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7812, i32 1 }
@___asan_gen_.724 = private unnamed_addr constant [27 x i8] c"event_enter__sched_getattr\00", align 1
@___asan_gen_.730 = private unnamed_addr constant [26 x i8] c"event_exit__sched_getattr\00", align 1
@___asan_gen_.736 = private unnamed_addr constant [21 x i8] c"types__sched_getattr\00", align 1
@___asan_gen_.739 = private unnamed_addr constant [20 x i8] c"args__sched_getattr\00", align 1
@___asan_gen_.745 = private unnamed_addr constant [31 x i8] c"event_enter__sched_setaffinity\00", align 1
@___asan_gen_.751 = private unnamed_addr constant [30 x i8] c"event_exit__sched_setaffinity\00", align 1
@___asan_gen_.757 = private unnamed_addr constant [25 x i8] c"types__sched_setaffinity\00", align 1
@___asan_gen_.760 = private unnamed_addr constant [24 x i8] c"args__sched_setaffinity\00", align 1
@___asan_gen_.766 = private unnamed_addr constant [31 x i8] c"event_enter__sched_getaffinity\00", align 1
@___asan_gen_.772 = private unnamed_addr constant [30 x i8] c"event_exit__sched_getaffinity\00", align 1
@___asan_gen_.778 = private unnamed_addr constant [25 x i8] c"types__sched_getaffinity\00", align 1
@___asan_gen_.781 = private unnamed_addr constant [24 x i8] c"args__sched_getaffinity\00", align 1
@___asan_gen_.783 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8120, i32 1 }
@___asan_gen_.787 = private unnamed_addr constant [25 x i8] c"event_enter__sched_yield\00", align 1
@___asan_gen_.793 = private unnamed_addr constant [24 x i8] c"event_exit__sched_yield\00", align 1
@___asan_gen_.798 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8173, i32 1 }
@___asan_gen_.802 = private unnamed_addr constant [36 x i8] c"event_enter__sched_get_priority_max\00", align 1
@___asan_gen_.808 = private unnamed_addr constant [35 x i8] c"event_exit__sched_get_priority_max\00", align 1
@___asan_gen_.814 = private unnamed_addr constant [30 x i8] c"types__sched_get_priority_max\00", align 1
@___asan_gen_.817 = private unnamed_addr constant [29 x i8] c"args__sched_get_priority_max\00", align 1
@___asan_gen_.819 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8429, i32 1 }
@___asan_gen_.823 = private unnamed_addr constant [36 x i8] c"event_enter__sched_get_priority_min\00", align 1
@___asan_gen_.829 = private unnamed_addr constant [35 x i8] c"event_exit__sched_get_priority_min\00", align 1
@___asan_gen_.835 = private unnamed_addr constant [30 x i8] c"types__sched_get_priority_min\00", align 1
@___asan_gen_.838 = private unnamed_addr constant [29 x i8] c"args__sched_get_priority_min\00", align 1
@___asan_gen_.840 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8456, i32 1 }
@___asan_gen_.844 = private unnamed_addr constant [35 x i8] c"event_enter__sched_rr_get_interval\00", align 1
@___asan_gen_.850 = private unnamed_addr constant [34 x i8] c"event_exit__sched_rr_get_interval\00", align 1
@___asan_gen_.856 = private unnamed_addr constant [29 x i8] c"types__sched_rr_get_interval\00", align 1
@___asan_gen_.859 = private unnamed_addr constant [28 x i8] c"args__sched_rr_get_interval\00", align 1
@___asan_gen_.865 = private unnamed_addr constant [42 x i8] c"event_enter__sched_rr_get_interval_time32\00", align 1
@___asan_gen_.871 = private unnamed_addr constant [41 x i8] c"event_exit__sched_rr_get_interval_time32\00", align 1
@___asan_gen_.877 = private unnamed_addr constant [36 x i8] c"types__sched_rr_get_interval_time32\00", align 1
@___asan_gen_.880 = private unnamed_addr constant [35 x i8] c"args__sched_rr_get_interval_time32\00", align 1
@___asan_gen_.891 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8554, i32 2 }
@___asan_gen_.897 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8557, i32 3 }
@___asan_gen_.903 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8566, i32 2 }
@___asan_gen_.906 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8570, i32 20 }
@___asan_gen_.909 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8701, i32 22 }
@___asan_gen_.912 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8701, i32 31 }
@___asan_gen_.915 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9225, i32 3 }
@___asan_gen_.918 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9226, i32 21 }
@___asan_gen_.919 = private unnamed_addr constant [12 x i8] c"task_groups\00", align 1
@___asan_gen_.921 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9290, i32 1 }
@___asan_gen_.924 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9364, i32 21 }
@___asan_gen_.930 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9376, i32 3 }
@___asan_gen_.933 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9508, i32 2 }
@___asan_gen_.939 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9547, i32 2 }
@___asan_gen_.945 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9562, i32 2 }
@___asan_gen_.948 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9564, i32 2 }
@___asan_gen_.951 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9567, i32 2 }
@___asan_gen_.954 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9576, i32 3 }
@___asan_gen_.960 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9607, i32 2 }
@___asan_gen_.963 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9608, i32 2 }
@___asan_gen_.969 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9639, i32 2 }
@___asan_gen_.972 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9640, i32 2 }
@___asan_gen_.973 = private unnamed_addr constant [16 x i8] c"task_group_lock\00", align 1
@___asan_gen_.976 = private unnamed_addr constant [21 x i8] c"max_cfs_quota_period\00", align 1
@___asan_gen_.978 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10238, i32 11 }
@___asan_gen_.979 = private unnamed_addr constant [10 x i8] c"cpu_files\00", align 1
@___asan_gen_.981 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10808, i32 22 }
@___asan_gen_.982 = private unnamed_addr constant [17 x i8] c"cpu_legacy_files\00", align 1
@___asan_gen_.984 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10599, i32 22 }
@___asan_gen_.985 = private unnamed_addr constant [16 x i8] c"cpu_cgrp_subsys\00", align 1
@___asan_gen_.987 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10860, i32 22 }
@___asan_gen_.996 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10879, i32 2 }
@___asan_gen_.997 = private unnamed_addr constant [21 x i8] c"sched_prio_to_weight\00", align 1
@___asan_gen_.999 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10895, i32 11 }
@___asan_gen_.1000 = private unnamed_addr constant [20 x i8] c"sched_prio_to_wmult\00", align 1
@___asan_gen_.1002 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10913, i32 11 }
@___asan_gen_.1017 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 16, i32 1 }
@___asan_gen_.1026 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 38, i32 1 }
@___asan_gen_.1041 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 64, i32 1 }
@___asan_gen_.1044 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 93, i32 1 }
@___asan_gen_.1053 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 141, i32 1 }
@___asan_gen_.1081 = private unnamed_addr constant [8 x i8] c"__flags\00", align 1
@___asan_gen_.1119 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 220, i32 1 }
@___asan_gen_.1128 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 271, i32 1 }
@___asan_gen_.1131 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 298, i32 1 }
@___asan_gen_.1146 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 369, i32 1 }
@___asan_gen_.1161 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 397, i32 1 }
@___asan_gen_.1170 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 433, i32 1 }
@___asan_gen_.1179 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 491, i32 1 }
@___asan_gen_.1188 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 525, i32 1 }
@___asan_gen_.1209 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 576, i32 1 }
@___asan_gen_.1230 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 608, i32 1 }
@___asan_gen_.1242 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 248, i32 8 }
@___asan_gen_.1243 = private unnamed_addr constant [16 x i8] c"sched_core_mask\00", align 1
@___asan_gen_.1245 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 250, i32 23 }
@___asan_gen_.1251 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1253, i32 1545, i32 2 }
@___asan_gen_.1253 = private unnamed_addr constant [24 x i8] c"../kernel/sched/sched.h\00", align 1
@___asan_gen_.1254 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1253, i32 1459, i32 2 }
@___asan_gen_.1256 = private unnamed_addr constant [32 x i8] c"../include/trace/events/sched.h\00", align 1
@___asan_gen_.1257 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1256, i32 668, i32 1 }
@___asan_gen_.1263 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1425, i32 695, i32 2 }
@___asan_gen_.1266 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1425, i32 723, i32 2 }
@___asan_gen_.1272 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1254, i32 8 }
@___asan_gen_.1275 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10052, i32 2 }
@___asan_gen_.1278 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1582, i32 2 }
@___asan_gen_.1281 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 1602, i32 2 }
@___asan_gen_.1284 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 2506, i32 3 }
@___asan_gen_.1285 = private unnamed_addr constant [6 x i8] c"__key\00", align 1
@___asan_gen_.1289 = private unnamed_addr constant [30 x i8] c"../include/linux/completion.h\00", align 1
@___asan_gen_.1290 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1289, i32 87, i32 2 }
@___asan_gen_.1293 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4339, i32 19 }
@___asan_gen_.1296 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4342, i32 26 }
@___asan_gen_.1305 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4348, i32 3 }
@___asan_gen_.1311 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 3416, i32 4 }
@___asan_gen_.1314 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 4850, i32 6 }
@___asan_gen_.1323 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 5233, i32 3 }
@___asan_gen_.1324 = private unnamed_addr constant [32 x i8] c"cpu_resched_latency.warned_once\00", align 1
@___asan_gen_.1327 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 5550, i32 9 }
@___asan_gen_.1336 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 5558, i32 3 }
@___asan_gen_.1342 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 5524, i32 2 }
@___asan_gen_.1345 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 5537, i32 9 }
@___asan_gen_.1348 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 6976, i32 1 }
@___asan_gen_.1357 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7714, i32 1 }
@___asan_gen_.1360 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1362, i32 230, i32 6 }
@___asan_gen_.1362 = private unnamed_addr constant [31 x i8] c"../include/linux/thread_info.h\00", align 1
@___asan_gen_.1363 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1362, i32 214, i32 2 }
@___asan_gen_.1365 = private unnamed_addr constant [27 x i8] c"../include/linux/uaccess.h\00", align 1
@___asan_gen_.1366 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1365, i32 156, i32 2 }
@___asan_gen_.1378 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7740, i32 1 }
@___asan_gen_.1381 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 7893, i32 1 }
@___asan_gen_.1390 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8068, i32 1 }
@___asan_gen_.1396 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8521, i32 1 }
@___asan_gen_.1399 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8534, i32 1 }
@___asan_gen_.1400 = private unnamed_addr constant [11 x i8] c"state_char\00", align 1
@___asan_gen_.1401 = private unnamed_addr constant [25 x i8] c"../include/linux/sched.h\00", align 1
@___asan_gen_.1402 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1401, i32 1638, i32 20 }
@___asan_gen_.1404 = private unnamed_addr constant [27 x i8] c"../include/linux/cpumask.h\00", align 1
@___asan_gen_.1405 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1404, i32 108, i32 2 }
@___asan_gen_.1406 = private unnamed_addr constant [16 x i8] c"num_cpus_frozen\00", align 1
@___asan_gen_.1408 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 8990, i32 12 }
@___asan_gen_.1417 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9203, i32 2 }
@___asan_gen_.1418 = private unnamed_addr constant [7 x i8] c"_entry\00", align 1
@___asan_gen_.1423 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9211, i32 3 }
@___asan_gen_.1425 = private unnamed_addr constant [28 x i8] c"../include/linux/rcupdate.h\00", align 1
@___asan_gen_.1426 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1425, i32 328, i32 2 }
@___asan_gen_.1429 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 9741, i32 8 }
@___asan_gen_.1432 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10676, i32 18 }
@___asan_gen_.1435 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10755, i32 16 }
@___asan_gen_.1438 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10757, i32 18 }
@___asan_gen_.1441 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10759, i32 17 }
@___asan_gen_.1444 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10768, i32 18 }
@___asan_gen_.1447 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10773, i32 18 }
@___asan_gen_.1448 = private unnamed_addr constant [22 x i8] c"cfs_constraints_mutex\00", align 1
@___asan_gen_.1456 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10236, i32 8 }
@___asan_gen_.1459 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10196, i32 16 }
@___asan_gen_.1462 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10202, i32 17 }
@___asan_gen_.1465 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10534, i32 17 }
@___asan_gen_.1468 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10535, i32 17 }
@___asan_gen_.1471 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10536, i32 17 }
@___asan_gen_.1474 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10548, i32 18 }
@___asan_gen_.1477 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10551, i32 17 }
@___asan_gen_.1478 = private unnamed_addr constant [17 x i8] c"<string literal>\00", align 1
@___asan_gen_.1479 = private constant [23 x i8] c"../kernel/sched/core.c\00", align 1
@___asan_gen_.1480 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.1479, i32 10552, i32 17 }
@___asan_gen_.1481 = private unnamed_addr constant [45 x i8] c"switch.table.__se_sys_sched_get_priority_max\00", align 1
@___asan_gen_.1482 = private unnamed_addr constant [45 x i8] c"switch.table.__se_sys_sched_get_priority_min\00", align 1
@llvm.compiler.used = appending global [716 x ptr] [ptr @__bpf_trace_tp_map_pelt_cfs_tp, ptr @__bpf_trace_tp_map_pelt_dl_tp, ptr @__bpf_trace_tp_map_pelt_irq_tp, ptr @__bpf_trace_tp_map_pelt_rt_tp, ptr @__bpf_trace_tp_map_pelt_se_tp, ptr @__bpf_trace_tp_map_pelt_thermal_tp, ptr @__bpf_trace_tp_map_sched_cpu_capacity_tp, ptr @__bpf_trace_tp_map_sched_kthread_stop, ptr @__bpf_trace_tp_map_sched_kthread_stop_ret, ptr @__bpf_trace_tp_map_sched_kthread_work_execute_end, ptr @__bpf_trace_tp_map_sched_kthread_work_execute_start, ptr @__bpf_trace_tp_map_sched_kthread_work_queue_work, ptr @__bpf_trace_tp_map_sched_migrate_task, ptr @__bpf_trace_tp_map_sched_move_numa, ptr @__bpf_trace_tp_map_sched_overutilized_tp, ptr @__bpf_trace_tp_map_sched_pi_setprio, ptr @__bpf_trace_tp_map_sched_process_exec, ptr @__bpf_trace_tp_map_sched_process_exit, ptr @__bpf_trace_tp_map_sched_process_fork, ptr @__bpf_trace_tp_map_sched_process_free, ptr @__bpf_trace_tp_map_sched_process_hang, ptr @__bpf_trace_tp_map_sched_process_wait, ptr @__bpf_trace_tp_map_sched_stat_blocked, ptr @__bpf_trace_tp_map_sched_stat_iowait, ptr @__bpf_trace_tp_map_sched_stat_runtime, ptr @__bpf_trace_tp_map_sched_stat_sleep, ptr @__bpf_trace_tp_map_sched_stat_wait, ptr @__bpf_trace_tp_map_sched_stick_numa, ptr @__bpf_trace_tp_map_sched_swap_numa, ptr @__bpf_trace_tp_map_sched_switch, ptr @__bpf_trace_tp_map_sched_update_nr_running_tp, ptr @__bpf_trace_tp_map_sched_util_est_cfs_tp, ptr @__bpf_trace_tp_map_sched_util_est_se_tp, ptr @__bpf_trace_tp_map_sched_wait_task, ptr @__bpf_trace_tp_map_sched_wake_idle_without_ipi, ptr @__bpf_trace_tp_map_sched_wakeup, ptr @__bpf_trace_tp_map_sched_wakeup_new, ptr @__bpf_trace_tp_map_sched_waking, ptr @__cant_migrate._entry, ptr @__cant_migrate._entry.93, ptr @__cant_migrate._entry_ptr, ptr @__cant_migrate._entry_ptr.95, ptr @__cant_sleep._entry, ptr @__cant_sleep._entry.88, ptr @__cant_sleep._entry_ptr, ptr @__cant_sleep._entry_ptr.90, ptr @__event_enter__nice, ptr @__event_enter__sched_get_priority_max, ptr @__event_enter__sched_get_priority_min, ptr @__event_enter__sched_getaffinity, ptr @__event_enter__sched_getattr, ptr @__event_enter__sched_getparam, ptr @__event_enter__sched_getscheduler, ptr @__event_enter__sched_rr_get_interval, ptr @__event_enter__sched_rr_get_interval_time32, ptr @__event_enter__sched_setaffinity, ptr @__event_enter__sched_setattr, ptr @__event_enter__sched_setparam, ptr @__event_enter__sched_setscheduler, ptr @__event_enter__sched_yield, ptr @__event_exit__nice, ptr @__event_exit__sched_get_priority_max, ptr @__event_exit__sched_get_priority_min, ptr @__event_exit__sched_getaffinity, ptr @__event_exit__sched_getattr, ptr @__event_exit__sched_getparam, ptr @__event_exit__sched_getscheduler, ptr @__event_exit__sched_rr_get_interval, ptr @__event_exit__sched_rr_get_interval_time32, ptr @__event_exit__sched_setaffinity, ptr @__event_exit__sched_setattr, ptr @__event_exit__sched_setparam, ptr @__event_exit__sched_setscheduler, ptr @__event_exit__sched_yield, ptr @__event_sched_kthread_stop, ptr @__event_sched_kthread_stop_ret, ptr @__event_sched_kthread_work_execute_end, ptr @__event_sched_kthread_work_execute_start, ptr @__event_sched_kthread_work_queue_work, ptr @__event_sched_migrate_task, ptr @__event_sched_move_numa, ptr @__event_sched_pi_setprio, ptr @__event_sched_process_exec, ptr @__event_sched_process_exit, ptr @__event_sched_process_fork, ptr @__event_sched_process_free, ptr @__event_sched_process_hang, ptr @__event_sched_process_wait, ptr @__event_sched_stat_blocked, ptr @__event_sched_stat_iowait, ptr @__event_sched_stat_runtime, ptr @__event_sched_stat_sleep, ptr @__event_sched_stat_wait, ptr @__event_sched_stick_numa, ptr @__event_sched_swap_numa, ptr @__event_sched_switch, ptr @__event_sched_wait_task, ptr @__event_sched_wake_idle_without_ipi, ptr @__event_sched_wakeup, ptr @__event_sched_wakeup_new, ptr @__event_sched_waking, ptr @__initcall__kmod_core__743_9268_migration_initearly, ptr @__ksymtab___SCK__tp_func_pelt_cfs_tp, ptr @__ksymtab___SCK__tp_func_pelt_dl_tp, ptr @__ksymtab___SCK__tp_func_pelt_irq_tp, ptr @__ksymtab___SCK__tp_func_pelt_rt_tp, ptr @__ksymtab___SCK__tp_func_pelt_se_tp, ptr @__ksymtab___SCK__tp_func_sched_cpu_capacity_tp, ptr @__ksymtab___SCK__tp_func_sched_overutilized_tp, ptr @__ksymtab___SCK__tp_func_sched_update_nr_running_tp, ptr @__ksymtab___SCK__tp_func_sched_util_est_cfs_tp, ptr @__ksymtab___SCK__tp_func_sched_util_est_se_tp, ptr @__ksymtab___cant_migrate, ptr @__ksymtab___cant_sleep, ptr @__ksymtab___cond_resched, ptr @__ksymtab___cond_resched_lock, ptr @__ksymtab___cond_resched_rwlock_read, ptr @__ksymtab___cond_resched_rwlock_write, ptr @__ksymtab___might_resched, ptr @__ksymtab___might_sleep, ptr @__ksymtab___traceiter_pelt_cfs_tp, ptr @__ksymtab___traceiter_pelt_dl_tp, ptr @__ksymtab___traceiter_pelt_irq_tp, ptr @__ksymtab___traceiter_pelt_rt_tp, ptr @__ksymtab___traceiter_pelt_se_tp, ptr @__ksymtab___traceiter_sched_cpu_capacity_tp, ptr @__ksymtab___traceiter_sched_overutilized_tp, ptr @__ksymtab___traceiter_sched_update_nr_running_tp, ptr @__ksymtab___traceiter_sched_util_est_cfs_tp, ptr @__ksymtab___traceiter_sched_util_est_se_tp, ptr @__ksymtab___tracepoint_pelt_cfs_tp, ptr @__ksymtab___tracepoint_pelt_dl_tp, ptr @__ksymtab___tracepoint_pelt_irq_tp, ptr @__ksymtab___tracepoint_pelt_rt_tp, ptr @__ksymtab___tracepoint_pelt_se_tp, ptr @__ksymtab___tracepoint_sched_cpu_capacity_tp, ptr @__ksymtab___tracepoint_sched_overutilized_tp, ptr @__ksymtab___tracepoint_sched_update_nr_running_tp, ptr @__ksymtab___tracepoint_sched_util_est_cfs_tp, ptr @__ksymtab___tracepoint_sched_util_est_se_tp, ptr @__ksymtab_default_wake_function, ptr @__ksymtab_io_schedule, ptr @__ksymtab_io_schedule_timeout, ptr @__ksymtab_kernel_cpustat, ptr @__ksymtab_kick_process, ptr @__ksymtab_kstat, ptr @__ksymtab_migrate_disable, ptr @__ksymtab_migrate_enable, ptr @__ksymtab_sched_set_fifo, ptr @__ksymtab_sched_set_fifo_low, ptr @__ksymtab_sched_set_normal, ptr @__ksymtab_sched_setattr_nocheck, ptr @__ksymtab_sched_show_task, ptr @__ksymtab_schedule, ptr @__ksymtab_set_cpus_allowed_ptr, ptr @__ksymtab_set_user_nice, ptr @__ksymtab_single_task_running, ptr @__ksymtab_wake_up_process, ptr @__ksymtab_yield, ptr @__ksymtab_yield_to, ptr @__might_resched._entry, ptr @__might_resched._entry.77, ptr @__might_resched._entry.80, ptr @__might_resched._entry.83, ptr @__might_resched._entry_ptr, ptr @__might_resched._entry_ptr.79, ptr @__might_resched._entry_ptr.82, ptr @__might_resched._entry_ptr.85, ptr @__p_syscall_meta__nice, ptr @__p_syscall_meta__sched_get_priority_max, ptr @__p_syscall_meta__sched_get_priority_min, ptr @__p_syscall_meta__sched_getaffinity, ptr @__p_syscall_meta__sched_getattr, ptr @__p_syscall_meta__sched_getparam, ptr @__p_syscall_meta__sched_getscheduler, ptr @__p_syscall_meta__sched_rr_get_interval, ptr @__p_syscall_meta__sched_rr_get_interval_time32, ptr @__p_syscall_meta__sched_setaffinity, ptr @__p_syscall_meta__sched_setattr, ptr @__p_syscall_meta__sched_setparam, ptr @__p_syscall_meta__sched_setscheduler, ptr @__p_syscall_meta__sched_yield, ptr @__schedule_bug._entry, ptr @__schedule_bug._entry_ptr, ptr @__setup_setup_resched_latency_warn_ms, ptr @__setup_setup_schedstats, ptr @__syscall_meta__nice, ptr @__syscall_meta__sched_get_priority_max, ptr @__syscall_meta__sched_get_priority_min, ptr @__syscall_meta__sched_getaffinity, ptr @__syscall_meta__sched_getattr, ptr @__syscall_meta__sched_getparam, ptr @__syscall_meta__sched_getscheduler, ptr @__syscall_meta__sched_rr_get_interval, ptr @__syscall_meta__sched_rr_get_interval_time32, ptr @__syscall_meta__sched_setaffinity, ptr @__syscall_meta__sched_setattr, ptr @__syscall_meta__sched_setparam, ptr @__syscall_meta__sched_setscheduler, ptr @__syscall_meta__sched_yield, ptr @__tracepoint_pelt_cfs_tp, ptr @__tracepoint_pelt_dl_tp, ptr @__tracepoint_pelt_irq_tp, ptr @__tracepoint_pelt_rt_tp, ptr @__tracepoint_pelt_se_tp, ptr @__tracepoint_pelt_thermal_tp, ptr @__tracepoint_ptr_pelt_cfs_tp, ptr @__tracepoint_ptr_pelt_dl_tp, ptr @__tracepoint_ptr_pelt_irq_tp, ptr @__tracepoint_ptr_pelt_rt_tp, ptr @__tracepoint_ptr_pelt_se_tp, ptr @__tracepoint_ptr_pelt_thermal_tp, ptr @__tracepoint_ptr_sched_cpu_capacity_tp, ptr @__tracepoint_ptr_sched_kthread_stop, ptr @__tracepoint_ptr_sched_kthread_stop_ret, ptr @__tracepoint_ptr_sched_kthread_work_execute_end, ptr @__tracepoint_ptr_sched_kthread_work_execute_start, ptr @__tracepoint_ptr_sched_kthread_work_queue_work, ptr @__tracepoint_ptr_sched_migrate_task, ptr @__tracepoint_ptr_sched_move_numa, ptr @__tracepoint_ptr_sched_overutilized_tp, ptr @__tracepoint_ptr_sched_pi_setprio, ptr @__tracepoint_ptr_sched_process_exec, ptr @__tracepoint_ptr_sched_process_exit, ptr @__tracepoint_ptr_sched_process_fork, ptr @__tracepoint_ptr_sched_process_free, ptr @__tracepoint_ptr_sched_process_hang, ptr @__tracepoint_ptr_sched_process_wait, ptr @__tracepoint_ptr_sched_stat_blocked, ptr @__tracepoint_ptr_sched_stat_iowait, ptr @__tracepoint_ptr_sched_stat_runtime, ptr @__tracepoint_ptr_sched_stat_sleep, ptr @__tracepoint_ptr_sched_stat_wait, ptr @__tracepoint_ptr_sched_stick_numa, ptr @__tracepoint_ptr_sched_swap_numa, ptr @__tracepoint_ptr_sched_switch, ptr @__tracepoint_ptr_sched_update_nr_running_tp, ptr @__tracepoint_ptr_sched_util_est_cfs_tp, ptr @__tracepoint_ptr_sched_util_est_se_tp, ptr @__tracepoint_ptr_sched_wait_task, ptr @__tracepoint_ptr_sched_wake_idle_without_ipi, ptr @__tracepoint_ptr_sched_wakeup, ptr @__tracepoint_ptr_sched_wakeup_new, ptr @__tracepoint_ptr_sched_waking, ptr @__tracepoint_sched_cpu_capacity_tp, ptr @__tracepoint_sched_kthread_stop, ptr @__tracepoint_sched_kthread_stop_ret, ptr @__tracepoint_sched_kthread_work_execute_end, ptr @__tracepoint_sched_kthread_work_execute_start, ptr @__tracepoint_sched_kthread_work_queue_work, ptr @__tracepoint_sched_migrate_task, ptr @__tracepoint_sched_move_numa, ptr @__tracepoint_sched_overutilized_tp, ptr @__tracepoint_sched_pi_setprio, ptr @__tracepoint_sched_process_exec, ptr @__tracepoint_sched_process_exit, ptr @__tracepoint_sched_process_fork, ptr @__tracepoint_sched_process_free, ptr @__tracepoint_sched_process_hang, ptr @__tracepoint_sched_process_wait, ptr @__tracepoint_sched_stat_blocked, ptr @__tracepoint_sched_stat_iowait, ptr @__tracepoint_sched_stat_runtime, ptr @__tracepoint_sched_stat_sleep, ptr @__tracepoint_sched_stat_wait, ptr @__tracepoint_sched_stick_numa, ptr @__tracepoint_sched_swap_numa, ptr @__tracepoint_sched_switch, ptr @__tracepoint_sched_update_nr_running_tp, ptr @__tracepoint_sched_util_est_cfs_tp, ptr @__tracepoint_sched_util_est_se_tp, ptr @__tracepoint_sched_wait_task, ptr @__tracepoint_sched_wake_idle_without_ipi, ptr @__tracepoint_sched_wakeup, ptr @__tracepoint_sched_wakeup_new, ptr @__tracepoint_sched_waking, ptr @dump_cpu_task._entry, ptr @dump_cpu_task._entry_ptr, ptr @dump_rq_tasks._entry, ptr @dump_rq_tasks._entry.240, ptr @dump_rq_tasks._entry_ptr, ptr @dump_rq_tasks._entry_ptr.242, ptr @event_class_sched_kthread_stop, ptr @event_class_sched_kthread_stop_ret, ptr @event_class_sched_kthread_work_execute_end, ptr @event_class_sched_kthread_work_execute_start, ptr @event_class_sched_kthread_work_queue_work, ptr @event_class_sched_migrate_task, ptr @event_class_sched_move_numa, ptr @event_class_sched_numa_pair_template, ptr @event_class_sched_pi_setprio, ptr @event_class_sched_process_exec, ptr @event_class_sched_process_fork, ptr @event_class_sched_process_hang, ptr @event_class_sched_process_template, ptr @event_class_sched_process_wait, ptr @event_class_sched_stat_runtime, ptr @event_class_sched_stat_template, ptr @event_class_sched_switch, ptr @event_class_sched_wake_idle_without_ipi, ptr @event_class_sched_wakeup_template, ptr @event_enter__nice, ptr @event_enter__sched_get_priority_max, ptr @event_enter__sched_get_priority_min, ptr @event_enter__sched_getaffinity, ptr @event_enter__sched_getattr, ptr @event_enter__sched_getparam, ptr @event_enter__sched_getscheduler, ptr @event_enter__sched_rr_get_interval, ptr @event_enter__sched_rr_get_interval_time32, ptr @event_enter__sched_setaffinity, ptr @event_enter__sched_setattr, ptr @event_enter__sched_setparam, ptr @event_enter__sched_setscheduler, ptr @event_enter__sched_yield, ptr @event_exit__nice, ptr @event_exit__sched_get_priority_max, ptr @event_exit__sched_get_priority_min, ptr @event_exit__sched_getaffinity, ptr @event_exit__sched_getattr, ptr @event_exit__sched_getparam, ptr @event_exit__sched_getscheduler, ptr @event_exit__sched_rr_get_interval, ptr @event_exit__sched_rr_get_interval_time32, ptr @event_exit__sched_setaffinity, ptr @event_exit__sched_setattr, ptr @event_exit__sched_setparam, ptr @event_exit__sched_setscheduler, ptr @event_exit__sched_yield, ptr @event_sched_kthread_stop, ptr @event_sched_kthread_stop_ret, ptr @event_sched_kthread_work_execute_end, ptr @event_sched_kthread_work_execute_start, ptr @event_sched_kthread_work_queue_work, ptr @event_sched_migrate_task, ptr @event_sched_move_numa, ptr @event_sched_pi_setprio, ptr @event_sched_process_exec, ptr @event_sched_process_exit, ptr @event_sched_process_fork, ptr @event_sched_process_free, ptr @event_sched_process_hang, ptr @event_sched_process_wait, ptr @event_sched_stat_blocked, ptr @event_sched_stat_iowait, ptr @event_sched_stat_runtime, ptr @event_sched_stat_sleep, ptr @event_sched_stat_wait, ptr @event_sched_stick_numa, ptr @event_sched_swap_numa, ptr @event_sched_switch, ptr @event_sched_wait_task, ptr @event_sched_wake_idle_without_ipi, ptr @event_sched_wakeup, ptr @event_sched_wakeup_new, ptr @event_sched_waking, ptr @force_compatible_cpus_allowed_ptr._entry, ptr @force_compatible_cpus_allowed_ptr._entry_ptr, ptr @force_schedstat_enabled._entry, ptr @force_schedstat_enabled._entry_ptr, ptr @sched_show_task._entry, ptr @sched_show_task._entry.58, ptr @sched_show_task._entry.61, ptr @sched_show_task._entry_ptr, ptr @sched_show_task._entry_ptr.60, ptr @sched_show_task._entry_ptr.63, ptr @schedule_debug._entry, ptr @schedule_debug._entry_ptr, ptr @select_fallback_rq._entry, ptr @select_fallback_rq._entry_ptr, ptr @setup_resched_latency_warn_ms._entry, ptr @setup_resched_latency_warn_ms._entry_ptr, ptr @setup_schedstats._entry, ptr @setup_schedstats._entry_ptr, ptr @str__sched__trace_system_name, ptr @trace_event_fields_sched_kthread_stop, ptr @trace_event_type_funcs_sched_kthread_stop, ptr @print_fmt_sched_kthread_stop, ptr @trace_event_fields_sched_kthread_stop_ret, ptr @trace_event_type_funcs_sched_kthread_stop_ret, ptr @print_fmt_sched_kthread_stop_ret, ptr @trace_event_fields_sched_kthread_work_queue_work, ptr @trace_event_type_funcs_sched_kthread_work_queue_work, ptr @print_fmt_sched_kthread_work_queue_work, ptr @trace_event_fields_sched_kthread_work_execute_start, ptr @trace_event_type_funcs_sched_kthread_work_execute_start, ptr @print_fmt_sched_kthread_work_execute_start, ptr @trace_event_fields_sched_kthread_work_execute_end, ptr @trace_event_type_funcs_sched_kthread_work_execute_end, ptr @print_fmt_sched_kthread_work_execute_end, ptr @trace_event_fields_sched_wakeup_template, ptr @trace_event_type_funcs_sched_wakeup_template, ptr @print_fmt_sched_wakeup_template, ptr @trace_event_fields_sched_switch, ptr @trace_event_type_funcs_sched_switch, ptr @print_fmt_sched_switch, ptr @trace_event_fields_sched_migrate_task, ptr @trace_event_type_funcs_sched_migrate_task, ptr @print_fmt_sched_migrate_task, ptr @trace_event_fields_sched_process_template, ptr @trace_event_type_funcs_sched_process_template, ptr @print_fmt_sched_process_template, ptr @trace_event_fields_sched_process_wait, ptr @trace_event_type_funcs_sched_process_wait, ptr @print_fmt_sched_process_wait, ptr @trace_event_fields_sched_process_fork, ptr @trace_event_type_funcs_sched_process_fork, ptr @print_fmt_sched_process_fork, ptr @trace_event_fields_sched_process_exec, ptr @trace_event_type_funcs_sched_process_exec, ptr @print_fmt_sched_process_exec, ptr @trace_event_fields_sched_stat_template, ptr @trace_event_type_funcs_sched_stat_template, ptr @print_fmt_sched_stat_template, ptr @trace_event_fields_sched_stat_runtime, ptr @trace_event_type_funcs_sched_stat_runtime, ptr @print_fmt_sched_stat_runtime, ptr @trace_event_fields_sched_pi_setprio, ptr @trace_event_type_funcs_sched_pi_setprio, ptr @print_fmt_sched_pi_setprio, ptr @trace_event_fields_sched_process_hang, ptr @trace_event_type_funcs_sched_process_hang, ptr @print_fmt_sched_process_hang, ptr @trace_event_fields_sched_move_numa, ptr @trace_event_type_funcs_sched_move_numa, ptr @print_fmt_sched_move_numa, ptr @trace_event_fields_sched_numa_pair_template, ptr @trace_event_type_funcs_sched_numa_pair_template, ptr @print_fmt_sched_numa_pair_template, ptr @trace_event_fields_sched_wake_idle_without_ipi, ptr @trace_event_type_funcs_sched_wake_idle_without_ipi, ptr @print_fmt_sched_wake_idle_without_ipi, ptr @sysctl_sched_rt_period, ptr @sched_core_count, ptr @sched_core_mutex, ptr @sched_core_put._work, ptr @.str, ptr @sysctl_sched_rt_runtime, ptr @.str.1, ptr @.str.2, ptr @.str.3, ptr @.str.4, ptr @sysctl_sched_uclamp_util_min, ptr @sysctl_sched_uclamp_util_max, ptr @sysctl_sched_uclamp_util_min_rt_default, ptr @sched_uclamp_used, ptr @uclamp_mutex, ptr @uclamp_default, ptr @.str.5, ptr @sched_set_stop_task.stop_pi_lock, ptr @.str.10, ptr @sched_numa_balancing, ptr @sched_schedstats, ptr @.str.12, ptr @.str.13, ptr @balance_push_callback, ptr @.str.14, ptr @.str.15, ptr @.str.16, ptr @types__nice, ptr @args__nice, ptr @.str.17, ptr @.str.18, ptr @.str.19, ptr @types__sched_setscheduler, ptr @args__sched_setscheduler, ptr @.str.20, ptr @.str.21, ptr @.str.22, ptr @types__sched_setparam, ptr @args__sched_setparam, ptr @.str.23, ptr @.str.24, ptr @.str.25, ptr @types__sched_setattr, ptr @args__sched_setattr, ptr @.str.26, ptr @.str.27, ptr @.str.28, ptr @types__sched_getscheduler, ptr @args__sched_getscheduler, ptr @.str.29, ptr @.str.30, ptr @.str.31, ptr @types__sched_getparam, ptr @args__sched_getparam, ptr @.str.32, ptr @.str.33, ptr @.str.34, ptr @types__sched_getattr, ptr @args__sched_getattr, ptr @.str.35, ptr @.str.36, ptr @.str.37, ptr @types__sched_setaffinity, ptr @args__sched_setaffinity, ptr @.str.38, ptr @.str.39, ptr @.str.40, ptr @types__sched_getaffinity, ptr @args__sched_getaffinity, ptr @.str.41, ptr @.str.42, ptr @.str.43, ptr @.str.44, ptr @.str.45, ptr @.str.46, ptr @types__sched_get_priority_max, ptr @args__sched_get_priority_max, ptr @.str.47, ptr @.str.48, ptr @.str.49, ptr @types__sched_get_priority_min, ptr @args__sched_get_priority_min, ptr @.str.50, ptr @.str.51, ptr @.str.52, ptr @types__sched_rr_get_interval, ptr @args__sched_rr_get_interval, ptr @.str.53, ptr @.str.54, ptr @.str.55, ptr @types__sched_rr_get_interval_time32, ptr @args__sched_rr_get_interval_time32, ptr @.str.56, ptr @.str.57, ptr @.str.59, ptr @.str.62, ptr @.str.64, ptr @.str.65, ptr @.str.66, ptr @.str.67, ptr @.str.68, ptr @task_groups, ptr @.str.69, ptr @sched_init.__key, ptr @.str.70, ptr @.str.71, ptr @.str.72, ptr @.str.74, ptr @.str.75, ptr @.str.76, ptr @.str.78, ptr @.str.81, ptr @.str.84, ptr @.str.86, ptr @.str.87, ptr @.str.89, ptr @.str.91, ptr @.str.92, ptr @.str.94, ptr @task_group_lock, ptr @max_cfs_quota_period, ptr @cpu_files, ptr @cpu_legacy_files, ptr @cpu_cgrp_subsys, ptr @.str.96, ptr @.str.97, ptr @sched_prio_to_weight, ptr @sched_prio_to_wmult, ptr @.str.98, ptr @.str.99, ptr @.str.100, ptr @.str.101, ptr @.str.102, ptr @.str.103, ptr @.str.104, ptr @.str.105, ptr @.str.106, ptr @.str.107, ptr @.str.108, ptr @.str.109, ptr @.str.110, ptr @.str.111, ptr @.str.112, ptr @.str.113, ptr @.str.114, ptr @.str.115, ptr @.str.116, ptr @.str.117, ptr @.str.118, ptr @.str.119, ptr @.str.120, ptr @.str.121, ptr @.str.122, ptr @.str.123, ptr @trace_raw_output_sched_switch.__flags, ptr @.str.124, ptr @.str.125, ptr @.str.126, ptr @.str.127, ptr @.str.128, ptr @.str.129, ptr @.str.130, ptr @.str.131, ptr @.str.132, ptr @.str.133, ptr @.str.134, ptr @.str.135, ptr @.str.136, ptr @.str.137, ptr @.str.138, ptr @.str.139, ptr @.str.140, ptr @.str.141, ptr @.str.142, ptr @.str.143, ptr @.str.144, ptr @.str.145, ptr @.str.146, ptr @.str.147, ptr @.str.148, ptr @.str.149, ptr @.str.150, ptr @.str.151, ptr @.str.152, ptr @.str.153, ptr @.str.154, ptr @.str.155, ptr @.str.156, ptr @.str.157, ptr @.str.158, ptr @.str.159, ptr @.str.160, ptr @.str.161, ptr @.str.162, ptr @.str.163, ptr @.str.164, ptr @.str.165, ptr @.str.166, ptr @.str.167, ptr @.str.168, ptr @.str.169, ptr @.str.170, ptr @.str.171, ptr @.str.172, ptr @.str.173, ptr @.str.174, ptr @.str.175, ptr @.str.176, ptr @sched_core_mask, ptr @.str.177, ptr @.str.178, ptr @.str.179, ptr @.str.180, ptr @.str.181, ptr @.str.182, ptr @.str.183, ptr @.str.184, ptr @.str.185, ptr @.str.186, ptr @.str.187, ptr @.str.189, ptr @.str.190, ptr @init_completion.__key, ptr @.str.192, ptr @.str.193, ptr @.str.194, ptr @.str.195, ptr @.str.196, ptr @.str.197, ptr @.str.198, ptr @.str.200, ptr @.str.201, ptr @cpu_resched_latency.warned_once, ptr @.str.202, ptr @.str.204, ptr @.str.205, ptr @.str.208, ptr @.str.209, ptr @.str.210, ptr @.str.214, ptr @.str.215, ptr @.str.216, ptr @.str.217, ptr @.str.218, ptr @.str.219, ptr @.str.220, ptr @.str.221, ptr @.str.222, ptr @.str.223, ptr @.str.224, ptr @.str.225, ptr @.str.227, ptr @.str.228, ptr @.str.229, ptr @.str.230, ptr @.str.231, ptr @.str.232, ptr @task_index_to_char.state_char, ptr @.str.233, ptr @num_cpus_frozen, ptr @.str.238, ptr @.str.239, ptr @.str.241, ptr @.str.243, ptr @.str.244, ptr @.str.245, ptr @.str.246, ptr @.str.247, ptr @.str.248, ptr @.str.249, ptr @.str.250, ptr @cfs_constraints_mutex, ptr @.str.251, ptr @.str.252, ptr @.str.253, ptr @.str.254, ptr @.str.255, ptr @.str.256, ptr @.str.257, ptr @.str.258, ptr @.str.259, ptr @.str.260, ptr @switch.table.__se_sys_sched_get_priority_max, ptr @switch.table.__se_sys_sched_get_priority_min], section "llvm.metadata"
@0 = internal global [409 x { i32, i32, i32, i32, i32, i32, i32, i32 }] [{ i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @str__sched__trace_system_name to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.262 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.264 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_kthread_stop to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.265 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_kthread_stop to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.268 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_kthread_stop to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.271 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_kthread_stop to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.274 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_kthread_stop_ret to i32), i32 48, i32 96, i32 ptrtoint (ptr @___asan_gen_.277 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_kthread_stop_ret to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.280 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_kthread_stop_ret to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.283 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_kthread_stop_ret to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.286 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_kthread_work_queue_work to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.289 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_kthread_work_queue_work to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.292 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_kthread_work_queue_work to i32), i32 79, i32 128, i32 ptrtoint (ptr @___asan_gen_.295 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_kthread_work_queue_work to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.298 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_kthread_work_execute_start to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.301 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_kthread_work_execute_start to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.304 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_kthread_work_execute_start to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.307 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_kthread_work_execute_start to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.310 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_kthread_work_execute_end to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.313 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.324 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_kthread_work_execute_end to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.316 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.324 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_kthread_work_execute_end to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.319 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.324 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_kthread_work_execute_end to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.322 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.324 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_wakeup_template to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.325 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_wakeup_template to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.328 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_wakeup_template to i32), i32 90, i32 128, i32 ptrtoint (ptr @___asan_gen_.331 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_waking to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.334 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_wakeup to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.337 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.339 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_wakeup_new to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.340 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.342 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_switch to i32), i32 192, i32 224, i32 ptrtoint (ptr @___asan_gen_.343 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_switch to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.346 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_switch to i32), i32 692, i32 864, i32 ptrtoint (ptr @___asan_gen_.349 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_switch to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.352 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_migrate_task to i32), i32 144, i32 192, i32 ptrtoint (ptr @___asan_gen_.355 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_migrate_task to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.358 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_migrate_task to i32), i32 111, i32 160, i32 ptrtoint (ptr @___asan_gen_.361 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_migrate_task to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.364 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_process_template to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.367 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1131 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_process_template to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.370 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1131 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_process_template to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.373 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1131 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_free to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.376 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_exit to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.379 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_wait_task to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.382 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.384 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_process_wait to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.385 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_process_wait to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.388 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_process_wait to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.391 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_wait to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.394 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_process_fork to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.397 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_process_fork to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.400 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_process_fork to i32), i32 112, i32 160, i32 ptrtoint (ptr @___asan_gen_.403 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_fork to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.406 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_process_exec to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.409 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_process_exec to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.412 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_process_exec to i32), i32 77, i32 128, i32 ptrtoint (ptr @___asan_gen_.415 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_exec to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_stat_template to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.421 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_stat_template to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.424 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_stat_template to i32), i32 85, i32 128, i32 ptrtoint (ptr @___asan_gen_.427 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stat_wait to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.430 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stat_sleep to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.433 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.435 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stat_iowait to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.436 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.438 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stat_blocked to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.439 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.441 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_stat_runtime to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.442 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_stat_runtime to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.445 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_stat_runtime to i32), i32 142, i32 192, i32 ptrtoint (ptr @___asan_gen_.448 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stat_runtime to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.451 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.453 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_pi_setprio to i32), i32 120, i32 160, i32 ptrtoint (ptr @___asan_gen_.454 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_pi_setprio to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.457 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_pi_setprio to i32), i32 88, i32 128, i32 ptrtoint (ptr @___asan_gen_.460 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_pi_setprio to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.463 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_process_hang to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.466 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_process_hang to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.469 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_process_hang to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.472 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_process_hang to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.475 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_move_numa to i32), i32 192, i32 224, i32 ptrtoint (ptr @___asan_gen_.478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_move_numa to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.481 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_move_numa to i32), i32 157, i32 192, i32 ptrtoint (ptr @___asan_gen_.484 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_move_numa to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.487 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_numa_pair_template to i32), i32 264, i32 352, i32 ptrtoint (ptr @___asan_gen_.490 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_numa_pair_template to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.493 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_numa_pair_template to i32), i32 260, i32 352, i32 ptrtoint (ptr @___asan_gen_.496 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_stick_numa to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.499 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.501 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_swap_numa to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.502 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.504 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_fields_sched_wake_idle_without_ipi to i32), i32 48, i32 96, i32 ptrtoint (ptr @___asan_gen_.505 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_event_type_funcs_sched_wake_idle_without_ipi to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.508 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_fmt_sched_wake_idle_without_ipi to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.511 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_sched_wake_idle_without_ipi to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.514 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sysctl_sched_rt_period to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.517 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.519 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_core_count to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.520 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.522 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_core_mutex to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.523 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1242 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_core_put._work to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.526 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.531 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.531 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sysctl_sched_rt_runtime to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.532 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.534 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.1 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.537 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.2 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.540 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.3 to i32), i32 41, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.543 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.4 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.546 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sysctl_sched_uclamp_util_min to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.547 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.549 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sysctl_sched_uclamp_util_max to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.550 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.552 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sysctl_sched_uclamp_util_min_rt_default to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.553 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.555 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_uclamp_used to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.556 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.558 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @uclamp_mutex to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.559 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1272 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @uclamp_default to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.562 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.564 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @force_compatible_cpus_allowed_ptr._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.570 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.5 to i32), i32 55, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.570 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_set_stop_task.stop_pi_lock to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.571 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.573 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.10 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.576 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_numa_balancing to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.577 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.579 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_schedstats to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.580 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.582 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @force_schedstat_enabled._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.591 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.12 to i32), i32 77, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.591 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.13 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.591 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @balance_push_callback to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.592 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.594 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.14 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__nice to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.598 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.15 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__nice to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.604 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.16 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__nice to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.610 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__nice to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.613 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.17 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_setscheduler to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.619 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.18 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_setscheduler to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.625 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.19 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_setscheduler to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.631 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_setscheduler to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.634 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.20 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_setparam to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.640 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.21 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_setparam to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.646 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.22 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_setparam to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.652 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_setparam to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.655 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.657 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.23 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_setattr to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.661 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.24 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_setattr to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.667 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.25 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_setattr to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.673 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_setattr to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.676 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.26 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_getscheduler to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.682 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.27 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_getscheduler to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.688 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.28 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_getscheduler to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.694 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_getscheduler to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.697 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.699 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.29 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_getparam to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.703 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.30 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_getparam to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.709 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.31 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_getparam to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.715 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_getparam to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.718 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.720 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.32 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_getattr to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.724 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.33 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_getattr to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.730 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.34 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_getattr to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.736 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_getattr to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.739 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.35 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_setaffinity to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.745 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.36 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_setaffinity to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.751 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.37 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_setaffinity to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.757 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_setaffinity to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.760 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.38 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_getaffinity to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.766 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.39 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_getaffinity to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.772 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.40 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_getaffinity to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.778 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_getaffinity to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.781 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.783 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.41 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.798 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_yield to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.787 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.798 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.42 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.798 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_yield to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.793 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.798 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.43 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.798 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.44 to i32), i32 33, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_get_priority_max to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.802 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.45 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_get_priority_max to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.808 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.46 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_get_priority_max to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.814 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_get_priority_max to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.817 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.819 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.47 to i32), i32 33, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_get_priority_min to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.823 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.48 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_get_priority_min to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.829 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.49 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_get_priority_min to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.835 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_get_priority_min to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.838 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.840 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.50 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_rr_get_interval to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.844 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.51 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_rr_get_interval to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.850 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.52 to i32), i32 26, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_rr_get_interval to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.856 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_rr_get_interval to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.859 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.53 to i32), i32 39, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_enter__sched_rr_get_interval_time32 to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.865 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.54 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @event_exit__sched_rr_get_interval_time32 to i32), i32 76, i32 128, i32 ptrtoint (ptr @___asan_gen_.871 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.55 to i32), i32 33, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @types__sched_rr_get_interval_time32 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.877 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @args__sched_rr_get_interval_time32 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.880 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_show_task._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.891 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.56 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.891 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.57 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.891 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_show_task._entry.58 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.897 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.59 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.897 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_show_task._entry.61 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.903 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.62 to i32), i32 46, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.903 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.64 to i32), i32 3, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.906 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.65 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.909 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.66 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.912 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.67 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.915 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.68 to i32), i32 3, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.918 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @task_groups to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.919 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.921 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.69 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.924 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_init.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1285 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.930 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.70 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.930 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.71 to i32), i32 73, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.933 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.72 to i32), i32 60, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.939 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.74 to i32), i32 63, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.939 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.75 to i32), i32 63, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.945 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.76 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.945 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.78 to i32), i32 74, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.948 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.81 to i32), i32 35, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.951 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.84 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.954 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.86 to i32), i32 41, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.960 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.87 to i32), i32 13, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.960 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.89 to i32), i32 59, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.963 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.91 to i32), i32 49, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.969 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.92 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.969 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.94 to i32), i32 83, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.972 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @task_group_lock to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.973 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1429 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @max_cfs_quota_period to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.976 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.978 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cpu_files to i32), i32 1216, i32 1504, i32 ptrtoint (ptr @___asan_gen_.979 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.981 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cpu_legacy_files to i32), i32 1672, i32 2112, i32 ptrtoint (ptr @___asan_gen_.982 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.984 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cpu_cgrp_subsys to i32), i32 172, i32 224, i32 ptrtoint (ptr @___asan_gen_.985 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.987 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dump_cpu_task._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.996 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.96 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.996 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.97 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.996 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_prio_to_weight to i32), i32 160, i32 192, i32 ptrtoint (ptr @___asan_gen_.997 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.999 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_prio_to_wmult to i32), i32 160, i32 192, i32 ptrtoint (ptr @___asan_gen_.1000 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1002 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.98 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.99 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.100 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.101 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.102 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.103 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.104 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.105 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.106 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.107 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.108 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.109 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.110 to i32), i32 39, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.111 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.112 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.113 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.114 to i32), i32 40, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.115 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.116 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.117 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.118 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.119 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.120 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.121 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.122 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.123 to i32), i32 97, i32 160, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @trace_raw_output_sched_switch.__flags to i32), i32 72, i32 128, i32 ptrtoint (ptr @___asan_gen_.1081 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.124 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.125 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.126 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.127 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.128 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.129 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.130 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.131 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.132 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.133 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.134 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.135 to i32), i32 1, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1119 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.136 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.137 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.138 to i32), i32 48, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1128 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.139 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1131 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.140 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.141 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.142 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.143 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.144 to i32), i32 43, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1146 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.145 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.146 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.147 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.148 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.149 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1161 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.150 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.151 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.152 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1170 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.153 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.154 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.155 to i32), i32 51, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1179 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.156 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.157 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.158 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1188 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.159 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.160 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.161 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.162 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.163 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.164 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.165 to i32), i32 68, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1209 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.166 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.167 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.168 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.169 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.170 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.171 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.172 to i32), i32 115, i32 160, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1230 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.173 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.174 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.175 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1242 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.176 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1242 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @sched_core_mask to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1243 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1245 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.177 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1251 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.178 to i32), i32 71, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1251 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.179 to i32), i32 39, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1254 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.180 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1257 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.181 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1263 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.182 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1263 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.183 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1266 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.184 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1272 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.185 to i32), i32 13, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1272 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.186 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.187 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1278 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.189 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1281 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.190 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1284 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_completion.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1285 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1290 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.192 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1290 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.193 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1293 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.194 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1296 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @setup_schedstats._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1305 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.195 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1305 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.196 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1305 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @select_fallback_rq._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1311 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.197 to i32), i32 43, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1311 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.198 to i32), i32 37, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1314 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @setup_resched_latency_warn_ms._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1323 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.200 to i32), i32 41, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1323 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.201 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1323 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cpu_resched_latency.warned_once to i32), i32 1, i32 32, i32 ptrtoint (ptr @___asan_gen_.1324 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 0, i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.202 to i32), i32 47, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1327 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @schedule_debug._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.204 to i32), i32 55, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.205 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1336 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.208 to i32), i32 46, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1342 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.209 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1342 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.210 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1345 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.214 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1348 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.215 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.216 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.217 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1357 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.218 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1360 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.219 to i32), i32 38, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1363 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.220 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1366 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.221 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.222 to i32), i32 13, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.223 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.224 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1378 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.225 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1381 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.227 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.228 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.229 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1390 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.230 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.231 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1396 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.232 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1399 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @task_index_to_char.state_char to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1400 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1402 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.233 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1405 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @num_cpus_frozen to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1406 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1408 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dump_rq_tasks._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1417 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.238 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1417 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.239 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1417 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dump_rq_tasks._entry.240 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.1418 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1423 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.241 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1423 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.243 to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1426 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.244 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1429 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.245 to i32), i32 80, i32 128, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1432 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.246 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1435 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.247 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1438 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.248 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1441 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.249 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1444 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.250 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1447 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @cfs_constraints_mutex to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.1448 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1456 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.251 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1456 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.252 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1456 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.253 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1459 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.254 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1462 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.255 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1465 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.256 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1468 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.257 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1471 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.258 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1474 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.259 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1477 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.260 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.1478 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1480 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @switch.table.__se_sys_sched_get_priority_max to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1481 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 0, i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @switch.table.__se_sys_sched_get_priority_min to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 ptrtoint (ptr @___asan_gen_.1479 to i32), i32 0, i32 0, i32 -1 }]
@llvm.used = appending global [2 x ptr] [ptr @asan.module_ctor, ptr @asan.module_dtor], section "llvm.metadata"
@llvm.global_ctors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_ctor, ptr null }]
@llvm.global_dtors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_dtor, ptr null }]

@sys_nice = dso_local alias i32 (i32), ptr @__se_sys_nice
@sys_sched_setscheduler = dso_local alias i32 (i32, i32, ptr), ptr @__se_sys_sched_setscheduler
@sys_sched_setparam = dso_local alias i32 (i32, ptr), ptr @__se_sys_sched_setparam
@sys_sched_setattr = dso_local alias i32 (i32, ptr, i32), ptr @__se_sys_sched_setattr
@sys_sched_getscheduler = dso_local alias i32 (i32), ptr @__se_sys_sched_getscheduler
@sys_sched_getparam = dso_local alias i32 (i32, ptr), ptr @__se_sys_sched_getparam
@sys_sched_getattr = dso_local alias i32 (i32, ptr, i32, i32), ptr @__se_sys_sched_getattr
@sys_sched_setaffinity = dso_local alias i32 (i32, i32, ptr), ptr @__se_sys_sched_setaffinity
@sys_sched_getaffinity = dso_local alias i32 (i32, i32, ptr), ptr @__se_sys_sched_getaffinity
@sys_sched_get_priority_max = dso_local alias i32 (i32), ptr @__se_sys_sched_get_priority_max
@sys_sched_get_priority_min = dso_local alias i32 (i32), ptr @__se_sys_sched_get_priority_min
@sys_sched_rr_get_interval = dso_local alias i32 (i32, ptr), ptr @__se_sys_sched_rr_get_interval
@sys_sched_rr_get_interval_time32 = dso_local alias i32 (i32, ptr), ptr @__se_sys_sched_rr_get_interval_time32

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_kthread_stop(ptr nocapture readnone %__data, ptr noundef %t) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_kthread_stop, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %t) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #1

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #1

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_kthread_stop_ret(ptr nocapture readnone %__data, i32 noundef %ret) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_kthread_stop_ret, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, i32 noundef %ret) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_kthread_work_queue_work(ptr nocapture readnone %__data, ptr noundef %worker, ptr noundef %work) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_kthread_work_queue_work, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %worker, ptr noundef %work) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_kthread_work_execute_start(ptr nocapture readnone %__data, ptr noundef %work) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_kthread_work_execute_start, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %work) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_kthread_work_execute_end(ptr nocapture readnone %__data, ptr noundef %work, ptr noundef %function) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_kthread_work_execute_end, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %work, ptr noundef %function) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_waking(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_waking, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_wakeup(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_wakeup_new(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup_new, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_switch(ptr nocapture readnone %__data, i1 noundef zeroext %preempt, ptr noundef %prev, ptr noundef %next) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_switch, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, i1 noundef zeroext %preempt, ptr noundef %prev, ptr noundef %next) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool10.not = icmp eq ptr %6, null
  br i1 %tobool10.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_migrate_task(ptr nocapture readnone %__data, ptr noundef %p, i32 noundef %dest_cpu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_migrate_task, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p, i32 noundef %dest_cpu) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_free(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_free, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_exit(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_exit, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_wait_task(ptr nocapture readnone %__data, ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wait_task, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_wait(ptr nocapture readnone %__data, ptr noundef %pid) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_wait, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %pid) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_fork(ptr nocapture readnone %__data, ptr noundef %parent, ptr noundef %child) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_fork, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %parent, ptr noundef %child) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_exec(ptr nocapture readnone %__data, ptr noundef %p, i32 noundef %old_pid, ptr noundef %bprm) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_exec, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %p, i32 noundef %old_pid, ptr noundef %bprm) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stat_wait(ptr nocapture readnone %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stat_wait, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i64 noundef %delay) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stat_sleep(ptr nocapture readnone %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stat_sleep, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i64 noundef %delay) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stat_iowait(ptr nocapture readnone %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stat_iowait, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i64 noundef %delay) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stat_blocked(ptr nocapture readnone %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stat_blocked, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i64 noundef %delay) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stat_runtime(ptr nocapture readnone %__data, ptr noundef %tsk, i64 noundef %runtime, i64 noundef %vruntime) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stat_runtime, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i64 noundef %runtime, i64 noundef %vruntime) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_pi_setprio(ptr nocapture readnone %__data, ptr noundef %tsk, ptr noundef %pi_task) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_pi_setprio, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, ptr noundef %pi_task) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_process_hang(ptr nocapture readnone %__data, ptr noundef %tsk) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_process_hang, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_move_numa(ptr nocapture readnone %__data, ptr noundef %tsk, i32 noundef %src_cpu, i32 noundef %dst_cpu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_move_numa, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %tsk, i32 noundef %src_cpu, i32 noundef %dst_cpu) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_stick_numa(ptr nocapture readnone %__data, ptr noundef %src_tsk, i32 noundef %src_cpu, ptr noundef %dst_tsk, i32 noundef %dst_cpu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_stick_numa, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %src_tsk, i32 noundef %src_cpu, ptr noundef %dst_tsk, i32 noundef %dst_cpu) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_swap_numa(ptr nocapture readnone %__data, ptr noundef %src_tsk, i32 noundef %src_cpu, ptr noundef %dst_tsk, i32 noundef %dst_cpu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_swap_numa, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %src_tsk, i32 noundef %src_cpu, ptr noundef %dst_tsk, i32 noundef %dst_cpu) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_wake_idle_without_ipi(ptr nocapture readnone %__data, i32 noundef %cpu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wake_idle_without_ipi, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, i32 noundef %cpu) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_cfs_tp(ptr nocapture readnone %__data, ptr noundef %cfs_rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_cfs_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %cfs_rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_rt_tp(ptr nocapture readnone %__data, ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_rt_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_dl_tp(ptr nocapture readnone %__data, ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_dl_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_thermal_tp(ptr nocapture readnone %__data, ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_thermal_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_irq_tp(ptr nocapture readnone %__data, ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_irq_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_pelt_se_tp(ptr nocapture readnone %__data, ptr noundef %se) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_pelt_se_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %se) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_cpu_capacity_tp(ptr nocapture readnone %__data, ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_cpu_capacity_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_overutilized_tp(ptr nocapture readnone %__data, ptr noundef %rd, i1 noundef zeroext %overutilized) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_overutilized_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rd, i1 noundef zeroext %overutilized) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool10.not = icmp eq ptr %6, null
  br i1 %tobool10.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_util_est_cfs_tp(ptr nocapture readnone %__data, ptr noundef %cfs_rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_util_est_cfs_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %cfs_rq) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_util_est_se_tp(ptr nocapture readnone %__data, ptr noundef %se) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_util_est_se_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %se) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__traceiter_sched_update_nr_running_tp(ptr nocapture readnone %__data, ptr noundef %rq, i32 noundef %change) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_update_nr_running_tp, i32 0, i32 7), align 4
  %tobool.not = icmp eq ptr %0, null
  br i1 %tobool.not, label %if.end, label %do.body2

do.body2:                                         ; preds = %do.body2, %entry
  %it_func_ptr.0 = phi ptr [ %incdec.ptr, %do.body2 ], [ %0, %entry ]
  %1 = ptrtoint ptr %it_func_ptr.0 to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile ptr, ptr %it_func_ptr.0, align 4
  %data = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0, i32 0, i32 1
  %3 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %data, align 4
  tail call void %2(ptr noundef %4, ptr noundef %rq, i32 noundef %change) #33
  %incdec.ptr = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0, i32 1
  %5 = ptrtoint ptr %incdec.ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %incdec.ptr, align 4
  %tobool9.not = icmp eq ptr %6, null
  br i1 %tobool9.not, label %if.end, label %do.body2

if.end:                                           ; preds = %do.body2, %entry
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_kthread_stop(ptr noundef %__data, ptr nocapture noundef readonly %t) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 28) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %t, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %t, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_kthread_stop(ptr noundef %__data, ptr nocapture noundef readonly %t) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 28, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %t, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %t, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 4
  %31 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %rctx, align 4
  %33 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 28, i32 noundef %32, ptr noundef %__data, i64 noundef 1, ptr noundef %34, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @trace_event_reg(ptr noundef, i32 noundef, ptr noundef) #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @trace_event_raw_init(ptr noundef) #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_kthread_stop_ret(ptr noundef %__data, i32 noundef %ret) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 12) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %ret6 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop_ret, ptr %call3, i32 0, i32 1
  %3 = ptrtoint ptr %ret6 to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 %ret, ptr %ret6, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_kthread_stop_ret(ptr noundef %__data, i32 noundef %ret) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 12, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %ret17 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop_ret, ptr %call13, i32 0, i32 1
  %27 = ptrtoint ptr %ret17 to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %ret, ptr %ret17, align 4
  %28 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %rctx, align 4
  %30 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 12, i32 noundef %29, ptr noundef %__data, i64 noundef 1, ptr noundef %31, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_kthread_work_queue_work(ptr noundef %__data, ptr noundef %worker, ptr noundef %work) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 20) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %work6 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call3, i32 0, i32 1
  %3 = ptrtoint ptr %work6 to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %work, ptr %work6, align 4
  %func = getelementptr inbounds %struct.kthread_work, ptr %work, i32 0, i32 1
  %4 = ptrtoint ptr %func to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %func, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %function to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr %5, ptr %function, align 4
  %worker7 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call3, i32 0, i32 3
  %7 = ptrtoint ptr %worker7 to i32
  call void @__asan_store4_noabort(i32 %7)
  store ptr %worker, ptr %worker7, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_kthread_work_queue_work(ptr noundef %__data, ptr noundef %worker, ptr noundef %work) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 20, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %work17 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call13, i32 0, i32 1
  %27 = ptrtoint ptr %work17 to i32
  call void @__asan_store4_noabort(i32 %27)
  store ptr %work, ptr %work17, align 4
  %func = getelementptr inbounds %struct.kthread_work, ptr %work, i32 0, i32 1
  %28 = ptrtoint ptr %func to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %func, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %function to i32
  call void @__asan_store4_noabort(i32 %30)
  store ptr %29, ptr %function, align 4
  %worker18 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %call13, i32 0, i32 3
  %31 = ptrtoint ptr %worker18 to i32
  call void @__asan_store4_noabort(i32 %31)
  store ptr %worker, ptr %worker18, align 4
  %32 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %rctx, align 4
  %34 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 20, i32 noundef %33, ptr noundef %__data, i64 noundef 1, ptr noundef %35, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_kthread_work_execute_start(ptr noundef %__data, ptr noundef %work) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 16) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %work6 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %call3, i32 0, i32 1
  %3 = ptrtoint ptr %work6 to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %work, ptr %work6, align 4
  %func = getelementptr inbounds %struct.kthread_work, ptr %work, i32 0, i32 1
  %4 = ptrtoint ptr %func to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %func, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %function to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr %5, ptr %function, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_kthread_work_execute_start(ptr noundef %__data, ptr noundef %work) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 20, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %work17 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %call13, i32 0, i32 1
  %27 = ptrtoint ptr %work17 to i32
  call void @__asan_store4_noabort(i32 %27)
  store ptr %work, ptr %work17, align 4
  %func = getelementptr inbounds %struct.kthread_work, ptr %work, i32 0, i32 1
  %28 = ptrtoint ptr %func to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %func, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %function to i32
  call void @__asan_store4_noabort(i32 %30)
  store ptr %29, ptr %function, align 4
  %31 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %rctx, align 4
  %33 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 20, i32 noundef %32, ptr noundef %__data, i64 noundef 1, ptr noundef %34, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_kthread_work_execute_end(ptr noundef %__data, ptr noundef %work, ptr noundef %function) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 16) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %work6 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %call3, i32 0, i32 1
  %3 = ptrtoint ptr %work6 to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %work, ptr %work6, align 4
  %function7 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %call3, i32 0, i32 2
  %4 = ptrtoint ptr %function7 to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr %function, ptr %function7, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_kthread_work_execute_end(ptr noundef %__data, ptr noundef %work, ptr noundef %function) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 20, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %work17 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %call13, i32 0, i32 1
  %27 = ptrtoint ptr %work17 to i32
  call void @__asan_store4_noabort(i32 %27)
  store ptr %work, ptr %work17, align 4
  %function18 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %call13, i32 0, i32 2
  %28 = ptrtoint ptr %function18 to i32
  call void @__asan_store4_noabort(i32 %28)
  store ptr %function, ptr %function18, align 4
  %29 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %rctx, align 4
  %31 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 20, i32 noundef %30, ptr noundef %__data, i64 noundef 1, ptr noundef %32, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_wakeup_template(ptr noundef %__data, ptr nocapture noundef readonly %p) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 36) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %7 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %prio, align 8
  %prio9 = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %prio9 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %prio9, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %10 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 3
  %12 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %cpu.i, align 4
  %target_cpu = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call3, i32 0, i32 4
  %14 = ptrtoint ptr %target_cpu to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %13, ptr %target_cpu, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_wakeup_template(ptr noundef %__data, ptr noundef %p) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %10 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile ptr, ptr %prog_array.i, align 4
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 36, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %entry
  %12 = ptrtoint ptr %3 to i32
  %add = add i32 %9, %12
  %13 = inttoptr i32 %add to ptr
  %14 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %__regs, align 4
  %16 = call ptr @llvm.returnaddress(i32 0) #33
  %17 = ptrtoint ptr %16 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %15, i32 0, i32 15
  %18 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %17, ptr %arrayidx.i, align 4
  %19 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %20 = ptrtoint ptr %19 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %15, i32 0, i32 11
  %21 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %20, ptr %arrayidx2.i, align 4
  %22 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %15, i32 0, i32 13
  %23 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %15, i32 0, i32 16
  %24 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %25 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %26 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call13, i32 0, i32 2
  %28 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 %27, ptr %pid19, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %29 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %prio, align 8
  %prio20 = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call13, i32 0, i32 3
  %31 = ptrtoint ptr %prio20 to i32
  call void @__asan_store4_noabort(i32 %31)
  store i32 %30, ptr %prio20, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %32 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %33, i32 0, i32 3
  %34 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load volatile i32, ptr %cpu.i, align 4
  %target_cpu = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %call13, i32 0, i32 4
  %36 = ptrtoint ptr %target_cpu to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 %35, ptr %target_cpu, align 4
  %37 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %rctx, align 4
  %39 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 36, i32 noundef %38, ptr noundef %__data, i64 noundef 1, ptr noundef %40, ptr noundef %13, ptr noundef %p) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %entry
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_switch(ptr noundef %__data, i1 noundef zeroext %preempt, ptr noundef %prev, ptr nocapture noundef readonly %next) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 60) #33
  %tobool4.not = icmp eq ptr %call3, null
  br i1 %tobool4.not, label %cleanup, label %if.end6

if.end6:                                          ; preds = %if.end
  %next_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 5
  %comm = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %next_comm, ptr %comm, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %prev_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %prev_pid to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %prev_pid, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 13
  %7 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %prio, align 8
  %prev_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %prev_prio to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %prev_prio, align 4
  %10 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 2
  %12 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task.i, align 8
  %cmp.not.i = icmp eq ptr %13, %prev
  br i1 %cmp.not.i, label %do.end7.i, label %do.body2.i, !prof !1191

do.body2.i:                                       ; preds = %if.end6
  call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22include/trace/events/sched.h\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 195, 0\0A.popsection", ""() #33, !srcloc !1194
  unreachable

do.end7.i:                                        ; preds = %if.end6
  br i1 %preempt, label %__trace_sched_switch_state.exit, label %if.end10.i

if.end10.i:                                       ; preds = %do.end7.i
  %14 = ptrtoint ptr %prev to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %prev, align 128
  %exit_state.i.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 57
  %16 = ptrtoint ptr %exit_state.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %exit_state.i.i, align 4
  %or.i.i = or i32 %17, %15
  %and.i16.i = and i32 %or.i.i, 127
  %cmp.i.i = icmp eq i32 %15, 1026
  %spec.store.select.i.i = select i1 %cmp.i.i, i32 128, i32 %and.i16.i
  %tobool.not.i.i.i = icmp eq i32 %spec.store.select.i.i, 0
  %18 = call i32 @llvm.ctlz.i32(i32 %spec.store.select.i.i, i1 true) #33, !range !1195
  %sub.i.i.i = sub nuw nsw i32 32, %18
  %cond.i.i.i = select i1 %tobool.not.i.i.i, i32 0, i32 %sub.i.i.i
  %tobool12.not.i = icmp eq i32 %cond.i.i.i, 0
  %sub.i = add nsw i32 %cond.i.i.i, -1
  %shl.i = shl nuw i32 1, %sub.i
  %cond.i = select i1 %tobool12.not.i, i32 0, i32 %shl.i
  br label %__trace_sched_switch_state.exit

__trace_sched_switch_state.exit:                  ; preds = %if.end10.i, %do.end7.i
  %retval.0.i35 = phi i32 [ %cond.i, %if.end10.i ], [ 256, %do.end7.i ]
  %prev_state = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 4
  %19 = ptrtoint ptr %prev_state to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %retval.0.i35, ptr %prev_state, align 4
  %prev_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 1
  %comm11 = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 101
  %20 = call ptr @memcpy(ptr %prev_comm, ptr %comm11, i32 16)
  %pid13 = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 68
  %21 = ptrtoint ptr %pid13 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %pid13, align 8
  %next_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 6
  %23 = ptrtoint ptr %next_pid to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %next_pid, align 4
  %prio14 = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 13
  %24 = ptrtoint ptr %prio14 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %prio14, align 8
  %next_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call3, i32 0, i32 7
  %26 = ptrtoint ptr %next_prio to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %25, ptr %next_prio, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %__trace_sched_switch_state.exit, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_switch(ptr noundef %__data, i1 noundef zeroext %preempt, ptr noundef %prev, ptr nocapture noundef readonly %next) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true8, label %if.end

land.lhs.true8:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true8, %entry
  %call14 = call ptr @perf_trace_buf_alloc(i32 noundef 60, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool15.not = icmp eq ptr %call14, null
  br i1 %tobool15.not, label %cleanup, label %if.end17

if.end17:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %next_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 5
  %comm = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %next_comm, ptr %comm, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %prev_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 2
  %30 = ptrtoint ptr %prev_pid to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %prev_pid, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 13
  %31 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %prio, align 8
  %prev_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 3
  %33 = ptrtoint ptr %prev_prio to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %32, ptr %prev_prio, align 4
  %34 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 2
  %36 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %task.i, align 8
  %cmp.not.i = icmp eq ptr %37, %prev
  br i1 %cmp.not.i, label %do.end7.i, label %do.body2.i, !prof !1191

do.body2.i:                                       ; preds = %if.end17
  call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22include/trace/events/sched.h\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 195, 0\0A.popsection", ""() #33, !srcloc !1194
  unreachable

do.end7.i:                                        ; preds = %if.end17
  br i1 %preempt, label %__trace_sched_switch_state.exit, label %if.end10.i

if.end10.i:                                       ; preds = %do.end7.i
  %38 = ptrtoint ptr %prev to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %prev, align 128
  %exit_state.i.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 57
  %40 = ptrtoint ptr %exit_state.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %exit_state.i.i, align 4
  %or.i.i = or i32 %41, %39
  %and.i16.i = and i32 %or.i.i, 127
  %cmp.i.i = icmp eq i32 %39, 1026
  %spec.store.select.i.i = select i1 %cmp.i.i, i32 128, i32 %and.i16.i
  %tobool.not.i.i.i = icmp eq i32 %spec.store.select.i.i, 0
  %42 = call i32 @llvm.ctlz.i32(i32 %spec.store.select.i.i, i1 true) #33, !range !1195
  %sub.i.i.i = sub nuw nsw i32 32, %42
  %cond.i.i.i = select i1 %tobool.not.i.i.i, i32 0, i32 %sub.i.i.i
  %tobool12.not.i = icmp eq i32 %cond.i.i.i, 0
  %sub.i = add nsw i32 %cond.i.i.i, -1
  %shl.i = shl nuw i32 1, %sub.i
  %cond.i = select i1 %tobool12.not.i, i32 0, i32 %shl.i
  br label %__trace_sched_switch_state.exit

__trace_sched_switch_state.exit:                  ; preds = %if.end10.i, %do.end7.i
  %retval.0.i = phi i32 [ %cond.i, %if.end10.i ], [ 256, %do.end7.i ]
  %prev_state = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 4
  %43 = ptrtoint ptr %prev_state to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 %retval.0.i, ptr %prev_state, align 4
  %prev_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 1
  %comm22 = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 101
  %44 = call ptr @memcpy(ptr %prev_comm, ptr %comm22, i32 16)
  %pid24 = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 68
  %45 = ptrtoint ptr %pid24 to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %pid24, align 8
  %next_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 6
  %47 = ptrtoint ptr %next_pid to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 %46, ptr %next_pid, align 4
  %prio25 = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 13
  %48 = ptrtoint ptr %prio25 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %prio25, align 8
  %next_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %call14, i32 0, i32 7
  %50 = ptrtoint ptr %next_prio to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 %49, ptr %next_prio, align 4
  %51 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %rctx, align 4
  %53 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call14, i32 noundef 60, i32 noundef %52, ptr noundef %__data, i64 noundef 1, ptr noundef %54, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %__trace_sched_switch_state.exit, %if.end, %land.lhs.true8
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_migrate_task(ptr noundef %__data, ptr nocapture noundef readonly %p, i32 noundef %dest_cpu) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 40) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %7 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %prio, align 8
  %prio9 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %prio9 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %prio9, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %10 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 3
  %12 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %cpu.i, align 4
  %orig_cpu = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call3, i32 0, i32 4
  %14 = ptrtoint ptr %orig_cpu to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %13, ptr %orig_cpu, align 4
  %dest_cpu11 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call3, i32 0, i32 5
  %15 = ptrtoint ptr %dest_cpu11 to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 %dest_cpu, ptr %dest_cpu11, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_migrate_task(ptr noundef %__data, ptr nocapture noundef readonly %p, i32 noundef %dest_cpu) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 44, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %31 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %prio, align 8
  %prio20 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call13, i32 0, i32 3
  %33 = ptrtoint ptr %prio20 to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %32, ptr %prio20, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %34 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 3
  %36 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %cpu.i, align 4
  %orig_cpu = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call13, i32 0, i32 4
  %38 = ptrtoint ptr %orig_cpu to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %37, ptr %orig_cpu, align 4
  %dest_cpu22 = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %call13, i32 0, i32 5
  %39 = ptrtoint ptr %dest_cpu22 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 %dest_cpu, ptr %dest_cpu22, align 4
  %40 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %rctx, align 4
  %42 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 44, i32 noundef %41, ptr noundef %__data, i64 noundef 1, ptr noundef %43, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_process_template(ptr noundef %__data, ptr nocapture noundef readonly %p) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 32) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %7 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %prio, align 8
  %prio9 = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %prio9 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %prio9, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_process_template(ptr noundef %__data, ptr nocapture noundef readonly %p) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 36, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %31 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %prio, align 8
  %prio20 = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %call13, i32 0, i32 3
  %33 = ptrtoint ptr %prio20 to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %32, ptr %prio20, align 4
  %34 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %rctx, align 4
  %36 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 36, i32 noundef %35, ptr noundef %__data, i64 noundef 1, ptr noundef %37, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_process_wait(ptr noundef %__data, ptr noundef readonly %pid) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 32) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call3, i32 0, i32 1
  %3 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i23 = and i32 %3, -16384
  %4 = inttoptr i32 %and.i23 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %4, i32 0, i32 2
  %5 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %task, align 8
  %comm7 = getelementptr inbounds %struct.task_struct, ptr %6, i32 0, i32 101
  %7 = call ptr @memcpy(ptr %comm, ptr %comm7, i32 16)
  %tobool.not.i24 = icmp eq ptr %pid, null
  br i1 %tobool.not.i24, label %pid_nr.exit, label %if.then.i

if.then.i:                                        ; preds = %if.end5
  %numbers.i = getelementptr inbounds %struct.pid, ptr %pid, i32 0, i32 7
  %8 = ptrtoint ptr %numbers.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %numbers.i, align 4
  br label %pid_nr.exit

pid_nr.exit:                                      ; preds = %if.then.i, %if.end5
  %nr.0.i = phi i32 [ %9, %if.then.i ], [ 0, %if.end5 ]
  %pid10 = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call3, i32 0, i32 2
  %10 = ptrtoint ptr %pid10 to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %nr.0.i, ptr %pid10, align 4
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %prio = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 13
  %13 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %prio, align 8
  %prio13 = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call3, i32 0, i32 3
  %15 = ptrtoint ptr %prio13 to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 %14, ptr %prio13, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %pid_nr.exit, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_process_wait(ptr noundef %__data, ptr noundef readonly %pid) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 36, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call13, i32 0, i32 1
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %27 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task, align 8
  %comm18 = getelementptr inbounds %struct.task_struct, ptr %28, i32 0, i32 101
  %29 = call ptr @memcpy(ptr %comm, ptr %comm18, i32 16)
  %tobool.not.i46 = icmp eq ptr %pid, null
  br i1 %tobool.not.i46, label %pid_nr.exit, label %if.then.i

if.then.i:                                        ; preds = %if.end16
  %numbers.i = getelementptr inbounds %struct.pid, ptr %pid, i32 0, i32 7
  %30 = ptrtoint ptr %numbers.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %numbers.i, align 4
  br label %pid_nr.exit

pid_nr.exit:                                      ; preds = %if.then.i, %if.end16
  %nr.0.i = phi i32 [ %31, %if.then.i ], [ 0, %if.end16 ]
  %pid21 = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call13, i32 0, i32 2
  %32 = ptrtoint ptr %pid21 to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %nr.0.i, ptr %pid21, align 4
  %33 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %task, align 8
  %prio = getelementptr inbounds %struct.task_struct, ptr %34, i32 0, i32 13
  %35 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %prio, align 8
  %prio24 = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %call13, i32 0, i32 3
  %37 = ptrtoint ptr %prio24 to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 %36, ptr %prio24, align 4
  %38 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %rctx, align 4
  %40 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 36, i32 noundef %39, ptr noundef %__data, i64 noundef 1, ptr noundef %41, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %pid_nr.exit, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_process_fork(ptr noundef %__data, ptr nocapture noundef readonly %parent, ptr nocapture noundef readonly %child) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 48) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %parent_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call3, i32 0, i32 1
  %comm = getelementptr inbounds %struct.task_struct, ptr %parent, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %parent_comm, ptr %comm, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %parent, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %parent_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %parent_pid to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %parent_pid, align 4
  %child_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call3, i32 0, i32 3
  %comm8 = getelementptr inbounds %struct.task_struct, ptr %child, i32 0, i32 101
  %7 = call ptr @memcpy(ptr %child_comm, ptr %comm8, i32 16)
  %pid10 = getelementptr inbounds %struct.task_struct, ptr %child, i32 0, i32 68
  %8 = ptrtoint ptr %pid10 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %pid10, align 8
  %child_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call3, i32 0, i32 4
  %10 = ptrtoint ptr %child_pid to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %9, ptr %child_pid, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_process_fork(ptr noundef %__data, ptr nocapture noundef readonly %parent, ptr nocapture noundef readonly %child) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 52, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %parent_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call13, i32 0, i32 1
  %comm = getelementptr inbounds %struct.task_struct, ptr %parent, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %parent_comm, ptr %comm, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %parent, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %parent_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %parent_pid to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %parent_pid, align 4
  %child_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call13, i32 0, i32 3
  %comm19 = getelementptr inbounds %struct.task_struct, ptr %child, i32 0, i32 101
  %31 = call ptr @memcpy(ptr %child_comm, ptr %comm19, i32 16)
  %pid21 = getelementptr inbounds %struct.task_struct, ptr %child, i32 0, i32 68
  %32 = ptrtoint ptr %pid21 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %pid21, align 8
  %child_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %call13, i32 0, i32 4
  %34 = ptrtoint ptr %child_pid to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 %33, ptr %child_pid, align 4
  %35 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %rctx, align 4
  %37 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 52, i32 noundef %36, ptr noundef %__data, i64 noundef 1, ptr noundef %38, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_process_exec(ptr noundef %__data, ptr nocapture noundef readonly %p, i32 noundef %old_pid, ptr nocapture noundef readonly %bprm) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %filename.i = getelementptr inbounds %struct.linux_binprm, ptr %bprm, i32 0, i32 14
  %3 = ptrtoint ptr %filename.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %filename.i, align 4
  %tobool.not.i27 = icmp eq ptr %4, null
  %spec.select.i = select i1 %tobool.not.i27, ptr @.str.145, ptr %4
  %call.i28 = tail call i32 @strlen(ptr noundef nonnull %spec.select.i) #35
  %add = add i32 %call.i28, 21
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef %add) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %add.i = shl i32 %call.i28, 16
  %or.i = add i32 %add.i, 65556
  %__data_loc_filename = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call3, i32 0, i32 1
  %5 = ptrtoint ptr %__data_loc_filename to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 %or.i, ptr %__data_loc_filename, align 4
  %add.ptr = getelementptr i8, ptr %call3, i32 20
  %6 = ptrtoint ptr %filename.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %filename.i, align 4
  %tobool8.not = icmp eq ptr %7, null
  %spec.select = select i1 %tobool8.not, ptr @.str.145, ptr %7
  %call10 = call ptr @strcpy(ptr noundef %add.ptr, ptr noundef nonnull %spec.select) #36
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %8 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %pid, align 8
  %pid11 = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call3, i32 0, i32 2
  %10 = ptrtoint ptr %pid11 to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %9, ptr %pid11, align 4
  %old_pid12 = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call3, i32 0, i32 3
  %11 = ptrtoint ptr %old_pid12 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 %old_pid, ptr %old_pid12, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_process_exec(ptr noundef %__data, ptr nocapture noundef readonly %p, i32 noundef %old_pid, ptr nocapture noundef readonly %bprm) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %filename.i = getelementptr inbounds %struct.linux_binprm, ptr %bprm, i32 0, i32 14
  %2 = ptrtoint ptr %filename.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %filename.i, align 4
  %tobool.not.i = icmp eq ptr %3, null
  %spec.select.i = select i1 %tobool.not.i, ptr @.str.145, ptr %3
  %call.i = tail call i32 @strlen(ptr noundef nonnull %spec.select.i) #35
  %add.i = shl i32 %call.i, 16
  %or.i = add i32 %add.i, 65556
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %4 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %perf_events, align 4
  %6 = ptrtoint ptr %5 to i32
  %7 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 3
  %9 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %10
  %11 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %arrayidx, align 4
  %add = add i32 %12, %6
  %13 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %14 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %15, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %16 = ptrtoint ptr %13 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile ptr, ptr %13, align 4
  %tobool.not.i51.not = icmp eq ptr %17, null
  br i1 %tobool.not.i51.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %add12 = add i32 %call.i, 32
  %and = and i32 %add12, -8
  %sub = add i32 %and, -4
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef %sub, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %18 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %__regs, align 4
  %20 = call ptr @llvm.returnaddress(i32 0) #33
  %21 = ptrtoint ptr %20 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %19, i32 0, i32 15
  %22 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %21, ptr %arrayidx.i, align 4
  %23 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %24 = ptrtoint ptr %23 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %19, i32 0, i32 11
  %25 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx2.i, align 4
  %26 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %19, i32 0, i32 13
  %27 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %26, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %19, i32 0, i32 16
  %28 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 19, ptr %arrayidx6.i, align 4
  %__data_loc_filename = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call13, i32 0, i32 1
  %29 = ptrtoint ptr %__data_loc_filename to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %or.i, ptr %__data_loc_filename, align 4
  %add.ptr = getelementptr i8, ptr %call13, i32 20
  %30 = ptrtoint ptr %filename.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %filename.i, align 4
  %tobool20.not = icmp eq ptr %31, null
  %spec.select = select i1 %tobool20.not, ptr @.str.145, ptr %31
  %call22 = call ptr @strcpy(ptr noundef %add.ptr, ptr noundef nonnull %spec.select) #36
  %pid = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %32 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %pid, align 8
  %pid23 = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call13, i32 0, i32 2
  %34 = ptrtoint ptr %pid23 to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 %33, ptr %pid23, align 4
  %old_pid24 = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %call13, i32 0, i32 3
  %35 = ptrtoint ptr %old_pid24 to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 %old_pid, ptr %old_pid24, align 4
  %36 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %rctx, align 4
  %38 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef %sub, i32 noundef %37, ptr noundef %__data, i64 noundef 1, ptr noundef %39, ptr noundef %13, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_stat_template(ptr noundef %__data, ptr nocapture noundef readonly %tsk, i64 noundef %delay) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 40) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 8
  %delay9 = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call3, i32 0, i32 3
  %7 = ptrtoint ptr %delay9 to i32
  call void @__asan_store8_noabort(i32 %7)
  store i64 %delay, ptr %delay9, align 8
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_stat_template(ptr noundef %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %10 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile ptr, ptr %prog_array.i, align 4
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 44, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %entry
  %12 = ptrtoint ptr %3 to i32
  %add = add i32 %9, %12
  %13 = inttoptr i32 %add to ptr
  %14 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %__regs, align 4
  %16 = call ptr @llvm.returnaddress(i32 0) #33
  %17 = ptrtoint ptr %16 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %15, i32 0, i32 15
  %18 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %17, ptr %arrayidx.i, align 4
  %19 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %20 = ptrtoint ptr %19 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %15, i32 0, i32 11
  %21 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %20, ptr %arrayidx2.i, align 4
  %22 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %15, i32 0, i32 13
  %23 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %15, i32 0, i32 16
  %24 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %25 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %26 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call13, i32 0, i32 2
  %28 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 %27, ptr %pid19, align 8
  %delay20 = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %call13, i32 0, i32 3
  %29 = ptrtoint ptr %delay20 to i32
  call void @__asan_store8_noabort(i32 %29)
  store i64 %delay, ptr %delay20, align 8
  %30 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %rctx, align 4
  %32 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 44, i32 noundef %31, ptr noundef %__data, i64 noundef %delay, ptr noundef %33, ptr noundef %13, ptr noundef %tsk) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %entry
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_stat_runtime(ptr noundef %__data, ptr nocapture noundef readonly %tsk, i64 noundef %runtime, i64 noundef %vruntime) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 48) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 8
  %runtime9 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call3, i32 0, i32 3
  %7 = ptrtoint ptr %runtime9 to i32
  call void @__asan_store8_noabort(i32 %7)
  store i64 %runtime, ptr %runtime9, align 8
  %vruntime10 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call3, i32 0, i32 4
  %8 = ptrtoint ptr %vruntime10 to i32
  call void @__asan_store8_noabort(i32 %8)
  store i64 %vruntime, ptr %vruntime10, align 8
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_stat_runtime(ptr noundef %__data, ptr nocapture noundef readonly %tsk, i64 noundef %runtime, i64 noundef %vruntime) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 52, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 8
  %runtime20 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call13, i32 0, i32 3
  %31 = ptrtoint ptr %runtime20 to i32
  call void @__asan_store8_noabort(i32 %31)
  store i64 %runtime, ptr %runtime20, align 8
  %vruntime21 = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %call13, i32 0, i32 4
  %32 = ptrtoint ptr %vruntime21 to i32
  call void @__asan_store8_noabort(i32 %32)
  store i64 %vruntime, ptr %vruntime21, align 8
  %33 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %rctx, align 4
  %35 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 52, i32 noundef %34, ptr noundef %__data, i64 noundef %runtime, ptr noundef %36, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_pi_setprio(ptr noundef %__data, ptr nocapture noundef readonly %tsk, ptr noundef readonly %pi_task) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 36) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 13
  %7 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %prio, align 8
  %oldprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %oldprio to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %oldprio, align 4
  %tobool9.not = icmp eq ptr %pi_task, null
  %normal_prio13 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 15
  %10 = ptrtoint ptr %normal_prio13 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %normal_prio13, align 64
  br i1 %tobool9.not, label %cond.end14, label %cond.true

cond.true:                                        ; preds = %if.end5
  %prio10 = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 13
  %12 = ptrtoint ptr %prio10 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %prio10, align 8
  %14 = call i32 @llvm.smin.i32(i32 %11, i32 %13)
  br label %cond.end14

cond.end14:                                       ; preds = %cond.true, %if.end5
  %cond15 = phi i32 [ %14, %cond.true ], [ %11, %if.end5 ]
  %newprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call3, i32 0, i32 4
  %15 = ptrtoint ptr %newprio to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 %cond15, ptr %newprio, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %cond.end14, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_pi_setprio(ptr noundef %__data, ptr nocapture noundef readonly %tsk, ptr noundef readonly %pi_task) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 36, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 13
  %31 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %prio, align 8
  %oldprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call13, i32 0, i32 3
  %33 = ptrtoint ptr %oldprio to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %32, ptr %oldprio, align 4
  %tobool20.not = icmp eq ptr %pi_task, null
  %normal_prio25 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 15
  %34 = ptrtoint ptr %normal_prio25 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %normal_prio25, align 64
  br i1 %tobool20.not, label %cond.end26, label %cond.true

cond.true:                                        ; preds = %if.end16
  %prio21 = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 13
  %36 = ptrtoint ptr %prio21 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %prio21, align 8
  %38 = call i32 @llvm.smin.i32(i32 %35, i32 %37)
  br label %cond.end26

cond.end26:                                       ; preds = %cond.true, %if.end16
  %cond27 = phi i32 [ %38, %cond.true ], [ %35, %if.end16 ]
  %newprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %call13, i32 0, i32 4
  %39 = ptrtoint ptr %newprio to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 %cond27, ptr %newprio, align 4
  %40 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %rctx, align 4
  %42 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 36, i32 noundef %41, ptr noundef %__data, i64 noundef 1, ptr noundef %43, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %cond.end26, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_process_hang(ptr noundef %__data, ptr nocapture noundef readonly %tsk) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 28) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %call3, i32 0, i32 1
  %comm6 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %3 = call ptr @memcpy(ptr %comm, ptr %comm6, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 8
  %pid8 = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %call3, i32 0, i32 2
  %6 = ptrtoint ptr %pid8 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 %5, ptr %pid8, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_process_hang(ptr noundef %__data, ptr nocapture noundef readonly %tsk) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 28, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %call13, i32 0, i32 1
  %comm17 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 101
  %27 = call ptr @memcpy(ptr %comm, ptr %comm17, i32 16)
  %pid = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %28 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %pid, align 8
  %pid19 = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %call13, i32 0, i32 2
  %30 = ptrtoint ptr %pid19 to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %29, ptr %pid19, align 4
  %31 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %rctx, align 4
  %33 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 28, i32 noundef %32, ptr noundef %__data, i64 noundef 1, ptr noundef %34, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_move_numa(ptr noundef %__data, ptr nocapture noundef readonly %tsk, i32 noundef %src_cpu, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 36) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %3 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %pid.i, align 8
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 1
  %5 = ptrtoint ptr %pid to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 %4, ptr %pid, align 4
  %tgid.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 69
  %6 = ptrtoint ptr %tgid.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %tgid.i, align 4
  %tgid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 2
  %8 = ptrtoint ptr %tgid to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 %7, ptr %tgid, align 4
  %ngid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %ngid to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 0, ptr %ngid, align 4
  %src_cpu9 = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 4
  %10 = ptrtoint ptr %src_cpu9 to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %src_cpu, ptr %src_cpu9, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 5
  %11 = ptrtoint ptr %src_nid to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 0, ptr %src_nid, align 4
  %dst_cpu10 = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 6
  %12 = ptrtoint ptr %dst_cpu10 to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 %dst_cpu, ptr %dst_cpu10, align 4
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call3, i32 0, i32 7
  %13 = ptrtoint ptr %dst_nid to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 0, ptr %dst_nid, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_move_numa(ptr noundef %__data, ptr nocapture noundef readonly %tsk, i32 noundef %src_cpu, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 36, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 68
  %27 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %pid.i, align 8
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 1
  %29 = ptrtoint ptr %pid to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %28, ptr %pid, align 4
  %tgid.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 69
  %30 = ptrtoint ptr %tgid.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %tgid.i, align 4
  %tgid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 2
  %32 = ptrtoint ptr %tgid to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %31, ptr %tgid, align 4
  %ngid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 3
  %33 = ptrtoint ptr %ngid to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 0, ptr %ngid, align 4
  %src_cpu20 = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 4
  %34 = ptrtoint ptr %src_cpu20 to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 %src_cpu, ptr %src_cpu20, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 5
  %35 = ptrtoint ptr %src_nid to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 0, ptr %src_nid, align 4
  %dst_cpu21 = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 6
  %36 = ptrtoint ptr %dst_cpu21 to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 %dst_cpu, ptr %dst_cpu21, align 4
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %call13, i32 0, i32 7
  %37 = ptrtoint ptr %dst_nid to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 0, ptr %dst_nid, align 4
  %38 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %rctx, align 4
  %40 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 36, i32 noundef %39, ptr noundef %__data, i64 noundef 1, ptr noundef %41, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end16, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_numa_pair_template(ptr noundef %__data, ptr nocapture noundef readonly %src_tsk, i32 noundef %src_cpu, ptr noundef readonly %dst_tsk, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 48) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %src_tsk, i32 0, i32 68
  %3 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %pid.i, align 8
  %src_pid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 1
  %5 = ptrtoint ptr %src_pid to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 %4, ptr %src_pid, align 4
  %tgid.i = getelementptr inbounds %struct.task_struct, ptr %src_tsk, i32 0, i32 69
  %6 = ptrtoint ptr %tgid.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %tgid.i, align 4
  %src_tgid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 2
  %8 = ptrtoint ptr %src_tgid to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 %7, ptr %src_tgid, align 4
  %src_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 3
  %9 = ptrtoint ptr %src_ngid to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 0, ptr %src_ngid, align 4
  %src_cpu9 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 4
  %10 = ptrtoint ptr %src_cpu9 to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %src_cpu, ptr %src_cpu9, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 5
  %11 = ptrtoint ptr %src_nid to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 0, ptr %src_nid, align 4
  %tobool10.not = icmp eq ptr %dst_tsk, null
  br i1 %tobool10.not, label %cond.end16.critedge, label %cond.true

cond.true:                                        ; preds = %if.end5
  %pid.i60 = getelementptr inbounds %struct.task_struct, ptr %dst_tsk, i32 0, i32 68
  %12 = ptrtoint ptr %pid.i60 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %pid.i60, align 8
  %dst_pid.c58 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 6
  %14 = ptrtoint ptr %dst_pid.c58 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %13, ptr %dst_pid.c58, align 4
  %tgid.i61 = getelementptr inbounds %struct.task_struct, ptr %dst_tsk, i32 0, i32 69
  %15 = ptrtoint ptr %tgid.i61 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %tgid.i61, align 4
  br label %cond.end22

cond.end16.critedge:                              ; preds = %if.end5
  %dst_pid.c = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 6
  %17 = ptrtoint ptr %dst_pid.c to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %dst_pid.c, align 4
  br label %cond.end22

cond.end22:                                       ; preds = %cond.end16.critedge, %cond.true
  %.sink = phi i32 [ 0, %cond.end16.critedge ], [ %16, %cond.true ]
  %18 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 7
  %19 = ptrtoint ptr %18 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %.sink, ptr %18, align 4
  %dst_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 8
  %20 = ptrtoint ptr %dst_ngid to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 0, ptr %dst_ngid, align 4
  %dst_cpu24 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 9
  %21 = ptrtoint ptr %dst_cpu24 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %dst_cpu, ptr %dst_cpu24, align 4
  %dst_cpu.lobit = ashr i32 %dst_cpu, 31
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call3, i32 0, i32 10
  %22 = ptrtoint ptr %dst_nid to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %dst_cpu.lobit, ptr %dst_nid, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %cond.end22, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_numa_pair_template(ptr noundef %__data, ptr nocapture noundef readonly %src_tsk, i32 noundef %src_cpu, ptr noundef readonly %dst_tsk, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true7, label %if.end

land.lhs.true7:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true7, %entry
  %call13 = call ptr @perf_trace_buf_alloc(i32 noundef 52, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool14.not = icmp eq ptr %call13, null
  br i1 %tobool14.not, label %cleanup, label %if.end16

if.end16:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %src_tsk, i32 0, i32 68
  %27 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %pid.i, align 8
  %src_pid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 1
  %29 = ptrtoint ptr %src_pid to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %28, ptr %src_pid, align 4
  %tgid.i = getelementptr inbounds %struct.task_struct, ptr %src_tsk, i32 0, i32 69
  %30 = ptrtoint ptr %tgid.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %tgid.i, align 4
  %src_tgid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 2
  %32 = ptrtoint ptr %src_tgid to i32
  call void @__asan_store4_noabort(i32 %32)
  store i32 %31, ptr %src_tgid, align 4
  %src_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 3
  %33 = ptrtoint ptr %src_ngid to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 0, ptr %src_ngid, align 4
  %src_cpu20 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 4
  %34 = ptrtoint ptr %src_cpu20 to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 %src_cpu, ptr %src_cpu20, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 5
  %35 = ptrtoint ptr %src_nid to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 0, ptr %src_nid, align 4
  %tobool21.not = icmp eq ptr %dst_tsk, null
  br i1 %tobool21.not, label %cond.end27.critedge, label %cond.true

cond.true:                                        ; preds = %if.end16
  %pid.i83 = getelementptr inbounds %struct.task_struct, ptr %dst_tsk, i32 0, i32 68
  %36 = ptrtoint ptr %pid.i83 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %pid.i83, align 8
  %dst_pid.c81 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 6
  %38 = ptrtoint ptr %dst_pid.c81 to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %37, ptr %dst_pid.c81, align 4
  %tgid.i84 = getelementptr inbounds %struct.task_struct, ptr %dst_tsk, i32 0, i32 69
  %39 = ptrtoint ptr %tgid.i84 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %tgid.i84, align 4
  br label %cond.end33

cond.end27.critedge:                              ; preds = %if.end16
  %dst_pid.c = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 6
  %41 = ptrtoint ptr %dst_pid.c to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 0, ptr %dst_pid.c, align 4
  br label %cond.end33

cond.end33:                                       ; preds = %cond.end27.critedge, %cond.true
  %.sink = phi i32 [ 0, %cond.end27.critedge ], [ %40, %cond.true ]
  %42 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 7
  %43 = ptrtoint ptr %42 to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 %.sink, ptr %42, align 4
  %dst_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 8
  %44 = ptrtoint ptr %dst_ngid to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 0, ptr %dst_ngid, align 4
  %dst_cpu35 = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 9
  %45 = ptrtoint ptr %dst_cpu35 to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 %dst_cpu, ptr %dst_cpu35, align 4
  %dst_cpu.lobit = ashr i32 %dst_cpu, 31
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %call13, i32 0, i32 10
  %46 = ptrtoint ptr %dst_nid to i32
  call void @__asan_store4_noabort(i32 %46)
  store i32 %dst_cpu.lobit, ptr %dst_nid, align 4
  %47 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %rctx, align 4
  %49 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call13, i32 noundef 52, i32 noundef %48, ptr noundef %__data, i64 noundef 1, ptr noundef %50, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %cond.end33, %if.end, %land.lhs.true7
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @trace_event_raw_event_sched_wake_idle_without_ipi(ptr noundef %__data, i32 noundef %cpu) #0 align 64 {
entry:
  %fbuffer = alloca %struct.trace_event_buffer, align 4
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %fbuffer) #33
  %flags.i = getelementptr inbounds %struct.trace_event_file, ptr %__data, i32 0, i32 7
  %0 = call ptr @memset(ptr %fbuffer, i32 255, i32 24)
  %1 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %2, 704
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %if.end, label %if.end.i, !prof !1191

if.end.i:                                         ; preds = %entry
  %and4.i = and i32 %2, 256
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %trace_trigger_soft_disabled.exit, label %if.end, !prof !1192

trace_trigger_soft_disabled.exit:                 ; preds = %if.end.i
  %call.i = tail call zeroext i1 @__trace_trigger_soft_disabled(ptr noundef %__data) #33
  br i1 %call.i, label %cleanup, label %if.end

if.end:                                           ; preds = %trace_trigger_soft_disabled.exit, %if.end.i, %entry
  %call3 = call ptr @trace_event_buffer_reserve(ptr noundef nonnull %fbuffer, ptr noundef %__data, i32 noundef 12) #33
  %tobool.not = icmp eq ptr %call3, null
  br i1 %tobool.not, label %cleanup, label %if.end5

if.end5:                                          ; preds = %if.end
  %cpu6 = getelementptr inbounds %struct.trace_event_raw_sched_wake_idle_without_ipi, ptr %call3, i32 0, i32 1
  %3 = ptrtoint ptr %cpu6 to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 %cpu, ptr %cpu6, align 4
  call void @trace_event_buffer_commit(ptr noundef nonnull %fbuffer) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %if.end, %trace_trigger_soft_disabled.exit
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %fbuffer) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @perf_trace_sched_wake_idle_without_ipi(ptr noundef %__data, i32 noundef %cpu) #0 align 64 {
entry:
  %__regs = alloca ptr, align 4
  %rctx = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %__regs) #33
  %0 = ptrtoint ptr %__regs to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %__regs, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %rctx) #33
  %1 = ptrtoint ptr %rctx to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %rctx, align 4, !annotation !1193
  %perf_events = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 10
  %2 = ptrtoint ptr %perf_events to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %perf_events, align 4
  %4 = ptrtoint ptr %3 to i32
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu4 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu4 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu4, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, %4
  %11 = inttoptr i32 %add to ptr
  %prog_array.i = getelementptr inbounds %struct.trace_event_call, ptr %__data, i32 0, i32 11
  %12 = ptrtoint ptr %prog_array.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %prog_array.i, align 4
  %tobool.i.not = icmp eq ptr %13, null
  br i1 %tobool.i.not, label %land.lhs.true8, label %if.end

land.lhs.true8:                                   ; preds = %entry
  %14 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %11, align 4
  %tobool.not.i.not = icmp eq ptr %15, null
  br i1 %tobool.not.i.not, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true8, %entry
  %call14 = call ptr @perf_trace_buf_alloc(i32 noundef 12, ptr noundef nonnull %__regs, ptr noundef nonnull %rctx) #33
  %tobool15.not = icmp eq ptr %call14, null
  br i1 %tobool15.not, label %cleanup, label %if.end17

if.end17:                                         ; preds = %if.end
  %16 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %__regs, align 4
  %18 = call ptr @llvm.returnaddress(i32 0) #33
  %19 = ptrtoint ptr %18 to i32
  %arrayidx.i = getelementptr [18 x i32], ptr %17, i32 0, i32 15
  %20 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %19, ptr %arrayidx.i, align 4
  %21 = call ptr @llvm.frameaddress.p0(i32 0) #33
  %22 = ptrtoint ptr %21 to i32
  %arrayidx2.i = getelementptr [18 x i32], ptr %17, i32 0, i32 11
  %23 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %22, ptr %arrayidx2.i, align 4
  %24 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i = getelementptr [18 x i32], ptr %17, i32 0, i32 13
  %25 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 %24, ptr %arrayidx4.i, align 4
  %arrayidx6.i = getelementptr [18 x i32], ptr %17, i32 0, i32 16
  %26 = ptrtoint ptr %arrayidx6.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 19, ptr %arrayidx6.i, align 4
  %cpu18 = getelementptr inbounds %struct.trace_event_raw_sched_wake_idle_without_ipi, ptr %call14, i32 0, i32 1
  %27 = ptrtoint ptr %cpu18 to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %cpu, ptr %cpu18, align 4
  %28 = ptrtoint ptr %rctx to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %rctx, align 4
  %30 = ptrtoint ptr %__regs to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %__regs, align 4
  call void @perf_trace_run_bpf_submit(ptr noundef nonnull %call14, i32 noundef 12, i32 noundef %29, ptr noundef %__data, i64 noundef 1, ptr noundef %31, ptr noundef %11, ptr noundef null) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end17, %if.end, %land.lhs.true8
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %rctx) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %__regs) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_kthread_stop(ptr noundef %__data, ptr noundef %t) #0 align 64 {
entry:
  %0 = ptrtoint ptr %t to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_kthread_stop_ret(ptr noundef %__data, i32 noundef %ret) #0 align 64 {
entry:
  %conv = zext i32 %ret to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_kthread_work_queue_work(ptr noundef %__data, ptr noundef %worker, ptr noundef %work) #0 align 64 {
entry:
  %0 = ptrtoint ptr %worker to i32
  %conv = zext i32 %0 to i64
  %1 = ptrtoint ptr %work to i32
  %conv4 = zext i32 %1 to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_kthread_work_execute_start(ptr noundef %__data, ptr noundef %work) #0 align 64 {
entry:
  %0 = ptrtoint ptr %work to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_kthread_work_execute_end(ptr noundef %__data, ptr noundef %work, ptr noundef %function) #0 align 64 {
entry:
  %0 = ptrtoint ptr %work to i32
  %conv = zext i32 %0 to i64
  %1 = ptrtoint ptr %function to i32
  %conv4 = zext i32 %1 to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_wakeup_template(ptr noundef %__data, ptr noundef %p) #0 align 64 {
entry:
  %0 = ptrtoint ptr %p to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_switch(ptr noundef %__data, i1 noundef zeroext %preempt, ptr noundef %prev, ptr noundef %next) #0 align 64 {
entry:
  %conv = zext i1 %preempt to i64
  %0 = ptrtoint ptr %prev to i32
  %conv5 = zext i32 %0 to i64
  %1 = ptrtoint ptr %next to i32
  %conv9 = zext i32 %1 to i64
  tail call void @bpf_trace_run3(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv5, i64 noundef %conv9) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_migrate_task(ptr noundef %__data, ptr noundef %p, i32 noundef %dest_cpu) #0 align 64 {
entry:
  %0 = ptrtoint ptr %p to i32
  %conv = zext i32 %0 to i64
  %conv4 = zext i32 %dest_cpu to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_process_template(ptr noundef %__data, ptr noundef %p) #0 align 64 {
entry:
  %0 = ptrtoint ptr %p to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_process_wait(ptr noundef %__data, ptr noundef %pid) #0 align 64 {
entry:
  %0 = ptrtoint ptr %pid to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_process_fork(ptr noundef %__data, ptr noundef %parent, ptr noundef %child) #0 align 64 {
entry:
  %0 = ptrtoint ptr %parent to i32
  %conv = zext i32 %0 to i64
  %1 = ptrtoint ptr %child to i32
  %conv4 = zext i32 %1 to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_process_exec(ptr noundef %__data, ptr noundef %p, i32 noundef %old_pid, ptr noundef %bprm) #0 align 64 {
entry:
  %0 = ptrtoint ptr %p to i32
  %conv = zext i32 %0 to i64
  %conv4 = zext i32 %old_pid to i64
  %1 = ptrtoint ptr %bprm to i32
  %conv8 = zext i32 %1 to i64
  tail call void @bpf_trace_run3(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4, i64 noundef %conv8) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_stat_template(ptr noundef %__data, ptr noundef %tsk, i64 noundef %delay) #0 align 64 {
entry:
  %0 = ptrtoint ptr %tsk to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %delay) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_stat_runtime(ptr noundef %__data, ptr noundef %tsk, i64 noundef %runtime, i64 noundef %vruntime) #0 align 64 {
entry:
  %0 = ptrtoint ptr %tsk to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run3(ptr noundef %__data, i64 noundef %conv, i64 noundef %runtime, i64 noundef %vruntime) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_pi_setprio(ptr noundef %__data, ptr noundef %tsk, ptr noundef %pi_task) #0 align 64 {
entry:
  %0 = ptrtoint ptr %tsk to i32
  %conv = zext i32 %0 to i64
  %1 = ptrtoint ptr %pi_task to i32
  %conv4 = zext i32 %1 to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_process_hang(ptr noundef %__data, ptr noundef %tsk) #0 align 64 {
entry:
  %0 = ptrtoint ptr %tsk to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_move_numa(ptr noundef %__data, ptr noundef %tsk, i32 noundef %src_cpu, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %0 = ptrtoint ptr %tsk to i32
  %conv = zext i32 %0 to i64
  %conv4 = zext i32 %src_cpu to i64
  %conv8 = zext i32 %dst_cpu to i64
  tail call void @bpf_trace_run3(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4, i64 noundef %conv8) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_numa_pair_template(ptr noundef %__data, ptr noundef %src_tsk, i32 noundef %src_cpu, ptr noundef %dst_tsk, i32 noundef %dst_cpu) #0 align 64 {
entry:
  %0 = ptrtoint ptr %src_tsk to i32
  %conv = zext i32 %0 to i64
  %conv4 = zext i32 %src_cpu to i64
  %1 = ptrtoint ptr %dst_tsk to i32
  %conv8 = zext i32 %1 to i64
  %conv12 = zext i32 %dst_cpu to i64
  tail call void @bpf_trace_run4(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4, i64 noundef %conv8, i64 noundef %conv12) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_wake_idle_without_ipi(ptr noundef %__data, i32 noundef %cpu) #0 align 64 {
entry:
  %conv = zext i32 %cpu to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_cfs_tp(ptr noundef %__data, ptr noundef %cfs_rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %cfs_rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_rt_tp(ptr noundef %__data, ptr noundef %rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_dl_tp(ptr noundef %__data, ptr noundef %rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_thermal_tp(ptr noundef %__data, ptr noundef %rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_irq_tp(ptr noundef %__data, ptr noundef %rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_pelt_se_tp(ptr noundef %__data, ptr noundef %se) #0 align 64 {
entry:
  %0 = ptrtoint ptr %se to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_cpu_capacity_tp(ptr noundef %__data, ptr noundef %rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_overutilized_tp(ptr noundef %__data, ptr noundef %rd, i1 noundef zeroext %overutilized) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rd to i32
  %conv = zext i32 %0 to i64
  %conv5 = zext i1 %overutilized to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv5) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_util_est_cfs_tp(ptr noundef %__data, ptr noundef %cfs_rq) #0 align 64 {
entry:
  %0 = ptrtoint ptr %cfs_rq to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_util_est_se_tp(ptr noundef %__data, ptr noundef %se) #0 align 64 {
entry:
  %0 = ptrtoint ptr %se to i32
  %conv = zext i32 %0 to i64
  tail call void @bpf_trace_run1(ptr noundef %__data, i64 noundef %conv) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__bpf_trace_sched_update_nr_running_tp(ptr noundef %__data, ptr noundef %rq, i32 noundef %change) #0 align 64 {
entry:
  %0 = ptrtoint ptr %rq to i32
  %conv = zext i32 %0 to i64
  %conv4 = zext i32 %change to i64
  tail call void @bpf_trace_run2(ptr noundef %__data, i64 noundef %conv, i64 noundef %conv4) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_core_enqueue(ptr noundef %rq, ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %core = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %0 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %core, align 8
  %core_task_seq = getelementptr inbounds %struct.rq, ptr %1, i32 0, i32 84
  %2 = ptrtoint ptr %core_task_seq to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %core_task_seq, align 4
  %inc = add i32 %3, 1
  store i32 %inc, ptr %core_task_seq, align 4
  %core_cookie = getelementptr %struct.task_struct, ptr %p, i32 0, i32 23
  %4 = ptrtoint ptr %core_cookie to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_cookie, align 16
  %tobool.not = icmp eq i32 %5, 0
  br i1 %tobool.not, label %return, label %if.end

if.end:                                           ; preds = %entry
  %core_node = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22
  %core_tree = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 83
  %6 = ptrtoint ptr %core_tree to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core_tree, align 4
  %tobool.not12.i = icmp eq ptr %7, null
  br i1 %tobool.not12.i, label %rb_add.exit, label %while.body.lr.ph.i

while.body.lr.ph.i:                               ; preds = %if.end
  %stack.i.i.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 1
  %sched_class.i27.i.i.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 21
  %prio.i29.i.i.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 13
  %deadline11.i.i.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 20, i32 7
  br label %while.body.i

while.body.i:                                     ; preds = %while.cond.i, %while.body.lr.ph.i
  %8 = phi ptr [ %7, %while.body.lr.ph.i ], [ %38, %while.cond.i ]
  %add.ptr3.i.i = getelementptr i8, ptr %8, i32 -612
  %9 = ptrtoint ptr %core_cookie to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_cookie, align 16
  %core_cookie1.i.i.i = getelementptr i8, ptr %8, i32 12
  %11 = ptrtoint ptr %core_cookie1.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %core_cookie1.i.i.i, align 16
  %cmp.i.i.i = icmp ult i32 %10, %12
  br i1 %cmp.i.i.i, label %rb_sched_core_less.exit.thread5.i, label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %while.body.i
  %cmp4.i.i.i = icmp ugt i32 %10, %12
  br i1 %cmp4.i.i.i, label %rb_sched_core_less.exit.thread.i, label %if.end6.i.i.i

if.end6.i.i.i:                                    ; preds = %if.end.i.i.i
  %13 = ptrtoint ptr %stack.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %stack.i.i.i.i, align 4
  %cpu.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 3
  %15 = ptrtoint ptr %cpu.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %cpu.i.i.i.i, align 4
  %arrayidx.i.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %16
  %17 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %arrayidx.i.i.i, align 4
  %add.i.i.i = add i32 %18, ptrtoint (ptr @runqueues to i32)
  %19 = inttoptr i32 %add.i.i.i to ptr
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %19, i32 0, i32 79
  %20 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i.i.i, align 8
  %core_forceidle_count.i.i.i = getelementptr inbounds %struct.rq, ptr %21, i32 0, i32 87
  %22 = ptrtoint ptr %core_forceidle_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %core_forceidle_count.i.i.i, align 8
  %tobool.i.i.i = icmp ne i32 %23, 0
  %sched_class.i.i.i.i.i = getelementptr i8, ptr %8, i32 -4
  %24 = ptrtoint ptr %sched_class.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %sched_class.i.i.i.i.i, align 32
  %cmp.i.i.i.i.i = icmp eq ptr %25, @stop_sched_class
  br i1 %cmp.i.i.i.i.i, label %__task_prio.exit.i.i.i.i, label %if.end.i.i.i.i.i

if.end.i.i.i.i.i:                                 ; preds = %if.end6.i.i.i
  %prio.i.i.i.i.i = getelementptr i8, ptr %8, i32 -556
  %26 = ptrtoint ptr %prio.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %prio.i.i.i.i.i, align 8
  %cmp.i.i.i.i.i.i = icmp sgt i32 %27, 99
  br i1 %cmp.i.i.i.i.i.i, label %if.end3.i.i.i.i.i, label %__task_prio.exit.i.i.i.i

if.end3.i.i.i.i.i:                                ; preds = %if.end.i.i.i.i.i
  %cmp5.i.i.i.i.i = icmp eq ptr %25, @idle_sched_class
  %..i.i.i.i.i = select i1 %cmp5.i.i.i.i.i, i32 140, i32 119
  br label %__task_prio.exit.i.i.i.i

__task_prio.exit.i.i.i.i:                         ; preds = %if.end3.i.i.i.i.i, %if.end.i.i.i.i.i, %if.end6.i.i.i
  %retval.0.i.i.i.i.i = phi i32 [ -2, %if.end6.i.i.i ], [ %..i.i.i.i.i, %if.end3.i.i.i.i.i ], [ %27, %if.end.i.i.i.i.i ]
  %28 = ptrtoint ptr %sched_class.i27.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %sched_class.i27.i.i.i.i, align 32
  %cmp.i28.i.i.i.i = icmp eq ptr %29, @stop_sched_class
  br i1 %cmp.i28.i.i.i.i, label %__task_prio.exit36.i.i.i.i, label %if.end.i31.i.i.i.i

if.end.i31.i.i.i.i:                               ; preds = %__task_prio.exit.i.i.i.i
  %30 = ptrtoint ptr %prio.i29.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %prio.i29.i.i.i.i, align 8
  %cmp.i.i30.i.i.i.i = icmp sgt i32 %31, 99
  br i1 %cmp.i.i30.i.i.i.i, label %if.end3.i34.i.i.i.i, label %__task_prio.exit36.i.i.i.i

if.end3.i34.i.i.i.i:                              ; preds = %if.end.i31.i.i.i.i
  %cmp5.i32.i.i.i.i = icmp eq ptr %29, @idle_sched_class
  %..i33.i.i.i.i = select i1 %cmp5.i32.i.i.i.i, i32 140, i32 119
  br label %__task_prio.exit36.i.i.i.i

__task_prio.exit36.i.i.i.i:                       ; preds = %if.end3.i34.i.i.i.i, %if.end.i31.i.i.i.i, %__task_prio.exit.i.i.i.i
  %retval.0.i35.i.i.i.i = phi i32 [ -2, %__task_prio.exit.i.i.i.i ], [ %..i33.i.i.i.i, %if.end3.i34.i.i.i.i ], [ %31, %if.end.i31.i.i.i.i ]
  %sub.i.i.i.i = sub i32 0, %retval.0.i.i.i.i.i
  %sub2.i.i.i.i = sub i32 0, %retval.0.i35.i.i.i.i
  %cmp.i.i.i.i = icmp slt i32 %sub.i.i.i.i, %sub2.i.i.i.i
  br i1 %cmp.i.i.i.i, label %rb_sched_core_less.exit.thread5.i, label %if.end.i.i.i.i

if.end.i.i.i.i:                                   ; preds = %__task_prio.exit36.i.i.i.i
  %cmp5.i.i.i.i = icmp slt i32 %sub2.i.i.i.i, %sub.i.i.i.i
  br i1 %cmp5.i.i.i.i, label %rb_sched_core_less.exit.thread.i, label %if.end7.i.i.i.i

if.end7.i.i.i.i:                                  ; preds = %if.end.i.i.i.i
  switch i32 %retval.0.i.i.i.i.i, label %rb_sched_core_less.exit.thread.i [
    i32 -1, label %if.then9.i.i.i.i
    i32 119, label %rb_sched_core_less.exit.i
  ]

if.then9.i.i.i.i:                                 ; preds = %if.end7.i.i.i.i
  %deadline.i.i.i.i = getelementptr i8, ptr %8, i32 -124
  %32 = ptrtoint ptr %deadline.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %32)
  %33 = load i64, ptr %deadline.i.i.i.i, align 8
  %34 = ptrtoint ptr %deadline11.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %34)
  %35 = load i64, ptr %deadline11.i.i.i.i, align 8
  %sub.i.i.i.i.i = sub i64 %33, %35
  %cmp.i37.i.i.i.i = icmp sgt i64 %sub.i.i.i.i.i, -1
  %rb_right11.i = getelementptr inbounds %struct.rb_node, ptr %8, i32 0, i32 1
  br i1 %cmp.i37.i.i.i.i, label %rb_sched_core_less.exit.thread5.i, label %while.cond.i

rb_sched_core_less.exit.thread.i:                 ; preds = %if.end7.i.i.i.i, %if.end.i.i.i.i, %if.end.i.i.i
  %rb_right3.i = getelementptr inbounds %struct.rb_node, ptr %8, i32 0, i32 1
  br label %while.cond.i

rb_sched_core_less.exit.i:                        ; preds = %if.end7.i.i.i.i
  %call16.i.i.i.i = tail call zeroext i1 @cfs_prio_less(ptr noundef %add.ptr3.i.i, ptr noundef %p, i1 noundef zeroext %tobool.i.i.i) #33
  %rb_right.i = getelementptr inbounds %struct.rb_node, ptr %8, i32 0, i32 1
  br i1 %call16.i.i.i.i, label %rb_sched_core_less.exit.thread5.i, label %while.cond.i

rb_sched_core_less.exit.thread5.i:                ; preds = %rb_sched_core_less.exit.i, %if.then9.i.i.i.i, %__task_prio.exit36.i.i.i.i, %while.body.i
  %rb_left9.i = getelementptr inbounds %struct.rb_node, ptr %8, i32 0, i32 2
  br label %while.cond.i

while.cond.i:                                     ; preds = %rb_sched_core_less.exit.thread5.i, %rb_sched_core_less.exit.i, %rb_sched_core_less.exit.thread.i, %if.then9.i.i.i.i
  %36 = phi ptr [ %rb_left9.i, %rb_sched_core_less.exit.thread5.i ], [ %rb_right.i, %rb_sched_core_less.exit.i ], [ %rb_right3.i, %rb_sched_core_less.exit.thread.i ], [ %rb_right11.i, %if.then9.i.i.i.i ]
  %37 = ptrtoint ptr %36 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %36, align 4
  %tobool.not.i = icmp eq ptr %38, null
  br i1 %tobool.not.i, label %while.cond.while.end_crit_edge.i, label %while.body.i

while.cond.while.end_crit_edge.i:                 ; preds = %while.cond.i
  %phi.cast.le.i = ptrtoint ptr %8 to i32
  br label %rb_add.exit

rb_add.exit:                                      ; preds = %while.cond.while.end_crit_edge.i, %if.end
  %link.0.lcssa.i = phi ptr [ %36, %while.cond.while.end_crit_edge.i ], [ %core_tree, %if.end ]
  %parent.0.lcssa.i = phi i32 [ %phi.cast.le.i, %while.cond.while.end_crit_edge.i ], [ 0, %if.end ]
  %39 = ptrtoint ptr %core_node to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 %parent.0.lcssa.i, ptr %core_node, align 4
  %rb_right.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22, i32 1
  %40 = ptrtoint ptr %rb_right.i.i to i32
  call void @__asan_store4_noabort(i32 %40)
  store ptr null, ptr %rb_right.i.i, align 4
  %rb_left.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22, i32 2
  %41 = ptrtoint ptr %rb_left.i.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store ptr null, ptr %rb_left.i.i, align 4
  %42 = ptrtoint ptr %link.0.lcssa.i to i32
  call void @__asan_store4_noabort(i32 %42)
  store ptr %core_node, ptr %link.0.lcssa.i, align 4
  tail call void @rb_insert_color(ptr noundef %core_node, ptr noundef %core_tree) #33
  br label %return

return:                                           ; preds = %rb_add.exit, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_core_dequeue(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %core = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %0 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %core, align 8
  %core_task_seq = getelementptr inbounds %struct.rq, ptr %1, i32 0, i32 84
  %2 = ptrtoint ptr %core_task_seq to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %core_task_seq, align 4
  %inc = add i32 %3, 1
  store i32 %inc, ptr %core_task_seq, align 4
  %core_node.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22
  %4 = ptrtoint ptr %core_node.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_node.i, align 4
  %6 = ptrtoint ptr %core_node.i to i32
  %cmp.i.not = icmp eq i32 %5, %6
  br i1 %cmp.i.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %core_tree = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 83
  tail call void @rb_erase(ptr noundef %core_node.i, ptr noundef %core_tree) #33
  %7 = ptrtoint ptr %core_node.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 %6, ptr %core_node.i, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %and = and i32 %flags, 2
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %land.lhs.true, label %if.end9

land.lhs.true:                                    ; preds = %if.end
  %nr_running = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %8 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %nr_running, align 4
  %cmp = icmp eq i32 %9, 1
  br i1 %cmp, label %land.lhs.true3, label %if.end9

land.lhs.true3:                                   ; preds = %land.lhs.true
  %10 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core, align 8
  %core_forceidle_count = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 87
  %12 = ptrtoint ptr %core_forceidle_count to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %core_forceidle_count, align 8
  %tobool5.not = icmp eq i32 %13, 0
  br i1 %tobool5.not, label %if.end9, label %land.lhs.true6

land.lhs.true6:                                   ; preds = %land.lhs.true3
  %curr = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %14 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %curr, align 8
  %idle = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 21
  %16 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %idle, align 4
  %cmp7 = icmp eq ptr %15, %17
  br i1 %cmp7, label %if.then8, label %if.end9

if.then8:                                         ; preds = %land.lhs.true6
  tail call void @resched_curr(ptr noundef %rq)
  br label %if.end9

if.end9:                                          ; preds = %if.then8, %land.lhs.true6, %land.lhs.true3, %land.lhs.true, %if.end
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @rb_erase(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @resched_curr(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %curr1 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %0 = ptrtoint ptr %curr1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %curr1, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %2 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %6, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %stack.i.i = getelementptr inbounds %struct.task_struct, ptr %1, i32 0, i32 1
  %7 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %stack.i.i, align 4
  %9 = ptrtoint ptr %8 to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %8, align 4
  %11 = and i32 %10, 2
  %tobool.not = icmp eq i32 %11, 0
  br i1 %tobool.not, label %if.end, label %cleanup

if.end:                                           ; preds = %lockdep_assert_rq_held.exit
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %12 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %cpu.i, align 4
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %14, -16384
  %15 = inttoptr i32 %and.i to ptr
  %cpu4 = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 3
  %16 = ptrtoint ptr %cpu4 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %cpu4, align 4
  %cmp = icmp eq i32 %13, %17
  tail call void @_set_bit(i32 noundef 1, ptr noundef %8) #33
  br i1 %cmp, label %cleanup, label %if.end6

if.end6:                                          ; preds = %if.end
  tail call void @smp_send_reschedule(i32 noundef %13) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end6, %if.end, %lockdep_assert_rq_held.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_core_get() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @sched_core_count, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1196
  tail call void @llvm.prefetch.p0(ptr nonnull @sched_core_count, i32 1, i32 3, i32 1) #33
  %0 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_add_unless\0A1:\09ldrex\09$0, [$4]\0A\09teq\09$0, $5\0A\09beq\092f\0A\09add\09$1, $0, $6\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b\0A2:", "=&r,=&r,=&r,=*Qo,r,r,r,*Qo,~{cc}"(ptr nonnull elementtype(i32) @sched_core_count, ptr nonnull @sched_core_count, i32 0, i32 1, ptr nonnull elementtype(i32) @sched_core_count) #33, !srcloc !1197
  %asmresult.i.i.i.i = extractvalue { i32, i32, i32 } %0, 0
  %cmp.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i, 0
  br i1 %cmp.not.i.i.i.i, label %if.end, label %atomic_inc_not_zero.exit.thread

atomic_inc_not_zero.exit.thread:                  ; preds = %entry
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1198
  br label %return

if.end:                                           ; preds = %entry
  tail call void @mutex_lock_nested(ptr noundef nonnull @sched_core_mutex, i32 noundef 0) #33
  %call.i.i6 = tail call zeroext i1 @__kasan_check_read(ptr noundef nonnull @sched_core_count, i32 noundef 4) #33
  %1 = load volatile i32, ptr @sched_core_count, align 4
  %tobool.not = icmp eq i32 %1, 0
  br i1 %tobool.not, label %if.then2, label %do.end

if.then2:                                         ; preds = %if.end
  tail call void @static_key_enable(ptr noundef nonnull @__sched_core_enabled) #33
  tail call void @synchronize_rcu() #33
  tail call fastcc void @__sched_core_flip(i1 noundef zeroext true) #33
  %call51.i.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %2 = load i32, ptr @nr_cpu_ids, align 4
  %cmp52.i.i = icmp ult i32 %call51.i.i, %2
  br i1 %cmp52.i.i, label %for.body.i.i, label %do.end

for.body.i.i:                                     ; preds = %if.end38.i.i, %if.then2
  %call53.i.i = phi i32 [ %call.i.i8, %if.end38.i.i ], [ %call51.i.i, %if.then2 ]
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call53.i.i
  %3 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %4, ptrtoint (ptr @runqueues to i32)
  %5 = inttoptr i32 %add.i.i to ptr
  %core_tree.i.i = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 83
  %6 = ptrtoint ptr %core_tree.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile ptr, ptr %core_tree.i.i, align 8
  %cmp6.not.i.i = icmp eq ptr %7, null
  br i1 %cmp6.not.i.i, label %if.end38.i.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %for.body.i.i
  %.b50.i.i = load i1, ptr @sched_core_assert_empty.__already_done, align 1
  br i1 %.b50.i.i, label %if.end38.i.i, label %if.then.i.i, !prof !1191

if.then.i.i:                                      ; preds = %land.rhs.i.i
  store i1 true, ptr @sched_core_assert_empty.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 315, i32 noundef 9, ptr noundef null) #33
  br label %if.end38.i.i

if.end38.i.i:                                     ; preds = %if.then.i.i, %land.rhs.i.i, %for.body.i.i
  %call.i.i8 = tail call i32 @cpumask_next(i32 noundef %call53.i.i, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.i.i = icmp ult i32 %call.i.i8, %8
  br i1 %cmp.i.i, label %for.body.i.i, label %do.end

do.end:                                           ; preds = %if.end38.i.i, %if.then2, %if.end
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1199
  %call.i.i7 = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @sched_core_count, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr nonnull @sched_core_count, i32 1, i32 3, i32 1) #33
  %9 = tail call { i32, i32 } asm sideeffect "@ atomic_add\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @sched_core_count, ptr nonnull @sched_core_count, i32 1, ptr nonnull elementtype(i32) @sched_core_count) #33, !srcloc !1200
  tail call void @mutex_unlock(ptr noundef nonnull @sched_core_mutex) #33
  br label %return

return:                                           ; preds = %do.end, %atomic_inc_not_zero.exit.thread
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_lock_nested(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_unlock(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_core_put() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @sched_core_count, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1196
  tail call void @llvm.prefetch.p0(ptr nonnull @sched_core_count, i32 1, i32 3, i32 1) #33
  %0 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_add_unless\0A1:\09ldrex\09$0, [$4]\0A\09teq\09$0, $5\0A\09beq\092f\0A\09add\09$1, $0, $6\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b\0A2:", "=&r,=&r,=&r,=*Qo,r,r,r,*Qo,~{cc}"(ptr nonnull elementtype(i32) @sched_core_count, ptr nonnull @sched_core_count, i32 1, i32 -1, ptr nonnull elementtype(i32) @sched_core_count) #33, !srcloc !1197
  %asmresult.i.i.i = extractvalue { i32, i32, i32 } %0, 0
  %cmp.not.i.i.i = icmp eq i32 %asmresult.i.i.i, 1
  br i1 %cmp.not.i.i.i, label %if.then, label %atomic_add_unless.exit.thread

atomic_add_unless.exit.thread:                    ; preds = %entry
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1198
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @system_wq to i32))
  %1 = load ptr, ptr @system_wq, align 4
  %call.i.i2 = tail call zeroext i1 @queue_work_on(i32 noundef 4, ptr noundef %1, ptr noundef nonnull @sched_core_put._work) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %atomic_add_unless.exit.thread
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__sched_core_put(ptr nocapture noundef readnone %work) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @atomic_dec_and_mutex_lock(ptr noundef nonnull @sched_core_count, ptr noundef nonnull @sched_core_mutex) #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %call51.i.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp52.i.i = icmp ult i32 %call51.i.i, %0
  br i1 %cmp52.i.i, label %for.body.i.i, label %__sched_core_disable.exit

for.body.i.i:                                     ; preds = %if.end38.i.i, %if.then
  %call53.i.i = phi i32 [ %call.i.i, %if.end38.i.i ], [ %call51.i.i, %if.then ]
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call53.i.i
  %1 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add.i.i to ptr
  %core_tree.i.i = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 83
  %4 = ptrtoint ptr %core_tree.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile ptr, ptr %core_tree.i.i, align 8
  %cmp6.not.i.i = icmp eq ptr %5, null
  br i1 %cmp6.not.i.i, label %if.end38.i.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %for.body.i.i
  %.b50.i.i = load i1, ptr @sched_core_assert_empty.__already_done, align 1
  br i1 %.b50.i.i, label %if.end38.i.i, label %if.then.i.i, !prof !1191

if.then.i.i:                                      ; preds = %land.rhs.i.i
  store i1 true, ptr @sched_core_assert_empty.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 315, i32 noundef 9, ptr noundef null) #33
  br label %if.end38.i.i

if.end38.i.i:                                     ; preds = %if.then.i.i, %land.rhs.i.i, %for.body.i.i
  %call.i.i = tail call i32 @cpumask_next(i32 noundef %call53.i.i, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %6 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.i.i = icmp ult i32 %call.i.i, %6
  br i1 %cmp.i.i, label %for.body.i.i, label %__sched_core_disable.exit

__sched_core_disable.exit:                        ; preds = %if.end38.i.i, %if.then
  tail call fastcc void @__sched_core_flip(i1 noundef zeroext false) #33
  tail call void @static_key_disable(ptr noundef nonnull @__sched_core_enabled) #33
  tail call void @mutex_unlock(ptr noundef nonnull @sched_core_mutex) #33
  br label %if.end

if.end:                                           ; preds = %__sched_core_disable.exit, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @raw_spin_rq_lock_nested(ptr noundef %rq, i32 noundef %subclass) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_lock_nested, %for.cond)) #33
          to label %if.then [label %for.cond], !srcloc !1202

if.then:                                          ; preds = %entry
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef %subclass) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %cleanup

for.cond:                                         ; preds = %if.end11, %entry
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %4 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i = icmp eq i32 %5, 0
  br i1 %tobool.not.i, label %__rq_lockp.exit, label %if.then.i

if.then.i:                                        ; preds = %for.cond
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %6 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core.i, align 8
  br label %__rq_lockp.exit

__rq_lockp.exit:                                  ; preds = %if.then.i, %for.cond
  %retval.0.i = phi ptr [ %7, %if.then.i ], [ %rq, %for.cond ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i, i32 noundef %subclass) #33
  %8 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i23 = icmp eq i32 %9, 0
  br i1 %tobool.not.i23, label %__rq_lockp.exit27, label %if.then.i25

if.then.i25:                                      ; preds = %__rq_lockp.exit
  %core.i24 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %10 = ptrtoint ptr %core.i24 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i24, align 8
  br label %__rq_lockp.exit27

__rq_lockp.exit27:                                ; preds = %if.then.i25, %__rq_lockp.exit
  %retval.0.i26 = phi ptr [ %11, %if.then.i25 ], [ %rq, %__rq_lockp.exit ]
  %cmp = icmp eq ptr %retval.0.i, %retval.0.i26
  br i1 %cmp, label %do.body8, label %if.end11, !prof !1191

do.body8:                                         ; preds = %__rq_lockp.exit27
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %cleanup

if.end11:                                         ; preds = %__rq_lockp.exit27
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i) #33
  br label %for.cond

cleanup:                                          ; preds = %do.body8, %if.then
  %12 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19 = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i19 to ptr
  %preempt_count.i.i20 = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i20 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i.i20, align 4
  %sub.i21 = add i32 %15, -1
  store volatile i32 %sub.i21, ptr %preempt_count.i.i20, align 4
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock_nested(ptr noundef, i32 noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local zeroext i1 @raw_spin_rq_trylock(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1205
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_trylock, %for.cond)) #33
          to label %if.then [label %for.cond], !srcloc !1202

if.then:                                          ; preds = %entry
  %call1 = tail call i32 @_raw_spin_trylock(ptr noundef %rq) #33
  %tobool = icmp ne i32 %call1, 0
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1206
  br label %cleanup

for.cond:                                         ; preds = %if.end19, %entry
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %4 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i = icmp eq i32 %5, 0
  br i1 %tobool.not.i, label %__rq_lockp.exit, label %if.then.i

if.then.i:                                        ; preds = %for.cond
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %6 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core.i, align 8
  br label %__rq_lockp.exit

__rq_lockp.exit:                                  ; preds = %if.then.i, %for.cond
  %retval.0.i = phi ptr [ %7, %if.then.i ], [ %rq, %for.cond ]
  %call7 = tail call i32 @_raw_spin_trylock(ptr noundef %retval.0.i) #33
  %tobool8.not = icmp eq i32 %call7, 0
  br i1 %tobool8.not, label %do.body15, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %__rq_lockp.exit
  %8 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i33 = icmp eq i32 %9, 0
  br i1 %tobool.not.i33, label %__rq_lockp.exit37, label %if.then.i35

if.then.i35:                                      ; preds = %lor.lhs.false
  %core.i34 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %10 = ptrtoint ptr %core.i34 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i34, align 8
  br label %__rq_lockp.exit37

__rq_lockp.exit37:                                ; preds = %if.then.i35, %lor.lhs.false
  %retval.0.i36 = phi ptr [ %11, %if.then.i35 ], [ %rq, %lor.lhs.false ]
  %cmp = icmp eq ptr %retval.0.i, %retval.0.i36
  br i1 %cmp, label %do.body15, label %if.end19, !prof !1191

do.body15:                                        ; preds = %__rq_lockp.exit37, %__rq_lockp.exit
  %12 = xor i1 %tobool8.not, true
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1207
  br label %cleanup

if.end19:                                         ; preds = %__rq_lockp.exit37
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i) #33
  br label %for.cond

cleanup:                                          ; preds = %do.body15, %if.then
  %retval.0 = phi i1 [ %tobool, %if.then ], [ %12, %do.body15 ]
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i29 = and i32 %13, -16384
  %14 = inttoptr i32 %and.i.i.i29 to ptr
  %preempt_count.i.i30 = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 1
  %15 = ptrtoint ptr %preempt_count.i.i30 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %preempt_count.i.i30, align 4
  %sub.i31 = add i32 %16, -1
  store volatile i32 %sub.i31, ptr %preempt_count.i.i30, align 4
  ret i1 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_raw_spin_trylock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @raw_spin_rq_unlock(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_unlock, %land.rhs.i.i)) #33
          to label %rq_lockp.exit [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i = icmp eq i32 %1, 0
  br i1 %tobool3.i.not.i, label %rq_lockp.exit, label %if.then.i

if.then.i:                                        ; preds = %land.rhs.i.i
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core.i, align 8
  br label %rq_lockp.exit

rq_lockp.exit:                                    ; preds = %if.then.i, %land.rhs.i.i, %entry
  %retval.0.i = phi ptr [ %3, %if.then.i ], [ %rq, %land.rhs.i.i ], [ %rq, %entry ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @double_rq_lock(ptr noundef %rq1, ptr noundef %rq2) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %if.end86, label %land.lhs.true

land.lhs.true:                                    ; preds = %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1208
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @lockdep_recursion to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %11, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1209
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i119 = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i119 to ptr
  %preempt_count.i.i120 = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i120 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %preempt_count.i.i120, align 4
  %sub.i = add i32 %17, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i120, align 4
  %tobool20.not = icmp eq i32 %13, 0
  br i1 %tobool20.not, label %land.rhs, label %if.end86

land.rhs:                                         ; preds = %land.lhs.true
  %18 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i121 = and i32 %18, -16384
  %19 = inttoptr i32 %and.i.i.i121 to ptr
  %preempt_count.i.i122 = getelementptr inbounds %struct.thread_info, ptr %19, i32 0, i32 1
  %20 = ptrtoint ptr %preempt_count.i.i122 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load volatile i32, ptr %preempt_count.i.i122, align 4
  %add.i123 = add i32 %21, 1
  store volatile i32 %add.i123, ptr %preempt_count.i.i122, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1210
  %22 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %cpu, align 4
  %arrayidx44 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %23
  %24 = ptrtoint ptr %arrayidx44 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %arrayidx44, align 4
  %add45 = add i32 %25, ptrtoint (ptr @hardirqs_enabled to i32)
  %26 = inttoptr i32 %add45 to ptr
  %27 = ptrtoint ptr %26 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load volatile i32, ptr %26, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1211
  %29 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i124 = and i32 %29, -16384
  %30 = inttoptr i32 %and.i.i.i124 to ptr
  %preempt_count.i.i125 = getelementptr inbounds %struct.thread_info, ptr %30, i32 0, i32 1
  %31 = ptrtoint ptr %preempt_count.i.i125 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load volatile i32, ptr %preempt_count.i.i125, align 4
  %sub.i126 = add i32 %32, -1
  store volatile i32 %sub.i126, ptr %preempt_count.i.i125, align 4
  %tobool52.not = icmp eq i32 %28, 0
  br i1 %tobool52.not, label %if.end86, label %land.rhs55

land.rhs55:                                       ; preds = %land.rhs
  %.b114 = load i1, ptr @double_rq_lock.__already_done, align 1
  br i1 %.b114, label %if.end86, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs55
  store i1 true, ptr @double_rq_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 542, i32 noundef 9, ptr noundef null) #33
  br label %if.end86

if.end86:                                         ; preds = %if.then, %land.rhs55, %land.rhs, %land.lhs.true, %entry
  %core.i = getelementptr inbounds %struct.rq, ptr %rq2, i32 0, i32 79
  %33 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %core.i, align 8
  %cpu.i = getelementptr inbounds %struct.rq, ptr %34, i32 0, i32 46
  %35 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %cpu.i, align 4
  %core1.i = getelementptr inbounds %struct.rq, ptr %rq1, i32 0, i32 79
  %37 = ptrtoint ptr %core1.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %core1.i, align 8
  %cpu2.i = getelementptr inbounds %struct.rq, ptr %38, i32 0, i32 46
  %39 = ptrtoint ptr %cpu2.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %cpu2.i, align 4
  %cmp.i = icmp slt i32 %36, %40
  br i1 %cmp.i, label %rq_order_less.exit.thread, label %if.end.i

if.end.i:                                         ; preds = %if.end86
  %cmp7.i = icmp sgt i32 %36, %40
  br i1 %cmp7.i, label %.thread, label %rq_order_less.exit

rq_order_less.exit:                               ; preds = %if.end.i
  %cpu10.i = getelementptr inbounds %struct.rq, ptr %rq2, i32 0, i32 46
  %41 = ptrtoint ptr %cpu10.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %cpu10.i, align 4
  %cpu11.i = getelementptr inbounds %struct.rq, ptr %rq1, i32 0, i32 46
  %43 = ptrtoint ptr %cpu11.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %cpu11.i, align 4
  %cmp12.i = icmp slt i32 %42, %44
  br i1 %cmp12.i, label %rq_order_less.exit.thread, label %.thread

.thread:                                          ; preds = %rq_order_less.exit, %if.end.i
  br label %rq_order_less.exit.thread

rq_order_less.exit.thread:                        ; preds = %.thread, %rq_order_less.exit, %if.end86
  %45 = phi ptr [ %rq2, %.thread ], [ %rq1, %rq_order_less.exit ], [ %rq1, %if.end86 ]
  %46 = phi ptr [ %rq1, %.thread ], [ %rq2, %rq_order_less.exit ], [ %rq2, %if.end86 ]
  %47 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %47, -16384
  %48 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %48, i32 0, i32 1
  %49 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %50, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@double_rq_lock, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %rq_order_less.exit.thread
  tail call void @_raw_spin_lock_nested(ptr noundef %46, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %rq_order_less.exit.thread
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %46, i32 0, i32 81
  %51 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %52, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %46, i32 0, i32 79
  %53 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %54, %if.then.i.i.i ], [ %46, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %55 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %56, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %46, i32 0, i32 79
  %57 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %58, %if.then.i25.i.i ], [ %46, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %59 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %59, -16384
  %60 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %60, i32 0, i32 1
  %61 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %62, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %46, i32 0, i32 81
  %63 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i = icmp eq i32 %64, 0
  br i1 %tobool.not.i, label %__rq_lockp.exit, label %if.then.i

if.then.i:                                        ; preds = %raw_spin_rq_lock.exit
  %core.i127 = getelementptr inbounds %struct.rq, ptr %46, i32 0, i32 79
  %65 = ptrtoint ptr %core.i127 to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %core.i127, align 8
  br label %__rq_lockp.exit

__rq_lockp.exit:                                  ; preds = %if.then.i, %raw_spin_rq_lock.exit
  %retval.0.i128 = phi ptr [ %66, %if.then.i ], [ %46, %raw_spin_rq_lock.exit ]
  %core_enabled.i129 = getelementptr inbounds %struct.rq, ptr %45, i32 0, i32 81
  %67 = ptrtoint ptr %core_enabled.i129 to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %core_enabled.i129, align 128
  %tobool.not.i130 = icmp eq i32 %68, 0
  br i1 %tobool.not.i130, label %__rq_lockp.exit134, label %if.then.i132

if.then.i132:                                     ; preds = %__rq_lockp.exit
  %core.i131 = getelementptr inbounds %struct.rq, ptr %45, i32 0, i32 79
  %69 = ptrtoint ptr %core.i131 to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %core.i131, align 8
  br label %__rq_lockp.exit134

__rq_lockp.exit134:                               ; preds = %if.then.i132, %__rq_lockp.exit
  %retval.0.i133 = phi ptr [ %70, %if.then.i132 ], [ %45, %__rq_lockp.exit ]
  %cmp = icmp eq ptr %retval.0.i128, %retval.0.i133
  br i1 %cmp, label %return, label %if.end105

if.end105:                                        ; preds = %__rq_lockp.exit134
  %71 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %71, -16384
  %72 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %72, i32 0, i32 1
  %73 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %74, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@double_rq_lock, %for.cond.i)) #33
          to label %if.then.i135 [label %for.cond.i], !srcloc !1202

if.then.i135:                                     ; preds = %if.end105
  tail call void @_raw_spin_lock_nested(ptr noundef %45, i32 noundef 1) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock_nested.exit

for.cond.i:                                       ; preds = %if.end11.i, %if.end105
  %75 = ptrtoint ptr %core_enabled.i129 to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %core_enabled.i129, align 128
  %tobool.not.i.i = icmp eq i32 %76, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i136

if.then.i.i136:                                   ; preds = %for.cond.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %45, i32 0, i32 79
  %77 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i136, %for.cond.i
  %retval.0.i.i = phi ptr [ %78, %if.then.i.i136 ], [ %45, %for.cond.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i, i32 noundef 1) #33
  %79 = ptrtoint ptr %core_enabled.i129 to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %core_enabled.i129, align 128
  %tobool.not.i23.i = icmp eq i32 %80, 0
  br i1 %tobool.not.i23.i, label %__rq_lockp.exit27.i, label %if.then.i25.i

if.then.i25.i:                                    ; preds = %__rq_lockp.exit.i
  %core.i24.i = getelementptr inbounds %struct.rq, ptr %45, i32 0, i32 79
  %81 = ptrtoint ptr %core.i24.i to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load ptr, ptr %core.i24.i, align 8
  br label %__rq_lockp.exit27.i

__rq_lockp.exit27.i:                              ; preds = %if.then.i25.i, %__rq_lockp.exit.i
  %retval.0.i26.i = phi ptr [ %82, %if.then.i25.i ], [ %45, %__rq_lockp.exit.i ]
  %cmp.i137 = icmp eq ptr %retval.0.i.i, %retval.0.i26.i
  br i1 %cmp.i137, label %do.body8.i, label %if.end11.i, !prof !1191

do.body8.i:                                       ; preds = %__rq_lockp.exit27.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock_nested.exit

if.end11.i:                                       ; preds = %__rq_lockp.exit27.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i) #33
  br label %for.cond.i

raw_spin_rq_lock_nested.exit:                     ; preds = %do.body8.i, %if.then.i135
  %83 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i = and i32 %83, -16384
  %84 = inttoptr i32 %and.i.i.i19.i to ptr
  %preempt_count.i.i20.i = getelementptr inbounds %struct.thread_info, ptr %84, i32 0, i32 1
  %85 = ptrtoint ptr %preempt_count.i.i20.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load volatile i32, ptr %preempt_count.i.i20.i, align 4
  %sub.i21.i = add i32 %86, -1
  store volatile i32 %sub.i21.i, ptr %preempt_count.i.i20.i, align 4
  br label %return

return:                                           ; preds = %raw_spin_rq_lock_nested.exit, %__rq_lockp.exit134
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @warn_slowpath_fmt(ptr noundef, i32 noundef, i32 noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @raw_spin_rq_lock(ptr noundef %rq) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %3, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_lock, %for.cond.i)) #33
          to label %if.then.i [label %for.cond.i], !srcloc !1202

if.then.i:                                        ; preds = %entry
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock_nested.exit

for.cond.i:                                       ; preds = %if.end11.i, %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %4 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %5, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %for.cond.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %6 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %for.cond.i
  %retval.0.i.i = phi ptr [ %7, %if.then.i.i ], [ %rq, %for.cond.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i, i32 noundef 0) #33
  %8 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i23.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i23.i, label %__rq_lockp.exit27.i, label %if.then.i25.i

if.then.i25.i:                                    ; preds = %__rq_lockp.exit.i
  %core.i24.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %10 = ptrtoint ptr %core.i24.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i24.i, align 8
  br label %__rq_lockp.exit27.i

__rq_lockp.exit27.i:                              ; preds = %if.then.i25.i, %__rq_lockp.exit.i
  %retval.0.i26.i = phi ptr [ %11, %if.then.i25.i ], [ %rq, %__rq_lockp.exit.i ]
  %cmp.i = icmp eq ptr %retval.0.i.i, %retval.0.i26.i
  br i1 %cmp.i, label %do.body8.i, label %if.end11.i, !prof !1191

do.body8.i:                                       ; preds = %__rq_lockp.exit27.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock_nested.exit

if.end11.i:                                       ; preds = %__rq_lockp.exit27.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i) #33
  br label %for.cond.i

raw_spin_rq_lock_nested.exit:                     ; preds = %do.body8.i, %if.then.i
  %12 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i19.i to ptr
  %preempt_count.i.i20.i = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i20.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i.i20.i, align 4
  %sub.i21.i = add i32 %15, -1
  store volatile i32 %sub.i21.i, ptr %preempt_count.i.i20.i, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local ptr @__task_rq_lock(ptr noundef %p, ptr nocapture noundef writeonly %rf) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %if.end, label %land.rhs

land.rhs:                                         ; preds = %entry
  %dep_map = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef -1) #33
  %cmp.not = icmp eq i32 %call.i, 0
  br i1 %cmp.not, label %do.end, label %if.end, !prof !1192

do.end:                                           ; preds = %land.rhs
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 563, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %land.rhs, %entry
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  br label %for.cond

for.cond:                                         ; preds = %for.cond.backedge, %if.end
  %1 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 3
  %3 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %4
  %5 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %arrayidx, align 4
  %add = add i32 %6, ptrtoint (ptr @runqueues to i32)
  %7 = inttoptr i32 %add to ptr
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %11, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__task_rq_lock, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %for.cond
  tail call void @_raw_spin_lock_nested(ptr noundef %7, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %for.cond
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 81
  %12 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %14 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %15, %if.then.i.i.i ], [ %7, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %16 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %17, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %18 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %19, %if.then.i25.i.i ], [ %7, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %23, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %24 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %stack.i, align 4
  %cpu.i82 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu.i82 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %cpu.i82, align 4
  %arrayidx38 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %27
  %28 = ptrtoint ptr %arrayidx38 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx38, align 4
  %add39 = add i32 %29, ptrtoint (ptr @runqueues to i32)
  %30 = inttoptr i32 %add39 to ptr
  %cmp40 = icmp eq ptr %7, %30
  br i1 %cmp40, label %land.rhs41, label %if.end54, !prof !1191

land.rhs41:                                       ; preds = %raw_spin_rq_lock.exit
  %31 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %32, 2
  br i1 %cmp.i.not, label %if.end54, label %if.then53, !prof !1192

if.then53:                                        ; preds = %land.rhs41
  %33 = inttoptr i32 %add to ptr
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 81
  %34 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %35, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i83

if.then.i.i83:                                    ; preds = %if.then53
  %core.i.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 79
  %36 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i83, %if.then53
  %retval.0.i.i = phi ptr [ %37, %if.then.i.i83 ], [ %33, %if.then53 ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call1.i = tail call i32 @lock_pin_lock(ptr noundef %dep_map.i) #33
  %38 = ptrtoint ptr %cookie.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %call1.i, ptr %cookie.i, align 4
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 25
  %39 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %clock_update_flags.i, align 4
  %and.i = and i32 %40, 3
  store i32 %and.i, ptr %clock_update_flags.i, align 4
  %clock_update_flags2.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %41 = ptrtoint ptr %clock_update_flags2.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 0, ptr %clock_update_flags2.i, align 4
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 39
  %42 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %balance_callback.i, align 8
  %tobool.not.i = icmp ne ptr %43, null
  %cmp.i84 = icmp ne ptr %43, @balance_push_callback
  %spec.select.i = and i1 %tobool.not.i, %cmp.i84
  br i1 %spec.select.i, label %land.rhs6.i, label %rq_pin_lock.exit

land.rhs6.i:                                      ; preds = %__rq_lockp.exit.i
  %.b48.i = load i1, ptr @rq_pin_lock.__already_done, align 1
  br i1 %.b48.i, label %rq_pin_lock.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs6.i
  store i1 true, ptr @rq_pin_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1545, i32 noundef 9, ptr noundef nonnull @.str.178) #33
  br label %rq_pin_lock.exit

rq_pin_lock.exit:                                 ; preds = %if.then.i, %land.rhs6.i, %__rq_lockp.exit.i
  ret ptr %33

if.end54:                                         ; preds = %land.rhs41, %raw_spin_rq_lock.exit
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__task_rq_lock, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %if.end54
  %core_enabled.i.i.i85 = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 81
  %44 = ptrtoint ptr %core_enabled.i.i.i85 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %core_enabled.i.i.i85, align 128
  %tobool3.i.not.i.i = icmp eq i32 %45, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i87

if.then.i.i87:                                    ; preds = %land.rhs.i.i.i
  %core.i.i86 = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %46 = ptrtoint ptr %core.i.i86 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %core.i.i86, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i87, %land.rhs.i.i.i, %if.end54
  %retval.0.i.i88 = phi ptr [ %47, %if.then.i.i87 ], [ %7, %land.rhs.i.i.i ], [ %7, %if.end54 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i88) #33
  %48 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i90.not92 = icmp eq i32 %49, 2
  br i1 %cmp.i90.not92, label %do.end67, label %for.cond.backedge, !prof !1192

for.cond.backedge:                                ; preds = %do.end67, %raw_spin_rq_unlock.exit
  br label %for.cond

do.end67:                                         ; preds = %do.end67, %raw_spin_rq_unlock.exit
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1212
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1213
  %50 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i90.not = icmp eq i32 %51, 2
  br i1 %cmp.i90.not, label %do.end67, label %for.cond.backedge, !prof !1192
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local ptr @task_rq_lock(ptr noundef %p, ptr nocapture noundef %rf) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  br label %for.cond

for.cond:                                         ; preds = %for.cond.backedge, %entry
  %call = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 %call, ptr %rf, align 4
  %1 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 3
  %3 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %4
  %5 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %arrayidx, align 4
  %add = add i32 %6, ptrtoint (ptr @runqueues to i32)
  %7 = inttoptr i32 %add to ptr
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %11, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@task_rq_lock, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %for.cond
  tail call void @_raw_spin_lock_nested(ptr noundef %7, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %for.cond
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 81
  %12 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %14 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %15, %if.then.i.i.i ], [ %7, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %16 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %17, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %18 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %19, %if.then.i25.i.i ], [ %7, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %23, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %24 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %stack.i, align 4
  %cpu.i62 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu.i62 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %cpu.i62, align 4
  %arrayidx15 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %27
  %28 = ptrtoint ptr %arrayidx15 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx15, align 4
  %add16 = add i32 %29, ptrtoint (ptr @runqueues to i32)
  %30 = inttoptr i32 %add16 to ptr
  %cmp17 = icmp eq ptr %7, %30
  br i1 %cmp17, label %land.rhs, label %if.end, !prof !1191

land.rhs:                                         ; preds = %raw_spin_rq_lock.exit
  %31 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %32, 2
  br i1 %cmp.i.not, label %if.end, label %if.then, !prof !1192

if.then:                                          ; preds = %land.rhs
  %33 = inttoptr i32 %add to ptr
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 81
  %34 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %35, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i63

if.then.i.i63:                                    ; preds = %if.then
  %core.i.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 79
  %36 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i63, %if.then
  %retval.0.i.i = phi ptr [ %37, %if.then.i.i63 ], [ %33, %if.then ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call1.i = tail call i32 @lock_pin_lock(ptr noundef %dep_map.i) #33
  %38 = ptrtoint ptr %cookie.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %call1.i, ptr %cookie.i, align 4
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 25
  %39 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %clock_update_flags.i, align 4
  %and.i = and i32 %40, 3
  store i32 %and.i, ptr %clock_update_flags.i, align 4
  %clock_update_flags2.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %41 = ptrtoint ptr %clock_update_flags2.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 0, ptr %clock_update_flags2.i, align 4
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %33, i32 0, i32 39
  %42 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %balance_callback.i, align 8
  %tobool.not.i = icmp ne ptr %43, null
  %cmp.i64 = icmp ne ptr %43, @balance_push_callback
  %spec.select.i = and i1 %tobool.not.i, %cmp.i64
  br i1 %spec.select.i, label %land.rhs6.i, label %rq_pin_lock.exit

land.rhs6.i:                                      ; preds = %__rq_lockp.exit.i
  %.b48.i = load i1, ptr @rq_pin_lock.__already_done, align 1
  br i1 %.b48.i, label %rq_pin_lock.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs6.i
  store i1 true, ptr @rq_pin_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1545, i32 noundef 9, ptr noundef nonnull @.str.178) #33
  br label %rq_pin_lock.exit

rq_pin_lock.exit:                                 ; preds = %if.then.i, %land.rhs6.i, %__rq_lockp.exit.i
  ret ptr %33

if.end:                                           ; preds = %land.rhs, %raw_spin_rq_lock.exit
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@task_rq_lock, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %if.end
  %core_enabled.i.i.i65 = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 81
  %44 = ptrtoint ptr %core_enabled.i.i.i65 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %core_enabled.i.i.i65, align 128
  %tobool3.i.not.i.i = icmp eq i32 %45, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i67

if.then.i.i67:                                    ; preds = %land.rhs.i.i.i
  %core.i.i66 = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %46 = ptrtoint ptr %core.i.i66 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %core.i.i66, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i67, %land.rhs.i.i.i, %if.end
  %retval.0.i.i68 = phi ptr [ %47, %if.then.i.i67 ], [ %7, %land.rhs.i.i.i ], [ %7, %if.end ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i68) #33
  %48 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %49) #33
  %50 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i70.not72 = icmp eq i32 %51, 2
  br i1 %cmp.i70.not72, label %do.end45, label %for.cond.backedge, !prof !1192

for.cond.backedge:                                ; preds = %do.end45, %raw_spin_rq_unlock.exit
  br label %for.cond

do.end45:                                         ; preds = %do.end45, %raw_spin_rq_unlock.exit
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1214
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1215
  %52 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load volatile i32, ptr %on_rq.i, align 4
  %cmp.i70.not = icmp eq i32 %53, 2
  br i1 %cmp.i70.not, label %do.end45, label %for.cond.backedge, !prof !1192
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_raw_spin_lock_irqsave(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock_irqrestore(ptr noundef, i32 noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @update_rq_clock(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %clock_update_flags = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %5 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %clock_update_flags, align 4
  %and = and i32 %6, 2
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end, label %cleanup

if.end:                                           ; preds = %lockdep_assert_rq_held.exit
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 12), ptr blockaddress(@update_rq_clock, %if.then1)) #33
          to label %if.end42 [label %if.then1], !srcloc !1202

if.then1:                                         ; preds = %if.end
  %7 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %clock_update_flags, align 4
  %and3 = and i32 %8, 4
  %tobool4.not = icmp eq i32 %and3, 0
  br i1 %tobool4.not, label %if.end42, label %land.rhs

land.rhs:                                         ; preds = %if.then1
  %.b60 = load i1, ptr @update_rq_clock.__already_done, align 1
  br i1 %.b60, label %if.end42, label %if.then12, !prof !1191

if.then12:                                        ; preds = %land.rhs
  store i1 true, ptr @update_rq_clock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 690, i32 noundef 9, ptr noundef nonnull @.str.2) #33
  br label %if.end42

if.end42:                                         ; preds = %if.then12, %land.rhs, %if.then1, %if.end
  %9 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %clock_update_flags, align 4
  %or = or i32 %10, 4
  store i32 %or, ptr %clock_update_flags, align 4
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %11 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu.i, align 4
  %call45 = tail call i64 @sched_clock_cpu(i32 noundef %12) #33
  %clock = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 26
  %13 = ptrtoint ptr %clock to i32
  call void @__asan_load8_noabort(i32 %13)
  %14 = load i64, ptr %clock, align 32
  %sub = sub i64 %call45, %14
  %cmp = icmp slt i64 %sub, 0
  br i1 %cmp, label %cleanup, label %if.end47

if.end47:                                         ; preds = %if.end42
  %15 = ptrtoint ptr %clock to i32
  call void @__asan_store8_noabort(i32 %15)
  store i64 %call45, ptr %clock, align 32
  tail call fastcc void @update_rq_clock_task(ptr noundef %rq, i64 noundef %sub)
  br label %cleanup

cleanup:                                          ; preds = %if.end47, %if.end42, %lockdep_assert_rq_held.exit
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i64 @sched_clock_cpu(i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @update_rq_clock_task(ptr noundef %rq, i64 noundef %delta) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %0 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %1
  %2 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %3, ptrtoint (ptr @cpu_irqtime to i32)
  %4 = inttoptr i32 %add.i to ptr
  %sync.i = getelementptr inbounds %struct.irqtime, ptr %4, i32 0, i32 3
  %dep_map.c48.i.i.i = getelementptr inbounds %struct.irqtime, ptr %4, i32 0, i32 3, i32 0, i32 1
  br label %do.body2.i

do.body2.i:                                       ; preds = %__u64_stats_fetch_begin.exit.i, %entry
  %5 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %and.i.i.i.i = and i32 %5, 128
  %tobool.not.i.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool.not.i.i.i, label %if.then.i.i.i, label %do.body24.critedge.i.i.i

if.then.i.i.i:                                    ; preds = %do.body2.i
  tail call void @trace_hardirqs_off() #33
  %6 = tail call ptr @llvm.returnaddress(i32 0) #33
  %7 = ptrtoint ptr %6 to i32
  tail call void @lock_acquire(ptr noundef %dep_map.c48.i.i.i, i32 noundef 0, i32 noundef 0, i32 noundef 2, i32 noundef 1, ptr noundef null, i32 noundef %7) #33
  tail call void @lock_release(ptr noundef %dep_map.c48.i.i.i, i32 noundef %7) #33
  tail call void @trace_hardirqs_on() #33
  br label %do.body24.i.i.i

do.body24.critedge.i.i.i:                         ; preds = %do.body2.i
  %8 = tail call ptr @llvm.returnaddress(i32 0) #33
  %9 = ptrtoint ptr %8 to i32
  tail call void @lock_acquire(ptr noundef %dep_map.c48.i.i.i, i32 noundef 0, i32 noundef 0, i32 noundef 2, i32 noundef 1, ptr noundef null, i32 noundef %9) #33
  tail call void @lock_release(ptr noundef %dep_map.c48.i.i.i, i32 noundef %9) #33
  br label %do.body24.i.i.i

do.body24.i.i.i:                                  ; preds = %do.body24.critedge.i.i.i, %if.then.i.i.i
  %10 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i.i = and i32 %10, 128
  %tobool32.not.i.i.i = icmp eq i32 %and.i.i.i.i.i, 0
  br i1 %tobool32.not.i.i.i, label %if.then36.i.i.i, label %seqcount_lockdep_reader_access.exit.i.i, !prof !1192

if.then36.i.i.i:                                  ; preds = %do.body24.i.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %seqcount_lockdep_reader_access.exit.i.i

seqcount_lockdep_reader_access.exit.i.i:          ; preds = %if.then36.i.i.i, %do.body24.i.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %5) #33, !srcloc !1218
  %11 = ptrtoint ptr %sync.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %sync.i, align 4
  %and18.i.i = and i32 %12, 1
  %tobool.not19.i.i = icmp eq i32 %and18.i.i, 0
  br i1 %tobool.not19.i.i, label %__u64_stats_fetch_begin.exit.i, label %do.end.i.i

do.end.i.i:                                       ; preds = %do.end.i.i, %seqcount_lockdep_reader_access.exit.i.i
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1219
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1220
  %13 = ptrtoint ptr %sync.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %sync.i, align 4
  %and.i.i = and i32 %14, 1
  %tobool.not.i.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool.not.i.i, label %__u64_stats_fetch_begin.exit.i, label %do.end.i.i

__u64_stats_fetch_begin.exit.i:                   ; preds = %do.end.i.i, %seqcount_lockdep_reader_access.exit.i.i
  %.lcssa.i.i = phi i32 [ %12, %seqcount_lockdep_reader_access.exit.i.i ], [ %14, %do.end.i.i ]
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1221
  %15 = ptrtoint ptr %4 to i32
  call void @__asan_load8_noabort(i32 %15)
  %16 = load i64, ptr %4, align 8
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1222
  %17 = ptrtoint ptr %sync.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %sync.i, align 4
  %cmp.i.i.i.not.i = icmp eq i32 %18, %.lcssa.i.i
  br i1 %cmp.i.i.i.not.i, label %irq_time_read.exit, label %do.body2.i

irq_time_read.exit:                               ; preds = %__u64_stats_fetch_begin.exit.i
  %prev_irq_time = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 60
  %19 = ptrtoint ptr %prev_irq_time to i32
  call void @__asan_load8_noabort(i32 %19)
  %20 = load i64, ptr %prev_irq_time, align 16
  %sub = sub i64 %16, %20
  %21 = tail call i64 @llvm.smin.i64(i64 %sub, i64 %delta)
  %add = add i64 %21, %20
  %22 = ptrtoint ptr %prev_irq_time to i32
  call void @__asan_store8_noabort(i32 %22)
  store i64 %add, ptr %prev_irq_time, align 16
  %sub3 = sub i64 %delta, %21
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @paravirt_steal_rq_enabled, ptr blockaddress(@update_rq_clock_task, %if.then5)) #33
          to label %if.end16 [label %if.then5], !srcloc !1202

if.then5:                                         ; preds = %irq_time_read.exit
  %23 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %cpu.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @__SCK__pv_steal_clock to i32))
  %25 = load ptr, ptr @__SCK__pv_steal_clock, align 4
  %call.i = tail call i64 %25(i32 noundef %24) #33
  %prev_steal_time_rq = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 62
  %26 = ptrtoint ptr %prev_steal_time_rq to i32
  call void @__asan_load8_noabort(i32 %26)
  %27 = load i64, ptr %prev_steal_time_rq, align 64
  %sub8 = sub i64 %call.i, %27
  %cmp9 = icmp sgt i64 %sub8, %sub3
  br i1 %cmp9, label %if.then11, label %if.end12, !prof !1192

if.then11:                                        ; preds = %if.then5
  br label %if.end12

if.end12:                                         ; preds = %if.then11, %if.then5
  %steal.0 = phi i64 [ %sub3, %if.then11 ], [ %sub8, %if.then5 ]
  %add14 = add i64 %steal.0, %27
  %28 = ptrtoint ptr %prev_steal_time_rq to i32
  call void @__asan_store8_noabort(i32 %28)
  store i64 %add14, ptr %prev_steal_time_rq, align 64
  %sub15 = sub i64 %sub3, %steal.0
  br label %if.end16

if.end16:                                         ; preds = %if.end12, %irq_time_read.exit
  %delta.addr.0 = phi i64 [ %sub15, %if.end12 ], [ %sub3, %irq_time_read.exit ]
  %steal.1 = phi i64 [ %steal.0, %if.end12 ], [ 0, %irq_time_read.exit ]
  %clock_task = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 28
  %29 = ptrtoint ptr %clock_task to i32
  call void @__asan_load8_noabort(i32 %29)
  %30 = load i64, ptr %clock_task, align 128
  %add17 = add i64 %30, %delta.addr.0
  store i64 %add17, ptr %clock_task, align 128
  %add18 = add i64 %steal.1, %21
  %tobool19.not = icmp eq i64 %add18, 0
  br i1 %tobool19.not, label %if.end24, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.end16
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr (i8, ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 9), i32 1), ptr blockaddress(@update_rq_clock_task, %if.end24)) #33
          to label %if.then21 [label %if.end24], !srcloc !1202

if.then21:                                        ; preds = %land.lhs.true
  %call23 = tail call i32 @update_irq_load_avg(ptr noundef %rq, i64 noundef %add18) #33
  br label %if.end24

if.end24:                                         ; preds = %if.then21, %land.lhs.true, %if.end16
  %curr.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %31 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %curr.i, align 8
  %flags.i.i = getelementptr inbounds %struct.task_struct, ptr %32, i32 0, i32 3
  %33 = ptrtoint ptr %flags.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %flags.i.i, align 4
  %and.i.i50 = and i32 %34, 2
  %tobool.i.not.i = icmp eq i32 %and.i.i50, 0
  br i1 %tobool.i.not.i, label %if.end.i, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %if.end24
  %call2.i = tail call fastcc i64 @rq_clock_task(ptr noundef %rq) #33
  %clock_pelt.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 29
  %35 = ptrtoint ptr %clock_pelt.i to i32
  call void @__asan_store8_noabort(i32 %35)
  store i64 %call2.i, ptr %clock_pelt.i, align 8
  br label %update_rq_clock_pelt.exit

if.end.i:                                         ; preds = %if.end24
  %36 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %cpu.i, align 4
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %37
  %38 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %39, ptrtoint (ptr @cpu_scale to i32)
  %40 = inttoptr i32 %add.i.i to ptr
  %41 = ptrtoint ptr %40 to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %40, align 4
  %conv.i = zext i32 %42 to i64
  %mul.i = mul i64 %delta.addr.0, %conv.i
  %shr9.i = ashr i64 %mul.i, 10
  %clock_pelt10.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 29
  %43 = ptrtoint ptr %clock_pelt10.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %clock_pelt10.i, align 8
  %add.i51 = add i64 %shr9.i, %44
  store i64 %add.i51, ptr %clock_pelt10.i, align 8
  br label %update_rq_clock_pelt.exit

update_rq_clock_pelt.exit:                        ; preds = %if.end.i, %if.then.i
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @hrtick_start(ptr noundef %rq, i64 noundef %delay) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i64 @llvm.smax.i64(i64 %delay, i64 10000)
  %base = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 66, i32 3
  %1 = ptrtoint ptr %base to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %base, align 4
  %get_time = getelementptr inbounds %struct.hrtimer_clock_base, ptr %2, i32 0, i32 6
  %3 = ptrtoint ptr %get_time to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %get_time, align 4
  %call = tail call i64 %4() #33
  %add = add i64 %call, %0
  %hrtick_time = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 67
  %5 = ptrtoint ptr %hrtick_time to i32
  call void @__asan_store8_noabort(i32 %5)
  store i64 %add, ptr %hrtick_time, align 16
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add4 = add i32 %11, ptrtoint (ptr @runqueues to i32)
  %12 = inttoptr i32 %add4 to ptr
  %cmp5 = icmp eq ptr %12, %rq
  br i1 %cmp5, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %hrtick_timer.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 66
  tail call void @hrtimer_start_range_ns(ptr noundef %hrtick_timer.i, i64 noundef %add, i64 noundef 0, i32 noundef 10) #33
  br label %if.end

if.else:                                          ; preds = %entry
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %13 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %cpu.i, align 4
  %hrtick_csd = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 65
  %call7 = tail call i32 @smp_call_function_single_async(i32 noundef %14, ptr noundef %hrtick_csd) #33
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @smp_call_function_single_async(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_q_add(ptr nocapture noundef %head, ptr noundef %task) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %wake_q.i = getelementptr inbounds %struct.task_struct, ptr %task, i32 0, i32 129
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1223
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %wake_q.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %wake_q.i, i32 1, i32 3, i32 1) #33
  br label %do.body.i.i

do.body.i.i:                                      ; preds = %do.body.i.i, %entry
  %0 = tail call { i32, i32 } asm sideeffect "@ __cmpxchg4\0A\09ldrex\09$1, [$2]\0A\09mov\09$0, #0\0A\09teq\09$1, $3\0A\09strexeq $0, $4, [$2]\0A", "=&r,=&r,r,Ir,r,~{memory},~{cc}"(ptr %wake_q.i, i32 0, i32 1) #33, !srcloc !1224
  %asmresult.i.i = extractvalue { i32, i32 } %0, 0
  %tobool.not.i.i = icmp eq i32 %asmresult.i.i, 0
  br i1 %tobool.not.i.i, label %__cmpxchg.exit.i, label %do.body.i.i

__cmpxchg.exit.i:                                 ; preds = %do.body.i.i
  %asmresult1.i.i = extractvalue { i32, i32 } %0, 1
  %tobool.not.i = icmp eq i32 %asmresult1.i.i, 0
  br i1 %tobool.not.i, label %if.then, label %if.end, !prof !1191

if.then:                                          ; preds = %__cmpxchg.exit.i
  %lastp.i = getelementptr inbounds %struct.wake_q_head, ptr %head, i32 0, i32 1
  %1 = ptrtoint ptr %lastp.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %lastp.i, align 4
  %3 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %wake_q.i, ptr %2, align 4
  store ptr %wake_q.i, ptr %lastp.i, align 4
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %task, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %4 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %4, 0
  %tobool1.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i, label %if.end15.sink.split.i.i.i.i, label %if.else.i.i.i.i, !prof !1192

if.else.i.i.i.i:                                  ; preds = %if.then
  %add.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i, 1
  %5 = or i32 %add.i.i.i.i, %asmresult.i.i.i.i.i.i
  %.not.i.i.i.i = icmp sgt i32 %5, -1
  br i1 %.not.i.i.i.i, label %if.end, label %if.end15.sink.split.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i:                      ; preds = %if.else.i.i.i.i, %if.then
  %.sink.i.i.i.i = phi i32 [ 2, %if.then ], [ 1, %if.else.i.i.i.i ]
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef %.sink.i.i.i.i) #33
  br label %if.end

if.end:                                           ; preds = %if.end15.sink.split.i.i.i.i, %if.else.i.i.i.i, %__cmpxchg.exit.i
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_q_add_safe(ptr nocapture noundef %head, ptr noundef %task) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %wake_q.i = getelementptr inbounds %struct.task_struct, ptr %task, i32 0, i32 129
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1223
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %wake_q.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %wake_q.i, i32 1, i32 3, i32 1) #33
  br label %do.body.i.i

do.body.i.i:                                      ; preds = %do.body.i.i, %entry
  %0 = tail call { i32, i32 } asm sideeffect "@ __cmpxchg4\0A\09ldrex\09$1, [$2]\0A\09mov\09$0, #0\0A\09teq\09$1, $3\0A\09strexeq $0, $4, [$2]\0A", "=&r,=&r,r,Ir,r,~{memory},~{cc}"(ptr %wake_q.i, i32 0, i32 1) #33, !srcloc !1224
  %asmresult.i.i = extractvalue { i32, i32 } %0, 0
  %tobool.not.i.i = icmp eq i32 %asmresult.i.i, 0
  br i1 %tobool.not.i.i, label %__cmpxchg.exit.i, label %do.body.i.i

__cmpxchg.exit.i:                                 ; preds = %do.body.i.i
  %asmresult1.i.i = extractvalue { i32, i32 } %0, 1
  %tobool.not.i = icmp eq i32 %asmresult1.i.i, 0
  br i1 %tobool.not.i, label %__wake_q_add.exit.thread, label %if.then, !prof !1191

__wake_q_add.exit.thread:                         ; preds = %__cmpxchg.exit.i
  %lastp.i = getelementptr inbounds %struct.wake_q_head, ptr %head, i32 0, i32 1
  %1 = ptrtoint ptr %lastp.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %lastp.i, align 4
  %3 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %wake_q.i, ptr %2, align 4
  store ptr %wake_q.i, ptr %lastp.i, align 4
  br label %if.end

if.then:                                          ; preds = %__cmpxchg.exit.i
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %task, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %4 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %4, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %if.then
  %.not.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i, label %if.end, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %if.end

if.then.i:                                        ; preds = %if.then
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  tail call void @__put_task_struct(ptr noundef %task) #33
  br label %if.end

if.end:                                           ; preds = %if.then.i, %if.then10.i.i.i.i, %if.end5.i.i.i.i, %__wake_q_add.exit.thread
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_up_q(ptr nocapture noundef readonly %head) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %head to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %head, align 4
  %cmp.not6 = icmp eq ptr %1, inttoptr (i32 1 to ptr)
  br i1 %cmp.not6, label %while.end, label %while.body

while.body:                                       ; preds = %put_task_struct.exit, %entry
  %node.07 = phi ptr [ %3, %put_task_struct.exit ], [ %1, %entry ]
  %add.ptr = getelementptr i8, ptr %node.07, i32 -1872
  %2 = ptrtoint ptr %node.07 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %node.07, align 4
  store ptr null, ptr %node.07, align 16
  %call.i = tail call fastcc i32 @try_to_wake_up(ptr noundef %add.ptr, i32 noundef 3, i32 noundef 0) #33
  %usage.i = getelementptr i8, ptr %node.07, i32 -1864
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %4 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %4, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %while.body
  %.not.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i, label %put_task_struct.exit, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %put_task_struct.exit

if.then.i:                                        ; preds = %while.body
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  tail call void @__put_task_struct(ptr noundef %add.ptr) #33
  br label %put_task_struct.exit

put_task_struct.exit:                             ; preds = %if.then.i, %if.then10.i.i.i.i, %if.end5.i.i.i.i
  %cmp.not = icmp eq ptr %3, inttoptr (i32 1 to ptr)
  br i1 %cmp.not, label %while.end, label %while.body

while.end:                                        ; preds = %put_task_struct.exit, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @wake_up_process(ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @try_to_wake_up(ptr noundef %p, i32 noundef 3, i32 noundef 0)
  ret i32 %call
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @smp_send_reschedule(i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @resched_cpu(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %3 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %and.i.i = and i32 %3, 128
  %tobool.not.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool.not.i, label %if.then.i, label %do.end11.i

if.then.i:                                        ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.end11.i

do.end11.i:                                       ; preds = %if.then.i, %entry
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %7, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@resched_cpu, %for.cond.i.i.i)) #33
          to label %if.then.i.i.i [label %for.cond.i.i.i], !srcloc !1202

if.then.i.i.i:                                    ; preds = %do.end11.i
  tail call void @_raw_spin_lock_nested(ptr noundef %2, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %_raw_spin_rq_lock_irqsave.exit

for.cond.i.i.i:                                   ; preds = %if.end11.i.i.i, %do.end11.i
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %8 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %for.cond.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %10 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %for.cond.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %11, %if.then.i.i.i.i ], [ %2, %for.cond.i.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i.i, i32 noundef 0) #33
  %12 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i23.i.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i23.i.i.i, label %__rq_lockp.exit27.i.i.i, label %if.then.i25.i.i.i

if.then.i25.i.i.i:                                ; preds = %__rq_lockp.exit.i.i.i
  %core.i24.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %14 = ptrtoint ptr %core.i24.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %core.i24.i.i.i, align 8
  br label %__rq_lockp.exit27.i.i.i

__rq_lockp.exit27.i.i.i:                          ; preds = %if.then.i25.i.i.i, %__rq_lockp.exit.i.i.i
  %retval.0.i26.i.i.i = phi ptr [ %15, %if.then.i25.i.i.i ], [ %2, %__rq_lockp.exit.i.i.i ]
  %cmp.i.i.i = icmp eq ptr %retval.0.i.i.i.i, %retval.0.i26.i.i.i
  br i1 %cmp.i.i.i, label %do.body8.i.i.i, label %if.end11.i.i.i, !prof !1191

do.body8.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %_raw_spin_rq_lock_irqsave.exit

if.end11.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  br label %for.cond.i.i.i

_raw_spin_rq_lock_irqsave.exit:                   ; preds = %do.body8.i.i.i, %if.then.i.i.i
  %16 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i.i = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i19.i.i.i to ptr
  %preempt_count.i.i20.i.i.i = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i20.i.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i20.i.i.i, align 4
  %sub.i21.i.i.i = add i32 %19, -1
  store volatile i32 %sub.i21.i.i.i, ptr %preempt_count.i.i20.i.i.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %20 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %20, %cpu
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %_raw_spin_rq_lock_irqsave.exit
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i12, !prof !1191

if.then.i.i.i.i12:                                ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i12, %land.rhs.i.i.i.i, %_raw_spin_rq_lock_irqsave.exit
  %div3.i.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %21 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %cpu, 31
  %23 = shl nuw i32 1, %and.i.i.i
  %24 = and i32 %22, %23
  %tobool.i.not = icmp eq i32 %24, 0
  br i1 %tobool.i.not, label %lor.lhs.false, label %if.then

lor.lhs.false:                                    ; preds = %cpu_online.exit
  %25 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %25, -16384
  %26 = inttoptr i32 %and.i to ptr
  %cpu7 = getelementptr inbounds %struct.thread_info, ptr %26, i32 0, i32 3
  %27 = ptrtoint ptr %cpu7 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu7, align 4
  %cmp = icmp eq i32 %28, %cpu
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %lor.lhs.false, %cpu_online.exit
  tail call void @resched_curr(ptr noundef %2)
  br label %if.end

if.end:                                           ; preds = %if.then, %lor.lhs.false
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@resched_cpu, %land.rhs.i.i.i.i14)) #33
          to label %raw_spin_rq_unlock.exit.i [label %land.rhs.i.i.i.i14], !srcloc !1202

land.rhs.i.i.i.i14:                               ; preds = %if.end
  %core_enabled.i.i.i.i13 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %29 = ptrtoint ptr %core_enabled.i.i.i.i13 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %core_enabled.i.i.i.i13, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %30, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock.exit.i, label %if.then.i.i.i15

if.then.i.i.i15:                                  ; preds = %land.rhs.i.i.i.i14
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %31 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %core.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i

raw_spin_rq_unlock.exit.i:                        ; preds = %if.then.i.i.i15, %land.rhs.i.i.i.i14, %if.end
  %retval.0.i.i.i = phi ptr [ %32, %if.then.i.i.i15 ], [ %2, %land.rhs.i.i.i.i14 ], [ %2, %if.end ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br i1 %tobool.not.i, label %if.then.i18, label %do.body2.i

if.then.i18:                                      ; preds = %raw_spin_rq_unlock.exit.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i

do.body2.i:                                       ; preds = %if.then.i18, %raw_spin_rq_unlock.exit.i
  %33 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i19 = and i32 %33, 128
  %tobool10.not.i = icmp eq i32 %and.i.i.i19, 0
  br i1 %tobool10.not.i, label %if.then14.i, label %raw_spin_rq_unlock_irqrestore.exit, !prof !1192

if.then14.i:                                      ; preds = %do.body2.i
  tail call void @warn_bogus_irq_restore() #33
  br label %raw_spin_rq_unlock_irqrestore.exit

raw_spin_rq_unlock_irqrestore.exit:               ; preds = %if.then14.i, %do.body2.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %3) #33, !srcloc !1218
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @_raw_spin_rq_lock_irqsave(ptr noundef %rq) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %and.i = and i32 %0, 128
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %if.then, label %do.end11

if.then:                                          ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.end11

do.end11:                                         ; preds = %if.then, %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %4, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@_raw_spin_rq_lock_irqsave, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %do.end11
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %do.end11
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %5 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %6, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %7 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %8, %if.then.i.i.i ], [ %rq, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %9 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %12, %if.then.i25.i.i ], [ %rq, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %13, -16384
  %14 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 1
  %15 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %16, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  ret i32 %0
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @raw_spin_rq_unlock_irqrestore(ptr noundef %rq, i32 noundef %flags) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_unlock_irqrestore, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %1, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i.i.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core.i.i, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i, %land.rhs.i.i.i, %entry
  %retval.0.i.i = phi ptr [ %3, %if.then.i.i ], [ %rq, %land.rhs.i.i.i ], [ %rq, %entry ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i) #33
  %and.i = and i32 %flags, 128
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %if.then, label %do.body2

if.then:                                          ; preds = %raw_spin_rq_unlock.exit
  tail call void @trace_hardirqs_on() #33
  br label %do.body2

do.body2:                                         ; preds = %if.then, %raw_spin_rq_unlock.exit
  %4 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i = and i32 %4, 128
  %tobool10.not = icmp eq i32 %and.i.i, 0
  br i1 %tobool10.not, label %if.then14, label %do.end, !prof !1192

if.then14:                                        ; preds = %do.body2
  tail call void @warn_bogus_irq_restore() #33
  br label %do.end

do.end:                                           ; preds = %if.then14, %do.body2
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %flags) #33, !srcloc !1218
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @get_nohz_timer_target() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu1 = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu1, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @housekeeping_overridden, ptr blockaddress(@get_nohz_timer_target, %if.then.i62)) #33
          to label %if.then [label %if.then.i62], !srcloc !1202

if.then.i62:                                      ; preds = %entry
  %call3.i = tail call zeroext i1 @housekeeping_test_cpu(i32 noundef %3, i32 noundef 1) #33
  br i1 %call3.i, label %if.then, label %if.end5

if.then:                                          ; preds = %if.then.i62, %entry
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add.i to ptr
  %curr.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 20
  %7 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %curr.i, align 8
  %idle.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 21
  %9 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %idle.i, align 4
  %cmp.not.i = icmp eq ptr %8, %10
  br i1 %cmp.not.i, label %if.end.i, label %cleanup

if.end.i:                                         ; preds = %if.then
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 1
  %11 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %nr_running.i, align 4
  %tobool.not.i63 = icmp eq i32 %12, 0
  br i1 %tobool.not.i63, label %idle_cpu.exit, label %cleanup

idle_cpu.exit:                                    ; preds = %if.end.i
  %ttwu_pending.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 8
  %13 = ptrtoint ptr %ttwu_pending.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %ttwu_pending.i, align 8
  %tobool4.not.i.not = icmp eq i32 %14, 0
  br i1 %tobool4.not.i.not, label %if.end5, label %cleanup

if.end5:                                          ; preds = %idle_cpu.exit, %if.then.i62
  %default_cpu.0 = phi i32 [ %3, %idle_cpu.exit ], [ -1, %if.then.i62 ]
  %call6 = tail call ptr @housekeeping_cpumask(i32 noundef 1) #33
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %18, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end5
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end5
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %19 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %arrayidx, align 4
  %add = add i32 %20, ptrtoint (ptr @runqueues to i32)
  %21 = inttoptr i32 %add to ptr
  %sd12 = getelementptr inbounds %struct.rq, ptr %21, i32 0, i32 36
  %22 = ptrtoint ptr %sd12 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile ptr, ptr %sd12, align 4
  %call.i65 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @sched_domains_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool15.not = icmp eq i32 %call.i65, 0
  br i1 %tobool15.not, label %lor.lhs.false, label %do.end25

lor.lhs.false:                                    ; preds = %rcu_read_lock.exit
  %call16 = tail call i32 @rcu_read_lock_held() #33
  %tobool17.not = icmp eq i32 %call16, 0
  br i1 %tobool17.not, label %land.lhs.true, label %do.end25

land.lhs.true:                                    ; preds = %lor.lhs.false
  %call18 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool19.not = icmp eq i32 %call18, 0
  br i1 %tobool19.not, label %do.end25, label %land.lhs.true20

land.lhs.true20:                                  ; preds = %land.lhs.true
  %.b61 = load i1, ptr @get_nohz_timer_target.__warned, align 1
  br i1 %.b61, label %do.end25, label %if.then22

if.then22:                                        ; preds = %land.lhs.true20
  store i1 true, ptr @get_nohz_timer_target.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 1036, ptr noundef nonnull @.str.3) #33
  br label %do.end25

do.end25:                                         ; preds = %if.then22, %land.lhs.true20, %land.lhs.true, %lor.lhs.false, %rcu_read_lock.exit
  %tobool27.not97 = icmp eq ptr %23, null
  br i1 %tobool27.not97, label %for.end39, label %for.cond28.preheader.lr.ph

for.cond28.preheader.lr.ph:                       ; preds = %do.end25
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %24 = load i32, ptr @nr_cpu_ids, align 4
  br label %for.cond28.preheader

for.cond28.preheader:                             ; preds = %for.inc, %for.cond28.preheader.lr.ph
  %sd.098 = phi ptr [ %23, %for.cond28.preheader.lr.ph ], [ %37, %for.inc ]
  %span.i = getelementptr inbounds %struct.sched_domain, ptr %sd.098, i32 0, i32 41
  %call3094 = tail call i32 @cpumask_next_and(i32 noundef -1, ptr noundef %span.i, ptr noundef %call6) #37
  %cmp95 = icmp ult i32 %call3094, %24
  br i1 %cmp95, label %for.body31, label %for.inc

for.body31:                                       ; preds = %for.cond28.backedge, %for.cond28.preheader
  %call3096 = phi i32 [ %call30, %for.cond28.backedge ], [ %call3094, %for.cond28.preheader ]
  %cmp32 = icmp eq i32 %3, %call3096
  br i1 %cmp32, label %for.cond28.backedge, label %if.end34

for.cond28.backedge:                              ; preds = %idle_cpu.exit79, %for.body31
  %call30 = tail call i32 @cpumask_next_and(i32 noundef %call3096, ptr noundef %span.i, ptr noundef %call6) #37
  %cmp = icmp ult i32 %call30, %24
  br i1 %cmp, label %for.body31, label %for.inc

if.end34:                                         ; preds = %for.body31
  %arrayidx.i66 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call3096
  %25 = ptrtoint ptr %arrayidx.i66 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %arrayidx.i66, align 4
  %add.i67 = add i32 %26, ptrtoint (ptr @runqueues to i32)
  %27 = inttoptr i32 %add.i67 to ptr
  %curr.i68 = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 20
  %28 = ptrtoint ptr %curr.i68 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %curr.i68, align 8
  %idle.i69 = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 21
  %30 = ptrtoint ptr %idle.i69 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %idle.i69, align 4
  %cmp.not.i70 = icmp eq ptr %29, %31
  br i1 %cmp.not.i70, label %if.end.i73, label %unlock

if.end.i73:                                       ; preds = %if.end34
  %nr_running.i71 = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 1
  %32 = ptrtoint ptr %nr_running.i71 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %nr_running.i71, align 4
  %tobool.not.i72 = icmp eq i32 %33, 0
  br i1 %tobool.not.i72, label %idle_cpu.exit79, label %unlock

idle_cpu.exit79:                                  ; preds = %if.end.i73
  %ttwu_pending.i74 = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 8
  %34 = ptrtoint ptr %ttwu_pending.i74 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %ttwu_pending.i74, align 8
  %tobool4.not.i75.not = icmp eq i32 %35, 0
  br i1 %tobool4.not.i75.not, label %for.cond28.backedge, label %unlock

for.inc:                                          ; preds = %for.cond28.backedge, %for.cond28.preheader
  %36 = ptrtoint ptr %sd.098 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %sd.098, align 8
  %tobool27.not = icmp eq ptr %37, null
  br i1 %tobool27.not, label %for.end39, label %for.cond28.preheader

for.end39:                                        ; preds = %for.inc, %do.end25
  %cmp40 = icmp eq i32 %default_cpu.0, -1
  br i1 %cmp40, label %if.then41, label %unlock

if.then41:                                        ; preds = %for.end39
  %call42 = tail call i32 @housekeeping_any_cpu(i32 noundef 1) #33
  br label %unlock

unlock:                                           ; preds = %if.then41, %for.end39, %idle_cpu.exit79, %if.end.i73, %if.end34
  %cpu.0 = phi i32 [ %call42, %if.then41 ], [ %default_cpu.0, %for.end39 ], [ %call3096, %idle_cpu.exit79 ], [ %call3096, %if.end34 ], [ %call3096, %if.end.i73 ]
  %call.i80 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i80, label %rcu_read_unlock.exit, label %land.lhs.true.i83

land.lhs.true.i83:                                ; preds = %unlock
  %call1.i81 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i82 = icmp eq i32 %call1.i81, 0
  br i1 %tobool.not.i82, label %rcu_read_unlock.exit, label %land.lhs.true2.i85

land.lhs.true2.i85:                               ; preds = %land.lhs.true.i83
  %.b4.i84 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i84, label %rcu_read_unlock.exit, label %if.then.i86

if.then.i86:                                      ; preds = %land.lhs.true2.i85
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i86, %land.lhs.true2.i85, %land.lhs.true.i83, %unlock
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i87 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i.i87 to ptr
  %preempt_count.i.i.i.i88 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i.i88 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i.i88, align 4
  %sub.i.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i88, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %cleanup

cleanup:                                          ; preds = %rcu_read_unlock.exit, %idle_cpu.exit, %if.end.i, %if.then
  %retval.0 = phi i32 [ %cpu.0, %rcu_read_unlock.exit ], [ %3, %idle_cpu.exit ], [ %3, %if.then ], [ %3, %if.end.i ]
  ret i32 %retval.0
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @idle_cpu(i32 noundef %cpu) local_unnamed_addr #4 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %curr = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %3 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %curr, align 8
  %idle = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 21
  %5 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %idle, align 4
  %cmp.not = icmp eq ptr %4, %6
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %nr_running = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 1
  %7 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %nr_running, align 4
  %tobool.not = icmp eq i32 %8, 0
  br i1 %tobool.not, label %if.end3, label %cleanup

if.end3:                                          ; preds = %if.end
  %ttwu_pending = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 8
  %9 = ptrtoint ptr %ttwu_pending to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %ttwu_pending, align 8
  %tobool4.not = icmp eq i32 %10, 0
  %. = zext i1 %tobool4.not to i32
  br label %cleanup

cleanup:                                          ; preds = %if.end3, %if.end, %entry
  %retval.0 = phi i32 [ 0, %entry ], [ 0, %if.end ], [ %., %if.end3 ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @housekeeping_cpumask(i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @rcu_read_lock_held() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @debug_lockdep_rcu_enabled() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_rcu_suspicious(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: mustprogress nofree nounwind null_pointer_is_valid readonly willreturn
declare dso_local i32 @cpumask_next_and(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #5

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @housekeeping_any_cpu(i32 noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rcu_read_unlock() unnamed_addr #3 align 64 {
entry:
  %call = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call, label %do.end, label %land.lhs.true

land.lhs.true:                                    ; preds = %entry
  %call1 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not = icmp eq i32 %call1, 0
  br i1 %tobool.not, label %do.end, label %land.lhs.true2

land.lhs.true2:                                   ; preds = %land.lhs.true
  %.b4 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4, label %do.end, label %if.then

if.then:                                          ; preds = %land.lhs.true2
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %do.end

do.end:                                           ; preds = %if.then, %land.lhs.true2, %land.lhs.true, %entry
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %3, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_up_nohz_cpu(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i.i = icmp ugt i32 %0, %cpu
  br i1 %cmp.not.i.i.i.i.i, label %wake_up_full_nohz_cpu.exit, label %land.rhs.i.i.i.i.i

land.rhs.i.i.i.i.i:                               ; preds = %entry
  %.b37.i.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i.i, label %wake_up_full_nohz_cpu.exit, label %if.then.i.i.i.i.i, !prof !1191

if.then.i.i.i.i.i:                                ; preds = %land.rhs.i.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %wake_up_full_nohz_cpu.exit

wake_up_full_nohz_cpu.exit:                       ; preds = %if.then.i.i.i.i.i, %land.rhs.i.i.i.i.i, %entry
  %div3.i.i.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i.i
  %1 = ptrtoint ptr %arrayidx.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile i32, ptr %arrayidx.i.i.i.i, align 4
  %and.i.i.i.i = and i32 %cpu, 31
  %3 = shl nuw i32 1, %and.i.i.i.i
  %4 = and i32 %2, %3
  %tobool.i.not.i = icmp eq i32 %4, 0
  br i1 %tobool.i.not.i, label %if.end, label %if.then

if.then:                                          ; preds = %wake_up_full_nohz_cpu.exit
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i.i to ptr
  %cpu2.i = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu2.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu2.i, align 4
  %cmp.i = icmp eq i32 %8, %cpu
  br i1 %cmp.i, label %if.end, label %if.end.i

if.end.i:                                         ; preds = %if.then
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %9 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %10, ptrtoint (ptr @runqueues to i32)
  %11 = inttoptr i32 %add.i to ptr
  %idle.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 21
  %12 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %idle.i, align 4
  %stack.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %stack.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %stack.i.i.i.i, align 4
  tail call void @_set_bit(i32 noundef 1, ptr noundef %15) #33
  tail call void @smp_send_reschedule(i32 noundef %cpu) #33
  br label %if.end

if.end:                                           ; preds = %if.end.i, %if.then, %wake_up_full_nohz_cpu.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @walk_tg_tree_from(ptr noundef %from, ptr nocapture noundef readonly %down, ptr nocapture noundef readonly %up, ptr noundef %data) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call55 = tail call i32 %down(ptr noundef %from, ptr noundef %data) #33
  %tobool.not56 = icmp eq i32 %call55, 0
  br i1 %tobool.not56, label %do.body, label %out

do.body:                                          ; preds = %for.body, %entry
  %parent.057 = phi ptr [ %child.0, %for.body ], [ %from, %entry ]
  %call2 = tail call i32 @rcu_read_lock_any_held() #33
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %land.lhs.true, label %do.end

land.lhs.true:                                    ; preds = %do.body
  %call4 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool5.not = icmp eq i32 %call4, 0
  br i1 %tobool5.not, label %do.end, label %land.lhs.true6

land.lhs.true6:                                   ; preds = %land.lhs.true
  %.b47 = load i1, ptr @walk_tg_tree_from.__warned, align 1
  br i1 %.b47, label %do.end, label %if.then8

if.then8:                                         ; preds = %land.lhs.true6
  store i1 true, ptr @walk_tg_tree_from.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 1192, ptr noundef nonnull @.str.4) #33
  br label %do.end

do.end:                                           ; preds = %if.then8, %land.lhs.true6, %land.lhs.true, %do.body
  %children = getelementptr inbounds %struct.task_group, ptr %parent.057, i32 0, i32 14
  %0 = ptrtoint ptr %children to i32
  call void @__asan_load4_noabort(i32 %0)
  %.pn51 = load volatile ptr, ptr %children, align 4
  %cmp.not53 = icmp eq ptr %.pn51, %children
  br i1 %cmp.not53, label %for.end, label %for.body

for.cond:                                         ; preds = %if.end29
  %siblings21 = getelementptr inbounds %struct.task_group, ptr %parent.154, i32 0, i32 13
  %1 = ptrtoint ptr %siblings21 to i32
  call void @__asan_load4_noabort(i32 %1)
  %.pn = load volatile ptr, ptr %siblings21, align 4
  %children14 = getelementptr inbounds %struct.task_group, ptr %3, i32 0, i32 14
  %cmp.not = icmp eq ptr %.pn, %children14
  br i1 %cmp.not, label %for.end, label %for.body

for.body:                                         ; preds = %for.cond, %do.end
  %.pn.lcssa = phi ptr [ %.pn51, %do.end ], [ %.pn, %for.cond ]
  %child.0 = getelementptr i8, ptr %.pn.lcssa, i32 -412
  %call = tail call i32 %down(ptr noundef %child.0, ptr noundef %data) #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %do.body, label %out

for.end:                                          ; preds = %for.cond, %do.end
  %parent.154 = phi ptr [ %3, %for.cond ], [ %parent.057, %do.end ]
  %call25 = tail call i32 %up(ptr noundef %parent.154, ptr noundef %data) #33
  %tobool26.not = icmp eq i32 %call25, 0
  br i1 %tobool26.not, label %lor.lhs.false, label %out

lor.lhs.false:                                    ; preds = %for.end
  %cmp27 = icmp eq ptr %parent.154, %from
  br i1 %cmp27, label %out, label %if.end29

if.end29:                                         ; preds = %lor.lhs.false
  %parent30 = getelementptr inbounds %struct.task_group, ptr %parent.154, i32 0, i32 12
  %2 = ptrtoint ptr %parent30 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %parent30, align 8
  %tobool31.not = icmp eq ptr %3, null
  br i1 %tobool31.not, label %out, label %for.cond

out:                                              ; preds = %if.end29, %lor.lhs.false, %for.end, %for.body, %entry
  %ret.0 = phi i32 [ %call55, %entry ], [ 0, %if.end29 ], [ 0, %lor.lhs.false ], [ %call25, %for.end ], [ %call, %for.body ]
  ret i32 %ret.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @rcu_read_lock_any_held() local_unnamed_addr #2

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readnone sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @tg_nop(ptr nocapture readnone %tg, ptr nocapture readnone %data) local_unnamed_addr #6 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  ret i32 0
}

; Function Attrs: mustprogress nofree nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @uclamp_eff_value(ptr nocapture noundef readonly %p, i32 noundef %clamp_id) local_unnamed_addr #7 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 %clamp_id
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load2_noabort(i32 %0)
  %bf.load = load i16, ptr %arrayidx, align 4
  %1 = and i16 %bf.load, 2
  %tobool.not = icmp eq i16 %1, 0
  br i1 %tobool.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %arrayidx.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 %clamp_id
  %2 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %arrayidx.i.i, align 4
  %retval.sroa.0.0.extract.shift.i.i = lshr i32 %3, 16
  %retval.sroa.0.0.extract.trunc.i.i = trunc i32 %retval.sroa.0.0.extract.shift.i.i to i16
  %sched_task_group.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %4 = ptrtoint ptr %sched_task_group.i.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %sched_task_group.i.i.i, align 8
  %autogroup.i.i.i = getelementptr inbounds %struct.task_group, ptr %5, i32 0, i32 15
  %6 = ptrtoint ptr %autogroup.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %autogroup.i.i.i, align 4
  %tobool.i.i.i = icmp ne ptr %7, null
  %cmp.i.i = icmp eq ptr %5, @root_task_group
  %or.cond.i.i = select i1 %tobool.i.i.i, i1 true, i1 %cmp.i.i
  br i1 %or.cond.i.i, label %uclamp_tg_restrict.exit.i, label %if.end4.i.i

if.end4.i.i:                                      ; preds = %if.end
  %uclamp.i.i = getelementptr inbounds %struct.task_group, ptr %5, i32 0, i32 19
  %8 = ptrtoint ptr %uclamp.i.i to i32
  call void @__asan_load2_noabort(i32 %8)
  %bf.load.i.i = load i16, ptr %uclamp.i.i, align 16
  %bf.lshr.i.i = lshr i16 %bf.load.i.i, 5
  %arrayidx9.i.i = getelementptr %struct.task_group, ptr %5, i32 0, i32 19, i32 1
  %9 = ptrtoint ptr %arrayidx9.i.i to i32
  call void @__asan_load2_noabort(i32 %9)
  %bf.load10.i.i = load i16, ptr %arrayidx9.i.i, align 4
  %bf.lshr11.i.i = lshr i16 %bf.load10.i.i, 5
  %bf.lshr14.i.i = lshr i16 %retval.sroa.0.0.extract.trunc.i.i, 5
  %10 = tail call i16 @llvm.umax.i16(i16 %bf.lshr14.i.i, i16 %bf.lshr.i.i) #33
  %11 = tail call i16 @llvm.umin.i16(i16 %10, i16 %bf.lshr11.i.i) #33
  %bf.shl.i.i.i = shl nuw i16 %11, 5
  %cmp10.i.i.i.i = icmp ult i16 %11, 820
  %bf.shl3.i.i.i = select i1 %cmp10.i.i.i.i, i16 0, i16 16
  %bf.set5.i.i.i = or i16 %bf.shl3.i.i.i, %bf.shl.i.i.i
  br label %uclamp_tg_restrict.exit.i

uclamp_tg_restrict.exit.i:                        ; preds = %if.end4.i.i, %if.end
  %retval.sroa.0.0.i.i = phi i16 [ %retval.sroa.0.0.extract.trunc.i.i, %if.end ], [ %bf.set5.i.i.i, %if.end4.i.i ]
  %arrayidx.i = getelementptr [2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 %clamp_id
  %12 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load2_noabort(i32 %12)
  %uc_max.sroa.0.0.copyload.i = load i16, ptr %arrayidx.i, align 4
  %13 = lshr i16 %retval.sroa.0.0.i.i, 5
  %bf.lshr2.i = lshr i16 %uc_max.sroa.0.0.copyload.i, 5
  %cmp.i = icmp ugt i16 %13, %bf.lshr2.i
  %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i = select i1 %cmp.i, i16 %uc_max.sroa.0.0.copyload.i, i16 %retval.sroa.0.0.i.i, !prof !1192
  br label %cleanup

cleanup:                                          ; preds = %uclamp_tg_restrict.exit.i, %entry
  %retval.0.in.in = phi i16 [ %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i, %uclamp_tg_restrict.exit.i ], [ %bf.load, %entry ]
  %retval.0.in = lshr i16 %retval.0.in.in, 5
  %retval.0 = zext i16 %retval.0.in to i32
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sysctl_sched_uclamp_handler(ptr noundef %table, i32 noundef %write, ptr noundef %buffer, ptr noundef %lenp, ptr noundef %ppos) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @mutex_lock_nested(ptr noundef nonnull @uclamp_mutex, i32 noundef 0) #33
  %0 = load i32, ptr @sysctl_sched_uclamp_util_min, align 4
  %1 = load i32, ptr @sysctl_sched_uclamp_util_max, align 4
  %2 = load i32, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  %call = tail call i32 @proc_dointvec(ptr noundef %table, i32 noundef %write, ptr noundef %buffer, ptr noundef %lenp, ptr noundef %ppos) #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %if.end, label %undo

if.end:                                           ; preds = %entry
  %tobool1.not = icmp eq i32 %write, 0
  br i1 %tobool1.not, label %done, label %if.end3

if.end3:                                          ; preds = %if.end
  %3 = load i32, ptr @sysctl_sched_uclamp_util_min, align 4
  %4 = load i32, ptr @sysctl_sched_uclamp_util_max, align 4
  %cmp = icmp ugt i32 %3, %4
  %cmp4 = icmp ugt i32 %4, 1024
  %or.cond = or i1 %cmp, %cmp4
  br i1 %or.cond, label %undo, label %lor.lhs.false5

lor.lhs.false5:                                   ; preds = %if.end3
  %5 = load i32, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  %cmp6 = icmp ugt i32 %5, 1024
  br i1 %cmp6, label %undo, label %if.end8

if.end8:                                          ; preds = %lor.lhs.false5
  %cmp9.not = icmp eq i32 %0, %3
  br i1 %cmp9.not, label %if.end11, label %if.end11.thread

if.end11:                                         ; preds = %if.end8
  %cmp12.not = icmp eq i32 %1, %4
  br i1 %cmp12.not, label %if.end17, label %if.then13

if.end11.thread:                                  ; preds = %if.end8
  %6 = trunc i32 %3 to i16
  %bf.load.i = load i16, ptr @uclamp_default, align 4
  %bf.shl.i = shl i16 %6, 5
  %bf.clear.i = and i16 %bf.load.i, 2
  %bf.set.i = or i16 %bf.clear.i, %bf.shl.i
  %cmp10.i.i = icmp ult i32 %3, 820
  %div8.i.i = udiv i32 %3, 205
  %7 = trunc i32 %div8.i.i to i16
  %.op.i = shl i16 %7, 2
  %.op.op.i = and i16 %.op.i, 28
  %bf.shl3.i = select i1 %cmp10.i.i, i16 %.op.op.i, i16 16
  %bf.set5.i = or i16 %bf.set.i, %bf.shl3.i
  store i16 %bf.set5.i, ptr @uclamp_default, align 4
  %cmp12.not51 = icmp eq i32 %1, %4
  br i1 %cmp12.not51, label %if.then16, label %if.then13

if.then13:                                        ; preds = %if.end11.thread, %if.end11
  %8 = trunc i32 %4 to i16
  %bf.load.i28 = load i16, ptr getelementptr inbounds ([2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 1), align 4
  %bf.shl.i29 = shl nuw i16 %8, 5
  %bf.clear.i30 = and i16 %bf.load.i28, 2
  %bf.set.i31 = or i16 %bf.clear.i30, %bf.shl.i29
  %cmp10.i.i32 = icmp ult i32 %4, 820
  %div8.i.i3350 = udiv i16 %8, 205
  %.op.i34 = shl nuw nsw i16 %div8.i.i3350, 2
  %.op.op.i35 = and i16 %.op.i34, 28
  %bf.shl3.i36 = select i1 %cmp10.i.i32, i16 %.op.op.i35, i16 16
  %bf.set5.i37 = or i16 %bf.set.i31, %bf.shl3.i36
  store i16 %bf.set5.i37, ptr getelementptr inbounds ([2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 1), align 4
  br label %if.then16

if.then16:                                        ; preds = %if.then13, %if.end11.thread
  tail call void @static_key_enable(ptr noundef nonnull @sched_uclamp_used) #33
  %9 = load i32, ptr @sysctl_sched_uclamp_util_min, align 4
  %10 = trunc i32 %9 to i16
  %bf.load.i.i = load i16, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18), align 8
  %bf.shl.i.i = shl i16 %10, 5
  %bf.clear.i.i = and i16 %bf.load.i.i, 2
  %bf.set.i.i = or i16 %bf.clear.i.i, %bf.shl.i.i
  %cmp10.i.i.i = icmp ult i32 %9, 820
  %div8.i.i.i = udiv i32 %9, 205
  %11 = trunc i32 %div8.i.i.i to i16
  %.op.i.i = shl i16 %11, 2
  %.op.op.i.i = and i16 %.op.i.i, 28
  %bf.shl3.i.i = select i1 %cmp10.i.i.i, i16 %.op.op.i.i, i16 16
  %bf.set5.i.i = or i16 %bf.shl3.i.i, %bf.set.i.i
  store i16 %bf.set5.i.i, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18), align 8
  %12 = load i32, ptr @sysctl_sched_uclamp_util_max, align 4
  %13 = trunc i32 %12 to i16
  %bf.load.i4.i = load i16, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18, i32 1), align 4
  %bf.shl.i5.i = shl i16 %13, 5
  %bf.clear.i6.i = and i16 %bf.load.i4.i, 2
  %bf.set.i7.i = or i16 %bf.clear.i6.i, %bf.shl.i5.i
  %cmp10.i.i8.i = icmp ult i32 %12, 820
  %div8.i.i9.i = udiv i32 %12, 205
  %14 = trunc i32 %div8.i.i9.i to i16
  %.op.i10.i = shl i16 %14, 2
  %.op.op.i11.i = and i16 %.op.i10.i, 28
  %bf.shl3.i12.i = select i1 %cmp10.i.i8.i, i16 %.op.op.i11.i, i16 16
  %bf.set5.i13.i = or i16 %bf.shl3.i12.i, %bf.set.i7.i
  store i16 %bf.set5.i13.i, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18, i32 1), align 4
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %18, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.then16
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.then16
  tail call fastcc void @cpu_util_update_eff(ptr noundef nonnull @root_task_group) #33
  %call.i14.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i14.i, label %uclamp_update_root_tg.exit, label %land.lhs.true.i17.i

land.lhs.true.i17.i:                              ; preds = %rcu_read_lock.exit.i
  %call1.i15.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i16.i = icmp eq i32 %call1.i15.i, 0
  br i1 %tobool.not.i16.i, label %uclamp_update_root_tg.exit, label %land.lhs.true2.i19.i

land.lhs.true2.i19.i:                             ; preds = %land.lhs.true.i17.i
  %.b4.i18.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i18.i, label %uclamp_update_root_tg.exit, label %if.then.i20.i

if.then.i20.i:                                    ; preds = %land.lhs.true2.i19.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %uclamp_update_root_tg.exit

uclamp_update_root_tg.exit:                       ; preds = %if.then.i20.i, %land.lhs.true2.i19.i, %land.lhs.true.i17.i, %rcu_read_lock.exit.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i21.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i.i.i.i21.i to ptr
  %preempt_count.i.i.i.i22.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i.i.i.i22.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i.i.i.i22.i, align 4
  %sub.i.i.i.i = add i32 %22, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i22.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %if.end17

if.end17:                                         ; preds = %uclamp_update_root_tg.exit, %if.end11
  %23 = load i32, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  %cmp18.not = icmp eq i32 %2, %23
  br i1 %cmp18.not, label %done, label %if.then19

if.then19:                                        ; preds = %if.end17
  tail call void @static_key_enable(ptr noundef nonnull @sched_uclamp_used) #33
  tail call void @_raw_read_lock(ptr noundef nonnull @tasklist_lock) #33
  tail call void @_raw_read_unlock(ptr noundef nonnull @tasklist_lock) #33
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i38 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i.i.i.i.i38 to ptr
  %preempt_count.i.i.i.i.i39 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 1
  %26 = ptrtoint ptr %preempt_count.i.i.i.i.i39 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %preempt_count.i.i.i.i.i39, align 4
  %add.i.i.i.i40 = add i32 %27, 1
  store volatile i32 %add.i.i.i.i40, ptr %preempt_count.i.i.i.i.i39, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i41 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i41, label %rcu_read_lock.exit.i48, label %land.lhs.true.i.i44

land.lhs.true.i.i44:                              ; preds = %if.then19
  %call1.i.i42 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i43 = icmp eq i32 %call1.i.i42, 0
  br i1 %tobool.not.i.i43, label %rcu_read_lock.exit.i48, label %land.lhs.true2.i.i46

land.lhs.true2.i.i46:                             ; preds = %land.lhs.true.i.i44
  %.b4.i.i45 = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i45, label %rcu_read_lock.exit.i48, label %if.then.i.i47

if.then.i.i47:                                    ; preds = %land.lhs.true2.i.i46
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i48

rcu_read_lock.exit.i48:                           ; preds = %if.then.i.i47, %land.lhs.true2.i.i46, %land.lhs.true.i.i44, %if.then19
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50) to i32))
  %28 = load volatile ptr, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50), align 16
  %add.ptr53.i = getelementptr i8, ptr %28, i32 -1136
  %cmp.not54.i = icmp eq ptr %add.ptr53.i, @init_task
  br i1 %cmp.not54.i, label %for.end34.i, label %do.body5.i

for.cond.loopexit.i:                              ; preds = %for.body24.i, %do.end11.i
  %29 = ptrtoint ptr %31 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile ptr, ptr %31, align 16
  %add.ptr.i = getelementptr i8, ptr %30, i32 -1136
  %cmp.not.i = icmp eq ptr %add.ptr.i, @init_task
  br i1 %cmp.not.i, label %for.end34.i, label %do.body5.i

do.body5.i:                                       ; preds = %for.cond.loopexit.i, %rcu_read_lock.exit.i48
  %31 = phi ptr [ %30, %for.cond.loopexit.i ], [ %28, %rcu_read_lock.exit.i48 ]
  %call.i = tail call i32 @rcu_read_lock_any_held() #33
  %tobool.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %do.end11.i

land.lhs.true.i:                                  ; preds = %do.body5.i
  %call6.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool7.not.i = icmp eq i32 %call6.i, 0
  br i1 %tobool7.not.i, label %do.end11.i, label %land.lhs.true8.i

land.lhs.true8.i:                                 ; preds = %land.lhs.true.i
  %.b39.i = load i1, ptr @uclamp_sync_util_min_rt_default.__warned, align 1
  br i1 %.b39.i, label %do.end11.i, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true8.i
  store i1 true, ptr @uclamp_sync_util_min_rt_default.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 1429, ptr noundef nonnull @.str.4) #33
  br label %do.end11.i

do.end11.i:                                       ; preds = %if.then.i, %land.lhs.true8.i, %land.lhs.true.i, %do.body5.i
  %signal.i = getelementptr i8, ptr %31, i32 544
  %32 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %signal.i, align 16
  %thread_head.i = getelementptr inbounds %struct.signal_struct, ptr %33, i32 0, i32 3
  %34 = ptrtoint ptr %thread_head.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %.pn49.i = load volatile ptr, ptr %thread_head.i, align 4
  %cmp23.not51.i = icmp eq ptr %.pn49.i, %thread_head.i
  br i1 %cmp23.not51.i, label %for.cond.loopexit.i, label %for.body24.i

for.body24.i:                                     ; preds = %for.body24.i, %do.end11.i
  %.pn52.i = phi ptr [ %.pn.i, %for.body24.i ], [ %.pn49.i, %do.end11.i ]
  %p.0.i = getelementptr i8, ptr %.pn52.i, i32 -1404
  tail call fastcc void @uclamp_update_util_min_rt_default(ptr noundef %p.0.i) #33
  %35 = ptrtoint ptr %.pn52.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %.pn.i = load volatile ptr, ptr %.pn52.i, align 4
  %36 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %signal.i, align 16
  %thread_head22.i = getelementptr inbounds %struct.signal_struct, ptr %37, i32 0, i32 3
  %cmp23.not.i = icmp eq ptr %.pn.i, %thread_head22.i
  br i1 %cmp23.not.i, label %for.cond.loopexit.i, label %for.body24.i

for.end34.i:                                      ; preds = %for.cond.loopexit.i, %rcu_read_lock.exit.i48
  %call.i40.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i40.i, label %uclamp_sync_util_min_rt_default.exit, label %land.lhs.true.i43.i

land.lhs.true.i43.i:                              ; preds = %for.end34.i
  %call1.i41.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i42.i = icmp eq i32 %call1.i41.i, 0
  br i1 %tobool.not.i42.i, label %uclamp_sync_util_min_rt_default.exit, label %land.lhs.true2.i45.i

land.lhs.true2.i45.i:                             ; preds = %land.lhs.true.i43.i
  %.b4.i44.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i44.i, label %uclamp_sync_util_min_rt_default.exit, label %if.then.i46.i

if.then.i46.i:                                    ; preds = %land.lhs.true2.i45.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %uclamp_sync_util_min_rt_default.exit

uclamp_sync_util_min_rt_default.exit:             ; preds = %if.then.i46.i, %land.lhs.true2.i45.i, %land.lhs.true.i43.i, %for.end34.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i47.i = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i.i47.i to ptr
  %preempt_count.i.i.i.i48.i = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i.i48.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i.i48.i, align 4
  %sub.i.i.i.i49 = add i32 %41, -1
  store volatile i32 %sub.i.i.i.i49, ptr %preempt_count.i.i.i.i48.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %done

undo:                                             ; preds = %lor.lhs.false5, %if.end3, %entry
  %result.0 = phi i32 [ %call, %entry ], [ -22, %lor.lhs.false5 ], [ -22, %if.end3 ]
  store i32 %0, ptr @sysctl_sched_uclamp_util_min, align 4
  store i32 %1, ptr @sysctl_sched_uclamp_util_max, align 4
  store i32 %2, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  br label %done

done:                                             ; preds = %undo, %uclamp_sync_util_min_rt_default.exit, %if.end17, %if.end
  %result.1 = phi i32 [ %result.0, %undo ], [ 0, %uclamp_sync_util_min_rt_default.exit ], [ 0, %if.end17 ], [ 0, %if.end ]
  tail call void @mutex_unlock(ptr noundef nonnull @uclamp_mutex) #33
  ret i32 %result.1
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @proc_dointvec(ptr noundef, i32 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @static_key_enable(ptr noundef) local_unnamed_addr #2

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local zeroext i1 @sched_task_on_rq(ptr nocapture noundef readonly %p) local_unnamed_addr #8 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %0 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %on_rq.i, align 4
  %cmp.i = icmp eq i32 %1, 1
  ret i1 %cmp.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @get_wchan(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %tobool.not = icmp eq ptr %p, null
  br i1 %tobool.not, label %cleanup, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %cmp = icmp eq ptr %3, %p
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %lor.lhs.false
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  tail call void @_raw_spin_lock_irq(ptr noundef %pi_lock) #33
  %4 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %p, align 128
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1231
  switch i32 %5, label %land.lhs.true9 [
    i32 0, label %if.end13
    i32 512, label %if.end13
  ]

land.lhs.true9:                                   ; preds = %if.end
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %6 = ptrtoint ptr %on_rq to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %on_rq, align 4
  %tobool10.not = icmp eq i32 %7, 0
  br i1 %tobool10.not, label %if.then11, label %if.end13

if.then11:                                        ; preds = %land.lhs.true9
  %call12 = tail call i32 @__get_wchan(ptr noundef nonnull %p) #33
  br label %if.end13

if.end13:                                         ; preds = %if.then11, %land.lhs.true9, %if.end, %if.end
  %ip.0 = phi i32 [ 0, %land.lhs.true9 ], [ %call12, %if.then11 ], [ 0, %if.end ], [ 0, %if.end ]
  tail call void @_raw_spin_unlock_irq(ptr noundef %pi_lock) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end13, %lor.lhs.false, %entry
  %retval.0 = phi i32 [ %ip.0, %if.end13 ], [ 0, %lor.lhs.false ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock_irq(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__get_wchan(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock_irq(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @activate_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @enqueue_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags)
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %0 = ptrtoint ptr %on_rq to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 1, ptr %on_rq, align 4
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @enqueue_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) unnamed_addr #3 align 64 {
entry:
  %and = and i32 %flags, 8
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  tail call void @update_rq_clock(ptr noundef %rq)
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %and1 = and i32 %flags, 2
  %tobool2.not = icmp eq i32 %and1, 0
  br i1 %tobool2.not, label %if.then3, label %if.end6

if.then3:                                         ; preds = %if.end
  %last_queued.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 49, i32 3
  %0 = ptrtoint ptr %last_queued.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %last_queued.i, align 8
  %tobool.not.i = icmp eq i64 %1, 0
  br i1 %tobool.not.i, label %if.then.i, label %sched_info_enqueue.exit

if.then.i:                                        ; preds = %if.then3
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %2 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i.i, label %lockdep_assert_rq_held.exit.i.i, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.then.i
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %6, %if.then.i.i.i.i ], [ %rq, %land.rhs.i.i.i ]
  %dep_map.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i, i32 0, i32 4
  %call.i.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i = icmp eq i32 %call.i.i.i.i, 0
  br i1 %cmp.not.i.i.i, label %do.end.i.i.i, label %lockdep_assert_rq_held.exit.i.i, !prof !1192

do.end.i.i.i:                                     ; preds = %__rq_lockp.exit.i.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i

lockdep_assert_rq_held.exit.i.i:                  ; preds = %do.end.i.i.i, %__rq_lockp.exit.i.i.i, %if.then.i
  %clock_update_flags.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %7 = ptrtoint ptr %clock_update_flags.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %clock_update_flags.i.i.i, align 4
  %cmp.i.i.i = icmp ult i32 %8, 2
  br i1 %cmp.i.i.i, label %land.rhs.i3.i.i, label %rq_clock.exit.i

land.rhs.i3.i.i:                                  ; preds = %lockdep_assert_rq_held.exit.i.i
  %.b37.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i, label %rq_clock.exit.i, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i3.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i

rq_clock.exit.i:                                  ; preds = %if.then.i.i.i, %land.rhs.i3.i.i, %lockdep_assert_rq_held.exit.i.i
  %clock.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 26
  %9 = ptrtoint ptr %clock.i.i to i32
  call void @__asan_load8_noabort(i32 %9)
  %10 = load i64, ptr %clock.i.i, align 32
  %11 = ptrtoint ptr %last_queued.i to i32
  call void @__asan_store8_noabort(i32 %11)
  store i64 %10, ptr %last_queued.i, align 8
  br label %sched_info_enqueue.exit

sched_info_enqueue.exit:                          ; preds = %rq_clock.exit.i, %if.then3
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @psi_disabled, i32 1), ptr blockaddress(@enqueue_task, %if.end.i)) #33
          to label %if.end6 [label %if.end.i], !srcloc !1232

if.end.i:                                         ; preds = %sched_info_enqueue.exit
  %and4 = and i32 %flags, 1
  %tobool5.not = icmp eq i32 %and4, 0
  %in_memstall.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 65
  %12 = ptrtoint ptr %in_memstall.i to i32
  call void @__asan_load2_noabort(i32 %12)
  %bf.load.i = load i16, ptr %in_memstall.i, align 8
  %13 = and i16 %bf.load.i, 128
  %tobool5.not.i = icmp eq i16 %13, 0
  %spec.select.i = select i1 %tobool5.not.i, i32 4, i32 20
  br i1 %tobool5.not, label %if.then14.i, label %lor.lhs.false.i

lor.lhs.false.i:                                  ; preds = %if.end.i
  %sched_psi_wake_requeue.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %14 = ptrtoint ptr %sched_psi_wake_requeue.i to i32
  call void @__asan_load1_noabort(i32 %14)
  %bf.load9.i = load i8, ptr %sched_psi_wake_requeue.i, align 4
  %15 = and i8 %bf.load9.i, 16
  %tobool13.not.i = icmp eq i8 %15, 0
  br i1 %tobool13.not.i, label %if.else.i, label %if.then14.i

if.then14.i:                                      ; preds = %lor.lhs.false.i, %if.end.i
  %spec.select54.i = select i1 %tobool5.not.i, i32 4, i32 22
  %sched_psi_wake_requeue24.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %16 = ptrtoint ptr %sched_psi_wake_requeue24.i to i32
  call void @__asan_load1_noabort(i32 %16)
  %bf.load25.i = load i8, ptr %sched_psi_wake_requeue24.i, align 4
  %17 = and i8 %bf.load25.i, 16
  %tobool29.not.i = icmp eq i8 %17, 0
  br i1 %tobool29.not.i, label %if.end43.i, label %if.then30.i

if.then30.i:                                      ; preds = %if.then14.i
  %bf.clear33.i = and i8 %bf.load25.i, -17
  %18 = ptrtoint ptr %sched_psi_wake_requeue24.i to i32
  call void @__asan_store1_noabort(i32 %18)
  store i8 %bf.clear33.i, ptr %sched_psi_wake_requeue24.i, align 4
  br label %if.end43.i

if.else.i:                                        ; preds = %lor.lhs.false.i
  %19 = lshr i16 %bf.load.i, 13
  %.lobit.i = and i16 %19, 1
  %20 = zext i16 %.lobit.i to i32
  br label %if.end43.i

if.end43.i:                                       ; preds = %if.else.i, %if.then30.i, %if.then14.i
  %set.2.i = phi i32 [ %spec.select54.i, %if.then30.i ], [ %spec.select54.i, %if.then14.i ], [ %spec.select.i, %if.else.i ]
  %clear.0.i = phi i32 [ 0, %if.then30.i ], [ 0, %if.then14.i ], [ %20, %if.else.i ]
  tail call void @psi_task_change(ptr noundef %p, i32 noundef %clear.0.i, i32 noundef %set.2.i) #33
  br label %if.end6

if.end6:                                          ; preds = %if.end43.i, %sched_info_enqueue.exit, %if.end
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@enqueue_task, %if.end.i22)) #33
          to label %uclamp_rq_inc.exit [label %if.end.i22], !srcloc !1202

if.end.i22:                                       ; preds = %if.end6
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %21 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %sched_class.i, align 32
  %23 = ptrtoint ptr %22 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %22, align 4
  %tobool3.not.i = icmp eq i32 %24, 0
  br i1 %tobool3.not.i, label %uclamp_rq_inc.exit, label %for.body.preheader.i, !prof !1192

for.body.preheader.i:                             ; preds = %if.end.i22
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %rq, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %rq, ptr noundef %p, i32 noundef 1) #33
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 12
  %25 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %uclamp_flags.i, align 16
  %and.i = and i32 %26, 1
  %tobool14.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool14.not.i, label %uclamp_rq_inc.exit, label %if.then15.i

if.then15.i:                                      ; preds = %for.body.preheader.i
  %and17.i = and i32 %26, -2
  %27 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %and17.i, ptr %uclamp_flags.i, align 16
  br label %uclamp_rq_inc.exit

uclamp_rq_inc.exit:                               ; preds = %if.then15.i, %for.body.preheader.i, %if.end.i22, %if.end6
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %28 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %sched_class, align 32
  %enqueue_task = getelementptr inbounds %struct.sched_class, ptr %29, i32 0, i32 1
  %30 = ptrtoint ptr %enqueue_task to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %enqueue_task, align 4
  tail call void %31(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@enqueue_task, %land.rhs.i)) #33
          to label %if.end8 [label %land.rhs.i], !srcloc !1202

land.rhs.i:                                       ; preds = %uclamp_rq_inc.exit
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %32 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_enabled.i, align 128
  %tobool3.i.not = icmp eq i32 %33, 0
  br i1 %tobool3.i.not, label %if.end8, label %if.then7

if.then7:                                         ; preds = %land.rhs.i
  tail call void @sched_core_enqueue(ptr noundef %rq, ptr noundef %p)
  br label %if.end8

if.end8:                                          ; preds = %if.then7, %land.rhs.i, %uclamp_rq_inc.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @deactivate_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %and = shl i32 %flags, 1
  %0 = and i32 %and, 2
  %1 = xor i32 %0, 2
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %2 = ptrtoint ptr %on_rq to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 %1, ptr %on_rq, align 4
  tail call fastcc void @dequeue_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags)
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @dequeue_task(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@dequeue_task, %land.rhs.i)) #33
          to label %if.end [label %land.rhs.i], !srcloc !1202

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i, align 128
  %tobool3.i.not = icmp eq i32 %1, 0
  br i1 %tobool3.i.not, label %if.end, label %if.then

if.then:                                          ; preds = %land.rhs.i
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core.i, align 8
  %core_task_seq.i = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 84
  %4 = ptrtoint ptr %core_task_seq.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_task_seq.i, align 4
  %inc.i = add i32 %5, 1
  store i32 %inc.i, ptr %core_task_seq.i, align 4
  %core_node.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22
  %6 = ptrtoint ptr %core_node.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %core_node.i.i, align 4
  %8 = ptrtoint ptr %core_node.i.i to i32
  %cmp.i.not.i = icmp eq i32 %7, %8
  br i1 %cmp.i.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %if.then
  %core_tree.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 83
  tail call void @rb_erase(ptr noundef %core_node.i.i, ptr noundef %core_tree.i) #33
  %9 = ptrtoint ptr %core_node.i.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %core_node.i.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %if.then
  %and.i = and i32 %flags, 2
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %if.end

land.lhs.true.i:                                  ; preds = %if.end.i
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %10 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %nr_running.i, align 4
  %cmp.i = icmp eq i32 %11, 1
  br i1 %cmp.i, label %land.lhs.true3.i, label %if.end

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %12 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %core.i, align 8
  %core_forceidle_count.i = getelementptr inbounds %struct.rq, ptr %13, i32 0, i32 87
  %14 = ptrtoint ptr %core_forceidle_count.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %core_forceidle_count.i, align 8
  %tobool5.not.i = icmp eq i32 %15, 0
  br i1 %tobool5.not.i, label %if.end, label %land.lhs.true6.i

land.lhs.true6.i:                                 ; preds = %land.lhs.true3.i
  %curr.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %16 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %curr.i, align 8
  %idle.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 21
  %18 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %idle.i, align 4
  %cmp7.i = icmp eq ptr %17, %19
  br i1 %cmp7.i, label %if.then8.i, label %if.end

if.then8.i:                                       ; preds = %land.lhs.true6.i
  tail call void @resched_curr(ptr noundef %rq) #33
  br label %if.end

if.end:                                           ; preds = %if.then8.i, %land.lhs.true6.i, %land.lhs.true3.i, %land.lhs.true.i, %if.end.i, %land.rhs.i, %entry
  %and = and i32 %flags, 8
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.then1, label %if.end2

if.then1:                                         ; preds = %if.end
  tail call void @update_rq_clock(ptr noundef %rq)
  br label %if.end2

if.end2:                                          ; preds = %if.then1, %if.end
  %and3 = and i32 %flags, 2
  %tobool4.not = icmp eq i32 %and3, 0
  br i1 %tobool4.not, label %if.then5, label %if.end8

if.then5:                                         ; preds = %if.end2
  %last_queued.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 49, i32 3
  %20 = ptrtoint ptr %last_queued.i to i32
  call void @__asan_load8_noabort(i32 %20)
  %21 = load i64, ptr %last_queued.i, align 8
  %tobool.not.i23 = icmp eq i64 %21, 0
  br i1 %tobool.not.i23, label %sched_info_dequeue.exit, label %if.end.i24

if.end.i24:                                       ; preds = %if.then5
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %22 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i = icmp eq i32 %22, 0
  br i1 %tobool.not.i.i.i, label %lockdep_assert_rq_held.exit.i.i, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.end.i24
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %23 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %24, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %25 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %26, %if.then.i.i.i.i ], [ %rq, %land.rhs.i.i.i ]
  %dep_map.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i, i32 0, i32 4
  %call.i.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i = icmp eq i32 %call.i.i.i.i, 0
  br i1 %cmp.not.i.i.i, label %do.end.i.i.i, label %lockdep_assert_rq_held.exit.i.i, !prof !1192

do.end.i.i.i:                                     ; preds = %__rq_lockp.exit.i.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i

lockdep_assert_rq_held.exit.i.i:                  ; preds = %do.end.i.i.i, %__rq_lockp.exit.i.i.i, %if.end.i24
  %clock_update_flags.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %27 = ptrtoint ptr %clock_update_flags.i.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %clock_update_flags.i.i.i, align 4
  %cmp.i.i.i = icmp ult i32 %28, 2
  br i1 %cmp.i.i.i, label %land.rhs.i3.i.i, label %rq_clock.exit.i

land.rhs.i3.i.i:                                  ; preds = %lockdep_assert_rq_held.exit.i.i
  %.b37.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i, label %rq_clock.exit.i, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i3.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i

rq_clock.exit.i:                                  ; preds = %if.then.i.i.i, %land.rhs.i3.i.i, %lockdep_assert_rq_held.exit.i.i
  %clock.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 26
  %29 = ptrtoint ptr %clock.i.i to i32
  call void @__asan_load8_noabort(i32 %29)
  %30 = load i64, ptr %clock.i.i, align 32
  %31 = ptrtoint ptr %last_queued.i to i32
  call void @__asan_load8_noabort(i32 %31)
  %32 = load i64, ptr %last_queued.i, align 8
  %sub.i = sub i64 %30, %32
  store i64 0, ptr %last_queued.i, align 8
  %run_delay.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 49, i32 1
  %33 = ptrtoint ptr %run_delay.i to i32
  call void @__asan_load8_noabort(i32 %33)
  %34 = load i64, ptr %run_delay.i, align 8
  %add.i = add i64 %34, %sub.i
  store i64 %add.i, ptr %run_delay.i, align 8
  %tobool.not.i.i = icmp eq ptr %rq, null
  br i1 %tobool.not.i.i, label %sched_info_dequeue.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %rq_clock.exit.i
  %run_delay.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 68, i32 1
  %35 = ptrtoint ptr %run_delay.i.i to i32
  call void @__asan_load8_noabort(i32 %35)
  %36 = load i64, ptr %run_delay.i.i, align 8
  %add.i.i = add i64 %36, %sub.i
  store i64 %add.i.i, ptr %run_delay.i.i, align 8
  br label %sched_info_dequeue.exit

sched_info_dequeue.exit:                          ; preds = %if.then.i.i, %rq_clock.exit.i, %if.then5
  %and6 = and i32 %flags, 1
  %tobool7 = icmp ne i32 %and6, 0
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @psi_disabled, i32 1), ptr blockaddress(@dequeue_task, %l_yes.i.i)) #33
          to label %arch_static_branch_jump.exit.i [label %l_yes.i.i], !srcloc !1232

l_yes.i.i:                                        ; preds = %sched_info_dequeue.exit
  br label %arch_static_branch_jump.exit.i

arch_static_branch_jump.exit.i:                   ; preds = %l_yes.i.i, %sched_info_dequeue.exit
  %retval.0.i.i = phi i1 [ false, %l_yes.i.i ], [ true, %sched_info_dequeue.exit ]
  %brmerge.i = or i1 %tobool7, %retval.0.i.i
  br i1 %brmerge.i, label %if.end8, label %if.end7.i

if.end7.i:                                        ; preds = %arch_static_branch_jump.exit.i
  %in_memstall.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 65
  %37 = ptrtoint ptr %in_memstall.i to i32
  call void @__asan_load2_noabort(i32 %37)
  %bf.load.i = load i16, ptr %in_memstall.i, align 8
  %38 = and i16 %bf.load.i, 128
  %tobool8.not.i = icmp eq i16 %38, 0
  %spec.select.i = select i1 %tobool8.not.i, i32 4, i32 22
  tail call void @psi_task_change(ptr noundef %p, i32 noundef %spec.select.i, i32 noundef 0) #33
  br label %if.end8

if.end8:                                          ; preds = %if.end7.i, %arch_static_branch_jump.exit.i, %if.end2
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@dequeue_task, %if.end.i25)) #33
          to label %uclamp_rq_dec.exit [label %if.end.i25], !srcloc !1202

if.end.i25:                                       ; preds = %if.end8
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %39 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %sched_class.i, align 32
  %41 = ptrtoint ptr %40 to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %40, align 4
  %tobool3.not.i = icmp eq i32 %42, 0
  br i1 %tobool3.not.i, label %uclamp_rq_dec.exit, label %for.body.preheader.i, !prof !1192

for.body.preheader.i:                             ; preds = %if.end.i25
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %rq, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %rq, ptr noundef %p, i32 noundef 1) #33
  br label %uclamp_rq_dec.exit

uclamp_rq_dec.exit:                               ; preds = %for.body.preheader.i, %if.end.i25, %if.end8
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %43 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %sched_class, align 32
  %dequeue_task = getelementptr inbounds %struct.sched_class, ptr %44, i32 0, i32 2
  %45 = ptrtoint ptr %dequeue_task to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %dequeue_task, align 4
  tail call void %46(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) #33
  ret void
}

; Function Attrs: inlinehint mustprogress nofree norecurse nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @task_curr(ptr noundef readonly %p) local_unnamed_addr #9 align 64 {
entry:
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %0 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %curr = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 20
  %7 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %curr, align 8
  %cmp = icmp eq ptr %8, %p
  %conv = zext i1 %cmp to i32
  ret i32 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @check_preempt_curr(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %0 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %sched_class, align 32
  %curr = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %2 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %curr, align 8
  %sched_class1 = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 21
  %4 = ptrtoint ptr %sched_class1 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %sched_class1, align 32
  %cmp = icmp eq ptr %1, %5
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %check_preempt_curr = getelementptr inbounds %struct.sched_class, ptr %1, i32 0, i32 5
  %6 = ptrtoint ptr %check_preempt_curr to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %check_preempt_curr, align 4
  tail call void %7(ptr noundef %rq, ptr noundef %p, i32 noundef %flags) #33
  br label %if.end9

if.else:                                          ; preds = %entry
  %cmp7 = icmp ugt ptr %1, %5
  br i1 %cmp7, label %if.then8, label %if.end9

if.then8:                                         ; preds = %if.else
  tail call void @resched_curr(ptr noundef %rq)
  br label %if.end9

if.end9:                                          ; preds = %if.then8, %if.else, %if.then
  %8 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %curr, align 8
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %9, i32 0, i32 12
  %10 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %11, 1
  br i1 %cmp.i.not, label %land.lhs.true, label %if.end15

land.lhs.true:                                    ; preds = %if.end9
  %stack.i.i = getelementptr inbounds %struct.task_struct, ptr %9, i32 0, i32 1
  %12 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %stack.i.i, align 4
  %14 = ptrtoint ptr %13 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %13, align 4
  %16 = and i32 %15, 2
  %tobool13.not = icmp eq i32 %16, 0
  br i1 %tobool13.not, label %if.end15, label %if.then14

if.then14:                                        ; preds = %land.lhs.true
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %17 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i = icmp eq i32 %17, 0
  br i1 %tobool.not.i.i, label %rq_clock_skip_update.exit, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %if.then14
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %18 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %19, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %20 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i
  %retval.0.i.i.i = phi ptr [ %21, %if.then.i.i.i ], [ %rq, %land.rhs.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %rq_clock_skip_update.exit, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %rq_clock_skip_update.exit

rq_clock_skip_update.exit:                        ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %if.then14
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %22 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %clock_update_flags.i, align 4
  %or.i = or i32 %23, 1
  store i32 %or.i, ptr %clock_update_flags.i, align 4
  br label %if.end15

if.end15:                                         ; preds = %rq_clock_skip_update.exit, %land.lhs.true, %if.end9
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @migrate_disable() #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %migration_disabled = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 37
  %4 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_load2_noabort(i32 %4)
  %5 = load i16, ptr %migration_disabled, align 4
  %tobool.not = icmp eq i16 %5, 0
  br i1 %tobool.not, label %do.body, label %if.then

if.then:                                          ; preds = %entry
  %inc = add i16 %5, 1
  %6 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_store2_noabort(i32 %6)
  store i16 %inc, ptr %migration_disabled, align 4
  br label %cleanup

do.body:                                          ; preds = %entry
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %7 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %8, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1233
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %9 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %10
  %11 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %arrayidx, align 4
  %add = add i32 %12, ptrtoint (ptr @runqueues to i32)
  %13 = inttoptr i32 %add to ptr
  %nr_pinned = getelementptr inbounds %struct.rq, ptr %13, i32 0, i32 76
  %14 = ptrtoint ptr %nr_pinned to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %nr_pinned, align 8
  %inc7 = add i32 %15, 1
  store i32 %inc7, ptr %nr_pinned, align 8
  %16 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_store2_noabort(i32 %16)
  store i16 1, ptr %migration_disabled, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1234
  %17 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i14 = and i32 %17, -16384
  %18 = inttoptr i32 %and.i.i.i14 to ptr
  %preempt_count.i.i15 = getelementptr inbounds %struct.thread_info, ptr %18, i32 0, i32 1
  %19 = ptrtoint ptr %preempt_count.i.i15 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %preempt_count.i.i15, align 4
  %sub.i = add i32 %20, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i15, align 4
  br label %cleanup

cleanup:                                          ; preds = %do.body, %if.then
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @migrate_enable() #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf.i = alloca %struct.rq_flags, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %migration_disabled = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 37
  %4 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_load2_noabort(i32 %4)
  %5 = load i16, ptr %migration_disabled, align 4
  %cmp = icmp ugt i16 %5, 1
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %dec = add i16 %5, -1
  %6 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_store2_noabort(i32 %6)
  store i16 %dec, ptr %migration_disabled, align 4
  br label %cleanup

if.end:                                           ; preds = %entry
  %tobool.not = icmp eq i16 %5, 0
  br i1 %tobool.not, label %land.rhs, label %do.body46

land.rhs:                                         ; preds = %if.end
  %.b75 = load i1, ptr @migrate_enable.__already_done, align 1
  br i1 %.b75, label %cleanup, label %if.then13, !prof !1191

if.then13:                                        ; preds = %land.rhs
  store i1 true, ptr @migrate_enable.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2187, i32 noundef 9, ptr noundef null) #33
  br label %cleanup

do.body46:                                        ; preds = %if.end
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %7 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %8, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1235
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 33
  %9 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %cpus_ptr, align 4
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 35
  %cmp49.not = icmp eq ptr %10, %cpus_mask
  br i1 %cmp49.not, label %if.end54, label %if.then51

if.then51:                                        ; preds = %do.body46
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i) #33
  %11 = ptrtoint ptr %rf.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 -1, ptr %rf.i, align 4, !annotation !1193
  %12 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 1
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 -1, ptr %12, align 4, !annotation !1193
  %14 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 2
  %15 = ptrtoint ptr %14 to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 -1, ptr %14, align 4, !annotation !1193
  %call.i = call ptr @task_rq_lock(ptr noundef %3, ptr noundef nonnull %rf.i) #33
  %call1.i = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %3, ptr noundef %cpus_mask, i32 noundef 4, ptr noundef %call.i, ptr noundef nonnull %rf.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i) #33
  br label %if.end54

if.end54:                                         ; preds = %if.then51, %do.body46
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1236
  %16 = ptrtoint ptr %migration_disabled to i32
  call void @__asan_store2_noabort(i32 %16)
  store i16 0, ptr %migration_disabled, align 4
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %17 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %18
  %19 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %arrayidx, align 4
  %add = add i32 %20, ptrtoint (ptr @runqueues to i32)
  %21 = inttoptr i32 %add to ptr
  %nr_pinned = getelementptr inbounds %struct.rq, ptr %21, i32 0, i32 76
  %22 = ptrtoint ptr %nr_pinned to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %nr_pinned, align 8
  %dec62 = add i32 %23, -1
  store i32 %dec62, ptr %nr_pinned, align 8
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1237
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i77 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i.i77 to ptr
  %preempt_count.i.i78 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 1
  %26 = ptrtoint ptr %preempt_count.i.i78 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %preempt_count.i.i78, align 4
  %sub.i = add i32 %27, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i78, align 4
  br label %cleanup

cleanup:                                          ; preds = %if.end54, %if.then13, %land.rhs, %if.then
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @push_cpu_stop(ptr noundef %arg) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 128
  tail call void @_raw_spin_lock_irq(ptr noundef %pi_lock) #33
  %7 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %10, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@push_cpu_stop, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %entry
  tail call void @_raw_spin_lock_nested(ptr noundef %6, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %11 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %12, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %13 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %14, %if.then.i.i.i ], [ %6, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %15 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %16, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %17 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %18, %if.then.i25.i.i ], [ %6, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %22, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 1
  %23 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 3
  %25 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx10 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %26
  %27 = ptrtoint ptr %arrayidx10 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %arrayidx10, align 4
  %add11 = add i32 %28, ptrtoint (ptr @runqueues to i32)
  %29 = inttoptr i32 %add11 to ptr
  %cmp.not = icmp eq ptr %29, %6
  br i1 %cmp.not, label %if.end, label %out_unlock

if.end:                                           ; preds = %raw_spin_rq_lock.exit
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 37
  %30 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %30)
  %31 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %31, 0
  %migration_flags16 = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 38
  %32 = ptrtoint ptr %migration_flags16 to i32
  call void @__asan_load2_noabort(i32 %32)
  %33 = load i16, ptr %migration_flags16, align 2
  br i1 %tobool.i.not, label %if.end15, label %if.then13

if.then13:                                        ; preds = %if.end
  %34 = or i16 %33, 1
  %35 = ptrtoint ptr %migration_flags16 to i32
  call void @__asan_store2_noabort(i32 %35)
  store i16 %34, ptr %migration_flags16, align 2
  br label %out_unlock

if.end15:                                         ; preds = %if.end
  %36 = and i16 %33, -2
  %37 = ptrtoint ptr %migration_flags16 to i32
  call void @__asan_store2_noabort(i32 %37)
  store i16 %36, ptr %migration_flags16, align 2
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 21
  %38 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %sched_class, align 32
  %find_lock_rq = getelementptr inbounds %struct.sched_class, ptr %39, i32 0, i32 17
  %40 = ptrtoint ptr %find_lock_rq to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %find_lock_rq, align 4
  %tobool.not = icmp eq ptr %41, null
  br i1 %tobool.not, label %out_unlock, label %if.end23

if.end23:                                         ; preds = %if.end15
  %call22 = tail call ptr %41(ptr noundef %arg, ptr noundef %6) #33
  %tobool24.not = icmp eq ptr %call22, null
  br i1 %tobool24.not, label %out_unlock, label %do.body27

do.body27:                                        ; preds = %if.end23
  %42 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %stack.i, align 4
  %cpu.i69 = getelementptr inbounds %struct.thread_info, ptr %43, i32 0, i32 3
  %44 = ptrtoint ptr %cpu.i69 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load volatile i32, ptr %cpu.i69, align 4
  %arrayidx35 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %45
  %46 = ptrtoint ptr %arrayidx35 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %arrayidx35, align 4
  %add36 = add i32 %47, ptrtoint (ptr @runqueues to i32)
  %48 = inttoptr i32 %add36 to ptr
  %cmp37 = icmp eq ptr %48, %6
  br i1 %cmp37, label %if.then39, label %if.end41

if.then39:                                        ; preds = %do.body27
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 12
  %49 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %49)
  store i32 2, ptr %on_rq.i, align 4
  tail call fastcc void @dequeue_task(ptr noundef %6, ptr noundef %arg, i32 noundef 0) #33
  %cpu40 = getelementptr inbounds %struct.rq, ptr %call22, i32 0, i32 46
  %50 = ptrtoint ptr %cpu40 to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %cpu40, align 4
  tail call void @set_task_cpu(ptr noundef %arg, i32 noundef %51)
  tail call fastcc void @enqueue_task(ptr noundef nonnull %call22, ptr noundef %arg, i32 noundef 0) #33
  %52 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 1, ptr %on_rq.i, align 4
  tail call void @resched_curr(ptr noundef nonnull %call22)
  br label %if.end41

if.end41:                                         ; preds = %if.then39, %do.body27
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %53 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %54, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i71

if.then.i.i71:                                    ; preds = %if.end41
  %core.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %55 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i71, %if.end41
  %retval.0.i.i = phi ptr [ %56, %if.then.i.i71 ], [ %6, %if.end41 ]
  %core_enabled.i5.i = getelementptr inbounds %struct.rq, ptr %call22, i32 0, i32 81
  %57 = ptrtoint ptr %core_enabled.i5.i to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %core_enabled.i5.i, align 128
  %tobool.not.i6.i = icmp eq i32 %58, 0
  br i1 %tobool.not.i6.i, label %__rq_lockp.exit10.i, label %if.then.i8.i

if.then.i8.i:                                     ; preds = %__rq_lockp.exit.i
  %core.i7.i = getelementptr inbounds %struct.rq, ptr %call22, i32 0, i32 79
  %59 = ptrtoint ptr %core.i7.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %core.i7.i, align 8
  br label %__rq_lockp.exit10.i

__rq_lockp.exit10.i:                              ; preds = %if.then.i8.i, %__rq_lockp.exit.i
  %retval.0.i9.i = phi ptr [ %60, %if.then.i8.i ], [ %call22, %__rq_lockp.exit.i ]
  %cmp.not.i = icmp eq ptr %retval.0.i.i, %retval.0.i9.i
  br i1 %cmp.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %__rq_lockp.exit10.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@push_cpu_stop, %land.rhs.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %if.then.i
  %61 = ptrtoint ptr %core_enabled.i5.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load i32, ptr %core_enabled.i5.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %62, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock.exit.i, label %if.then.i.i.i73

if.then.i.i.i73:                                  ; preds = %land.rhs.i.i.i.i
  %core.i.i.i72 = getelementptr inbounds %struct.rq, ptr %call22, i32 0, i32 79
  %63 = ptrtoint ptr %core.i.i.i72 to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %core.i.i.i72, align 8
  br label %raw_spin_rq_unlock.exit.i

raw_spin_rq_unlock.exit.i:                        ; preds = %if.then.i.i.i73, %land.rhs.i.i.i.i, %if.then.i
  %retval.0.i.i.i74 = phi ptr [ %64, %if.then.i.i.i73 ], [ %call22, %land.rhs.i.i.i.i ], [ %call22, %if.then.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i74) #33
  br label %if.end.i

if.end.i:                                         ; preds = %raw_spin_rq_unlock.exit.i, %__rq_lockp.exit10.i
  %65 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i12.i = icmp eq i32 %66, 0
  br i1 %tobool.not.i12.i, label %double_unlock_balance.exit, label %if.then.i14.i

if.then.i14.i:                                    ; preds = %if.end.i
  %core.i13.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %67 = ptrtoint ptr %core.i13.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %core.i13.i, align 8
  br label %double_unlock_balance.exit

double_unlock_balance.exit:                       ; preds = %if.then.i14.i, %if.end.i
  %retval.0.i15.i = phi ptr [ %68, %if.then.i14.i ], [ %6, %if.end.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i15.i, i32 0, i32 4
  %69 = tail call ptr @llvm.returnaddress(i32 0) #33
  %70 = ptrtoint ptr %69 to i32
  %name.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i15.i, i32 0, i32 4, i32 2
  %71 = ptrtoint ptr %name.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load ptr, ptr %name.i.i, align 4
  %73 = ptrtoint ptr %dep_map.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %dep_map.i, align 4
  tail call void @lock_set_class(ptr noundef %dep_map.i, ptr noundef %72, ptr noundef %74, i32 noundef 0, i32 noundef %70) #33
  br label %out_unlock

out_unlock:                                       ; preds = %double_unlock_balance.exit, %if.end23, %if.end15, %if.then13, %raw_spin_rq_lock.exit
  %push_busy = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 77
  %75 = ptrtoint ptr %push_busy to i32
  call void @__asan_store4_noabort(i32 %75)
  store i32 0, ptr %push_busy, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@push_cpu_stop, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %out_unlock
  %core_enabled.i.i.i75 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %76 = ptrtoint ptr %core_enabled.i.i.i75 to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load i32, ptr %core_enabled.i.i.i75, align 128
  %tobool3.i.not.i.i = icmp eq i32 %77, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i77

if.then.i.i77:                                    ; preds = %land.rhs.i.i.i
  %core.i.i76 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %78 = ptrtoint ptr %core.i.i76 to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load ptr, ptr %core.i.i76, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i77, %land.rhs.i.i.i, %out_unlock
  %retval.0.i.i78 = phi ptr [ %79, %if.then.i.i77 ], [ %6, %land.rhs.i.i.i ], [ %6, %out_unlock ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i78) #33
  tail call void @_raw_spin_unlock_irq(ptr noundef %pi_lock) #33
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %80 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %80, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i79, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %raw_spin_rq_unlock.exit
  %.not.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i, label %put_task_struct.exit, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %put_task_struct.exit

if.then.i79:                                      ; preds = %raw_spin_rq_unlock.exit
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  tail call void @__put_task_struct(ptr noundef %arg) #33
  br label %put_task_struct.exit

put_task_struct.exit:                             ; preds = %if.then.i79, %if.then10.i.i.i.i, %if.end5.i.i.i.i
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @set_task_cpu(ptr noundef %p, i32 noundef %new_cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load volatile i32, ptr %p, align 128
  switch i32 %1, label %land.rhs [
    i32 0, label %land.lhs.true46
    i32 512, label %if.end101
  ]

land.rhs:                                         ; preds = %entry
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %2 = ptrtoint ptr %on_rq to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %on_rq, align 4
  %tobool.not = icmp eq i32 %3, 0
  br i1 %tobool.not, label %land.rhs5, label %if.end36

land.rhs5:                                        ; preds = %land.rhs
  %.b340 = load i1, ptr @set_task_cpu.__already_done, align 1
  br i1 %.b340, label %if.end36, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs5
  store i1 true, ptr @set_task_cpu.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3035, i32 noundef 9, ptr noundef null) #33
  br label %if.end36

if.end36:                                         ; preds = %if.then, %land.rhs5, %land.rhs
  %cmp45 = icmp eq i32 %1, 0
  br i1 %cmp45, label %land.lhs.true46, label %if.end101

land.lhs.true46:                                  ; preds = %if.end36, %entry
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %4 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %sched_class, align 32
  %cmp47 = icmp eq ptr %5, @fair_sched_class
  br i1 %cmp47, label %land.rhs48, label %if.end101

land.rhs48:                                       ; preds = %land.lhs.true46
  %on_rq49 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %6 = ptrtoint ptr %on_rq49 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %on_rq49, align 4
  %tobool50.not = icmp eq i32 %7, 0
  br i1 %tobool50.not, label %if.end101, label %land.rhs51

land.rhs51:                                       ; preds = %land.rhs48
  %8 = ptrtoint ptr %on_rq49 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %on_rq49, align 4
  %cmp.i.not = icmp eq i32 %9, 2
  br i1 %cmp.i.not, label %if.end101, label %land.rhs63

land.rhs63:                                       ; preds = %land.rhs51
  %.b332339 = load i1, ptr @set_task_cpu.__already_done.6, align 1
  br i1 %.b332339, label %if.end101, label %if.then74, !prof !1191

if.then74:                                        ; preds = %land.rhs63
  store i1 true, ptr @set_task_cpu.__already_done.6, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3044, i32 noundef 9, ptr noundef null) #33
  br label %if.end101

if.end101:                                        ; preds = %if.then74, %land.rhs63, %land.rhs51, %land.rhs48, %land.lhs.true46, %if.end36, %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %10 = load i32, ptr @debug_locks, align 4
  %tobool110.not = icmp eq i32 %10, 0
  br i1 %tobool110.not, label %if.end171, label %land.rhs111

land.rhs111:                                      ; preds = %if.end101
  %dep_map = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef -1) #33
  %tobool113.not = icmp eq i32 %call.i, 0
  br i1 %tobool113.not, label %do.body114, label %if.end171

do.body114:                                       ; preds = %land.rhs111
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %11 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 3
  %13 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %14
  %15 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %arrayidx, align 4
  %add = add i32 %16, ptrtoint (ptr @runqueues to i32)
  %17 = inttoptr i32 %add to ptr
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %17, i32 0, i32 81
  %18 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i = icmp eq i32 %19, 0
  br i1 %tobool.not.i, label %__rq_lockp.exit, label %if.then.i

if.then.i:                                        ; preds = %do.body114
  %core.i = getelementptr inbounds %struct.rq, ptr %17, i32 0, i32 79
  %20 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i, align 8
  br label %__rq_lockp.exit

__rq_lockp.exit:                                  ; preds = %if.then.i, %do.body114
  %retval.0.i = phi ptr [ %21, %if.then.i ], [ %17, %do.body114 ]
  %dep_map121 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i, i32 0, i32 4
  %call.i352 = tail call i32 @lock_is_held_type(ptr noundef %dep_map121, i32 noundef -1) #33
  %tobool123 = icmp eq i32 %call.i352, 0
  br i1 %tobool123, label %land.rhs133, label %if.end171

land.rhs133:                                      ; preds = %__rq_lockp.exit
  %.b333338 = load i1, ptr @set_task_cpu.__already_done.7, align 1
  br i1 %.b333338, label %if.end171, label %if.then144, !prof !1191

if.then144:                                       ; preds = %land.rhs133
  store i1 true, ptr @set_task_cpu.__already_done.7, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3058, i32 noundef 9, ptr noundef null) #33
  br label %if.end171

if.end171:                                        ; preds = %if.then144, %land.rhs133, %__rq_lockp.exit, %land.rhs111, %if.end101
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %22 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %22, %new_cpu
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %if.end171
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %if.end171
  %div3.i.i.i = lshr i32 %new_cpu, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %23 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %new_cpu, 31
  %25 = shl nuw i32 1, %and.i.i.i
  %26 = and i32 %24, %25
  %tobool.i.not = icmp eq i32 %26, 0
  br i1 %tobool.i.not, label %land.rhs189, label %if.end227

land.rhs189:                                      ; preds = %cpu_online.exit
  %.b334337 = load i1, ptr @set_task_cpu.__already_done.8, align 1
  br i1 %.b334337, label %if.end227, label %if.then200, !prof !1191

if.then200:                                       ; preds = %land.rhs189
  store i1 true, ptr @set_task_cpu.__already_done.8, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3063, i32 noundef 9, ptr noundef null) #33
  br label %if.end227

if.end227:                                        ; preds = %if.then200, %land.rhs189, %cpu_online.exit
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %27 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %27)
  %28 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i353.not = icmp eq i16 %28, 0
  br i1 %tobool.i353.not, label %if.end281, label %land.rhs243

land.rhs243:                                      ; preds = %if.end227
  %.b335336 = load i1, ptr @set_task_cpu.__already_done.9, align 1
  br i1 %.b335336, label %if.end281, label %if.then254, !prof !1191

if.then254:                                       ; preds = %land.rhs243
  store i1 true, ptr @set_task_cpu.__already_done.9, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3065, i32 noundef 9, ptr noundef null) #33
  br label %if.end281

if.end281:                                        ; preds = %if.then254, %land.rhs243, %if.end227
  tail call fastcc void @trace_sched_migrate_task(ptr noundef %p, i32 noundef %new_cpu)
  %stack.i354 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %29 = ptrtoint ptr %stack.i354 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %stack.i354, align 4
  %cpu.i355 = getelementptr inbounds %struct.thread_info, ptr %30, i32 0, i32 3
  %31 = ptrtoint ptr %cpu.i355 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load volatile i32, ptr %cpu.i355, align 4
  %cmp290.not = icmp eq i32 %32, %new_cpu
  br i1 %cmp290.not, label %if.end298, label %if.then291

if.then291:                                       ; preds = %if.end281
  %sched_class292 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %33 = ptrtoint ptr %sched_class292 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %sched_class292, align 32
  %migrate_task_rq = getelementptr inbounds %struct.sched_class, ptr %34, i32 0, i32 12
  %35 = ptrtoint ptr %migrate_task_rq to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %migrate_task_rq, align 4
  %tobool293.not = icmp eq ptr %36, null
  br i1 %tobool293.not, label %if.end297, label %if.then294

if.then294:                                       ; preds = %if.then291
  tail call void %36(ptr noundef %p, i32 noundef %new_cpu) #33
  br label %if.end297

if.end297:                                        ; preds = %if.then294, %if.then291
  %nr_migrations = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 8
  %37 = ptrtoint ptr %nr_migrations to i32
  call void @__asan_load8_noabort(i32 %37)
  %38 = load i64, ptr %nr_migrations, align 64
  %inc = add i64 %38, 1
  store i64 %inc, ptr %nr_migrations, align 64
  %rseq_event_mask.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 176
  %39 = ptrtoint ptr %rseq_event_mask.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %rseq_event_mask.i, align 4
  %or.i.i = or i32 %40, 4
  store i32 %or.i.i, ptr %rseq_event_mask.i, align 4
  %rseq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 174
  %41 = ptrtoint ptr %rseq.i.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %rseq.i.i, align 8
  %tobool.not.i.i = icmp eq ptr %42, null
  br i1 %tobool.not.i.i, label %rseq_migrate.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end297
  %43 = ptrtoint ptr %stack.i354 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %stack.i354, align 4
  tail call void @_set_bit(i32 noundef 2, ptr noundef %44) #33
  br label %rseq_migrate.exit

rseq_migrate.exit:                                ; preds = %if.then.i.i, %if.end297
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([12 x %struct.static_key], ptr @perf_swevent_enabled, i32 0, i32 4), ptr blockaddress(@set_task_cpu, %if.then.i356)) #33
          to label %if.end298 [label %if.then.i356], !srcloc !1202

if.then.i356:                                     ; preds = %rseq_migrate.exit
  %sched_migrated.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %45 = ptrtoint ptr %sched_migrated.i to i32
  call void @__asan_load1_noabort(i32 %45)
  %bf.load.i = load i8, ptr %sched_migrated.i, align 4
  %bf.set.i = or i8 %bf.load.i, 32
  store i8 %bf.set.i, ptr %sched_migrated.i, align 4
  br label %if.end298

if.end298:                                        ; preds = %if.then.i356, %rseq_migrate.exit, %if.end281
  %sched_task_group.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %46 = ptrtoint ptr %sched_task_group.i.i.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %sched_task_group.i.i.i, align 8
  %se.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %cfs_rq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 11
  %48 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %cfs_rq.i.i, align 16
  %cfs_rq2.i.i = getelementptr inbounds %struct.task_group, ptr %47, i32 0, i32 2
  %50 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx.i.i = getelementptr ptr, ptr %51, i32 %new_cpu
  %52 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %arrayidx.i.i, align 4
  tail call void @set_task_rq_fair(ptr noundef %se.i.i, ptr noundef %49, ptr noundef %53) #33
  %54 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx4.i.i = getelementptr ptr, ptr %55, i32 %new_cpu
  %56 = ptrtoint ptr %arrayidx4.i.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %arrayidx4.i.i, align 4
  %58 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_store4_noabort(i32 %58)
  store ptr %57, ptr %cfs_rq.i.i, align 16
  %se7.i.i = getelementptr inbounds %struct.task_group, ptr %47, i32 0, i32 1
  %59 = ptrtoint ptr %se7.i.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %se7.i.i, align 8
  %arrayidx8.i.i = getelementptr ptr, ptr %60, i32 %new_cpu
  %61 = ptrtoint ptr %arrayidx8.i.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load ptr, ptr %arrayidx8.i.i, align 4
  %parent.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 10
  %63 = ptrtoint ptr %parent.i.i to i32
  call void @__asan_store4_noabort(i32 %63)
  store ptr %62, ptr %parent.i.i, align 4
  %rt_rq.i.i = getelementptr inbounds %struct.task_group, ptr %47, i32 0, i32 8
  %64 = ptrtoint ptr %rt_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load ptr, ptr %rt_rq.i.i, align 8
  %arrayidx10.i.i = getelementptr ptr, ptr %65, i32 %new_cpu
  %66 = ptrtoint ptr %arrayidx10.i.i to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load ptr, ptr %arrayidx10.i.i, align 4
  %rt_rq11.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 8
  %68 = ptrtoint ptr %rt_rq11.i.i to i32
  call void @__asan_store4_noabort(i32 %68)
  store ptr %67, ptr %rt_rq11.i.i, align 32
  %rt_se.i.i = getelementptr inbounds %struct.task_group, ptr %47, i32 0, i32 7
  %69 = ptrtoint ptr %rt_se.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %rt_se.i.i, align 4
  %arrayidx12.i.i = getelementptr ptr, ptr %70, i32 %new_cpu
  %71 = ptrtoint ptr %arrayidx12.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load ptr, ptr %arrayidx12.i.i, align 4
  %parent14.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 7
  %73 = ptrtoint ptr %parent14.i.i to i32
  call void @__asan_store4_noabort(i32 %73)
  store ptr %72, ptr %parent14.i.i, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1238
  %74 = ptrtoint ptr %stack.i354 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load ptr, ptr %stack.i354, align 4
  %cpu7.i = getelementptr inbounds %struct.thread_info, ptr %75, i32 0, i32 3
  %76 = ptrtoint ptr %cpu7.i to i32
  call void @__asan_store4_noabort(i32 %76)
  store volatile i32 %new_cpu, ptr %cpu7.i, align 4
  %wake_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 11
  %77 = ptrtoint ptr %wake_cpu.i to i32
  call void @__asan_store4_noabort(i32 %77)
  store i32 %new_cpu, ptr %wake_cpu.i, align 16
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @set_cpus_allowed_common(ptr nocapture noundef writeonly %p, ptr noundef %new_mask, i32 noundef %flags) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %and = and i32 %flags, 6
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  %0 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr %new_mask, ptr %cpus_ptr, align 4
  br label %return

if.end:                                           ; preds = %entry
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %1 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i = add i32 %1, 31
  %2 = lshr i32 %sub.i.i, 3
  %mul.i.i = and i32 %2, 536870908
  %3 = call ptr @memcpy(ptr %cpus_mask, ptr %new_mask, i32 %mul.i.i)
  %call4.i.i = tail call i32 @__bitmap_weight(ptr noundef %new_mask, i32 noundef %1) #33
  %nr_cpus_allowed = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 32
  %4 = ptrtoint ptr %nr_cpus_allowed to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %call4.i.i, ptr %nr_cpus_allowed, align 8
  br label %return

return:                                           ; preds = %if.end, %if.then
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @do_set_cpus_allowed(ptr noundef %p, ptr noundef %new_mask) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @__do_set_cpus_allowed(ptr noundef %p, ptr noundef %new_mask, i32 noundef 0)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__do_set_cpus_allowed(ptr noundef %p, ptr noundef %new_mask, i32 noundef %flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %0 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %and = and i32 %flags, 2
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %do.body44, label %if.then

if.then:                                          ; preds = %entry
  %on_cpu = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %7 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %on_cpu, align 4
  %tobool2.not = icmp eq i32 %8, 0
  br i1 %tobool2.not, label %land.rhs, label %if.end83

land.rhs:                                         ; preds = %if.then
  %.b123 = load i1, ptr @__do_set_cpus_allowed.__already_done, align 1
  br i1 %.b123, label %if.end83, label %if.then11, !prof !1191

if.then11:                                        ; preds = %land.rhs
  store i1 true, ptr @__do_set_cpus_allowed.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2506, i32 noundef 9, ptr noundef nonnull @.str.190) #33
  br label %if.end83

do.body44:                                        ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %9 = load i32, ptr @debug_locks, align 4
  %tobool46.not = icmp eq i32 %9, 0
  br i1 %tobool46.not, label %if.end83, label %land.rhs47

land.rhs47:                                       ; preds = %do.body44
  %dep_map = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef -1) #33
  %cmp.not = icmp eq i32 %call.i, 0
  br i1 %cmp.not, label %do.end67, label %if.end83, !prof !1192

do.end67:                                         ; preds = %land.rhs47
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2508, i32 noundef 9, ptr noundef null) #33
  br label %if.end83

if.end83:                                         ; preds = %do.end67, %land.rhs47, %do.body44, %if.then11, %land.rhs, %if.then
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %10 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %11, 1
  %curr.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 20
  %12 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %curr.i, align 8
  %cmp.i124.not = icmp eq ptr %13, %p
  br i1 %cmp.i.not, label %if.then91, label %if.end92

if.then91:                                        ; preds = %if.end83
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %14 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %14, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then91
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %15 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %16, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %17 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %18, %if.then.i.i ], [ %6, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %if.then91
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__do_set_cpus_allowed, %land.rhs.i.i)) #33
          to label %if.end.i [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %lockdep_assert_rq_held.exit
  %core_enabled.i.i126 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %19 = ptrtoint ptr %core_enabled.i.i126 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %core_enabled.i.i126, align 128
  %tobool3.i.not.i = icmp eq i32 %20, 0
  br i1 %tobool3.i.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %land.rhs.i.i
  %core.i.i127 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %21 = ptrtoint ptr %core.i.i127 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %core.i.i127, align 8
  %core_task_seq.i.i = getelementptr inbounds %struct.rq, ptr %22, i32 0, i32 84
  %23 = ptrtoint ptr %core_task_seq.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %core_task_seq.i.i, align 4
  %inc.i.i = add i32 %24, 1
  store i32 %inc.i.i, ptr %core_task_seq.i.i, align 4
  %core_node.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22
  %25 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %core_node.i.i.i, align 4
  %27 = ptrtoint ptr %core_node.i.i.i to i32
  %cmp.i.not.i.i = icmp eq i32 %26, %27
  br i1 %cmp.i.not.i.i, label %if.end.i, label %if.then.i.i128

if.then.i.i128:                                   ; preds = %if.then.i
  %core_tree.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 83
  tail call void @rb_erase(ptr noundef %core_node.i.i.i, ptr noundef %core_tree.i.i) #33
  %28 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 %27, ptr %core_node.i.i.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i.i128, %if.then.i, %land.rhs.i.i, %lockdep_assert_rq_held.exit
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@__do_set_cpus_allowed, %if.end.i25.i)) #33
          to label %dequeue_task.exit [label %if.end.i25.i], !srcloc !1202

if.end.i25.i:                                     ; preds = %if.end.i
  %sched_class.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %29 = ptrtoint ptr %sched_class.i.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %sched_class.i.i, align 32
  %31 = ptrtoint ptr %30 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %30, align 4
  %tobool3.not.i.i = icmp eq i32 %32, 0
  br i1 %tobool3.not.i.i, label %dequeue_task.exit, label %for.body.preheader.i.i, !prof !1192

for.body.preheader.i.i:                           ; preds = %if.end.i25.i
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %6, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %6, ptr noundef %p, i32 noundef 1) #33
  br label %dequeue_task.exit

dequeue_task.exit:                                ; preds = %for.body.preheader.i.i, %if.end.i25.i, %if.end.i
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %33 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %sched_class.i, align 32
  %dequeue_task.i = getelementptr inbounds %struct.sched_class, ptr %34, i32 0, i32 2
  %35 = ptrtoint ptr %dequeue_task.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %dequeue_task.i, align 4
  tail call void %36(ptr noundef %6, ptr noundef %p, i32 noundef 10) #33
  br label %if.end92

if.end92:                                         ; preds = %dequeue_task.exit, %if.end83
  br i1 %cmp.i124.not, label %if.then94, label %if.end95

if.then94:                                        ; preds = %if.end92
  %37 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %curr.i, align 8
  %cmp.not.i130 = icmp eq ptr %38, %p
  br i1 %cmp.not.i130, label %put_prev_task.exit, label %land.rhs.i131

land.rhs.i131:                                    ; preds = %if.then94
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i132, !prof !1191

if.then.i132:                                     ; preds = %land.rhs.i131
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i132, %land.rhs.i131, %if.then94
  %sched_class.i133 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %39 = ptrtoint ptr %sched_class.i133 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %sched_class.i133, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %40, i32 0, i32 7
  %41 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %42(ptr noundef %6, ptr noundef %p) #33
  br label %if.end95

if.end95:                                         ; preds = %put_prev_task.exit, %if.end92
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %43 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %sched_class, align 32
  %set_cpus_allowed = getelementptr inbounds %struct.sched_class, ptr %44, i32 0, i32 14
  %45 = ptrtoint ptr %set_cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %set_cpus_allowed, align 4
  tail call void %46(ptr noundef %p, ptr noundef %new_mask, i32 noundef %flags) #33
  br i1 %cmp.i.not, label %if.then97, label %if.end98

if.then97:                                        ; preds = %if.end95
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@__do_set_cpus_allowed, %if.end.i22.i)) #33
          to label %uclamp_rq_inc.exit.i [label %if.end.i22.i], !srcloc !1202

if.end.i22.i:                                     ; preds = %if.then97
  %47 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %sched_class, align 32
  %49 = ptrtoint ptr %48 to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %48, align 4
  %tobool3.not.i.i136 = icmp eq i32 %50, 0
  br i1 %tobool3.not.i.i136, label %uclamp_rq_inc.exit.i, label %for.body.preheader.i.i137, !prof !1192

for.body.preheader.i.i137:                        ; preds = %if.end.i22.i
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %6, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %6, ptr noundef %p, i32 noundef 1) #33
  %uclamp_flags.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 12
  %51 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %uclamp_flags.i.i, align 16
  %and.i.i = and i32 %52, 1
  %tobool14.not.i.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool14.not.i.i, label %uclamp_rq_inc.exit.i, label %if.then15.i.i

if.then15.i.i:                                    ; preds = %for.body.preheader.i.i137
  %and17.i.i = and i32 %52, -2
  %53 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %and17.i.i, ptr %uclamp_flags.i.i, align 16
  br label %uclamp_rq_inc.exit.i

uclamp_rq_inc.exit.i:                             ; preds = %if.then15.i.i, %for.body.preheader.i.i137, %if.end.i22.i, %if.then97
  %54 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %sched_class, align 32
  %enqueue_task.i = getelementptr inbounds %struct.sched_class, ptr %55, i32 0, i32 1
  %56 = ptrtoint ptr %enqueue_task.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %enqueue_task.i, align 4
  tail call void %57(ptr noundef %6, ptr noundef %p, i32 noundef 10) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__do_set_cpus_allowed, %land.rhs.i.i141)) #33
          to label %if.end98 [label %land.rhs.i.i141], !srcloc !1202

land.rhs.i.i141:                                  ; preds = %uclamp_rq_inc.exit.i
  %core_enabled.i.i139 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %58 = ptrtoint ptr %core_enabled.i.i139 to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %core_enabled.i.i139, align 128
  %tobool3.i.not.i140 = icmp eq i32 %59, 0
  br i1 %tobool3.i.not.i140, label %if.end98, label %if.then7.i

if.then7.i:                                       ; preds = %land.rhs.i.i141
  tail call void @sched_core_enqueue(ptr noundef %6, ptr noundef %p) #33
  br label %if.end98

if.end98:                                         ; preds = %if.then7.i, %land.rhs.i.i141, %uclamp_rq_inc.exit.i, %if.end95
  br i1 %cmp.i124.not, label %if.then100, label %if.end101

if.then100:                                       ; preds = %if.end98
  %60 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %sched_class, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %61, i32 0, i32 8
  %62 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load ptr, ptr %set_next_task.i, align 4
  tail call void %63(ptr noundef %6, ptr noundef %p, i1 noundef zeroext false) #33
  br label %if.end101

if.end101:                                        ; preds = %if.then100, %if.end98
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @dup_user_cpus_ptr(ptr nocapture noundef writeonly %dst, ptr nocapture noundef readonly %src, i32 noundef %node) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %user_cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %src, i32 0, i32 34
  %0 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %user_cpus_ptr, align 16
  %tobool.not = icmp eq ptr %1, null
  br i1 %tobool.not, label %return, label %if.end5.i

if.end5.i:                                        ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %2 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i = add i32 %2, 31
  %3 = lshr i32 %sub.i, 3
  %mul.i = and i32 %3, 536870908
  %call.i4.i = tail call noalias align 128 ptr @__kmalloc(i32 noundef %mul.i, i32 noundef 3264) #38
  %user_cpus_ptr2 = getelementptr inbounds %struct.task_struct, ptr %dst, i32 0, i32 34
  %4 = ptrtoint ptr %user_cpus_ptr2 to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr %call.i4.i, ptr %user_cpus_ptr2, align 16
  %tobool4.not = icmp eq ptr %call.i4.i, null
  br i1 %tobool4.not, label %return, label %if.end6

if.end6:                                          ; preds = %if.end5.i
  %5 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %user_cpus_ptr, align 16
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i = add i32 %7, 31
  %8 = lshr i32 %sub.i.i, 3
  %mul.i.i = and i32 %8, 536870908
  %9 = call ptr @memcpy(ptr %call.i4.i, ptr %6, i32 %mul.i.i)
  br label %return

return:                                           ; preds = %if.end6, %if.end5.i, %entry
  %retval.0 = phi i32 [ 0, %if.end6 ], [ 0, %entry ], [ -12, %if.end5.i ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @release_user_cpus_ptr(ptr nocapture noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %user_cpus_ptr.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 34
  %0 = ptrtoint ptr %user_cpus_ptr.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %user_cpus_ptr.i, align 16
  store ptr null, ptr %user_cpus_ptr.i, align 16
  tail call void @kfree(ptr noundef %1) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @kfree(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @set_cpus_allowed_ptr(ptr noundef %p, ptr noundef %new_mask) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf.i = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i) #33
  %0 = ptrtoint ptr %rf.i to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf.i, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call.i = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf.i) #33
  %call1.i = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %new_mask, i32 noundef 0, ptr noundef %call.i, ptr noundef nonnull %rf.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i) #33
  ret i32 %call1.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @force_compatible_cpus_allowed_ptr(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf.i.i = alloca %struct.rq_flags, align 4
  %new_mask = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %new_mask) #33
  %0 = ptrtoint ptr %new_mask to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %new_mask, align 4, !annotation !1193
  %call = call zeroext i1 @alloc_cpumask_var(ptr noundef nonnull %new_mask, i32 noundef 3264) #33
  call void @cpus_read_lock() #33
  %1 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %new_mask, align 4
  %cmp.i.not = icmp eq ptr %2, null
  br i1 %cmp.i.not, label %out_set_mask, label %if.end

if.end:                                           ; preds = %entry
  %call2 = call fastcc i32 @restrict_cpus_allowed_ptr(ptr noundef %p, ptr noundef nonnull %2)
  %tobool.not = icmp eq i32 %call2, 0
  br i1 %tobool.not, label %out_free_mask, label %if.end4

if.end4:                                          ; preds = %if.end
  %3 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %new_mask, align 4
  call void @cpuset_cpus_allowed(ptr noundef %p, ptr noundef %4) #33
  %5 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %new_mask, align 4
  br label %out_set_mask

out_set_mask:                                     ; preds = %if.end4, %entry
  %override_mask.0 = phi ptr [ %6, %if.end4 ], [ @__cpu_possible_mask, %entry ]
  %call5 = call i32 @__printk_ratelimit(ptr noundef nonnull @__func__.force_compatible_cpus_allowed_ptr) #33
  %tobool6.not = icmp eq i32 %call5, 0
  br i1 %tobool6.not, label %if.end11, label %do.end

do.end:                                           ; preds = %out_set_mask
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %7 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %pid.i, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %9 = load i32, ptr @nr_cpu_ids, align 4
  %call10 = call i32 (ptr, ...) @_printk_deferred(ptr noundef nonnull @.str.5, i32 noundef %8, ptr noundef %comm, i32 noundef %9, ptr noundef %override_mask.0) #39
  br label %if.end11

if.end11:                                         ; preds = %do.end, %out_set_mask
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i.i) #33
  %10 = ptrtoint ptr %rf.i.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 -1, ptr %rf.i.i, align 4, !annotation !1193
  %11 = getelementptr inbounds %struct.rq_flags, ptr %rf.i.i, i32 0, i32 1
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 -1, ptr %11, align 4, !annotation !1193
  %13 = getelementptr inbounds %struct.rq_flags, ptr %rf.i.i, i32 0, i32 2
  %14 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 -1, ptr %13, align 4, !annotation !1193
  %call.i.i = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf.i.i) #33
  %call1.i.i = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %override_mask.0, i32 noundef 0, ptr noundef %call.i.i, ptr noundef nonnull %rf.i.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i.i) #33
  %tobool13.not = icmp eq i32 %call1.i.i, 0
  br i1 %tobool13.not, label %out_free_mask, label %do.end25, !prof !1191

do.end25:                                         ; preds = %if.end11
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2989, i32 noundef 9, ptr noundef null) #33
  br label %out_free_mask

out_free_mask:                                    ; preds = %do.end25, %if.end11, %if.end
  call void @cpus_read_unlock() #33
  %15 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %new_mask, align 4
  call void @free_cpumask_var(ptr noundef %16) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %new_mask) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @alloc_cpumask_var(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpus_read_lock() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @restrict_cpus_allowed_ptr(ptr noundef %p, ptr noundef %new_mask) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %user_cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 34
  %5 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %user_cpus_ptr, align 16
  %tobool.not = icmp eq ptr %6, null
  br i1 %tobool.not, label %if.end8.i, label %if.end4

if.end8.i:                                        ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i = add i32 %7, 31
  %8 = lshr i32 %sub.i, 3
  %mul.i = and i32 %8, 536870908
  %call9.i = tail call noalias align 128 ptr @__kmalloc(i32 noundef %mul.i, i32 noundef 3264) #38
  %tobool2.not = icmp eq ptr %call9.i, null
  br i1 %tobool2.not, label %cleanup, label %if.end4

if.end4:                                          ; preds = %if.end8.i, %entry
  %user_mask.0 = phi ptr [ null, %entry ], [ %call9.i, %if.end8.i ]
  %call5 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 31
  %9 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %policy.i, align 4
  %cmp.i.i1.not = icmp eq i32 %10, 6
  br i1 %cmp.i.i1.not, label %land.lhs.true, label %if.end.i.i3

land.lhs.true:                                    ; preds = %if.end4
  %11 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %tobool9.not = icmp slt i32 %11, 0
  br i1 %tobool9.not, label %if.end.i.i3, label %err_unlock

if.end.i.i3:                                      ; preds = %land.lhs.true, %if.end4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %12 = load i32, ptr @nr_cpu_ids, align 4
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 35
  %call.i.i = tail call i32 @__bitmap_and(ptr noundef %new_mask, ptr noundef %cpus_mask, ptr noundef nonnull @__cpu_possible_mask, i32 noundef %12) #33
  %tobool13.not = icmp eq i32 %call.i.i, 0
  br i1 %tobool13.not, label %err_unlock, label %if.end15

if.end15:                                         ; preds = %if.end.i.i3
  %tobool16.not = icmp eq ptr %user_mask.0, null
  br i1 %tobool16.not, label %if.end19, label %if.then17

if.then17:                                        ; preds = %if.end15
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  %13 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %cpus_ptr, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %15 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i4 = add i32 %15, 31
  %16 = lshr i32 %sub.i.i4, 3
  %mul.i.i = and i32 %16, 536870908
  %17 = call ptr @memcpy(ptr %user_mask.0, ptr %14, i32 %mul.i.i)
  %18 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr %user_mask.0, ptr %user_cpus_ptr, align 16
  br label %if.end19

if.end19:                                         ; preds = %if.then17, %if.end15
  %call20 = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %new_mask, i32 noundef 0, ptr noundef %call5, ptr noundef nonnull %rf)
  br label %cleanup

err_unlock:                                       ; preds = %if.end.i.i3, %land.lhs.true
  %err.0 = phi i32 [ -1, %land.lhs.true ], [ -22, %if.end.i.i3 ]
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 81
  %19 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %20, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %err_unlock
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 79
  %21 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %err_unlock
  %retval.0.i.i.i = phi ptr [ %22, %if.then.i.i.i ], [ %call5, %err_unlock ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %23 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %23)
  %.unpack.i.i = load i32, ptr %1, align 4
  %24 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %24) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@restrict_cpus_allowed_ptr, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %25 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %26, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 79
  %27 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %28, %if.then.i.i4.i ], [ %call5, %land.rhs.i.i.i.i ], [ %call5, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %29 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %30) #33
  tail call void @kfree(ptr noundef %user_mask.0) #33
  br label %cleanup

cleanup:                                          ; preds = %task_rq_unlock.exit, %if.end19, %if.end8.i
  %retval.0 = phi i32 [ %err.0, %task_rq_unlock.exit ], [ %call20, %if.end19 ], [ -12, %if.end8.i ]
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpuset_cpus_allowed(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__printk_ratelimit(ptr noundef) local_unnamed_addr #2

; Function Attrs: cold null_pointer_is_valid
declare dso_local i32 @_printk_deferred(ptr noundef, ...) local_unnamed_addr #10

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpus_read_unlock() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @free_cpumask_var(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @relax_compatible_cpus_allowed_ptr(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %user_cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 34
  %0 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %user_cpus_ptr, align 16
  %tobool.not = icmp eq ptr %1, null
  br i1 %tobool.not, label %cleanup, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %entry
  %call = tail call fastcc i32 @__sched_setaffinity(ptr noundef %p, ptr noundef nonnull %1)
  %tobool1.not = icmp eq i32 %call, 0
  br i1 %tobool1.not, label %cleanup, label %do.body

do.body:                                          ; preds = %lor.lhs.false
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %call2 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %2 = ptrtoint ptr %user_cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %user_cpus_ptr, align 16
  store ptr null, ptr %user_cpus_ptr, align 16
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call2) #33
  tail call void @kfree(ptr noundef %3) #33
  br label %cleanup

cleanup:                                          ; preds = %do.body, %lor.lhs.false, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @__sched_setaffinity(ptr noundef %p, ptr noundef %mask) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf.i = alloca %struct.rq_flags, align 4
  %cpus_allowed = alloca ptr, align 4
  %new_mask = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %cpus_allowed) #33
  %0 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %cpus_allowed, align 4, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %new_mask) #33
  %1 = ptrtoint ptr %new_mask to i32
  call void @__asan_store4_noabort(i32 %1)
  store ptr inttoptr (i32 -1 to ptr), ptr %new_mask, align 4, !annotation !1193
  %call = call zeroext i1 @alloc_cpumask_var(ptr noundef nonnull %cpus_allowed, i32 noundef 3264) #33
  br i1 %call, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %call2 = call zeroext i1 @alloc_cpumask_var(ptr noundef nonnull %new_mask, i32 noundef 3264) #33
  br i1 %call2, label %if.end4, label %out_free_cpus_allowed

if.end4:                                          ; preds = %if.end
  %2 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %cpus_allowed, align 4
  call void @cpuset_cpus_allowed(ptr noundef %p, ptr noundef %3) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %5 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %cpus_allowed, align 4
  %7 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %new_mask, align 4
  %call.i.i = call i32 @__bitmap_and(ptr noundef %8, ptr noundef %mask, ptr noundef %6, i32 noundef %4) #33
  %9 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %new_mask, align 4
  %call6 = call i32 @dl_task_check_affinity(ptr noundef %p, ptr noundef %10)
  %tobool.not = icmp eq i32 %call6, 0
  br i1 %tobool.not, label %again.preheader, label %out_free_new_mask

again.preheader:                                  ; preds = %if.end4
  %11 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 1
  %12 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 2
  %13 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %new_mask, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i) #33
  %15 = ptrtoint ptr %rf.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 -1, ptr %rf.i, align 4, !annotation !1193
  %16 = ptrtoint ptr %11 to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 -1, ptr %11, align 4, !annotation !1193
  %17 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 -1, ptr %12, align 4, !annotation !1193
  %call.i33 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf.i) #33
  %call1.i34 = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %14, i32 noundef 9, ptr noundef %call.i33, ptr noundef nonnull %rf.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i) #33
  %tobool10.not35 = icmp eq i32 %call1.i34, 0
  br i1 %tobool10.not35, label %if.end12, label %out_free_new_mask

if.end12:                                         ; preds = %if.then15, %again.preheader
  %18 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %cpus_allowed, align 4
  call void @cpuset_cpus_allowed(ptr noundef %p, ptr noundef %19) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %20 = load i32, ptr @nr_cpu_ids, align 4
  %21 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %cpus_allowed, align 4
  %23 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %new_mask, align 4
  %call.i.i30 = call i32 @__bitmap_subset(ptr noundef %24, ptr noundef %22, i32 noundef %20) #33
  %tobool14.not = icmp eq i32 %call.i.i30, 0
  br i1 %tobool14.not, label %if.then15, label %out_free_new_mask

if.then15:                                        ; preds = %if.end12
  %25 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %new_mask, align 4
  %27 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %cpus_allowed, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %29 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i32 = add i32 %29, 31
  %30 = lshr i32 %sub.i.i32, 3
  %mul.i.i = and i32 %30, 536870908
  %31 = call ptr @memcpy(ptr %26, ptr %28, i32 %mul.i.i)
  %32 = load ptr, ptr %new_mask, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i) #33
  %33 = ptrtoint ptr %rf.i to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 -1, ptr %rf.i, align 4, !annotation !1193
  %34 = ptrtoint ptr %11 to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 -1, ptr %11, align 4, !annotation !1193
  %35 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 -1, ptr %12, align 4, !annotation !1193
  %call.i = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf.i) #33
  %call1.i = call fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %32, i32 noundef 9, ptr noundef %call.i, ptr noundef nonnull %rf.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i) #33
  %tobool10.not = icmp eq i32 %call1.i, 0
  br i1 %tobool10.not, label %if.end12, label %out_free_new_mask

out_free_new_mask:                                ; preds = %if.then15, %if.end12, %again.preheader, %if.end4
  %retval1.0 = phi i32 [ %call6, %if.end4 ], [ %call1.i34, %again.preheader ], [ %call1.i, %if.then15 ], [ 0, %if.end12 ]
  %36 = ptrtoint ptr %new_mask to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %new_mask, align 4
  call void @free_cpumask_var(ptr noundef %37) #33
  br label %out_free_cpus_allowed

out_free_cpus_allowed:                            ; preds = %out_free_new_mask, %if.end
  %retval1.1 = phi i32 [ %retval1.0, %out_free_new_mask ], [ -12, %if.end ]
  %38 = ptrtoint ptr %cpus_allowed to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %cpus_allowed, align 4
  call void @free_cpumask_var(ptr noundef %39) #33
  br label %cleanup

cleanup:                                          ; preds = %out_free_cpus_allowed, %entry
  %retval.0 = phi i32 [ %retval1.1, %out_free_cpus_allowed ], [ -12, %entry ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %new_mask) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %cpus_allowed) #33
  ret i32 %retval.0
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_migrate_task(ptr noundef %p, i32 noundef %dest_cpu) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_migrate_task, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_migrate_task, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1239
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_migrate_task, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %p, i32 noundef %dest_cpu) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1240
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1240
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_migrate_task, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_migrate_task.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_migrate_task.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 296, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @wait_task_inactive(ptr noundef %p, i32 noundef %match_state) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %to = alloca i64, align 8
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %on_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %tobool3.not = icmp eq i32 %match_state, 0
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %nvcsw = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 90
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  br label %for.cond

for.cond:                                         ; preds = %for.cond.backedge, %entry
  %5 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %cpu.i, align 4
  %9 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %on_cpu.i, align 4
  %tobool.not167 = icmp eq i32 %10, 0
  br i1 %tobool.not167, label %while.end, label %while.body

while.body:                                       ; preds = %do.end14, %for.cond
  br i1 %tobool3.not, label %do.end14, label %do.end6

do.end6:                                          ; preds = %while.body
  %11 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %p, align 128
  %cmp.not = icmp eq i32 %12, %match_state
  br i1 %cmp.not, label %do.end14, label %cleanup, !prof !1191

do.end14:                                         ; preds = %do.end6, %while.body
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1243
  call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1244
  %13 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %on_cpu.i, align 4
  %tobool.not = icmp eq i32 %14, 0
  br i1 %tobool.not, label %while.end, label %while.body

while.end:                                        ; preds = %do.end14, %for.cond
  %call19 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  call fastcc void @trace_sched_wait_task(ptr noundef %p)
  %15 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %on_cpu.i, align 4
  %17 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %18, 1
  br i1 %tobool3.not, label %if.then29, label %do.end25

do.end25:                                         ; preds = %while.end
  %19 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %p, align 128
  %cmp28 = icmp eq i32 %20, %match_state
  br i1 %cmp28, label %if.then29, label %if.end30

if.then29:                                        ; preds = %do.end25, %while.end
  %21 = ptrtoint ptr %nvcsw to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %nvcsw, align 16
  %or = or i32 %22, -2147483648
  br label %if.end30

if.end30:                                         ; preds = %if.then29, %do.end25
  %ncsw.0 = phi i32 [ %or, %if.then29 ], [ 0, %do.end25 ]
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %call19, i32 0, i32 25
  %23 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %24, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end30
  %25 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 4, ptr %3, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end30
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call19, i32 0, i32 81
  %26 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %27, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call19, i32 0, i32 79
  %28 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %29, %if.then.i.i.i ], [ %call19, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %30 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %30)
  %.unpack.i.i = load i32, ptr %1, align 4
  %31 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %31) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@wait_task_inactive, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %32 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %33, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call19, i32 0, i32 79
  %34 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %35, %if.then.i.i4.i ], [ %call19, %land.rhs.i.i.i.i ], [ %call19, %rq_unpin_lock.exit.i ]
  call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %36 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %rf, align 4
  call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %37) #33
  %tobool31.not = icmp eq i32 %ncsw.0, 0
  br i1 %tobool31.not, label %cleanup, label %if.end41, !prof !1192

if.end41:                                         ; preds = %task_rq_unlock.exit
  %tobool42.not = icmp eq i32 %16, 0
  br i1 %tobool42.not, label %if.end59, label %do.end54, !prof !1191

do.end54:                                         ; preds = %if.end41
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1245
  call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1246
  br label %for.cond.backedge

for.cond.backedge:                                ; preds = %__here, %do.end54
  br label %for.cond

if.end59:                                         ; preds = %if.end41
  br i1 %cmp.i.not, label %if.then67, label %cleanup, !prof !1192

if.then67:                                        ; preds = %if.end59
  call void @llvm.lifetime.start.p0(i64 8, ptr nonnull %to) #33
  %38 = ptrtoint ptr %to to i32
  call void @__asan_store8_noabort(i32 %38)
  store i64 10000000, ptr %to, align 8
  br label %__here

__here:                                           ; preds = %if.then67
  %39 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %39, -16384
  %40 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %40, i32 0, i32 2
  %41 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %task, align 8
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %42, i32 0, i32 212
  %43 = ptrtoint ptr %task_state_change to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 ptrtoint (ptr blockaddress(@wait_task_inactive, %__here) to i32), ptr %task_state_change, align 4
  %44 = load ptr, ptr %task, align 8
  %45 = ptrtoint ptr %44 to i32
  call void @__asan_store4_noabort(i32 %45)
  store volatile i32 2, ptr %44, align 128
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1247
  %call141 = call i32 @schedule_hrtimeout(ptr noundef nonnull %to, i32 noundef 9) #33
  call void @llvm.lifetime.end.p0(i64 8, ptr nonnull %to) #33
  br label %for.cond.backedge

cleanup:                                          ; preds = %if.end59, %task_rq_unlock.exit, %do.end6
  %retval.0 = phi i32 [ 0, %do.end6 ], [ 0, %task_rq_unlock.exit ], [ %ncsw.0, %if.end59 ]
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %retval.0
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_wait_task(ptr noundef %p) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wait_task, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_wait_task, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1248
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wait_task, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %p) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1249
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1249
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wait_task, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_wait_task.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_wait_task.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 339, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @task_rq_unlock(ptr noundef %rq, ptr noundef %p, ptr nocapture noundef %rf) unnamed_addr #3 align 64 {
entry:
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %0 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ugt i32 %1, 2
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %clock_update_flags1.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %2 = ptrtoint ptr %clock_update_flags1.i to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 4, ptr %clock_update_flags1.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %if.end.i
  %retval.0.i.i = phi ptr [ %6, %if.then.i.i ], [ %rq, %if.end.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %7 = ptrtoint ptr %cookie.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %.unpack.i = load i32, ptr %cookie.i, align 4
  %8 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %8) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@task_rq_unlock, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %rq_unpin_lock.exit
  %9 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %10, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i4

if.then.i.i4:                                     ; preds = %land.rhs.i.i.i
  %core.i.i3 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i3 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i3, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i4, %land.rhs.i.i.i, %rq_unpin_lock.exit
  %retval.0.i.i5 = phi ptr [ %12, %if.then.i.i4 ], [ %rq, %land.rhs.i.i.i ], [ %rq, %rq_unpin_lock.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5) #33
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %13 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %14) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @schedule_hrtimeout(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @kick_process(ptr noundef readonly %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1250
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %4 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %cpu.i, align 4
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i to ptr
  %cpu2 = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 3
  %10 = ptrtoint ptr %cpu2 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %cpu2, align 4
  %cmp.not = icmp eq i32 %7, %11
  br i1 %cmp.not, label %do.body4, label %land.lhs.true

land.lhs.true:                                    ; preds = %entry
  %12 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %13
  %14 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx.i, align 4
  %add.i11 = add i32 %15, ptrtoint (ptr @runqueues to i32)
  %16 = inttoptr i32 %add.i11 to ptr
  %curr.i = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 20
  %17 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %curr.i, align 8
  %cmp.i.not = icmp eq ptr %18, %p
  br i1 %cmp.i.not, label %if.then, label %do.body4

if.then:                                          ; preds = %land.lhs.true
  tail call void @smp_send_reschedule(i32 noundef %7) #33
  br label %do.body4

do.body4:                                         ; preds = %if.then, %land.lhs.true, %entry
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1251
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i9 = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i.i9 to ptr
  %preempt_count.i.i10 = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i.i10 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i.i10, align 4
  %sub.i = add i32 %22, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i10, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_set_stop_task(i32 noundef %cpu, ptr noundef %stop) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i.i = alloca %struct.sched_attr, align 8
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %stop2 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 22
  %3 = ptrtoint ptr %stop2 to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %stop2, align 16
  %tobool.not = icmp eq ptr %stop, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i.i) #33
  %5 = call ptr @memset(ptr %attr.i.i, i32 0, i32 56)
  %sched_policy.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 1
  %6 = ptrtoint ptr %sched_policy.i.i to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 1, ptr %sched_policy.i.i, align 4
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 3
  %static_prio.i.i = getelementptr inbounds %struct.task_struct, ptr %stop, i32 0, i32 14
  %7 = ptrtoint ptr %static_prio.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %static_prio.i.i, align 4
  %sub.i.i = add i32 %8, -120
  %9 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %sub.i.i, ptr %sched_nice.i.i, align 8
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 4
  %10 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 99, ptr %sched_priority.i.i, align 4
  %call.i.i = call fastcc i32 @__sched_setscheduler(ptr noundef nonnull %stop, ptr noundef nonnull %attr.i.i, i1 noundef zeroext false, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i.i) #33
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %stop, i32 0, i32 21
  %11 = ptrtoint ptr %sched_class to i32
  call void @__asan_store4_noabort(i32 %11)
  store ptr @stop_sched_class, ptr %sched_class, align 32
  %dep_map = getelementptr inbounds %struct.task_struct, ptr %stop, i32 0, i32 128, i32 4
  %wait_type_inner = getelementptr inbounds %struct.task_struct, ptr %stop, i32 0, i32 128, i32 4, i32 4
  %12 = ptrtoint ptr %wait_type_inner to i32
  call void @__asan_load1_noabort(i32 %12)
  %13 = load i8, ptr %wait_type_inner, align 1
  call void @lockdep_init_map_type(ptr noundef %dep_map, ptr noundef nonnull @.str.10, ptr noundef nonnull @sched_set_stop_task.stop_pi_lock, i32 noundef 0, i8 noundef zeroext %13, i8 noundef zeroext 0, i8 noundef zeroext 0) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %14 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx, align 4
  %add15 = add i32 %15, ptrtoint (ptr @runqueues to i32)
  %16 = inttoptr i32 %add15 to ptr
  %stop16 = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 22
  %17 = ptrtoint ptr %stop16 to i32
  call void @__asan_store4_noabort(i32 %17)
  store ptr %stop, ptr %stop16, align 16
  %tobool17.not = icmp eq ptr %4, null
  br i1 %tobool17.not, label %if.end20, label %if.then18

if.then18:                                        ; preds = %if.end
  %sched_class19 = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 21
  %18 = ptrtoint ptr %sched_class19 to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr @rt_sched_class, ptr %sched_class19, align 32
  br label %if.end20

if.end20:                                         ; preds = %if.then18, %if.end
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_setscheduler_nocheck(ptr noundef %p, i32 noundef %policy, ptr nocapture noundef readonly %param) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i) #33
  %0 = call ptr @memset(ptr %attr.i, i32 0, i32 56)
  %sched_policy.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 1
  %1 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 %policy, ptr %sched_policy.i, align 4
  %sched_nice.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 3
  %static_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %2 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %static_prio.i, align 4
  %sub.i = add i32 %3, -120
  %4 = ptrtoint ptr %sched_nice.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %sub.i, ptr %sched_nice.i, align 8
  %sched_priority.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 4
  %5 = ptrtoint ptr %param to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %param, align 4
  %7 = ptrtoint ptr %sched_priority.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 %6, ptr %sched_priority.i, align 4
  %cmp.not.i = icmp eq i32 %policy, -1
  %and.i = and i32 %policy, 1073741824
  %tobool.not.i = icmp eq i32 %and.i, 0
  %or.cond.i = or i1 %cmp.not.i, %tobool.not.i
  br i1 %or.cond.i, label %_sched_setscheduler.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %sched_flags.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 2
  %8 = ptrtoint ptr %sched_flags.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %sched_flags.i, align 8
  %or.i = or i64 %9, 1
  store i64 %or.i, ptr %sched_flags.i, align 8
  %and2.i = and i32 %policy, -1073741825
  %10 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %and2.i, ptr %sched_policy.i, align 4
  br label %_sched_setscheduler.exit

_sched_setscheduler.exit:                         ; preds = %if.then.i, %entry
  %call.i = call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef nonnull %attr.i, i1 noundef zeroext false, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i) #33
  ret i32 %call.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_ttwu_pending(ptr noundef %arg) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %7 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %8 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %9 = ptrtoint ptr %8 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 -1, ptr %8, align 4, !annotation !1193
  %10 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %11 = ptrtoint ptr %10 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 -1, ptr %10, align 4, !annotation !1193
  %tobool.not = icmp eq ptr %arg, null
  br i1 %tobool.not, label %cleanup, label %do.body6

do.body6:                                         ; preds = %entry
  %ttwu_pending = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 8
  %12 = ptrtoint ptr %ttwu_pending to i32
  call void @__asan_store4_noabort(i32 %12)
  store volatile i32 0, ptr %ttwu_pending, align 8
  call fastcc void @rq_lock_irqsave(ptr noundef %6, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %6)
  %p.0183 = getelementptr i8, ptr %arg, i32 -24
  %cmp.not184 = icmp eq ptr %p.0183, inttoptr (i32 -24 to ptr)
  br i1 %cmp.not184, label %for.end151, label %land.rhs.lr.ph

land.rhs.lr.ph:                                   ; preds = %do.body6
  %cpu.i180 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 46
  br label %land.rhs

land.rhs:                                         ; preds = %if.end149, %land.rhs.lr.ph
  %p.0186 = phi ptr [ %p.0183, %land.rhs.lr.ph ], [ %p.0, %if.end149 ]
  %arg.pn185 = phi ptr [ %arg, %land.rhs.lr.ph ], [ %14, %if.end149 ]
  %13 = ptrtoint ptr %arg.pn185 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %arg.pn185, align 8
  %on_cpu = getelementptr i8, ptr %arg.pn185, i32 -4
  %15 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %on_cpu, align 4
  %tobool17.not = icmp eq i32 %16, 0
  br i1 %tobool17.not, label %if.end89, label %land.rhs20

land.rhs20:                                       ; preds = %land.rhs
  %.b177 = load i1, ptr @sched_ttwu_pending.__already_done, align 1
  br i1 %.b177, label %if.then62, label %if.then27, !prof !1191

if.then27:                                        ; preds = %land.rhs20
  store i1 true, ptr @sched_ttwu_pending.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3683, i32 noundef 9, ptr noundef null) #33
  br label %if.then62

if.then62:                                        ; preds = %if.then27, %land.rhs20
  %17 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %on_cpu, align 4
  %tobool69.not182 = icmp eq i32 %18, 0
  br i1 %tobool69.not182, label %for.end, label %do.end76

do.end76:                                         ; preds = %do.end76, %if.then62
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1252
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1253
  %19 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %on_cpu, align 4
  %tobool69.not = icmp eq i32 %20, 0
  br i1 %tobool69.not, label %for.end, label %do.end76

for.end:                                          ; preds = %do.end76, %if.then62
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1254
  br label %if.end89

if.end89:                                         ; preds = %for.end, %land.rhs
  %stack.i = getelementptr i8, ptr %arg.pn185, i32 -20
  %21 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %22, i32 0, i32 3
  %23 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %cpu.i, align 4
  %25 = ptrtoint ptr %cpu.i180 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %cpu.i180, align 4
  %cmp93.not = icmp eq i32 %24, %26
  br i1 %cmp93.not, label %if.end149, label %land.rhs100

land.rhs100:                                      ; preds = %if.end89
  %.b175176 = load i1, ptr @sched_ttwu_pending.__already_done.11, align 1
  br i1 %.b175176, label %if.then147, label %if.then111, !prof !1191

if.then111:                                       ; preds = %land.rhs100
  store i1 true, ptr @sched_ttwu_pending.__already_done.11, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3686, i32 noundef 9, ptr noundef null) #33
  br label %if.then147

if.then147:                                       ; preds = %if.then111, %land.rhs100
  %27 = ptrtoint ptr %cpu.i180 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu.i180, align 4
  tail call void @set_task_cpu(ptr noundef %p.0186, i32 noundef %28)
  br label %if.end149

if.end149:                                        ; preds = %if.then147, %if.end89
  %sched_remote_wakeup = getelementptr i8, ptr %arg.pn185, i32 1232
  %29 = ptrtoint ptr %sched_remote_wakeup to i32
  call void @__asan_load2_noabort(i32 %29)
  %bf.load = load i16, ptr %sched_remote_wakeup, align 8
  %30 = lshr i16 %bf.load, 10
  %31 = and i16 %30, 32
  %32 = zext i16 %31 to i32
  call fastcc void @ttwu_do_activate(ptr noundef %6, ptr noundef %p.0186, i32 noundef %32, ptr noundef nonnull %rf)
  %p.0 = getelementptr i8, ptr %14, i32 -24
  %cmp.not = icmp eq ptr %p.0, inttoptr (i32 -24 to ptr)
  br i1 %cmp.not, label %for.end151, label %land.rhs

for.end151:                                       ; preds = %if.end149, %do.body6
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 25
  %33 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %34, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.end151
  %35 = ptrtoint ptr %10 to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 4, ptr %10, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.end151
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %36 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %37, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %38 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %39, %if.then.i.i.i ], [ %6, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %40 = ptrtoint ptr %8 to i32
  call void @__asan_load4_noabort(i32 %40)
  %.unpack.i.i = load i32, ptr %8, align 4
  %41 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %41) #33
  %42 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_ttwu_pending, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %44 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %45, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %46 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %47, %if.then.i.i.i.i ], [ %6, %land.rhs.i.i.i.i.i ], [ %6, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i = and i32 %43, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %48 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %48, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %43) #33, !srcloc !1218
  br label %cleanup

cleanup:                                          ; preds = %rq_unlock_irqrestore.exit, %entry
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rq_lock_irqsave(ptr noundef %rq, ptr nocapture noundef writeonly %rf) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %and.i.i = and i32 %0, 128
  %tobool.not.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool.not.i, label %if.then.i, label %do.end11.i

if.then.i:                                        ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.end11.i

do.end11.i:                                       ; preds = %if.then.i, %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %4, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@rq_lock_irqsave, %for.cond.i.i.i)) #33
          to label %if.then.i.i.i [label %for.cond.i.i.i], !srcloc !1202

if.then.i.i.i:                                    ; preds = %do.end11.i
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %_raw_spin_rq_lock_irqsave.exit

for.cond.i.i.i:                                   ; preds = %if.end11.i.i.i, %do.end11.i
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %5 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %6, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %for.cond.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %7 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %for.cond.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %8, %if.then.i.i.i.i ], [ %rq, %for.cond.i.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i.i, i32 noundef 0) #33
  %9 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i23.i.i.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i23.i.i.i, label %__rq_lockp.exit27.i.i.i, label %if.then.i25.i.i.i

if.then.i25.i.i.i:                                ; preds = %__rq_lockp.exit.i.i.i
  %core.i24.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i24.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i24.i.i.i, align 8
  br label %__rq_lockp.exit27.i.i.i

__rq_lockp.exit27.i.i.i:                          ; preds = %if.then.i25.i.i.i, %__rq_lockp.exit.i.i.i
  %retval.0.i26.i.i.i = phi ptr [ %12, %if.then.i25.i.i.i ], [ %rq, %__rq_lockp.exit.i.i.i ]
  %cmp.i.i.i = icmp eq ptr %retval.0.i.i.i.i, %retval.0.i26.i.i.i
  br i1 %cmp.i.i.i, label %do.body8.i.i.i, label %if.end11.i.i.i, !prof !1191

do.body8.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %_raw_spin_rq_lock_irqsave.exit

if.end11.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  br label %for.cond.i.i.i

_raw_spin_rq_lock_irqsave.exit:                   ; preds = %do.body8.i.i.i, %if.then.i.i.i
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i.i = and i32 %13, -16384
  %14 = inttoptr i32 %and.i.i.i19.i.i.i to ptr
  %preempt_count.i.i20.i.i.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 1
  %15 = ptrtoint ptr %preempt_count.i.i20.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %preempt_count.i.i20.i.i.i, align 4
  %sub.i21.i.i.i = add i32 %16, -1
  store volatile i32 %sub.i21.i.i.i, ptr %preempt_count.i.i20.i.i.i, align 4
  %17 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 %0, ptr %rf, align 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %18 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %19, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %_raw_spin_rq_lock_irqsave.exit
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %20 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %_raw_spin_rq_lock_irqsave.exit
  %retval.0.i.i = phi ptr [ %21, %if.then.i.i ], [ %rq, %_raw_spin_rq_lock_irqsave.exit ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call1.i = tail call i32 @lock_pin_lock(ptr noundef %dep_map.i) #33
  %22 = ptrtoint ptr %cookie.i to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %call1.i, ptr %cookie.i, align 4
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %23 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %clock_update_flags.i, align 4
  %and.i = and i32 %24, 3
  store i32 %and.i, ptr %clock_update_flags.i, align 4
  %clock_update_flags2.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %25 = ptrtoint ptr %clock_update_flags2.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 0, ptr %clock_update_flags2.i, align 4
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %26 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %balance_callback.i, align 8
  %tobool.not.i3 = icmp ne ptr %27, null
  %cmp.i = icmp ne ptr %27, @balance_push_callback
  %spec.select.i = and i1 %tobool.not.i3, %cmp.i
  br i1 %spec.select.i, label %land.rhs6.i, label %rq_pin_lock.exit

land.rhs6.i:                                      ; preds = %__rq_lockp.exit.i
  %.b48.i = load i1, ptr @rq_pin_lock.__already_done, align 1
  br i1 %.b48.i, label %rq_pin_lock.exit, label %if.then.i4, !prof !1191

if.then.i4:                                       ; preds = %land.rhs6.i
  store i1 true, ptr @rq_pin_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1545, i32 noundef 9, ptr noundef nonnull @.str.178) #33
  br label %rq_pin_lock.exit

rq_pin_lock.exit:                                 ; preds = %if.then.i4, %land.rhs6.i, %__rq_lockp.exit.i
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @ttwu_do_activate(ptr noundef %rq, ptr noundef %p, i32 noundef %wake_flags, ptr nocapture noundef %rf) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i22 = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i22, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %sched_contributes_to_load = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %5 = ptrtoint ptr %sched_contributes_to_load to i32
  call void @__asan_load1_noabort(i32 %5)
  %bf.load = load i8, ptr %sched_contributes_to_load, align 4
  %6 = and i8 %bf.load, 64
  %tobool.not = icmp eq i8 %6, 0
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %lockdep_assert_rq_held.exit
  %nr_uninterruptible = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 19
  %7 = ptrtoint ptr %nr_uninterruptible to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %nr_uninterruptible, align 4
  %dec = add i32 %8, -1
  store i32 %dec, ptr %nr_uninterruptible, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %lockdep_assert_rq_held.exit
  %and = and i32 %wake_flags, 32
  %tobool1.not = icmp eq i32 %and, 0
  br i1 %tobool1.not, label %if.else, label %if.end11

if.else:                                          ; preds = %if.end
  %in_iowait = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 65
  %9 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %9)
  %bf.load3 = load i16, ptr %in_iowait, align 8
  %10 = and i16 %bf.load3, 8192
  %tobool7.not = icmp eq i16 %10, 0
  br i1 %tobool7.not, label %if.end11, label %if.then8

if.then8:                                         ; preds = %if.else
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @delayacct_key, ptr blockaddress(@ttwu_do_activate, %if.end.i)) #33
          to label %delayacct_blkio_end.exit [label %if.end.i], !srcloc !1202

if.end.i:                                         ; preds = %if.then8
  %delays.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 181
  %11 = ptrtoint ptr %delays.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %delays.i, align 8
  %tobool3.not.i = icmp eq ptr %12, null
  br i1 %tobool3.not.i, label %delayacct_blkio_end.exit, label %if.then4.i

if.then4.i:                                       ; preds = %if.end.i
  tail call void @__delayacct_blkio_end(ptr noundef %p) #33
  br label %delayacct_blkio_end.exit

delayacct_blkio_end.exit:                         ; preds = %if.then4.i, %if.end.i, %if.then8
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %13 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 3
  %15 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %16
  %17 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %arrayidx, align 4
  %add = add i32 %18, ptrtoint (ptr @runqueues to i32)
  %19 = inttoptr i32 %add to ptr
  %nr_iowait = getelementptr inbounds %struct.rq, ptr %19, i32 0, i32 31
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %nr_iowait, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %nr_iowait, i32 1, i32 3, i32 1) #33
  %20 = tail call { i32, i32 } asm sideeffect "@ atomic_sub\0A1:\09ldrex\09$0, [$3]\0A\09sub\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %nr_iowait, ptr %nr_iowait, i32 1, ptr elementtype(i32) %nr_iowait) #33, !srcloc !1255
  br label %if.end11

if.end11:                                         ; preds = %delayacct_blkio_end.exit, %if.else, %if.end
  %en_flags.0 = phi i32 [ 9, %delayacct_blkio_end.exit ], [ 9, %if.else ], [ 73, %if.end ]
  tail call fastcc void @enqueue_task(ptr noundef %rq, ptr noundef %p, i32 noundef %en_flags.0) #33
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %21 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %on_rq.i, align 4
  tail call fastcc void @ttwu_do_wakeup(ptr noundef %rq, ptr noundef %p, i32 noundef %wake_flags, ptr noundef %rf)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @send_call_function_single_ipi(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @arch_send_call_function_single_ipi(i32 noundef %cpu) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @arch_send_call_function_single_ipi(i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_up_if_idle(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %3 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %4 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %5 = ptrtoint ptr %4 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %4, align 4, !annotation !1193
  %6 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %7 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %6, align 4, !annotation !1193
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %11, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  %curr = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %12 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile ptr, ptr %curr, align 8
  %call = tail call i32 @rcu_read_lock_held() #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %land.lhs.true, label %do.end12

land.lhs.true:                                    ; preds = %rcu_read_lock.exit
  %call7 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool8.not = icmp eq i32 %call7, 0
  br i1 %tobool8.not, label %do.end12, label %land.lhs.true9

land.lhs.true9:                                   ; preds = %land.lhs.true
  %.b25 = load i1, ptr @wake_up_if_idle.__warned, align 1
  br i1 %.b25, label %do.end12, label %if.then

if.then:                                          ; preds = %land.lhs.true9
  store i1 true, ptr @wake_up_if_idle.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 3728, ptr noundef nonnull @.str.3) #33
  br label %do.end12

do.end12:                                         ; preds = %if.then, %land.lhs.true9, %land.lhs.true, %rcu_read_lock.exit
  %flags.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 3
  %14 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %15, 2
  %tobool.i.not = icmp eq i32 %and.i, 0
  br i1 %tobool.i.not, label %out, label %if.end16

if.end16:                                         ; preds = %do.end12
  call fastcc void @rq_lock_irqsave(ptr noundef %2, ptr noundef nonnull %rf)
  %16 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %curr, align 8
  %flags.i26 = getelementptr inbounds %struct.task_struct, ptr %17, i32 0, i32 3
  %18 = ptrtoint ptr %flags.i26 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %flags.i26, align 4
  %and.i27 = and i32 %19, 2
  %tobool.i28.not = icmp eq i32 %and.i27, 0
  br i1 %tobool.i28.not, label %if.end20, label %if.then19

if.then19:                                        ; preds = %if.end16
  tail call void @resched_curr(ptr noundef %2)
  br label %if.end20

if.end20:                                         ; preds = %if.then19, %if.end16
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 25
  %20 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %21, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end20
  %22 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 4, ptr %6, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end20
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %23 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %24, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %25 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %26, %if.then.i.i.i ], [ %2, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %27 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %27)
  %.unpack.i.i = load i32, ptr %4, align 4
  %28 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %28) #33
  %29 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@wake_up_if_idle, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %31 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %32, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %33 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %34, %if.then.i.i.i.i ], [ %2, %land.rhs.i.i.i.i.i ], [ %2, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i = and i32 %30, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %35 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %35, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %30) #33, !srcloc !1218
  br label %out

out:                                              ; preds = %rq_unlock_irqrestore.exit, %do.end12
  %call.i29 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i29, label %rcu_read_unlock.exit, label %land.lhs.true.i32

land.lhs.true.i32:                                ; preds = %out
  %call1.i30 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i31 = icmp eq i32 %call1.i30, 0
  br i1 %tobool.not.i31, label %rcu_read_unlock.exit, label %land.lhs.true2.i34

land.lhs.true2.i34:                               ; preds = %land.lhs.true.i32
  %.b4.i33 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i33, label %rcu_read_unlock.exit, label %if.then.i35

if.then.i35:                                      ; preds = %land.lhs.true2.i34
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i35, %land.lhs.true2.i34, %land.lhs.true.i32, %out
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %36 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i36 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i.i.i36 to ptr
  %preempt_count.i.i.i.i37 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i.i.i37 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i.i.i37, align 4
  %sub.i.i.i = add i32 %39, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i37, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local zeroext i1 @cpus_share_cache(i32 noundef %this_cpu, i32 noundef %that_cpu) local_unnamed_addr #4 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cmp = icmp eq i32 %this_cpu, %that_cpu
  br i1 %cmp, label %return, label %do.body

do.body:                                          ; preds = %entry
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %this_cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @sd_llc_id to i32)
  %2 = inttoptr i32 %add to ptr
  %3 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %2, align 4
  %arrayidx8 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %that_cpu
  %5 = ptrtoint ptr %arrayidx8 to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %arrayidx8, align 4
  %add9 = add i32 %6, ptrtoint (ptr @sd_llc_id to i32)
  %7 = inttoptr i32 %add9 to ptr
  %8 = ptrtoint ptr %7 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %7, align 4
  %cmp10 = icmp eq i32 %4, %9
  br label %return

return:                                           ; preds = %do.body, %entry
  %retval.0 = phi i1 [ %cmp10, %do.body ], [ true, %entry ]
  ret i1 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @task_call_func(ptr noundef %p, ptr nocapture noundef readonly %func, ptr noundef %arg) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %1 = ptrtoint ptr %0 to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %0, align 4, !annotation !1193
  %2 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %3 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %2, align 4, !annotation !1193
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %call = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %4 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %call, ptr %rf, align 4
  %5 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %p, align 128
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1256
  switch i32 %6, label %lor.lhs.false15 [
    i32 0, label %if.end
    i32 512, label %if.end
  ]

lor.lhs.false15:                                  ; preds = %entry
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %7 = ptrtoint ptr %on_rq to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %on_rq, align 4
  %tobool.not = icmp eq i32 %8, 0
  br i1 %tobool.not, label %if.end.thread, label %if.end

if.end.thread:                                    ; preds = %lor.lhs.false15
  %call1739 = tail call i32 %func(ptr noundef %p, ptr noundef %arg) #33
  br label %do.body21

if.end:                                           ; preds = %lor.lhs.false15, %entry, %entry
  %call16 = call ptr @__task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  %call17 = tail call i32 %func(ptr noundef %p, ptr noundef %arg) #33
  %tobool18.not = icmp eq ptr %call16, null
  br i1 %tobool18.not, label %do.body21, label %if.then19

if.then19:                                        ; preds = %if.end
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call16, i32 0, i32 81
  %9 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.then19
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call16, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.then19
  %retval.0.i.i.i = phi ptr [ %12, %if.then.i.i.i ], [ %call16, %if.then19 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %13 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %13)
  %.unpack.i.i = load i32, ptr %0, align 4
  %14 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %14) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@task_call_func, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %15 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %16, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %call16, i32 0, i32 79
  %17 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %18, %if.then.i.i3.i ], [ %call16, %land.rhs.i.i.i.i ], [ %call16, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  br label %do.body21

do.body21:                                        ; preds = %rq_unlock.exit, %if.end, %if.end.thread
  %call1742 = phi i32 [ %call1739, %if.end.thread ], [ %call17, %if.end ], [ %call17, %rq_unlock.exit ]
  %19 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %20) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %call1742
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @try_to_wake_up(ptr noundef %p, i32 noundef %state, i32 noundef %wake_flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf.i = alloca %struct.rq_flags, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1257
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i168 = and i32 %4, -16384
  %5 = inttoptr i32 %and.i168 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task, align 8
  %cmp = icmp eq ptr %7, %p
  br i1 %cmp, label %if.then, label %do.body13

if.then:                                          ; preds = %entry
  %8 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %p, align 128
  %and.i = and i32 %9, %state
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %do.body124, label %out.thread189

out.thread189:                                    ; preds = %if.then
  tail call fastcc void @trace_sched_waking(ptr noundef %p)
  %10 = ptrtoint ptr %p to i32
  call void @__asan_store4_noabort(i32 %10)
  store volatile i32 0, ptr %p, align 128
  tail call fastcc void @trace_sched_wakeup(ptr noundef %p)
  br label %if.then121

do.body13:                                        ; preds = %entry
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %call15 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %11 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %p, align 128
  %and.i162 = and i32 %12, %state
  %tobool.not.i163 = icmp eq i32 %and.i162, 0
  br i1 %tobool.not.i163, label %out, label %if.end23

if.end23:                                         ; preds = %do.body13
  tail call fastcc void @trace_sched_waking(ptr noundef %p)
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1258
  %on_rq = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %13 = ptrtoint ptr %on_rq to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %on_rq, align 4
  %tobool.not = icmp eq i32 %14, 0
  br i1 %tobool.not, label %do.end41, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.end23
  %call34 = tail call fastcc i32 @ttwu_runnable(ptr noundef %p, i32 noundef %wake_flags)
  %tobool35.not = icmp eq i32 %call34, 0
  br i1 %tobool35.not, label %do.end41, label %out.thread195

do.end41:                                         ; preds = %land.lhs.true, %if.end23
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1259
  %15 = ptrtoint ptr %p to i32
  call void @__asan_store4_noabort(i32 %15)
  store volatile i32 512, ptr %p, align 128
  %on_cpu = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %16 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %on_cpu, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1260
  %tobool62.not = icmp eq i32 %17, 0
  br i1 %tobool62.not, label %if.end68, label %land.lhs.true63

land.lhs.true63:                                  ; preds = %do.end41
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %18 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %19, i32 0, i32 3
  %20 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load volatile i32, ptr %cpu.i, align 4
  %or = or i32 %wake_flags, 64
  %call65 = tail call fastcc zeroext i1 @ttwu_queue_wakelist(ptr noundef %p, i32 noundef %21, i32 noundef %or)
  br i1 %call65, label %out.thread195, label %if.end68

if.end68:                                         ; preds = %land.lhs.true63, %do.end41
  %22 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %on_cpu, align 4
  %tobool74.not199 = icmp eq i32 %23, 0
  br i1 %tobool74.not199, label %for.end, label %do.end81

do.end81:                                         ; preds = %do.end81, %if.end68
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1261
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1262
  %24 = ptrtoint ptr %on_cpu to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %on_cpu, align 4
  %tobool74.not = icmp eq i32 %25, 0
  br i1 %tobool74.not, label %for.end, label %do.end81

for.end:                                          ; preds = %do.end81, %if.end68
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1263
  %wake_cpu = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 11
  %26 = ptrtoint ptr %wake_cpu to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %wake_cpu, align 16
  %or94 = or i32 %wake_flags, 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %28 = load i32, ptr @debug_locks, align 4
  %tobool.not.i169 = icmp eq i32 %28, 0
  br i1 %tobool.not.i169, label %if.end.i, label %land.rhs.i

land.rhs.i:                                       ; preds = %for.end
  %dep_map.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i.i170 = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i170, 0
  br i1 %cmp.not.i, label %do.end.i, label %if.end.i, !prof !1192

do.end.i:                                         ; preds = %land.rhs.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3430, i32 noundef 9, ptr noundef null) #33
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i, %for.end
  %nr_cpus_allowed.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 32
  %29 = ptrtoint ptr %nr_cpus_allowed.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %nr_cpus_allowed.i, align 8
  %cmp24.i = icmp sgt i32 %30, 1
  br i1 %cmp24.i, label %land.lhs.true.i, label %if.else.i

land.lhs.true.i:                                  ; preds = %if.end.i
  %migration_disabled.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %31 = ptrtoint ptr %migration_disabled.i.i to i32
  call void @__asan_load2_noabort(i32 %31)
  %32 = load i16, ptr %migration_disabled.i.i, align 4
  %tobool.i.not.i = icmp eq i16 %32, 0
  br i1 %tobool.i.not.i, label %if.then26.i, label %if.else.i

if.then26.i:                                      ; preds = %land.lhs.true.i
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %33 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %sched_class.i, align 32
  %select_task_rq.i = getelementptr inbounds %struct.sched_class, ptr %34, i32 0, i32 10
  %35 = ptrtoint ptr %select_task_rq.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %select_task_rq.i, align 4
  %call27.i = tail call i32 %36(ptr noundef %p, i32 noundef %27, i32 noundef %or94) #33
  br label %if.end29.i

if.else.i:                                        ; preds = %land.lhs.true.i, %if.end.i
  %cpus_ptr.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  %37 = ptrtoint ptr %cpus_ptr.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %cpus_ptr.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %39 = load i32, ptr @nr_cpu_ids, align 4
  %call.i54.i = tail call i32 @_find_first_bit_be(ptr noundef %38, i32 noundef %39) #33
  br label %if.end29.i

if.end29.i:                                       ; preds = %if.else.i, %if.then26.i
  %cpu.addr.0.i = phi i32 [ %call.i54.i, %if.else.i ], [ %call27.i, %if.then26.i ]
  %call30.i = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %p, i32 noundef %cpu.addr.0.i) #33
  br i1 %call30.i, label %select_task_rq.exit, label %if.then39.i, !prof !1191

if.then39.i:                                      ; preds = %if.end29.i
  %stack.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %40 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %stack.i.i, align 4
  %cpu.i.i = getelementptr inbounds %struct.thread_info, ptr %41, i32 0, i32 3
  %42 = ptrtoint ptr %cpu.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %cpu.i.i, align 4
  %call41.i = tail call fastcc i32 @select_fallback_rq(i32 noundef %43, ptr noundef %p) #33
  br label %select_task_rq.exit

select_task_rq.exit:                              ; preds = %if.then39.i, %if.end29.i
  %cpu.addr.1.i = phi i32 [ %call41.i, %if.then39.i ], [ %cpu.addr.0.i, %if.end29.i ]
  %stack.i171 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %44 = ptrtoint ptr %stack.i171 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %stack.i171, align 4
  %cpu.i172 = getelementptr inbounds %struct.thread_info, ptr %45, i32 0, i32 3
  %46 = ptrtoint ptr %cpu.i172 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load volatile i32, ptr %cpu.i172, align 4
  %cmp97.not = icmp eq i32 %47, %cpu.addr.1.i
  br i1 %cmp97.not, label %if.end110, label %if.then99

if.then99:                                        ; preds = %select_task_rq.exit
  %in_iowait = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 65
  %48 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %48)
  %bf.load = load i16, ptr %in_iowait, align 8
  %49 = and i16 %bf.load, 8192
  %tobool100.not = icmp eq i16 %49, 0
  br i1 %tobool100.not, label %if.end108, label %if.then101

if.then101:                                       ; preds = %if.then99
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @delayacct_key, ptr blockaddress(@try_to_wake_up, %if.end.i173)) #33
          to label %delayacct_blkio_end.exit [label %if.end.i173], !srcloc !1202

if.end.i173:                                      ; preds = %if.then101
  %delays.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 181
  %50 = ptrtoint ptr %delays.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %delays.i, align 8
  %tobool3.not.i = icmp eq ptr %51, null
  br i1 %tobool3.not.i, label %delayacct_blkio_end.exit, label %if.then4.i

if.then4.i:                                       ; preds = %if.end.i173
  tail call void @__delayacct_blkio_end(ptr noundef %p) #33
  br label %delayacct_blkio_end.exit

delayacct_blkio_end.exit:                         ; preds = %if.then4.i, %if.end.i173, %if.then101
  %52 = ptrtoint ptr %stack.i171 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %stack.i171, align 4
  %cpu.i175 = getelementptr inbounds %struct.thread_info, ptr %53, i32 0, i32 3
  %54 = ptrtoint ptr %cpu.i175 to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load volatile i32, ptr %cpu.i175, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %55
  %56 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %arrayidx, align 4
  %add = add i32 %57, ptrtoint (ptr @runqueues to i32)
  %58 = inttoptr i32 %add to ptr
  %nr_iowait = getelementptr inbounds %struct.rq, ptr %58, i32 0, i32 31
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %nr_iowait, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %nr_iowait, i32 1, i32 3, i32 1) #33
  %59 = tail call { i32, i32 } asm sideeffect "@ atomic_sub\0A1:\09ldrex\09$0, [$3]\0A\09sub\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %nr_iowait, ptr %nr_iowait, i32 1, ptr elementtype(i32) %nr_iowait) #33, !srcloc !1255
  br label %if.end108

if.end108:                                        ; preds = %delayacct_blkio_end.exit, %if.then99
  %or109 = or i32 %wake_flags, 32
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @psi_disabled, i32 1), ptr blockaddress(@try_to_wake_up, %if.end.i176)) #33
          to label %psi_ttwu_dequeue.exit [label %if.end.i176], !srcloc !1232

if.end.i176:                                      ; preds = %if.end108
  %60 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %60)
  %bf.load.i = load i16, ptr %in_iowait, align 8
  %61 = and i16 %bf.load.i, 8320
  %.not.i = icmp eq i16 %61, 0
  br i1 %.not.i, label %psi_ttwu_dequeue.exit, label %if.then16.i, !prof !1191

if.then16.i:                                      ; preds = %if.end.i176
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf.i) #33
  %62 = ptrtoint ptr %rf.i to i32
  call void @__asan_store4_noabort(i32 %62)
  store i32 -1, ptr %rf.i, align 4, !annotation !1193
  %63 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 1
  %64 = ptrtoint ptr %63 to i32
  call void @__asan_store4_noabort(i32 %64)
  store i32 -1, ptr %63, align 4, !annotation !1193
  %65 = getelementptr inbounds %struct.rq_flags, ptr %rf.i, i32 0, i32 2
  %66 = ptrtoint ptr %65 to i32
  call void @__asan_store4_noabort(i32 %66)
  store i32 -1, ptr %65, align 4, !annotation !1193
  %67 = lshr i16 %bf.load.i, 13
  %.lobit.i = and i16 %67, 1
  %68 = lshr i16 %bf.load.i, 6
  %69 = and i16 %68, 2
  %70 = or i16 %69, %.lobit.i
  %71 = zext i16 %70 to i32
  %call34.i = call ptr @__task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf.i) #33
  tail call void @psi_task_change(ptr noundef %p, i32 noundef %71, i32 noundef 0) #33
  %sched_psi_wake_requeue.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %72 = ptrtoint ptr %sched_psi_wake_requeue.i to i32
  call void @__asan_load1_noabort(i32 %72)
  %bf.load35.i = load i8, ptr %sched_psi_wake_requeue.i, align 4
  %bf.set.i = or i8 %bf.load35.i, 16
  store i8 %bf.set.i, ptr %sched_psi_wake_requeue.i, align 4
  call fastcc void @__task_rq_unlock(ptr noundef %call34.i, ptr noundef nonnull %rf.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf.i) #33
  br label %psi_ttwu_dequeue.exit

psi_ttwu_dequeue.exit:                            ; preds = %if.then16.i, %if.end.i176, %if.end108
  tail call void @set_task_cpu(ptr noundef %p, i32 noundef %cpu.addr.1.i)
  br label %if.end110

if.end110:                                        ; preds = %psi_ttwu_dequeue.exit, %select_task_rq.exit
  %wake_flags.addr.0 = phi i32 [ %or109, %psi_ttwu_dequeue.exit ], [ %wake_flags, %select_task_rq.exit ]
  tail call fastcc void @ttwu_queue(ptr noundef %p, i32 noundef %cpu.addr.1.i, i32 noundef %wake_flags.addr.0)
  br label %out.thread195

out.thread195:                                    ; preds = %if.end110, %land.lhs.true63, %land.lhs.true
  %wake_flags.addr.1.ph = phi i32 [ %wake_flags.addr.0, %if.end110 ], [ %wake_flags, %land.lhs.true63 ], [ %wake_flags, %land.lhs.true ]
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call15) #33
  br label %if.then121

out:                                              ; preds = %do.body13
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call15) #33
  br label %do.body124

if.then121:                                       ; preds = %out.thread195, %out.thread189
  %wake_flags.addr.2194 = phi i32 [ %wake_flags, %out.thread189 ], [ %wake_flags.addr.1.ph, %out.thread195 ]
  %stack.i177 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %73 = ptrtoint ptr %stack.i177 to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %stack.i177, align 4
  %cpu.i178 = getelementptr inbounds %struct.thread_info, ptr %74, i32 0, i32 3
  %75 = ptrtoint ptr %cpu.i178 to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load volatile i32, ptr %cpu.i178, align 4
  tail call fastcc void @ttwu_stat(ptr noundef %p, i32 noundef %76, i32 noundef %wake_flags.addr.2194)
  br label %do.body124

do.body124:                                       ; preds = %if.then121, %out, %if.then
  %success.2188 = phi i32 [ 0, %out ], [ 1, %if.then121 ], [ 0, %if.then ]
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1264
  %77 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i166 = and i32 %77, -16384
  %78 = inttoptr i32 %and.i.i.i166 to ptr
  %preempt_count.i.i167 = getelementptr inbounds %struct.thread_info, ptr %78, i32 0, i32 1
  %79 = ptrtoint ptr %preempt_count.i.i167 to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load volatile i32, ptr %preempt_count.i.i167, align 4
  %sub.i = add i32 %80, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i167, align 4
  ret i32 %success.2188
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @wake_up_state(ptr noundef %p, i32 noundef %state) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @try_to_wake_up(ptr noundef %p, i32 noundef %state, i32 noundef 0)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @force_schedstat_enabled() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@force_schedstat_enabled, %if.end)) #33
          to label %do.end [label %if.end], !srcloc !1202

do.end:                                           ; preds = %entry
  %call4 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.12) #39
  tail call void @static_key_enable(ptr noundef nonnull @sched_schedstats) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %entry
  ret void
}

; Function Attrs: cold null_pointer_is_valid
declare dso_local i32 @_printk(ptr noundef, ...) local_unnamed_addr #10

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define internal i32 @setup_schedstats(ptr noundef readonly %str) #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %tobool.not = icmp eq ptr %str, null
  br i1 %tobool.not, label %do.end, label %if.end

if.end:                                           ; preds = %entry
  %call = tail call i32 @strcmp(ptr noundef nonnull %str, ptr noundef nonnull dereferenceable(7) @.str.193) #36
  %tobool1.not = icmp eq i32 %call, 0
  br i1 %tobool1.not, label %if.then2, label %if.else

if.then2:                                         ; preds = %if.end
  tail call void @static_key_enable(ptr noundef nonnull @sched_schedstats) #33
  br label %if.end11

if.else:                                          ; preds = %if.end
  %call3 = tail call i32 @strcmp(ptr noundef nonnull %str, ptr noundef nonnull dereferenceable(8) @.str.194) #36
  %tobool4.not = icmp eq i32 %call3, 0
  br i1 %tobool4.not, label %if.then5, label %do.end

if.then5:                                         ; preds = %if.else
  tail call void @static_key_disable(ptr noundef nonnull @sched_schedstats) #33
  br label %if.end11

do.end:                                           ; preds = %if.else, %entry
  %call10 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.195) #39
  br label %if.end11

if.end11:                                         ; preds = %do.end, %if.then5, %if.then2
  %ret.017 = phi i32 [ 0, %do.end ], [ 1, %if.then2 ], [ 1, %if.then5 ]
  ret i32 %ret.017
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sysctl_schedstats(ptr nocapture noundef readonly %table, i32 noundef %write, ptr noundef %buffer, ptr noundef %lenp, ptr noundef %ppos) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %t = alloca %struct.ctl_table, align 4
  %state = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 36, ptr nonnull %t) #33
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %state) #33
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @sched_schedstats, i32 1), ptr blockaddress(@sysctl_schedstats, %l_yes.i)) #33
          to label %arch_static_branch_jump.exit [label %l_yes.i], !srcloc !1232

l_yes.i:                                          ; preds = %entry
  br label %arch_static_branch_jump.exit

arch_static_branch_jump.exit:                     ; preds = %l_yes.i, %entry
  %retval.0.i = phi i32 [ 0, %l_yes.i ], [ 1, %entry ]
  %0 = ptrtoint ptr %state to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 %retval.0.i, ptr %state, align 4
  %tobool3.not = icmp eq i32 %write, 0
  br i1 %tobool3.not, label %if.end, label %land.lhs.true

land.lhs.true:                                    ; preds = %arch_static_branch_jump.exit
  %call4 = tail call zeroext i1 @capable(i32 noundef 21) #33
  br i1 %call4, label %if.end, label %cleanup

if.end:                                           ; preds = %land.lhs.true, %arch_static_branch_jump.exit
  %1 = call ptr @memcpy(ptr %t, ptr %table, i32 36)
  %data = getelementptr inbounds %struct.ctl_table, ptr %t, i32 0, i32 1
  %2 = ptrtoint ptr %data to i32
  call void @__asan_store4_noabort(i32 %2)
  store ptr %state, ptr %data, align 4
  %call5 = call i32 @proc_dointvec_minmax(ptr noundef nonnull %t, i32 noundef %write, ptr noundef %buffer, ptr noundef %lenp, ptr noundef %ppos) #33
  %cmp = icmp slt i32 %call5, 0
  %brmerge = or i1 %tobool3.not, %cmp
  br i1 %brmerge, label %cleanup, label %if.then9

if.then9:                                         ; preds = %if.end
  %3 = ptrtoint ptr %state to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %state, align 4
  %tobool10.not = icmp eq i32 %4, 0
  br i1 %tobool10.not, label %if.else.i, label %if.then.i

if.then.i:                                        ; preds = %if.then9
  call void @static_key_enable(ptr noundef nonnull @sched_schedstats) #33
  br label %cleanup

if.else.i:                                        ; preds = %if.then9
  call void @static_key_disable(ptr noundef nonnull @sched_schedstats) #33
  br label %cleanup

cleanup:                                          ; preds = %if.else.i, %if.then.i, %if.end, %land.lhs.true
  %retval.0 = phi i32 [ -1, %land.lhs.true ], [ %call5, %if.end ], [ %call5, %if.then.i ], [ %call5, %if.else.i ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %state) #33
  call void @llvm.lifetime.end.p0(i64 36, ptr nonnull %t) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @capable(i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @proc_dointvec_minmax(ptr noundef, i32 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_fork(i32 noundef %clone_flags, ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %0 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 0, ptr %on_rq.i, align 4
  %on_rq1.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 3
  %group_node.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 2
  %1 = call ptr @memset(ptr %on_rq1.i, i32 0, i32 44)
  %2 = ptrtoint ptr %group_node.i to i32
  call void @__asan_store4_noabort(i32 %2)
  store volatile ptr %group_node.i, ptr %group_node.i, align 4
  %prev.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 2, i32 1
  %3 = ptrtoint ptr %prev.i.i to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %group_node.i, ptr %prev.i.i, align 4
  %cfs_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 11
  %4 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr null, ptr %cfs_rq.i, align 16
  %stats.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29
  %5 = call ptr @memset(ptr %stats.i, i32 0, i32 256)
  %dl.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20
  %6 = ptrtoint ptr %dl.i to i32
  %7 = ptrtoint ptr %dl.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 %6, ptr %dl.i, align 8
  tail call void @init_dl_task_timer(ptr noundef %dl.i) #33
  tail call void @init_dl_inactive_task_timer(ptr noundef %dl.i) #33
  tail call void @__dl_clear_params(ptr noundef %p) #33
  %rt.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19
  %8 = ptrtoint ptr %rt.i to i32
  call void @__asan_store4_noabort(i32 %8)
  store volatile ptr %rt.i, ptr %rt.i, align 4
  %prev.i1.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 0, i32 1
  %9 = ptrtoint ptr %prev.i1.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store ptr %rt.i, ptr %prev.i1.i, align 4
  %timeout.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 1
  %10 = ptrtoint ptr %timeout.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 0, ptr %timeout.i, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sched_rr_timeslice to i32))
  %11 = load i32, ptr @sched_rr_timeslice, align 4
  %time_slice.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 3
  %12 = ptrtoint ptr %time_slice.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 %11, ptr %time_slice.i, align 16
  %on_rq16.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 4
  %13 = ptrtoint ptr %on_rq16.i to i32
  call void @__asan_store2_noabort(i32 %13)
  store i16 0, ptr %on_rq16.i, align 4
  %on_list.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 5
  %14 = ptrtoint ptr %on_list.i to i32
  call void @__asan_store2_noabort(i32 %14)
  store i16 0, ptr %on_list.i, align 2
  %capture_control.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 152
  %15 = ptrtoint ptr %capture_control.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store ptr null, ptr %capture_control.i, align 4
  %16 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 6, i32 1
  %17 = ptrtoint ptr %16 to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 48, ptr %16, align 4
  %migration_pending.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 36
  %18 = ptrtoint ptr %migration_pending.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr null, ptr %migration_pending.i, align 8
  %19 = ptrtoint ptr %p to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 2048, ptr %p, align 128
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 2
  %22 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %task, align 8
  %normal_prio = getelementptr inbounds %struct.task_struct, ptr %23, i32 0, i32 15
  %24 = ptrtoint ptr %normal_prio to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %normal_prio, align 64
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %26 = ptrtoint ptr %prio to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %25, ptr %prio, align 8
  %arrayidx.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 0
  %27 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load2_noabort(i32 %27)
  %bf.load.i = load i16, ptr %arrayidx.i, align 4
  %bf.clear.i = and i16 %bf.load.i, -3
  store i16 %bf.clear.i, ptr %arrayidx.i, align 4
  %arrayidx.1.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 1
  %28 = ptrtoint ptr %arrayidx.1.i to i32
  call void @__asan_load2_noabort(i32 %28)
  %bf.load.1.i = load i16, ptr %arrayidx.1.i, align 4
  %bf.clear.1.i = and i16 %bf.load.1.i, -3
  store i16 %bf.clear.1.i, ptr %arrayidx.1.i, align 4
  %sched_reset_on_fork.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %29 = ptrtoint ptr %sched_reset_on_fork.i to i32
  call void @__asan_load1_noabort(i32 %29)
  %bf.load1.i = load i8, ptr %sched_reset_on_fork.i, align 4
  %tobool.not.i = icmp sgt i8 %bf.load1.i, -1
  br i1 %tobool.not.i, label %if.end17, label %if.then, !prof !1191

if.then:                                          ; preds = %entry
  %arrayidx8.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 0
  %30 = ptrtoint ptr %arrayidx8.i to i32
  call void @__asan_load2_noabort(i32 %30)
  %bf.load.i.i = load i16, ptr %arrayidx8.i, align 4
  %bf.clear.i.i = and i16 %bf.load.i.i, 2
  store i16 %bf.clear.i.i, ptr %arrayidx8.i, align 4
  %arrayidx8.1.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 1
  %31 = ptrtoint ptr %arrayidx8.1.i to i32
  call void @__asan_load2_noabort(i32 %31)
  %bf.load.i.1.i = load i16, ptr %arrayidx8.1.i, align 4
  %bf.clear.i.1.i = and i16 %bf.load.i.1.i, 2
  %bf.set5.i.1.i = or i16 %bf.clear.i.1.i, -32752
  store i16 %bf.set5.i.1.i, ptr %arrayidx8.1.i, align 4
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 31
  %32 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %policy.i, align 4
  switch i32 %33, label %if.else [
    i32 6, label %if.end11.thread
    i32 2, label %if.end11.thread
    i32 1, label %if.end11.thread
  ]

if.end11.thread:                                  ; preds = %if.then, %if.then, %if.then
  %34 = ptrtoint ptr %policy.i to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 0, ptr %policy.i, align 4
  %static_prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %35 = ptrtoint ptr %static_prio to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 120, ptr %static_prio, align 4
  %rt_priority = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 16
  %36 = ptrtoint ptr %rt_priority to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 0, ptr %rt_priority, align 4
  %normal_prio1375 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 15
  %37 = ptrtoint ptr %normal_prio1375 to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 120, ptr %normal_prio1375, align 64
  %38 = ptrtoint ptr %prio to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 120, ptr %prio, align 8
  %se.i76 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  br label %if.end.i

if.else:                                          ; preds = %if.then
  %static_prio8 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %39 = ptrtoint ptr %static_prio8 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %static_prio8, align 4
  %sub = add i32 %40, -120
  %cmp = icmp slt i32 %sub, 0
  br i1 %cmp, label %if.then9, label %if.end11

if.then9:                                         ; preds = %if.else
  %41 = ptrtoint ptr %static_prio8 to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 120, ptr %static_prio8, align 4
  br label %if.end11

if.end11:                                         ; preds = %if.then9, %if.else
  %42 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %.pr = load i32, ptr %policy.i, align 4
  %static_prio12 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %43 = ptrtoint ptr %static_prio12 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %static_prio12, align 4
  %normal_prio13 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 15
  %45 = ptrtoint ptr %normal_prio13 to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 %44, ptr %normal_prio13, align 64
  %46 = ptrtoint ptr %prio to i32
  call void @__asan_store4_noabort(i32 %46)
  store i32 %44, ptr %prio, align 8
  %se.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %cmp.i.i.not.i = icmp eq i32 %.pr, 5
  br i1 %cmp.i.i.not.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %if.end11
  %47 = ptrtoint ptr %se.i to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 3, ptr %se.i, align 4
  br label %set_load_weight.exit

if.end.i:                                         ; preds = %if.end11, %if.end11.thread
  %se.i78 = phi ptr [ %se.i76, %if.end11.thread ], [ %se.i, %if.end11 ]
  %48 = phi i32 [ 120, %if.end11.thread ], [ %44, %if.end11 ]
  %sub.i = add i32 %48, -100
  %arrayidx.i70 = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %sub.i
  %49 = ptrtoint ptr %arrayidx.i70 to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %arrayidx.i70, align 4
  %51 = ptrtoint ptr %se.i78 to i32
  call void @__asan_store4_noabort(i32 %51)
  store i32 %50, ptr %se.i78, align 4
  %arrayidx5.i = getelementptr [40 x i32], ptr @sched_prio_to_wmult, i32 0, i32 %sub.i
  %52 = ptrtoint ptr %arrayidx5.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %arrayidx5.i, align 4
  br label %set_load_weight.exit

set_load_weight.exit:                             ; preds = %if.end.i, %if.then.i
  %.sink = phi i32 [ 1431655765, %if.then.i ], [ %53, %if.end.i ]
  %54 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 0, i32 1
  %55 = ptrtoint ptr %54 to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 %.sink, ptr %54, align 4
  %bf.clear = and i8 %bf.load1.i, 127
  %56 = ptrtoint ptr %sched_reset_on_fork.i to i32
  call void @__asan_store1_noabort(i32 %56)
  store i8 %bf.clear, ptr %sched_reset_on_fork.i, align 4
  br label %if.end17

if.end17:                                         ; preds = %set_load_weight.exit, %entry
  %57 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %prio, align 8
  %tobool20.not = icmp sgt i32 %58, -1
  br i1 %tobool20.not, label %if.else22, label %return

if.else22:                                        ; preds = %if.end17
  %cmp.i = icmp ugt i32 %58, 99
  %spec.select = select i1 %cmp.i, ptr @fair_sched_class, ptr @rt_sched_class
  %59 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %60 = ptrtoint ptr %59 to i32
  call void @__asan_store4_noabort(i32 %60)
  store ptr %spec.select, ptr %59, align 32
  %se = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  tail call void @init_entity_runnable_average(ptr noundef %se) #33
  %sched_info = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 49
  %61 = call ptr @memset(ptr %sched_info, i32 0, i32 32)
  %on_cpu = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %62 = ptrtoint ptr %on_cpu to i32
  call void @__asan_store4_noabort(i32 %62)
  store i32 0, ptr %on_cpu, align 4
  %stack = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %63 = ptrtoint ptr %stack to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %stack, align 4
  %preempt_count = getelementptr inbounds %struct.thread_info, ptr %64, i32 0, i32 1
  %65 = ptrtoint ptr %preempt_count to i32
  call void @__asan_store4_noabort(i32 %65)
  store i32 2, ptr %preempt_count, align 4
  %pushable_tasks = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 51
  %66 = ptrtoint ptr %pushable_tasks to i32
  call void @__asan_store4_noabort(i32 %66)
  store i32 140, ptr %pushable_tasks, align 4
  %prio_list.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 51, i32 1
  %67 = ptrtoint ptr %prio_list.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store volatile ptr %prio_list.i, ptr %prio_list.i, align 4
  %prev.i.i71 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 51, i32 1, i32 1
  %68 = ptrtoint ptr %prev.i.i71 to i32
  call void @__asan_store4_noabort(i32 %68)
  store ptr %prio_list.i, ptr %prev.i.i71, align 4
  %node_list.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 51, i32 2
  %69 = ptrtoint ptr %node_list.i to i32
  call void @__asan_store4_noabort(i32 %69)
  store volatile ptr %node_list.i, ptr %node_list.i, align 4
  %prev.i1.i72 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 51, i32 2, i32 1
  %70 = ptrtoint ptr %prev.i1.i72 to i32
  call void @__asan_store4_noabort(i32 %70)
  store ptr %node_list.i, ptr %prev.i1.i72, align 4
  %pushable_dl_tasks = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 52
  %71 = ptrtoint ptr %pushable_dl_tasks to i32
  %72 = ptrtoint ptr %pushable_dl_tasks to i32
  call void @__asan_store4_noabort(i32 %72)
  store i32 %71, ptr %pushable_dl_tasks, align 4
  br label %return

return:                                           ; preds = %if.else22, %if.end17
  %retval.0 = phi i32 [ 0, %if.else22 ], [ -11, %if.end17 ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_entity_runnable_average(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_cgroup_fork(ptr noundef %p, ptr nocapture noundef readonly %kargs) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %call = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %cset = getelementptr inbounds %struct.kernel_clone_args, ptr %kargs, i32 0, i32 13
  %0 = ptrtoint ptr %cset to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %cset, align 8
  %arrayidx = getelementptr [14 x ptr], ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %arrayidx, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sysctl_sched_autogroup_enabled to i32))
  %4 = load volatile i32, ptr @sysctl_sched_autogroup_enabled, align 4
  %tobool.not.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i, label %autogroup_task_group.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call.i = tail call zeroext i1 @task_wants_autogroup(ptr noundef %p, ptr noundef %3) #33
  br i1 %call.i, label %if.then.i, label %autogroup_task_group.exit

if.then.i:                                        ; preds = %land.lhs.true.i
  %signal.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 111
  %5 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %signal.i, align 16
  %autogroup.i = getelementptr inbounds %struct.signal_struct, ptr %6, i32 0, i32 26
  %7 = ptrtoint ptr %autogroup.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %autogroup.i, align 4
  %tg1.i = getelementptr inbounds %struct.autogroup, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %tg1.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %tg1.i, align 4
  br label %autogroup_task_group.exit

autogroup_task_group.exit:                        ; preds = %if.then.i, %land.lhs.true.i, %entry
  %retval.0.i = phi ptr [ %10, %if.then.i ], [ %3, %land.lhs.true.i ], [ %3, %entry ]
  %sched_task_group = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %11 = ptrtoint ptr %sched_task_group to i32
  call void @__asan_store4_noabort(i32 %11)
  store ptr %retval.0.i, ptr %sched_task_group, align 8
  %rseq_event_mask.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 176
  %12 = ptrtoint ptr %rseq_event_mask.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %rseq_event_mask.i, align 4
  %or.i.i = or i32 %13, 4
  store i32 %or.i.i, ptr %rseq_event_mask.i, align 4
  %rseq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 174
  %14 = ptrtoint ptr %rseq.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %rseq.i.i, align 8
  %tobool.not.i.i = icmp eq ptr %15, null
  br i1 %tobool.not.i.i, label %rseq_migrate.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %autogroup_task_group.exit
  %stack.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %16 = ptrtoint ptr %stack.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %stack.i.i.i, align 4
  tail call void @_set_bit(i32 noundef 2, ptr noundef %17) #33
  br label %rseq_migrate.exit

rseq_migrate.exit:                                ; preds = %if.then.i.i, %autogroup_task_group.exit
  %18 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %18, -16384
  %19 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %19, i32 0, i32 3
  %20 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %cpu, align 4
  %22 = ptrtoint ptr %sched_task_group to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %sched_task_group, align 8
  %se.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %cfs_rq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 11
  %24 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %cfs_rq.i.i, align 16
  %cfs_rq2.i.i = getelementptr inbounds %struct.task_group, ptr %23, i32 0, i32 2
  %26 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx.i.i = getelementptr ptr, ptr %27, i32 %21
  %28 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %arrayidx.i.i, align 4
  tail call void @set_task_rq_fair(ptr noundef %se.i.i, ptr noundef %25, ptr noundef %29) #33
  %30 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx4.i.i = getelementptr ptr, ptr %31, i32 %21
  %32 = ptrtoint ptr %arrayidx4.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %arrayidx4.i.i, align 4
  %34 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_store4_noabort(i32 %34)
  store ptr %33, ptr %cfs_rq.i.i, align 16
  %se7.i.i = getelementptr inbounds %struct.task_group, ptr %23, i32 0, i32 1
  %35 = ptrtoint ptr %se7.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %se7.i.i, align 8
  %arrayidx8.i.i = getelementptr ptr, ptr %36, i32 %21
  %37 = ptrtoint ptr %arrayidx8.i.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %arrayidx8.i.i, align 4
  %parent.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 10
  %39 = ptrtoint ptr %parent.i.i to i32
  call void @__asan_store4_noabort(i32 %39)
  store ptr %38, ptr %parent.i.i, align 4
  %rt_rq.i.i = getelementptr inbounds %struct.task_group, ptr %23, i32 0, i32 8
  %40 = ptrtoint ptr %rt_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %rt_rq.i.i, align 8
  %arrayidx10.i.i = getelementptr ptr, ptr %41, i32 %21
  %42 = ptrtoint ptr %arrayidx10.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %arrayidx10.i.i, align 4
  %rt_rq11.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 8
  %44 = ptrtoint ptr %rt_rq11.i.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store ptr %43, ptr %rt_rq11.i.i, align 32
  %rt_se.i.i = getelementptr inbounds %struct.task_group, ptr %23, i32 0, i32 7
  %45 = ptrtoint ptr %rt_se.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %rt_se.i.i, align 4
  %arrayidx12.i.i = getelementptr ptr, ptr %46, i32 %21
  %47 = ptrtoint ptr %arrayidx12.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %arrayidx12.i.i, align 4
  %parent14.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 7
  %49 = ptrtoint ptr %parent14.i.i to i32
  call void @__asan_store4_noabort(i32 %49)
  store ptr %48, ptr %parent14.i.i, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1238
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %50 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %stack.i, align 4
  %cpu7.i = getelementptr inbounds %struct.thread_info, ptr %51, i32 0, i32 3
  %52 = ptrtoint ptr %cpu7.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store volatile i32 %21, ptr %cpu7.i, align 4
  %wake_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 11
  %53 = ptrtoint ptr %wake_cpu.i to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %21, ptr %wake_cpu.i, align 16
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %54 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %sched_class, align 32
  %task_fork = getelementptr inbounds %struct.sched_class, ptr %55, i32 0, i32 19
  %56 = ptrtoint ptr %task_fork to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %task_fork, align 4
  %tobool.not = icmp eq ptr %57, null
  br i1 %tobool.not, label %do.body6, label %if.then

if.then:                                          ; preds = %rseq_migrate.exit
  tail call void %57(ptr noundef %p) #33
  br label %do.body6

do.body6:                                         ; preds = %if.then, %rseq_migrate.exit
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_post_fork(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @uclamp_update_util_min_rt_default(ptr noundef %p) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @to_ratio(i64 noundef %period, i64 noundef %runtime) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cmp = icmp eq i64 %runtime, -1
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %cmp1 = icmp eq i64 %period, 0
  br i1 %cmp1, label %return, label %if.end3

if.end3:                                          ; preds = %if.end
  %shl = shl i64 %runtime, 20
  %call = tail call i64 @div64_u64(i64 noundef %shl, i64 noundef %period) #33
  %conv = trunc i64 %call to i32
  br label %return

return:                                           ; preds = %if.end3, %if.end, %entry
  %retval.0 = phi i32 [ %conv, %if.end3 ], [ 1048576, %entry ], [ 0, %if.end ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i64 @div64_u64(i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @wake_up_new_task(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %1 = ptrtoint ptr %0 to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 -1, ptr %0, align 4, !annotation !1193
  %2 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %3 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %2, align 4, !annotation !1193
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %call = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %4 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %call, ptr %rf, align 4
  %5 = ptrtoint ptr %p to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile i32 0, ptr %p, align 128
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %6 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %cpu.i, align 4
  %recent_used_cpu = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 10
  %10 = ptrtoint ptr %recent_used_cpu to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %9, ptr %recent_used_cpu, align 4
  %rseq_event_mask.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 176
  %11 = ptrtoint ptr %rseq_event_mask.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %rseq_event_mask.i, align 4
  %or.i.i = or i32 %12, 4
  store i32 %or.i.i, ptr %rseq_event_mask.i, align 4
  %rseq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 174
  %13 = ptrtoint ptr %rseq.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %rseq.i.i, align 8
  %tobool.not.i.i = icmp eq ptr %14, null
  br i1 %tobool.not.i.i, label %rseq_migrate.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %entry
  tail call void @_set_bit(i32 noundef 2, ptr noundef %7) #33
  br label %rseq_migrate.exit

rseq_migrate.exit:                                ; preds = %if.then.i.i, %entry
  %15 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %stack.i, align 4
  %cpu.i39 = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 3
  %17 = ptrtoint ptr %cpu.i39 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %cpu.i39, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %19 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %19, 0
  br i1 %tobool.not.i, label %if.end.i, label %land.rhs.i

land.rhs.i:                                       ; preds = %rseq_migrate.exit
  %dep_map.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %if.end.i, !prof !1192

do.end.i:                                         ; preds = %land.rhs.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3430, i32 noundef 9, ptr noundef null) #33
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i, %rseq_migrate.exit
  %nr_cpus_allowed.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 32
  %20 = ptrtoint ptr %nr_cpus_allowed.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %nr_cpus_allowed.i, align 8
  %cmp24.i = icmp sgt i32 %21, 1
  br i1 %cmp24.i, label %land.lhs.true.i, label %if.else.i

land.lhs.true.i:                                  ; preds = %if.end.i
  %migration_disabled.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %22 = ptrtoint ptr %migration_disabled.i.i to i32
  call void @__asan_load2_noabort(i32 %22)
  %23 = load i16, ptr %migration_disabled.i.i, align 4
  %tobool.i.not.i = icmp eq i16 %23, 0
  br i1 %tobool.i.not.i, label %if.then26.i, label %if.else.i

if.then26.i:                                      ; preds = %land.lhs.true.i
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %24 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %sched_class.i, align 32
  %select_task_rq.i = getelementptr inbounds %struct.sched_class, ptr %25, i32 0, i32 10
  %26 = ptrtoint ptr %select_task_rq.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %select_task_rq.i, align 4
  %call27.i = tail call i32 %27(ptr noundef %p, i32 noundef %18, i32 noundef 4) #33
  br label %if.end29.i

if.else.i:                                        ; preds = %land.lhs.true.i, %if.end.i
  %cpus_ptr.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  %28 = ptrtoint ptr %cpus_ptr.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %cpus_ptr.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %30 = load i32, ptr @nr_cpu_ids, align 4
  %call.i54.i = tail call i32 @_find_first_bit_be(ptr noundef %29, i32 noundef %30) #33
  br label %if.end29.i

if.end29.i:                                       ; preds = %if.else.i, %if.then26.i
  %cpu.addr.0.i = phi i32 [ %call.i54.i, %if.else.i ], [ %call27.i, %if.then26.i ]
  %call30.i = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %p, i32 noundef %cpu.addr.0.i) #33
  br i1 %call30.i, label %select_task_rq.exit, label %if.then39.i, !prof !1191

if.then39.i:                                      ; preds = %if.end29.i
  %31 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %stack.i, align 4
  %cpu.i.i = getelementptr inbounds %struct.thread_info, ptr %32, i32 0, i32 3
  %33 = ptrtoint ptr %cpu.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load volatile i32, ptr %cpu.i.i, align 4
  %call41.i = tail call fastcc i32 @select_fallback_rq(i32 noundef %34, ptr noundef %p) #33
  br label %select_task_rq.exit

select_task_rq.exit:                              ; preds = %if.then39.i, %if.end29.i
  %cpu.addr.1.i = phi i32 [ %call41.i, %if.then39.i ], [ %cpu.addr.0.i, %if.end29.i ]
  %sched_task_group.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %35 = ptrtoint ptr %sched_task_group.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %sched_task_group.i.i.i, align 8
  %se.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %cfs_rq.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 11
  %37 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %cfs_rq.i.i, align 16
  %cfs_rq2.i.i = getelementptr inbounds %struct.task_group, ptr %36, i32 0, i32 2
  %39 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx.i.i = getelementptr ptr, ptr %40, i32 %cpu.addr.1.i
  %41 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %arrayidx.i.i, align 4
  tail call void @set_task_rq_fair(ptr noundef %se.i.i, ptr noundef %38, ptr noundef %42) #33
  %43 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx4.i.i = getelementptr ptr, ptr %44, i32 %cpu.addr.1.i
  %45 = ptrtoint ptr %arrayidx4.i.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %arrayidx4.i.i, align 4
  %47 = ptrtoint ptr %cfs_rq.i.i to i32
  call void @__asan_store4_noabort(i32 %47)
  store ptr %46, ptr %cfs_rq.i.i, align 16
  %se7.i.i = getelementptr inbounds %struct.task_group, ptr %36, i32 0, i32 1
  %48 = ptrtoint ptr %se7.i.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %se7.i.i, align 8
  %arrayidx8.i.i = getelementptr ptr, ptr %49, i32 %cpu.addr.1.i
  %50 = ptrtoint ptr %arrayidx8.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %arrayidx8.i.i, align 4
  %parent.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 10
  %52 = ptrtoint ptr %parent.i.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store ptr %51, ptr %parent.i.i, align 4
  %rt_rq.i.i = getelementptr inbounds %struct.task_group, ptr %36, i32 0, i32 8
  %53 = ptrtoint ptr %rt_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %rt_rq.i.i, align 8
  %arrayidx10.i.i = getelementptr ptr, ptr %54, i32 %cpu.addr.1.i
  %55 = ptrtoint ptr %arrayidx10.i.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %arrayidx10.i.i, align 4
  %rt_rq11.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 8
  %57 = ptrtoint ptr %rt_rq11.i.i to i32
  call void @__asan_store4_noabort(i32 %57)
  store ptr %56, ptr %rt_rq11.i.i, align 32
  %rt_se.i.i = getelementptr inbounds %struct.task_group, ptr %36, i32 0, i32 7
  %58 = ptrtoint ptr %rt_se.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %rt_se.i.i, align 4
  %arrayidx12.i.i = getelementptr ptr, ptr %59, i32 %cpu.addr.1.i
  %60 = ptrtoint ptr %arrayidx12.i.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %arrayidx12.i.i, align 4
  %parent14.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 7
  %62 = ptrtoint ptr %parent14.i.i to i32
  call void @__asan_store4_noabort(i32 %62)
  store ptr %61, ptr %parent14.i.i, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1238
  %63 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %stack.i, align 4
  %cpu7.i = getelementptr inbounds %struct.thread_info, ptr %64, i32 0, i32 3
  %65 = ptrtoint ptr %cpu7.i to i32
  call void @__asan_store4_noabort(i32 %65)
  store volatile i32 %cpu.addr.1.i, ptr %cpu7.i, align 4
  %wake_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 11
  %66 = ptrtoint ptr %wake_cpu.i to i32
  call void @__asan_store4_noabort(i32 %66)
  store i32 %cpu.addr.1.i, ptr %wake_cpu.i, align 16
  %call13 = call ptr @__task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call13)
  tail call void @post_init_entity_util_avg(ptr noundef %p) #33
  tail call fastcc void @enqueue_task(ptr noundef %call13, ptr noundef %p, i32 noundef 8) #33
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %67 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store i32 1, ptr %on_rq.i, align 4
  tail call fastcc void @trace_sched_wakeup_new(ptr noundef %p)
  tail call void @check_preempt_curr(ptr noundef %call13, ptr noundef %p, i32 noundef 4)
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %68 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %sched_class, align 32
  %task_woken = getelementptr inbounds %struct.sched_class, ptr %69, i32 0, i32 13
  %70 = ptrtoint ptr %task_woken to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load ptr, ptr %task_woken, align 4
  %tobool.not = icmp eq ptr %71, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %select_task_rq.exit
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 25
  %72 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ugt i32 %73, 2
  br i1 %cmp.i, label %if.then.i, label %if.end.i42

if.then.i:                                        ; preds = %if.then
  %74 = ptrtoint ptr %2 to i32
  call void @__asan_store4_noabort(i32 %74)
  store i32 4, ptr %2, align 4
  br label %if.end.i42

if.end.i42:                                       ; preds = %if.then.i, %if.then
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 81
  %75 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i41 = icmp eq i32 %76, 0
  br i1 %tobool.not.i.i41, label %rq_unpin_lock.exit, label %if.then.i.i43

if.then.i.i43:                                    ; preds = %if.end.i42
  %core.i.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 79
  %77 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i43, %if.end.i42
  %retval.0.i.i = phi ptr [ %78, %if.then.i.i43 ], [ %call13, %if.end.i42 ]
  %dep_map.i44 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %79 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %79)
  %.unpack.i = load i32, ptr %0, align 4
  %80 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i44, [1 x i32] %80) #33
  %81 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load ptr, ptr %sched_class, align 32
  %task_woken15 = getelementptr inbounds %struct.sched_class, ptr %82, i32 0, i32 13
  %83 = ptrtoint ptr %task_woken15 to i32
  call void @__asan_load4_noabort(i32 %83)
  %84 = load ptr, ptr %task_woken15, align 4
  tail call void %84(ptr noundef %call13, ptr noundef %p) #33
  %85 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i46 = icmp eq i32 %86, 0
  br i1 %tobool.not.i.i46, label %rq_repin_lock.exit, label %if.then.i.i48

if.then.i.i48:                                    ; preds = %rq_unpin_lock.exit
  %core.i.i47 = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 79
  %87 = ptrtoint ptr %core.i.i47 to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load ptr, ptr %core.i.i47, align 8
  br label %rq_repin_lock.exit

rq_repin_lock.exit:                               ; preds = %if.then.i.i48, %rq_unpin_lock.exit
  %retval.0.i.i49 = phi ptr [ %88, %if.then.i.i48 ], [ %call13, %rq_unpin_lock.exit ]
  %dep_map.i50 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i49, i32 0, i32 4
  tail call void @lock_repin_lock(ptr noundef %dep_map.i50, [1 x i32] %80) #33
  %89 = ptrtoint ptr %2 to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load i32, ptr %2, align 4
  %91 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %clock_update_flags.i, align 4
  %or.i = or i32 %92, %90
  store i32 %or.i, ptr %clock_update_flags.i, align 4
  br label %if.end

if.end:                                           ; preds = %rq_repin_lock.exit, %select_task_rq.exit
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 81
  %93 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %94, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 79
  %95 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %95)
  %96 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end
  %retval.0.i.i.i = phi ptr [ %96, %if.then.i.i.i ], [ %call13, %if.end ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %97 = ptrtoint ptr %0 to i32
  call void @__asan_load4_noabort(i32 %97)
  %.unpack.i.i = load i32, ptr %0, align 4
  %98 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %98) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@wake_up_new_task, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %99 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %99)
  %100 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %100, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call13, i32 0, i32 79
  %101 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %102, %if.then.i.i4.i ], [ %call13, %land.rhs.i.i.i.i ], [ %call13, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %103 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %103)
  %104 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %104) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @post_init_entity_util_avg(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_wakeup_new(ptr noundef %p) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup_new, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_wakeup_new, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1265
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup_new, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %p) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1266
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1266
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup_new, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_wakeup_new.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_wakeup_new.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 187, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @balance_push(ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %curr = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %0 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %curr, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %2 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %6, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %balance_callback = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %7 = ptrtoint ptr %balance_callback to i32
  call void @__asan_store4_noabort(i32 %7)
  store ptr @balance_push_callback, ptr %balance_callback, align 8
  %cpu = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %10 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %10, %9
  br i1 %cmp.not.i.i.i.i, label %cpu_dying.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %lockdep_assert_rq_held.exit
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_dying.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_dying.exit

cpu_dying.exit:                                   ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %lockdep_assert_rq_held.exit
  %div3.i.i.i = lshr i32 %9, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_dying_mask, i32 %div3.i.i.i
  %11 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %9, 31
  %13 = shl nuw i32 1, %and.i.i.i
  %14 = and i32 %12, %13
  %tobool.i.not = icmp eq i32 %14, 0
  br i1 %tobool.i.not, label %cleanup, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %cpu_dying.exit
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i to ptr
  %cpu3 = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 3
  %17 = ptrtoint ptr %cpu3 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %cpu3, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %18
  %19 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %arrayidx, align 4
  %add = add i32 %20, ptrtoint (ptr @runqueues to i32)
  %21 = inttoptr i32 %add to ptr
  %cmp.not = icmp eq ptr %21, %rq
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %lor.lhs.false
  %call4 = tail call zeroext i1 @kthread_is_per_cpu(ptr noundef %1) #33
  br i1 %call4, label %if.then7, label %lor.lhs.false5

lor.lhs.false5:                                   ; preds = %if.end
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %1, i32 0, i32 37
  %22 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %22)
  %23 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i47.not = icmp eq i16 %23, 0
  br i1 %tobool.i47.not, label %if.end16, label %if.then7

if.then7:                                         ; preds = %lor.lhs.false5, %if.end
  %nr_running = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %24 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %nr_running, align 4
  %tobool.not = icmp eq i32 %25, 0
  br i1 %tobool.not, label %land.lhs.true, label %cleanup

land.lhs.true:                                    ; preds = %if.then7
  %nr_pinned.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 76
  %26 = ptrtoint ptr %nr_pinned.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %nr_pinned.i, align 8
  %tobool.i48.not = icmp eq i32 %27, 0
  br i1 %tobool.i48.not, label %land.lhs.true9, label %cleanup

land.lhs.true9:                                   ; preds = %land.lhs.true
  %hotplug_wait = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 59
  %28 = ptrtoint ptr %hotplug_wait to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load volatile ptr, ptr %hotplug_wait, align 4
  %tobool.i49.not = icmp eq ptr %29, null
  br i1 %tobool.i49.not, label %cleanup, label %if.then12

if.then12:                                        ; preds = %land.lhs.true9
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@balance_push, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %if.then12
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %30 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %31, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i51

if.then.i.i51:                                    ; preds = %land.rhs.i.i.i
  %core.i.i50 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %32 = ptrtoint ptr %core.i.i50 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %core.i.i50, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i51, %land.rhs.i.i.i, %if.then12
  %retval.0.i.i52 = phi ptr [ %33, %if.then.i.i51 ], [ %rq, %land.rhs.i.i.i ], [ %rq, %if.then12 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i52) #33
  %call14 = tail call i32 @rcuwait_wake_up(ptr noundef %hotplug_wait) #33
  tail call fastcc void @raw_spin_rq_lock(ptr noundef %rq)
  br label %cleanup

if.end16:                                         ; preds = %lor.lhs.false5
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %1, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %34 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %34, 0
  %tobool1.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i, label %if.end15.sink.split.i.i.i.i, label %if.else.i.i.i.i, !prof !1192

if.else.i.i.i.i:                                  ; preds = %if.end16
  %add.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i, 1
  %35 = or i32 %add.i.i.i.i, %asmresult.i.i.i.i.i.i
  %.not.i.i.i.i = icmp sgt i32 %35, -1
  br i1 %.not.i.i.i.i, label %get_task_struct.exit, label %if.end15.sink.split.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i:                      ; preds = %if.else.i.i.i.i, %if.end16
  %.sink.i.i.i.i = phi i32 [ 2, %if.end16 ], [ 1, %if.else.i.i.i.i ]
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef %.sink.i.i.i.i) #33
  br label %get_task_struct.exit

get_task_struct.exit:                             ; preds = %if.end15.sink.split.i.i.i.i, %if.else.i.i.i.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@balance_push, %land.rhs.i.i.i55)) #33
          to label %raw_spin_rq_unlock.exit59 [label %land.rhs.i.i.i55], !srcloc !1202

land.rhs.i.i.i55:                                 ; preds = %get_task_struct.exit
  %core_enabled.i.i.i53 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %36 = ptrtoint ptr %core_enabled.i.i.i53 to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %core_enabled.i.i.i53, align 128
  %tobool3.i.not.i.i54 = icmp eq i32 %37, 0
  br i1 %tobool3.i.not.i.i54, label %raw_spin_rq_unlock.exit59, label %if.then.i.i57

if.then.i.i57:                                    ; preds = %land.rhs.i.i.i55
  %core.i.i56 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %38 = ptrtoint ptr %core.i.i56 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %core.i.i56, align 8
  br label %raw_spin_rq_unlock.exit59

raw_spin_rq_unlock.exit59:                        ; preds = %if.then.i.i57, %land.rhs.i.i.i55, %get_task_struct.exit
  %retval.0.i.i58 = phi ptr [ %39, %if.then.i.i57 ], [ %rq, %land.rhs.i.i.i55 ], [ %rq, %get_task_struct.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i58) #33
  %40 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %cpu, align 4
  %42 = ptrtoint ptr %cpu3 to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %cpu3, align 4
  %arrayidx28 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %43
  %44 = ptrtoint ptr %arrayidx28 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %arrayidx28, align 4
  %add29 = add i32 %45, ptrtoint (ptr @push_work to i32)
  %46 = inttoptr i32 %add29 to ptr
  %call30 = tail call zeroext i1 @stop_one_cpu_nowait(i32 noundef %41, ptr noundef nonnull @__balance_push_cpu_stop, ptr noundef %1, ptr noundef %46) #33
  %47 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %47, -16384
  %48 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %48, i32 0, i32 1
  %49 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %50, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@balance_push, %for.cond.i.i)) #33
          to label %if.then.i.i60 [label %for.cond.i.i], !srcloc !1202

if.then.i.i60:                                    ; preds = %raw_spin_rq_unlock.exit59
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %raw_spin_rq_unlock.exit59
  %core_enabled.i.i.i61 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %51 = ptrtoint ptr %core_enabled.i.i.i61 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %core_enabled.i.i.i61, align 128
  %tobool.not.i.i.i = icmp eq i32 %52, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %53 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %54, %if.then.i.i.i ], [ %rq, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %55 = ptrtoint ptr %core_enabled.i.i.i61 to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %core_enabled.i.i.i61, align 128
  %tobool.not.i23.i.i = icmp eq i32 %56, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %57 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %58, %if.then.i25.i.i ], [ %rq, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i60
  %59 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %59, -16384
  %60 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %60, i32 0, i32 1
  %61 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %62, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  br label %cleanup

cleanup:                                          ; preds = %raw_spin_rq_lock.exit, %raw_spin_rq_unlock.exit, %land.lhs.true9, %land.lhs.true, %if.then7, %lor.lhs.false, %cpu_dying.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @schedule_tail(ptr noundef %prev) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @finish_task_switch(ptr noundef %prev)
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1267
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %sub.i = add i32 %3, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i, align 4
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i13 = and i32 %4, -16384
  %5 = inttoptr i32 %and.i13 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task, align 8
  %set_child_tid = getelementptr inbounds %struct.task_struct, ptr %7, i32 0, i32 83
  %8 = ptrtoint ptr %set_child_tid to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %set_child_tid, align 8
  %tobool.not = icmp eq ptr %9, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %call.i = tail call i32 @__task_pid_nr_ns(ptr noundef %7, i32 noundef 0, ptr noundef null) #33
  tail call void @__might_fault(ptr noundef nonnull @.str.1, i32 noundef 4935) #33
  %10 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i12 = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i.i12 to ptr
  %cpu_domain.i.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 4
  %12 = tail call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i) #22, !srcloc !1268
  %and.i = and i32 %12, -13
  %or.i = or i32 %and.i, 4
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %13 = tail call i32 asm sideeffect ".ifnc $0,r0; .ifnc $0r0,fpr11; .ifnc $0r0,r11fp; .ifnc $0r0,ipr12; .ifnc $0r0,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $2,r2; .ifnc $2r2,fpr11; .ifnc $2r2,r11fp; .ifnc $2r2,ipr12; .ifnc $2r2,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $3,r1; .ifnc $3r1,fpr11; .ifnc $3r1,r11fp; .ifnc $3r1,ipr12; .ifnc $3r1,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09bl\09__put_user_4", "=&{r0},{r0},{r2},{r1},~{r12},~{lr},~{cc}"(ptr nonnull %9, i32 %call.i, i32 -1226833921) #33, !srcloc !1271
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %12) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  tail call void @calculate_sigpending() #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @finish_task_switch(ptr noundef %prev) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %prev_mm = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 24
  %7 = ptrtoint ptr %prev_mm to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %prev_mm, align 8
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %cmp.not = icmp eq i32 %10, 2
  br i1 %cmp.not, label %if.end47, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b1 = load i1, ptr @finish_task_switch.__already_done, align 1
  br i1 %.b1, label %if.then46, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @finish_task_switch.__already_done, align 1
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 101
  %pid = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 68
  %13 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %pid, align 8
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i3 = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i3 to ptr
  %preempt_count.i4 = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i4 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i4, align 4
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 4852, i32 noundef 9, ptr noundef nonnull @.str.198, ptr noundef %comm, i32 noundef %14, i32 noundef %18) #33
  br label %if.then46

if.then46:                                        ; preds = %if.then, %land.rhs
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store volatile i32 2, ptr %preempt_count.i.i, align 4
  br label %if.end47

if.end47:                                         ; preds = %if.then46, %entry
  %22 = ptrtoint ptr %prev_mm to i32
  call void @__asan_store4_noabort(i32 %22)
  store ptr null, ptr %prev_mm, align 8
  %23 = ptrtoint ptr %prev to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %prev, align 128
  %task54 = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %25 = ptrtoint ptr %task54 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %task54, align 8
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @perf_sched_events, ptr blockaddress(@finish_task_switch, %if.then.i)) #33
          to label %if.end.i [label %if.then.i], !srcloc !1202

if.then.i:                                        ; preds = %if.end47
  tail call void @__perf_event_task_sched_in(ptr noundef %prev, ptr noundef %26) #33
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %if.end47
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([12 x %struct.static_key], ptr @perf_swevent_enabled, i32 0, i32 4), ptr blockaddress(@finish_task_switch, %land.lhs.true.i)) #33
          to label %perf_event_task_sched_in.exit [label %land.lhs.true.i], !srcloc !1202

land.lhs.true.i:                                  ; preds = %if.end.i
  %sched_migrated.i = getelementptr inbounds %struct.task_struct, ptr %26, i32 0, i32 63
  %27 = ptrtoint ptr %sched_migrated.i to i32
  call void @__asan_load1_noabort(i32 %27)
  %bf.load.i = load i8, ptr %sched_migrated.i, align 4
  %28 = and i8 %bf.load.i, 32
  %tobool4.not.i = icmp eq i8 %28, 0
  br i1 %tobool4.not.i, label %perf_event_task_sched_in.exit, label %if.then5.i

if.then5.i:                                       ; preds = %land.lhs.true.i
  %29 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i5 = and i32 %29, -16384
  %30 = inttoptr i32 %and.i.i.i5 to ptr
  %cpu.i.i = getelementptr inbounds %struct.thread_info, ptr %30, i32 0, i32 3
  %31 = ptrtoint ptr %cpu.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %cpu.i.i, align 4
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %32
  %33 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %34, ptrtoint (ptr @__perf_regs to i32)
  %35 = inttoptr i32 %add.i.i to ptr
  %36 = tail call ptr @llvm.returnaddress(i32 0) #33
  %37 = ptrtoint ptr %36 to i32
  %arrayidx.i.i.i = getelementptr [18 x i32], ptr %35, i32 0, i32 15
  %38 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %37, ptr %arrayidx.i.i.i, align 4
  %39 = tail call ptr @llvm.frameaddress.p0(i32 0) #33
  %40 = ptrtoint ptr %39 to i32
  %arrayidx2.i.i.i = getelementptr [18 x i32], ptr %35, i32 0, i32 11
  %41 = ptrtoint ptr %arrayidx2.i.i.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 %40, ptr %arrayidx2.i.i.i, align 4
  %42 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i.i.i = getelementptr [18 x i32], ptr %35, i32 0, i32 13
  %43 = ptrtoint ptr %arrayidx4.i.i.i to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 %42, ptr %arrayidx4.i.i.i, align 4
  %arrayidx6.i.i.i = getelementptr [18 x i32], ptr %35, i32 0, i32 16
  %44 = ptrtoint ptr %arrayidx6.i.i.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 19, ptr %arrayidx6.i.i.i, align 4
  tail call void @___perf_sw_event(i32 noundef 4, i64 noundef 1, ptr noundef %35, i64 noundef 0) #33
  %45 = ptrtoint ptr %sched_migrated.i to i32
  call void @__asan_load1_noabort(i32 %45)
  %bf.load7.i = load i8, ptr %sched_migrated.i, align 4
  %bf.clear8.i = and i8 %bf.load7.i, -33
  store i8 %bf.clear8.i, ptr %sched_migrated.i, align 4
  br label %perf_event_task_sched_in.exit

perf_event_task_sched_in.exit:                    ; preds = %if.then5.i, %land.lhs.true.i, %if.end.i
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1272
  %on_cpu.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 5
  %46 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_store4_noabort(i32 %46)
  store volatile i32 0, ptr %on_cpu.i, align 4
  tail call fastcc void @finish_lock_switch(ptr noundef %6)
  %47 = ptrtoint ptr %task54 to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %task54, align 8
  %kcov_mode = getelementptr inbounds %struct.task_struct, ptr %48, i32 0, i32 195
  %49 = ptrtoint ptr %kcov_mode to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %kcov_mode, align 8
  %and = and i32 %50, -1073741825
  store i32 %and, ptr %kcov_mode, align 8
  %51 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i6 = and i32 %51, -16384
  %52 = inttoptr i32 %and.i.i6 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %52, i32 0, i32 2
  %53 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load ptr, ptr %task.i, align 8
  %kmap_ctrl.i = getelementptr inbounds %struct.task_struct, ptr %54, i32 0, i32 211
  %55 = ptrtoint ptr %kmap_ctrl.i to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %kmap_ctrl.i, align 4
  %tobool.not.i = icmp eq i32 %56, 0
  br i1 %tobool.not.i, label %kmap_local_sched_in.exit, label %if.then.i7, !prof !1191

if.then.i7:                                       ; preds = %perf_event_task_sched_in.exit
  tail call void @__kmap_local_sched_in() #33
  br label %kmap_local_sched_in.exit

kmap_local_sched_in.exit:                         ; preds = %if.then.i7, %perf_event_task_sched_in.exit
  %tobool65.not = icmp eq ptr %8, null
  br i1 %tobool65.not, label %if.end67, label %if.then66

if.then66:                                        ; preds = %kmap_local_sched_in.exit
  %57 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i9 = and i32 %57, -16384
  %58 = inttoptr i32 %and.i.i9 to ptr
  %task.i10 = getelementptr inbounds %struct.thread_info, ptr %58, i32 0, i32 2
  %59 = ptrtoint ptr %task.i10 to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %task.i10, align 8
  %mm1.i = getelementptr inbounds %struct.task_struct, ptr %60, i32 0, i32 53
  %61 = ptrtoint ptr %mm1.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load ptr, ptr %mm1.i, align 8
  %cmp.not.i = icmp eq ptr %62, %8
  br i1 %cmp.not.i, label %if.end.i11, label %membarrier_mm_sync_core_before_usermode.exit

if.end.i11:                                       ; preds = %if.then66
  %membarrier_state.i = getelementptr inbounds %struct.anon.3, ptr %8, i32 0, i32 9
  %call.i.i.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %membarrier_state.i, i32 noundef 4) #33
  %63 = ptrtoint ptr %membarrier_state.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load volatile i32, ptr %membarrier_state.i, align 4
  br label %membarrier_mm_sync_core_before_usermode.exit

membarrier_mm_sync_core_before_usermode.exit:     ; preds = %if.end.i11, %if.then66
  %mm_count.i.i = getelementptr inbounds %struct.anon.3, ptr %8, i32 0, i32 11
  %call.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %mm_count.i.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1273
  tail call void @llvm.prefetch.p0(ptr %mm_count.i.i, i32 1, i32 3, i32 1) #33
  %65 = tail call { i32, i32 } asm sideeffect "@ atomic_sub_return\0A1:\09ldrex\09$0, [$3]\0A\09sub\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %mm_count.i.i, ptr %mm_count.i.i, i32 1, ptr elementtype(i32) %mm_count.i.i) #33, !srcloc !1274
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32 } %65, 0
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1275
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %cmp.i.i.i.i, label %if.then.i.i, label %if.end67, !prof !1192

if.then.i.i:                                      ; preds = %membarrier_mm_sync_core_before_usermode.exit
  tail call void @__mmdrop(ptr noundef nonnull %8) #33
  br label %if.end67

if.end67:                                         ; preds = %if.then.i.i, %membarrier_mm_sync_core_before_usermode.exit, %kmap_local_sched_in.exit
  %cmp68 = icmp eq i32 %24, 128
  br i1 %cmp68, label %if.then75, label %if.end81, !prof !1192

if.then75:                                        ; preds = %if.end67
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %66 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load ptr, ptr %sched_class, align 32
  %task_dead = getelementptr inbounds %struct.sched_class, ptr %67, i32 0, i32 20
  %68 = ptrtoint ptr %task_dead to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %task_dead, align 4
  %tobool76.not = icmp eq ptr %69, null
  br i1 %tobool76.not, label %if.end80, label %if.then77

if.then77:                                        ; preds = %if.then75
  tail call void %69(ptr noundef %prev) #33
  br label %if.end80

if.end80:                                         ; preds = %if.then77, %if.then75
  tail call void @put_task_struct_rcu_user(ptr noundef %prev) #33
  br label %if.end81

if.end81:                                         ; preds = %if.end80, %if.end67
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__might_fault(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @calculate_sigpending() local_unnamed_addr #2

; Function Attrs: nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define dso_local i32 @nr_running() local_unnamed_addr #12 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %call6 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_online_mask) #37
  %cmp7 = icmp ult i32 %call6, %0
  br i1 %cmp7, label %do.body, label %for.end

do.body:                                          ; preds = %do.body, %entry
  %call9 = phi i32 [ %call, %do.body ], [ %call6, %entry ]
  %sum.08 = phi i32 [ %add2, %do.body ], [ 0, %entry ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call9
  %1 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx, align 4
  %add = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add to ptr
  %nr_running = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %nr_running, align 4
  %add2 = add i32 %5, %sum.08
  %call = tail call i32 @cpumask_next(i32 noundef %call9, ptr noundef nonnull @__cpu_online_mask) #37
  %cmp = icmp ult i32 %call, %0
  br i1 %cmp, label %do.body, label %for.end

for.end:                                          ; preds = %do.body, %entry
  %sum.0.lcssa = phi i32 [ 0, %entry ], [ %add2, %do.body ]
  ret i32 %sum.0.lcssa
}

; Function Attrs: mustprogress nofree nounwind null_pointer_is_valid readonly willreturn
declare dso_local i32 @cpumask_next(i32 noundef, ptr noundef) local_unnamed_addr #5

; Function Attrs: mustprogress nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local zeroext i1 @single_task_running() #13 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %nr_running = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 1
  %7 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %nr_running, align 4
  %cmp = icmp eq i32 %8, 1
  ret i1 %cmp
}

; Function Attrs: nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define dso_local i64 @nr_context_switches() local_unnamed_addr #12 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %call6 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  %cmp7 = icmp ult i32 %call6, %0
  br i1 %cmp7, label %do.body, label %for.end

do.body:                                          ; preds = %do.body, %entry
  %call9 = phi i32 [ %call, %do.body ], [ %call6, %entry ]
  %sum.08 = phi i64 [ %add2, %do.body ], [ 0, %entry ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call9
  %1 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx, align 4
  %add = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add to ptr
  %nr_switches = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 9
  %4 = ptrtoint ptr %nr_switches to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %nr_switches, align 32
  %add2 = add i64 %5, %sum.08
  %call = tail call i32 @cpumask_next(i32 noundef %call9, ptr noundef nonnull @__cpu_possible_mask) #37
  %cmp = icmp ult i32 %call, %0
  br i1 %cmp, label %do.body, label %for.end

for.end:                                          ; preds = %do.body, %entry
  %sum.0.lcssa = phi i64 [ 0, %entry ], [ %add2, %do.body ]
  ret i64 %sum.0.lcssa
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @nr_iowait_cpu(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %nr_iowait = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 31
  %call.i.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %nr_iowait, i32 noundef 4) #33
  %3 = ptrtoint ptr %nr_iowait to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %nr_iowait, align 4
  ret i32 %4
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @nr_iowait() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call5 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp6 = icmp ult i32 %call5, %0
  br i1 %cmp6, label %for.body, label %for.end

for.body:                                         ; preds = %for.body, %entry
  %call8 = phi i32 [ %call, %for.body ], [ %call5, %entry ]
  %sum.07 = phi i32 [ %add, %for.body ], [ 0, %entry ]
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call8
  %1 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add.i to ptr
  %nr_iowait.i = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 31
  %call.i.i.i = tail call zeroext i1 @__kasan_check_read(ptr noundef %nr_iowait.i, i32 noundef 4) #33
  %4 = ptrtoint ptr %nr_iowait.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %nr_iowait.i, align 4
  %add = add i32 %5, %sum.07
  %call = tail call i32 @cpumask_next(i32 noundef %call8, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %6 = load i32, ptr @nr_cpu_ids, align 4
  %cmp = icmp ult i32 %call, %6
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body, %entry
  %sum.0.lcssa = phi i32 [ 0, %entry ], [ %add, %for.body ]
  ret i32 %sum.0.lcssa
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_exec() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arg = alloca %struct.migration_arg, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 128
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 21
  %4 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %sched_class, align 32
  %select_task_rq = getelementptr inbounds %struct.sched_class, ptr %5, i32 0, i32 10
  %6 = ptrtoint ptr %select_task_rq to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %select_task_rq, align 4
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 1
  %8 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 3
  %10 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %cpu.i, align 4
  %call3 = tail call i32 %7(ptr noundef %3, i32 noundef %11, i32 noundef 2) #33
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %12 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %cpu, align 4
  %cmp5 = icmp eq i32 %call3, %13
  br i1 %cmp5, label %do.body24, label %if.end

if.end:                                           ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %14 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %14, %call3
  br i1 %cmp.not.i.i.i.i, label %cpu_active.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %if.end
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_active.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_active.exit

cpu_active.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %if.end
  %div3.i.i.i = lshr i32 %call3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_active_mask, i32 %div3.i.i.i
  %15 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %call3, 31
  %17 = shl nuw i32 1, %and.i.i.i
  %18 = and i32 %16, %17
  %tobool.i.not = icmp eq i32 %18, 0
  br i1 %tobool.i.not, label %do.body24, label %if.then9, !prof !1192

if.then9:                                         ; preds = %cpu_active.exit
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %arg) #33
  %19 = getelementptr inbounds %struct.migration_arg, ptr %arg, i32 0, i32 1
  %20 = getelementptr inbounds %struct.migration_arg, ptr %arg, i32 0, i32 2
  %21 = ptrtoint ptr %arg to i32
  call void @__asan_store4_noabort(i32 %21)
  store ptr %3, ptr %arg, align 4
  %22 = ptrtoint ptr %19 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 %call3, ptr %19, align 4
  %23 = ptrtoint ptr %20 to i32
  call void @__asan_store4_noabort(i32 %23)
  store ptr null, ptr %20, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call1) #33
  %24 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %stack.i, align 4
  %cpu.i46 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu.i46 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %cpu.i46, align 4
  %call22 = call i32 @stop_one_cpu(i32 noundef %27, ptr noundef nonnull @migration_cpu_stop, ptr noundef nonnull %arg) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %arg) #33
  br label %cleanup

do.body24:                                        ; preds = %cpu_active.exit, %entry
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call1) #33
  br label %cleanup

cleanup:                                          ; preds = %do.body24, %if.then9
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @stop_one_cpu(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @migration_cpu_stop(ptr nocapture noundef readonly %data) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %pending1 = getelementptr inbounds %struct.migration_arg, ptr %data, i32 0, i32 2
  %0 = ptrtoint ptr %pending1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %pending1, align 4
  %2 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %data, align 4
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %add = add i32 %9, ptrtoint (ptr @runqueues to i32)
  %10 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %11 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 -1, ptr %11, align 4, !annotation !1193
  %13 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %14 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 -1, ptr %13, align 4, !annotation !1193
  %15 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %16 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 %15, ptr %rf, align 4
  %and.i222 = and i32 %15, 128
  %tobool.not = icmp eq i32 %and.i222, 0
  br i1 %tobool.not, label %if.then, label %do.end18

if.then:                                          ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.end18

do.end18:                                         ; preds = %if.then, %entry
  tail call void @flush_smp_call_function_from_idle() #33
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 128
  tail call void @_raw_spin_lock(ptr noundef %pi_lock) #33
  call fastcc void @rq_lock(ptr noundef %10, ptr noundef nonnull %rf)
  %tobool19.not = icmp eq ptr %1, null
  br i1 %tobool19.not, label %if.end58.thread, label %land.rhs

land.rhs:                                         ; preds = %do.end18
  %migration_pending = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 36
  %17 = ptrtoint ptr %migration_pending to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %migration_pending, align 8
  %cmp20.not = icmp eq ptr %1, %18
  br i1 %cmp20.not, label %if.end58, label %land.rhs25

land.rhs25:                                       ; preds = %land.rhs
  %.b220 = load i1, ptr @migration_cpu_stop.__already_done, align 1
  br i1 %.b220, label %if.end58, label %if.then32, !prof !1191

if.then32:                                        ; preds = %land.rhs25
  store i1 true, ptr @migration_cpu_stop.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2355, i32 noundef 9, ptr noundef null) #33
  br label %if.end58

if.end58:                                         ; preds = %if.then32, %land.rhs25, %land.rhs
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 1
  %19 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 3
  %21 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx74 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %22
  %23 = ptrtoint ptr %arrayidx74 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %arrayidx74, align 4
  %add75 = add i32 %24, ptrtoint (ptr @runqueues to i32)
  %25 = inttoptr i32 %add75 to ptr
  %cmp76 = icmp eq ptr %25, %10
  br i1 %cmp76, label %if.then78, label %if.then99.critedge

if.end58.thread:                                  ; preds = %do.end18
  %stack.i261 = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 1
  %26 = ptrtoint ptr %stack.i261 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %stack.i261, align 4
  %cpu.i262 = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 3
  %28 = ptrtoint ptr %cpu.i262 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load volatile i32, ptr %cpu.i262, align 4
  %arrayidx74263 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx74263 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx74263, align 4
  %add75264 = add i32 %31, ptrtoint (ptr @runqueues to i32)
  %32 = inttoptr i32 %add75264 to ptr
  %cmp76265 = icmp eq ptr %32, %10
  br i1 %cmp76265, label %if.then78.thread, label %if.end171

if.then78:                                        ; preds = %if.end58
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 37
  %33 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %33)
  %34 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %34, 0
  br i1 %tobool.i.not, label %if.then83.critedge, label %if.then169

if.then78.thread:                                 ; preds = %if.end58.thread
  %migration_disabled.i283 = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 37
  %35 = ptrtoint ptr %migration_disabled.i283 to i32
  call void @__asan_load2_noabort(i32 %35)
  %36 = load i16, ptr %migration_disabled.i283, align 4
  %tobool.i284.not = icmp eq i16 %36, 0
  br i1 %tobool.i284.not, label %if.end90, label %if.end171

if.then83.critedge:                               ; preds = %if.then78
  %37 = ptrtoint ptr %migration_pending to i32
  call void @__asan_store4_noabort(i32 %37)
  store ptr null, ptr %migration_pending, align 8
  %38 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %cpu.i, align 4
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %40 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %40, %39
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.then83.critedge
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %if.then83.critedge
  %div3.i.i = lshr i32 %39, 5
  %arrayidx.i.i = getelementptr i32, ptr %cpus_mask, i32 %div3.i.i
  %41 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i = and i32 %39, 31
  %43 = shl nuw i32 1, %and.i.i
  %44 = and i32 %42, %43
  %tobool87.not = icmp eq i32 %44, 0
  br i1 %tobool87.not, label %if.end90, label %if.then169

if.end90:                                         ; preds = %cpumask_test_cpu.exit, %if.then78.thread
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 12
  %45 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %46, 1
  %dest_cpu = getelementptr inbounds %struct.migration_arg, ptr %data, i32 0, i32 1
  %47 = ptrtoint ptr %dest_cpu to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %dest_cpu, align 4
  br i1 %cmp.i.not, label %if.then93, label %if.else

if.then93:                                        ; preds = %if.end90
  %call.i = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %3, i32 noundef %48) #33
  br i1 %call.i, label %if.end.i, label %out

if.end.i:                                         ; preds = %if.then93
  tail call void @update_rq_clock(ptr noundef %10) #33
  %call1.i = call fastcc ptr @move_queued_task(ptr noundef %10, ptr noundef nonnull %rf, ptr noundef %3, i32 noundef %48) #33
  br label %out

if.else:                                          ; preds = %if.end90
  %wake_cpu = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 11
  %49 = ptrtoint ptr %wake_cpu to i32
  call void @__asan_store4_noabort(i32 %49)
  store i32 %48, ptr %wake_cpu, align 16
  br label %out

if.then99.critedge:                               ; preds = %if.end58
  %50 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load volatile i32, ptr %cpu.i, align 4
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 33
  %52 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %cpus_ptr, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %54 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i227 = icmp ugt i32 %54, %51
  br i1 %cmp.not.i.i.i227, label %cpumask_test_cpu.exit236, label %land.rhs.i.i.i229

land.rhs.i.i.i229:                                ; preds = %if.then99.critedge
  %.b37.i.i.i228 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i228, label %cpumask_test_cpu.exit236, label %if.then.i.i.i230, !prof !1191

if.then.i.i.i230:                                 ; preds = %land.rhs.i.i.i229
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit236

cpumask_test_cpu.exit236:                         ; preds = %if.then.i.i.i230, %land.rhs.i.i.i229, %if.then99.critedge
  %div3.i.i231 = lshr i32 %51, 5
  %arrayidx.i.i232 = getelementptr i32, ptr %53, i32 %div3.i.i231
  %55 = ptrtoint ptr %arrayidx.i.i232 to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load volatile i32, ptr %arrayidx.i.i232, align 4
  %and.i.i233 = and i32 %51, 31
  %57 = shl nuw i32 1, %and.i.i233
  %58 = and i32 %56, %57
  %tobool102.not = icmp eq i32 %58, 0
  br i1 %tobool102.not, label %if.end105, label %if.then103

if.then103:                                       ; preds = %cpumask_test_cpu.exit236
  %59 = ptrtoint ptr %migration_pending to i32
  call void @__asan_store4_noabort(i32 %59)
  store ptr null, ptr %migration_pending, align 8
  br label %if.then169

if.end105:                                        ; preds = %cpumask_test_cpu.exit236
  %stop_pending = getelementptr inbounds %struct.set_affinity_pending, ptr %1, i32 0, i32 1
  %60 = ptrtoint ptr %stop_pending to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %stop_pending, align 4
  %tobool107.not = icmp eq i32 %61, 0
  br i1 %tobool107.not, label %land.rhs117, label %if.end155

land.rhs117:                                      ; preds = %if.end105
  %.b217219 = load i1, ptr @migration_cpu_stop.__already_done.199, align 1
  br i1 %.b217219, label %if.end155, label %if.then128, !prof !1191

if.then128:                                       ; preds = %land.rhs117
  store i1 true, ptr @migration_cpu_stop.__already_done.199, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2412, i32 noundef 9, ptr noundef null) #33
  br label %if.end155

if.end155:                                        ; preds = %if.then128, %land.rhs117, %if.end105
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 25
  %62 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %63, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end155
  %64 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %64)
  store i32 4, ptr %13, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end155
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 81
  %65 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %66, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i237

if.then.i.i.i237:                                 ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 79
  %67 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i237, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %68, %if.then.i.i.i237 ], [ %10, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %69 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %69)
  %.unpack.i.i = load i32, ptr %11, align 4
  %70 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %70) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@migration_cpu_stop, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %71 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %72, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 79
  %73 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %74, %if.then.i.i4.i ], [ %10, %land.rhs.i.i.i.i ], [ %10, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %75 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %76) #33
  %77 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load ptr, ptr %stack.i, align 4
  %cpu.i239 = getelementptr inbounds %struct.thread_info, ptr %78, i32 0, i32 3
  %79 = ptrtoint ptr %cpu.i239 to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load volatile i32, ptr %cpu.i239, align 4
  %arg164 = getelementptr inbounds %struct.set_affinity_pending, ptr %1, i32 0, i32 4
  %stop_work = getelementptr inbounds %struct.set_affinity_pending, ptr %1, i32 0, i32 3
  %call165 = tail call zeroext i1 @stop_one_cpu_nowait(i32 noundef %80, ptr noundef nonnull @migration_cpu_stop, ptr noundef %arg164, ptr noundef %stop_work) #33
  br label %cleanup

out:                                              ; preds = %if.else, %if.end.i, %if.then93
  %rq.0 = phi ptr [ %10, %if.else ], [ %10, %if.then93 ], [ %call1.i, %if.end.i ]
  br i1 %tobool19.not, label %if.end171, label %if.then169

if.then169:                                       ; preds = %out, %if.then103, %cpumask_test_cpu.exit, %if.then78
  %rq.0281 = phi ptr [ %rq.0, %out ], [ %10, %cpumask_test_cpu.exit ], [ %10, %if.then103 ], [ %10, %if.then78 ]
  %complete.1.off0280 = phi i1 [ true, %out ], [ true, %cpumask_test_cpu.exit ], [ true, %if.then103 ], [ false, %if.then78 ]
  %stop_pending170 = getelementptr inbounds %struct.set_affinity_pending, ptr %1, i32 0, i32 1
  %81 = ptrtoint ptr %stop_pending170 to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 0, ptr %stop_pending170, align 4
  br label %if.end171

if.end171:                                        ; preds = %if.then169, %out, %if.then78.thread, %if.end58.thread
  %rq.0274 = phi ptr [ %rq.0281, %if.then169 ], [ %rq.0, %out ], [ %10, %if.end58.thread ], [ %10, %if.then78.thread ]
  %complete.1.off0273 = phi i1 [ %complete.1.off0280, %if.then169 ], [ false, %out ], [ false, %if.end58.thread ], [ false, %if.then78.thread ]
  %clock_update_flags.i.i240 = getelementptr inbounds %struct.rq, ptr %rq.0274, i32 0, i32 25
  %82 = ptrtoint ptr %clock_update_flags.i.i240 to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load i32, ptr %clock_update_flags.i.i240, align 4
  %cmp.i.i241 = icmp ugt i32 %83, 2
  br i1 %cmp.i.i241, label %if.then.i.i243, label %if.end.i.i246

if.then.i.i243:                                   ; preds = %if.end171
  %84 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %84)
  store i32 4, ptr %13, align 4
  br label %if.end.i.i246

if.end.i.i246:                                    ; preds = %if.then.i.i243, %if.end171
  %core_enabled.i.i.i244 = getelementptr inbounds %struct.rq, ptr %rq.0274, i32 0, i32 81
  %85 = ptrtoint ptr %core_enabled.i.i.i244 to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %core_enabled.i.i.i244, align 128
  %tobool.not.i.i.i245 = icmp eq i32 %86, 0
  br i1 %tobool.not.i.i.i245, label %rq_unpin_lock.exit.i253, label %if.then.i.i.i248

if.then.i.i.i248:                                 ; preds = %if.end.i.i246
  %core.i.i.i247 = getelementptr inbounds %struct.rq, ptr %rq.0274, i32 0, i32 79
  %87 = ptrtoint ptr %core.i.i.i247 to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load ptr, ptr %core.i.i.i247, align 8
  br label %rq_unpin_lock.exit.i253

rq_unpin_lock.exit.i253:                          ; preds = %if.then.i.i.i248, %if.end.i.i246
  %retval.0.i.i.i249 = phi ptr [ %88, %if.then.i.i.i248 ], [ %rq.0274, %if.end.i.i246 ]
  %dep_map.i.i250 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i249, i32 0, i32 4
  %89 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %89)
  %.unpack.i.i252 = load i32, ptr %11, align 4
  %90 = insertvalue [1 x i32] undef, i32 %.unpack.i.i252, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i250, [1 x i32] %90) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@migration_cpu_stop, %land.rhs.i.i.i.i255)) #33
          to label %task_rq_unlock.exit260 [label %land.rhs.i.i.i.i255], !srcloc !1202

land.rhs.i.i.i.i255:                              ; preds = %rq_unpin_lock.exit.i253
  %91 = ptrtoint ptr %core_enabled.i.i.i244 to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %core_enabled.i.i.i244, align 128
  %tobool3.i.not.i.i.i254 = icmp eq i32 %92, 0
  br i1 %tobool3.i.not.i.i.i254, label %task_rq_unlock.exit260, label %if.then.i.i4.i257

if.then.i.i4.i257:                                ; preds = %land.rhs.i.i.i.i255
  %core.i.i3.i256 = getelementptr inbounds %struct.rq, ptr %rq.0274, i32 0, i32 79
  %93 = ptrtoint ptr %core.i.i3.i256 to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load ptr, ptr %core.i.i3.i256, align 8
  br label %task_rq_unlock.exit260

task_rq_unlock.exit260:                           ; preds = %if.then.i.i4.i257, %land.rhs.i.i.i.i255, %rq_unpin_lock.exit.i253
  %retval.0.i.i5.i258 = phi ptr [ %94, %if.then.i.i4.i257 ], [ %rq.0274, %land.rhs.i.i.i.i255 ], [ %rq.0274, %rq_unpin_lock.exit.i253 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i258) #33
  %95 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %95)
  %96 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %96) #33
  br i1 %complete.1.off0273, label %if.then173, label %cleanup

if.then173:                                       ; preds = %task_rq_unlock.exit260
  %done = getelementptr inbounds %struct.set_affinity_pending, ptr %1, i32 0, i32 2
  tail call void @complete_all(ptr noundef %done) #33
  br label %cleanup

cleanup:                                          ; preds = %if.then173, %task_rq_unlock.exit260, %task_rq_unlock.exit
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @task_sched_runtime(ptr noundef %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  %curr.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 20
  %5 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %curr.i, align 8
  %cmp.i.not = icmp eq ptr %6, %p
  br i1 %cmp.i.not, label %land.lhs.true, label %if.end

land.lhs.true:                                    ; preds = %entry
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %7 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %on_rq.i, align 4
  %cmp.i13.not = icmp eq i32 %8, 1
  br i1 %cmp.i13.not, label %if.then, label %if.end

if.then:                                          ; preds = %land.lhs.true
  %cfs_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 11
  %9 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %cfs_rq.i, align 16
  %curr1.i = getelementptr inbounds %struct.cfs_rq, ptr %10, i32 0, i32 11
  %11 = ptrtoint ptr %curr1.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %curr1.i, align 8
  tail call void asm sideeffect "pld\09${0:a}", "r"(ptr %12) #33, !srcloc !1276
  %exec_start.i = getelementptr inbounds %struct.sched_entity, ptr %12, i32 0, i32 4
  tail call void asm sideeffect "pld\09${0:a}", "r"(ptr %exec_start.i) #33, !srcloc !1276
  tail call void @update_rq_clock(ptr noundef %call)
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %13 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %sched_class, align 32
  %update_curr = getelementptr inbounds %struct.sched_class, ptr %14, i32 0, i32 25
  %15 = ptrtoint ptr %update_curr to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %update_curr, align 4
  tail call void %16(ptr noundef %call) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %land.lhs.true, %entry
  %sum_exec_runtime = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 5
  %17 = ptrtoint ptr %sum_exec_runtime to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %sum_exec_runtime, align 8
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %19 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %20, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %21 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end
  %retval.0.i.i.i = phi ptr [ %22, %if.then.i.i.i ], [ %call, %if.end ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %23 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %23)
  %.unpack.i.i = load i32, ptr %1, align 4
  %24 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %24) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@task_sched_runtime, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %25 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %26, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %27 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %28, %if.then.i.i4.i ], [ %call, %land.rhs.i.i.i.i ], [ %call, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %29 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %30) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i64 %18
}

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define internal i32 @setup_resched_latency_warn_ms(ptr noundef %str) #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %val = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %val) #33
  %0 = ptrtoint ptr %val to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %val, align 4, !annotation !1193
  %call.i = call i32 @_kstrtol(ptr noundef %str, i32 noundef 0, ptr noundef nonnull %val) #33
  %tobool.not = icmp eq i32 %call.i, 0
  br i1 %tobool.not, label %if.end, label %do.end

do.end:                                           ; preds = %entry
  %call1 = call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.200) #39
  br label %cleanup

if.end:                                           ; preds = %entry
  %1 = ptrtoint ptr %val to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %val, align 4
  store i32 %2, ptr @sysctl_resched_latency_warn_ms, align 4
  br label %cleanup

cleanup:                                          ; preds = %if.end, %do.end
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %val) #33
  ret i32 1
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @scheduler_tick() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu1 = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu1, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %curr3 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 20
  %7 = ptrtoint ptr %curr3 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %curr3, align 8
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %9 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %10 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %11 = ptrtoint ptr %10 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 -1, ptr %10, align 4, !annotation !1193
  %12 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 -1, ptr %12, align 4, !annotation !1193
  call fastcc void @rq_lock(ptr noundef %6, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %6)
  %cpu.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 46
  %14 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %15
  %16 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %17, ptrtoint (ptr @thermal_pressure to i32)
  %18 = inttoptr i32 %add.i to ptr
  %19 = ptrtoint ptr %18 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %18, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %21 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i = icmp eq i32 %21, 0
  br i1 %tobool.not.i.i.i, label %lockdep_assert_rq_held.exit.i.i, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %entry
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %22 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %23, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %24 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %25, %if.then.i.i.i.i ], [ %6, %land.rhs.i.i.i ]
  %dep_map.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i, i32 0, i32 4
  %call.i.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i = icmp eq i32 %call.i.i.i.i, 0
  br i1 %cmp.not.i.i.i, label %do.end.i.i.i, label %lockdep_assert_rq_held.exit.i.i, !prof !1192

do.end.i.i.i:                                     ; preds = %__rq_lockp.exit.i.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i

lockdep_assert_rq_held.exit.i.i:                  ; preds = %do.end.i.i.i, %__rq_lockp.exit.i.i.i, %entry
  %clock_update_flags.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 25
  %26 = ptrtoint ptr %clock_update_flags.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %clock_update_flags.i.i.i, align 4
  %cmp.i.i.i = icmp ult i32 %27, 2
  br i1 %cmp.i.i.i, label %land.rhs.i3.i.i, label %rq_clock_thermal.exit

land.rhs.i3.i.i:                                  ; preds = %lockdep_assert_rq_held.exit.i.i
  %.b37.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i, label %rq_clock_thermal.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i3.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock_thermal.exit

rq_clock_thermal.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i3.i.i, %lockdep_assert_rq_held.exit.i.i
  %clock_task.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 28
  %28 = ptrtoint ptr %clock_task.i.i to i32
  call void @__asan_load8_noabort(i32 %28)
  %29 = load i64, ptr %clock_task.i.i, align 128
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sched_thermal_decay_shift to i32))
  %30 = load i32, ptr @sched_thermal_decay_shift, align 4
  %sh_prom.i = zext i32 %30 to i64
  %shr.i = lshr i64 %29, %sh_prom.i
  %conv = zext i32 %20 to i64
  %call7 = tail call i32 @update_thermal_load_avg(i64 noundef %shr.i, ptr noundef %6, i64 noundef %conv) #33
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %8, i32 0, i32 21
  %31 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %sched_class, align 32
  %task_tick = getelementptr inbounds %struct.sched_class, ptr %32, i32 0, i32 18
  %33 = ptrtoint ptr %task_tick to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %task_tick, align 4
  tail call void %34(ptr noundef %6, ptr noundef %8, i32 noundef 0) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 22), ptr blockaddress(@scheduler_tick, %if.then)) #33
          to label %if.end [label %if.then], !srcloc !1202

if.then:                                          ; preds = %rq_clock_thermal.exit
  %35 = load volatile i32, ptr @sysctl_resched_latency_warn_ms, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %36 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i35 = icmp eq i32 %36, 0
  br i1 %tobool.not.i.i.i35, label %lockdep_assert_rq_held.exit.i.i49, label %land.rhs.i.i.i38

land.rhs.i.i.i38:                                 ; preds = %if.then
  %core_enabled.i.i.i.i36 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %37 = ptrtoint ptr %core_enabled.i.i.i.i36 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %core_enabled.i.i.i.i36, align 128
  %tobool.not.i.i.i.i37 = icmp eq i32 %38, 0
  br i1 %tobool.not.i.i.i.i37, label %__rq_lockp.exit.i.i.i45, label %if.then.i.i.i.i40

if.then.i.i.i.i40:                                ; preds = %land.rhs.i.i.i38
  %core.i.i.i.i39 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %39 = ptrtoint ptr %core.i.i.i.i39 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %core.i.i.i.i39, align 8
  br label %__rq_lockp.exit.i.i.i45

__rq_lockp.exit.i.i.i45:                          ; preds = %if.then.i.i.i.i40, %land.rhs.i.i.i38
  %retval.0.i.i.i.i41 = phi ptr [ %40, %if.then.i.i.i.i40 ], [ %6, %land.rhs.i.i.i38 ]
  %dep_map.i.i.i42 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i41, i32 0, i32 4
  %call.i.i.i.i43 = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i42, i32 noundef -1) #33
  %cmp.not.i.i.i44 = icmp eq i32 %call.i.i.i.i43, 0
  br i1 %cmp.not.i.i.i44, label %do.end.i.i.i46, label %lockdep_assert_rq_held.exit.i.i49, !prof !1192

do.end.i.i.i46:                                   ; preds = %__rq_lockp.exit.i.i.i45
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i49

lockdep_assert_rq_held.exit.i.i49:                ; preds = %do.end.i.i.i46, %__rq_lockp.exit.i.i.i45, %if.then
  %41 = ptrtoint ptr %clock_update_flags.i.i.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %clock_update_flags.i.i.i, align 4
  %cmp.i.i.i48 = icmp ult i32 %42, 2
  br i1 %cmp.i.i.i48, label %land.rhs.i3.i.i51, label %rq_clock.exit.i

land.rhs.i3.i.i51:                                ; preds = %lockdep_assert_rq_held.exit.i.i49
  %.b37.i.i.i50 = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i50, label %rq_clock.exit.i, label %if.then.i.i.i52, !prof !1191

if.then.i.i.i52:                                  ; preds = %land.rhs.i3.i.i51
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i

rq_clock.exit.i:                                  ; preds = %if.then.i.i.i52, %land.rhs.i3.i.i51, %lockdep_assert_rq_held.exit.i.i49
  %clock.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 26
  %43 = ptrtoint ptr %clock.i.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %clock.i.i, align 32
  %45 = load i32, ptr @sysctl_resched_latency_warn_once, align 4
  %tobool.not.i = icmp eq i32 %45, 0
  br i1 %tobool.not.i, label %if.end.i, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %rq_clock.exit.i
  %.b28.i = load i1, ptr @cpu_resched_latency.warned_once, align 1
  br i1 %.b28.i, label %if.end, label %if.end.i

if.end.i:                                         ; preds = %land.lhs.true.i, %rq_clock.exit.i
  %46 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %46, -16384
  %47 = inttoptr i32 %and.i.i.i to ptr
  %48 = ptrtoint ptr %47 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load volatile i32, ptr %47, align 16384
  %50 = and i32 %49, 2
  %tobool.i.not.i = icmp eq i32 %50, 0
  %tobool3.not.i = icmp eq i32 %35, 0
  %or.cond.i = select i1 %tobool.i.not.i, i1 true, i1 %tobool3.not.i
  br i1 %or.cond.i, label %if.end, label %if.end5.i

if.end5.i:                                        ; preds = %if.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @system_state to i32))
  %51 = load i32, ptr @system_state, align 4
  %cmp.i = icmp eq i32 %51, 0
  br i1 %cmp.i, label %if.end, label %if.end7.i

if.end7.i:                                        ; preds = %if.end5.i
  %last_seen_need_resched_ns.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 32
  %52 = ptrtoint ptr %last_seen_need_resched_ns.i to i32
  call void @__asan_load8_noabort(i32 %52)
  %53 = load i64, ptr %last_seen_need_resched_ns.i, align 8
  %tobool8.not.i = icmp eq i64 %53, 0
  br i1 %tobool8.not.i, label %if.then9.i, label %if.end11.i

if.then9.i:                                       ; preds = %if.end7.i
  %54 = ptrtoint ptr %last_seen_need_resched_ns.i to i32
  call void @__asan_store8_noabort(i32 %54)
  store i64 %44, ptr %last_seen_need_resched_ns.i, align 8
  %ticks_without_resched.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 33
  %55 = ptrtoint ptr %ticks_without_resched.i to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 0, ptr %ticks_without_resched.i, align 32
  br label %if.end

if.end11.i:                                       ; preds = %if.end7.i
  %ticks_without_resched12.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 33
  %56 = ptrtoint ptr %ticks_without_resched12.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %ticks_without_resched12.i, align 32
  %inc.i = add i32 %57, 1
  store i32 %inc.i, ptr %ticks_without_resched12.i, align 32
  %sub.i = sub i64 %44, %53
  %mul.i = mul i32 %35, 1000000
  %conv.i = sext i32 %mul.i to i64
  %cmp14.not.i = icmp ugt i64 %sub.i, %conv.i
  br i1 %cmp14.not.i, label %if.end17.i, label %if.end

if.end17.i:                                       ; preds = %if.end11.i
  store i1 true, ptr @cpu_resched_latency.warned_once, align 1
  br label %if.end

if.end:                                           ; preds = %if.end17.i, %if.end11.i, %if.then9.i, %if.end5.i, %if.end.i, %land.lhs.true.i, %rq_clock_thermal.exit
  %resched_latency.0 = phi i64 [ -1, %rq_clock_thermal.exit ], [ %sub.i, %if.end17.i ], [ 0, %if.then9.i ], [ 0, %land.lhs.true.i ], [ 0, %if.end.i ], [ 0, %if.end5.i ], [ 0, %if.end11.i ]
  tail call void @calc_global_load_tick(ptr noundef %6) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@scheduler_tick, %land.rhs.i.i)) #33
          to label %sched_core_tick.exit [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %if.end
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %58 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i = icmp eq i32 %59, 0
  br i1 %tobool3.i.not.i, label %sched_core_tick.exit, label %land.lhs.true.i53

land.lhs.true.i53:                                ; preds = %land.rhs.i.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@scheduler_tick, %if.then.i)) #33
          to label %sched_core_tick.exit [label %if.then.i], !srcloc !1202

if.then.i:                                        ; preds = %land.lhs.true.i53
  tail call void @__sched_core_tick(ptr noundef %6) #33
  br label %sched_core_tick.exit

sched_core_tick.exit:                             ; preds = %if.then.i, %land.lhs.true.i53, %land.rhs.i.i, %if.end
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 81
  %60 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i55 = icmp eq i32 %61, 0
  br i1 %tobool.not.i.i.i55, label %rq_unpin_lock.exit.i, label %if.then.i.i.i56

if.then.i.i.i56:                                  ; preds = %sched_core_tick.exit
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %62 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i56, %sched_core_tick.exit
  %retval.0.i.i.i57 = phi ptr [ %63, %if.then.i.i.i56 ], [ %6, %sched_core_tick.exit ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i57, i32 0, i32 4
  %64 = ptrtoint ptr %10 to i32
  call void @__asan_load4_noabort(i32 %64)
  %.unpack.i.i = load i32, ptr %10, align 4
  %65 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %65) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@scheduler_tick, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %66 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %67, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 79
  %68 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %69, %if.then.i.i3.i ], [ %6, %land.rhs.i.i.i.i ], [ %6, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 22), ptr blockaddress(@scheduler_tick, %l_yes.i.i.i32)) #33
          to label %static_branch_LATENCY_WARN.exit34 [label %l_yes.i.i.i32], !srcloc !1202

l_yes.i.i.i32:                                    ; preds = %rq_unlock.exit
  br label %static_branch_LATENCY_WARN.exit34

static_branch_LATENCY_WARN.exit34:                ; preds = %l_yes.i.i.i32, %rq_unlock.exit
  %retval.0.i.i.i33 = phi i1 [ false, %l_yes.i.i.i32 ], [ true, %rq_unlock.exit ]
  %tobool.not = icmp eq i64 %resched_latency.0, 0
  %or.cond = select i1 %retval.0.i.i.i33, i1 true, i1 %tobool.not
  br i1 %or.cond, label %if.end13, label %if.then12

if.then12:                                        ; preds = %static_branch_LATENCY_WARN.exit34
  tail call void @resched_latency_warn(i32 noundef %3, i64 noundef %resched_latency.0) #33
  br label %if.end13

if.end13:                                         ; preds = %if.then12, %static_branch_LATENCY_WARN.exit34
  tail call void @perf_event_task_tick() #33
  %70 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load i32, ptr %arrayidx, align 4
  %add.i59 = add i32 %71, ptrtoint (ptr @runqueues to i32)
  %72 = inttoptr i32 %add.i59 to ptr
  %curr.i = getelementptr inbounds %struct.rq, ptr %72, i32 0, i32 20
  %73 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %curr.i, align 8
  %idle.i = getelementptr inbounds %struct.rq, ptr %72, i32 0, i32 21
  %75 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load ptr, ptr %idle.i, align 4
  %cmp.not.i = icmp eq ptr %74, %76
  br i1 %cmp.not.i, label %if.end.i61, label %idle_cpu.exit

if.end.i61:                                       ; preds = %if.end13
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %72, i32 0, i32 1
  %77 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %nr_running.i, align 4
  %tobool.not.i60 = icmp eq i32 %78, 0
  br i1 %tobool.not.i60, label %if.end3.i, label %idle_cpu.exit

if.end3.i:                                        ; preds = %if.end.i61
  %ttwu_pending.i = getelementptr inbounds %struct.rq, ptr %72, i32 0, i32 8
  %79 = ptrtoint ptr %ttwu_pending.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %ttwu_pending.i, align 8
  %tobool4.not.i = icmp eq i32 %80, 0
  %phi.cast = zext i1 %tobool4.not.i to i8
  br label %idle_cpu.exit

idle_cpu.exit:                                    ; preds = %if.end3.i, %if.end.i61, %if.end13
  %retval.0.i62 = phi i8 [ 0, %if.end13 ], [ 0, %if.end.i61 ], [ %phi.cast, %if.end3.i ]
  %idle_balance = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 41
  %81 = ptrtoint ptr %idle_balance to i32
  call void @__asan_store1_noabort(i32 %81)
  store i8 %retval.0.i62, ptr %idle_balance, align 1
  tail call void @trigger_load_balance(ptr noundef %6) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rq_lock(ptr noundef %rq, ptr nocapture noundef writeonly %rf) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@rq_lock, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %entry
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %4 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %5, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %6 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %7, %if.then.i.i.i ], [ %rq, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %8 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %10 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %11, %if.then.i25.i.i ], [ %rq, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %12 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %15, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %16 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %17, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i2

if.then.i.i2:                                     ; preds = %raw_spin_rq_lock.exit
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %18 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i2, %raw_spin_rq_lock.exit
  %retval.0.i.i = phi ptr [ %19, %if.then.i.i2 ], [ %rq, %raw_spin_rq_lock.exit ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call1.i = tail call i32 @lock_pin_lock(ptr noundef %dep_map.i) #33
  %20 = ptrtoint ptr %cookie.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 %call1.i, ptr %cookie.i, align 4
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %21 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %clock_update_flags.i, align 4
  %and.i = and i32 %22, 3
  store i32 %and.i, ptr %clock_update_flags.i, align 4
  %clock_update_flags2.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %23 = ptrtoint ptr %clock_update_flags2.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 0, ptr %clock_update_flags2.i, align 4
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %24 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %balance_callback.i, align 8
  %tobool.not.i = icmp ne ptr %25, null
  %cmp.i = icmp ne ptr %25, @balance_push_callback
  %spec.select.i = and i1 %tobool.not.i, %cmp.i
  br i1 %spec.select.i, label %land.rhs6.i, label %rq_pin_lock.exit

land.rhs6.i:                                      ; preds = %__rq_lockp.exit.i
  %.b48.i = load i1, ptr @rq_pin_lock.__already_done, align 1
  br i1 %.b48.i, label %rq_pin_lock.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs6.i
  store i1 true, ptr @rq_pin_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1545, i32 noundef 9, ptr noundef nonnull @.str.178) #33
  br label %rq_pin_lock.exit

rq_pin_lock.exit:                                 ; preds = %if.then.i, %land.rhs6.i, %__rq_lockp.exit.i
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @update_thermal_load_avg(i64 noundef, ptr noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @calc_global_load_tick(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @resched_latency_warn(i32 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @perf_event_task_tick() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @trigger_load_balance(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @queue_core_balance(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@queue_core_balance, %land.rhs.i)) #33
          to label %return [label %land.rhs.i], !srcloc !1202

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i, align 128
  %tobool3.i.not = icmp eq i32 %1, 0
  br i1 %tobool3.i.not, label %return, label %if.end

if.end:                                           ; preds = %land.rhs.i
  %core = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core, align 8
  %core_cookie = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 86
  %4 = ptrtoint ptr %core_cookie to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_cookie, align 4
  %tobool.not = icmp eq i32 %5, 0
  br i1 %tobool.not, label %return, label %if.end2

if.end2:                                          ; preds = %if.end
  %nr_running = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %6 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %nr_running, align 4
  %tobool3.not = icmp eq i32 %7, 0
  br i1 %tobool3.not, label %return, label %if.end5

if.end5:                                          ; preds = %if.end2
  %cpu = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @core_balance_head to i32)
  %12 = inttoptr i32 %add to ptr
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %13 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i.i, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %if.end5
  %14 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %15, 0
  %spec.select = select i1 %tobool.not.i.i.i, ptr %rq, ptr %3
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %spec.select, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %land.rhs.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %land.rhs.i.i, %if.end5
  %16 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %12, align 4
  %tobool.not.i = icmp eq ptr %17, null
  br i1 %tobool.not.i, label %lor.rhs.i, label %return, !prof !1191

lor.rhs.i:                                        ; preds = %lockdep_assert_rq_held.exit.i
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %18 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %balance_callback.i, align 8
  %cmp.i = icmp eq ptr %19, @balance_push_callback
  br i1 %cmp.i, label %return, label %if.end.i, !prof !1192

if.end.i:                                         ; preds = %lor.rhs.i
  %func3.i = getelementptr inbounds %struct.callback_head, ptr %12, i32 0, i32 1
  %20 = ptrtoint ptr %func3.i to i32
  call void @__asan_store4_noabort(i32 %20)
  store ptr @sched_core_balance, ptr %func3.i, align 4
  %21 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %balance_callback.i, align 8
  %23 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %23)
  store ptr %22, ptr %12, align 4
  store ptr %12, ptr %balance_callback.i, align 8
  br label %return

return:                                           ; preds = %if.end.i, %lor.rhs.i, %lockdep_assert_rq_held.exit.i, %if.end2, %if.end, %land.rhs.i, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @sched_core_balance(ptr noundef %rq) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %0 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %cpu.i, align 4
  %2 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1277
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 1
  %8 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %9, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_core_balance, %land.rhs.i.i.i.i)) #33
          to label %raw_spin_rq_unlock_irq.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rcu_read_lock.exit
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %10 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %11, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock_irq.exit, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %12 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %core.i.i.i, align 8
  br label %raw_spin_rq_unlock_irq.exit

raw_spin_rq_unlock_irq.exit:                      ; preds = %if.then.i.i.i, %land.rhs.i.i.i.i, %rcu_read_lock.exit
  %retval.0.i.i.i = phi ptr [ %13, %if.then.i.i.i ], [ %rq, %land.rhs.i.i.i.i ], [ %rq, %rcu_read_lock.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %1
  %14 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx, align 4
  %add = add i32 %15, ptrtoint (ptr @runqueues to i32)
  %16 = inttoptr i32 %add to ptr
  %sd9 = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 36
  %17 = ptrtoint ptr %sd9 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile ptr, ptr %sd9, align 4
  %call.i39 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @sched_domains_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool.not = icmp eq i32 %call.i39, 0
  br i1 %tobool.not, label %lor.lhs.false, label %do.end19

lor.lhs.false:                                    ; preds = %raw_spin_rq_unlock_irq.exit
  %call12 = tail call i32 @rcu_read_lock_held() #33
  %tobool13.not = icmp eq i32 %call12, 0
  br i1 %tobool13.not, label %land.lhs.true, label %do.end19

land.lhs.true:                                    ; preds = %lor.lhs.false
  %call14 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool15.not = icmp eq i32 %call14, 0
  br i1 %tobool15.not, label %do.end19, label %land.lhs.true16

land.lhs.true16:                                  ; preds = %land.lhs.true
  %.b36 = load i1, ptr @sched_core_balance.__warned, align 1
  br i1 %.b36, label %do.end19, label %if.then

if.then:                                          ; preds = %land.lhs.true16
  store i1 true, ptr @sched_core_balance.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 5977, ptr noundef nonnull @.str.3) #33
  br label %do.end19

do.end19:                                         ; preds = %if.then, %land.lhs.true16, %land.lhs.true, %lor.lhs.false, %raw_spin_rq_unlock_irq.exit
  %tobool21.not60 = icmp eq ptr %18, null
  br i1 %tobool21.not60, label %for.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %do.end19
  %sub.i40 = add i32 %1, -1
  br label %for.body

for.body:                                         ; preds = %for.inc, %for.body.lr.ph
  %sd.061 = phi ptr [ %18, %for.body.lr.ph ], [ %32, %for.inc ]
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %21 = ptrtoint ptr %20 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %20, align 16384
  %23 = and i32 %22, 2
  %tobool.i.not = icmp eq i32 %23, 0
  br i1 %tobool.i.not, label %if.end24, label %for.end

if.end24:                                         ; preds = %for.body
  %span.i.i = getelementptr inbounds %struct.sched_domain, ptr %sd.061, i32 0, i32 41
  %call1.i41 = tail call i32 @cpumask_next_wrap(i32 noundef %sub.i40, ptr noundef %span.i.i, i32 noundef %1, i1 noundef zeroext false) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %24 = load i32, ptr @nr_cpu_ids, align 4
  %cmp20.i = icmp ult i32 %call1.i41, %24
  br i1 %cmp20.i, label %for.body.i, label %for.inc

for.body.i:                                       ; preds = %for.inc.i, %if.end24
  %i.021.i = phi i32 [ %call10.i, %for.inc.i ], [ %call1.i41, %if.end24 ]
  %cmp2.i = icmp eq i32 %i.021.i, %1
  br i1 %cmp2.i, label %for.inc.i, label %if.end.i

if.end.i:                                         ; preds = %for.body.i
  %25 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i42 = and i32 %25, -16384
  %26 = inttoptr i32 %and.i.i.i42 to ptr
  %27 = ptrtoint ptr %26 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load volatile i32, ptr %26, align 16384
  %29 = and i32 %28, 2
  %tobool.i.not.i = icmp eq i32 %29, 0
  br i1 %tobool.i.not.i, label %if.end5.i, label %for.inc

if.end5.i:                                        ; preds = %if.end.i
  %call6.i = tail call fastcc zeroext i1 @try_steal_cookie(i32 noundef %1, i32 noundef %i.021.i) #33
  br i1 %call6.i, label %for.end, label %for.inc.i

for.inc.i:                                        ; preds = %if.end5.i, %for.body.i
  %call10.i = tail call i32 @cpumask_next_wrap(i32 noundef %i.021.i, ptr noundef %span.i.i, i32 noundef %1, i1 noundef zeroext true) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %30 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.i = icmp ult i32 %call10.i, %30
  br i1 %cmp.i, label %for.body.i, label %for.inc

for.inc:                                          ; preds = %for.inc.i, %if.end.i, %if.end24
  %31 = ptrtoint ptr %sd.061 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %sd.061, align 8
  %tobool21.not = icmp eq ptr %32, null
  br i1 %tobool21.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc, %if.end5.i, %for.body, %do.end19
  %33 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i43 = and i32 %33, 128
  %tobool.not.i44 = icmp eq i32 %and.i.i.i43, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool.not.i44, label %if.then.i45, label %if.end.i46

if.then.i45:                                      ; preds = %for.end
  tail call void @trace_hardirqs_off() #33
  br label %if.end.i46

if.end.i46:                                       ; preds = %if.then.i45, %for.end
  %34 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 1
  %36 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %37, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_core_balance, %for.cond.i.i.i)) #33
          to label %if.then.i.i.i47 [label %for.cond.i.i.i], !srcloc !1202

if.then.i.i.i47:                                  ; preds = %if.end.i46
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock_irq.exit

for.cond.i.i.i:                                   ; preds = %if.end11.i.i.i, %if.end.i46
  %core_enabled.i.i.i.i48 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %38 = ptrtoint ptr %core_enabled.i.i.i.i48 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %core_enabled.i.i.i.i48, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %39, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %for.cond.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %40 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %for.cond.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %41, %if.then.i.i.i.i ], [ %rq, %for.cond.i.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i.i, i32 noundef 0) #33
  %42 = ptrtoint ptr %core_enabled.i.i.i.i48 to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %core_enabled.i.i.i.i48, align 128
  %tobool.not.i23.i.i.i = icmp eq i32 %43, 0
  br i1 %tobool.not.i23.i.i.i, label %__rq_lockp.exit27.i.i.i, label %if.then.i25.i.i.i

if.then.i25.i.i.i:                                ; preds = %__rq_lockp.exit.i.i.i
  %core.i24.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %44 = ptrtoint ptr %core.i24.i.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %core.i24.i.i.i, align 8
  br label %__rq_lockp.exit27.i.i.i

__rq_lockp.exit27.i.i.i:                          ; preds = %if.then.i25.i.i.i, %__rq_lockp.exit.i.i.i
  %retval.0.i26.i.i.i = phi ptr [ %45, %if.then.i25.i.i.i ], [ %rq, %__rq_lockp.exit.i.i.i ]
  %cmp.i.i.i = icmp eq ptr %retval.0.i.i.i.i, %retval.0.i26.i.i.i
  br i1 %cmp.i.i.i, label %do.body8.i.i.i, label %if.end11.i.i.i, !prof !1191

do.body8.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock_irq.exit

if.end11.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  br label %for.cond.i.i.i

raw_spin_rq_lock_irq.exit:                        ; preds = %do.body8.i.i.i, %if.then.i.i.i47
  %46 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i.i = and i32 %46, -16384
  %47 = inttoptr i32 %and.i.i.i19.i.i.i to ptr
  %preempt_count.i.i20.i.i.i = getelementptr inbounds %struct.thread_info, ptr %47, i32 0, i32 1
  %48 = ptrtoint ptr %preempt_count.i.i20.i.i.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load volatile i32, ptr %preempt_count.i.i20.i.i.i, align 4
  %sub.i21.i.i.i = add i32 %49, -1
  store volatile i32 %sub.i21.i.i.i, ptr %preempt_count.i.i20.i.i.i, align 4
  %call.i49 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i49, label %rcu_read_unlock.exit, label %land.lhs.true.i52

land.lhs.true.i52:                                ; preds = %raw_spin_rq_lock_irq.exit
  %call1.i50 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i51 = icmp eq i32 %call1.i50, 0
  br i1 %tobool.not.i51, label %rcu_read_unlock.exit, label %land.lhs.true2.i54

land.lhs.true2.i54:                               ; preds = %land.lhs.true.i52
  %.b4.i53 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i53, label %rcu_read_unlock.exit, label %if.then.i55

if.then.i55:                                      ; preds = %land.lhs.true2.i54
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i55, %land.lhs.true2.i54, %land.lhs.true.i52, %raw_spin_rq_lock_irq.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %50 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i56 = and i32 %50, -16384
  %51 = inttoptr i32 %and.i.i.i.i.i56 to ptr
  %preempt_count.i.i.i.i57 = getelementptr inbounds %struct.thread_info, ptr %51, i32 0, i32 1
  %52 = ptrtoint ptr %preempt_count.i.i.i.i57 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load volatile i32, ptr %preempt_count.i.i.i.i57, align 4
  %sub.i.i.i = add i32 %53, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i57, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1280
  %54 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i37 = and i32 %54, -16384
  %55 = inttoptr i32 %and.i.i.i37 to ptr
  %preempt_count.i.i38 = getelementptr inbounds %struct.thread_info, ptr %55, i32 0, i32 1
  %56 = ptrtoint ptr %preempt_count.i.i38 to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load volatile i32, ptr %preempt_count.i.i38, align 4
  %sub.i = add i32 %57, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i38, align 4
  ret void
}

; Function Attrs: noreturn nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @do_task_dead() #14 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 128
  %call2 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  br label %__here

__here:                                           ; preds = %entry
  %4 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task, align 8
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 212
  %6 = ptrtoint ptr %task_state_change to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 ptrtoint (ptr blockaddress(@do_task_dead, %__here) to i32), ptr %task_state_change, align 4
  %7 = load ptr, ptr %task, align 8
  %8 = ptrtoint ptr %7 to i32
  call void @__asan_store4_noabort(i32 %8)
  store volatile i32 128, ptr %7, align 128
  %9 = load ptr, ptr %task, align 8
  %pi_lock65 = getelementptr inbounds %struct.task_struct, ptr %9, i32 0, i32 128
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock65, i32 noundef %call2) #33
  %10 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %task, align 8
  %flags72 = getelementptr inbounds %struct.task_struct, ptr %11, i32 0, i32 3
  %12 = ptrtoint ptr %flags72 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %flags72, align 4
  %or = or i32 %13, 32768
  store i32 %or, ptr %flags72, align 4
  tail call fastcc void @__schedule(i32 noundef 0)
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 6323, 0\0A.popsection", ""() #33, !srcloc !1281
  unreachable
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__schedule(i32 noundef %sched_mode) unnamed_addr #0 section ".sched.text" align 64 {
entry:
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i143 = and i32 %5, -16384
  %6 = inttoptr i32 %and.i143 to ptr
  %cpu1 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu1 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu1, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @runqueues to i32)
  %11 = inttoptr i32 %add to ptr
  %curr = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 20
  %12 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %curr, align 8
  %tobool = icmp ne i32 %sched_mode, 0
  tail call fastcc void @schedule_debug(ptr noundef %13, i1 noundef zeroext %tobool)
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 6), ptr blockaddress(@__schedule, %if.then)) #33
          to label %lor.lhs.false [label %if.then], !srcloc !1202

lor.lhs.false:                                    ; preds = %entry
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 7), ptr blockaddress(@__schedule, %if.then)) #33
          to label %do.body6 [label %if.then], !srcloc !1202

if.then:                                          ; preds = %lor.lhs.false, %entry
  %hrtick_timer.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 66
  %call.i144 = tail call zeroext i1 @hrtimer_active(ptr noundef %hrtick_timer.i) #33
  br i1 %call.i144, label %if.then.i145, label %do.body6

if.then.i145:                                     ; preds = %if.then
  %call2.i = tail call i32 @hrtimer_cancel(ptr noundef %hrtick_timer.i) #33
  br label %do.body6

do.body6:                                         ; preds = %if.then.i145, %if.then, %lor.lhs.false
  %14 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i = and i32 %14, 128
  %tobool8.not = icmp eq i32 %and.i.i, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool8.not, label %if.then10, label %if.end11

if.then10:                                        ; preds = %do.body6
  tail call void @trace_hardirqs_off() #33
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %do.body6
  tail call void @rcu_note_context_switch(i1 noundef zeroext %tobool) #33
  call fastcc void @rq_lock(ptr noundef %11, ptr noundef nonnull %rf)
  %clock_update_flags = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 25
  %15 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %clock_update_flags, align 4
  %shl = shl i32 %16, 1
  store i32 %shl, ptr %clock_update_flags, align 4
  tail call void @update_rq_clock(ptr noundef %11)
  %nivcsw = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 91
  %17 = ptrtoint ptr %13 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %13, align 128
  %tobool25.not = icmp eq i32 %18, 0
  %or.cond = select i1 %tobool, i1 true, i1 %tobool25.not
  br i1 %or.cond, label %if.end62, label %if.then26

if.then26:                                        ; preds = %if.end11
  %and.i146 = and i32 %18, 257
  %tobool.not.i147 = icmp eq i32 %and.i146, 0
  br i1 %tobool.not.i147, label %if.else, label %if.end.i

if.end.i:                                         ; preds = %if.then26
  %stack.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 1
  %19 = ptrtoint ptr %stack.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %stack.i.i.i, align 4
  %21 = ptrtoint ptr %20 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %20, align 4
  %23 = and i32 %22, 256
  %tobool.not.i.i = icmp eq i32 %23, 0
  br i1 %tobool.not.i.i, label %signal_pending.exit.i, label %if.end3.i, !prof !1191

signal_pending.exit.i:                            ; preds = %if.end.i
  %24 = ptrtoint ptr %20 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %20, align 4
  %and1.i.i.i.i.i.i = and i32 %25, 1
  %tobool1.not.i = icmp eq i32 %and1.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i, label %if.else, label %if.end3.i

if.end3.i:                                        ; preds = %signal_pending.exit.i, %if.end.i
  %and4.i = and i32 %18, 1
  %tobool5.not.i = icmp eq i32 %and4.i, 0
  br i1 %tobool5.not.i, label %signal_pending_state.exit, label %do.body34

signal_pending_state.exit:                        ; preds = %if.end3.i
  %signal.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 116, i32 1
  %26 = ptrtoint ptr %signal.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %signal.i.i, align 4
  %28 = and i32 %27, 256
  %tobool28.not = icmp eq i32 %28, 0
  br i1 %tobool28.not, label %if.else, label %do.body34

do.body34:                                        ; preds = %signal_pending_state.exit, %if.end3.i
  %29 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %29)
  store volatile i32 0, ptr %13, align 128
  br label %if.end61

if.else:                                          ; preds = %signal_pending_state.exit, %signal_pending.exit.i, %if.then26
  %30 = and i32 %18, 1026
  %31 = icmp eq i32 %30, 2
  br i1 %31, label %land.end, label %land.end.thread

land.end.thread:                                  ; preds = %if.else
  %sched_contributes_to_load168 = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 63
  %32 = ptrtoint ptr %sched_contributes_to_load168 to i32
  call void @__asan_load1_noabort(i32 %32)
  %bf.load169 = load i8, ptr %sched_contributes_to_load168, align 4
  %bf.clear170 = and i8 %bf.load169, -65
  store i8 %bf.clear170, ptr %sched_contributes_to_load168, align 4
  br label %if.end53

land.end:                                         ; preds = %if.else
  %flags = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 3
  %33 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %flags, align 4
  %and45 = lshr i32 %34, 10
  %35 = trunc i32 %and45 to i8
  %36 = and i8 %35, 64
  %37 = xor i8 %36, 64
  %sched_contributes_to_load = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 63
  %38 = ptrtoint ptr %sched_contributes_to_load to i32
  call void @__asan_load1_noabort(i32 %38)
  %bf.load = load i8, ptr %sched_contributes_to_load, align 4
  %bf.clear = and i8 %bf.load, -65
  %bf.set = or i8 %37, %bf.clear
  store i8 %bf.set, ptr %sched_contributes_to_load, align 4
  %tobool51.not = icmp eq i8 %37, 0
  br i1 %tobool51.not, label %if.end53, label %if.then52

if.then52:                                        ; preds = %land.end
  %nr_uninterruptible = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 19
  %39 = ptrtoint ptr %nr_uninterruptible to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %nr_uninterruptible, align 4
  %inc = add i32 %40, 1
  store i32 %inc, ptr %nr_uninterruptible, align 4
  br label %if.end53

if.end53:                                         ; preds = %if.then52, %land.end, %land.end.thread
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 12
  %41 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 0, ptr %on_rq.i, align 4
  tail call fastcc void @dequeue_task(ptr noundef %11, ptr noundef %13, i32 noundef 9) #33
  %in_iowait = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 65
  %42 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %42)
  %bf.load54 = load i16, ptr %in_iowait, align 8
  %43 = and i16 %bf.load54, 8192
  %tobool58.not = icmp eq i16 %43, 0
  br i1 %tobool58.not, label %if.end61, label %if.then59

if.then59:                                        ; preds = %if.end53
  %nr_iowait = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 31
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %nr_iowait, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %nr_iowait, i32 1, i32 3, i32 1) #33
  %44 = tail call { i32, i32 } asm sideeffect "@ atomic_add\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %nr_iowait, ptr %nr_iowait, i32 1, ptr elementtype(i32) %nr_iowait) #33, !srcloc !1200
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @delayacct_key, ptr blockaddress(@__schedule, %if.end.i150)) #33
          to label %if.end61 [label %if.end.i150], !srcloc !1202

if.end.i150:                                      ; preds = %if.then59
  %45 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i148 = and i32 %45, -16384
  %46 = inttoptr i32 %and.i.i148 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %46, i32 0, i32 2
  %47 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %task.i, align 8
  %delays.i = getelementptr inbounds %struct.task_struct, ptr %48, i32 0, i32 181
  %49 = ptrtoint ptr %delays.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load ptr, ptr %delays.i, align 8
  %tobool4.not.i149 = icmp eq ptr %50, null
  br i1 %tobool4.not.i149, label %if.end61, label %if.then5.i151

if.then5.i151:                                    ; preds = %if.end.i150
  tail call void @__delayacct_blkio_start() #33
  br label %if.end61

if.end61:                                         ; preds = %if.then5.i151, %if.end.i150, %if.then59, %if.end53, %do.body34
  %nvcsw = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 90
  br label %if.end62

if.end62:                                         ; preds = %if.end61, %if.end11
  %switch_count.0 = phi ptr [ %nivcsw, %if.end11 ], [ %nvcsw, %if.end61 ]
  %call63 = call fastcc ptr @pick_next_task(ptr noundef %11, ptr noundef %13, ptr noundef nonnull %rf)
  %stack.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 1
  %51 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %stack.i.i, align 4
  call void @_clear_bit(i32 noundef 1, ptr noundef %52) #33
  %last_seen_need_resched_ns = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 32
  %53 = ptrtoint ptr %last_seen_need_resched_ns to i32
  call void @__asan_store8_noabort(i32 %53)
  store i64 0, ptr %last_seen_need_resched_ns, align 8
  %cmp.not = icmp eq ptr %13, %call63
  br i1 %cmp.not, label %if.else90, label %if.then67, !prof !1192

if.then67:                                        ; preds = %if.end62
  %nr_switches = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 9
  %54 = ptrtoint ptr %nr_switches to i32
  call void @__asan_load8_noabort(i32 %54)
  %55 = load i64, ptr %nr_switches, align 32
  %inc68 = add i64 %55, 1
  store i64 %inc68, ptr %nr_switches, align 32
  %56 = ptrtoint ptr %curr to i32
  call void @__asan_store4_noabort(i32 %56)
  store volatile ptr %call63, ptr %curr, align 8
  %57 = ptrtoint ptr %switch_count.0 to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %switch_count.0, align 4
  %inc82 = add i32 %58, 1
  store i32 %inc82, ptr %switch_count.0, align 4
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 37
  %59 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %59)
  %60 = load i16, ptr %migration_disabled.i, align 4
  %tobool.not.i152 = icmp eq i16 %60, 0
  br i1 %tobool.not.i152, label %migrate_disable_switch.exit, label %if.end.i153, !prof !1191

if.end.i153:                                      ; preds = %if.then67
  %cpus_ptr.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 33
  %61 = ptrtoint ptr %cpus_ptr.i to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load ptr, ptr %cpus_ptr.i, align 4
  %cpus_mask.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 35
  %cmp.not.i = icmp eq ptr %62, %cpus_mask.i
  br i1 %cmp.not.i, label %if.end5.i, label %migrate_disable_switch.exit

if.end5.i:                                        ; preds = %if.end.i153
  %cpu.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 46
  %63 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load i32, ptr %cpu.i, align 4
  %rem.i.i = and i32 %64, 31
  %add.i.i = add nuw nsw i32 %rem.i.i, 1
  %arrayidx.i.i = getelementptr [33 x [1 x i32]], ptr @cpu_bit_bitmap, i32 0, i32 %add.i.i
  %div3.i.i = lshr i32 %64, 5
  %idx.neg.i.i = sub nsw i32 0, %div3.i.i
  %add.ptr.i.i = getelementptr i32, ptr %arrayidx.i.i, i32 %idx.neg.i.i
  call fastcc void @__do_set_cpus_allowed(ptr noundef %13, ptr noundef %add.ptr.i.i, i32 noundef 2) #33
  br label %migrate_disable_switch.exit

migrate_disable_switch.exit:                      ; preds = %if.end5.i, %if.end.i153, %if.then67
  %on_rq.i154 = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 12
  %65 = ptrtoint ptr %on_rq.i154 to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %on_rq.i154, align 4
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @psi_disabled, i32 1), ptr blockaddress(@__schedule, %if.end.i155)) #33
          to label %psi_sched_switch.exit [label %if.end.i155], !srcloc !1232

if.end.i155:                                      ; preds = %migrate_disable_switch.exit
  %cmp.i = icmp ne i32 %66, 1
  call void @psi_task_switch(ptr noundef %13, ptr noundef %call63, i1 noundef zeroext %cmp.i) #33
  br label %psi_sched_switch.exit

psi_sched_switch.exit:                            ; preds = %if.end.i155, %migrate_disable_switch.exit
  call fastcc void @trace_sched_switch(i1 noundef zeroext %tobool, ptr noundef %13, ptr noundef %call63)
  %kcov_mode.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 195
  %67 = ptrtoint ptr %kcov_mode.i.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %kcov_mode.i.i, align 8
  %or.i.i = or i32 %68, 1073741824
  store i32 %or.i.i, ptr %kcov_mode.i.i, align 8
  %idle.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 21
  %69 = ptrtoint ptr %idle.i.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load ptr, ptr %idle.i.i.i, align 4
  %cmp.not.i.i.i = icmp eq ptr %70, %13
  br i1 %cmp.not.i.i.i, label %if.end.i.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %psi_sched_switch.exit
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %71 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i.i.i.i = icmp eq i32 %71, 0
  br i1 %tobool.not.i.i.i.i.i.i, label %lockdep_assert_rq_held.exit.i.i.i.i.i, label %land.rhs.i.i.i.i.i.i

land.rhs.i.i.i.i.i.i:                             ; preds = %if.then.i.i.i
  %core_enabled.i.i.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 81
  %72 = ptrtoint ptr %core_enabled.i.i.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load i32, ptr %core_enabled.i.i.i.i.i.i.i, align 128
  %tobool.not.i.i.i.i.i.i.i = icmp eq i32 %73, 0
  br i1 %tobool.not.i.i.i.i.i.i.i, label %__rq_lockp.exit.i.i.i.i.i.i, label %if.then.i.i.i.i.i.i.i

if.then.i.i.i.i.i.i.i:                            ; preds = %land.rhs.i.i.i.i.i.i
  %core.i.i.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 79
  %74 = ptrtoint ptr %core.i.i.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load ptr, ptr %core.i.i.i.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i.i.i.i

__rq_lockp.exit.i.i.i.i.i.i:                      ; preds = %if.then.i.i.i.i.i.i.i, %land.rhs.i.i.i.i.i.i
  %retval.0.i.i.i.i.i.i.i = phi ptr [ %75, %if.then.i.i.i.i.i.i.i ], [ %11, %land.rhs.i.i.i.i.i.i ]
  %dep_map.i.i.i.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i.i.i.i, i32 0, i32 4
  %call.i.i.i.i.i.i.i = call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i.i.i.i = icmp eq i32 %call.i.i.i.i.i.i.i, 0
  br i1 %cmp.not.i.i.i.i.i.i, label %do.end.i.i.i.i.i.i, label %lockdep_assert_rq_held.exit.i.i.i.i.i, !prof !1192

do.end.i.i.i.i.i.i:                               ; preds = %__rq_lockp.exit.i.i.i.i.i.i
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i.i.i.i

lockdep_assert_rq_held.exit.i.i.i.i.i:            ; preds = %do.end.i.i.i.i.i.i, %__rq_lockp.exit.i.i.i.i.i.i, %if.then.i.i.i
  %76 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load i32, ptr %clock_update_flags, align 4
  %cmp.i.i.i.i.i.i = icmp ult i32 %77, 2
  br i1 %cmp.i.i.i.i.i.i, label %land.rhs.i3.i.i.i.i.i, label %rq_clock.exit.i.i.i.i

land.rhs.i3.i.i.i.i.i:                            ; preds = %lockdep_assert_rq_held.exit.i.i.i.i.i
  %.b37.i.i.i.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i.i.i.i, label %rq_clock.exit.i.i.i.i, label %if.then.i.i.i.i.i.i, !prof !1191

if.then.i.i.i.i.i.i:                              ; preds = %land.rhs.i3.i.i.i.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i.i.i.i

rq_clock.exit.i.i.i.i:                            ; preds = %if.then.i.i.i.i.i.i, %land.rhs.i3.i.i.i.i.i, %lockdep_assert_rq_held.exit.i.i.i.i.i
  %clock.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 26
  %tobool.not.i.i.i.i.i = icmp eq i32 %add, 0
  br i1 %tobool.not.i.i.i.i.i, label %rq_sched_info_depart.exit.i.i.i.i, label %if.then.i.i.i.i.i

if.then.i.i.i.i.i:                                ; preds = %rq_clock.exit.i.i.i.i
  %78 = ptrtoint ptr %clock.i.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %78)
  %79 = load i64, ptr %clock.i.i.i.i.i, align 32
  %last_arrival.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 49, i32 2
  %80 = ptrtoint ptr %last_arrival.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %80)
  %81 = load i64, ptr %last_arrival.i.i.i.i, align 16
  %sub.i.i.i.i = sub i64 %79, %81
  %rq_cpu_time.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 69
  %82 = ptrtoint ptr %rq_cpu_time.i.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %82)
  %83 = load i64, ptr %rq_cpu_time.i.i.i.i.i, align 8
  %add.i.i.i.i.i = add i64 %sub.i.i.i.i, %83
  store i64 %add.i.i.i.i.i, ptr %rq_cpu_time.i.i.i.i.i, align 8
  br label %rq_sched_info_depart.exit.i.i.i.i

rq_sched_info_depart.exit.i.i.i.i:                ; preds = %if.then.i.i.i.i.i, %rq_clock.exit.i.i.i.i
  %84 = ptrtoint ptr %13 to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load volatile i32, ptr %13, align 128
  %cmp.i.i.i.i = icmp eq i32 %85, 0
  br i1 %cmp.i.i.i.i, label %if.then.i.i.i.i, label %if.end.i.i.i

if.then.i.i.i.i:                                  ; preds = %rq_sched_info_depart.exit.i.i.i.i
  %last_queued.i.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 49, i32 3
  %86 = ptrtoint ptr %last_queued.i.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %86)
  %87 = load i64, ptr %last_queued.i.i.i.i.i, align 8
  %tobool.not.i5.i.i.i.i = icmp eq i64 %87, 0
  br i1 %tobool.not.i5.i.i.i.i, label %if.then.i7.i.i.i.i, label %if.end.i.i.i

if.then.i7.i.i.i.i:                               ; preds = %if.then.i.i.i.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %88 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i6.i.i.i.i = icmp eq i32 %88, 0
  br i1 %tobool.not.i.i.i6.i.i.i.i, label %lockdep_assert_rq_held.exit.i.i.i.i.i.i, label %land.rhs.i.i.i.i.i.i.i

land.rhs.i.i.i.i.i.i.i:                           ; preds = %if.then.i7.i.i.i.i
  %core_enabled.i.i.i.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 81
  %89 = ptrtoint ptr %core_enabled.i.i.i.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load i32, ptr %core_enabled.i.i.i.i.i.i.i.i, align 128
  %tobool.not.i.i.i.i.i.i.i.i = icmp eq i32 %90, 0
  br i1 %tobool.not.i.i.i.i.i.i.i.i, label %__rq_lockp.exit.i.i.i.i.i.i.i, label %if.then.i.i.i.i.i.i.i.i

if.then.i.i.i.i.i.i.i.i:                          ; preds = %land.rhs.i.i.i.i.i.i.i
  %core.i.i.i.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 79
  %91 = ptrtoint ptr %core.i.i.i.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load ptr, ptr %core.i.i.i.i.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i.i.i.i.i

__rq_lockp.exit.i.i.i.i.i.i.i:                    ; preds = %if.then.i.i.i.i.i.i.i.i, %land.rhs.i.i.i.i.i.i.i
  %retval.0.i.i.i.i.i.i.i.i = phi ptr [ %92, %if.then.i.i.i.i.i.i.i.i ], [ %11, %land.rhs.i.i.i.i.i.i.i ]
  %dep_map.i.i.i.i.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i.i.i.i.i, i32 0, i32 4
  %call.i.i.i.i.i.i.i.i = call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i.i.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i.i.i.i.i = icmp eq i32 %call.i.i.i.i.i.i.i.i, 0
  br i1 %cmp.not.i.i.i.i.i.i.i, label %do.end.i.i.i.i.i.i.i, label %lockdep_assert_rq_held.exit.i.i.i.i.i.i, !prof !1192

do.end.i.i.i.i.i.i.i:                             ; preds = %__rq_lockp.exit.i.i.i.i.i.i.i
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i.i.i.i.i

lockdep_assert_rq_held.exit.i.i.i.i.i.i:          ; preds = %do.end.i.i.i.i.i.i.i, %__rq_lockp.exit.i.i.i.i.i.i.i, %if.then.i7.i.i.i.i
  %93 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %clock_update_flags, align 4
  %cmp.i.i.i.i.i.i.i = icmp ult i32 %94, 2
  br i1 %cmp.i.i.i.i.i.i.i, label %land.rhs.i3.i.i.i.i.i.i, label %rq_clock.exit.i.i.i.i.i

land.rhs.i3.i.i.i.i.i.i:                          ; preds = %lockdep_assert_rq_held.exit.i.i.i.i.i.i
  %.b37.i.i.i.i.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i.i.i.i.i, label %rq_clock.exit.i.i.i.i.i, label %if.then.i.i.i8.i.i.i.i, !prof !1191

if.then.i.i.i8.i.i.i.i:                           ; preds = %land.rhs.i3.i.i.i.i.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i.i.i.i.i

rq_clock.exit.i.i.i.i.i:                          ; preds = %if.then.i.i.i8.i.i.i.i, %land.rhs.i3.i.i.i.i.i.i, %lockdep_assert_rq_held.exit.i.i.i.i.i.i
  %95 = ptrtoint ptr %clock.i.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %95)
  %96 = load i64, ptr %clock.i.i.i.i.i, align 32
  %97 = ptrtoint ptr %last_queued.i.i.i.i.i to i32
  call void @__asan_store8_noabort(i32 %97)
  store i64 %96, ptr %last_queued.i.i.i.i.i, align 8
  br label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %rq_clock.exit.i.i.i.i.i, %if.then.i.i.i.i, %rq_sched_info_depart.exit.i.i.i.i, %psi_sched_switch.exit
  %98 = ptrtoint ptr %idle.i.i.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load ptr, ptr %idle.i.i.i, align 4
  %cmp2.not.i.i.i = icmp eq ptr %99, %call63
  br i1 %cmp2.not.i.i.i, label %sched_info_switch.exit.i.i, label %if.then3.i.i.i

if.then3.i.i.i:                                   ; preds = %if.end.i.i.i
  %last_queued.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 49, i32 3
  %100 = ptrtoint ptr %last_queued.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %100)
  %101 = load i64, ptr %last_queued.i.i.i.i, align 8
  %tobool.not.i.i.i.i = icmp eq i64 %101, 0
  br i1 %tobool.not.i.i.i.i, label %sched_info_switch.exit.i.i, label %if.end.i.i.i.i

if.end.i.i.i.i:                                   ; preds = %if.then3.i.i.i
  %sched_info.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 49
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %102 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i.i10.i.i.i = icmp eq i32 %102, 0
  br i1 %tobool.not.i.i.i10.i.i.i, label %lockdep_assert_rq_held.exit.i.i24.i.i.i, label %land.rhs.i.i.i13.i.i.i

land.rhs.i.i.i13.i.i.i:                           ; preds = %if.end.i.i.i.i
  %core_enabled.i.i.i.i11.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 81
  %103 = ptrtoint ptr %core_enabled.i.i.i.i11.i.i.i to i32
  call void @__asan_load4_noabort(i32 %103)
  %104 = load i32, ptr %core_enabled.i.i.i.i11.i.i.i, align 128
  %tobool.not.i.i.i.i12.i.i.i = icmp eq i32 %104, 0
  br i1 %tobool.not.i.i.i.i12.i.i.i, label %__rq_lockp.exit.i.i.i20.i.i.i, label %if.then.i.i.i.i15.i.i.i

if.then.i.i.i.i15.i.i.i:                          ; preds = %land.rhs.i.i.i13.i.i.i
  %core.i.i.i.i14.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 79
  %105 = ptrtoint ptr %core.i.i.i.i14.i.i.i to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load ptr, ptr %core.i.i.i.i14.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i20.i.i.i

__rq_lockp.exit.i.i.i20.i.i.i:                    ; preds = %if.then.i.i.i.i15.i.i.i, %land.rhs.i.i.i13.i.i.i
  %retval.0.i.i.i.i16.i.i.i = phi ptr [ %106, %if.then.i.i.i.i15.i.i.i ], [ %11, %land.rhs.i.i.i13.i.i.i ]
  %dep_map.i.i.i17.i.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i.i16.i.i.i, i32 0, i32 4
  %call.i.i.i.i18.i.i.i = call i32 @lock_is_held_type(ptr noundef %dep_map.i.i.i17.i.i.i, i32 noundef -1) #33
  %cmp.not.i.i.i19.i.i.i = icmp eq i32 %call.i.i.i.i18.i.i.i, 0
  br i1 %cmp.not.i.i.i19.i.i.i, label %do.end.i.i.i21.i.i.i, label %lockdep_assert_rq_held.exit.i.i24.i.i.i, !prof !1192

do.end.i.i.i21.i.i.i:                             ; preds = %__rq_lockp.exit.i.i.i20.i.i.i
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i.i24.i.i.i

lockdep_assert_rq_held.exit.i.i24.i.i.i:          ; preds = %do.end.i.i.i21.i.i.i, %__rq_lockp.exit.i.i.i20.i.i.i, %if.end.i.i.i.i
  %107 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load i32, ptr %clock_update_flags, align 4
  %cmp.i.i.i23.i.i.i = icmp ult i32 %108, 2
  br i1 %cmp.i.i.i23.i.i.i, label %land.rhs.i3.i.i26.i.i.i, label %rq_clock.exit.i32.i.i.i

land.rhs.i3.i.i26.i.i.i:                          ; preds = %lockdep_assert_rq_held.exit.i.i24.i.i.i
  %.b37.i.i.i25.i.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i.i25.i.i.i, label %rq_clock.exit.i32.i.i.i, label %if.then.i.i.i27.i.i.i, !prof !1191

if.then.i.i.i27.i.i.i:                            ; preds = %land.rhs.i3.i.i26.i.i.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit.i32.i.i.i

rq_clock.exit.i32.i.i.i:                          ; preds = %if.then.i.i.i27.i.i.i, %land.rhs.i3.i.i26.i.i.i, %lockdep_assert_rq_held.exit.i.i24.i.i.i
  %clock.i.i28.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 26
  %109 = ptrtoint ptr %clock.i.i28.i.i.i to i32
  call void @__asan_load8_noabort(i32 %109)
  %110 = load i64, ptr %clock.i.i28.i.i.i, align 32
  %111 = ptrtoint ptr %last_queued.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %111)
  %112 = load i64, ptr %last_queued.i.i.i.i, align 8
  %sub.i29.i.i.i = sub i64 %110, %112
  store i64 0, ptr %last_queued.i.i.i.i, align 8
  %run_delay.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 49, i32 1
  %113 = ptrtoint ptr %run_delay.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %113)
  %114 = load i64, ptr %run_delay.i.i.i.i, align 8
  %add.i.i.i.i = add i64 %114, %sub.i29.i.i.i
  store i64 %add.i.i.i.i, ptr %run_delay.i.i.i.i, align 8
  %last_arrival.i30.i.i.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 49, i32 2
  %115 = ptrtoint ptr %last_arrival.i30.i.i.i to i32
  call void @__asan_store8_noabort(i32 %115)
  store i64 %110, ptr %last_arrival.i30.i.i.i, align 16
  %116 = ptrtoint ptr %sched_info.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %116)
  %117 = load i32, ptr %sched_info.i.i.i.i, align 16
  %inc.i.i.i.i = add i32 %117, 1
  store i32 %inc.i.i.i.i, ptr %sched_info.i.i.i.i, align 16
  %tobool.not.i.i31.i.i.i = icmp eq i32 %add, 0
  br i1 %tobool.not.i.i31.i.i.i, label %sched_info_switch.exit.i.i, label %if.then.i.i34.i.i.i

if.then.i.i34.i.i.i:                              ; preds = %rq_clock.exit.i32.i.i.i
  %rq_sched_info.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 68
  %run_delay.i.i.i.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 68, i32 1
  %118 = ptrtoint ptr %run_delay.i.i.i.i.i to i32
  call void @__asan_load8_noabort(i32 %118)
  %119 = load i64, ptr %run_delay.i.i.i.i.i, align 8
  %add.i.i33.i.i.i = add i64 %119, %sub.i29.i.i.i
  store i64 %add.i.i33.i.i.i, ptr %run_delay.i.i.i.i.i, align 8
  %120 = ptrtoint ptr %rq_sched_info.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load i32, ptr %rq_sched_info.i.i.i.i.i, align 8
  %inc.i.i.i.i.i = add i32 %121, 1
  store i32 %inc.i.i.i.i.i, ptr %rq_sched_info.i.i.i.i.i, align 8
  br label %sched_info_switch.exit.i.i

sched_info_switch.exit.i.i:                       ; preds = %if.then.i.i34.i.i.i, %rq_clock.exit.i32.i.i.i, %if.then3.i.i.i, %if.end.i.i.i
  call fastcc void @perf_event_task_sched_out(ptr noundef %13, ptr noundef %call63) #33
  %rseq_event_mask.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 176
  %122 = ptrtoint ptr %rseq_event_mask.i.i.i to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load i32, ptr %rseq_event_mask.i.i.i, align 4
  %or.i.i.i.i = or i32 %123, 1
  store i32 %or.i.i.i.i, ptr %rseq_event_mask.i.i.i, align 4
  %rseq.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 174
  %124 = ptrtoint ptr %rseq.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load ptr, ptr %rseq.i.i.i.i, align 8
  %tobool.not.i.i10.i.i = icmp eq ptr %125, null
  br i1 %tobool.not.i.i10.i.i, label %rseq_preempt.exit.i.i, label %if.then.i.i11.i.i

if.then.i.i11.i.i:                                ; preds = %sched_info_switch.exit.i.i
  %126 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load ptr, ptr %stack.i.i, align 4
  call void @_set_bit(i32 noundef 2, ptr noundef %127) #33
  br label %rseq_preempt.exit.i.i

rseq_preempt.exit.i.i:                            ; preds = %if.then.i.i11.i.i, %sched_info_switch.exit.i.i
  %128 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %128, -16384
  %129 = inttoptr i32 %and.i.i.i.i to ptr
  %task.i.i.i = getelementptr inbounds %struct.thread_info, ptr %129, i32 0, i32 2
  %130 = ptrtoint ptr %task.i.i.i to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load ptr, ptr %task.i.i.i, align 8
  %kmap_ctrl.i.i.i = getelementptr inbounds %struct.task_struct, ptr %131, i32 0, i32 211
  %132 = ptrtoint ptr %kmap_ctrl.i.i.i to i32
  call void @__asan_load4_noabort(i32 %132)
  %133 = load i32, ptr %kmap_ctrl.i.i.i, align 4
  %tobool.not.i.i.i = icmp eq i32 %133, 0
  br i1 %tobool.not.i.i.i, label %prepare_task_switch.exit.i, label %if.then.i12.i.i, !prof !1191

if.then.i12.i.i:                                  ; preds = %rseq_preempt.exit.i.i
  call void @__kmap_local_sched_out() #33
  br label %prepare_task_switch.exit.i

prepare_task_switch.exit.i:                       ; preds = %if.then.i12.i.i, %rseq_preempt.exit.i.i
  %on_cpu.i.i.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 5
  %134 = ptrtoint ptr %on_cpu.i.i.i to i32
  call void @__asan_store4_noabort(i32 %134)
  store volatile i32 1, ptr %on_cpu.i.i.i, align 4
  %mm.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 53
  %135 = ptrtoint ptr %mm.i to i32
  call void @__asan_load4_noabort(i32 %135)
  %136 = load ptr, ptr %mm.i, align 8
  %tobool.not.i = icmp eq ptr %136, null
  %active_mm.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 54
  %137 = ptrtoint ptr %active_mm.i to i32
  call void @__asan_load4_noabort(i32 %137)
  %138 = load ptr, ptr %active_mm.i, align 4
  br i1 %tobool.not.i, label %if.then.i, label %if.else8.i

if.then.i:                                        ; preds = %prepare_task_switch.exit.i
  %active_mm2.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 54
  %139 = ptrtoint ptr %active_mm2.i to i32
  call void @__asan_store4_noabort(i32 %139)
  store ptr %138, ptr %active_mm2.i, align 4
  %mm3.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 53
  %140 = ptrtoint ptr %mm3.i to i32
  call void @__asan_load4_noabort(i32 %140)
  %141 = load ptr, ptr %mm3.i, align 8
  %tobool4.not.i = icmp eq ptr %141, null
  br i1 %tobool4.not.i, label %if.else.i, label %if.then5.i

if.then5.i:                                       ; preds = %if.then.i
  %142 = ptrtoint ptr %active_mm.i to i32
  call void @__asan_load4_noabort(i32 %142)
  %143 = load ptr, ptr %active_mm.i, align 4
  %mm_count.i.i = getelementptr inbounds %struct.anon.3, ptr %143, i32 0, i32 11
  %call.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %mm_count.i.i, i32 noundef 4) #33
  call void @llvm.prefetch.p0(ptr %mm_count.i.i, i32 1, i32 3, i32 1) #33
  %144 = call { i32, i32 } asm sideeffect "@ atomic_add\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %mm_count.i.i, ptr %mm_count.i.i, i32 1, ptr elementtype(i32) %mm_count.i.i) #33, !srcloc !1200
  br label %context_switch.exit

if.else.i:                                        ; preds = %if.then.i
  %145 = ptrtoint ptr %active_mm.i to i32
  call void @__asan_store4_noabort(i32 %145)
  store ptr null, ptr %active_mm.i, align 4
  br label %context_switch.exit

if.else8.i:                                       ; preds = %prepare_task_switch.exit.i
  %cmp.i.i = icmp eq ptr %138, %136
  br i1 %cmp.i.i, label %membarrier_switch_mm.exit.i, label %if.end.i.i

if.end.i.i:                                       ; preds = %if.else8.i
  %membarrier_state1.i.i = getelementptr inbounds %struct.anon.3, ptr %136, i32 0, i32 9
  %call.i.i.i1.i = call zeroext i1 @__kasan_check_read(ptr noundef %membarrier_state1.i.i, i32 noundef 4) #33
  %146 = ptrtoint ptr %membarrier_state1.i.i to i32
  call void @__asan_load4_noabort(i32 %146)
  %147 = load volatile i32, ptr %membarrier_state1.i.i, align 4
  %membarrier_state2.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 34
  %148 = ptrtoint ptr %membarrier_state2.i.i to i32
  call void @__asan_load4_noabort(i32 %148)
  %149 = load volatile i32, ptr %membarrier_state2.i.i, align 4
  %cmp3.i.i = icmp eq i32 %149, %147
  br i1 %cmp3.i.i, label %membarrier_switch_mm.exit.i, label %do.body10.i.i

do.body10.i.i:                                    ; preds = %if.end.i.i
  %150 = ptrtoint ptr %membarrier_state2.i.i to i32
  call void @__asan_store4_noabort(i32 %150)
  store volatile i32 %147, ptr %membarrier_state2.i.i, align 4
  br label %membarrier_switch_mm.exit.i

membarrier_switch_mm.exit.i:                      ; preds = %do.body10.i.i, %if.end.i.i, %if.else8.i
  %151 = ptrtoint ptr %active_mm.i to i32
  call void @__asan_load4_noabort(i32 %151)
  %152 = load ptr, ptr %active_mm.i, align 4
  %153 = ptrtoint ptr %mm.i to i32
  call void @__asan_load4_noabort(i32 %153)
  %154 = load ptr, ptr %mm.i, align 8
  call fastcc void @switch_mm(ptr noundef %152, ptr noundef %154, ptr noundef %call63) #33
  %mm13.i = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 53
  %155 = ptrtoint ptr %mm13.i to i32
  call void @__asan_load4_noabort(i32 %155)
  %156 = load ptr, ptr %mm13.i, align 8
  %tobool14.not.i = icmp eq ptr %156, null
  br i1 %tobool14.not.i, label %if.then15.i, label %context_switch.exit

if.then15.i:                                      ; preds = %membarrier_switch_mm.exit.i
  %157 = ptrtoint ptr %active_mm.i to i32
  call void @__asan_load4_noabort(i32 %157)
  %158 = load ptr, ptr %active_mm.i, align 4
  %prev_mm.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 24
  %159 = ptrtoint ptr %prev_mm.i to i32
  call void @__asan_store4_noabort(i32 %159)
  store ptr %158, ptr %prev_mm.i, align 8
  store ptr null, ptr %active_mm.i, align 4
  br label %context_switch.exit

context_switch.exit:                              ; preds = %if.then15.i, %membarrier_switch_mm.exit.i, %if.else.i, %if.then5.i
  %160 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %160)
  %161 = load i32, ptr %clock_update_flags, align 4
  %and.i = and i32 %161, -4
  store i32 %and.i, ptr %clock_update_flags, align 4
  call fastcc void @prepare_lock_switch(ptr noundef %11, ptr noundef %call63, ptr noundef nonnull %rf) #33
  %162 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %162)
  %163 = load ptr, ptr %stack.i.i, align 4
  %stack21.i = getelementptr inbounds %struct.task_struct, ptr %call63, i32 0, i32 1
  %164 = ptrtoint ptr %stack21.i to i32
  call void @__asan_load4_noabort(i32 %164)
  %165 = load ptr, ptr %stack21.i, align 4
  %call.i = call ptr @__switch_to(ptr noundef %13, ptr noundef %163, ptr noundef %165) #33
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1282
  call fastcc void @finish_task_switch(ptr noundef %call.i) #33
  br label %if.end93

if.else90:                                        ; preds = %if.end62
  %166 = ptrtoint ptr %clock_update_flags to i32
  call void @__asan_load4_noabort(i32 %166)
  %167 = load i32, ptr %clock_update_flags, align 4
  %and92 = and i32 %167, -4
  store i32 %and92, ptr %clock_update_flags, align 4
  %cmp.i157.not = icmp eq i32 %and92, 0
  br i1 %cmp.i157.not, label %if.end.i160, label %if.then.i158

if.then.i158:                                     ; preds = %if.else90
  %168 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %168)
  store i32 4, ptr %3, align 4
  br label %if.end.i160

if.end.i160:                                      ; preds = %if.then.i158, %if.else90
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 81
  %169 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %169)
  %170 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i159 = icmp eq i32 %170, 0
  br i1 %tobool.not.i.i159, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end.i160
  %core.i.i = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 79
  %171 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %171)
  %172 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %if.end.i160
  %retval.0.i.i = phi ptr [ %172, %if.then.i.i ], [ %11, %if.end.i160 ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %173 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %173)
  %.unpack.i = load i32, ptr %1, align 4
  %174 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %174) #33
  call fastcc void @__balance_callbacks(ptr noundef %11)
  call fastcc void @raw_spin_rq_unlock_irq(ptr noundef %11)
  br label %if.end93

if.end93:                                         ; preds = %rq_unpin_lock.exit, %context_switch.exit
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @schedule() #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %3, align 128
  %cmp.i = icmp eq i32 %5, 0
  br i1 %cmp.i, label %do.body.preheader, label %if.end.i

if.end.i:                                         ; preds = %entry
  %flags.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 3
  %6 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %flags.i, align 4
  %and.i11 = and i32 %7, 48
  %tobool.not.i = icmp eq i32 %and.i11, 0
  br i1 %tobool.not.i, label %if.end6.i, label %if.then1.i

if.then1.i:                                       ; preds = %if.end.i
  %and2.i = and i32 %7, 32
  %tobool3.not.i = icmp eq i32 %and2.i, 0
  br i1 %tobool3.not.i, label %if.else.i, label %if.then4.i

if.then4.i:                                       ; preds = %if.then1.i
  tail call void @wq_worker_sleeping(ptr noundef %3) #33
  br label %if.end6.i

if.else.i:                                        ; preds = %if.then1.i
  tail call void @io_wq_worker_sleeping(ptr noundef %3) #33
  br label %if.end6.i

if.end6.i:                                        ; preds = %if.else.i, %if.then4.i, %if.end.i
  %pi_blocked_on.i.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 132
  %8 = ptrtoint ptr %pi_blocked_on.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %pi_blocked_on.i.i, align 32
  %cmp.i.not.i = icmp eq ptr %9, null
  br i1 %cmp.i.not.i, label %if.end8.i, label %do.body.preheader

if.end8.i:                                        ; preds = %if.end6.i
  %plug1.i.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 148
  %10 = ptrtoint ptr %plug1.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %plug1.i.i, align 4
  %tobool.not.i.i = icmp eq ptr %11, null
  br i1 %tobool.not.i.i, label %do.body.preheader, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %if.end8.i
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %11, align 4
  %tobool2.not.i.i = icmp eq ptr %13, null
  br i1 %tobool2.not.i.i, label %blk_needs_flush_plug.exit.i, label %if.then10.i

blk_needs_flush_plug.exit.i:                      ; preds = %land.rhs.i.i
  %cb_list.i.i = getelementptr inbounds %struct.blk_plug, ptr %11, i32 0, i32 7
  %14 = ptrtoint ptr %cb_list.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %cb_list.i.i, align 4
  %cmp.i.i.not.i = icmp eq ptr %15, %cb_list.i.i
  br i1 %cmp.i.i.not.i, label %do.body.preheader, label %if.then10.i

if.then10.i:                                      ; preds = %blk_needs_flush_plug.exit.i, %land.rhs.i.i
  tail call void @blk_flush_plug(ptr noundef nonnull %11, i1 noundef zeroext true) #33
  br label %do.body.preheader

do.body.preheader:                                ; preds = %if.then10.i, %blk_needs_flush_plug.exit.i, %if.end8.i, %if.end6.i, %entry
  br label %do.body

do.body:                                          ; preds = %do.body, %do.body.preheader
  %16 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %19, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1283
  tail call fastcc void @__schedule(i32 noundef 0)
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1284
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i9 = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i9 to ptr
  %preempt_count.i.i10 = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i10 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i10, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i10, align 4
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i to ptr
  %26 = ptrtoint ptr %25 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %25, align 16384
  %28 = and i32 %27, 2
  %tobool.i.not = icmp eq i32 %28, 0
  br i1 %tobool.i.not, label %do.end7, label %do.body

do.end7:                                          ; preds = %do.body
  %flags.i12 = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 3
  %29 = ptrtoint ptr %flags.i12 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %flags.i12, align 4
  %and.i13 = and i32 %30, 48
  %tobool.not.i14 = icmp eq i32 %and.i13, 0
  br i1 %tobool.not.i14, label %sched_update_worker.exit, label %if.then.i

if.then.i:                                        ; preds = %do.end7
  %and2.i15 = and i32 %30, 32
  %tobool3.not.i16 = icmp eq i32 %and2.i15, 0
  br i1 %tobool3.not.i16, label %if.else.i18, label %if.then4.i17

if.then4.i17:                                     ; preds = %if.then.i
  tail call void @wq_worker_running(ptr noundef %3) #33
  br label %sched_update_worker.exit

if.else.i18:                                      ; preds = %if.then.i
  tail call void @io_wq_worker_running(ptr noundef %3) #33
  br label %sched_update_worker.exit

sched_update_worker.exit:                         ; preds = %if.else.i18, %if.then4.i17, %do.end7
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @schedule_idle() local_unnamed_addr #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %3, align 128
  %tobool.not = icmp eq i32 %5, 0
  br i1 %tobool.not, label %do.body36.preheader, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b42 = load i1, ptr @schedule_idle.__already_done, align 1
  br i1 %.b42, label %do.body36.preheader, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @schedule_idle.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6403, i32 noundef 9, ptr noundef null) #33
  br label %do.body36.preheader

do.body36.preheader:                              ; preds = %if.then, %land.rhs, %entry
  br label %do.body36

do.body36:                                        ; preds = %do.body36, %do.body36.preheader
  tail call fastcc void @__schedule(i32 noundef 0)
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i to ptr
  %8 = ptrtoint ptr %7 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %7, align 16384
  %10 = and i32 %9, 2
  %tobool.i.not = icmp eq i32 %10, 0
  br i1 %tobool.i.not, label %do.end39, label %do.body36

do.end39:                                         ; preds = %do.body36
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @schedule_preempt_disabled() local_unnamed_addr #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1285
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %sub.i = add i32 %3, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i, align 4
  tail call void @schedule()
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i3 = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i3 to ptr
  %preempt_count.i.i4 = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i4 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i4, align 4
  %add.i = add i32 %7, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i4, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1286
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @preempt_schedule_irq() local_unnamed_addr #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i, align 4
  %tobool.not = icmp eq i32 %3, 0
  br i1 %tobool.not, label %lor.rhs, label %do.body15, !prof !1191

lor.rhs:                                          ; preds = %entry
  %4 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i = and i32 %4, 128
  %tobool11.not = icmp eq i32 %and.i, 0
  br i1 %tobool11.not, label %do.body15, label %do.body24, !prof !1192

do.body15:                                        ; preds = %lor.rhs, %entry
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 6712, 0\0A.popsection", ""() #33, !srcloc !1287
  unreachable

do.body24:                                        ; preds = %if.end36, %lor.rhs
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 1
  %7 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %8, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1288
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  tail call fastcc void @__schedule(i32 noundef 1)
  %9 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i48 = and i32 %9, 128
  %tobool33.not = icmp eq i32 %and.i.i48, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool33.not, label %if.then35, label %if.end36

if.then35:                                        ; preds = %do.body24
  tail call void @trace_hardirqs_off() #33
  br label %if.end36

if.end36:                                         ; preds = %if.then35, %do.body24
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1289
  %10 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i45 = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i.i45 to ptr
  %preempt_count.i.i46 = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 1
  %12 = ptrtoint ptr %preempt_count.i.i46 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %preempt_count.i.i46, align 4
  %sub.i = add i32 %13, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i46, align 4
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i47 = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i47 to ptr
  %16 = ptrtoint ptr %15 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %15, align 16384
  %18 = and i32 %17, 2
  %tobool.i.not = icmp eq i32 %18, 0
  br i1 %tobool.i.not, label %do.end44, label %do.body24

do.end44:                                         ; preds = %if.end36
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_hardirqs_on() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_hardirqs_off() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @default_wake_function(ptr nocapture noundef readonly %curr, i32 noundef %mode, i32 noundef %wake_flags, ptr nocapture readnone %key) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %and = and i32 %wake_flags, -17
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end28, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b39 = load i1, ptr @default_wake_function.__already_done, align 1
  br i1 %.b39, label %if.end28, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @default_wake_function.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6730, i32 noundef 9, ptr noundef null) #33
  br label %if.end28

if.end28:                                         ; preds = %if.then, %land.rhs, %entry
  %private = getelementptr inbounds %struct.wait_queue_entry, ptr %curr, i32 0, i32 1
  %0 = ptrtoint ptr %private to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %private, align 4
  %call = tail call fastcc i32 @try_to_wake_up(ptr noundef %1, i32 noundef %mode, i32 noundef %wake_flags)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @rt_mutex_setprio(ptr noundef %p, ptr noundef %pi_task) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %normal_prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 15
  %3 = ptrtoint ptr %normal_prio to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %normal_prio, align 64
  %tobool.not.i = icmp eq ptr %pi_task, null
  br i1 %tobool.not.i, label %__rt_effective_prio.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %prio1.i = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 13
  %5 = ptrtoint ptr %prio1.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %prio1.i, align 8
  %7 = tail call i32 @llvm.smin.i32(i32 %6, i32 %4) #33
  br label %__rt_effective_prio.exit

__rt_effective_prio.exit:                         ; preds = %if.then.i, %entry
  %prio.addr.0.i = phi i32 [ %7, %if.then.i ], [ %4, %entry ]
  %pi_top_task = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 131
  %8 = ptrtoint ptr %pi_top_task to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %pi_top_task, align 4
  %cmp = icmp eq ptr %9, %pi_task
  br i1 %cmp, label %land.lhs.true, label %if.end

land.lhs.true:                                    ; preds = %__rt_effective_prio.exit
  %prio1 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %10 = ptrtoint ptr %prio1 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %prio1, align 8
  %cmp2 = icmp eq i32 %prio.addr.0.i, %11
  %tobool.not = icmp sgt i32 %prio.addr.0.i, -1
  %or.cond = and i1 %tobool.not, %cmp2
  br i1 %or.cond, label %cleanup, label %if.end

if.end:                                           ; preds = %land.lhs.true, %__rt_effective_prio.exit
  %call5 = call ptr @__task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call5)
  %12 = ptrtoint ptr %pi_top_task to i32
  call void @__asan_store4_noabort(i32 %12)
  store ptr %pi_task, ptr %pi_top_task, align 4
  %prio7 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %13 = ptrtoint ptr %prio7 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %prio7, align 8
  %cmp8 = icmp eq i32 %prio.addr.0.i, %14
  %tobool11.not = icmp sgt i32 %prio.addr.0.i, -1
  %or.cond258 = and i1 %tobool11.not, %cmp8
  br i1 %or.cond258, label %do.body145, label %if.end13

if.end13:                                         ; preds = %if.end
  %idle = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 21
  %15 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %idle, align 4
  %cmp14 = icmp eq ptr %16, %p
  br i1 %cmp14, label %if.then17, label %if.end75, !prof !1192

if.then17:                                        ; preds = %if.end13
  %curr = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 20
  %17 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %curr, align 8
  %cmp18.not = icmp eq ptr %18, %p
  br i1 %cmp18.not, label %if.end37, label %do.end, !prof !1191

do.end:                                           ; preds = %if.then17
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6825, i32 noundef 9, ptr noundef null) #33
  br label %if.end37

if.end37:                                         ; preds = %do.end, %if.then17
  %pi_blocked_on = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 132
  %19 = ptrtoint ptr %pi_blocked_on to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %pi_blocked_on, align 32
  %tobool45.not = icmp eq ptr %20, null
  br i1 %tobool45.not, label %do.body145, label %do.end61, !prof !1191

do.end61:                                         ; preds = %if.end37
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6826, i32 noundef 9, ptr noundef null) #33
  br label %do.body145

if.end75:                                         ; preds = %if.end13
  tail call fastcc void @trace_sched_pi_setprio(ptr noundef %p, ptr noundef %pi_task)
  %21 = ptrtoint ptr %prio7 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %prio7, align 8
  %cmp77 = icmp eq i32 %22, %prio.addr.0.i
  %spec.select = select i1 %cmp77, i32 10, i32 14
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %23 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %sched_class, align 32
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %25 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %26, 1
  %curr.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 20
  %27 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %curr.i, align 8
  %cmp.i230.not = icmp eq ptr %28, %p
  br i1 %cmp.i.not, label %if.then83, label %if.end84

if.then83:                                        ; preds = %if.end75
  tail call fastcc void @dequeue_task(ptr noundef %call5, ptr noundef %p, i32 noundef %spec.select)
  br label %if.end84

if.end84:                                         ; preds = %if.then83, %if.end75
  br i1 %cmp.i230.not, label %if.then86, label %if.end87

if.then86:                                        ; preds = %if.end84
  %29 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %curr.i, align 8
  %cmp.not.i = icmp eq ptr %30, %p
  br i1 %cmp.not.i, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then86
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i233, !prof !1191

if.then.i233:                                     ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i233, %land.rhs.i, %if.then86
  %31 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %sched_class, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %32, i32 0, i32 7
  %33 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %34(ptr noundef %call5, ptr noundef %p) #33
  br label %if.end87

if.end87:                                         ; preds = %put_prev_task.exit, %if.end84
  br i1 %tobool11.not, label %if.else110, label %if.then90

if.then90:                                        ; preds = %if.end87
  %35 = ptrtoint ptr %normal_prio to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %normal_prio, align 64
  %tobool93.not = icmp sgt i32 %36, -1
  br i1 %tobool93.not, label %if.then102, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %if.then90
  br i1 %tobool.not.i, label %if.else, label %land.lhs.true95

land.lhs.true95:                                  ; preds = %lor.lhs.false
  %prio96 = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 13
  %37 = ptrtoint ptr %prio96 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %prio96, align 8
  %tobool98.not = icmp sgt i32 %38, -1
  br i1 %tobool98.not, label %if.else, label %land.lhs.true99

land.lhs.true99:                                  ; preds = %land.lhs.true95
  %flags.i.i = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 20, i32 8
  %39 = ptrtoint ptr %flags.i.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %flags.i.i, align 8
  %and.i.i = and i32 %40, 268435456
  %tobool.i.not.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool.i.not.i, label %dl_entity_preempt.exit, label %if.then102

dl_entity_preempt.exit:                           ; preds = %land.lhs.true99
  %deadline.i = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 20, i32 7
  %41 = ptrtoint ptr %deadline.i to i32
  call void @__asan_load8_noabort(i32 %41)
  %42 = load i64, ptr %deadline.i, align 8
  %deadline1.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20, i32 7
  %43 = ptrtoint ptr %deadline1.i to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %deadline1.i, align 8
  %sub.i.i = sub i64 %42, %44
  %cmp.i.i = icmp slt i64 %sub.i.i, 0
  br i1 %cmp.i.i, label %if.then102, label %if.else

if.then102:                                       ; preds = %dl_entity_preempt.exit, %land.lhs.true99, %if.then90
  %pi_se = getelementptr inbounds %struct.task_struct, ptr %pi_task, i32 0, i32 20, i32 12
  %45 = ptrtoint ptr %pi_se to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %pi_se, align 8
  %pi_se105 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20, i32 12
  %47 = ptrtoint ptr %pi_se105 to i32
  call void @__asan_store4_noabort(i32 %47)
  store ptr %46, ptr %pi_se105, align 8
  %or = or i32 %spec.select, 32
  br label %__setscheduler_prio.exit

if.else:                                          ; preds = %dl_entity_preempt.exit, %land.lhs.true95, %lor.lhs.false
  %dl106 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20
  %pi_se108 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20, i32 12
  %48 = ptrtoint ptr %pi_se108 to i32
  call void @__asan_store4_noabort(i32 %48)
  store ptr %dl106, ptr %pi_se108, align 8
  br label %__setscheduler_prio.exit

if.else110:                                       ; preds = %if.end87
  %cmp.i237 = icmp ugt i32 %prio.addr.0.i, 99
  %tobool127.not = icmp sgt i32 %22, -1
  br i1 %cmp.i237, label %if.else125, label %if.then113

if.then113:                                       ; preds = %if.else110
  br i1 %tobool127.not, label %if.then3.i, label %if.then116

if.then116:                                       ; preds = %if.then113
  %dl117 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20
  %pi_se119 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20, i32 12
  %49 = ptrtoint ptr %pi_se119 to i32
  call void @__asan_store4_noabort(i32 %49)
  store ptr %dl117, ptr %pi_se119, align 8
  br label %if.then3.i

if.else125:                                       ; preds = %if.else110
  br i1 %tobool127.not, label %if.end132, label %if.end132.thread

if.end132.thread:                                 ; preds = %if.else125
  %dl129 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20
  %pi_se131 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 20, i32 12
  %50 = ptrtoint ptr %pi_se131 to i32
  call void @__asan_store4_noabort(i32 %50)
  store ptr %dl129, ptr %pi_se131, align 8
  br label %if.then135

if.end132:                                        ; preds = %if.else125
  %cmp.i240 = icmp ugt i32 %22, 99
  br i1 %cmp.i240, label %__setscheduler_prio.exit, label %if.then135

if.then135:                                       ; preds = %if.end132, %if.end132.thread
  %timeout = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 19, i32 1
  %51 = ptrtoint ptr %timeout to i32
  call void @__asan_store4_noabort(i32 %51)
  store i32 0, ptr %timeout, align 8
  br label %__setscheduler_prio.exit

if.then3.i:                                       ; preds = %if.then116, %if.then113
  %cmp121 = icmp slt i32 %22, %prio.addr.0.i
  %or123 = or i32 %spec.select, 16
  %spec.select226 = select i1 %cmp121, i32 %or123, i32 %spec.select
  br label %__setscheduler_prio.exit

__setscheduler_prio.exit:                         ; preds = %if.then3.i, %if.then135, %if.end132, %if.else, %if.then102
  %dl_sched_class.sink = phi ptr [ @rt_sched_class, %if.then3.i ], [ @dl_sched_class, %if.else ], [ @dl_sched_class, %if.then102 ], [ @fair_sched_class, %if.then135 ], [ @fair_sched_class, %if.end132 ]
  %queue_flag.1261 = phi i32 [ %spec.select226, %if.then3.i ], [ %spec.select, %if.else ], [ %or, %if.then102 ], [ %spec.select, %if.then135 ], [ %spec.select, %if.end132 ]
  %52 = ptrtoint ptr %sched_class to i32
  call void @__asan_store4_noabort(i32 %52)
  store ptr %dl_sched_class.sink, ptr %sched_class, align 32
  %53 = ptrtoint ptr %prio7 to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %prio.addr.0.i, ptr %prio7, align 8
  br i1 %cmp.i.not, label %if.then140, label %if.end141

if.then140:                                       ; preds = %__setscheduler_prio.exit
  tail call fastcc void @enqueue_task(ptr noundef %call5, ptr noundef %p, i32 noundef %queue_flag.1261)
  br label %if.end141

if.end141:                                        ; preds = %if.then140, %__setscheduler_prio.exit
  br i1 %cmp.i230.not, label %if.then143, label %if.end144

if.then143:                                       ; preds = %if.end141
  %54 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %sched_class, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %55, i32 0, i32 8
  %56 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %set_next_task.i, align 4
  tail call void %57(ptr noundef %call5, ptr noundef %p, i1 noundef zeroext false) #33
  br label %if.end144

if.end144:                                        ; preds = %if.then143, %if.end141
  %58 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %sched_class, align 32
  %cmp.not.i248 = icmp eq ptr %59, %24
  br i1 %cmp.not.i248, label %if.else.i251, label %if.then.i250

if.then.i250:                                     ; preds = %if.end144
  %switched_from.i = getelementptr inbounds %struct.sched_class, ptr %24, i32 0, i32 21
  %60 = ptrtoint ptr %switched_from.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %switched_from.i, align 4
  %tobool.not.i249 = icmp eq ptr %61, null
  br i1 %tobool.not.i249, label %if.end.i, label %if.then1.i

if.then1.i:                                       ; preds = %if.then.i250
  tail call void %61(ptr noundef %call5, ptr noundef %p) #33
  br label %if.end.i

if.end.i:                                         ; preds = %if.then1.i, %if.then.i250
  %62 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load ptr, ptr %sched_class, align 32
  %switched_to.i = getelementptr inbounds %struct.sched_class, ptr %63, i32 0, i32 22
  %64 = ptrtoint ptr %switched_to.i to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load ptr, ptr %switched_to.i, align 4
  tail call void %65(ptr noundef %call5, ptr noundef %p) #33
  br label %do.body145

if.else.i251:                                     ; preds = %if.end144
  %66 = ptrtoint ptr %prio7 to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %prio7, align 8
  %cmp4.not.i = icmp eq i32 %67, %22
  %tobool5.not.i = icmp sgt i32 %67, -1
  %or.cond.i = and i1 %cmp4.not.i, %tobool5.not.i
  br i1 %or.cond.i, label %do.body145, label %if.then6.i

if.then6.i:                                       ; preds = %if.else.i251
  %prio_changed.i = getelementptr inbounds %struct.sched_class, ptr %24, i32 0, i32 23
  %68 = ptrtoint ptr %prio_changed.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %prio_changed.i, align 4
  tail call void %69(ptr noundef %call5, ptr noundef %p, i32 noundef %22) #33
  br label %do.body145

do.body145:                                       ; preds = %if.then6.i, %if.else.i251, %if.end.i, %do.end61, %if.end37, %if.end
  %70 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %70, -16384
  %71 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %71, i32 0, i32 1
  %72 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %73, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1290
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 81
  %74 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %75, 0
  br i1 %tobool.not.i.i, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %do.body145
  %core.i.i = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 79
  %76 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %do.body145
  %retval.0.i.i = phi ptr [ %77, %if.then.i.i ], [ %call5, %do.body145 ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %78 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %78)
  %.unpack.i = load i32, ptr %1, align 4
  %79 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %79) #33
  tail call fastcc void @__balance_callbacks(ptr noundef %call5)
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@rt_mutex_setprio, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %rq_unpin_lock.exit
  %80 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %81, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i256

if.then.i.i256:                                   ; preds = %land.rhs.i.i.i
  %core.i.i255 = getelementptr inbounds %struct.rq, ptr %call5, i32 0, i32 79
  %82 = ptrtoint ptr %core.i.i255 to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load ptr, ptr %core.i.i255, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i256, %land.rhs.i.i.i, %rq_unpin_lock.exit
  %retval.0.i.i257 = phi ptr [ %83, %if.then.i.i256 ], [ %call5, %land.rhs.i.i.i ], [ %call5, %rq_unpin_lock.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i257) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1291
  %84 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i227 = and i32 %84, -16384
  %85 = inttoptr i32 %and.i.i.i227 to ptr
  %preempt_count.i.i228 = getelementptr inbounds %struct.thread_info, ptr %85, i32 0, i32 1
  %86 = ptrtoint ptr %preempt_count.i.i228 to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load volatile i32, ptr %preempt_count.i.i228, align 4
  %sub.i = add i32 %87, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i228, align 4
  br label %cleanup

cleanup:                                          ; preds = %raw_spin_rq_unlock.exit, %land.lhs.true
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_pi_setprio(ptr noundef %tsk, ptr noundef %pi_task) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_pi_setprio, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_pi_setprio, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1292
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_pi_setprio, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %tsk, ptr noundef %pi_task) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1293
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1293
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_pi_setprio, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_pi_setprio.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_pi_setprio.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 551, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__balance_callbacks(ptr noundef %rq) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %0 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %balance_callback.i, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %2 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i
  %retval.0.i.i.i = phi ptr [ %6, %if.then.i.i.i ], [ %rq, %land.rhs.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %entry
  %tobool.not.i = icmp eq ptr %1, null
  br i1 %tobool.not.i, label %splice_balance_callbacks.exit, label %if.then.i

if.then.i:                                        ; preds = %lockdep_assert_rq_held.exit.i
  %7 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store ptr null, ptr %balance_callback.i, align 8
  br label %splice_balance_callbacks.exit

splice_balance_callbacks.exit:                    ; preds = %if.then.i, %lockdep_assert_rq_held.exit.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %8 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i2 = icmp eq i32 %8, 0
  br i1 %tobool.not.i.i2, label %lockdep_assert_rq_held.exit.i14, label %land.rhs.i.i5

land.rhs.i.i5:                                    ; preds = %splice_balance_callbacks.exit
  %core_enabled.i.i.i3 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %9 = ptrtoint ptr %core_enabled.i.i.i3 to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i3, align 128
  %tobool.not.i.i.i4 = icmp eq i32 %10, 0
  br i1 %tobool.not.i.i.i4, label %__rq_lockp.exit.i.i12, label %if.then.i.i.i7

if.then.i.i.i7:                                   ; preds = %land.rhs.i.i5
  %core.i.i.i6 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i.i6 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i.i6, align 8
  br label %__rq_lockp.exit.i.i12

__rq_lockp.exit.i.i12:                            ; preds = %if.then.i.i.i7, %land.rhs.i.i5
  %retval.0.i.i.i8 = phi ptr [ %12, %if.then.i.i.i7 ], [ %rq, %land.rhs.i.i5 ]
  %dep_map.i.i9 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i8, i32 0, i32 4
  %call.i.i.i10 = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i9, i32 noundef -1) #33
  %cmp.not.i.i11 = icmp eq i32 %call.i.i.i10, 0
  br i1 %cmp.not.i.i11, label %do.end.i.i13, label %lockdep_assert_rq_held.exit.i14, !prof !1192

do.end.i.i13:                                     ; preds = %__rq_lockp.exit.i.i12
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i14

lockdep_assert_rq_held.exit.i14:                  ; preds = %do.end.i.i13, %__rq_lockp.exit.i.i12, %splice_balance_callbacks.exit
  br i1 %tobool.not.i, label %do_balance_callbacks.exit, label %while.body.i

while.body.i:                                     ; preds = %while.body.i, %lockdep_assert_rq_held.exit.i14
  %head.addr.09.i = phi ptr [ %16, %while.body.i ], [ %1, %lockdep_assert_rq_held.exit.i14 ]
  %func1.i = getelementptr inbounds %struct.callback_head, ptr %head.addr.09.i, i32 0, i32 1
  %13 = ptrtoint ptr %func1.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %func1.i, align 4
  %15 = ptrtoint ptr %head.addr.09.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %head.addr.09.i, align 4
  store ptr null, ptr %head.addr.09.i, align 4
  tail call void %14(ptr noundef %rq) #33
  %tobool.not.i15 = icmp eq ptr %16, null
  br i1 %tobool.not.i15, label %do_balance_callbacks.exit, label %while.body.i

do_balance_callbacks.exit:                        ; preds = %while.body.i, %lockdep_assert_rq_held.exit.i14
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @set_user_nice(ptr noundef %p, i32 noundef %nice) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %static_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %5 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %static_prio.i, align 4
  %sub.i = add i32 %6, -120
  %cmp = icmp eq i32 %sub.i, %nice
  %7 = add i32 %nice, -20
  %8 = icmp ult i32 %7, -40
  %9 = or i1 %8, %cmp
  br i1 %9, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %call4 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call4)
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 31
  %10 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %policy.i, align 4
  switch i32 %11, label %if.end10 [
    i32 6, label %if.then9
    i32 2, label %if.then9
    i32 1, label %if.then9
  ]

if.then9:                                         ; preds = %if.end, %if.end, %if.end
  %add = add nsw i32 %nice, 120
  %12 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 %add, ptr %static_prio.i, align 4
  br label %out_unlock

if.end10:                                         ; preds = %if.end
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %13 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %14, 1
  %curr.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 20
  %15 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %curr.i, align 8
  %cmp.i69.not = icmp eq ptr %16, %p
  br i1 %cmp.i.not, label %if.then17, label %if.end18

if.then17:                                        ; preds = %if.end10
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@set_user_nice, %land.rhs.i.i)) #33
          to label %if.end.i [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %if.then17
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 81
  %17 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i = icmp eq i32 %18, 0
  br i1 %tobool3.i.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %land.rhs.i.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 79
  %19 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %core.i.i, align 8
  %core_task_seq.i.i = getelementptr inbounds %struct.rq, ptr %20, i32 0, i32 84
  %21 = ptrtoint ptr %core_task_seq.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %core_task_seq.i.i, align 4
  %inc.i.i = add i32 %22, 1
  store i32 %inc.i.i, ptr %core_task_seq.i.i, align 4
  %core_node.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 22
  %23 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %core_node.i.i.i, align 4
  %25 = ptrtoint ptr %core_node.i.i.i to i32
  %cmp.i.not.i.i = icmp eq i32 %24, %25
  br i1 %cmp.i.not.i.i, label %if.end.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.then.i
  %core_tree.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 83
  tail call void @rb_erase(ptr noundef %core_node.i.i.i, ptr noundef %core_tree.i.i) #33
  %26 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %25, ptr %core_node.i.i.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i.i, %if.then.i, %land.rhs.i.i, %if.then17
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@set_user_nice, %if.end.i25.i)) #33
          to label %dequeue_task.exit [label %if.end.i25.i], !srcloc !1202

if.end.i25.i:                                     ; preds = %if.end.i
  %sched_class.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %27 = ptrtoint ptr %sched_class.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %sched_class.i.i, align 32
  %29 = ptrtoint ptr %28 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %28, align 4
  %tobool3.not.i.i = icmp eq i32 %30, 0
  br i1 %tobool3.not.i.i, label %dequeue_task.exit, label %for.body.preheader.i.i, !prof !1192

for.body.preheader.i.i:                           ; preds = %if.end.i25.i
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call4, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call4, ptr noundef %p, i32 noundef 1) #33
  br label %dequeue_task.exit

dequeue_task.exit:                                ; preds = %for.body.preheader.i.i, %if.end.i25.i, %if.end.i
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %31 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %sched_class.i, align 32
  %dequeue_task.i = getelementptr inbounds %struct.sched_class, ptr %32, i32 0, i32 2
  %33 = ptrtoint ptr %dequeue_task.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %dequeue_task.i, align 4
  tail call void %34(ptr noundef %call4, ptr noundef %p, i32 noundef 10) #33
  br label %if.end18

if.end18:                                         ; preds = %dequeue_task.exit, %if.end10
  br i1 %cmp.i69.not, label %if.then20, label %if.end21

if.then20:                                        ; preds = %if.end18
  %35 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %curr.i, align 8
  %cmp.not.i = icmp eq ptr %36, %p
  br i1 %cmp.not.i, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then20
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i72, !prof !1191

if.then.i72:                                      ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i72, %land.rhs.i, %if.then20
  %sched_class.i73 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %37 = ptrtoint ptr %sched_class.i73 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %sched_class.i73, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %38, i32 0, i32 7
  %39 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %40(ptr noundef %call4, ptr noundef %p) #33
  br label %if.end21

if.end21:                                         ; preds = %put_prev_task.exit, %if.end18
  %add22 = add nsw i32 %nice, 120
  %41 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 %add22, ptr %static_prio.i, align 4
  %sub.i75 = add nsw i32 %nice, 20
  %se.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %42 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %policy.i, align 4
  %cmp.i.i.not.i = icmp eq i32 %43, 5
  br i1 %cmp.i.i.not.i, label %if.then.i76, label %if.end.i77

if.then.i76:                                      ; preds = %if.end21
  %44 = ptrtoint ptr %se.i to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 3, ptr %se.i, align 4
  %inv_weight.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 0, i32 1
  %45 = ptrtoint ptr %inv_weight.i to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 1431655765, ptr %inv_weight.i, align 4
  br label %set_load_weight.exit

if.end.i77:                                       ; preds = %if.end21
  %sched_class.i78 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %46 = ptrtoint ptr %sched_class.i78 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %sched_class.i78, align 32
  %cmp.i79 = icmp eq ptr %47, @fair_sched_class
  br i1 %cmp.i79, label %if.then3.i, label %if.else.i

if.then3.i:                                       ; preds = %if.end.i77
  tail call void @reweight_task(ptr noundef %p, i32 noundef %sub.i75) #33
  br label %set_load_weight.exit

if.else.i:                                        ; preds = %if.end.i77
  %arrayidx.i = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %sub.i75
  %48 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx.i, align 4
  %50 = ptrtoint ptr %se.i to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 %49, ptr %se.i, align 4
  %arrayidx5.i = getelementptr [40 x i32], ptr @sched_prio_to_wmult, i32 0, i32 %sub.i75
  %51 = ptrtoint ptr %arrayidx5.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %arrayidx5.i, align 4
  %inv_weight6.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 0, i32 1
  %53 = ptrtoint ptr %inv_weight6.i to i32
  call void @__asan_store4_noabort(i32 %53)
  store i32 %52, ptr %inv_weight6.i, align 4
  br label %set_load_weight.exit

set_load_weight.exit:                             ; preds = %if.else.i, %if.then3.i, %if.then.i76
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %54 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %prio, align 8
  %56 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %policy.i, align 4
  %rt_priority.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 16
  %58 = ptrtoint ptr %rt_priority.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load i32, ptr %rt_priority.i.i, align 4
  %60 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %static_prio.i, align 4
  %cmp.i.not.i.i.i = icmp eq i32 %57, 6
  %62 = add i32 %57, -3
  %63 = icmp ult i32 %62, -2
  %sub.i.i.i = sub i32 99, %59
  %spec.select.i.i = select i1 %63, i32 %61, i32 %sub.i.i.i
  %prio.0.i.i.i = select i1 %cmp.i.not.i.i.i, i32 -1, i32 %spec.select.i.i
  %normal_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 15
  %64 = ptrtoint ptr %normal_prio.i to i32
  call void @__asan_store4_noabort(i32 %64)
  store i32 %prio.0.i.i.i, ptr %normal_prio.i, align 64
  %cmp.i.i81 = icmp sgt i32 %55, 99
  %retval.0.i = select i1 %cmp.i.i81, i32 %prio.0.i.i.i, i32 %55
  store i32 %retval.0.i, ptr %prio, align 8
  br i1 %cmp.i.not, label %if.then27, label %if.end28

if.then27:                                        ; preds = %set_load_weight.exit
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@set_user_nice, %if.end.i22.i)) #33
          to label %uclamp_rq_inc.exit.i [label %if.end.i22.i], !srcloc !1202

if.end.i22.i:                                     ; preds = %if.then27
  %sched_class.i.i83 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %65 = ptrtoint ptr %sched_class.i.i83 to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %sched_class.i.i83, align 32
  %67 = ptrtoint ptr %66 to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %66, align 4
  %tobool3.not.i.i84 = icmp eq i32 %68, 0
  br i1 %tobool3.not.i.i84, label %uclamp_rq_inc.exit.i, label %for.body.preheader.i.i85, !prof !1192

for.body.preheader.i.i85:                         ; preds = %if.end.i22.i
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call4, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call4, ptr noundef %p, i32 noundef 1) #33
  %uclamp_flags.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 12
  %69 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %uclamp_flags.i.i, align 16
  %and.i.i = and i32 %70, 1
  %tobool14.not.i.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool14.not.i.i, label %uclamp_rq_inc.exit.i, label %if.then15.i.i

if.then15.i.i:                                    ; preds = %for.body.preheader.i.i85
  %and17.i.i = and i32 %70, -2
  %71 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_store4_noabort(i32 %71)
  store i32 %and17.i.i, ptr %uclamp_flags.i.i, align 16
  br label %uclamp_rq_inc.exit.i

uclamp_rq_inc.exit.i:                             ; preds = %if.then15.i.i, %for.body.preheader.i.i85, %if.end.i22.i, %if.then27
  %sched_class.i86 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %72 = ptrtoint ptr %sched_class.i86 to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load ptr, ptr %sched_class.i86, align 32
  %enqueue_task.i = getelementptr inbounds %struct.sched_class, ptr %73, i32 0, i32 1
  %74 = ptrtoint ptr %enqueue_task.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load ptr, ptr %enqueue_task.i, align 4
  tail call void %75(ptr noundef %call4, ptr noundef %p, i32 noundef 10) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@set_user_nice, %land.rhs.i.i89)) #33
          to label %if.end28 [label %land.rhs.i.i89], !srcloc !1202

land.rhs.i.i89:                                   ; preds = %uclamp_rq_inc.exit.i
  %core_enabled.i.i87 = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 81
  %76 = ptrtoint ptr %core_enabled.i.i87 to i32
  call void @__asan_load4_noabort(i32 %76)
  %77 = load i32, ptr %core_enabled.i.i87, align 128
  %tobool3.i.not.i88 = icmp eq i32 %77, 0
  br i1 %tobool3.i.not.i88, label %if.end28, label %if.then7.i

if.then7.i:                                       ; preds = %land.rhs.i.i89
  tail call void @sched_core_enqueue(ptr noundef %call4, ptr noundef %p) #33
  br label %if.end28

if.end28:                                         ; preds = %if.then7.i, %land.rhs.i.i89, %uclamp_rq_inc.exit.i, %set_load_weight.exit
  br i1 %cmp.i69.not, label %if.then30, label %if.end31

if.then30:                                        ; preds = %if.end28
  %sched_class.i90 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %78 = ptrtoint ptr %sched_class.i90 to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load ptr, ptr %sched_class.i90, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %79, i32 0, i32 8
  %80 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load ptr, ptr %set_next_task.i, align 4
  tail call void %81(ptr noundef %call4, ptr noundef %p, i1 noundef zeroext false) #33
  br label %if.end31

if.end31:                                         ; preds = %if.then30, %if.end28
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %82 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %82)
  %83 = load ptr, ptr %sched_class, align 32
  %prio_changed = getelementptr inbounds %struct.sched_class, ptr %83, i32 0, i32 23
  %84 = ptrtoint ptr %prio_changed to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load ptr, ptr %prio_changed, align 4
  tail call void %85(ptr noundef %call4, ptr noundef %p, i32 noundef %55) #33
  br label %out_unlock

out_unlock:                                       ; preds = %if.end31, %if.then9
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 81
  %86 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %87, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %out_unlock
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 79
  %88 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %out_unlock
  %retval.0.i.i.i = phi ptr [ %89, %if.then.i.i.i ], [ %call4, %out_unlock ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %90 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %90)
  %.unpack.i.i = load i32, ptr %1, align 4
  %91 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %91) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@set_user_nice, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %92 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %93, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call4, i32 0, i32 79
  %94 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %95, %if.then.i.i4.i ], [ %call4, %land.rhs.i.i.i.i ], [ %call4, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %96 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %96)
  %97 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %97) #33
  br label %cleanup

cleanup:                                          ; preds = %task_rq_unlock.exit, %entry
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @can_nice(ptr nocapture noundef readonly %p, i32 noundef %nice) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %add.i = sub i32 20, %nice
  %signal.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 111
  %0 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %signal.i, align 16
  %arrayidx.i = getelementptr %struct.signal_struct, ptr %1, i32 0, i32 51, i32 13
  %2 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %arrayidx.i, align 8
  %cmp.not = icmp ugt i32 %add.i, %3
  br i1 %cmp.not, label %lor.rhs, label %lor.end

lor.rhs:                                          ; preds = %entry
  %call2 = tail call zeroext i1 @capable(i32 noundef 23) #33
  %phi.cast = zext i1 %call2 to i32
  br label %lor.end

lor.end:                                          ; preds = %lor.rhs, %entry
  %4 = phi i32 [ 1, %entry ], [ %phi.cast, %lor.rhs ]
  ret i32 %4
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_nice(i32 noundef %increment) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.smax.i32(i32 %increment, i32 -40) #33
  %1 = tail call i32 @llvm.smin.i32(i32 %0, i32 40) #33
  %2 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 2
  %4 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task.i, align 8
  %static_prio.i.i = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 14
  %6 = ptrtoint ptr %static_prio.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %static_prio.i.i, align 4
  %sub.i.i = add nsw i32 %1, -120
  %add.i = add i32 %sub.i.i, %7
  %8 = tail call i32 @llvm.smax.i32(i32 %add.i, i32 -20) #33
  %9 = tail call i32 @llvm.smin.i32(i32 %8, i32 19) #33
  %cmp21.i = icmp slt i32 %1, 0
  br i1 %cmp21.i, label %land.lhs.true.i, label %if.end.i

land.lhs.true.i:                                  ; preds = %entry
  %add.i.i.i = sub nsw i32 20, %9
  %signal.i.i.i = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 111
  %10 = ptrtoint ptr %signal.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %signal.i.i.i, align 16
  %arrayidx.i.i.i = getelementptr %struct.signal_struct, ptr %11, i32 0, i32 51, i32 13
  %12 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %arrayidx.i.i.i, align 8
  %cmp.not.i.i = icmp ugt i32 %add.i.i.i, %13
  br i1 %cmp.not.i.i, label %can_nice.exit.i, label %if.end.i

can_nice.exit.i:                                  ; preds = %land.lhs.true.i
  %call2.i.i = tail call zeroext i1 @capable(i32 noundef 23) #33
  br i1 %call2.i.i, label %if.end.i, label %__do_sys_nice.exit

if.end.i:                                         ; preds = %can_nice.exit.i, %land.lhs.true.i, %entry
  %14 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task.i, align 8
  %call27.i = tail call i32 @security_task_setnice(ptr noundef %15, i32 noundef %9) #33
  %tobool28.not.i = icmp eq i32 %call27.i, 0
  br i1 %tobool28.not.i, label %if.end30.i, label %__do_sys_nice.exit

if.end30.i:                                       ; preds = %if.end.i
  %16 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %task.i, align 8
  tail call void @set_user_nice(ptr noundef %17, i32 noundef %9) #33
  br label %__do_sys_nice.exit

__do_sys_nice.exit:                               ; preds = %if.end30.i, %if.end.i, %can_nice.exit.i
  %retval.0.i = phi i32 [ 0, %if.end30.i ], [ -1, %can_nice.exit.i ], [ %call27.i, %if.end.i ]
  ret i32 %retval.0.i
}

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @task_prio(ptr nocapture noundef readonly %p) local_unnamed_addr #8 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %0 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %prio, align 8
  %sub = add i32 %1, -100
  ret i32 %sub
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @available_idle_cpu(i32 noundef %cpu) local_unnamed_addr #4 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add.i to ptr
  %curr.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %3 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %curr.i, align 8
  %idle.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 21
  %5 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %idle.i, align 4
  %cmp.not.i = icmp eq ptr %4, %6
  br i1 %cmp.not.i, label %if.end.i, label %return

if.end.i:                                         ; preds = %entry
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 1
  %7 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %nr_running.i, align 4
  %tobool.not.i = icmp eq i32 %8, 0
  br i1 %tobool.not.i, label %idle_cpu.exit, label %return

idle_cpu.exit:                                    ; preds = %if.end.i
  %ttwu_pending.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 8
  %9 = ptrtoint ptr %ttwu_pending.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %ttwu_pending.i, align 8
  %tobool4.not.i.not = icmp eq i32 %10, 0
  %spec.select = zext i1 %tobool4.not.i.not to i32
  br label %return

return:                                           ; preds = %idle_cpu.exit, %if.end.i, %entry
  %retval.0 = phi i32 [ 0, %entry ], [ 0, %if.end.i ], [ %spec.select, %idle_cpu.exit ]
  ret i32 %retval.0
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local ptr @idle_task(i32 noundef %cpu) local_unnamed_addr #4 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %idle = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 21
  %3 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %idle, align 4
  ret ptr %4
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @effective_cpu_util(i32 noundef %cpu, i32 noundef %util_cfs, i32 noundef %max, i32 noundef %type, ptr noundef readonly %p) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @sched_uclamp_used, i32 1), ptr blockaddress(@effective_cpu_util, %l_yes.i.i)) #33
          to label %uclamp_is_used.exit [label %l_yes.i.i], !srcloc !1232

l_yes.i.i:                                        ; preds = %entry
  br label %uclamp_is_used.exit

uclamp_is_used.exit:                              ; preds = %l_yes.i.i, %entry
  %retval.0.i.i = phi i1 [ true, %l_yes.i.i ], [ false, %entry ]
  %cmp = icmp eq i32 %type, 0
  %or.cond = and i1 %cmp, %retval.0.i.i
  br i1 %or.cond, label %land.lhs.true2, label %if.end

land.lhs.true2:                                   ; preds = %uclamp_is_used.exit
  %rt_queued.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 15, i32 8
  %3 = ptrtoint ptr %rt_queued.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %rt_queued.i, align 4
  %tobool.not.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i, label %if.end, label %rt_rq_is_runnable.exit

rt_rq_is_runnable.exit:                           ; preds = %land.lhs.true2
  %rt_nr_running.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 15, i32 1
  %5 = ptrtoint ptr %rt_nr_running.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %rt_nr_running.i, align 8
  %tobool1.i.not = icmp eq i32 %6, 0
  br i1 %tobool1.i.not, label %if.end, label %cleanup

if.end:                                           ; preds = %rt_rq_is_runnable.exit, %land.lhs.true2, %uclamp_is_used.exit
  %util_avg.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 52, i32 7
  %7 = ptrtoint ptr %util_avg.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %util_avg.i, align 8
  %cmp5.not = icmp ult i32 %8, %max
  br i1 %cmp5.not, label %if.end8, label %cleanup, !prof !1191

if.end8:                                          ; preds = %if.end
  %util_avg.i61 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 50, i32 7
  %9 = ptrtoint ptr %util_avg.i61 to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %util_avg.i61, align 8
  %add10 = add i32 %10, %util_cfs
  br i1 %cmp, label %if.then12, label %if.end14

if.then12:                                        ; preds = %if.end8
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @sched_uclamp_used, i32 1), ptr blockaddress(@effective_cpu_util, %if.end14)) #33
          to label %if.end.i [label %if.end14], !srcloc !1232

if.end.i:                                         ; preds = %if.then12
  %tobool4.not.i = icmp eq ptr %p, null
  br i1 %tobool4.not.i, label %if.end11.i, label %if.then5.i

if.then5.i:                                       ; preds = %if.end.i
  %arrayidx.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 0
  %11 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load2_noabort(i32 %11)
  %bf.load.i.i = load i16, ptr %arrayidx.i.i, align 4
  %12 = and i16 %bf.load.i.i, 2
  %tobool.not.i.i = icmp eq i16 %12, 0
  br i1 %tobool.not.i.i, label %if.end.i.i, label %uclamp_eff_value.exit.i

if.end.i.i:                                       ; preds = %if.then5.i
  %arrayidx.i.i.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 0
  %13 = ptrtoint ptr %arrayidx.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %arrayidx.i.i.i.i, align 4
  %retval.sroa.0.0.extract.shift.i.i.i.i = lshr i32 %14, 16
  %retval.sroa.0.0.extract.trunc.i.i.i.i = trunc i32 %retval.sroa.0.0.extract.shift.i.i.i.i to i16
  %sched_task_group.i.i.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %15 = ptrtoint ptr %sched_task_group.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %sched_task_group.i.i.i.i.i, align 8
  %autogroup.i.i.i.i.i = getelementptr inbounds %struct.task_group, ptr %16, i32 0, i32 15
  %17 = ptrtoint ptr %autogroup.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %autogroup.i.i.i.i.i, align 4
  %tobool.i.i.i.i.i = icmp ne ptr %18, null
  %cmp.i.i.i.i = icmp eq ptr %16, @root_task_group
  %or.cond.i.i.i.i = select i1 %tobool.i.i.i.i.i, i1 true, i1 %cmp.i.i.i.i
  br i1 %or.cond.i.i.i.i, label %uclamp_tg_restrict.exit.i.i.i, label %if.end4.i.i.i.i

if.end4.i.i.i.i:                                  ; preds = %if.end.i.i
  %uclamp.i.i.i.i = getelementptr inbounds %struct.task_group, ptr %16, i32 0, i32 19
  %19 = ptrtoint ptr %uclamp.i.i.i.i to i32
  call void @__asan_load2_noabort(i32 %19)
  %bf.load.i.i.i.i = load i16, ptr %uclamp.i.i.i.i, align 16
  %bf.lshr.i.i.i.i = lshr i16 %bf.load.i.i.i.i, 5
  %arrayidx9.i.i.i.i = getelementptr %struct.task_group, ptr %16, i32 0, i32 19, i32 1
  %20 = ptrtoint ptr %arrayidx9.i.i.i.i to i32
  call void @__asan_load2_noabort(i32 %20)
  %bf.load10.i.i.i.i = load i16, ptr %arrayidx9.i.i.i.i, align 4
  %bf.lshr11.i.i.i.i = lshr i16 %bf.load10.i.i.i.i, 5
  %bf.lshr14.i.i.i.i = lshr i16 %retval.sroa.0.0.extract.trunc.i.i.i.i, 5
  %21 = tail call i16 @llvm.umax.i16(i16 %bf.lshr14.i.i.i.i, i16 %bf.lshr.i.i.i.i) #33
  %22 = tail call i16 @llvm.umin.i16(i16 %21, i16 %bf.lshr11.i.i.i.i) #33
  %bf.shl.i.i.i.i.i = shl nuw i16 %22, 5
  %cmp10.i.i.i.i.i.i = icmp ult i16 %22, 820
  %bf.shl3.i.i.i.i.i = select i1 %cmp10.i.i.i.i.i.i, i16 0, i16 16
  %bf.set5.i.i.i.i.i = or i16 %bf.shl3.i.i.i.i.i, %bf.shl.i.i.i.i.i
  br label %uclamp_tg_restrict.exit.i.i.i

uclamp_tg_restrict.exit.i.i.i:                    ; preds = %if.end4.i.i.i.i, %if.end.i.i
  %retval.sroa.0.0.i.i.i.i = phi i16 [ %retval.sroa.0.0.extract.trunc.i.i.i.i, %if.end.i.i ], [ %bf.set5.i.i.i.i.i, %if.end4.i.i.i.i ]
  %uc_max.sroa.0.0.copyload.i.i.i = load i16, ptr @uclamp_default, align 4
  %23 = lshr i16 %retval.sroa.0.0.i.i.i.i, 5
  %bf.lshr2.i.i.i = lshr i16 %uc_max.sroa.0.0.copyload.i.i.i, 5
  %cmp.i.i.i = icmp ugt i16 %23, %bf.lshr2.i.i.i
  %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i.i.i = select i1 %cmp.i.i.i, i16 %uc_max.sroa.0.0.copyload.i.i.i, i16 %retval.sroa.0.0.i.i.i.i, !prof !1192
  br label %uclamp_eff_value.exit.i

uclamp_eff_value.exit.i:                          ; preds = %uclamp_tg_restrict.exit.i.i.i, %if.then5.i
  %retval.0.in.in.i.i = phi i16 [ %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i.i.i, %uclamp_tg_restrict.exit.i.i.i ], [ %bf.load.i.i, %if.then5.i ]
  %retval.0.in.i.i = lshr i16 %retval.0.in.in.i.i, 5
  %retval.0.i68.i = zext i16 %retval.0.in.i.i to i32
  %arrayidx.i69.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 1
  %24 = ptrtoint ptr %arrayidx.i69.i to i32
  call void @__asan_load2_noabort(i32 %24)
  %bf.load.i70.i = load i16, ptr %arrayidx.i69.i, align 4
  %25 = and i16 %bf.load.i70.i, 2
  %tobool.not.i71.i = icmp eq i16 %25, 0
  br i1 %tobool.not.i71.i, label %if.end.i80.i, label %uclamp_eff_value.exit102.i

if.end.i80.i:                                     ; preds = %uclamp_eff_value.exit.i
  %arrayidx.i.i.i72.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 1
  %26 = ptrtoint ptr %arrayidx.i.i.i72.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %arrayidx.i.i.i72.i, align 4
  %retval.sroa.0.0.extract.shift.i.i.i73.i = lshr i32 %27, 16
  %retval.sroa.0.0.extract.trunc.i.i.i74.i = trunc i32 %retval.sroa.0.0.extract.shift.i.i.i73.i to i16
  %sched_task_group.i.i.i.i75.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %28 = ptrtoint ptr %sched_task_group.i.i.i.i75.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %sched_task_group.i.i.i.i75.i, align 8
  %autogroup.i.i.i.i76.i = getelementptr inbounds %struct.task_group, ptr %29, i32 0, i32 15
  %30 = ptrtoint ptr %autogroup.i.i.i.i76.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %autogroup.i.i.i.i76.i, align 4
  %tobool.i.i.i.i77.i = icmp ne ptr %31, null
  %cmp.i.i.i78.i = icmp eq ptr %29, @root_task_group
  %or.cond.i.i.i79.i = select i1 %tobool.i.i.i.i77.i, i1 true, i1 %cmp.i.i.i78.i
  br i1 %or.cond.i.i.i79.i, label %uclamp_tg_restrict.exit.i.i98.i, label %if.end4.i.i.i92.i

if.end4.i.i.i92.i:                                ; preds = %if.end.i80.i
  %uclamp.i.i.i81.i = getelementptr inbounds %struct.task_group, ptr %29, i32 0, i32 19
  %32 = ptrtoint ptr %uclamp.i.i.i81.i to i32
  call void @__asan_load2_noabort(i32 %32)
  %bf.load.i.i.i82.i = load i16, ptr %uclamp.i.i.i81.i, align 16
  %bf.lshr.i.i.i83.i = lshr i16 %bf.load.i.i.i82.i, 5
  %arrayidx9.i.i.i84.i = getelementptr %struct.task_group, ptr %29, i32 0, i32 19, i32 1
  %33 = ptrtoint ptr %arrayidx9.i.i.i84.i to i32
  call void @__asan_load2_noabort(i32 %33)
  %bf.load10.i.i.i85.i = load i16, ptr %arrayidx9.i.i.i84.i, align 4
  %bf.lshr11.i.i.i86.i = lshr i16 %bf.load10.i.i.i85.i, 5
  %bf.lshr14.i.i.i87.i = lshr i16 %retval.sroa.0.0.extract.trunc.i.i.i74.i, 5
  %34 = tail call i16 @llvm.umax.i16(i16 %bf.lshr14.i.i.i87.i, i16 %bf.lshr.i.i.i83.i) #33
  %35 = tail call i16 @llvm.umin.i16(i16 %34, i16 %bf.lshr11.i.i.i86.i) #33
  %bf.shl.i.i.i.i88.i = shl nuw i16 %35, 5
  %cmp10.i.i.i.i.i89.i = icmp ult i16 %35, 820
  %bf.shl3.i.i.i.i90.i = select i1 %cmp10.i.i.i.i.i89.i, i16 0, i16 16
  %bf.set5.i.i.i.i91.i = or i16 %bf.shl3.i.i.i.i90.i, %bf.shl.i.i.i.i88.i
  br label %uclamp_tg_restrict.exit.i.i98.i

uclamp_tg_restrict.exit.i.i98.i:                  ; preds = %if.end4.i.i.i92.i, %if.end.i80.i
  %retval.sroa.0.0.i.i.i93.i = phi i16 [ %retval.sroa.0.0.extract.trunc.i.i.i74.i, %if.end.i80.i ], [ %bf.set5.i.i.i.i91.i, %if.end4.i.i.i92.i ]
  %uc_max.sroa.0.0.copyload.i.i94.i = load i16, ptr getelementptr inbounds ([2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 1), align 4
  %36 = lshr i16 %retval.sroa.0.0.i.i.i93.i, 5
  %bf.lshr2.i.i95.i = lshr i16 %uc_max.sroa.0.0.copyload.i.i94.i, 5
  %cmp.i.i96.i = icmp ugt i16 %36, %bf.lshr2.i.i95.i
  %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i.i97.i = select i1 %cmp.i.i96.i, i16 %uc_max.sroa.0.0.copyload.i.i94.i, i16 %retval.sroa.0.0.i.i.i93.i, !prof !1192
  br label %uclamp_eff_value.exit102.i

uclamp_eff_value.exit102.i:                       ; preds = %uclamp_tg_restrict.exit.i.i98.i, %uclamp_eff_value.exit.i
  %retval.0.in.in.i99.i = phi i16 [ %uc_max.sroa.0.0.copyload.i.retval.sroa.0.0.i.i.i97.i, %uclamp_tg_restrict.exit.i.i98.i ], [ %bf.load.i70.i, %uclamp_eff_value.exit.i ]
  %retval.0.in.i100.i = lshr i16 %retval.0.in.in.i99.i, 5
  %retval.0.i101.i = zext i16 %retval.0.in.i100.i to i32
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 12
  %37 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %uclamp_flags.i, align 16
  %and.i = and i32 %38, 1
  %tobool8.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool8.not.i, label %if.end11.i, label %out.i

if.end11.i:                                       ; preds = %uclamp_eff_value.exit102.i, %if.end.i
  %max_util.0.i = phi i32 [ %retval.0.i101.i, %uclamp_eff_value.exit102.i ], [ 0, %if.end.i ]
  %min_util.0.i = phi i32 [ %retval.0.i68.i, %uclamp_eff_value.exit102.i ], [ 0, %if.end.i ]
  %uclamp.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 11
  %39 = ptrtoint ptr %uclamp.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load volatile i32, ptr %uclamp.i, align 128
  %41 = tail call i32 @llvm.umax.i32(i32 %min_util.0.i, i32 %40) #33
  %arrayidx19.i = getelementptr %struct.rq, ptr %2, i32 0, i32 11, i32 1
  %42 = ptrtoint ptr %arrayidx19.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %arrayidx19.i, align 8
  %44 = tail call i32 @llvm.umax.i32(i32 %max_util.0.i, i32 %43) #33
  br label %out.i

out.i:                                            ; preds = %if.end11.i, %uclamp_eff_value.exit102.i
  %max_util.1.i = phi i32 [ %retval.0.i101.i, %uclamp_eff_value.exit102.i ], [ %44, %if.end11.i ]
  %min_util.1.i = phi i32 [ %retval.0.i68.i, %uclamp_eff_value.exit102.i ], [ %41, %if.end11.i ]
  %cmp27.not.i = icmp ult i32 %min_util.1.i, %max_util.1.i
  br i1 %cmp27.not.i, label %if.end35.i, label %if.end14, !prof !1191

if.end35.i:                                       ; preds = %out.i
  %45 = tail call i32 @llvm.umax.i32(i32 %min_util.1.i, i32 %add10) #33
  %46 = tail call i32 @llvm.umin.i32(i32 %45, i32 %max_util.1.i) #33
  br label %if.end14

if.end14:                                         ; preds = %if.end35.i, %out.i, %if.then12, %if.end8
  %util.0 = phi i32 [ %add10, %if.end8 ], [ %46, %if.end35.i ], [ %min_util.1.i, %out.i ], [ %add10, %if.then12 ]
  %util_avg.i62 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 51, i32 7
  %47 = ptrtoint ptr %util_avg.i62 to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load volatile i32, ptr %util_avg.i62, align 8
  %add16 = add i32 %48, %util.0
  %cmp17.not = icmp ult i32 %add16, %max
  br i1 %cmp17.not, label %if.end19, label %cleanup

if.end19:                                         ; preds = %if.end14
  %cmp20 = icmp eq i32 %type, 1
  %spec.select = select i1 %cmp20, i32 %add16, i32 %util.0
  %sub.i = sub i32 %max, %8
  %mul.i = mul i32 %spec.select, %sub.i
  %div.i = udiv i32 %mul.i, %max
  %add25 = add i32 %div.i, %8
  br i1 %cmp, label %if.then27, label %if.end30

if.then27:                                        ; preds = %if.end19
  %running_bw.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 16, i32 6
  %49 = ptrtoint ptr %running_bw.i to i32
  call void @__asan_load8_noabort(i32 %49)
  %50 = load i64, ptr %running_bw.i, align 8
  %51 = lshr i64 %50, 10
  %conv.i = trunc i64 %51 to i32
  %add29 = add i32 %add25, %conv.i
  br label %if.end30

if.end30:                                         ; preds = %if.then27, %if.end19
  %util.2 = phi i32 [ %add29, %if.then27 ], [ %add25, %if.end19 ]
  %52 = tail call i32 @llvm.umin.i32(i32 %util.2, i32 %max)
  br label %cleanup

cleanup:                                          ; preds = %if.end30, %if.end14, %if.end, %rt_rq_is_runnable.exit
  %retval.0 = phi i32 [ %52, %if.end30 ], [ %max, %rt_rq_is_runnable.exit ], [ %max, %if.end ], [ %max, %if.end14 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_util(i32 noundef %cpu, i32 noundef %max) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add.i to ptr
  %util_avg.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 14, i32 17, i32 7
  %3 = ptrtoint ptr %util_avg.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %util_avg.i, align 8
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr (i8, ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 20), i32 1), ptr blockaddress(@sched_cpu_util, %cpu_util_cfs.exit)) #33
          to label %if.then.i [label %cpu_util_cfs.exit], !srcloc !1202

if.then.i:                                        ; preds = %entry
  %util_est.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 14, i32 17, i32 9
  %5 = ptrtoint ptr %util_est.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %util_est.i, align 16
  %7 = tail call i32 @llvm.umax.i32(i32 %4, i32 %6) #33
  br label %cpu_util_cfs.exit

cpu_util_cfs.exit:                                ; preds = %if.then.i, %entry
  %util.0.i = phi i32 [ %7, %if.then.i ], [ %4, %entry ]
  %8 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx.i, align 4
  %add.i.i = add i32 %9, ptrtoint (ptr @runqueues to i32)
  %10 = inttoptr i32 %add.i.i to ptr
  %cpu_capacity_orig.i.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 38
  %11 = ptrtoint ptr %cpu_capacity_orig.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu_capacity_orig.i.i, align 4
  %13 = tail call i32 @llvm.umin.i32(i32 %util.0.i, i32 %12) #33
  callbr void asm sideeffect "1:\0A\09b ${1:l}\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @sched_uclamp_used, i32 1), ptr blockaddress(@sched_cpu_util, %l_yes.i.i.i)) #33
          to label %uclamp_is_used.exit.i [label %l_yes.i.i.i], !srcloc !1232

l_yes.i.i.i:                                      ; preds = %cpu_util_cfs.exit
  br label %uclamp_is_used.exit.i

uclamp_is_used.exit.i:                            ; preds = %l_yes.i.i.i, %cpu_util_cfs.exit
  %util_avg.i.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 52, i32 7
  %14 = ptrtoint ptr %util_avg.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %util_avg.i.i, align 8
  %cmp5.not.i = icmp ult i32 %15, %max
  br i1 %cmp5.not.i, label %if.end8.i, label %effective_cpu_util.exit, !prof !1191

if.end8.i:                                        ; preds = %uclamp_is_used.exit.i
  %util_avg.i61.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 50, i32 7
  %16 = ptrtoint ptr %util_avg.i61.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %util_avg.i61.i, align 8
  %add10.i = add i32 %17, %13
  %util_avg.i62.i = getelementptr inbounds %struct.rq, ptr %10, i32 0, i32 51, i32 7
  %18 = ptrtoint ptr %util_avg.i62.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %util_avg.i62.i, align 8
  %add16.i = add i32 %add10.i, %19
  %cmp17.not.i = icmp ult i32 %add16.i, %max
  br i1 %cmp17.not.i, label %if.end19.i, label %effective_cpu_util.exit

if.end19.i:                                       ; preds = %if.end8.i
  %sub.i.i = sub i32 %max, %15
  %mul.i.i = mul i32 %add16.i, %sub.i.i
  %div.i.i = udiv i32 %mul.i.i, %max
  %add25.i = add i32 %div.i.i, %15
  %20 = tail call i32 @llvm.umin.i32(i32 %add25.i, i32 %max) #33
  br label %effective_cpu_util.exit

effective_cpu_util.exit:                          ; preds = %if.end19.i, %if.end8.i, %uclamp_is_used.exit.i
  %retval.0.i = phi i32 [ %20, %if.end19.i ], [ %max, %uclamp_is_used.exit.i ], [ %max, %if.end8.i ]
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_setscheduler(ptr noundef %p, i32 noundef %policy, ptr nocapture noundef readonly %param) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i) #33
  %0 = call ptr @memset(ptr %attr.i, i32 0, i32 56)
  %sched_policy.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 1
  %1 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 %policy, ptr %sched_policy.i, align 4
  %sched_nice.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 3
  %static_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %2 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %static_prio.i, align 4
  %sub.i = add i32 %3, -120
  %4 = ptrtoint ptr %sched_nice.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %sub.i, ptr %sched_nice.i, align 8
  %sched_priority.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 4
  %5 = ptrtoint ptr %param to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %param, align 4
  %7 = ptrtoint ptr %sched_priority.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 %6, ptr %sched_priority.i, align 4
  %cmp.not.i = icmp eq i32 %policy, -1
  %and.i = and i32 %policy, 1073741824
  %tobool.not.i = icmp eq i32 %and.i, 0
  %or.cond.i = or i1 %cmp.not.i, %tobool.not.i
  br i1 %or.cond.i, label %_sched_setscheduler.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  %sched_flags.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 2
  %8 = ptrtoint ptr %sched_flags.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %sched_flags.i, align 8
  %or.i = or i64 %9, 1
  store i64 %or.i, ptr %sched_flags.i, align 8
  %and2.i = and i32 %policy, -1073741825
  %10 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %and2.i, ptr %sched_policy.i, align 4
  br label %_sched_setscheduler.exit

_sched_setscheduler.exit:                         ; preds = %if.then.i, %entry
  %call.i = call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef nonnull %attr.i, i1 noundef zeroext true, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i) #33
  ret i32 %call.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_setattr(ptr noundef %p, ptr noundef %attr) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef %attr, i1 noundef zeroext true, i1 noundef zeroext true)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef %attr, i1 noundef zeroext %user, i1 noundef zeroext %pi) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %sched_policy = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 1
  %0 = ptrtoint ptr %sched_policy to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %sched_policy, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %2 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %5 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 -1, ptr %5, align 4, !annotation !1193
  br i1 %pi, label %land.rhs, label %recheck.preheader

recheck.preheader:                                ; preds = %land.rhs, %entry
  %sched_flags = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 2
  %sched_reset_on_fork = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 63
  %policy18 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 31
  %sched_priority = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 4
  %sched_nice = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 3
  %static_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %signal.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 111
  %rt_priority = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 16
  %uclamp_req.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26
  %arrayidx2.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 1
  %sched_util_min.i = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 8
  %sched_util_max.i = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 9
  %sched_task_group.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  br label %recheck

land.rhs:                                         ; preds = %entry
  %7 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 15728640
  %11 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i454 = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i454 to ptr
  %preempt_count.i455 = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i455 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i455, align 4
  %and4 = and i32 %14, 983040
  %or = or i32 %and4, %and
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i456 = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i456 to ptr
  %preempt_count.i457 = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i457 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i457, align 4
  %and6 = and i32 %18, 65280
  %or7 = or i32 %or, %and6
  %tobool8.not = icmp eq i32 %or7, 0
  br i1 %tobool8.not, label %recheck.preheader, label %do.body11, !prof !1191

do.body11:                                        ; preds = %land.rhs
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 7257, 0\0A.popsection", ""() #33, !srcloc !1294
  unreachable

recheck:                                          ; preds = %recheck.backedge, %recheck.preheader
  %policy.0 = phi i32 [ %1, %recheck.preheader ], [ -1, %recheck.backedge ]
  %cmp = icmp slt i32 %policy.0, 0
  br i1 %cmp, label %if.then17, label %if.else

if.then17:                                        ; preds = %recheck
  %19 = ptrtoint ptr %sched_reset_on_fork to i32
  call void @__asan_load1_noabort(i32 %19)
  %bf.load = load i8, ptr %sched_reset_on_fork, align 4
  %bf.lshr = lshr i8 %bf.load, 7
  %bf.cast = zext i8 %bf.lshr to i32
  %20 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %policy18, align 4
  br label %if.end28

if.else:                                          ; preds = %recheck
  %22 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %22)
  %23 = load i64, ptr %sched_flags, align 8
  %24 = trunc i64 %23 to i32
  %25 = and i32 %24, 1
  switch i32 %policy.0, label %cleanup312 [
    i32 5, label %if.end28
    i32 3, label %if.end28
    i32 0, label %if.end28
    i32 6, label %if.end28
    i32 2, label %if.end28
    i32 1, label %if.end28
  ]

if.end28:                                         ; preds = %if.else, %if.else, %if.else, %if.else, %if.else, %if.else, %if.then17
  %oldpolicy.1 = phi i32 [ %21, %if.then17 ], [ -1, %if.else ], [ -1, %if.else ], [ -1, %if.else ], [ -1, %if.else ], [ -1, %if.else ], [ -1, %if.else ]
  %policy.1 = phi i32 [ %21, %if.then17 ], [ %policy.0, %if.else ], [ %policy.0, %if.else ], [ %policy.0, %if.else ], [ %policy.0, %if.else ], [ %policy.0, %if.else ], [ %policy.0, %if.else ]
  %reset_on_fork.0 = phi i32 [ %bf.cast, %if.then17 ], [ %25, %if.else ], [ %25, %if.else ], [ %25, %if.else ], [ %25, %if.else ], [ %25, %if.else ], [ %25, %if.else ]
  %26 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %26)
  %27 = load i64, ptr %sched_flags, align 8
  %and30 = and i64 %27, -268435584
  %tobool31.not = icmp eq i64 %and30, 0
  br i1 %tobool31.not, label %if.end33, label %cleanup312

if.end33:                                         ; preds = %if.end28
  %28 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %sched_priority, align 4
  %cmp34 = icmp ugt i32 %29, 99
  br i1 %cmp34, label %cleanup312, label %if.end36

if.end36:                                         ; preds = %if.end33
  %cmp.i = icmp eq i32 %policy.1, 6
  br i1 %cmp.i, label %land.lhs.true, label %lor.lhs.false

land.lhs.true:                                    ; preds = %if.end36
  %call39 = tail call zeroext i1 @__checkparam_dl(ptr noundef %attr) #33
  br i1 %call39, label %lor.lhs.false, label %cleanup312

lor.lhs.false:                                    ; preds = %land.lhs.true, %if.end36
  %30 = add i32 %policy.1, -1
  %31 = icmp ult i32 %30, 2
  %32 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %sched_priority, align 4
  %cmp42 = icmp eq i32 %33, 0
  %cmp43.not = xor i1 %31, %cmp42
  br i1 %cmp43.not, label %if.end46, label %cleanup312

if.end46:                                         ; preds = %lor.lhs.false
  br i1 %user, label %land.lhs.true49, label %if.end126

land.lhs.true49:                                  ; preds = %if.end46
  %call50 = tail call zeroext i1 @capable(i32 noundef 23) #33
  br i1 %call50, label %if.then116, label %if.then51

if.then51:                                        ; preds = %land.lhs.true49
  switch i32 %policy.1, label %if.end64 [
    i32 3, label %if.then54
    i32 0, label %if.then54
  ]

if.then54:                                        ; preds = %if.then51, %if.then51
  %34 = ptrtoint ptr %sched_nice to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %sched_nice, align 8
  %36 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %static_prio.i, align 4
  %sub.i461 = add i32 %37, -120
  %cmp56 = icmp slt i32 %35, %sub.i461
  br i1 %cmp56, label %land.lhs.true58, label %if.end64

land.lhs.true58:                                  ; preds = %if.then54
  %add.i.i = sub i32 20, %35
  %38 = ptrtoint ptr %signal.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %signal.i.i, align 16
  %arrayidx.i.i = getelementptr %struct.signal_struct, ptr %39, i32 0, i32 51, i32 13
  %40 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %arrayidx.i.i, align 8
  %cmp.not.i = icmp ugt i32 %add.i.i, %41
  br i1 %cmp.not.i, label %can_nice.exit, label %if.end64

can_nice.exit:                                    ; preds = %land.lhs.true58
  %call2.i = tail call zeroext i1 @capable(i32 noundef 23) #33
  br i1 %call2.i, label %if.end64, label %cleanup312

if.end64:                                         ; preds = %can_nice.exit, %land.lhs.true58, %if.then54, %if.then51
  br i1 %31, label %if.then67, label %if.end85

if.then67:                                        ; preds = %if.end64
  %42 = ptrtoint ptr %signal.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %signal.i.i, align 16
  %arrayidx.i = getelementptr %struct.signal_struct, ptr %43, i32 0, i32 51, i32 14
  %44 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load volatile i32, ptr %arrayidx.i, align 8
  %46 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %policy18, align 4
  %cmp70.not = icmp ne i32 %policy.1, %47
  %tobool73.not = icmp eq i32 %45, 0
  %or.cond = select i1 %cmp70.not, i1 %tobool73.not, i1 false
  br i1 %or.cond, label %cleanup312, label %if.end75

if.end75:                                         ; preds = %if.then67
  %48 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %sched_priority, align 4
  %50 = ptrtoint ptr %rt_priority to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %rt_priority, align 4
  %cmp77 = icmp ugt i32 %49, %51
  %cmp81 = icmp ugt i32 %49, %45
  %or.cond449 = select i1 %cmp77, i1 %cmp81, i1 false
  %brmerge = select i1 %or.cond449, i1 true, i1 %cmp.i
  br i1 %brmerge, label %cleanup312, label %if.end89

if.end85:                                         ; preds = %if.end64
  br i1 %cmp.i, label %cleanup312, label %if.end89

if.end89:                                         ; preds = %if.end85, %if.end75
  %52 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %policy18, align 4
  %cmp.i.i.not = icmp ne i32 %53, 5
  %cmp.i464.not = icmp eq i32 %policy.1, 5
  %or.cond577 = select i1 %cmp.i.i.not, i1 true, i1 %cmp.i464.not
  br i1 %or.cond577, label %if.end101, label %if.then95

if.then95:                                        ; preds = %if.end89
  %54 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %static_prio.i, align 4
  %add.i.i468 = sub i32 140, %55
  %56 = ptrtoint ptr %signal.i.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %signal.i.i, align 16
  %arrayidx.i.i470 = getelementptr %struct.signal_struct, ptr %57, i32 0, i32 51, i32 13
  %58 = ptrtoint ptr %arrayidx.i.i470 to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load volatile i32, ptr %arrayidx.i.i470, align 8
  %cmp.not.i471 = icmp ugt i32 %add.i.i468, %59
  br i1 %cmp.not.i471, label %can_nice.exit475, label %if.end101

can_nice.exit475:                                 ; preds = %if.then95
  %call2.i472 = tail call zeroext i1 @capable(i32 noundef 23) #33
  br i1 %call2.i472, label %if.end101, label %cleanup312

if.end101:                                        ; preds = %can_nice.exit475, %if.then95, %if.end89
  %call102 = tail call fastcc zeroext i1 @check_same_owner(ptr noundef %p)
  br i1 %call102, label %if.end104, label %cleanup312

if.end104:                                        ; preds = %if.end101
  %60 = ptrtoint ptr %sched_reset_on_fork to i32
  call void @__asan_load1_noabort(i32 %60)
  %bf.load106 = load i8, ptr %sched_reset_on_fork, align 4
  %tobool109.not = icmp slt i8 %bf.load106, 0
  %tobool111.not = icmp eq i32 %reset_on_fork.0, 0
  %or.cond450 = select i1 %tobool109.not, i1 %tobool111.not, i1 false
  br i1 %or.cond450, label %cleanup312, label %if.then116

if.then116:                                       ; preds = %if.end104, %land.lhs.true49
  %61 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %61)
  %62 = load i64, ptr %sched_flags, align 8
  %and118 = and i64 %62, 268435456
  %tobool119.not = icmp eq i64 %and118, 0
  br i1 %tobool119.not, label %if.end121, label %cleanup312

if.end121:                                        ; preds = %if.then116
  %call122 = tail call i32 @security_task_setscheduler(ptr noundef %p) #33
  %tobool123.not = icmp eq i32 %call122, 0
  br i1 %tobool123.not, label %if.end126, label %cleanup312

if.end126:                                        ; preds = %if.end121, %if.end46
  %63 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %63)
  %64 = load i64, ptr %sched_flags, align 8
  %and128 = and i64 %64, 96
  %tobool129.not = icmp eq i64 %and128, 0
  br i1 %tobool129.not, label %if.end135, label %if.then130

if.then130:                                       ; preds = %if.end126
  %65 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %65)
  %bf.load.i = load i16, ptr %uclamp_req.i, align 4
  %bf.lshr.i = lshr i16 %bf.load.i, 5
  %bf.cast.i = zext i16 %bf.lshr.i to i32
  %66 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_load2_noabort(i32 %66)
  %bf.load3.i = load i16, ptr %arrayidx2.i, align 4
  %bf.lshr4.i = lshr i16 %bf.load3.i, 5
  %bf.cast5.i = zext i16 %bf.lshr4.i to i32
  %and.i = and i64 %64, 32
  %tobool.not.i = icmp eq i64 %and.i, 0
  br i1 %tobool.not.i, label %if.end7.i, label %if.then.i

if.then.i:                                        ; preds = %if.then130
  %67 = ptrtoint ptr %sched_util_min.i to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %sched_util_min.i, align 8
  %add.i476 = add i32 %68, 1
  %cmp.i477 = icmp sgt i32 %add.i476, 1025
  br i1 %cmp.i477, label %cleanup312, label %if.end7.i

if.end7.i:                                        ; preds = %if.then.i, %if.then130
  %util_min.0.i = phi i32 [ %68, %if.then.i ], [ %bf.cast.i, %if.then130 ]
  %and9.i = and i64 %64, 64
  %tobool10.not.i = icmp eq i64 %and9.i, 0
  br i1 %tobool10.not.i, label %if.end16.i, label %if.then11.i

if.then11.i:                                      ; preds = %if.end7.i
  %69 = ptrtoint ptr %sched_util_max.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %sched_util_max.i, align 4
  %add12.i = add i32 %70, 1
  %cmp13.i = icmp sgt i32 %add12.i, 1025
  br i1 %cmp13.i, label %cleanup312, label %if.end16.i

if.end16.i:                                       ; preds = %if.then11.i, %if.end7.i
  %util_max.0.i = phi i32 [ %70, %if.then11.i ], [ %bf.cast5.i, %if.end7.i ]
  %cmp17.not.i = icmp ne i32 %util_min.0.i, -1
  %cmp18.not.i = icmp ne i32 %util_max.0.i, -1
  %or.cond.i = select i1 %cmp17.not.i, i1 %cmp18.not.i, i1 false
  %cmp20.i = icmp sgt i32 %util_min.0.i, %util_max.0.i
  %or.cond32.i = select i1 %or.cond.i, i1 %cmp20.i, i1 false
  br i1 %or.cond32.i, label %cleanup312, label %uclamp_validate.exit

uclamp_validate.exit:                             ; preds = %if.end16.i
  tail call void @static_key_enable(ptr noundef nonnull @sched_uclamp_used) #33
  br label %if.end135

if.end135:                                        ; preds = %uclamp_validate.exit, %if.end126
  br i1 %pi, label %if.then137, label %if.end138

if.then137:                                       ; preds = %if.end135
  tail call void @cpuset_read_lock() #33
  br label %if.end138

if.end138:                                        ; preds = %if.then137, %if.end135
  %call139 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call139)
  %stop = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 22
  %71 = ptrtoint ptr %stop to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load ptr, ptr %stop, align 16
  %cmp140 = icmp eq ptr %72, %p
  br i1 %cmp140, label %unlock, label %if.end143

if.end143:                                        ; preds = %if.end138
  %73 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load i32, ptr %policy18, align 4
  %cmp145 = icmp eq i32 %policy.1, %74
  br i1 %cmp145, label %if.then153, label %change, !prof !1192

if.then153:                                       ; preds = %if.end143
  switch i32 %policy.1, label %if.end162 [
    i32 3, label %land.lhs.true156
    i32 0, label %land.lhs.true156
  ]

land.lhs.true156:                                 ; preds = %if.then153, %if.then153
  %75 = ptrtoint ptr %sched_nice to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load i32, ptr %sched_nice, align 8
  %77 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %static_prio.i, align 4
  %sub.i482 = add i32 %78, -120
  %cmp159.not = icmp eq i32 %76, %sub.i482
  br i1 %cmp159.not, label %if.end162, label %change

if.end162:                                        ; preds = %land.lhs.true156, %if.then153
  br i1 %31, label %land.lhs.true165, label %if.end171

land.lhs.true165:                                 ; preds = %if.end162
  %79 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load i32, ptr %sched_priority, align 4
  %81 = ptrtoint ptr %rt_priority to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %rt_priority, align 4
  %cmp168.not = icmp eq i32 %80, %82
  br i1 %cmp168.not, label %if.end171, label %change

if.end171:                                        ; preds = %land.lhs.true165, %if.end162
  br i1 %cmp.i, label %land.lhs.true174, label %if.end178

land.lhs.true174:                                 ; preds = %if.end171
  %call175 = tail call zeroext i1 @dl_param_changed(ptr noundef %p, ptr noundef %attr) #33
  br i1 %call175, label %change, label %if.end178

if.end178:                                        ; preds = %land.lhs.true174, %if.end171
  %83 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %83)
  %84 = load i64, ptr %sched_flags, align 8
  %and180 = and i64 %84, 96
  %tobool181.not = icmp eq i64 %and180, 0
  br i1 %tobool181.not, label %if.end183, label %change

if.end183:                                        ; preds = %if.end178
  %85 = trunc i32 %reset_on_fork.0 to i8
  %86 = ptrtoint ptr %sched_reset_on_fork to i32
  call void @__asan_load1_noabort(i32 %86)
  %bf.load185 = load i8, ptr %sched_reset_on_fork, align 4
  %bf.shl = shl nuw i8 %85, 7
  %bf.clear = and i8 %bf.load185, 127
  %bf.set = or i8 %bf.clear, %bf.shl
  store i8 %bf.set, ptr %sched_reset_on_fork, align 4
  br label %unlock

change:                                           ; preds = %if.end178, %land.lhs.true174, %land.lhs.true165, %land.lhs.true156, %if.end143
  br i1 %user, label %if.then188, label %if.end226

if.then188:                                       ; preds = %change
  %87 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %tobool190.not = icmp slt i32 %87, 0
  br i1 %tobool190.not, label %if.end226, label %land.lhs.true191

land.lhs.true191:                                 ; preds = %if.then188
  br i1 %31, label %land.lhs.true194, label %land.lhs.true205

land.lhs.true194:                                 ; preds = %land.lhs.true191
  %88 = ptrtoint ptr %sched_task_group.i to i32
  call void @__asan_load4_noabort(i32 %88)
  %89 = load ptr, ptr %sched_task_group.i, align 8
  %rt_runtime = getelementptr inbounds %struct.task_group, ptr %89, i32 0, i32 9, i32 2
  %90 = ptrtoint ptr %rt_runtime to i32
  call void @__asan_load8_noabort(i32 %90)
  %91 = load i64, ptr %rt_runtime, align 8
  %cmp196 = icmp eq i64 %91, 0
  br i1 %cmp196, label %land.lhs.true198, label %land.lhs.true205

land.lhs.true198:                                 ; preds = %land.lhs.true194
  %autogroup.i = getelementptr inbounds %struct.task_group, ptr %89, i32 0, i32 15
  %92 = ptrtoint ptr %autogroup.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load ptr, ptr %autogroup.i, align 4
  %tobool.i.not = icmp eq ptr %93, null
  br i1 %tobool.i.not, label %unlock, label %land.lhs.true205

land.lhs.true205:                                 ; preds = %land.lhs.true198, %land.lhs.true194, %land.lhs.true191
  br i1 %cmp.i, label %land.lhs.true208, label %if.end226

land.lhs.true208:                                 ; preds = %land.lhs.true205
  %94 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %94)
  %95 = load i64, ptr %sched_flags, align 8
  %and210 = and i64 %95, 268435456
  %tobool211.not = icmp eq i64 %and210, 0
  br i1 %tobool211.not, label %if.then212, label %if.end226

if.then212:                                       ; preds = %land.lhs.true208
  %rd = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %96 = load i32, ptr @nr_cpu_ids, align 4
  %97 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %97)
  %98 = load ptr, ptr %cpus_ptr, align 4
  %99 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %99)
  %100 = load ptr, ptr %rd, align 8
  %span213 = getelementptr inbounds %struct.root_domain, ptr %100, i32 0, i32 3
  %101 = ptrtoint ptr %span213 to i32
  call void @__asan_load4_noabort(i32 %101)
  %102 = load ptr, ptr %span213, align 8
  %call.i.i = tail call i32 @__bitmap_subset(ptr noundef %102, ptr noundef %98, i32 noundef %96) #33
  %tobool215.not = icmp eq i32 %call.i.i, 0
  br i1 %tobool215.not, label %unlock, label %lor.lhs.false216

lor.lhs.false216:                                 ; preds = %if.then212
  %103 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %103)
  %104 = load ptr, ptr %rd, align 8
  %bw = getelementptr inbounds %struct.root_domain, ptr %104, i32 0, i32 9, i32 1
  %105 = ptrtoint ptr %bw to i32
  call void @__asan_load8_noabort(i32 %105)
  %106 = load i64, ptr %bw, align 8
  %cmp218 = icmp eq i64 %106, 0
  br i1 %cmp218, label %unlock, label %if.end226

if.end226:                                        ; preds = %lor.lhs.false216, %land.lhs.true208, %land.lhs.true205, %if.then188, %change
  %cmp227.not = icmp eq i32 %oldpolicy.1, -1
  br i1 %cmp227.not, label %if.end244, label %land.rhs229

land.rhs229:                                      ; preds = %if.end226
  %107 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load i32, ptr %policy18, align 4
  %cmp231.not = icmp eq i32 %oldpolicy.1, %108
  br i1 %cmp231.not, label %if.end244, label %if.then240, !prof !1191

if.then240:                                       ; preds = %land.rhs229
  call fastcc void @task_rq_unlock(ptr noundef %call139, ptr noundef %p, ptr noundef nonnull %rf)
  br i1 %pi, label %if.then242, label %recheck.backedge

if.then242:                                       ; preds = %if.then240
  tail call void @cpuset_read_unlock() #33
  br label %recheck.backedge

recheck.backedge:                                 ; preds = %if.then242, %if.then240
  br label %recheck

if.end244:                                        ; preds = %land.rhs229, %if.end226
  br i1 %cmp.i, label %land.lhs.true250, label %lor.lhs.false247

lor.lhs.false247:                                 ; preds = %if.end244
  %prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %109 = ptrtoint ptr %prio.i to i32
  call void @__asan_load4_noabort(i32 %109)
  %110 = load i32, ptr %prio.i, align 8
  %tobool249.not = icmp sgt i32 %110, -1
  br i1 %tobool249.not, label %if.end254, label %land.lhs.true250

land.lhs.true250:                                 ; preds = %lor.lhs.false247, %if.end244
  %call251 = tail call i32 @sched_dl_overflow(ptr noundef %p, i32 noundef %policy.1, ptr noundef %attr) #33
  %tobool252.not = icmp eq i32 %call251, 0
  br i1 %tobool252.not, label %if.end254, label %unlock

if.end254:                                        ; preds = %land.lhs.true250, %lor.lhs.false247
  %111 = trunc i32 %reset_on_fork.0 to i8
  %112 = ptrtoint ptr %sched_reset_on_fork to i32
  call void @__asan_load1_noabort(i32 %112)
  %bf.load256 = load i8, ptr %sched_reset_on_fork, align 4
  %bf.shl258 = shl nuw i8 %111, 7
  %bf.clear259 = and i8 %bf.load256, 127
  %bf.set260 = or i8 %bf.clear259, %bf.shl258
  store i8 %bf.set260, ptr %sched_reset_on_fork, align 4
  %prio = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %113 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %113)
  %114 = load i32, ptr %prio, align 8
  %115 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %115)
  %116 = load i32, ptr %sched_priority, align 4
  %117 = ptrtoint ptr %sched_nice to i32
  call void @__asan_load4_noabort(i32 %117)
  %118 = load i32, ptr %sched_nice, align 8
  br i1 %cmp.i, label %__normal_prio.exit, label %if.else.i

if.else.i:                                        ; preds = %if.end254
  %119 = add i32 %policy.1, -3
  %120 = icmp ult i32 %119, -2
  br i1 %120, label %if.else4.i, label %if.then3.i

if.then3.i:                                       ; preds = %if.else.i
  %sub.i492 = sub i32 99, %116
  br label %__normal_prio.exit

if.else4.i:                                       ; preds = %if.else.i
  %add.i493 = add i32 %118, 120
  br label %__normal_prio.exit

__normal_prio.exit:                               ; preds = %if.else4.i, %if.then3.i, %if.end254
  %prio.0.i = phi i32 [ %sub.i492, %if.then3.i ], [ %add.i493, %if.else4.i ], [ -1, %if.end254 ]
  br i1 %pi, label %if.then266, label %if.end273

if.then266:                                       ; preds = %__normal_prio.exit
  %pi_top_task.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 131
  %121 = ptrtoint ptr %pi_top_task.i.i to i32
  call void @__asan_load4_noabort(i32 %121)
  %122 = load ptr, ptr %pi_top_task.i.i, align 4
  %tobool.not.i.i494 = icmp eq ptr %122, null
  br i1 %tobool.not.i.i494, label %rt_effective_prio.exit, label %if.then.i.i495

if.then.i.i495:                                   ; preds = %if.then266
  %prio1.i.i = getelementptr inbounds %struct.task_struct, ptr %122, i32 0, i32 13
  %123 = ptrtoint ptr %prio1.i.i to i32
  call void @__asan_load4_noabort(i32 %123)
  %124 = load i32, ptr %prio1.i.i, align 8
  %125 = tail call i32 @llvm.smin.i32(i32 %124, i32 %prio.0.i) #33
  br label %rt_effective_prio.exit

rt_effective_prio.exit:                           ; preds = %if.then.i.i495, %if.then266
  %prio.addr.0.i.i = phi i32 [ %125, %if.then.i.i495 ], [ %prio.0.i, %if.then266 ]
  %cmp268 = icmp eq i32 %prio.addr.0.i.i, %114
  %spec.select = select i1 %cmp268, i32 10, i32 14
  br label %if.end273

if.end273:                                        ; preds = %rt_effective_prio.exit, %__normal_prio.exit
  %newprio.0 = phi i32 [ %prio.0.i, %__normal_prio.exit ], [ %prio.addr.0.i.i, %rt_effective_prio.exit ]
  %queue_flags.0 = phi i32 [ 14, %__normal_prio.exit ], [ %spec.select, %rt_effective_prio.exit ]
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %126 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %126)
  %127 = load i32, ptr %on_rq.i, align 4
  %cmp.i496.not = icmp eq i32 %127, 1
  %curr.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 20
  %128 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %128)
  %129 = load ptr, ptr %curr.i, align 8
  %cmp.i498.not = icmp eq ptr %129, %p
  br i1 %cmp.i496.not, label %if.then277, label %if.end278

if.then277:                                       ; preds = %if.end273
  tail call fastcc void @dequeue_task(ptr noundef %call139, ptr noundef %p, i32 noundef %queue_flags.0)
  br label %if.end278

if.end278:                                        ; preds = %if.then277, %if.end273
  br i1 %cmp.i498.not, label %if.then280, label %if.end281

if.then280:                                       ; preds = %if.end278
  %130 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load ptr, ptr %curr.i, align 8
  %cmp.not.i501 = icmp eq ptr %131, %p
  br i1 %cmp.not.i501, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then280
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i502, !prof !1191

if.then.i502:                                     ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i502, %land.rhs.i, %if.then280
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %132 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %132)
  %133 = load ptr, ptr %sched_class.i, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %133, i32 0, i32 7
  %134 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %134)
  %135 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %135(ptr noundef %call139, ptr noundef %p) #33
  br label %if.end281

if.end281:                                        ; preds = %put_prev_task.exit, %if.end278
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %136 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %136)
  %137 = load ptr, ptr %sched_class, align 32
  %138 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %138)
  %139 = load i64, ptr %sched_flags, align 8
  %and283 = and i64 %139, 16
  %tobool284.not = icmp eq i64 %and283, 0
  br i1 %tobool284.not, label %if.then285, label %if.end286

if.then285:                                       ; preds = %if.end281
  %140 = ptrtoint ptr %sched_policy to i32
  call void @__asan_load4_noabort(i32 %140)
  %141 = load i32, ptr %sched_policy, align 4
  %cmp.i503 = icmp eq i32 %141, -1
  br i1 %cmp.i503, label %if.then.i504, label %if.end.i

if.then.i504:                                     ; preds = %if.then285
  %142 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %142)
  %143 = load i32, ptr %policy18, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i504, %if.then285
  %policy.0.i = phi i32 [ %143, %if.then.i504 ], [ %141, %if.then285 ]
  %144 = ptrtoint ptr %policy18 to i32
  call void @__asan_store4_noabort(i32 %144)
  store i32 %policy.0.i, ptr %policy18, align 4
  switch i32 %policy.0.i, label %if.end8.i [
    i32 6, label %if.then3.i505
    i32 3, label %if.then6.i
    i32 0, label %if.then6.i
  ]

if.then3.i505:                                    ; preds = %if.end.i
  tail call void @__setparam_dl(ptr noundef %p, ptr noundef %attr) #33
  br label %if.end8thread-pre-split.i

if.then6.i:                                       ; preds = %if.end.i, %if.end.i
  %145 = ptrtoint ptr %sched_nice to i32
  call void @__asan_load4_noabort(i32 %145)
  %146 = load i32, ptr %sched_nice, align 8
  %add.i506 = add i32 %146, 120
  %147 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_store4_noabort(i32 %147)
  store i32 %add.i506, ptr %static_prio.i, align 4
  br label %if.end8thread-pre-split.i

if.end8thread-pre-split.i:                        ; preds = %if.then6.i, %if.then3.i505
  %148 = ptrtoint ptr %policy18 to i32
  call void @__asan_load4_noabort(i32 %148)
  %.pr.i = load i32, ptr %policy18, align 4
  br label %if.end8.i

if.end8.i:                                        ; preds = %if.end8thread-pre-split.i, %if.end.i
  %149 = phi i32 [ %.pr.i, %if.end8thread-pre-split.i ], [ %policy.0.i, %if.end.i ]
  %150 = ptrtoint ptr %sched_priority to i32
  call void @__asan_load4_noabort(i32 %150)
  %151 = load i32, ptr %sched_priority, align 4
  %152 = ptrtoint ptr %rt_priority to i32
  call void @__asan_store4_noabort(i32 %152)
  store i32 %151, ptr %rt_priority, align 4
  %153 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %153)
  %154 = load i32, ptr %static_prio.i, align 4
  %cmp.i.not.i.i.i = icmp eq i32 %149, 6
  %155 = add i32 %149, -3
  %156 = icmp ult i32 %155, -2
  %sub.i.i.i = sub i32 99, %151
  %spec.select.i.i = select i1 %156, i32 %154, i32 %sub.i.i.i
  %prio.0.i.i.i = select i1 %cmp.i.not.i.i.i, i32 -1, i32 %spec.select.i.i
  %normal_prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 15
  %157 = ptrtoint ptr %normal_prio.i to i32
  call void @__asan_store4_noabort(i32 %157)
  store i32 %prio.0.i.i.i, ptr %normal_prio.i, align 64
  %sub.i.i508 = add i32 %154, -100
  %se.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18
  %cmp.i.i.not.i.i = icmp eq i32 %149, 5
  br i1 %cmp.i.i.not.i.i, label %if.then.i.i509, label %if.end.i.i

if.then.i.i509:                                   ; preds = %if.end8.i
  %158 = ptrtoint ptr %se.i.i to i32
  call void @__asan_store4_noabort(i32 %158)
  store i32 3, ptr %se.i.i, align 4
  %inv_weight.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 0, i32 1
  %159 = ptrtoint ptr %inv_weight.i.i to i32
  call void @__asan_store4_noabort(i32 %159)
  store i32 1431655765, ptr %inv_weight.i.i, align 4
  br label %__setscheduler_params.exit

if.end.i.i:                                       ; preds = %if.end8.i
  %160 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %160)
  %161 = load ptr, ptr %sched_class, align 32
  %cmp.i25.i = icmp eq ptr %161, @fair_sched_class
  br i1 %cmp.i25.i, label %if.then3.i.i, label %if.else.i.i511

if.then3.i.i:                                     ; preds = %if.end.i.i
  tail call void @reweight_task(ptr noundef %p, i32 noundef %sub.i.i508) #33
  br label %__setscheduler_params.exit

if.else.i.i511:                                   ; preds = %if.end.i.i
  %arrayidx.i.i510 = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %sub.i.i508
  %162 = ptrtoint ptr %arrayidx.i.i510 to i32
  call void @__asan_load4_noabort(i32 %162)
  %163 = load i32, ptr %arrayidx.i.i510, align 4
  %164 = ptrtoint ptr %se.i.i to i32
  call void @__asan_store4_noabort(i32 %164)
  store i32 %163, ptr %se.i.i, align 4
  %arrayidx5.i.i = getelementptr [40 x i32], ptr @sched_prio_to_wmult, i32 0, i32 %sub.i.i508
  %165 = ptrtoint ptr %arrayidx5.i.i to i32
  call void @__asan_load4_noabort(i32 %165)
  %166 = load i32, ptr %arrayidx5.i.i, align 4
  %inv_weight6.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 18, i32 0, i32 1
  %167 = ptrtoint ptr %inv_weight6.i.i to i32
  call void @__asan_store4_noabort(i32 %167)
  store i32 %166, ptr %inv_weight6.i.i, align 4
  br label %__setscheduler_params.exit

__setscheduler_params.exit:                       ; preds = %if.else.i.i511, %if.then3.i.i, %if.then.i.i509
  %tobool.not.i512 = icmp sgt i32 %newprio.0, -1
  %cmp.i.i515 = icmp ugt i32 %newprio.0, 99
  %fair_sched_class.rt_sched_class = select i1 %cmp.i.i515, ptr @fair_sched_class, ptr @rt_sched_class
  %dl_sched_class.sink = select i1 %tobool.not.i512, ptr %fair_sched_class.rt_sched_class, ptr @dl_sched_class
  %168 = ptrtoint ptr %sched_class to i32
  call void @__asan_store4_noabort(i32 %168)
  store ptr %dl_sched_class.sink, ptr %sched_class, align 32
  %169 = ptrtoint ptr %prio to i32
  call void @__asan_store4_noabort(i32 %169)
  store i32 %newprio.0, ptr %prio, align 8
  br label %if.end286

if.end286:                                        ; preds = %__setscheduler_params.exit, %if.end281
  %170 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %170)
  %171 = load i64, ptr %sched_flags, align 8
  %and.i.i520 = and i64 %171, 96
  %tobool.not.i.i521 = icmp eq i64 %and.i.i520, 0
  br i1 %tobool.not.i.i521, label %land.lhs.true.i.i, label %land.lhs.true5.i.i, !prof !1191

land.lhs.true.i.i:                                ; preds = %if.end286
  %172 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %172)
  %bf.load.i.i = load i16, ptr %uclamp_req.i, align 4
  %bf.clear.i.i = and i16 %bf.load.i.i, 1
  %tobool4.not.i.i = icmp eq i16 %bf.clear.i.i, 0
  br i1 %tobool4.not.i.i, label %if.end.i522, label %land.lhs.true5.i.i

land.lhs.true5.i.i:                               ; preds = %land.lhs.true.i.i, %if.end286
  %and7.i.i = and i64 %171, 32
  %tobool8.not.i.i = icmp eq i64 %and7.i.i, 0
  br i1 %tobool8.not.i.i, label %cleanup.i, label %land.lhs.true9.i.i

land.lhs.true9.i.i:                               ; preds = %land.lhs.true5.i.i
  %173 = ptrtoint ptr %sched_util_min.i to i32
  call void @__asan_load4_noabort(i32 %173)
  %174 = load i32, ptr %sched_util_min.i, align 8
  %cmp10.i.i = icmp eq i32 %174, -1
  br i1 %cmp10.i.i, label %if.end.i522, label %cleanup.i

if.end.i522:                                      ; preds = %land.lhs.true9.i.i, %land.lhs.true.i.i
  %175 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %175)
  %176 = load i32, ptr %prio, align 8
  %cmp.i.i.i = icmp slt i32 %176, 100
  br i1 %cmp.i.i.i, label %if.end7.i523, label %if.end7.thread.i, !prof !1192

if.end7.thread.i:                                 ; preds = %if.end.i522
  %177 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %177)
  %bf.load.i5987.i = load i16, ptr %uclamp_req.i, align 4
  %bf.clear.i6089.i = and i16 %bf.load.i5987.i, 2
  br label %182

if.end7.i523:                                     ; preds = %if.end.i522
  %178 = load i32, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  %179 = trunc i32 %178 to i16
  %180 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %180)
  %bf.load.i59.i = load i16, ptr %uclamp_req.i, align 4
  %bf.shl.i.i = shl i16 %179, 5
  %bf.clear.i60.i = and i16 %bf.load.i59.i, 2
  %bf.set.i.i = or i16 %bf.clear.i60.i, %bf.shl.i.i
  %cmp10.i.i.i = icmp ult i32 %178, 820
  %div8.i.i.i = udiv i32 %178, 205
  %181 = trunc i32 %div8.i.i.i to i16
  %.op.i.i = shl i16 %181, 2
  %.op.op.i.i = and i16 %.op.i.i, 28
  br i1 %cmp10.i.i.i, label %182, label %183

182:                                              ; preds = %if.end7.i523, %if.end7.thread.i
  %.op.op.i97.i = phi i16 [ 0, %if.end7.thread.i ], [ %.op.op.i.i, %if.end7.i523 ]
  %bf.set.i96.i = phi i16 [ %bf.clear.i6089.i, %if.end7.thread.i ], [ %bf.set.i.i, %if.end7.i523 ]
  br label %183

183:                                              ; preds = %182, %if.end7.i523
  %bf.set.i95.i = phi i16 [ %bf.set.i96.i, %182 ], [ %bf.set.i.i, %if.end7.i523 ]
  %184 = phi i16 [ %.op.op.i97.i, %182 ], [ 16, %if.end7.i523 ]
  %bf.set5.i.i = or i16 %184, %bf.set.i95.i
  %185 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_store2_noabort(i32 %185)
  store i16 %bf.set5.i.i, ptr %uclamp_req.i, align 4
  br label %cleanup.i

cleanup.i:                                        ; preds = %183, %land.lhs.true9.i.i, %land.lhs.true5.i.i
  %186 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %186)
  %187 = load i64, ptr %sched_flags, align 8
  %and.i.1.i = and i64 %187, 96
  %tobool.not.i.1.i = icmp eq i64 %and.i.1.i, 0
  br i1 %tobool.not.i.1.i, label %land.lhs.true.i.1.i, label %land.lhs.true14.i.1.i, !prof !1191

land.lhs.true.i.1.i:                              ; preds = %cleanup.i
  %188 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_load2_noabort(i32 %188)
  %bf.load.i.1.i = load i16, ptr %arrayidx2.i, align 4
  %bf.clear.i.1.i = and i16 %bf.load.i.1.i, 1
  %tobool4.not.i.1.i = icmp eq i16 %bf.clear.i.1.i, 0
  br i1 %tobool4.not.i.1.i, label %if.end7.1.i, label %land.lhs.true14.i.1.i

land.lhs.true14.i.1.i:                            ; preds = %land.lhs.true.i.1.i, %cleanup.i
  %and16.i.1.i = and i64 %187, 64
  %tobool17.not.i.1.i = icmp eq i64 %and16.i.1.i, 0
  br i1 %tobool17.not.i.1.i, label %cleanup.1.i, label %land.lhs.true18.i.1.i

land.lhs.true18.i.1.i:                            ; preds = %land.lhs.true14.i.1.i
  %189 = ptrtoint ptr %sched_util_max.i to i32
  call void @__asan_load4_noabort(i32 %189)
  %190 = load i32, ptr %sched_util_max.i, align 4
  %cmp19.i.1.i = icmp eq i32 %190, -1
  br i1 %cmp19.i.1.i, label %if.end7.1.i, label %cleanup.1.i

if.end7.1.i:                                      ; preds = %land.lhs.true18.i.1.i, %land.lhs.true.i.1.i
  %191 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_load2_noabort(i32 %191)
  %bf.load.i59.1.i = load i16, ptr %arrayidx2.i, align 4
  %bf.clear.i60.1.i = and i16 %bf.load.i59.1.i, 2
  %bf.set5.i.1.i = or i16 %bf.clear.i60.1.i, -32752
  store i16 %bf.set5.i.1.i, ptr %arrayidx2.i, align 4
  br label %cleanup.1.i

cleanup.1.i:                                      ; preds = %if.end7.1.i, %land.lhs.true18.i.1.i, %land.lhs.true14.i.1.i
  %192 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %192)
  %193 = load i64, ptr %sched_flags, align 8
  %and.i524 = and i64 %193, 96
  %tobool9.not.i = icmp eq i64 %and.i524, 0
  br i1 %tobool9.not.i, label %__setscheduler_uclamp.exit, label %if.end19.i, !prof !1191

if.end19.i:                                       ; preds = %cleanup.1.i
  %and21.i = and i64 %193, 32
  %tobool22.not.i = icmp eq i64 %and21.i, 0
  br i1 %tobool22.not.i, label %if.end28.i, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end19.i
  %194 = ptrtoint ptr %sched_util_min.i to i32
  call void @__asan_load4_noabort(i32 %194)
  %195 = load i32, ptr %sched_util_min.i, align 8
  %cmp23.not.i = icmp eq i32 %195, -1
  br i1 %cmp23.not.i, label %if.end28.i, label %if.then24.i

if.then24.i:                                      ; preds = %land.lhs.true.i
  %196 = trunc i32 %195 to i16
  %197 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %197)
  %bf.load.i61.i = load i16, ptr %uclamp_req.i, align 4
  %bf.shl.i62.i = shl i16 %196, 5
  %bf.clear.i63.i = and i16 %bf.load.i61.i, 2
  %bf.set.i64.i = or i16 %bf.clear.i63.i, %bf.shl.i62.i
  %cmp10.i.i65.i = icmp ult i32 %195, 820
  %div8.i.i66.i = udiv i32 %195, 205
  %198 = trunc i32 %div8.i.i66.i to i16
  %.op.i67.i = shl i16 %198, 2
  %.op.op.i68.i = and i16 %.op.i67.i, 28
  %bf.shl3.i69.i = select i1 %cmp10.i.i65.i, i16 %.op.op.i68.i, i16 16
  %bf.set5.i70.i = or i16 %bf.set.i64.i, %bf.shl3.i69.i
  %bf.set10.i.i = or i16 %bf.set5.i70.i, 1
  store i16 %bf.set10.i.i, ptr %uclamp_req.i, align 4
  br label %if.end28.i

if.end28.i:                                       ; preds = %if.then24.i, %land.lhs.true.i, %if.end19.i
  %199 = ptrtoint ptr %sched_flags to i32
  call void @__asan_load8_noabort(i32 %199)
  %200 = load i64, ptr %sched_flags, align 8
  %and30.i = and i64 %200, 64
  %tobool31.not.i = icmp eq i64 %and30.i, 0
  br i1 %tobool31.not.i, label %__setscheduler_uclamp.exit, label %land.lhs.true32.i

land.lhs.true32.i:                                ; preds = %if.end28.i
  %201 = ptrtoint ptr %sched_util_max.i to i32
  call void @__asan_load4_noabort(i32 %201)
  %202 = load i32, ptr %sched_util_max.i, align 4
  %cmp33.not.i = icmp eq i32 %202, -1
  br i1 %cmp33.not.i, label %__setscheduler_uclamp.exit, label %if.then34.i

if.then34.i:                                      ; preds = %land.lhs.true32.i
  %203 = trunc i32 %202 to i16
  %204 = ptrtoint ptr %arrayidx2.i to i32
  call void @__asan_load2_noabort(i32 %204)
  %bf.load.i71.i = load i16, ptr %arrayidx2.i, align 4
  %bf.shl.i72.i = shl i16 %203, 5
  %bf.clear.i73.i = and i16 %bf.load.i71.i, 2
  %bf.set.i74.i = or i16 %bf.clear.i73.i, %bf.shl.i72.i
  %cmp10.i.i75.i = icmp ult i32 %202, 820
  %div8.i.i76.i = udiv i32 %202, 205
  %205 = trunc i32 %div8.i.i76.i to i16
  %.op.i77.i = shl i16 %205, 2
  %.op.op.i78.i = and i16 %.op.i77.i, 28
  %bf.shl3.i79.i = select i1 %cmp10.i.i75.i, i16 %.op.op.i78.i, i16 16
  %bf.set5.i80.i = or i16 %bf.set.i74.i, %bf.shl3.i79.i
  %bf.set10.i81.i = or i16 %bf.set5.i80.i, 1
  store i16 %bf.set10.i81.i, ptr %arrayidx2.i, align 4
  br label %__setscheduler_uclamp.exit

__setscheduler_uclamp.exit:                       ; preds = %if.then34.i, %land.lhs.true32.i, %if.end28.i, %cleanup.1.i
  br i1 %cmp.i496.not, label %if.then288, label %if.end295

if.then288:                                       ; preds = %__setscheduler_uclamp.exit
  %206 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %206)
  %207 = load i32, ptr %prio, align 8
  %cmp290 = icmp slt i32 %114, %207
  %or293 = or i32 %queue_flags.0, 16
  %spec.select451 = select i1 %cmp290, i32 %or293, i32 %queue_flags.0
  tail call fastcc void @enqueue_task(ptr noundef %call139, ptr noundef %p, i32 noundef %spec.select451)
  br label %if.end295

if.end295:                                        ; preds = %if.then288, %__setscheduler_uclamp.exit
  br i1 %cmp.i498.not, label %if.then297, label %if.end298

if.then297:                                       ; preds = %if.end295
  %208 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %208)
  %209 = load ptr, ptr %sched_class, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %209, i32 0, i32 8
  %210 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %210)
  %211 = load ptr, ptr %set_next_task.i, align 4
  tail call void %211(ptr noundef %call139, ptr noundef %p, i1 noundef zeroext false) #33
  br label %if.end298

if.end298:                                        ; preds = %if.then297, %if.end295
  %212 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %212)
  %213 = load ptr, ptr %sched_class, align 32
  %cmp.not.i527 = icmp eq ptr %213, %137
  br i1 %cmp.not.i527, label %if.else.i533, label %if.then.i529

if.then.i529:                                     ; preds = %if.end298
  %switched_from.i = getelementptr inbounds %struct.sched_class, ptr %137, i32 0, i32 21
  %214 = ptrtoint ptr %switched_from.i to i32
  call void @__asan_load4_noabort(i32 %214)
  %215 = load ptr, ptr %switched_from.i, align 4
  %tobool.not.i528 = icmp eq ptr %215, null
  br i1 %tobool.not.i528, label %if.end.i530, label %if.then1.i

if.then1.i:                                       ; preds = %if.then.i529
  tail call void %215(ptr noundef %call139, ptr noundef %p) #33
  br label %if.end.i530

if.end.i530:                                      ; preds = %if.then1.i, %if.then.i529
  %216 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %216)
  %217 = load ptr, ptr %sched_class, align 32
  %switched_to.i = getelementptr inbounds %struct.sched_class, ptr %217, i32 0, i32 22
  %218 = ptrtoint ptr %switched_to.i to i32
  call void @__asan_load4_noabort(i32 %218)
  %219 = load ptr, ptr %switched_to.i, align 4
  tail call void %219(ptr noundef %call139, ptr noundef %p) #33
  br label %check_class_changed.exit

if.else.i533:                                     ; preds = %if.end298
  %220 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %220)
  %221 = load i32, ptr %prio, align 8
  %cmp4.not.i = icmp eq i32 %221, %114
  %tobool5.not.i = icmp sgt i32 %221, -1
  %or.cond.i532 = and i1 %cmp4.not.i, %tobool5.not.i
  br i1 %or.cond.i532, label %check_class_changed.exit, label %if.then6.i534

if.then6.i534:                                    ; preds = %if.else.i533
  %prio_changed.i = getelementptr inbounds %struct.sched_class, ptr %137, i32 0, i32 23
  %222 = ptrtoint ptr %prio_changed.i to i32
  call void @__asan_load4_noabort(i32 %222)
  %223 = load ptr, ptr %prio_changed.i, align 4
  tail call void %223(ptr noundef %call139, ptr noundef %p, i32 noundef %114) #33
  br label %check_class_changed.exit

check_class_changed.exit:                         ; preds = %if.then6.i534, %if.else.i533, %if.end.i530
  %224 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %224, -16384
  %225 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %225, i32 0, i32 1
  %226 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %226)
  %227 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %227, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1295
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 39
  %228 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %228)
  %229 = load ptr, ptr %balance_callback.i, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %230 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i535 = icmp eq i32 %230, 0
  br i1 %tobool.not.i.i535, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %check_class_changed.exit
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 81
  %231 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %231)
  %232 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %232, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 79
  %233 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %233)
  %234 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i
  %retval.0.i.i.i = phi ptr [ %234, %if.then.i.i.i ], [ %call139, %land.rhs.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %check_class_changed.exit
  %tobool.not.i536 = icmp eq ptr %229, null
  br i1 %tobool.not.i536, label %splice_balance_callbacks.exit, label %if.then.i537

if.then.i537:                                     ; preds = %lockdep_assert_rq_held.exit.i
  %235 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_store4_noabort(i32 %235)
  store ptr null, ptr %balance_callback.i, align 8
  br label %splice_balance_callbacks.exit

splice_balance_callbacks.exit:                    ; preds = %if.then.i537, %lockdep_assert_rq_held.exit.i
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 25
  %236 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %236)
  %237 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i539 = icmp ugt i32 %237, 2
  br i1 %cmp.i.i539, label %if.then.i.i540, label %if.end.i.i543

if.then.i.i540:                                   ; preds = %splice_balance_callbacks.exit
  %238 = ptrtoint ptr %5 to i32
  call void @__asan_store4_noabort(i32 %238)
  store i32 4, ptr %5, align 4
  br label %if.end.i.i543

if.end.i.i543:                                    ; preds = %if.then.i.i540, %splice_balance_callbacks.exit
  %core_enabled.i.i.i541 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 81
  %239 = ptrtoint ptr %core_enabled.i.i.i541 to i32
  call void @__asan_load4_noabort(i32 %239)
  %240 = load i32, ptr %core_enabled.i.i.i541, align 128
  %tobool.not.i.i.i542 = icmp eq i32 %240, 0
  br i1 %tobool.not.i.i.i542, label %rq_unpin_lock.exit.i, label %if.then.i.i.i545

if.then.i.i.i545:                                 ; preds = %if.end.i.i543
  %core.i.i.i544 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 79
  %241 = ptrtoint ptr %core.i.i.i544 to i32
  call void @__asan_load4_noabort(i32 %241)
  %242 = load ptr, ptr %core.i.i.i544, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i545, %if.end.i.i543
  %retval.0.i.i.i546 = phi ptr [ %242, %if.then.i.i.i545 ], [ %call139, %if.end.i.i543 ]
  %dep_map.i.i547 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i546, i32 0, i32 4
  %243 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %243)
  %.unpack.i.i = load i32, ptr %3, align 4
  %244 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i547, [1 x i32] %244) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__sched_setscheduler, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %245 = ptrtoint ptr %core_enabled.i.i.i541 to i32
  call void @__asan_load4_noabort(i32 %245)
  %246 = load i32, ptr %core_enabled.i.i.i541, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %246, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 79
  %247 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %247)
  %248 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %248, %if.then.i.i4.i ], [ %call139, %land.rhs.i.i.i.i ], [ %call139, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %249 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %249)
  %250 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %250) #33
  br i1 %pi, label %if.then304, label %if.end305

if.then304:                                       ; preds = %task_rq_unlock.exit
  tail call void @cpuset_read_unlock() #33
  tail call void @rt_mutex_adjust_pi(ptr noundef %p) #33
  br label %if.end305

if.end305:                                        ; preds = %if.then304, %task_rq_unlock.exit
  br i1 %tobool.not.i536, label %balance_callbacks.exit, label %do.body.i, !prof !1191

do.body.i:                                        ; preds = %if.end305
  %call.i = tail call fastcc i32 @_raw_spin_rq_lock_irqsave(ptr noundef %call139) #33
  tail call fastcc void @do_balance_callbacks(ptr noundef %call139, ptr noundef nonnull %229) #33
  tail call fastcc void @raw_spin_rq_unlock_irqrestore(ptr noundef %call139, i32 noundef %call.i) #33
  br label %balance_callbacks.exit

balance_callbacks.exit:                           ; preds = %do.body.i, %if.end305
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1296
  %251 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i458 = and i32 %251, -16384
  %252 = inttoptr i32 %and.i.i.i458 to ptr
  %preempt_count.i.i459 = getelementptr inbounds %struct.thread_info, ptr %252, i32 0, i32 1
  %253 = ptrtoint ptr %preempt_count.i.i459 to i32
  call void @__asan_load4_noabort(i32 %253)
  %254 = load volatile i32, ptr %preempt_count.i.i459, align 4
  %sub.i = add i32 %254, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i459, align 4
  br label %cleanup312

unlock:                                           ; preds = %land.lhs.true250, %lor.lhs.false216, %if.then212, %land.lhs.true198, %if.end183, %if.end138
  %retval2.5 = phi i32 [ 0, %if.end183 ], [ -16, %land.lhs.true250 ], [ -1, %lor.lhs.false216 ], [ -1, %if.then212 ], [ -1, %land.lhs.true198 ], [ -22, %if.end138 ]
  %clock_update_flags.i.i550 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 25
  %255 = ptrtoint ptr %clock_update_flags.i.i550 to i32
  call void @__asan_load4_noabort(i32 %255)
  %256 = load i32, ptr %clock_update_flags.i.i550, align 4
  %cmp.i.i551 = icmp ugt i32 %256, 2
  br i1 %cmp.i.i551, label %if.then.i.i553, label %if.end.i.i556

if.then.i.i553:                                   ; preds = %unlock
  %257 = ptrtoint ptr %5 to i32
  call void @__asan_store4_noabort(i32 %257)
  store i32 4, ptr %5, align 4
  br label %if.end.i.i556

if.end.i.i556:                                    ; preds = %if.then.i.i553, %unlock
  %core_enabled.i.i.i554 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 81
  %258 = ptrtoint ptr %core_enabled.i.i.i554 to i32
  call void @__asan_load4_noabort(i32 %258)
  %259 = load i32, ptr %core_enabled.i.i.i554, align 128
  %tobool.not.i.i.i555 = icmp eq i32 %259, 0
  br i1 %tobool.not.i.i.i555, label %rq_unpin_lock.exit.i563, label %if.then.i.i.i558

if.then.i.i.i558:                                 ; preds = %if.end.i.i556
  %core.i.i.i557 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 79
  %260 = ptrtoint ptr %core.i.i.i557 to i32
  call void @__asan_load4_noabort(i32 %260)
  %261 = load ptr, ptr %core.i.i.i557, align 8
  br label %rq_unpin_lock.exit.i563

rq_unpin_lock.exit.i563:                          ; preds = %if.then.i.i.i558, %if.end.i.i556
  %retval.0.i.i.i559 = phi ptr [ %261, %if.then.i.i.i558 ], [ %call139, %if.end.i.i556 ]
  %dep_map.i.i560 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i559, i32 0, i32 4
  %262 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %262)
  %.unpack.i.i562 = load i32, ptr %3, align 4
  %263 = insertvalue [1 x i32] undef, i32 %.unpack.i.i562, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i560, [1 x i32] %263) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__sched_setscheduler, %land.rhs.i.i.i.i565)) #33
          to label %task_rq_unlock.exit570 [label %land.rhs.i.i.i.i565], !srcloc !1202

land.rhs.i.i.i.i565:                              ; preds = %rq_unpin_lock.exit.i563
  %264 = ptrtoint ptr %core_enabled.i.i.i554 to i32
  call void @__asan_load4_noabort(i32 %264)
  %265 = load i32, ptr %core_enabled.i.i.i554, align 128
  %tobool3.i.not.i.i.i564 = icmp eq i32 %265, 0
  br i1 %tobool3.i.not.i.i.i564, label %task_rq_unlock.exit570, label %if.then.i.i4.i567

if.then.i.i4.i567:                                ; preds = %land.rhs.i.i.i.i565
  %core.i.i3.i566 = getelementptr inbounds %struct.rq, ptr %call139, i32 0, i32 79
  %266 = ptrtoint ptr %core.i.i3.i566 to i32
  call void @__asan_load4_noabort(i32 %266)
  %267 = load ptr, ptr %core.i.i3.i566, align 8
  br label %task_rq_unlock.exit570

task_rq_unlock.exit570:                           ; preds = %if.then.i.i4.i567, %land.rhs.i.i.i.i565, %rq_unpin_lock.exit.i563
  %retval.0.i.i5.i568 = phi ptr [ %267, %if.then.i.i4.i567 ], [ %call139, %land.rhs.i.i.i.i565 ], [ %call139, %rq_unpin_lock.exit.i563 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i568) #33
  %pi_lock.i569 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %268 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %268)
  %269 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i569, i32 noundef %269) #33
  br i1 %pi, label %if.then310, label %cleanup312

if.then310:                                       ; preds = %task_rq_unlock.exit570
  tail call void @cpuset_read_unlock() #33
  br label %cleanup312

cleanup312:                                       ; preds = %if.then310, %task_rq_unlock.exit570, %balance_callbacks.exit, %if.end16.i, %if.then11.i, %if.then.i, %if.end121, %if.then116, %if.end104, %if.end101, %can_nice.exit475, %if.end85, %if.end75, %if.then67, %can_nice.exit, %lor.lhs.false, %land.lhs.true, %if.end33, %if.end28, %if.else
  %retval.4 = phi i32 [ 0, %balance_callbacks.exit ], [ %retval2.5, %if.then310 ], [ %retval2.5, %task_rq_unlock.exit570 ], [ -22, %if.else ], [ -22, %if.end16.i ], [ -22, %if.then11.i ], [ -22, %if.then.i ], [ %call122, %if.end121 ], [ -22, %if.then116 ], [ -1, %if.end104 ], [ -1, %if.end101 ], [ -1, %can_nice.exit475 ], [ -1, %if.end85 ], [ -1, %if.then67 ], [ -1, %if.end75 ], [ -1, %can_nice.exit ], [ -22, %land.lhs.true ], [ -22, %lor.lhs.false ], [ -22, %if.end33 ], [ -22, %if.end28 ]
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %retval.4
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_setattr_nocheck(ptr noundef %p, ptr noundef %attr) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef %attr, i1 noundef zeroext false, i1 noundef zeroext true)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_set_fifo(ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i.i = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i.i) #33
  %0 = call ptr @memset(ptr %attr.i.i, i32 0, i32 56)
  %sched_policy.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 1
  %1 = ptrtoint ptr %sched_policy.i.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 1, ptr %sched_policy.i.i, align 4
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 3
  %static_prio.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %2 = ptrtoint ptr %static_prio.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %static_prio.i.i, align 4
  %sub.i.i = add i32 %3, -120
  %4 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %sub.i.i, ptr %sched_nice.i.i, align 8
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 4
  %5 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 50, ptr %sched_priority.i.i, align 4
  %call.i.i = call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef nonnull %attr.i.i, i1 noundef zeroext false, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i.i) #33
  %cmp.not = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not, label %if.end27, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b37 = load i1, ptr @sched_set_fifo.__already_done, align 1
  br i1 %.b37, label %if.end27, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @sched_set_fifo.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 7600, i32 noundef 9, ptr noundef null) #33
  br label %if.end27

if.end27:                                         ; preds = %if.then, %land.rhs, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_set_fifo_low(ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i.i = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i.i) #33
  %0 = call ptr @memset(ptr %attr.i.i, i32 0, i32 56)
  %sched_policy.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 1
  %1 = ptrtoint ptr %sched_policy.i.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 1, ptr %sched_policy.i.i, align 4
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 3
  %static_prio.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 14
  %2 = ptrtoint ptr %static_prio.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %static_prio.i.i, align 4
  %sub.i.i = add i32 %3, -120
  %4 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %sub.i.i, ptr %sched_nice.i.i, align 8
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 4
  %5 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 1, ptr %sched_priority.i.i, align 4
  %call.i.i = call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef nonnull %attr.i.i, i1 noundef zeroext false, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i.i) #33
  %cmp.not = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not, label %if.end27, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b37 = load i1, ptr @sched_set_fifo_low.__already_done, align 1
  br i1 %.b37, label %if.end27, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @sched_set_fifo_low.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 7610, i32 noundef 9, ptr noundef null) #33
  br label %if.end27

if.end27:                                         ; preds = %if.then, %land.rhs, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_set_normal(ptr noundef %p, i32 noundef %nice) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr) #33
  %0 = call ptr @memset(ptr %attr, i32 0, i32 56)
  %sched_nice = getelementptr inbounds %struct.sched_attr, ptr %attr, i32 0, i32 3
  %1 = ptrtoint ptr %sched_nice to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 %nice, ptr %sched_nice, align 8
  %call.i = call fastcc i32 @__sched_setscheduler(ptr noundef %p, ptr noundef nonnull %attr, i1 noundef zeroext false, i1 noundef zeroext true) #33
  %cmp.not = icmp eq i32 %call.i, 0
  br i1 %cmp.not, label %if.end27, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b37 = load i1, ptr @sched_set_normal.__already_done, align 1
  br i1 %.b37, label %if.end27, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @sched_set_normal.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 7620, i32 noundef 9, ptr noundef null) #33
  br label %if.end27

if.end27:                                         ; preds = %if.then, %land.rhs, %entry
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_setscheduler(i32 noundef %pid, i32 noundef %policy, i32 noundef %param) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cmp.i = icmp slt i32 %policy, 0
  br i1 %cmp.i, label %__do_sys_sched_setscheduler.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %0 = inttoptr i32 %param to ptr
  %call.i = tail call fastcc i32 @do_sched_setscheduler(i32 noundef %pid, i32 noundef %policy, ptr noundef %0) #33
  br label %__do_sys_sched_setscheduler.exit

__do_sys_sched_setscheduler.exit:                 ; preds = %if.end.i, %entry
  %retval.0.i = phi i32 [ %call.i, %if.end.i ], [ -22, %entry ]
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_setparam(i32 noundef %pid, i32 noundef %param) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = inttoptr i32 %param to ptr
  %call.i = tail call fastcc i32 @do_sched_setscheduler(i32 noundef %pid, i32 noundef -1, ptr noundef %0) #33
  ret i32 %call.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_setattr(i32 noundef %pid, i32 noundef %uattr, i32 noundef %flags) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i = alloca %struct.sched_attr, align 8
  %0 = inttoptr i32 %uattr to ptr
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i) #33
  %tobool.not.i = icmp ne i32 %uattr, 0
  %cmp.i = icmp sgt i32 %pid, -1
  %or.cond.not.i = and i1 %cmp.i, %tobool.not.i
  %tobool3.not.i = icmp eq i32 %flags, 0
  %or.cond47.i = and i1 %or.cond.not.i, %tobool3.not.i
  br i1 %or.cond47.i, label %if.end.i, label %__do_sys_sched_setattr.exit

if.end.i:                                         ; preds = %entry
  %1 = call ptr @memset(ptr %attr.i, i32 0, i32 56)
  tail call void @__might_fault(ptr noundef nonnull @.str.1, i32 noundef 7662) #33
  %2 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i.i.i to ptr
  %cpu_domain.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 4
  %4 = tail call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i.i.i) #22, !srcloc !1268
  %and.i.i.i = and i32 %4, -13
  %or.i.i.i = or i32 %and.i.i.i, 4
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i.i.i) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %5 = tail call { i32, i32 } asm sideeffect ".ifnc $0,r0; .ifnc $0r0,fpr11; .ifnc $0r0,r11fp; .ifnc $0r0,ipr12; .ifnc $0r0,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $1,r2; .ifnc $1r2,fpr11; .ifnc $1r2,r11fp; .ifnc $1r2,ipr12; .ifnc $1r2,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $3,r1; .ifnc $3r1,fpr11; .ifnc $3r1,r11fp; .ifnc $3r1,ipr12; .ifnc $3r1,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09bl\09__get_user_4", "=&{r0},={r2},{r0},{r1},~{lr},~{cc}"(ptr nonnull %0, i32 -1226833921) #33, !srcloc !1297
  %asmresult.i.i = extractvalue { i32, i32 } %5, 0
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %4) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %tobool.not.i48.i = icmp eq i32 %asmresult.i.i, 0
  br i1 %tobool.not.i48.i, label %if.end.i.i, label %__do_sys_sched_setattr.exit

if.end.i.i:                                       ; preds = %if.end.i
  %asmresult2.i.i = extractvalue { i32, i32 } %5, 1
  %tobool4.not.i.i = icmp eq i32 %asmresult2.i.i, 0
  %spec.store.select.i.i = select i1 %tobool4.not.i.i, i32 48, i32 %asmresult2.i.i
  %6 = add i32 %spec.store.select.i.i, -4097
  %7 = icmp ult i32 %6, -4049
  br i1 %7, label %err_size.i.i, label %if.end9.i.i

if.end9.i.i:                                      ; preds = %if.end.i.i
  %8 = tail call i32 @llvm.umin.i32(i32 %spec.store.select.i.i, i32 56) #33
  %cmp2.i.i.i = icmp ult i32 %spec.store.select.i.i, 56
  %9 = tail call i32 @llvm.umax.i32(i32 %spec.store.select.i.i, i32 56) #33
  %sub.i.i.i = sub nuw nsw i32 %9, %8
  br i1 %cmp2.i.i.i, label %if.then.i.i.i, label %if.else.i.i.i

if.then.i.i.i:                                    ; preds = %if.end9.i.i
  %add.ptr.i.i.i = getelementptr i8, ptr %attr.i, i32 %8
  %10 = call ptr @memset(ptr %add.ptr.i.i.i, i32 0, i32 %sub.i.i.i)
  br label %if.then.i.i.i.i.i.i

if.else.i.i.i:                                    ; preds = %if.end9.i.i
  %cmp.not.i.i.i = icmp eq i32 %spec.store.select.i.i, 56
  br i1 %cmp.not.i.i.i, label %if.then.i.i.i.i.i.i, label %if.then9.i.i.i

if.then9.i.i.i:                                   ; preds = %if.else.i.i.i
  %add.ptr10.i.i.i = getelementptr i8, ptr %0, i32 %8
  %call.i.i.i = tail call i32 @check_zeroed_user(ptr noundef %add.ptr10.i.i.i, i32 noundef %sub.i.i.i) #33
  %cmp11.i.i.i = icmp slt i32 %call.i.i.i, 1
  br i1 %cmp11.i.i.i, label %copy_struct_from_user.exit.i.i, label %if.then.i.i.i.i.i.i

if.then.i.i.i.i.i.i:                              ; preds = %if.then9.i.i.i, %if.else.i.i.i, %if.then.i.i.i
  call void @__check_object_size(ptr noundef nonnull %attr.i, i32 noundef %8, i1 noundef zeroext false) #33
  call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 156) #33
  %call.i.i.i.i.i = call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i.i.i.i, label %if.then11.i.i.i.i.i, label %land.lhs.true.i.i.i.i.i

land.lhs.true.i.i.i.i.i:                          ; preds = %if.then.i.i.i.i.i.i
  %11 = call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr nonnull %0, i32 %8, i32 -1226833920) #40, !srcloc !1298
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %11, 0
  %cmp.i6.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i, 0
  br i1 %cmp.i6.i.i.i.i, label %if.end.i.i.i.i.i, label %if.then11.i.i.i.i.i, !prof !1191

if.end.i.i.i.i.i:                                 ; preds = %land.lhs.true.i.i.i.i.i
  %call.i.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef nonnull %attr.i, i32 noundef %8) #33
  %12 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i.i.i.i = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i.i.i.i.i.i.i to ptr
  %cpu_domain.i.i.i.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 4
  %14 = call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i.i.i.i.i.i.i) #22, !srcloc !1268
  %and.i.i.i.i.i.i.i = and i32 %14, -13
  %or.i.i.i.i.i.i.i = or i32 %and.i.i.i.i.i.i.i, 4
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i.i.i.i.i.i.i) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %call1.i.i.i.i.i.i = call i32 @arm_copy_from_user(ptr noundef nonnull %attr.i, ptr noundef nonnull %0, i32 noundef %8) #33
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %14) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %tobool4.not.i.i.i.i.i = icmp eq i32 %call1.i.i.i.i.i.i, 0
  br i1 %tobool4.not.i.i.i.i.i, label %if.end16.i.i, label %if.then11.i.i.i.i.i, !prof !1191

if.then11.i.i.i.i.i:                              ; preds = %if.end.i.i.i.i.i, %land.lhs.true.i.i.i.i.i, %if.then.i.i.i.i.i.i
  %res.0.i.i.i66.i.i = phi i32 [ %call1.i.i.i.i.i.i, %if.end.i.i.i.i.i ], [ %8, %if.then.i.i.i.i.i.i ], [ %8, %land.lhs.true.i.i.i.i.i ]
  %sub.i.i.i.i.i = sub i32 %8, %res.0.i.i.i66.i.i
  %add.ptr.i.i.i.i.i = getelementptr i8, ptr %attr.i, i32 %sub.i.i.i.i.i
  %15 = call ptr @memset(ptr %add.ptr.i.i.i.i.i, i32 0, i32 %res.0.i.i.i66.i.i)
  br label %__do_sys_sched_setattr.exit

copy_struct_from_user.exit.i.i:                   ; preds = %if.then9.i.i.i
  %tobool.not.i.i.i = icmp eq i32 %call.i.i.i, 0
  %..i.i.i = select i1 %tobool.not.i.i.i, i32 -7, i32 %call.i.i.i
  %cond.i.i = icmp eq i32 %..i.i.i, -7
  br i1 %cond.i.i, label %err_size.i.i, label %__do_sys_sched_setattr.exit

if.end16.i.i:                                     ; preds = %if.end.i.i.i.i.i
  %sched_flags.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 2
  %16 = ptrtoint ptr %sched_flags.i.i to i32
  call void @__asan_load8_noabort(i32 %16)
  %17 = load i64, ptr %sched_flags.i.i, align 8
  %and.i.i = and i64 %17, 96
  %tobool17.not.i.i = icmp ne i64 %and.i.i, 0
  %or.cond59.i.i = select i1 %tobool17.not.i.i, i1 %cmp2.i.i.i, i1 false
  br i1 %or.cond59.i.i, label %__do_sys_sched_setattr.exit, label %if.end6.i

err_size.i.i:                                     ; preds = %copy_struct_from_user.exit.i.i, %if.end.i.i
  tail call void @__might_fault(ptr noundef nonnull @.str.1, i32 noundef 7692) #33
  %18 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i60.i.i = and i32 %18, -16384
  %19 = inttoptr i32 %and.i.i.i60.i.i to ptr
  %cpu_domain.i.i61.i.i = getelementptr inbounds %struct.thread_info, ptr %19, i32 0, i32 4
  %20 = tail call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i61.i.i) #22, !srcloc !1268
  %and.i62.i.i = and i32 %20, -13
  %or.i63.i.i = or i32 %and.i62.i.i, 4
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i63.i.i) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %21 = tail call i32 asm sideeffect ".ifnc $0,r0; .ifnc $0r0,fpr11; .ifnc $0r0,r11fp; .ifnc $0r0,ipr12; .ifnc $0r0,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $2,r2; .ifnc $2r2,fpr11; .ifnc $2r2,r11fp; .ifnc $2r2,ipr12; .ifnc $2r2,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09.ifnc $3,r1; .ifnc $3r1,fpr11; .ifnc $3r1,r11fp; .ifnc $3r1,ipr12; .ifnc $3r1,r12ip; .err; .endif; .endif; .endif; .endif; .endif\0A\09bl\09__put_user_4", "=&{r0},{r0},{r2},{r1},~{r12},~{lr},~{cc}"(ptr nonnull %0, i32 56, i32 -1226833921) #33, !srcloc !1299
  tail call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %20) #33, !srcloc !1269
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  br label %__do_sys_sched_setattr.exit

if.end6.i:                                        ; preds = %if.end16.i.i
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 3
  %22 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %sched_nice.i.i, align 8
  %24 = call i32 @llvm.smax.i32(i32 %23, i32 -20) #33
  %25 = call i32 @llvm.smin.i32(i32 %24, i32 19) #33
  %26 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %25, ptr %sched_nice.i.i, align 8
  %sched_policy.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 1
  %27 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %sched_policy.i, align 4
  %cmp7.i = icmp slt i32 %28, 0
  br i1 %cmp7.i, label %__do_sys_sched_setattr.exit, label %if.end9.i

if.end9.i:                                        ; preds = %if.end6.i
  %and.i = and i64 %17, 8
  %tobool10.not.i = icmp eq i64 %and.i, 0
  br i1 %tobool10.not.i, label %if.end13.i, label %if.then11.i

if.then11.i:                                      ; preds = %if.end9.i
  %29 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 -1, ptr %sched_policy.i, align 4
  br label %if.end13.i

if.end13.i:                                       ; preds = %if.then11.i, %if.end9.i
  %30 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %30, -16384
  %31 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %31, i32 0, i32 1
  %32 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %33, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end13.i
  %call1.i.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.end13.i
  %tobool.not.i49.i = icmp eq i32 %pid, 0
  br i1 %tobool.not.i49.i, label %cond.false.i.i, label %cond.true.i.i

cond.true.i.i:                                    ; preds = %rcu_read_lock.exit.i
  %call.i50.i = call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit.i

cond.false.i.i:                                   ; preds = %rcu_read_lock.exit.i
  %34 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i51.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i51.i to ptr
  %task.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 2
  %36 = ptrtoint ptr %task.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %task.i.i, align 8
  br label %find_process_by_pid.exit.i

find_process_by_pid.exit.i:                       ; preds = %cond.false.i.i, %cond.true.i.i
  %cond.i52.i = phi ptr [ %call.i50.i, %cond.true.i.i ], [ %37, %cond.false.i.i ]
  %tobool15.not.i = icmp eq ptr %cond.i52.i, null
  br i1 %tobool15.not.i, label %if.end35.critedge.i, label %if.then18.i, !prof !1192

if.then18.i:                                      ; preds = %find_process_by_pid.exit.i
  %usage.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i52.i, i32 0, i32 2
  %call.i.i.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %usage.i.i, i32 noundef 4) #33
  call void @llvm.prefetch.p0(ptr %usage.i.i, i32 1, i32 3, i32 1) #33
  %38 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i.i, ptr %usage.i.i, i32 1, ptr elementtype(i32) %usage.i.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %38, 0
  %tobool1.not.i.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i.i, label %if.end15.sink.split.i.i.i.i.i, label %if.else.i.i.i.i53.i, !prof !1192

if.else.i.i.i.i53.i:                              ; preds = %if.then18.i
  %add.i.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i.i, 1
  %39 = or i32 %add.i.i.i.i.i, %asmresult.i.i.i.i.i.i.i
  %.not.i.i.i.i.i = icmp sgt i32 %39, -1
  br i1 %.not.i.i.i.i.i, label %get_task_struct.exit.i, label %if.end15.sink.split.i.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i.i:                    ; preds = %if.else.i.i.i.i53.i, %if.then18.i
  %.sink.i.i.i.i.i = phi i32 [ 2, %if.then18.i ], [ 1, %if.else.i.i.i.i53.i ]
  call void @refcount_warn_saturate(ptr noundef %usage.i.i, i32 noundef %.sink.i.i.i.i.i) #33
  br label %get_task_struct.exit.i

get_task_struct.exit.i:                           ; preds = %if.end15.sink.split.i.i.i.i.i, %if.else.i.i.i.i53.i
  %call.i54.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i54.i, label %rcu_read_unlock.exit.i, label %land.lhs.true.i57.i

land.lhs.true.i57.i:                              ; preds = %get_task_struct.exit.i
  %call1.i55.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i56.i = icmp eq i32 %call1.i55.i, 0
  br i1 %tobool.not.i56.i, label %rcu_read_unlock.exit.i, label %land.lhs.true2.i59.i

land.lhs.true2.i59.i:                             ; preds = %land.lhs.true.i57.i
  %.b4.i58.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i58.i, label %rcu_read_unlock.exit.i, label %if.then.i60.i

if.then.i60.i:                                    ; preds = %land.lhs.true2.i59.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit.i

rcu_read_unlock.exit.i:                           ; preds = %if.then.i60.i, %land.lhs.true2.i59.i, %land.lhs.true.i57.i, %get_task_struct.exit.i
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %40 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i61.i = and i32 %40, -16384
  %41 = inttoptr i32 %and.i.i.i.i.i61.i to ptr
  %preempt_count.i.i.i.i62.i = getelementptr inbounds %struct.thread_info, ptr %41, i32 0, i32 1
  %42 = ptrtoint ptr %preempt_count.i.i.i.i62.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %preempt_count.i.i.i.i62.i, align 4
  %sub.i.i.i.i = add i32 %43, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i62.i, align 4
  call void @rcu_read_unlock_strict() #33
  call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %44 = ptrtoint ptr %sched_flags.i.i to i32
  call void @__asan_load8_noabort(i32 %44)
  %45 = load i64, ptr %sched_flags.i.i, align 8
  %and30.i = and i64 %45, 16
  %tobool31.not.i = icmp eq i64 %and30.i, 0
  br i1 %tobool31.not.i, label %if.end33.i, label %if.then32.i

if.then32.i:                                      ; preds = %rcu_read_unlock.exit.i
  %policy.i.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i52.i, i32 0, i32 31
  %46 = ptrtoint ptr %policy.i.i.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %policy.i.i.i, align 4
  %cmp.i.i.not.i.i = icmp eq i32 %47, 6
  br i1 %cmp.i.i.not.i.i, label %if.then.i63.i, label %if.else.i.i

if.then.i63.i:                                    ; preds = %if.then32.i
  call void @__getparam_dl(ptr noundef nonnull %cond.i52.i, ptr noundef nonnull %attr.i) #33
  br label %if.end33.i

if.else.i.i:                                      ; preds = %if.then32.i
  %48 = add i32 %47, -3
  %49 = icmp ult i32 %48, -2
  br i1 %49, label %if.else4.i.i, label %if.then3.i.i

if.then3.i.i:                                     ; preds = %if.else.i.i
  %rt_priority.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i52.i, i32 0, i32 16
  %50 = ptrtoint ptr %rt_priority.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %rt_priority.i.i, align 4
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i, i32 0, i32 4
  %52 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 %51, ptr %sched_priority.i.i, align 4
  br label %if.end33.i

if.else4.i.i:                                     ; preds = %if.else.i.i
  %static_prio.i.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i52.i, i32 0, i32 14
  %53 = ptrtoint ptr %static_prio.i.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %static_prio.i.i.i, align 4
  %sub.i.i64.i = add i32 %54, -120
  %55 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 %sub.i.i64.i, ptr %sched_nice.i.i, align 8
  br label %if.end33.i

if.end33.i:                                       ; preds = %if.else4.i.i, %if.then3.i.i, %if.then.i63.i, %rcu_read_unlock.exit.i
  %call.i66.i = call fastcc i32 @__sched_setscheduler(ptr noundef nonnull %cond.i52.i, ptr noundef nonnull %attr.i, i1 noundef zeroext true, i1 noundef zeroext true) #33
  %call.i.i.i.i.i.i68.i = call zeroext i1 @__kasan_check_write(ptr noundef %usage.i.i, i32 noundef 4) #33
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  call void @llvm.prefetch.p0(ptr %usage.i.i, i32 1, i32 3, i32 1) #33
  %56 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i.i, ptr %usage.i.i, i32 1, ptr elementtype(i32) %usage.i.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %56, 0
  %cmp.i.i.i.i69.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i69.i, label %if.then.i71.i, label %if.end5.i.i.i.i.i

if.end5.i.i.i.i.i:                                ; preds = %if.end33.i
  %.not.i.i.i.i70.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i70.i, label %__do_sys_sched_setattr.exit, label %if.then10.i.i.i.i.i, !prof !1191

if.then10.i.i.i.i.i:                              ; preds = %if.end5.i.i.i.i.i
  call void @refcount_warn_saturate(ptr noundef %usage.i.i, i32 noundef 3) #33
  br label %__do_sys_sched_setattr.exit

if.then.i71.i:                                    ; preds = %if.end33.i
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  call void @__put_task_struct(ptr noundef nonnull %cond.i52.i) #33
  br label %__do_sys_sched_setattr.exit

if.end35.critedge.i:                              ; preds = %find_process_by_pid.exit.i
  %call.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_unlock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end35.critedge.i
  %call1.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i1 = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i1, label %rcu_read_unlock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_unlock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end35.critedge.i
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %57 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i2 = and i32 %57, -16384
  %58 = inttoptr i32 %and.i.i.i.i.i2 to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %58, i32 0, i32 1
  %59 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %sub.i.i.i3 = add i32 %60, -1
  store volatile i32 %sub.i.i.i3, ptr %preempt_count.i.i.i.i, align 4
  call void @rcu_read_unlock_strict() #33
  call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %__do_sys_sched_setattr.exit

__do_sys_sched_setattr.exit:                      ; preds = %rcu_read_unlock.exit, %if.then.i71.i, %if.then10.i.i.i.i.i, %if.end5.i.i.i.i.i, %if.end6.i, %err_size.i.i, %if.end16.i.i, %copy_struct_from_user.exit.i.i, %if.then11.i.i.i.i.i, %if.end.i, %entry
  %retval.0.i = phi i32 [ -22, %entry ], [ -22, %if.end6.i ], [ -3, %rcu_read_unlock.exit ], [ %call.i66.i, %if.end5.i.i.i.i.i ], [ %call.i66.i, %if.then10.i.i.i.i.i ], [ %call.i66.i, %if.then.i71.i ], [ -14, %if.then11.i.i.i.i.i ], [ -22, %if.end16.i.i ], [ %..i.i.i, %copy_struct_from_user.exit.i.i ], [ %asmresult.i.i, %if.end.i ], [ -7, %err_size.i.i ]
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i) #33
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_getscheduler(i32 noundef %pid) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cmp.i = icmp slt i32 %pid, 0
  br i1 %cmp.i, label %__do_sys_sched_getscheduler.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end.i
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.end.i
  %tobool.not.i15.i = icmp eq i32 %pid, 0
  br i1 %tobool.not.i15.i, label %cond.false.i.i, label %cond.true.i.i

cond.true.i.i:                                    ; preds = %rcu_read_lock.exit.i
  %call.i16.i = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit.i

cond.false.i.i:                                   ; preds = %rcu_read_lock.exit.i
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i to ptr
  %task.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task.i.i, align 8
  br label %find_process_by_pid.exit.i

find_process_by_pid.exit.i:                       ; preds = %cond.false.i.i, %cond.true.i.i
  %cond.i.i = phi ptr [ %call.i16.i, %cond.true.i.i ], [ %7, %cond.false.i.i ]
  %tobool.not.i = icmp eq ptr %cond.i.i, null
  br i1 %tobool.not.i, label %if.end8.i, label %if.then2.i

if.then2.i:                                       ; preds = %find_process_by_pid.exit.i
  %call3.i = tail call i32 @security_task_getscheduler(ptr noundef nonnull %cond.i.i) #33
  %tobool4.not.i = icmp eq i32 %call3.i, 0
  br i1 %tobool4.not.i, label %if.then5.i, label %if.end8.i

if.then5.i:                                       ; preds = %if.then2.i
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 31
  %8 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %policy.i, align 4
  %sched_reset_on_fork.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 63
  %10 = ptrtoint ptr %sched_reset_on_fork.i to i32
  call void @__asan_load1_noabort(i32 %10)
  %bf.load.i = load i8, ptr %sched_reset_on_fork.i, align 4
  %11 = and i8 %bf.load.i, -128
  %12 = zext i8 %11 to i32
  %13 = shl nuw nsw i32 %12, 23
  %or.i = or i32 %13, %9
  br label %if.end8.i

if.end8.i:                                        ; preds = %if.then5.i, %if.then2.i, %find_process_by_pid.exit.i
  %retval1.0.i = phi i32 [ %call3.i, %if.then2.i ], [ %or.i, %if.then5.i ], [ -3, %find_process_by_pid.exit.i ]
  %call.i17.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i17.i, label %rcu_read_unlock.exit.i, label %land.lhs.true.i20.i

land.lhs.true.i20.i:                              ; preds = %if.end8.i
  %call1.i18.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i19.i = icmp eq i32 %call1.i18.i, 0
  br i1 %tobool.not.i19.i, label %rcu_read_unlock.exit.i, label %land.lhs.true2.i22.i

land.lhs.true2.i22.i:                             ; preds = %land.lhs.true.i20.i
  %.b4.i21.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i21.i, label %rcu_read_unlock.exit.i, label %if.then.i23.i

if.then.i23.i:                                    ; preds = %land.lhs.true2.i22.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit.i

rcu_read_unlock.exit.i:                           ; preds = %if.then.i23.i, %land.lhs.true2.i22.i, %land.lhs.true.i20.i, %if.end8.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i24.i = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i.i.i24.i to ptr
  %preempt_count.i.i.i.i25.i = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i.i.i25.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %preempt_count.i.i.i.i25.i, align 4
  %sub.i.i.i.i = add i32 %17, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i25.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %__do_sys_sched_getscheduler.exit

__do_sys_sched_getscheduler.exit:                 ; preds = %rcu_read_unlock.exit.i, %entry
  %retval.0.i = phi i32 [ %retval1.0.i, %rcu_read_unlock.exit.i ], [ -22, %entry ]
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_getparam(i32 noundef %pid, i32 noundef %param) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %lp.i = alloca %struct.sched_param, align 4
  %0 = inttoptr i32 %param to ptr
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %lp.i) #33
  %1 = ptrtoint ptr %lp.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 0, ptr %lp.i, align 4
  %tobool.not.i = icmp eq i32 %param, 0
  %cmp.i = icmp slt i32 %pid, 0
  %or.cond.i = or i1 %cmp.i, %tobool.not.i
  br i1 %or.cond.i, label %__do_sys_sched_getparam.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %2 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %5, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end.i
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.end.i
  %tobool.not.i25.i = icmp eq i32 %pid, 0
  br i1 %tobool.not.i25.i, label %cond.false.i.i, label %cond.true.i.i

cond.true.i.i:                                    ; preds = %rcu_read_lock.exit.i
  %call.i26.i = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit.i

cond.false.i.i:                                   ; preds = %rcu_read_lock.exit.i
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i.i to ptr
  %task.i.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %8 = ptrtoint ptr %task.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %task.i.i, align 8
  br label %find_process_by_pid.exit.i

find_process_by_pid.exit.i:                       ; preds = %cond.false.i.i, %cond.true.i.i
  %cond.i.i = phi ptr [ %call.i26.i, %cond.true.i.i ], [ %9, %cond.false.i.i ]
  %tobool2.not.i = icmp eq ptr %cond.i.i, null
  br i1 %tobool2.not.i, label %out_unlock.i, label %if.end4.i

if.end4.i:                                        ; preds = %find_process_by_pid.exit.i
  %call5.i = tail call i32 @security_task_getscheduler(ptr noundef nonnull %cond.i.i) #33
  %tobool6.not.i = icmp eq i32 %call5.i, 0
  br i1 %tobool6.not.i, label %if.end8.i, label %out_unlock.i

if.end8.i:                                        ; preds = %if.end4.i
  %policy.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 31
  %10 = ptrtoint ptr %policy.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %policy.i.i, align 4
  %12 = add i32 %11, -3
  %13 = icmp ult i32 %12, -2
  br i1 %13, label %if.end12.i, label %if.then11.i

if.then11.i:                                      ; preds = %if.end8.i
  %rt_priority.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 16
  %14 = ptrtoint ptr %rt_priority.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %rt_priority.i, align 4
  %16 = ptrtoint ptr %lp.i to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 %15, ptr %lp.i, align 4
  br label %if.end12.i

if.end12.i:                                       ; preds = %if.then11.i, %if.end8.i
  %call.i27.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i27.i, label %rcu_read_unlock.exit.i, label %land.lhs.true.i30.i

land.lhs.true.i30.i:                              ; preds = %if.end12.i
  %call1.i28.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i29.i = icmp eq i32 %call1.i28.i, 0
  br i1 %tobool.not.i29.i, label %rcu_read_unlock.exit.i, label %land.lhs.true2.i32.i

land.lhs.true2.i32.i:                             ; preds = %land.lhs.true.i30.i
  %.b4.i31.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i31.i, label %rcu_read_unlock.exit.i, label %if.then.i33.i

if.then.i33.i:                                    ; preds = %land.lhs.true2.i32.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit.i

rcu_read_unlock.exit.i:                           ; preds = %if.then.i33.i, %land.lhs.true2.i32.i, %land.lhs.true.i30.i, %if.end12.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %17 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i34.i = and i32 %17, -16384
  %18 = inttoptr i32 %and.i.i.i.i.i34.i to ptr
  %preempt_count.i.i.i.i35.i = getelementptr inbounds %struct.thread_info, ptr %18, i32 0, i32 1
  %19 = ptrtoint ptr %preempt_count.i.i.i.i35.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %preempt_count.i.i.i.i35.i, align 4
  %sub.i.i.i.i = add i32 %20, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i35.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  tail call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 174) #33
  %call.i.i.i = tail call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i.i, label %__do_sys_sched_getparam.exit, label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %rcu_read_unlock.exit.i
  %21 = tail call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr nonnull %0, i32 4, i32 -1226833920) #40, !srcloc !1300
  %asmresult.i.i.i = extractvalue { i32, i32 } %21, 0
  %cmp.i6.i.i = icmp eq i32 %asmresult.i.i.i, 0
  br i1 %cmp.i6.i.i, label %copy_to_user.exit.i, label %__do_sys_sched_getparam.exit

copy_to_user.exit.i:                              ; preds = %if.end.i.i.i
  %call.i.i.i.i = call zeroext i1 @__kasan_check_read(ptr noundef nonnull %lp.i, i32 noundef 4) #33
  %call.i12.i.i.i = call i32 @arm_copy_to_user(ptr noundef nonnull %0, ptr noundef nonnull %lp.i, i32 noundef 4) #33
  %tobool14.not.i = icmp eq i32 %call.i12.i.i.i, 0
  %spec.select.i = select i1 %tobool14.not.i, i32 0, i32 -14
  br label %__do_sys_sched_getparam.exit

out_unlock.i:                                     ; preds = %if.end4.i, %find_process_by_pid.exit.i
  %retval1.0.i = phi i32 [ %call5.i, %if.end4.i ], [ -3, %find_process_by_pid.exit.i ]
  %call.i36.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i36.i, label %rcu_read_unlock.exit46.i, label %land.lhs.true.i39.i

land.lhs.true.i39.i:                              ; preds = %out_unlock.i
  %call1.i37.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i38.i = icmp eq i32 %call1.i37.i, 0
  br i1 %tobool.not.i38.i, label %rcu_read_unlock.exit46.i, label %land.lhs.true2.i41.i

land.lhs.true2.i41.i:                             ; preds = %land.lhs.true.i39.i
  %.b4.i40.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i40.i, label %rcu_read_unlock.exit46.i, label %if.then.i42.i

if.then.i42.i:                                    ; preds = %land.lhs.true2.i41.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit46.i

rcu_read_unlock.exit46.i:                         ; preds = %if.then.i42.i, %land.lhs.true2.i41.i, %land.lhs.true.i39.i, %out_unlock.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %22 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i43.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i.i.i.i43.i to ptr
  %preempt_count.i.i.i.i44.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i.i.i.i44.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i.i.i.i44.i, align 4
  %sub.i.i.i45.i = add i32 %25, -1
  store volatile i32 %sub.i.i.i45.i, ptr %preempt_count.i.i.i.i44.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %__do_sys_sched_getparam.exit

__do_sys_sched_getparam.exit:                     ; preds = %rcu_read_unlock.exit46.i, %copy_to_user.exit.i, %if.end.i.i.i, %rcu_read_unlock.exit.i, %entry
  %retval.0.i = phi i32 [ %retval1.0.i, %rcu_read_unlock.exit46.i ], [ -22, %entry ], [ -14, %rcu_read_unlock.exit.i ], [ -14, %if.end.i.i.i ], [ %spec.select.i, %copy_to_user.exit.i ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %lp.i) #33
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_getattr(i32 noundef %pid, i32 noundef %uattr, i32 noundef %usize, i32 noundef %flags) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %kattr.i = alloca %struct.sched_attr, align 8
  %0 = inttoptr i32 %uattr to ptr
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %kattr.i) #33
  %1 = call ptr @memset(ptr %kattr.i, i32 0, i32 56)
  %tobool.not.i = icmp eq i32 %uattr, 0
  %cmp.i = icmp slt i32 %pid, 0
  %or.cond.i = or i1 %cmp.i, %tobool.not.i
  %2 = add i32 %usize, -4097
  %3 = icmp ult i32 %2, -4049
  %4 = or i1 %or.cond.i, %3
  %tobool7.not.i = icmp ne i32 %flags, 0
  %5 = or i1 %tobool7.not.i, %4
  br i1 %5, label %__do_sys_sched_getattr.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 1
  %8 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %9, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end.i
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.end.i
  %tobool.not.i44.i = icmp eq i32 %pid, 0
  br i1 %tobool.not.i44.i, label %cond.false.i.i, label %cond.true.i.i

cond.true.i.i:                                    ; preds = %rcu_read_lock.exit.i
  %call.i45.i = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit.i

cond.false.i.i:                                   ; preds = %rcu_read_lock.exit.i
  %10 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i.i to ptr
  %task.i.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 2
  %12 = ptrtoint ptr %task.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task.i.i, align 8
  br label %find_process_by_pid.exit.i

find_process_by_pid.exit.i:                       ; preds = %cond.false.i.i, %cond.true.i.i
  %cond.i.i = phi ptr [ %call.i45.i, %cond.true.i.i ], [ %13, %cond.false.i.i ]
  %tobool8.not.i = icmp eq ptr %cond.i.i, null
  br i1 %tobool8.not.i, label %out_unlock.i, label %if.end10.i

if.end10.i:                                       ; preds = %find_process_by_pid.exit.i
  %call11.i = tail call i32 @security_task_getscheduler(ptr noundef nonnull %cond.i.i) #33
  %tobool12.not.i = icmp eq i32 %call11.i, 0
  br i1 %tobool12.not.i, label %if.end14.i, label %out_unlock.i

if.end14.i:                                       ; preds = %if.end10.i
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 31
  %14 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %policy.i, align 4
  %sched_policy.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 1
  %16 = ptrtoint ptr %sched_policy.i to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 %15, ptr %sched_policy.i, align 4
  %sched_reset_on_fork.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 63
  %17 = ptrtoint ptr %sched_reset_on_fork.i to i32
  call void @__asan_load1_noabort(i32 %17)
  %bf.load.i = load i8, ptr %sched_reset_on_fork.i, align 4
  %tobool15.not.i = icmp sgt i8 %bf.load.i, -1
  br i1 %tobool15.not.i, label %if.end17.i, label %if.then16.i

if.then16.i:                                      ; preds = %if.end14.i
  %sched_flags.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 2
  %18 = ptrtoint ptr %sched_flags.i to i32
  call void @__asan_load8_noabort(i32 %18)
  %19 = load i64, ptr %sched_flags.i, align 8
  %or.i = or i64 %19, 1
  store i64 %or.i, ptr %sched_flags.i, align 8
  br label %if.end17.i

if.end17.i:                                       ; preds = %if.then16.i, %if.end14.i
  %20 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %policy.i, align 4
  %cmp.i.i.not.i.i = icmp eq i32 %21, 6
  br i1 %cmp.i.i.not.i.i, label %if.then.i46.i, label %if.else.i.i

if.then.i46.i:                                    ; preds = %if.end17.i
  call void @__getparam_dl(ptr noundef nonnull %cond.i.i, ptr noundef nonnull %kattr.i) #33
  br label %get_params.exit.i

if.else.i.i:                                      ; preds = %if.end17.i
  %22 = add i32 %21, -3
  %23 = icmp ult i32 %22, -2
  br i1 %23, label %if.else4.i.i, label %if.then3.i.i

if.then3.i.i:                                     ; preds = %if.else.i.i
  %rt_priority.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 16
  %24 = ptrtoint ptr %rt_priority.i.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %rt_priority.i.i, align 4
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 4
  %26 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 %25, ptr %sched_priority.i.i, align 4
  br label %get_params.exit.i

if.else4.i.i:                                     ; preds = %if.else.i.i
  %static_prio.i.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 14
  %27 = ptrtoint ptr %static_prio.i.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %static_prio.i.i.i, align 4
  %sub.i.i.i = add i32 %28, -120
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 3
  %29 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %29)
  store i32 %sub.i.i.i, ptr %sched_nice.i.i, align 8
  br label %get_params.exit.i

get_params.exit.i:                                ; preds = %if.else4.i.i, %if.then3.i.i, %if.then.i46.i
  %sched_flags18.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 2
  %30 = ptrtoint ptr %sched_flags18.i to i32
  call void @__asan_load8_noabort(i32 %30)
  %31 = load i64, ptr %sched_flags18.i, align 8
  %and.i = and i64 %31, 127
  store i64 %and.i, ptr %sched_flags18.i, align 8
  %uclamp_req.i = getelementptr inbounds %struct.task_struct, ptr %cond.i.i, i32 0, i32 26
  %32 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %32)
  %bf.load19.i = load i16, ptr %uclamp_req.i, align 4
  %bf.lshr20.i = lshr i16 %bf.load19.i, 5
  %bf.cast21.i = zext i16 %bf.lshr20.i to i32
  %sched_util_min.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 8
  %33 = ptrtoint ptr %sched_util_min.i to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %bf.cast21.i, ptr %sched_util_min.i, align 8
  %arrayidx23.i = getelementptr %struct.task_struct, ptr %cond.i.i, i32 0, i32 26, i32 1
  %34 = ptrtoint ptr %arrayidx23.i to i32
  call void @__asan_load2_noabort(i32 %34)
  %bf.load24.i = load i16, ptr %arrayidx23.i, align 4
  %bf.lshr25.i = lshr i16 %bf.load24.i, 5
  %bf.cast26.i = zext i16 %bf.lshr25.i to i32
  %sched_util_max.i = getelementptr inbounds %struct.sched_attr, ptr %kattr.i, i32 0, i32 9
  %35 = ptrtoint ptr %sched_util_max.i to i32
  call void @__asan_store4_noabort(i32 %35)
  store i32 %bf.cast26.i, ptr %sched_util_max.i, align 4
  %call.i47.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i47.i, label %rcu_read_unlock.exit.i, label %land.lhs.true.i50.i

land.lhs.true.i50.i:                              ; preds = %get_params.exit.i
  %call1.i48.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i49.i = icmp eq i32 %call1.i48.i, 0
  br i1 %tobool.not.i49.i, label %rcu_read_unlock.exit.i, label %land.lhs.true2.i52.i

land.lhs.true2.i52.i:                             ; preds = %land.lhs.true.i50.i
  %.b4.i51.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i51.i, label %rcu_read_unlock.exit.i, label %if.then.i53.i

if.then.i53.i:                                    ; preds = %land.lhs.true2.i52.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit.i

rcu_read_unlock.exit.i:                           ; preds = %if.then.i53.i, %land.lhs.true2.i52.i, %land.lhs.true.i50.i, %get_params.exit.i
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %36 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i54.i = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i.i.i54.i to ptr
  %preempt_count.i.i.i.i55.i = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i.i.i55.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i.i.i55.i, align 4
  %sub.i.i.i.i = add i32 %39, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i55.i, align 4
  call void @rcu_read_unlock_strict() #33
  call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %40 = call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr nonnull %0, i32 %usize, i32 -1226833920) #40, !srcloc !1301
  %asmresult.i.i = extractvalue { i32, i32 } %40, 0
  %cmp.i.i = icmp eq i32 %asmresult.i.i, 0
  br i1 %cmp.i.i, label %if.end.i.i, label %__do_sys_sched_getattr.exit

if.end.i.i:                                       ; preds = %rcu_read_unlock.exit.i
  %41 = call i32 @llvm.umin.i32(i32 %usize, i32 56) #33
  %42 = ptrtoint ptr %kattr.i to i32
  call void @__asan_store4_noabort(i32 %42)
  store i32 %41, ptr %kattr.i, align 8
  call void @__check_object_size(ptr noundef nonnull %kattr.i, i32 noundef %41, i1 noundef zeroext true) #33
  call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 174) #33
  %call.i.i.i.i = call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i.i.i, label %copy_to_user.exit.i.i, label %if.end.i.i.i.i

if.end.i.i.i.i:                                   ; preds = %if.end.i.i
  %43 = call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr nonnull %0, i32 %41, i32 -1226833920) #40, !srcloc !1300
  %asmresult.i.i.i.i = extractvalue { i32, i32 } %43, 0
  %cmp.i6.i.i.i = icmp eq i32 %asmresult.i.i.i.i, 0
  br i1 %cmp.i6.i.i.i, label %if.then2.i.i.i.i, label %copy_to_user.exit.i.i

if.then2.i.i.i.i:                                 ; preds = %if.end.i.i.i.i
  %call.i.i.i.i.i = call zeroext i1 @__kasan_check_read(ptr noundef nonnull %kattr.i, i32 noundef %41) #33
  %call.i12.i.i.i.i = call i32 @arm_copy_to_user(ptr noundef nonnull %0, ptr noundef nonnull %kattr.i, i32 noundef %41) #33
  br label %copy_to_user.exit.i.i

copy_to_user.exit.i.i:                            ; preds = %if.then2.i.i.i.i, %if.end.i.i.i.i, %if.end.i.i
  %n.addr.0.i.i.i = phi i32 [ %41, %if.end.i.i ], [ %call.i12.i.i.i.i, %if.then2.i.i.i.i ], [ %41, %if.end.i.i.i.i ]
  %tobool.not.i56.i = icmp eq i32 %n.addr.0.i.i.i, 0
  %spec.select.i.i = select i1 %tobool.not.i56.i, i32 0, i32 -14
  br label %__do_sys_sched_getattr.exit

out_unlock.i:                                     ; preds = %if.end10.i, %find_process_by_pid.exit.i
  %retval1.0.i = phi i32 [ %call11.i, %if.end10.i ], [ -3, %find_process_by_pid.exit.i ]
  %call.i57.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i57.i, label %rcu_read_unlock.exit67.i, label %land.lhs.true.i60.i

land.lhs.true.i60.i:                              ; preds = %out_unlock.i
  %call1.i58.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i59.i = icmp eq i32 %call1.i58.i, 0
  br i1 %tobool.not.i59.i, label %rcu_read_unlock.exit67.i, label %land.lhs.true2.i62.i

land.lhs.true2.i62.i:                             ; preds = %land.lhs.true.i60.i
  %.b4.i61.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i61.i, label %rcu_read_unlock.exit67.i, label %if.then.i63.i

if.then.i63.i:                                    ; preds = %land.lhs.true2.i62.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit67.i

rcu_read_unlock.exit67.i:                         ; preds = %if.then.i63.i, %land.lhs.true2.i62.i, %land.lhs.true.i60.i, %out_unlock.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %44 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i64.i = and i32 %44, -16384
  %45 = inttoptr i32 %and.i.i.i.i.i64.i to ptr
  %preempt_count.i.i.i.i65.i = getelementptr inbounds %struct.thread_info, ptr %45, i32 0, i32 1
  %46 = ptrtoint ptr %preempt_count.i.i.i.i65.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load volatile i32, ptr %preempt_count.i.i.i.i65.i, align 4
  %sub.i.i.i66.i = add i32 %47, -1
  store volatile i32 %sub.i.i.i66.i, ptr %preempt_count.i.i.i.i65.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %__do_sys_sched_getattr.exit

__do_sys_sched_getattr.exit:                      ; preds = %rcu_read_unlock.exit67.i, %copy_to_user.exit.i.i, %rcu_read_unlock.exit.i, %entry
  %retval.0.i = phi i32 [ %retval1.0.i, %rcu_read_unlock.exit67.i ], [ -22, %entry ], [ -14, %rcu_read_unlock.exit.i ], [ %spec.select.i.i, %copy_to_user.exit.i.i ]
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %kattr.i) #33
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @dl_task_check_affinity(ptr nocapture noundef readonly %p, ptr noundef %mask) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %policy.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 31
  %0 = ptrtoint ptr %policy.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %policy.i, align 4
  %cmp.i.i.not = icmp eq i32 %1, 6
  br i1 %cmp.i.i.not, label %lor.lhs.false, label %cleanup

lor.lhs.false:                                    ; preds = %entry
  %2 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %tobool2.not = icmp slt i32 %2, 0
  br i1 %tobool2.not, label %cleanup, label %if.end

if.end:                                           ; preds = %lor.lhs.false
  %3 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %3, -16384
  %4 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %4, i32 0, i32 1
  %5 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %6, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %7 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 3
  %9 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %cpu.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %11 = load i32, ptr @nr_cpu_ids, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %10
  %12 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %arrayidx, align 4
  %add = add i32 %13, ptrtoint (ptr @runqueues to i32)
  %14 = inttoptr i32 %add to ptr
  %rd = getelementptr inbounds %struct.rq, ptr %14, i32 0, i32 35
  %15 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %rd, align 8
  %span = getelementptr inbounds %struct.root_domain, ptr %16, i32 0, i32 3
  %17 = ptrtoint ptr %span to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %span, align 8
  %call.i.i = tail call i32 @__bitmap_subset(ptr noundef %18, ptr noundef %mask, i32 noundef %11) #33
  %tobool6.not = icmp eq i32 %call.i.i, 0
  %spec.select = select i1 %tobool6.not, i32 -16, i32 0
  %call.i10 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i10, label %rcu_read_unlock.exit, label %land.lhs.true.i13

land.lhs.true.i13:                                ; preds = %rcu_read_lock.exit
  %call1.i11 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i12 = icmp eq i32 %call1.i11, 0
  br i1 %tobool.not.i12, label %rcu_read_unlock.exit, label %land.lhs.true2.i15

land.lhs.true2.i15:                               ; preds = %land.lhs.true.i13
  %.b4.i14 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i14, label %rcu_read_unlock.exit, label %if.then.i16

if.then.i16:                                      ; preds = %land.lhs.true2.i15
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i16, %land.lhs.true2.i15, %land.lhs.true.i13, %rcu_read_lock.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i17 = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i.i.i.i17 to ptr
  %preempt_count.i.i.i.i18 = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i.i.i.i18 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i.i.i.i18, align 4
  %sub.i.i.i = add i32 %22, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i18, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %cleanup

cleanup:                                          ; preds = %rcu_read_unlock.exit, %lor.lhs.false, %entry
  %retval.0 = phi i32 [ %spec.select, %rcu_read_unlock.exit ], [ 0, %lor.lhs.false ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_setaffinity(i32 noundef %pid, ptr noundef %in_mask) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  %tobool.not.i50 = icmp eq i32 %pid, 0
  br i1 %tobool.not.i50, label %cond.false.i, label %cond.true.i

cond.true.i:                                      ; preds = %rcu_read_lock.exit
  %call.i51 = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit

cond.false.i:                                     ; preds = %rcu_read_lock.exit
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task.i, align 8
  br label %find_process_by_pid.exit

find_process_by_pid.exit:                         ; preds = %cond.false.i, %cond.true.i
  %cond.i = phi ptr [ %call.i51, %cond.true.i ], [ %7, %cond.false.i ]
  %tobool.not = icmp eq ptr %cond.i, null
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %find_process_by_pid.exit
  %call.i52 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i52, label %rcu_read_unlock.exit, label %land.lhs.true.i55

land.lhs.true.i55:                                ; preds = %if.then
  %call1.i53 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i54 = icmp eq i32 %call1.i53, 0
  br i1 %tobool.not.i54, label %rcu_read_unlock.exit, label %land.lhs.true2.i57

land.lhs.true2.i57:                               ; preds = %land.lhs.true.i55
  %.b4.i56 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i56, label %rcu_read_unlock.exit, label %if.then.i58

if.then.i58:                                      ; preds = %land.lhs.true2.i57
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i58, %land.lhs.true2.i57, %land.lhs.true.i55, %if.then
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i59 = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i59 to ptr
  %preempt_count.i.i.i.i60 = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i60 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i60, align 4
  %sub.i.i.i = add i32 %11, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i60, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %cleanup

if.end:                                           ; preds = %find_process_by_pid.exit
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %12 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %12, 0
  %tobool1.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i, label %if.end15.sink.split.i.i.i.i, label %if.else.i.i.i.i, !prof !1192

if.else.i.i.i.i:                                  ; preds = %if.end
  %add.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i, 1
  %13 = or i32 %add.i.i.i.i, %asmresult.i.i.i.i.i.i
  %.not.i.i.i.i = icmp sgt i32 %13, -1
  br i1 %.not.i.i.i.i, label %get_task_struct.exit, label %if.end15.sink.split.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i:                      ; preds = %if.else.i.i.i.i, %if.end
  %.sink.i.i.i.i = phi i32 [ 2, %if.end ], [ 1, %if.else.i.i.i.i ]
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef %.sink.i.i.i.i) #33
  br label %get_task_struct.exit

get_task_struct.exit:                             ; preds = %if.end15.sink.split.i.i.i.i, %if.else.i.i.i.i
  %call.i61 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i61, label %rcu_read_unlock.exit71, label %land.lhs.true.i64

land.lhs.true.i64:                                ; preds = %get_task_struct.exit
  %call1.i62 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i63 = icmp eq i32 %call1.i62, 0
  br i1 %tobool.not.i63, label %rcu_read_unlock.exit71, label %land.lhs.true2.i66

land.lhs.true2.i66:                               ; preds = %land.lhs.true.i64
  %.b4.i65 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i65, label %rcu_read_unlock.exit71, label %if.then.i67

if.then.i67:                                      ; preds = %land.lhs.true2.i66
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit71

rcu_read_unlock.exit71:                           ; preds = %if.then.i67, %land.lhs.true2.i66, %land.lhs.true.i64, %get_task_struct.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i68 = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i.i.i68 to ptr
  %preempt_count.i.i.i.i69 = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i.i.i69 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %preempt_count.i.i.i.i69, align 4
  %sub.i.i.i70 = add i32 %17, -1
  store volatile i32 %sub.i.i.i70, ptr %preempt_count.i.i.i.i69, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %flags = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 3
  %18 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %flags, align 4
  %and = and i32 %19, 67108864
  %tobool3.not = icmp eq i32 %and, 0
  br i1 %tobool3.not, label %if.end5, label %out_put_task

if.end5:                                          ; preds = %rcu_read_unlock.exit71
  %call6 = tail call fastcc zeroext i1 @check_same_owner(ptr noundef nonnull %cond.i)
  br i1 %call6, label %if.end23, label %if.then7

if.then7:                                         ; preds = %if.end5
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i39 = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i39 to ptr
  %preempt_count.i.i.i.i40 = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i40 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i40, align 4
  %add.i.i.i41 = add i32 %23, 1
  store volatile i32 %add.i.i.i41, ptr %preempt_count.i.i.i.i40, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i42 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i42, label %rcu_read_lock.exit49, label %land.lhs.true.i45

land.lhs.true.i45:                                ; preds = %if.then7
  %call1.i43 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i44 = icmp eq i32 %call1.i43, 0
  br i1 %tobool.not.i44, label %rcu_read_lock.exit49, label %land.lhs.true2.i47

land.lhs.true2.i47:                               ; preds = %land.lhs.true.i45
  %.b4.i46 = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i46, label %rcu_read_lock.exit49, label %if.then.i48

if.then.i48:                                      ; preds = %land.lhs.true2.i47
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit49

rcu_read_lock.exit49:                             ; preds = %if.then.i48, %land.lhs.true2.i47, %land.lhs.true.i45, %if.then7
  %real_cred = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 98
  %24 = ptrtoint ptr %real_cred to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile ptr, ptr %real_cred, align 4
  %call9 = tail call i32 @rcu_read_lock_held() #33
  %tobool10.not = icmp eq i32 %call9, 0
  br i1 %tobool10.not, label %land.lhs.true, label %do.end18

land.lhs.true:                                    ; preds = %rcu_read_lock.exit49
  %call11 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool12.not = icmp eq i32 %call11, 0
  br i1 %tobool12.not, label %do.end18, label %land.lhs.true13

land.lhs.true13:                                  ; preds = %land.lhs.true
  %.b38 = load i1, ptr @sched_setaffinity.__warned, align 1
  br i1 %.b38, label %do.end18, label %if.then15

if.then15:                                        ; preds = %land.lhs.true13
  store i1 true, ptr @sched_setaffinity.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 8031, ptr noundef nonnull @.str.3) #33
  br label %do.end18

do.end18:                                         ; preds = %if.then15, %land.lhs.true13, %land.lhs.true, %rcu_read_lock.exit49
  %user_ns = getelementptr inbounds %struct.cred, ptr %25, i32 0, i32 25
  %26 = ptrtoint ptr %user_ns to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %user_ns, align 4
  %call20 = tail call zeroext i1 @ns_capable(ptr noundef %27, i32 noundef 23) #33
  %call.i83 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call20, label %if.end22, label %if.then21

if.then21:                                        ; preds = %do.end18
  br i1 %call.i83, label %rcu_read_unlock.exit82, label %land.lhs.true.i75

land.lhs.true.i75:                                ; preds = %if.then21
  %call1.i73 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i74 = icmp eq i32 %call1.i73, 0
  br i1 %tobool.not.i74, label %rcu_read_unlock.exit82, label %land.lhs.true2.i77

land.lhs.true2.i77:                               ; preds = %land.lhs.true.i75
  %.b4.i76 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i76, label %rcu_read_unlock.exit82, label %if.then.i78

if.then.i78:                                      ; preds = %land.lhs.true2.i77
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit82

rcu_read_unlock.exit82:                           ; preds = %if.then.i78, %land.lhs.true2.i77, %land.lhs.true.i75, %if.then21
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %28 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i79 = and i32 %28, -16384
  %29 = inttoptr i32 %and.i.i.i.i.i79 to ptr
  %preempt_count.i.i.i.i80 = getelementptr inbounds %struct.thread_info, ptr %29, i32 0, i32 1
  %30 = ptrtoint ptr %preempt_count.i.i.i.i80 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load volatile i32, ptr %preempt_count.i.i.i.i80, align 4
  %sub.i.i.i81 = add i32 %31, -1
  store volatile i32 %sub.i.i.i81, ptr %preempt_count.i.i.i.i80, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %out_put_task

if.end22:                                         ; preds = %do.end18
  br i1 %call.i83, label %rcu_read_unlock.exit93, label %land.lhs.true.i86

land.lhs.true.i86:                                ; preds = %if.end22
  %call1.i84 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i85 = icmp eq i32 %call1.i84, 0
  br i1 %tobool.not.i85, label %rcu_read_unlock.exit93, label %land.lhs.true2.i88

land.lhs.true2.i88:                               ; preds = %land.lhs.true.i86
  %.b4.i87 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i87, label %rcu_read_unlock.exit93, label %if.then.i89

if.then.i89:                                      ; preds = %land.lhs.true2.i88
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit93

rcu_read_unlock.exit93:                           ; preds = %if.then.i89, %land.lhs.true2.i88, %land.lhs.true.i86, %if.end22
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %32 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i90 = and i32 %32, -16384
  %33 = inttoptr i32 %and.i.i.i.i.i90 to ptr
  %preempt_count.i.i.i.i91 = getelementptr inbounds %struct.thread_info, ptr %33, i32 0, i32 1
  %34 = ptrtoint ptr %preempt_count.i.i.i.i91 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load volatile i32, ptr %preempt_count.i.i.i.i91, align 4
  %sub.i.i.i92 = add i32 %35, -1
  store volatile i32 %sub.i.i.i92, ptr %preempt_count.i.i.i.i91, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %if.end23

if.end23:                                         ; preds = %rcu_read_unlock.exit93, %if.end5
  %call24 = tail call i32 @security_task_setscheduler(ptr noundef nonnull %cond.i) #33
  %tobool25.not = icmp eq i32 %call24, 0
  br i1 %tobool25.not, label %if.end27, label %out_put_task

if.end27:                                         ; preds = %if.end23
  %call28 = tail call fastcc i32 @__sched_setaffinity(ptr noundef nonnull %cond.i, ptr noundef %in_mask)
  br label %out_put_task

out_put_task:                                     ; preds = %if.end27, %if.end23, %rcu_read_unlock.exit82, %rcu_read_unlock.exit71
  %retval1.0 = phi i32 [ %call24, %if.end23 ], [ %call28, %if.end27 ], [ -1, %rcu_read_unlock.exit82 ], [ -22, %rcu_read_unlock.exit71 ]
  %call.i.i.i.i.i.i95 = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %36 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %36, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i97, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %out_put_task
  %.not.i.i.i.i96 = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i96, label %cleanup, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %cleanup

if.then.i97:                                      ; preds = %out_put_task
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  tail call void @__put_task_struct(ptr noundef nonnull %cond.i) #33
  br label %cleanup

cleanup:                                          ; preds = %if.then.i97, %if.then10.i.i.i.i, %if.end5.i.i.i.i, %rcu_read_unlock.exit
  %retval.0 = phi i32 [ -3, %rcu_read_unlock.exit ], [ %retval1.0, %if.end5.i.i.i.i ], [ %retval1.0, %if.then10.i.i.i.i ], [ %retval1.0, %if.then.i97 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc zeroext i1 @check_same_owner(ptr noundef %p) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %cred1 = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 99
  %4 = ptrtoint ptr %cred1 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %cred1, align 16
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %7, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  %real_cred = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 98
  %8 = ptrtoint ptr %real_cred to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile ptr, ptr %real_cred, align 4
  %call7 = tail call i32 @rcu_read_lock_held() #33
  %tobool.not = icmp eq i32 %call7, 0
  br i1 %tobool.not, label %land.lhs.true, label %do.end13

land.lhs.true:                                    ; preds = %rcu_read_lock.exit
  %call8 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool9.not = icmp eq i32 %call8, 0
  br i1 %tobool9.not, label %do.end13, label %land.lhs.true10

land.lhs.true10:                                  ; preds = %land.lhs.true
  %.b28 = load i1, ptr @check_same_owner.__warned.226, align 1
  br i1 %.b28, label %do.end13, label %if.then

if.then:                                          ; preds = %land.lhs.true10
  store i1 true, ptr @check_same_owner.__warned.226, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 7236, ptr noundef nonnull @.str.3) #33
  br label %do.end13

do.end13:                                         ; preds = %if.then, %land.lhs.true10, %land.lhs.true, %rcu_read_lock.exit
  %euid = getelementptr inbounds %struct.cred, ptr %5, i32 0, i32 8
  %euid15 = getelementptr inbounds %struct.cred, ptr %9, i32 0, i32 8
  %10 = ptrtoint ptr %euid to i32
  call void @__asan_load4_noabort(i32 %10)
  %.unpack = load i32, ptr %euid, align 4
  %11 = ptrtoint ptr %euid15 to i32
  call void @__asan_load4_noabort(i32 %11)
  %.unpack25 = load i32, ptr %euid15, align 4
  %cmp.i = icmp eq i32 %.unpack, %.unpack25
  br i1 %cmp.i, label %lor.end, label %lor.rhs

lor.rhs:                                          ; preds = %do.end13
  %uid = getelementptr inbounds %struct.cred, ptr %9, i32 0, i32 4
  %12 = ptrtoint ptr %uid to i32
  call void @__asan_load4_noabort(i32 %12)
  %.unpack27 = load i32, ptr %uid, align 4
  %cmp.i29 = icmp eq i32 %.unpack, %.unpack27
  br label %lor.end

lor.end:                                          ; preds = %lor.rhs, %do.end13
  %13 = phi i1 [ true, %do.end13 ], [ %cmp.i29, %lor.rhs ]
  %call.i30 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i30, label %rcu_read_unlock.exit, label %land.lhs.true.i33

land.lhs.true.i33:                                ; preds = %lor.end
  %call1.i31 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i32 = icmp eq i32 %call1.i31, 0
  br i1 %tobool.not.i32, label %rcu_read_unlock.exit, label %land.lhs.true2.i35

land.lhs.true2.i35:                               ; preds = %land.lhs.true.i33
  %.b4.i34 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i34, label %rcu_read_unlock.exit, label %if.then.i36

if.then.i36:                                      ; preds = %land.lhs.true2.i35
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i36, %land.lhs.true2.i35, %land.lhs.true.i33, %lor.end
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i37 = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i.i.i37 to ptr
  %preempt_count.i.i.i.i38 = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i.i.i38 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %preempt_count.i.i.i.i38, align 4
  %sub.i.i.i = add i32 %17, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i38, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  ret i1 %13
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @ns_capable(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @security_task_setscheduler(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_setaffinity(i32 noundef %pid, i32 noundef %len, i32 noundef %user_mask_ptr) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %new_mask.i = alloca ptr, align 4
  %0 = inttoptr i32 %user_mask_ptr to ptr
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %new_mask.i) #33
  %1 = ptrtoint ptr %new_mask.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store ptr inttoptr (i32 -1 to ptr), ptr %new_mask.i, align 4, !annotation !1193
  %call.i = call zeroext i1 @alloc_cpumask_var(ptr noundef nonnull %new_mask.i, i32 noundef 3264) #33
  br i1 %call.i, label %if.end.i, label %__do_sys_sched_setaffinity.exit

if.end.i:                                         ; preds = %entry
  %2 = ptrtoint ptr %new_mask.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %new_mask.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i.i = add i32 %4, 31
  %5 = lshr i32 %sub.i.i.i, 3
  %mul.i.i.i = and i32 %5, 536870908
  %cmp.i.i = icmp ugt i32 %mul.i.i.i, %len
  br i1 %cmp.i.i, label %if.then.i.i, label %if.then.i.i.i.i.i

if.then.i.i:                                      ; preds = %if.end.i
  %6 = call ptr @memset(ptr %3, i32 0, i32 %mul.i.i.i)
  br label %if.then.i.i.i.i.i

if.then.i.i.i.i.i:                                ; preds = %if.then.i.i, %if.end.i
  %len.addr.0.i.i = phi i32 [ %len, %if.then.i.i ], [ %mul.i.i.i, %if.end.i ]
  call void @__check_object_size(ptr noundef %3, i32 noundef %len.addr.0.i.i, i1 noundef zeroext false) #33
  call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 156) #33
  %call.i.i.i.i = call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i.i.i, label %if.end.i.i.i.i, label %land.lhs.true.i.i.i.i

land.lhs.true.i.i.i.i:                            ; preds = %if.then.i.i.i.i.i
  %7 = call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr %0, i32 %len.addr.0.i.i, i32 -1226833920) #40, !srcloc !1298
  %asmresult.i.i.i.i = extractvalue { i32, i32 } %7, 0
  %cmp.i6.i.i.i = icmp eq i32 %asmresult.i.i.i.i, 0
  br i1 %cmp.i6.i.i.i, label %if.then.i7.i.i.i, label %if.end.i.i.i.i, !prof !1191

if.then.i7.i.i.i:                                 ; preds = %land.lhs.true.i.i.i.i
  %call.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %3, i32 noundef %len.addr.0.i.i) #33
  %8 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i.i.i.i to ptr
  %cpu_domain.i.i.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 4
  %10 = call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i.i.i.i.i.i) #22, !srcloc !1268
  %and.i.i.i.i.i.i = and i32 %10, -13
  %or.i.i.i.i.i.i = or i32 %and.i.i.i.i.i.i, 4
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i.i.i.i.i.i) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %call1.i.i.i.i.i = call i32 @arm_copy_from_user(ptr noundef %3, ptr noundef %0, i32 noundef %len.addr.0.i.i) #33
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %10) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  br label %if.end.i.i.i.i

if.end.i.i.i.i:                                   ; preds = %if.then.i7.i.i.i, %land.lhs.true.i.i.i.i, %if.then.i.i.i.i.i
  %res.0.i.i.i.i = phi i32 [ %len.addr.0.i.i, %if.then.i.i.i.i.i ], [ %call1.i.i.i.i.i, %if.then.i7.i.i.i ], [ %len.addr.0.i.i, %land.lhs.true.i.i.i.i ]
  %tobool4.not.i.i.i.i = icmp eq i32 %res.0.i.i.i.i, 0
  br i1 %tobool4.not.i.i.i.i, label %if.then3.i, label %if.then11.i.i.i.i, !prof !1191

if.then11.i.i.i.i:                                ; preds = %if.end.i.i.i.i
  %sub.i.i.i.i = sub i32 %len.addr.0.i.i, %res.0.i.i.i.i
  %add.ptr.i.i.i.i = getelementptr i8, ptr %3, i32 %sub.i.i.i.i
  %11 = call ptr @memset(ptr %add.ptr.i.i.i.i, i32 0, i32 %res.0.i.i.i.i)
  br label %if.end5.i

if.then3.i:                                       ; preds = %if.end.i.i.i.i
  %12 = ptrtoint ptr %new_mask.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %new_mask.i, align 4
  %call4.i = call i32 @sched_setaffinity(i32 noundef %pid, ptr noundef %13) #33
  br label %if.end5.i

if.end5.i:                                        ; preds = %if.then3.i, %if.then11.i.i.i.i
  %retval1.0.i = phi i32 [ %call4.i, %if.then3.i ], [ -14, %if.then11.i.i.i.i ]
  %14 = ptrtoint ptr %new_mask.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %new_mask.i, align 4
  call void @free_cpumask_var(ptr noundef %15) #33
  br label %__do_sys_sched_setaffinity.exit

__do_sys_sched_setaffinity.exit:                  ; preds = %if.end5.i, %entry
  %retval.0.i = phi i32 [ %retval1.0.i, %if.end5.i ], [ -12, %entry ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %new_mask.i) #33
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_getaffinity(i32 noundef %pid, ptr noundef %mask) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  %tobool.not.i22 = icmp eq i32 %pid, 0
  br i1 %tobool.not.i22, label %cond.false.i, label %cond.true.i

cond.true.i:                                      ; preds = %rcu_read_lock.exit
  %call.i23 = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit

cond.false.i:                                     ; preds = %rcu_read_lock.exit
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task.i, align 8
  br label %find_process_by_pid.exit

find_process_by_pid.exit:                         ; preds = %cond.false.i, %cond.true.i
  %cond.i = phi ptr [ %call.i23, %cond.true.i ], [ %7, %cond.false.i ]
  %tobool.not = icmp eq ptr %cond.i, null
  br i1 %tobool.not, label %out_unlock, label %if.end

if.end:                                           ; preds = %find_process_by_pid.exit
  %call2 = tail call i32 @security_task_getscheduler(ptr noundef nonnull %cond.i) #33
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %do.body, label %out_unlock

do.body:                                          ; preds = %if.end
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 128
  %call6 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 35
  %call.i.i = tail call i32 @__bitmap_and(ptr noundef %mask, ptr noundef %cpus_mask, ptr noundef nonnull @__cpu_active_mask, i32 noundef %8) #33
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call6) #33
  br label %out_unlock

out_unlock:                                       ; preds = %do.body, %if.end, %find_process_by_pid.exit
  %retval1.0 = phi i32 [ %call2, %if.end ], [ 0, %do.body ], [ -3, %find_process_by_pid.exit ]
  %call.i25 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i25, label %rcu_read_unlock.exit, label %land.lhs.true.i28

land.lhs.true.i28:                                ; preds = %out_unlock
  %call1.i26 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i27 = icmp eq i32 %call1.i26, 0
  br i1 %tobool.not.i27, label %rcu_read_unlock.exit, label %land.lhs.true2.i30

land.lhs.true2.i30:                               ; preds = %land.lhs.true.i28
  %.b4.i29 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i29, label %rcu_read_unlock.exit, label %if.then.i31

if.then.i31:                                      ; preds = %land.lhs.true2.i30
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i31, %land.lhs.true2.i30, %land.lhs.true.i28, %out_unlock
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i32 = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i.i.i32 to ptr
  %preempt_count.i.i.i.i33 = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i.i.i33 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i.i.i33, align 4
  %sub.i.i.i = add i32 %12, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i33, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  ret i32 %retval1.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @security_task_getscheduler(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_getaffinity(i32 noundef %pid, i32 noundef %len, i32 noundef %user_mask_ptr) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %mask.i = alloca ptr, align 4
  %0 = inttoptr i32 %user_mask_ptr to ptr
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %mask.i) #33
  %1 = ptrtoint ptr %mask.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store ptr inttoptr (i32 -1 to ptr), ptr %mask.i, align 4, !annotation !1193
  %mul.i = shl i32 %len, 3
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %2 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.i = icmp uge i32 %mul.i, %2
  %and.i = and i32 %len, 3
  %tobool.not.i = icmp eq i32 %and.i, 0
  %or.cond.i = and i1 %tobool.not.i, %cmp.i
  br i1 %or.cond.i, label %if.end2.i, label %__do_sys_sched_getaffinity.exit

if.end2.i:                                        ; preds = %entry
  %call.i = call zeroext i1 @alloc_cpumask_var(ptr noundef nonnull %mask.i, i32 noundef 3264) #33
  br i1 %call.i, label %if.end4.i, label %__do_sys_sched_getaffinity.exit

if.end4.i:                                        ; preds = %if.end2.i
  %3 = ptrtoint ptr %mask.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %mask.i, align 4
  %call5.i = call i32 @sched_getaffinity(i32 noundef %pid, ptr noundef %4) #33
  %cmp6.i = icmp eq i32 %call5.i, 0
  br i1 %cmp6.i, label %if.then7.i, label %if.end14.i

if.then7.i:                                       ; preds = %if.end4.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %5 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i = add i32 %5, 31
  %6 = lshr i32 %sub.i.i, 3
  %mul.i.i = and i32 %6, 536870908
  %7 = call i32 @llvm.umin.i32(i32 %mul.i.i, i32 %len) #33
  %8 = ptrtoint ptr %mask.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %mask.i, align 4
  call void @__check_object_size(ptr noundef %9, i32 noundef %7, i1 noundef zeroext true) #33
  call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 174) #33
  %call.i.i.i = call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i.i, label %copy_to_user.exit.i, label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %if.then7.i
  %10 = call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr %0, i32 %7, i32 -1226833920) #40, !srcloc !1300
  %asmresult.i.i.i = extractvalue { i32, i32 } %10, 0
  %cmp.i6.i.i = icmp eq i32 %asmresult.i.i.i, 0
  br i1 %cmp.i6.i.i, label %if.then2.i.i.i, label %copy_to_user.exit.i

if.then2.i.i.i:                                   ; preds = %if.end.i.i.i
  %call.i.i.i.i = call zeroext i1 @__kasan_check_read(ptr noundef %9, i32 noundef %7) #33
  %call.i12.i.i.i = call i32 @arm_copy_to_user(ptr noundef %0, ptr noundef %9, i32 noundef %7) #33
  br label %copy_to_user.exit.i

copy_to_user.exit.i:                              ; preds = %if.then2.i.i.i, %if.end.i.i.i, %if.then7.i
  %n.addr.0.i.i = phi i32 [ %7, %if.then7.i ], [ %call.i12.i.i.i, %if.then2.i.i.i ], [ %7, %if.end.i.i.i ]
  %tobool11.not.i = icmp eq i32 %n.addr.0.i.i, 0
  %spec.select.i = select i1 %tobool11.not.i, i32 %7, i32 -14
  br label %if.end14.i

if.end14.i:                                       ; preds = %copy_to_user.exit.i, %if.end4.i
  %ret.1.i = phi i32 [ %call5.i, %if.end4.i ], [ %spec.select.i, %copy_to_user.exit.i ]
  %11 = ptrtoint ptr %mask.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %mask.i, align 4
  call void @free_cpumask_var(ptr noundef %12) #33
  br label %__do_sys_sched_getaffinity.exit

__do_sys_sched_getaffinity.exit:                  ; preds = %if.end14.i, %if.end2.i, %entry
  %retval.0.i = phi i32 [ %ret.1.i, %if.end14.i ], [ -22, %entry ], [ -12, %if.end2.i ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %mask.i) #33
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sys_sched_yield() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @do_sched_yield()
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @do_sched_yield() unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %5 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i15 = and i32 %5, 128
  %tobool.not.i = icmp eq i32 %and.i.i.i15, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool.not.i, label %if.then.i, label %this_rq_lock_irq.exit

if.then.i:                                        ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %this_rq_lock_irq.exit

this_rq_lock_irq.exit:                            ; preds = %if.then.i, %entry
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i to ptr
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx.i, align 4
  %add.i16 = add i32 %11, ptrtoint (ptr @runqueues to i32)
  %12 = inttoptr i32 %add.i16 to ptr
  call fastcc void @rq_lock(ptr noundef %12, ptr noundef nonnull %rf) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@do_sched_yield, %if.then)) #33
          to label %do.end [label %if.then], !srcloc !1202

if.then:                                          ; preds = %this_rq_lock_irq.exit
  %yld_count = getelementptr inbounds %struct.rq, ptr %12, i32 0, i32 70
  %13 = ptrtoint ptr %yld_count to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %yld_count, align 64
  %inc = add i32 %14, 1
  store i32 %inc, ptr %yld_count, align 64
  br label %do.end

do.end:                                           ; preds = %if.then, %this_rq_lock_irq.exit
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 2
  %17 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task, align 8
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %18, i32 0, i32 21
  %19 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %sched_class, align 32
  %yield_task = getelementptr inbounds %struct.sched_class, ptr %20, i32 0, i32 3
  %21 = ptrtoint ptr %yield_task to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %yield_task, align 4
  tail call void %22(ptr noundef %12) #33
  %23 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %26, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1302
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %12, i32 0, i32 81
  %27 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %28, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %do.end
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %12, i32 0, i32 79
  %29 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %do.end
  %retval.0.i.i.i = phi ptr [ %30, %if.then.i.i.i ], [ %12, %do.end ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %31 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %31)
  %.unpack.i.i = load i32, ptr %1, align 4
  %32 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %32) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@do_sched_yield, %land.rhs.i.i.i.i.i)) #33
          to label %rq_unlock_irq.exit [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %33 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %34, 0
  br i1 %tobool3.i.not.i.i.i.i, label %rq_unlock_irq.exit, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %12, i32 0, i32 79
  %35 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %core.i.i.i.i, align 8
  br label %rq_unlock_irq.exit

rq_unlock_irq.exit:                               ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %36, %if.then.i.i.i.i ], [ %12, %land.rhs.i.i.i.i.i ], [ %12, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1303
  %37 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i13 = and i32 %37, -16384
  %38 = inttoptr i32 %and.i.i.i13 to ptr
  %preempt_count.i.i14 = getelementptr inbounds %struct.thread_info, ptr %38, i32 0, i32 1
  %39 = ptrtoint ptr %preempt_count.i.i14 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load volatile i32, ptr %preempt_count.i.i14, align 4
  %sub.i = add i32 %40, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i14, align 4
  tail call void @schedule()
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__cond_resched() #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %cmp.i = icmp eq i32 %3, 0
  br i1 %cmp.i, label %should_resched.exit, label %if.end

should_resched.exit:                              ; preds = %entry
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %5, align 16384
  %8 = and i32 %7, 2
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end, label %do.body.i

do.body.i:                                        ; preds = %do.body.i, %should_resched.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %12, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1304
  tail call fastcc void @__schedule(i32 noundef 1) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1305
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i5.i = and i32 %13, -16384
  %14 = inttoptr i32 %and.i.i.i5.i to ptr
  %preempt_count.i.i6.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 1
  %15 = ptrtoint ptr %preempt_count.i.i6.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %preempt_count.i.i6.i, align 4
  %sub.i.i = add i32 %16, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i6.i, align 4
  %17 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i1 = and i32 %17, -16384
  %18 = inttoptr i32 %and.i.i.i1 to ptr
  %19 = ptrtoint ptr %18 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %18, align 16384
  %21 = and i32 %20, 2
  %tobool.i.not.i = icmp eq i32 %21, 0
  br i1 %tobool.i.not.i, label %return, label %do.body.i

if.end:                                           ; preds = %should_resched.exit, %entry
  tail call void @rcu_all_qs() #33
  br label %return

return:                                           ; preds = %if.end, %do.body.i
  %retval.0 = phi i32 [ 0, %if.end ], [ 1, %do.body.i ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @rcu_all_qs() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__cond_resched_lock(ptr noundef %lock) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %cmp.i = icmp eq i32 %3, 1
  br i1 %cmp.i, label %land.rhs.i, label %should_resched.exit

land.rhs.i:                                       ; preds = %entry
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %5, align 16384
  %8 = and i32 %7, 2
  %tobool.i = icmp ne i32 %8, 0
  br label %should_resched.exit

should_resched.exit:                              ; preds = %land.rhs.i, %entry
  %9 = phi i1 [ false, %entry ], [ %tobool.i, %land.rhs.i ]
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %10 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %10, 0
  br i1 %tobool.not, label %if.end, label %land.rhs

land.rhs:                                         ; preds = %should_resched.exit
  %dep_map = getelementptr inbounds %struct.anon.7, ptr %lock, i32 0, i32 1
  %call.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef -1) #33
  %cmp.not = icmp eq i32 %call.i, 0
  br i1 %cmp.not, label %do.end, label %if.end, !prof !1192

do.end:                                           ; preds = %land.rhs
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 8226, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %land.rhs, %should_resched.exit
  br i1 %9, label %if.then29, label %if.end43

if.then29:                                        ; preds = %if.end
  tail call void @_raw_spin_unlock(ptr noundef %lock) #33
  %11 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %cmp.i.i.i = icmp eq i32 %14, 0
  br i1 %cmp.i.i.i, label %should_resched.exit.i.i, label %do.end37

should_resched.exit.i.i:                          ; preds = %if.then29
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i to ptr
  %17 = ptrtoint ptr %16 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %16, align 16384
  %19 = and i32 %18, 2
  %tobool.i.not.i.i = icmp eq i32 %19, 0
  br i1 %tobool.i.not.i.i, label %do.end37, label %do.body.i.i.i

do.body.i.i.i:                                    ; preds = %do.body.i.i.i, %should_resched.exit.i.i
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %23, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1304
  tail call fastcc void @__schedule(i32 noundef 1) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1305
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i5.i.i.i = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i.i5.i.i.i to ptr
  %preempt_count.i.i6.i.i.i = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 1
  %26 = ptrtoint ptr %preempt_count.i.i6.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %preempt_count.i.i6.i.i.i, align 4
  %sub.i.i.i.i = add i32 %27, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i6.i.i.i, align 4
  %28 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i1.i.i = and i32 %28, -16384
  %29 = inttoptr i32 %and.i.i.i1.i.i to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load volatile i32, ptr %29, align 16384
  %32 = and i32 %31, 2
  %tobool.i.not.i.i.i = icmp eq i32 %32, 0
  br i1 %tobool.i.not.i.i.i, label %if.end42, label %do.body.i.i.i

do.end37:                                         ; preds = %should_resched.exit.i.i, %if.then29
  tail call void @rcu_all_qs() #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1306
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1307
  br label %if.end42

if.end42:                                         ; preds = %do.end37, %do.body.i.i.i
  tail call void @_raw_spin_lock(ptr noundef %lock) #33
  br label %if.end43

if.end43:                                         ; preds = %if.end42, %if.end
  %ret.0 = phi i32 [ 1, %if.end42 ], [ 0, %if.end ]
  ret i32 %ret.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__cond_resched_rwlock_read(ptr noundef %lock) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %cmp.i = icmp eq i32 %3, 1
  br i1 %cmp.i, label %land.rhs.i, label %should_resched.exit

land.rhs.i:                                       ; preds = %entry
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %5, align 16384
  %8 = and i32 %7, 2
  %tobool.i = icmp ne i32 %8, 0
  br label %should_resched.exit

should_resched.exit:                              ; preds = %land.rhs.i, %entry
  %9 = phi i1 [ false, %entry ], [ %tobool.i, %land.rhs.i ]
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %10 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %10, 0
  br i1 %tobool.not, label %if.end, label %land.rhs

land.rhs:                                         ; preds = %should_resched.exit
  %dep_map = getelementptr inbounds %struct.rwlock_t, ptr %lock, i32 0, i32 4
  %call1 = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef 1) #33
  %tobool2.not = icmp eq i32 %call1, 0
  br i1 %tobool2.not, label %do.end, label %if.end, !prof !1192

do.end:                                           ; preds = %land.rhs
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 8244, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %land.rhs, %should_resched.exit
  br i1 %9, label %if.then29, label %if.end43

if.then29:                                        ; preds = %if.end
  tail call void @_raw_read_unlock(ptr noundef %lock) #33
  %11 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %cmp.i.i.i = icmp eq i32 %14, 0
  br i1 %cmp.i.i.i, label %should_resched.exit.i.i, label %do.end37

should_resched.exit.i.i:                          ; preds = %if.then29
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i to ptr
  %17 = ptrtoint ptr %16 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %16, align 16384
  %19 = and i32 %18, 2
  %tobool.i.not.i.i = icmp eq i32 %19, 0
  br i1 %tobool.i.not.i.i, label %do.end37, label %do.body.i.i.i

do.body.i.i.i:                                    ; preds = %do.body.i.i.i, %should_resched.exit.i.i
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %23, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1304
  tail call fastcc void @__schedule(i32 noundef 1) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1305
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i5.i.i.i = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i.i5.i.i.i to ptr
  %preempt_count.i.i6.i.i.i = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 1
  %26 = ptrtoint ptr %preempt_count.i.i6.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %preempt_count.i.i6.i.i.i, align 4
  %sub.i.i.i.i = add i32 %27, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i6.i.i.i, align 4
  %28 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i1.i.i = and i32 %28, -16384
  %29 = inttoptr i32 %and.i.i.i1.i.i to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load volatile i32, ptr %29, align 16384
  %32 = and i32 %31, 2
  %tobool.i.not.i.i.i = icmp eq i32 %32, 0
  br i1 %tobool.i.not.i.i.i, label %if.end42, label %do.body.i.i.i

do.end37:                                         ; preds = %should_resched.exit.i.i, %if.then29
  tail call void @rcu_all_qs() #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1308
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1309
  br label %if.end42

if.end42:                                         ; preds = %do.end37, %do.body.i.i.i
  tail call void @_raw_read_lock(ptr noundef %lock) #33
  br label %if.end43

if.end43:                                         ; preds = %if.end42, %if.end
  %ret.0 = phi i32 [ 1, %if.end42 ], [ 0, %if.end ]
  ret i32 %ret.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @lock_is_held_type(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_read_unlock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_read_lock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__cond_resched_rwlock_write(ptr noundef %lock) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %cmp.i = icmp eq i32 %3, 1
  br i1 %cmp.i, label %land.rhs.i, label %should_resched.exit

land.rhs.i:                                       ; preds = %entry
  %4 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i to ptr
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %5, align 16384
  %8 = and i32 %7, 2
  %tobool.i = icmp ne i32 %8, 0
  br label %should_resched.exit

should_resched.exit:                              ; preds = %land.rhs.i, %entry
  %9 = phi i1 [ false, %entry ], [ %tobool.i, %land.rhs.i ]
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %10 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %10, 0
  br i1 %tobool.not, label %if.end, label %land.rhs

land.rhs:                                         ; preds = %should_resched.exit
  %dep_map = getelementptr inbounds %struct.rwlock_t, ptr %lock, i32 0, i32 4
  %call1 = tail call i32 @lock_is_held_type(ptr noundef %dep_map, i32 noundef 0) #33
  %tobool2.not = icmp eq i32 %call1, 0
  br i1 %tobool2.not, label %do.end, label %if.end, !prof !1192

do.end:                                           ; preds = %land.rhs
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 8262, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %land.rhs, %should_resched.exit
  br i1 %9, label %if.then29, label %if.end43

if.then29:                                        ; preds = %if.end
  tail call void @_raw_write_unlock(ptr noundef %lock) #33
  %11 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %cmp.i.i.i = icmp eq i32 %14, 0
  br i1 %cmp.i.i.i, label %should_resched.exit.i.i, label %do.end37

should_resched.exit.i.i:                          ; preds = %if.then29
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i to ptr
  %17 = ptrtoint ptr %16 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %16, align 16384
  %19 = and i32 %18, 2
  %tobool.i.not.i.i = icmp eq i32 %19, 0
  br i1 %tobool.i.not.i.i, label %do.end37, label %do.body.i.i.i

do.body.i.i.i:                                    ; preds = %do.body.i.i.i, %should_resched.exit.i.i
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %23, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1304
  tail call fastcc void @__schedule(i32 noundef 1) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1305
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i5.i.i.i = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i.i5.i.i.i to ptr
  %preempt_count.i.i6.i.i.i = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 1
  %26 = ptrtoint ptr %preempt_count.i.i6.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load volatile i32, ptr %preempt_count.i.i6.i.i.i, align 4
  %sub.i.i.i.i = add i32 %27, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i6.i.i.i, align 4
  %28 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i1.i.i = and i32 %28, -16384
  %29 = inttoptr i32 %and.i.i.i1.i.i to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load volatile i32, ptr %29, align 16384
  %32 = and i32 %31, 2
  %tobool.i.not.i.i.i = icmp eq i32 %32, 0
  br i1 %tobool.i.not.i.i.i, label %if.end42, label %do.body.i.i.i

do.end37:                                         ; preds = %should_resched.exit.i.i, %if.then29
  tail call void @rcu_all_qs() #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1310
  tail call void asm sideeffect "nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;", ""() #33, !srcloc !1311
  br label %if.end42

if.end42:                                         ; preds = %do.end37, %do.body.i.i.i
  tail call void @_raw_write_lock(ptr noundef %lock) #33
  br label %if.end43

if.end43:                                         ; preds = %if.end42, %if.end
  %ret.0 = phi i32 [ 1, %if.end42 ], [ 0, %if.end ]
  ret i32 %ret.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_write_unlock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_write_lock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @yield() #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  br label %__here

__here:                                           ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 212
  %4 = ptrtoint ptr %task_state_change to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 ptrtoint (ptr blockaddress(@yield, %__here) to i32), ptr %task_state_change, align 4
  %5 = load ptr, ptr %task, align 8
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_store4_noabort(i32 %6)
  store volatile i32 0, ptr %5, align 128
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1312
  tail call fastcc void @do_sched_yield()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @yield_to(ptr noundef %p, i1 noundef zeroext %preempt) #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %4 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %and.i157 = and i32 %4, 128
  %tobool.not = icmp eq i32 %and.i157, 0
  br i1 %tobool.not, label %if.then, label %do.body12

if.then:                                          ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.body12

do.body12:                                        ; preds = %if.then, %entry
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %5 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %6
  %7 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %arrayidx, align 4
  %add = add i32 %8, ptrtoint (ptr @runqueues to i32)
  %9 = inttoptr i32 %add to ptr
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %nr_running = getelementptr inbounds %struct.rq, ptr %9, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %9, i32 0, i32 81
  %core.i.i = getelementptr inbounds %struct.rq, ptr %9, i32 0, i32 79
  br label %again

again:                                            ; preds = %double_rq_unlock.exit, %do.body12
  %10 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 3
  %12 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx26 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %13
  %14 = ptrtoint ptr %arrayidx26 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx26, align 4
  %add27 = add i32 %15, ptrtoint (ptr @runqueues to i32)
  %16 = inttoptr i32 %add27 to ptr
  %17 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %nr_running, align 4
  %cmp28 = icmp eq i32 %18, 1
  br i1 %cmp28, label %land.lhs.true, label %if.end34

land.lhs.true:                                    ; preds = %again
  %nr_running30 = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 1
  %19 = ptrtoint ptr %nr_running30 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %nr_running30, align 4
  %cmp31 = icmp eq i32 %20, 1
  br i1 %cmp31, label %do.body93, label %if.end34

if.end34:                                         ; preds = %land.lhs.true, %again
  tail call void @double_rq_lock(ptr noundef %9, ptr noundef %16)
  %21 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %stack.i, align 4
  %cpu.i159 = getelementptr inbounds %struct.thread_info, ptr %22, i32 0, i32 3
  %23 = ptrtoint ptr %cpu.i159 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %cpu.i159, align 4
  %arrayidx43 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %24
  %25 = ptrtoint ptr %arrayidx43 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %arrayidx43, align 4
  %add44 = add i32 %26, ptrtoint (ptr @runqueues to i32)
  %27 = inttoptr i32 %add44 to ptr
  %cmp45.not = icmp eq ptr %27, %16
  br i1 %cmp45.not, label %if.end48, label %if.then47

if.then47:                                        ; preds = %if.end34
  %28 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %29, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.then47
  %30 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %if.then47
  %retval.0.i.i = phi ptr [ %31, %if.then.i.i ], [ %9, %if.then47 ]
  %core_enabled.i4.i = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 81
  %32 = ptrtoint ptr %core_enabled.i4.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_enabled.i4.i, align 128
  %tobool.not.i5.i = icmp eq i32 %33, 0
  br i1 %tobool.not.i5.i, label %__rq_lockp.exit9.i, label %if.then.i7.i

if.then.i7.i:                                     ; preds = %__rq_lockp.exit.i
  %core.i6.i = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 79
  %34 = ptrtoint ptr %core.i6.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %core.i6.i, align 8
  br label %__rq_lockp.exit9.i

__rq_lockp.exit9.i:                               ; preds = %if.then.i7.i, %__rq_lockp.exit.i
  %retval.0.i8.i = phi ptr [ %35, %if.then.i7.i ], [ %16, %__rq_lockp.exit.i ]
  %cmp.not.i = icmp eq ptr %retval.0.i.i, %retval.0.i8.i
  br i1 %cmp.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %__rq_lockp.exit9.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@yield_to, %land.rhs.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %if.then.i
  %36 = ptrtoint ptr %core_enabled.i4.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %core_enabled.i4.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %37, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 79
  %38 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %core.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i

raw_spin_rq_unlock.exit.i:                        ; preds = %if.then.i.i.i, %land.rhs.i.i.i.i, %if.then.i
  %retval.0.i.i.i = phi ptr [ %39, %if.then.i.i.i ], [ %16, %land.rhs.i.i.i.i ], [ %16, %if.then.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %if.end.i

if.end.i:                                         ; preds = %raw_spin_rq_unlock.exit.i, %__rq_lockp.exit9.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@yield_to, %land.rhs.i.i.i12.i)) #33
          to label %double_rq_unlock.exit [label %land.rhs.i.i.i12.i], !srcloc !1202

land.rhs.i.i.i12.i:                               ; preds = %if.end.i
  %40 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i11.i = icmp eq i32 %41, 0
  br i1 %tobool3.i.not.i.i11.i, label %double_rq_unlock.exit, label %if.then.i.i14.i

if.then.i.i14.i:                                  ; preds = %land.rhs.i.i.i12.i
  %42 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %core.i.i, align 8
  br label %double_rq_unlock.exit

double_rq_unlock.exit:                            ; preds = %if.then.i.i14.i, %land.rhs.i.i.i12.i, %if.end.i
  %retval.0.i.i15.i = phi ptr [ %43, %if.then.i.i14.i ], [ %9, %land.rhs.i.i.i12.i ], [ %9, %if.end.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i15.i) #33
  br label %again

if.end48:                                         ; preds = %if.end34
  %44 = inttoptr i32 %add27 to ptr
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 21
  %45 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %sched_class, align 32
  %yield_to_task = getelementptr inbounds %struct.sched_class, ptr %46, i32 0, i32 4
  %47 = ptrtoint ptr %yield_to_task to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %yield_to_task, align 4
  %tobool49.not = icmp eq ptr %48, null
  br i1 %tobool49.not, label %out_unlock, label %if.end51

if.end51:                                         ; preds = %if.end48
  %sched_class53 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %49 = ptrtoint ptr %sched_class53 to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load ptr, ptr %sched_class53, align 32
  %cmp54.not = icmp eq ptr %46, %50
  br i1 %cmp54.not, label %if.end57, label %out_unlock

if.end57:                                         ; preds = %if.end51
  %on_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %51 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %on_cpu.i, align 4
  %tobool59.not = icmp eq i32 %52, 0
  br i1 %tobool59.not, label %do.end62, label %out_unlock

do.end62:                                         ; preds = %if.end57
  %53 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load volatile i32, ptr %p, align 128
  %cmp64 = icmp eq i32 %54, 0
  br i1 %cmp64, label %if.end67, label %out_unlock

if.end67:                                         ; preds = %do.end62
  %call70 = tail call zeroext i1 %48(ptr noundef %9, ptr noundef %p) #33
  br i1 %call70, label %do.body74, label %out_unlock

do.body74:                                        ; preds = %if.end67
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@yield_to, %if.then81)) #33
          to label %do.end84 [label %if.then81], !srcloc !1202

if.then81:                                        ; preds = %do.body74
  %yld_count = getelementptr inbounds %struct.rq, ptr %9, i32 0, i32 70
  %55 = ptrtoint ptr %yld_count to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %yld_count, align 64
  %inc = add i32 %56, 1
  store i32 %inc, ptr %yld_count, align 64
  br label %do.end84

do.end84:                                         ; preds = %if.then81, %do.body74
  %preempt.not = xor i1 %preempt, true
  %cmp88.not = icmp eq ptr %9, %44
  %or.cond = select i1 %preempt.not, i1 true, i1 %cmp88.not
  br i1 %or.cond, label %out_unlock, label %if.then90

if.then90:                                        ; preds = %do.end84
  tail call void @resched_curr(ptr noundef %44)
  br label %out_unlock

out_unlock:                                       ; preds = %if.then90, %do.end84, %if.end67, %do.end62, %if.end57, %if.end51, %if.end48
  %yielded.0.shrunk = phi i32 [ 0, %if.end51 ], [ 0, %if.end57 ], [ 1, %if.then90 ], [ 1, %do.end84 ], [ 0, %if.end67 ], [ 0, %do.end62 ], [ 0, %if.end48 ]
  %57 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %57)
  %58 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i161 = icmp eq i32 %58, 0
  br i1 %tobool.not.i.i161, label %__rq_lockp.exit.i167, label %if.then.i.i163

if.then.i.i163:                                   ; preds = %out_unlock
  %59 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i167

__rq_lockp.exit.i167:                             ; preds = %if.then.i.i163, %out_unlock
  %retval.0.i.i164 = phi ptr [ %60, %if.then.i.i163 ], [ %9, %out_unlock ]
  %core_enabled.i4.i165 = getelementptr inbounds %struct.rq, ptr %44, i32 0, i32 81
  %61 = ptrtoint ptr %core_enabled.i4.i165 to i32
  call void @__asan_load4_noabort(i32 %61)
  %62 = load i32, ptr %core_enabled.i4.i165, align 128
  %tobool.not.i5.i166 = icmp eq i32 %62, 0
  br i1 %tobool.not.i5.i166, label %__rq_lockp.exit9.i172, label %if.then.i7.i169

if.then.i7.i169:                                  ; preds = %__rq_lockp.exit.i167
  %core.i6.i168 = getelementptr inbounds %struct.rq, ptr %44, i32 0, i32 79
  %63 = ptrtoint ptr %core.i6.i168 to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %core.i6.i168, align 8
  br label %__rq_lockp.exit9.i172

__rq_lockp.exit9.i172:                            ; preds = %if.then.i7.i169, %__rq_lockp.exit.i167
  %retval.0.i8.i170 = phi ptr [ %64, %if.then.i7.i169 ], [ %44, %__rq_lockp.exit.i167 ]
  %cmp.not.i171 = icmp eq ptr %retval.0.i.i164, %retval.0.i8.i170
  br i1 %cmp.not.i171, label %if.end.i180, label %if.then.i173

if.then.i173:                                     ; preds = %__rq_lockp.exit9.i172
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@yield_to, %land.rhs.i.i.i.i175)) #33
          to label %raw_spin_rq_unlock.exit.i179 [label %land.rhs.i.i.i.i175], !srcloc !1202

land.rhs.i.i.i.i175:                              ; preds = %if.then.i173
  %65 = ptrtoint ptr %core_enabled.i4.i165 to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %core_enabled.i4.i165, align 128
  %tobool3.i.not.i.i.i174 = icmp eq i32 %66, 0
  br i1 %tobool3.i.not.i.i.i174, label %raw_spin_rq_unlock.exit.i179, label %if.then.i.i.i177

if.then.i.i.i177:                                 ; preds = %land.rhs.i.i.i.i175
  %core.i.i.i176 = getelementptr inbounds %struct.rq, ptr %44, i32 0, i32 79
  %67 = ptrtoint ptr %core.i.i.i176 to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load ptr, ptr %core.i.i.i176, align 8
  br label %raw_spin_rq_unlock.exit.i179

raw_spin_rq_unlock.exit.i179:                     ; preds = %if.then.i.i.i177, %land.rhs.i.i.i.i175, %if.then.i173
  %retval.0.i.i.i178 = phi ptr [ %68, %if.then.i.i.i177 ], [ %44, %land.rhs.i.i.i.i175 ], [ %44, %if.then.i173 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i178) #33
  br label %if.end.i180

if.end.i180:                                      ; preds = %raw_spin_rq_unlock.exit.i179, %__rq_lockp.exit9.i172
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@yield_to, %land.rhs.i.i.i12.i182)) #33
          to label %double_rq_unlock.exit186 [label %land.rhs.i.i.i12.i182], !srcloc !1202

land.rhs.i.i.i12.i182:                            ; preds = %if.end.i180
  %69 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i11.i181 = icmp eq i32 %70, 0
  br i1 %tobool3.i.not.i.i11.i181, label %double_rq_unlock.exit186, label %if.then.i.i14.i184

if.then.i.i14.i184:                               ; preds = %land.rhs.i.i.i12.i182
  %71 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load ptr, ptr %core.i.i, align 8
  br label %double_rq_unlock.exit186

double_rq_unlock.exit186:                         ; preds = %if.then.i.i14.i184, %land.rhs.i.i.i12.i182, %if.end.i180
  %retval.0.i.i15.i185 = phi ptr [ %72, %if.then.i.i14.i184 ], [ %9, %land.rhs.i.i.i12.i182 ], [ %9, %if.end.i180 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i15.i185) #33
  br label %do.body93

do.body93:                                        ; preds = %double_rq_unlock.exit186, %land.lhs.true
  %yielded.1 = phi i32 [ %yielded.0.shrunk, %double_rq_unlock.exit186 ], [ -3, %land.lhs.true ]
  br i1 %tobool.not, label %if.then102, label %do.body104

if.then102:                                       ; preds = %do.body93
  tail call void @trace_hardirqs_on() #33
  br label %do.body104

do.body104:                                       ; preds = %if.then102, %do.body93
  %73 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i = and i32 %73, 128
  %tobool112.not = icmp eq i32 %and.i.i, 0
  br i1 %tobool112.not, label %if.then121, label %do.end124, !prof !1192

if.then121:                                       ; preds = %do.body104
  tail call void @warn_bogus_irq_restore() #33
  br label %do.end124

do.end124:                                        ; preds = %if.then121, %do.body104
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %4) #33, !srcloc !1218
  %cmp129 = icmp sgt i32 %yielded.1, 0
  br i1 %cmp129, label %if.then131, label %if.end132

if.then131:                                       ; preds = %do.end124
  tail call void @schedule()
  br label %if.end132

if.end132:                                        ; preds = %if.then131, %do.end124
  ret i32 %yielded.1
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @warn_bogus_irq_restore() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @io_schedule_prepare() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %in_iowait = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 65
  %4 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %4)
  %bf.load = load i16, ptr %in_iowait, align 8
  %bf.set = or i16 %bf.load, 8192
  store i16 %bf.set, ptr %in_iowait, align 8
  %5 = load ptr, ptr %task, align 8
  %plug = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 148
  %6 = ptrtoint ptr %plug to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %plug, align 4
  %tobool.not = icmp eq ptr %7, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  tail call void @blk_flush_plug(ptr noundef nonnull %7, i1 noundef zeroext true) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %bf.lshr = lshr i16 %bf.load, 13
  %bf.clear = and i16 %bf.lshr, 1
  %bf.cast = zext i16 %bf.clear to i32
  ret i32 %bf.cast
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @blk_flush_plug(ptr noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: mustprogress nofree nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync)
define dso_local void @io_schedule_finish(i32 noundef %token) local_unnamed_addr #15 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %in_iowait = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 65
  %4 = trunc i32 %token to i16
  %5 = ptrtoint ptr %in_iowait to i32
  call void @__asan_load2_noabort(i32 %5)
  %bf.load = load i16, ptr %in_iowait, align 8
  %bf.value = shl i16 %4, 13
  %bf.shl = and i16 %bf.value, 8192
  %bf.clear = and i16 %bf.load, -8193
  %bf.set = or i16 %bf.clear, %bf.shl
  store i16 %bf.set, ptr %in_iowait, align 8
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @io_schedule_timeout(i32 noundef %timeout) #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  %in_iowait.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 65
  %4 = ptrtoint ptr %in_iowait.i to i32
  call void @__asan_load2_noabort(i32 %4)
  %bf.load.i = load i16, ptr %in_iowait.i, align 8
  %bf.set.i = or i16 %bf.load.i, 8192
  store i16 %bf.set.i, ptr %in_iowait.i, align 8
  %5 = load ptr, ptr %task.i, align 8
  %plug.i = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 148
  %6 = ptrtoint ptr %plug.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %plug.i, align 4
  %tobool.not.i = icmp eq ptr %7, null
  br i1 %tobool.not.i, label %io_schedule_prepare.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  tail call void @blk_flush_plug(ptr noundef nonnull %7, i1 noundef zeroext true) #33
  br label %io_schedule_prepare.exit

io_schedule_prepare.exit:                         ; preds = %if.then.i, %entry
  %bf.clear.i = and i16 %bf.load.i, 8192
  %call1 = tail call i32 @schedule_timeout(i32 noundef %timeout) #33
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i2 = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i2 to ptr
  %task.i3 = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 2
  %10 = ptrtoint ptr %task.i3 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %task.i3, align 8
  %in_iowait.i4 = getelementptr inbounds %struct.task_struct, ptr %11, i32 0, i32 65
  %12 = ptrtoint ptr %in_iowait.i4 to i32
  call void @__asan_load2_noabort(i32 %12)
  %bf.load.i5 = load i16, ptr %in_iowait.i4, align 8
  %bf.clear.i6 = and i16 %bf.load.i5, -8193
  %bf.set.i7 = or i16 %bf.clear.i6, %bf.clear.i
  store i16 %bf.set.i7, ptr %in_iowait.i4, align 8
  ret i32 %call1
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @schedule_timeout(i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @io_schedule() #0 section ".sched.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  %in_iowait.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 65
  %4 = ptrtoint ptr %in_iowait.i to i32
  call void @__asan_load2_noabort(i32 %4)
  %bf.load.i = load i16, ptr %in_iowait.i, align 8
  %bf.set.i = or i16 %bf.load.i, 8192
  store i16 %bf.set.i, ptr %in_iowait.i, align 8
  %5 = load ptr, ptr %task.i, align 8
  %plug.i = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 148
  %6 = ptrtoint ptr %plug.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %plug.i, align 4
  %tobool.not.i = icmp eq ptr %7, null
  br i1 %tobool.not.i, label %io_schedule_prepare.exit, label %if.then.i

if.then.i:                                        ; preds = %entry
  tail call void @blk_flush_plug(ptr noundef nonnull %7, i1 noundef zeroext true) #33
  br label %io_schedule_prepare.exit

io_schedule_prepare.exit:                         ; preds = %if.then.i, %entry
  %bf.clear.i = and i16 %bf.load.i, 8192
  tail call void @schedule()
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i1 = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i1 to ptr
  %task.i2 = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 2
  %10 = ptrtoint ptr %task.i2 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %task.i2, align 8
  %in_iowait.i3 = getelementptr inbounds %struct.task_struct, ptr %11, i32 0, i32 65
  %12 = ptrtoint ptr %in_iowait.i3 to i32
  call void @__asan_load2_noabort(i32 %12)
  %bf.load.i4 = load i16, ptr %in_iowait.i3, align 8
  %bf.clear.i5 = and i16 %bf.load.i4, -8193
  %bf.set.i6 = or i16 %bf.clear.i5, %bf.clear.i
  store i16 %bf.set.i6, ptr %in_iowait.i3, align 8
  ret void
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readnone sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @__se_sys_sched_get_priority_max(i32 noundef %policy) #6 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = icmp ult i32 %policy, 7
  br i1 %0, label %switch.lookup, label %__do_sys_sched_get_priority_max.exit

switch.lookup:                                    ; preds = %entry
  %switch.gep = getelementptr inbounds [7 x i32], ptr @switch.table.__se_sys_sched_get_priority_max, i32 0, i32 %policy
  %1 = ptrtoint ptr %switch.gep to i32
  call void @__asan_load4_noabort(i32 %1)
  %switch.load = load i32, ptr %switch.gep, align 4
  br label %__do_sys_sched_get_priority_max.exit

__do_sys_sched_get_priority_max.exit:             ; preds = %switch.lookup, %entry
  %ret.0.i = phi i32 [ -22, %entry ], [ %switch.load, %switch.lookup ]
  ret i32 %ret.0.i
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readnone sanitize_address sspstrong willreturn uwtable(sync)
define dso_local i32 @__se_sys_sched_get_priority_min(i32 noundef %policy) #6 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = icmp ult i32 %policy, 7
  br i1 %0, label %switch.lookup, label %__do_sys_sched_get_priority_min.exit

switch.lookup:                                    ; preds = %entry
  %switch.gep = getelementptr inbounds [7 x i32], ptr @switch.table.__se_sys_sched_get_priority_min, i32 0, i32 %policy
  %1 = ptrtoint ptr %switch.gep to i32
  call void @__asan_load4_noabort(i32 %1)
  %switch.load = load i32, ptr %switch.gep, align 4
  br label %__do_sys_sched_get_priority_min.exit

__do_sys_sched_get_priority_min.exit:             ; preds = %switch.lookup, %entry
  %ret.0.i = phi i32 [ -22, %entry ], [ %switch.load, %switch.lookup ]
  ret i32 %ret.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_rr_get_interval(i32 noundef %pid, i32 noundef %interval) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %t.i = alloca %struct.timespec64, align 8
  call void @llvm.lifetime.start.p0(i64 16, ptr nonnull %t.i) #33
  %0 = call ptr @memset(ptr %t.i, i32 255, i32 16)
  %call.i = call fastcc i32 @sched_rr_get_interval(i32 noundef %pid, ptr noundef nonnull %t.i) #33
  %cmp.i = icmp eq i32 %call.i, 0
  br i1 %cmp.i, label %if.then.i, label %__do_sys_sched_rr_get_interval.exit

if.then.i:                                        ; preds = %entry
  %1 = inttoptr i32 %interval to ptr
  %call2.i = call i32 @put_timespec64(ptr noundef nonnull %t.i, ptr noundef %1) #33
  br label %__do_sys_sched_rr_get_interval.exit

__do_sys_sched_rr_get_interval.exit:              ; preds = %if.then.i, %entry
  %retval1.0.i = phi i32 [ %call2.i, %if.then.i ], [ %call.i, %entry ]
  call void @llvm.lifetime.end.p0(i64 16, ptr nonnull %t.i) #33
  ret i32 %retval1.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @__se_sys_sched_rr_get_interval_time32(i32 noundef %pid, i32 noundef %interval) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %t.i = alloca %struct.timespec64, align 8
  call void @llvm.lifetime.start.p0(i64 16, ptr nonnull %t.i) #33
  %0 = call ptr @memset(ptr %t.i, i32 255, i32 16)
  %call.i = call fastcc i32 @sched_rr_get_interval(i32 noundef %pid, ptr noundef nonnull %t.i) #33
  %cmp.i = icmp eq i32 %call.i, 0
  br i1 %cmp.i, label %if.then.i, label %__do_sys_sched_rr_get_interval_time32.exit

if.then.i:                                        ; preds = %entry
  %1 = inttoptr i32 %interval to ptr
  %call2.i = call i32 @put_old_timespec32(ptr noundef nonnull %t.i, ptr noundef %1) #33
  br label %__do_sys_sched_rr_get_interval_time32.exit

__do_sys_sched_rr_get_interval_time32.exit:       ; preds = %if.then.i, %entry
  %retval1.0.i = phi i32 [ %call2.i, %if.then.i ], [ %call.i, %entry ]
  call void @llvm.lifetime.end.p0(i64 16, ptr nonnull %t.i) #33
  ret i32 %retval1.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_show_task(ptr noundef %p) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %0 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %stack.i, align 4
  %tobool.not = icmp eq ptr %1, null
  br i1 %tobool.not, label %cleanup, label %do.end

do.end:                                           ; preds = %entry
  %comm = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %2 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %p, align 128
  %exit_state.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 57
  %4 = ptrtoint ptr %exit_state.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %exit_state.i.i, align 4
  %or.i.i = or i32 %5, %3
  %and.i.i = and i32 %or.i.i, 127
  %cmp.i.i = icmp eq i32 %3, 1026
  %spec.store.select.i.i = select i1 %cmp.i.i, i32 128, i32 %and.i.i
  %tobool.not.i.i.i = icmp eq i32 %spec.store.select.i.i, 0
  %6 = tail call i32 @llvm.ctlz.i32(i32 %spec.store.select.i.i, i1 true) #33, !range !1195
  %sub.i.i.i = sub nuw nsw i32 32, %6
  %cond.i.i.i = select i1 %tobool.not.i.i.i, i32 0, i32 %sub.i.i.i
  %arrayidx.i.i = getelementptr [10 x i8], ptr @task_index_to_char.state_char, i32 0, i32 %cond.i.i.i
  %7 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load1_noabort(i32 %7)
  %8 = load i8, ptr %arrayidx.i.i, align 1
  %conv = zext i8 %8 to i32
  %call2 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.56, ptr noundef %comm, i32 noundef %conv) #39
  %9 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %p, align 128
  %cmp = icmp eq i32 %10, 0
  br i1 %cmp, label %do.end11, label %if.end14

do.end11:                                         ; preds = %do.end
  %call13 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.59) #39
  br label %if.end14

if.end14:                                         ; preds = %do.end11, %do.end
  %11 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %stack.i, align 4
  %add.ptr.i.i = getelementptr %struct.thread_info, ptr %12, i32 1
  br label %do.body.i

do.body.i:                                        ; preds = %do.body.i, %if.end14
  %n.0.i = phi ptr [ %add.ptr.i.i, %if.end14 ], [ %incdec.ptr.i, %do.body.i ]
  %incdec.ptr.i = getelementptr i32, ptr %n.0.i, i32 1
  %13 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %incdec.ptr.i, align 4
  %tobool.not.i58 = icmp eq i32 %14, 0
  br i1 %tobool.not.i58, label %do.body.i, label %stack_not_used.exit

stack_not_used.exit:                              ; preds = %do.body.i
  %15 = ptrtoint ptr %incdec.ptr.i to i32
  %16 = ptrtoint ptr %add.ptr.i.i to i32
  %sub.i = sub i32 %15, %16
  %17 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %17, -16384
  %18 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %18, i32 0, i32 1
  %19 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %20, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %stack_not_used.exit
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %stack_not_used.exit
  %thread_pid.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 78
  %21 = ptrtoint ptr %thread_pid.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %thread_pid.i, align 16
  %cmp.i.not = icmp eq ptr %22, null
  br i1 %cmp.i.not, label %if.end36, label %if.then18

if.then18:                                        ; preds = %rcu_read_lock.exit
  %real_parent = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 71
  %23 = ptrtoint ptr %real_parent to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile ptr, ptr %real_parent, align 4
  %call24 = tail call i32 @rcu_read_lock_held() #33
  %tobool25.not = icmp eq i32 %call24, 0
  br i1 %tobool25.not, label %land.lhs.true, label %do.end33

land.lhs.true:                                    ; preds = %if.then18
  %call26 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool27.not = icmp eq i32 %call26, 0
  br i1 %tobool27.not, label %do.end33, label %land.lhs.true28

land.lhs.true28:                                  ; preds = %land.lhs.true
  %.b57 = load i1, ptr @sched_show_task.__warned, align 1
  br i1 %.b57, label %do.end33, label %if.then30

if.then30:                                        ; preds = %land.lhs.true28
  store i1 true, ptr @sched_show_task.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 8564, ptr noundef nonnull @.str.3) #33
  br label %do.end33

do.end33:                                         ; preds = %if.then30, %land.lhs.true28, %land.lhs.true, %if.then18
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %24, i32 0, i32 68
  %25 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %pid.i, align 8
  br label %if.end36

if.end36:                                         ; preds = %do.end33, %rcu_read_lock.exit
  %ppid.0 = phi i32 [ %26, %do.end33 ], [ 0, %rcu_read_lock.exit ]
  %call.i59 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i59, label %rcu_read_unlock.exit, label %land.lhs.true.i62

land.lhs.true.i62:                                ; preds = %if.end36
  %call1.i60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i61 = icmp eq i32 %call1.i60, 0
  br i1 %tobool.not.i61, label %rcu_read_unlock.exit, label %land.lhs.true2.i64

land.lhs.true2.i64:                               ; preds = %land.lhs.true.i62
  %.b4.i63 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i63, label %rcu_read_unlock.exit, label %if.then.i65

if.then.i65:                                      ; preds = %land.lhs.true2.i64
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i65, %land.lhs.true2.i64, %land.lhs.true.i62, %if.end36
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %27 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i66 = and i32 %27, -16384
  %28 = inttoptr i32 %and.i.i.i.i.i66 to ptr
  %preempt_count.i.i.i.i67 = getelementptr inbounds %struct.thread_info, ptr %28, i32 0, i32 1
  %29 = ptrtoint ptr %preempt_count.i.i.i.i67 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %preempt_count.i.i.i.i67, align 4
  %sub.i.i.i68 = add i32 %30, -1
  store volatile i32 %sub.i.i.i68, ptr %preempt_count.i.i.i.i67, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %pid.i69 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %31 = ptrtoint ptr %pid.i69 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %pid.i69, align 8
  %33 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %stack.i, align 4
  %35 = ptrtoint ptr %34 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %34, align 8
  %call43 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.62, i32 noundef %sub.i, i32 noundef %32, i32 noundef %ppid.0, i32 noundef %36) #39
  tail call void @print_worker_info(ptr noundef nonnull @.str.64, ptr noundef %p) #33
  tail call void @print_stop_info(ptr noundef nonnull @.str.64, ptr noundef %p) #33
  tail call void @show_stack(ptr noundef %p, ptr noundef null, ptr noundef nonnull @.str.64) #33
  br label %cleanup

cleanup:                                          ; preds = %rcu_read_unlock.exit, %entry
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @print_worker_info(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @print_stop_info(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @show_stack(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @show_state_filter(i32 noundef %state_filter) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50) to i32))
  %4 = load volatile ptr, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50), align 16
  %add.ptr79 = getelementptr i8, ptr %4, i32 -1136
  %cmp.not80 = icmp eq ptr %add.ptr79, @init_task
  br i1 %cmp.not80, label %for.end34, label %do.body2.lr.ph

do.body2.lr.ph:                                   ; preds = %rcu_read_lock.exit
  %tobool.not.i49 = icmp eq i32 %state_filter, 0
  %cmp.i = icmp ne i32 %state_filter, 2
  br label %do.body2

for.cond.loopexit:                                ; preds = %for.inc, %do.end8
  %5 = ptrtoint ptr %7 to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile ptr, ptr %7, align 16
  %add.ptr = getelementptr i8, ptr %6, i32 -1136
  %cmp.not = icmp eq ptr %add.ptr, @init_task
  br i1 %cmp.not, label %for.end34, label %do.body2

do.body2:                                         ; preds = %for.cond.loopexit, %do.body2.lr.ph
  %7 = phi ptr [ %4, %do.body2.lr.ph ], [ %6, %for.cond.loopexit ]
  %call = tail call i32 @rcu_read_lock_any_held() #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %land.lhs.true, label %do.end8

land.lhs.true:                                    ; preds = %do.body2
  %call3 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool4.not = icmp eq i32 %call3, 0
  br i1 %tobool4.not, label %do.end8, label %land.lhs.true5

land.lhs.true5:                                   ; preds = %land.lhs.true
  %.b48 = load i1, ptr @show_state_filter.__warned, align 1
  br i1 %.b48, label %do.end8, label %if.then

if.then:                                          ; preds = %land.lhs.true5
  store i1 true, ptr @show_state_filter.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 8606, ptr noundef nonnull @.str.4) #33
  br label %do.end8

do.end8:                                          ; preds = %if.then, %land.lhs.true5, %land.lhs.true, %do.body2
  %signal = getelementptr i8, ptr %7, i32 544
  %8 = ptrtoint ptr %signal to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %signal, align 16
  %thread_head = getelementptr inbounds %struct.signal_struct, ptr %9, i32 0, i32 3
  %10 = ptrtoint ptr %thread_head to i32
  call void @__asan_load4_noabort(i32 %10)
  %.pn73 = load volatile ptr, ptr %thread_head, align 4
  %cmp20.not76 = icmp eq ptr %.pn73, %thread_head
  br i1 %cmp20.not76, label %for.cond.loopexit, label %for.body21

for.body21:                                       ; preds = %for.inc, %do.end8
  %.pn77 = phi ptr [ %.pn, %for.inc ], [ %.pn73, %do.end8 ]
  %p.078 = getelementptr i8, ptr %.pn77, i32 -1404
  tail call void @touch_softlockup_watchdog() #33
  tail call void @touch_all_softlockup_watchdogs() #33
  %11 = ptrtoint ptr %p.078 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %p.078, align 128
  br i1 %tobool.not.i49, label %if.then23, label %if.end.i

if.end.i:                                         ; preds = %for.body21
  %and.i = and i32 %12, %state_filter
  %tobool1.not.i = icmp ne i32 %and.i, 0
  %cmp4.i = icmp ne i32 %12, 1026
  %or.cond.i = select i1 %cmp.i, i1 true, i1 %cmp4.i
  %or.cond = and i1 %tobool1.not.i, %or.cond.i
  br i1 %or.cond, label %if.then23, label %for.inc

if.then23:                                        ; preds = %if.end.i, %for.body21
  tail call void @sched_show_task(ptr noundef %p.078)
  br label %for.inc

for.inc:                                          ; preds = %if.then23, %if.end.i
  %13 = ptrtoint ptr %.pn77 to i32
  call void @__asan_load4_noabort(i32 %13)
  %.pn = load volatile ptr, ptr %.pn77, align 4
  %14 = ptrtoint ptr %signal to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %signal, align 16
  %thread_head19 = getelementptr inbounds %struct.signal_struct, ptr %15, i32 0, i32 3
  %cmp20.not = icmp eq ptr %.pn, %thread_head19
  br i1 %cmp20.not, label %for.cond.loopexit, label %for.body21

for.end34:                                        ; preds = %for.cond.loopexit, %rcu_read_lock.exit
  %tobool35.not = icmp eq i32 %state_filter, 0
  br i1 %tobool35.not, label %if.then36, label %if.end40.critedge

if.then36:                                        ; preds = %for.end34
  tail call void @sysrq_sched_debug_show() #33
  %call.i50 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i50, label %rcu_read_unlock.exit, label %land.lhs.true.i53

land.lhs.true.i53:                                ; preds = %if.then36
  %call1.i51 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i52 = icmp eq i32 %call1.i51, 0
  br i1 %tobool.not.i52, label %rcu_read_unlock.exit, label %land.lhs.true2.i55

land.lhs.true2.i55:                               ; preds = %land.lhs.true.i53
  %.b4.i54 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i54, label %rcu_read_unlock.exit, label %if.then.i56

if.then.i56:                                      ; preds = %land.lhs.true2.i55
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i56, %land.lhs.true2.i55, %land.lhs.true.i53, %if.then36
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %16 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i57 = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i.i.i57 to ptr
  %preempt_count.i.i.i.i58 = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i.i.i58 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i.i.i58, align 4
  %sub.i.i.i = add i32 %19, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i58, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  tail call void @debug_show_all_locks() #33
  br label %if.end40

if.end40.critedge:                                ; preds = %for.end34
  %call.i59 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i59, label %rcu_read_unlock.exit69, label %land.lhs.true.i62

land.lhs.true.i62:                                ; preds = %if.end40.critedge
  %call1.i60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i61 = icmp eq i32 %call1.i60, 0
  br i1 %tobool.not.i61, label %rcu_read_unlock.exit69, label %land.lhs.true2.i64

land.lhs.true2.i64:                               ; preds = %land.lhs.true.i62
  %.b4.i63 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i63, label %rcu_read_unlock.exit69, label %if.then.i65

if.then.i65:                                      ; preds = %land.lhs.true2.i64
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit69

rcu_read_unlock.exit69:                           ; preds = %if.then.i65, %land.lhs.true2.i64, %land.lhs.true.i62, %if.end40.critedge
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i66 = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i66 to ptr
  %preempt_count.i.i.i.i67 = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i67 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i67, align 4
  %sub.i.i.i68 = add i32 %23, -1
  store volatile i32 %sub.i.i.i68, ptr %preempt_count.i.i.i.i67, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %if.end40

if.end40:                                         ; preds = %rcu_read_unlock.exit69, %rcu_read_unlock.exit
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @touch_all_softlockup_watchdogs() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @sysrq_sched_debug_show() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @debug_show_all_locks() local_unnamed_addr #2

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define dso_local void @init_idle(ptr noundef %idle, i32 noundef %cpu) local_unnamed_addr #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 12
  %3 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 0, ptr %on_rq.i, align 4
  %on_rq1.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 3
  %group_node.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 2
  %4 = call ptr @memset(ptr %on_rq1.i, i32 0, i32 44)
  %5 = ptrtoint ptr %group_node.i to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile ptr %group_node.i, ptr %group_node.i, align 4
  %prev.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 2, i32 1
  %6 = ptrtoint ptr %prev.i.i to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr %group_node.i, ptr %prev.i.i, align 4
  %cfs_rq.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 11
  %7 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store ptr null, ptr %cfs_rq.i, align 16
  %stats.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 29
  %8 = call ptr @memset(ptr %stats.i, i32 0, i32 256)
  %dl.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 20
  %9 = ptrtoint ptr %dl.i to i32
  %10 = ptrtoint ptr %dl.i to i32
  call void @__asan_store4_noabort(i32 %10)
  store i32 %9, ptr %dl.i, align 8
  tail call void @init_dl_task_timer(ptr noundef %dl.i) #33
  tail call void @init_dl_inactive_task_timer(ptr noundef %dl.i) #33
  tail call void @__dl_clear_params(ptr noundef %idle) #33
  %rt.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19
  %11 = ptrtoint ptr %rt.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store volatile ptr %rt.i, ptr %rt.i, align 4
  %prev.i1.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 0, i32 1
  %12 = ptrtoint ptr %prev.i1.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store ptr %rt.i, ptr %prev.i1.i, align 4
  %timeout.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 1
  %13 = ptrtoint ptr %timeout.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store i32 0, ptr %timeout.i, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sched_rr_timeslice to i32))
  %14 = load i32, ptr @sched_rr_timeslice, align 4
  %time_slice.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 3
  %15 = ptrtoint ptr %time_slice.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 %14, ptr %time_slice.i, align 16
  %on_rq16.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 4
  %16 = ptrtoint ptr %on_rq16.i to i32
  call void @__asan_store2_noabort(i32 %16)
  store i16 0, ptr %on_rq16.i, align 4
  %on_list.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 5
  %17 = ptrtoint ptr %on_list.i to i32
  call void @__asan_store2_noabort(i32 %17)
  store i16 0, ptr %on_list.i, align 2
  %capture_control.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 152
  %18 = ptrtoint ptr %capture_control.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store ptr null, ptr %capture_control.i, align 4
  %19 = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 6, i32 1
  %20 = ptrtoint ptr %19 to i32
  call void @__asan_store4_noabort(i32 %20)
  store i32 48, ptr %19, align 4
  %migration_pending.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 36
  %21 = ptrtoint ptr %migration_pending.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store ptr null, ptr %migration_pending.i, align 8
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 128
  %call = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %pi_lock) #33
  %22 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i85 = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i.i.i.i85 to ptr
  %preempt_count.i.i.i.i86 = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i.i.i.i86 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i.i.i.i86, align 4
  %add.i.i.i87 = add i32 %25, 1
  store volatile i32 %add.i.i.i87, ptr %preempt_count.i.i.i.i86, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@init_idle, %for.cond.i.i)) #33
          to label %if.then.i.i [label %for.cond.i.i], !srcloc !1202

if.then.i.i:                                      ; preds = %entry
  tail call void @_raw_spin_lock_nested(ptr noundef %2, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock.exit

for.cond.i.i:                                     ; preds = %if.end11.i.i, %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %26 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %27, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %for.cond.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %28 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %for.cond.i.i
  %retval.0.i.i.i = phi ptr [ %29, %if.then.i.i.i ], [ %2, %for.cond.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i, i32 noundef 0) #33
  %30 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i23.i.i = icmp eq i32 %31, 0
  br i1 %tobool.not.i23.i.i, label %__rq_lockp.exit27.i.i, label %if.then.i25.i.i

if.then.i25.i.i:                                  ; preds = %__rq_lockp.exit.i.i
  %core.i24.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %32 = ptrtoint ptr %core.i24.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %core.i24.i.i, align 8
  br label %__rq_lockp.exit27.i.i

__rq_lockp.exit27.i.i:                            ; preds = %if.then.i25.i.i, %__rq_lockp.exit.i.i
  %retval.0.i26.i.i = phi ptr [ %33, %if.then.i25.i.i ], [ %2, %__rq_lockp.exit.i.i ]
  %cmp.i.i = icmp eq ptr %retval.0.i.i.i, %retval.0.i26.i.i
  br i1 %cmp.i.i, label %do.body8.i.i, label %if.end11.i.i, !prof !1191

do.body8.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock.exit

if.end11.i.i:                                     ; preds = %__rq_lockp.exit27.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  br label %for.cond.i.i

raw_spin_rq_lock.exit:                            ; preds = %do.body8.i.i, %if.then.i.i
  %34 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i.i19.i.i to ptr
  %preempt_count.i.i20.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 1
  %36 = ptrtoint ptr %preempt_count.i.i20.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %preempt_count.i.i20.i.i, align 4
  %sub.i21.i.i = add i32 %37, -1
  store volatile i32 %sub.i21.i.i, ptr %preempt_count.i.i20.i.i, align 4
  %38 = ptrtoint ptr %idle to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 0, ptr %idle, align 128
  %call6 = tail call i64 @sched_clock() #33
  %exec_start = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 4
  %39 = ptrtoint ptr %exec_start to i32
  call void @__asan_store8_noabort(i32 %39)
  store i64 %call6, ptr %exec_start, align 32
  %flags7 = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 3
  %40 = ptrtoint ptr %flags7 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %flags7, align 4
  %or = or i32 %41, 69206018
  store i32 %or, ptr %flags7, align 4
  tail call void @kthread_set_per_cpu(ptr noundef %idle, i32 noundef %cpu) #33
  %rem.i = and i32 %cpu, 31
  %add.i = add nuw nsw i32 %rem.i, 1
  %arrayidx.i = getelementptr [33 x [1 x i32]], ptr @cpu_bit_bitmap, i32 0, i32 %add.i
  %div3.i = lshr i32 %cpu, 5
  %idx.neg.i = sub nsw i32 0, %div3.i
  %add.ptr.i = getelementptr i32, ptr %arrayidx.i, i32 %idx.neg.i
  %cpus_mask.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %42 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i.i = add i32 %42, 31
  %43 = lshr i32 %sub.i.i.i, 3
  %mul.i.i.i = and i32 %43, 536870908
  %44 = call ptr @memcpy(ptr %cpus_mask.i, ptr %add.ptr.i, i32 %mul.i.i.i)
  %call4.i.i.i = tail call i32 @__bitmap_weight(ptr noundef %add.ptr.i, i32 noundef %42) #33
  %nr_cpus_allowed.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 32
  %45 = ptrtoint ptr %nr_cpus_allowed.i to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 %call4.i.i.i, ptr %nr_cpus_allowed.i, align 8
  %46 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %46, -16384
  %47 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %47, i32 0, i32 1
  %48 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %49, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %raw_spin_rq_lock.exit
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %raw_spin_rq_lock.exit
  %sched_task_group.i.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 25
  %50 = ptrtoint ptr %sched_task_group.i.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %sched_task_group.i.i.i, align 8
  %se.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18
  %52 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %cfs_rq.i, align 16
  %cfs_rq2.i.i = getelementptr inbounds %struct.task_group, ptr %51, i32 0, i32 2
  %54 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx.i.i = getelementptr ptr, ptr %55, i32 %cpu
  %56 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %arrayidx.i.i, align 4
  tail call void @set_task_rq_fair(ptr noundef %se.i.i, ptr noundef %53, ptr noundef %57) #33
  %58 = ptrtoint ptr %cfs_rq2.i.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %cfs_rq2.i.i, align 4
  %arrayidx4.i.i = getelementptr ptr, ptr %59, i32 %cpu
  %60 = ptrtoint ptr %arrayidx4.i.i to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load ptr, ptr %arrayidx4.i.i, align 4
  %62 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_store4_noabort(i32 %62)
  store ptr %61, ptr %cfs_rq.i, align 16
  %se7.i.i = getelementptr inbounds %struct.task_group, ptr %51, i32 0, i32 1
  %63 = ptrtoint ptr %se7.i.i to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load ptr, ptr %se7.i.i, align 8
  %arrayidx8.i.i = getelementptr ptr, ptr %64, i32 %cpu
  %65 = ptrtoint ptr %arrayidx8.i.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %arrayidx8.i.i, align 4
  %parent.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 18, i32 10
  %67 = ptrtoint ptr %parent.i.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store ptr %66, ptr %parent.i.i, align 4
  %rt_rq.i.i = getelementptr inbounds %struct.task_group, ptr %51, i32 0, i32 8
  %68 = ptrtoint ptr %rt_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load ptr, ptr %rt_rq.i.i, align 8
  %arrayidx10.i.i = getelementptr ptr, ptr %69, i32 %cpu
  %70 = ptrtoint ptr %arrayidx10.i.i to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load ptr, ptr %arrayidx10.i.i, align 4
  %rt_rq11.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 8
  %72 = ptrtoint ptr %rt_rq11.i.i to i32
  call void @__asan_store4_noabort(i32 %72)
  store ptr %71, ptr %rt_rq11.i.i, align 32
  %rt_se.i.i = getelementptr inbounds %struct.task_group, ptr %51, i32 0, i32 7
  %73 = ptrtoint ptr %rt_se.i.i to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load ptr, ptr %rt_se.i.i, align 4
  %arrayidx12.i.i = getelementptr ptr, ptr %74, i32 %cpu
  %75 = ptrtoint ptr %arrayidx12.i.i to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load ptr, ptr %arrayidx12.i.i, align 4
  %parent14.i.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 19, i32 7
  %77 = ptrtoint ptr %parent14.i.i to i32
  call void @__asan_store4_noabort(i32 %77)
  store ptr %76, ptr %parent14.i.i, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1238
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 1
  %78 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load ptr, ptr %stack.i, align 4
  %cpu7.i = getelementptr inbounds %struct.thread_info, ptr %79, i32 0, i32 3
  %80 = ptrtoint ptr %cpu7.i to i32
  call void @__asan_store4_noabort(i32 %80)
  store volatile i32 %cpu, ptr %cpu7.i, align 4
  %wake_cpu.i = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 11
  %81 = ptrtoint ptr %wake_cpu.i to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 %cpu, ptr %wake_cpu.i, align 16
  %call.i90 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i90, label %rcu_read_unlock.exit, label %land.lhs.true.i93

land.lhs.true.i93:                                ; preds = %rcu_read_lock.exit
  %call1.i91 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i92 = icmp eq i32 %call1.i91, 0
  br i1 %tobool.not.i92, label %rcu_read_unlock.exit, label %land.lhs.true2.i95

land.lhs.true2.i95:                               ; preds = %land.lhs.true.i93
  %.b4.i94 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i94, label %rcu_read_unlock.exit, label %if.then.i96

if.then.i96:                                      ; preds = %land.lhs.true2.i95
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i96, %land.lhs.true2.i95, %land.lhs.true.i93, %rcu_read_lock.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %82 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i97 = and i32 %82, -16384
  %83 = inttoptr i32 %and.i.i.i.i.i97 to ptr
  %preempt_count.i.i.i.i98 = getelementptr inbounds %struct.thread_info, ptr %83, i32 0, i32 1
  %84 = ptrtoint ptr %preempt_count.i.i.i.i98 to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load volatile i32, ptr %preempt_count.i.i.i.i98, align 4
  %sub.i.i.i99 = add i32 %85, -1
  store volatile i32 %sub.i.i.i99, ptr %preempt_count.i.i.i.i98, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %idle9 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 21
  %86 = ptrtoint ptr %idle9 to i32
  call void @__asan_store4_noabort(i32 %86)
  store ptr %idle, ptr %idle9, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1313
  %curr35 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %87 = ptrtoint ptr %curr35 to i32
  call void @__asan_store4_noabort(i32 %87)
  store volatile ptr %idle, ptr %curr35, align 8
  %88 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %88)
  store i32 1, ptr %on_rq.i, align 4
  %on_cpu = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 5
  %89 = ptrtoint ptr %on_cpu to i32
  call void @__asan_store4_noabort(i32 %89)
  store i32 1, ptr %on_cpu, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@init_idle, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %rcu_read_unlock.exit
  %core_enabled.i.i.i100 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %90 = ptrtoint ptr %core_enabled.i.i.i100 to i32
  call void @__asan_load4_noabort(i32 %90)
  %91 = load i32, ptr %core_enabled.i.i.i100, align 128
  %tobool3.i.not.i.i = icmp eq i32 %91, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i101

if.then.i.i101:                                   ; preds = %land.rhs.i.i.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %92 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load ptr, ptr %core.i.i, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i101, %land.rhs.i.i.i, %rcu_read_unlock.exit
  %retval.0.i.i = phi ptr [ %93, %if.then.i.i101 ], [ %2, %land.rhs.i.i.i ], [ %2, %rcu_read_unlock.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i) #33
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock, i32 noundef %call) #33
  %94 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %stack.i, align 4
  %preempt_count = getelementptr inbounds %struct.thread_info, ptr %95, i32 0, i32 1
  %96 = ptrtoint ptr %preempt_count to i32
  call void @__asan_store4_noabort(i32 %96)
  store i32 1, ptr %preempt_count, align 4
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 21
  %97 = ptrtoint ptr %sched_class to i32
  call void @__asan_store4_noabort(i32 %97)
  store ptr @idle_sched_class, ptr %sched_class, align 32
  %comm = getelementptr inbounds %struct.task_struct, ptr %idle, i32 0, i32 101
  %call58 = tail call i32 (ptr, ptr, ...) @sprintf(ptr noundef %comm, ptr noundef nonnull @.str.65, ptr noundef nonnull @.str.66, i32 noundef %cpu)
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i64 @sched_clock() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @kthread_set_per_cpu(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nofree nounwind null_pointer_is_valid
declare dso_local noundef i32 @sprintf(ptr noalias nocapture noundef writeonly, ptr nocapture noundef readonly, ...) local_unnamed_addr #16

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @cpuset_cpumask_can_shrink(ptr noundef %cur, ptr noundef %trial) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %call4.i.i = tail call i32 @__bitmap_weight(ptr noundef %cur, i32 noundef %0) #33
  %tobool.not = icmp eq i32 %call4.i.i, 0
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %call1 = tail call i32 @dl_cpuset_cpumask_can_shrink(ptr noundef %cur, ptr noundef %trial) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ 1, %entry ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @dl_cpuset_cpumask_can_shrink(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @task_can_attach(ptr noundef %p, ptr noundef %cs_cpus_allowed) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %flags = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 3
  %0 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %flags, align 4
  %and = and i32 %1, 67108864
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %if.end, label %out

if.end:                                           ; preds = %entry
  %prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %2 = ptrtoint ptr %prio.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %prio.i, align 8
  %tobool1.not = icmp sgt i32 %3, -1
  br i1 %tobool1.not, label %out, label %do.body

do.body:                                          ; preds = %if.end
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %4 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %cpu.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @runqueues to i32)
  %11 = inttoptr i32 %add to ptr
  %rd = getelementptr inbounds %struct.rq, ptr %11, i32 0, i32 35
  %12 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %rd, align 8
  %span = getelementptr inbounds %struct.root_domain, ptr %13, i32 0, i32 3
  %14 = ptrtoint ptr %span to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %span, align 8
  %call.i.i = tail call i32 @__bitmap_intersects(ptr noundef %15, ptr noundef %cs_cpus_allowed, i32 noundef %8) #33
  %tobool.i.not = icmp eq i32 %call.i.i, 0
  br i1 %tobool.i.not, label %if.then5, label %out

if.then5:                                         ; preds = %do.body
  %call6 = tail call i32 @dl_task_can_attach(ptr noundef %p, ptr noundef %cs_cpus_allowed) #33
  br label %out

out:                                              ; preds = %if.then5, %do.body, %if.end, %entry
  %ret.0 = phi i32 [ 0, %do.body ], [ %call6, %if.then5 ], [ 0, %if.end ], [ -22, %entry ]
  ret i32 %ret.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @dl_task_can_attach(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @idle_task_exit() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %active_mm = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 54
  %4 = ptrtoint ptr %active_mm to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %active_mm, align 4
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %8, %7
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %entry
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %entry
  %div3.i.i.i = lshr i32 %7, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %9 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %7, 31
  %11 = shl nuw i32 1, %and.i.i.i
  %12 = and i32 %10, %11
  %tobool.i.not = icmp eq i32 %12, 0
  br i1 %tobool.i.not, label %do.body10, label %do.body4, !prof !1191

do.body4:                                         ; preds = %cpu_online.exit
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 8806, 0\0A.popsection", ""() #33, !srcloc !1314
  unreachable

do.body10:                                        ; preds = %cpu_online.exit
  %13 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %task, align 8
  %15 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %16
  %17 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %arrayidx, align 4
  %add = add i32 %18, ptrtoint (ptr @runqueues to i32)
  %19 = inttoptr i32 %add to ptr
  %idle = getelementptr inbounds %struct.rq, ptr %19, i32 0, i32 21
  %20 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %idle, align 4
  %cmp.not = icmp eq ptr %14, %21
  br i1 %cmp.not, label %do.end34, label %do.body26, !prof !1191

do.body26:                                        ; preds = %do.body10
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 8807, 0\0A.popsection", ""() #33, !srcloc !1315
  unreachable

do.end34:                                         ; preds = %do.body10
  %cmp35.not = icmp eq ptr %5, @init_mm
  br i1 %cmp35.not, label %if.end42, label %if.then36

if.then36:                                        ; preds = %do.end34
  tail call fastcc void @switch_mm(ptr noundef %5, ptr noundef nonnull @init_mm, ptr noundef %14)
  br label %if.end42

if.end42:                                         ; preds = %if.then36, %do.end34
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @switch_mm(ptr noundef readnone %prev, ptr noundef %next, ptr noundef %tsk) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu1 = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu1, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @smp_on_up to i32))
  %4 = load i32, ptr @smp_on_up, align 4
  %tobool.i.not.i = icmp eq i32 %4, 0
  br i1 %tobool.i.not.i, label %if.end, label %cache_ops_need_broadcast.exit

cache_ops_need_broadcast.exit:                    ; preds = %entry
  %5 = tail call i32 asm "mrc\09p15, 0, $0, c0, c1, 7", "=r,~{memory}"() #33, !srcloc !1316
  %6 = and i32 %5, 61440
  %cmp.i.not = icmp eq i32 %6, 0
  br i1 %cmp.i.not, label %land.lhs.true, label %if.end

land.lhs.true:                                    ; preds = %cache_ops_need_broadcast.exit
  %cpu_bitmap.i = getelementptr inbounds %struct.mm_struct, ptr %next, i32 0, i32 1
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %call.i.i = tail call i32 @_find_first_bit_be(ptr noundef %cpu_bitmap.i, i32 noundef %7) #33
  %cmp4.i.i = icmp eq i32 %call.i.i, %7
  br i1 %cmp4.i.i, label %if.end, label %land.lhs.true5

land.lhs.true5:                                   ; preds = %land.lhs.true
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %8, %3
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %land.lhs.true5
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %land.lhs.true5
  %div3.i.i = lshr i32 %3, 5
  %arrayidx.i.i = getelementptr i32, ptr %cpu_bitmap.i, i32 %div3.i.i
  %9 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i27 = and i32 %3, 31
  %11 = shl nuw i32 1, %and.i.i27
  %12 = and i32 %10, %11
  %tobool8.not = icmp eq i32 %12, 0
  br i1 %tobool8.not, label %if.then, label %if.end

if.then:                                          ; preds = %cpumask_test_cpu.exit
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @cpu_cache to i32))
  %13 = load ptr, ptr @cpu_cache, align 4
  tail call void %13() #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 4", "r,~{memory}"(i32 0) #33, !srcloc !1317
  br label %if.end

if.end:                                           ; preds = %if.then, %cpumask_test_cpu.exit, %land.lhs.true, %cache_ops_need_broadcast.exit, %entry
  %cpu_bitmap.i29 = getelementptr inbounds %struct.mm_struct, ptr %next, i32 0, i32 1
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %14 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i30 = icmp ugt i32 %14, %3
  br i1 %cmp.not.i.i.i30, label %cpumask_test_and_set_cpu.exit, label %land.rhs.i.i.i32

land.rhs.i.i.i32:                                 ; preds = %if.end
  %.b37.i.i.i31 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i31, label %cpumask_test_and_set_cpu.exit, label %if.then.i.i.i33, !prof !1191

if.then.i.i.i33:                                  ; preds = %land.rhs.i.i.i32
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_and_set_cpu.exit

cpumask_test_and_set_cpu.exit:                    ; preds = %if.then.i.i.i33, %land.rhs.i.i.i32, %if.end
  %call1.i = tail call i32 @_test_and_set_bit(i32 noundef %3, ptr noundef %cpu_bitmap.i29) #33
  %tobool11.not = icmp ne i32 %call1.i, 0
  %cmp.not = icmp eq ptr %prev, %next
  %or.cond = and i1 %cmp.not, %tobool11.not
  br i1 %or.cond, label %if.end18, label %if.then12

if.then12:                                        ; preds = %cpumask_test_and_set_cpu.exit
  tail call void @check_and_switch_context(ptr noundef %next, ptr noundef %tsk) #33
  br label %if.end18

if.end18:                                         ; preds = %if.then12, %cpumask_test_and_set_cpu.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @set_rq_online(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %online = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 47
  %0 = ptrtoint ptr %online to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %online, align 8
  %tobool.not = icmp eq i32 %1, 0
  br i1 %tobool.not, label %if.then, label %if.end6

if.then:                                          ; preds = %entry
  %cpu = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %rd = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 35
  %4 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %rd, align 8
  %online1 = getelementptr inbounds %struct.root_domain, ptr %5, i32 0, i32 4
  %6 = ptrtoint ptr %online1 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %online1, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %8, %3
  br i1 %cmp.not.i.i.i, label %cpumask_set_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.then
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_set_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_set_cpu.exit

cpumask_set_cpu.exit:                             ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %if.then
  tail call void @_set_bit(i32 noundef %3, ptr noundef %7) #33
  %9 = ptrtoint ptr %online to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 1, ptr %online, align 8
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %if.end6, label %for.body

for.body:                                         ; preds = %for.inc, %cpumask_set_cpu.exit
  %class.014 = phi ptr [ %incdec.ptr, %for.inc ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %cpumask_set_cpu.exit ]
  %rq_online = getelementptr inbounds %struct.sched_class, ptr %class.014, i32 0, i32 15
  %10 = ptrtoint ptr %rq_online to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %rq_online, align 4
  %tobool3.not = icmp eq ptr %11, null
  br i1 %tobool3.not, label %for.inc, label %if.then4

if.then4:                                         ; preds = %for.body
  tail call void %11(ptr noundef %rq) #33
  br label %for.inc

for.inc:                                          ; preds = %if.then4, %for.body
  %incdec.ptr = getelementptr %struct.sched_class, ptr %class.014, i32 -1
  %cmp.not = icmp eq ptr %incdec.ptr, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not, label %if.end6, label %for.body

if.end6:                                          ; preds = %for.inc, %cpumask_set_cpu.exit, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @set_rq_offline(ptr noundef %rq) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %online = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 47
  %0 = ptrtoint ptr %online to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %online, align 8
  %tobool.not = icmp eq i32 %1, 0
  br i1 %tobool.not, label %if.end6, label %for.cond.preheader

for.cond.preheader:                               ; preds = %entry
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %for.end, label %for.body

for.body:                                         ; preds = %for.inc, %for.cond.preheader
  %class.014 = phi ptr [ %incdec.ptr, %for.inc ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %for.cond.preheader ]
  %rq_offline = getelementptr inbounds %struct.sched_class, ptr %class.014, i32 0, i32 16
  %2 = ptrtoint ptr %rq_offline to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %rq_offline, align 4
  %tobool1.not = icmp eq ptr %3, null
  br i1 %tobool1.not, label %for.inc, label %if.then2

if.then2:                                         ; preds = %for.body
  tail call void %3(ptr noundef %rq) #33
  br label %for.inc

for.inc:                                          ; preds = %if.then2, %for.body
  %incdec.ptr = getelementptr %struct.sched_class, ptr %class.014, i32 -1
  %cmp.not = icmp eq ptr %incdec.ptr, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc, %for.cond.preheader
  %cpu = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %4 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %cpu, align 4
  %rd = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 35
  %6 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %rd, align 8
  %online4 = getelementptr inbounds %struct.root_domain, ptr %7, i32 0, i32 4
  %8 = ptrtoint ptr %online4 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %online4, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %10 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %10, %5
  br i1 %cmp.not.i.i.i, label %cpumask_clear_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %for.end
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_clear_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_clear_cpu.exit

cpumask_clear_cpu.exit:                           ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %for.end
  tail call void @_clear_bit(i32 noundef %5, ptr noundef %9) #33
  %11 = ptrtoint ptr %online to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 0, ptr %online, align 8
  br label %if.end6

if.end6:                                          ; preds = %cpumask_clear_cpu.exit, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_activate(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %3 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %4 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %5 = ptrtoint ptr %4 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %4, align 4, !annotation !1193
  %6 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %7 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %6, align 4, !annotation !1193
  tail call fastcc void @balance_push_set(i32 noundef %cpu, i1 noundef zeroext false)
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %thread_sibling.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %cpu, i32 5
  %call4.i.i = tail call i32 @__bitmap_weight(ptr noundef %thread_sibling.i, i32 noundef %8) #33
  %cmp = icmp eq i32 %call4.i.i, 2
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  tail call void @static_key_slow_inc_cpuslocked(ptr noundef nonnull @sched_smt_present) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %9 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %9, %cpu
  br i1 %cmp.not.i.i.i.i, label %set_cpu_active.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %if.end
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %set_cpu_active.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %set_cpu_active.exit

set_cpu_active.exit:                              ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %if.end
  tail call void @_set_bit(i32 noundef %cpu, ptr noundef nonnull @__cpu_active_mask) #33
  %10 = load i8, ptr @sched_smp_initialized, align 1, !range !1318
  %tobool.not = icmp eq i8 %10, 0
  br i1 %tobool.not, label %if.end4, label %if.then3

if.then3:                                         ; preds = %set_cpu_active.exit
  call void @__asan_load1_noabort(i32 ptrtoint (ptr @cpuhp_tasks_frozen to i32))
  %11 = load i8, ptr @cpuhp_tasks_frozen, align 1, !range !1318
  %tobool.not.i = icmp eq i8 %11, 0
  br i1 %tobool.not.i, label %if.end3.i, label %if.then.i

if.then.i:                                        ; preds = %if.then3
  tail call void @partition_sched_domains(i32 noundef 1, ptr noundef null, ptr noundef null) #33
  %12 = load i32, ptr @num_cpus_frozen, align 4
  %dec.i = add i32 %12, -1
  store i32 %dec.i, ptr @num_cpus_frozen, align 4
  %tobool1.not.i = icmp eq i32 %dec.i, 0
  br i1 %tobool1.not.i, label %if.end.i, label %if.end4

if.end.i:                                         ; preds = %if.then.i
  tail call void @cpuset_force_rebuild() #33
  br label %if.end3.i

if.end3.i:                                        ; preds = %if.end.i, %if.then3
  tail call void @cpuset_update_active_cpus() #33
  br label %if.end4

if.end4:                                          ; preds = %if.end3.i, %if.then.i, %set_cpu_active.exit
  call fastcc void @rq_lock_irqsave(ptr noundef %2, ptr noundef nonnull %rf)
  %rd = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 35
  %13 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %rd, align 8
  %tobool5.not = icmp eq ptr %14, null
  br i1 %tobool5.not, label %if.end24, label %do.body7

do.body7:                                         ; preds = %if.end4
  %span = getelementptr inbounds %struct.root_domain, ptr %14, i32 0, i32 3
  %15 = ptrtoint ptr %span to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %span, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %17 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %17, %cpu
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %do.body7
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %do.body7
  %div3.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i = getelementptr i32, ptr %16, i32 %div3.i.i
  %18 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i34 = and i32 %cpu, 31
  %20 = shl nuw i32 1, %and.i.i34
  %21 = and i32 %19, %20
  %tobool10.not = icmp eq i32 %21, 0
  br i1 %tobool10.not, label %do.body15, label %do.end23, !prof !1192

do.body15:                                        ; preds = %cpumask_test_cpu.exit
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 9071, 0\0A.popsection", ""() #33, !srcloc !1319
  unreachable

do.end23:                                         ; preds = %cpumask_test_cpu.exit
  %online.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 47
  %22 = ptrtoint ptr %online.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %online.i, align 8
  %tobool.not.i36 = icmp eq i32 %23, 0
  br i1 %tobool.not.i36, label %if.then.i38, label %if.end24

if.then.i38:                                      ; preds = %do.end23
  %cpu.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 46
  %24 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %cpu.i, align 4
  %26 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %rd, align 8
  %online1.i = getelementptr inbounds %struct.root_domain, ptr %27, i32 0, i32 4
  %28 = ptrtoint ptr %online1.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %online1.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %30 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i37 = icmp ugt i32 %30, %25
  br i1 %cmp.not.i.i.i.i37, label %cpumask_set_cpu.exit.i, label %land.rhs.i.i.i.i40

land.rhs.i.i.i.i40:                               ; preds = %if.then.i38
  %.b37.i.i.i.i39 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i39, label %cpumask_set_cpu.exit.i, label %if.then.i.i.i.i41, !prof !1191

if.then.i.i.i.i41:                                ; preds = %land.rhs.i.i.i.i40
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_set_cpu.exit.i

cpumask_set_cpu.exit.i:                           ; preds = %if.then.i.i.i.i41, %land.rhs.i.i.i.i40, %if.then.i38
  tail call void @_set_bit(i32 noundef %25, ptr noundef %29) #33
  %31 = ptrtoint ptr %online.i to i32
  call void @__asan_store4_noabort(i32 %31)
  store i32 1, ptr %online.i, align 8
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %if.end24, label %for.body.i

for.body.i:                                       ; preds = %for.inc.i, %cpumask_set_cpu.exit.i
  %class.014.i = phi ptr [ %incdec.ptr.i, %for.inc.i ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %cpumask_set_cpu.exit.i ]
  %rq_online.i = getelementptr inbounds %struct.sched_class, ptr %class.014.i, i32 0, i32 15
  %32 = ptrtoint ptr %rq_online.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %rq_online.i, align 4
  %tobool3.not.i = icmp eq ptr %33, null
  br i1 %tobool3.not.i, label %for.inc.i, label %if.then4.i

if.then4.i:                                       ; preds = %for.body.i
  tail call void %33(ptr noundef %2) #33
  br label %for.inc.i

for.inc.i:                                        ; preds = %if.then4.i, %for.body.i
  %incdec.ptr.i = getelementptr %struct.sched_class, ptr %class.014.i, i32 -1
  %cmp.not.i = icmp eq ptr %incdec.ptr.i, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not.i, label %if.end24, label %for.body.i

if.end24:                                         ; preds = %for.inc.i, %cpumask_set_cpu.exit.i, %do.end23, %if.end4
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %34 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %35, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i44

if.then.i.i.i44:                                  ; preds = %if.end24
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %36 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i44, %if.end24
  %retval.0.i.i.i = phi ptr [ %37, %if.then.i.i.i44 ], [ %2, %if.end24 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %38 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %38)
  %.unpack.i.i = load i32, ptr %4, align 4
  %39 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %39) #33
  %40 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_cpu_activate, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %42 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %43, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i45

if.then.i.i.i.i45:                                ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %44 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i45, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %45, %if.then.i.i.i.i45 ], [ %2, %land.rhs.i.i.i.i.i ], [ %2, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i46 = and i32 %41, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i46, 0
  br i1 %tobool.not.i.i, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %46 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %46, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %41) #33, !srcloc !1218
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @balance_push_set(i32 noundef %cpu, i1 noundef zeroext %on) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %3 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %4 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %5 = ptrtoint ptr %4 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %4, align 4, !annotation !1193
  %6 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %7 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %6, align 4, !annotation !1193
  call fastcc void @rq_lock_irqsave(ptr noundef %2, ptr noundef nonnull %rf)
  %balance_callback = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 39
  %8 = ptrtoint ptr %balance_callback to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %balance_callback, align 8
  br i1 %on, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %tobool2.not = icmp eq ptr %9, null
  br i1 %tobool2.not, label %if.end49.sink.split, label %land.rhs

land.rhs:                                         ; preds = %if.then
  %.b57 = load i1, ptr @balance_push_set.__already_done, align 1
  br i1 %.b57, label %if.end49.sink.split, label %if.then11, !prof !1191

if.then11:                                        ; preds = %land.rhs
  store i1 true, ptr @balance_push_set.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 8918, i32 noundef 9, ptr noundef null) #33
  br label %if.end49.sink.split

if.else:                                          ; preds = %entry
  %cmp = icmp eq ptr %9, @balance_push_callback
  br i1 %cmp, label %if.end49.sink.split, label %if.end49

if.end49.sink.split:                              ; preds = %if.else, %if.then11, %land.rhs, %if.then
  %.sink = phi ptr [ @balance_push_callback, %if.then ], [ @balance_push_callback, %if.then11 ], [ @balance_push_callback, %land.rhs ], [ null, %if.else ]
  %10 = ptrtoint ptr %balance_callback to i32
  call void @__asan_store4_noabort(i32 %10)
  store ptr %.sink, ptr %balance_callback, align 8
  br label %if.end49

if.end49:                                         ; preds = %if.end49.sink.split, %if.else
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %11 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %12, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end49
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %13 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end49
  %retval.0.i.i.i = phi ptr [ %14, %if.then.i.i.i ], [ %2, %if.end49 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %15 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %15)
  %.unpack.i.i = load i32, ptr %4, align 4
  %16 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %16) #33
  %17 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@balance_push_set, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %19 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %20, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %21 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %22, %if.then.i.i.i.i ], [ %2, %land.rhs.i.i.i.i.i ], [ %2, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i = and i32 %18, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %23 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %23, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %18) #33, !srcloc !1218
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @static_key_slow_inc_cpuslocked(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_deactivate(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %flags.i = alloca i32, align 4
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %3 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %4 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %5 = ptrtoint ptr %4 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %4, align 4, !annotation !1193
  %6 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  tail call void @nohz_balance_exit_idle(ptr noundef %2) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %7, %cpu
  br i1 %cmp.not.i.i.i.i, label %set_cpu_active.exit, label %land.rhs.i.i.i4.i

land.rhs.i.i.i4.i:                                ; preds = %entry
  %.b37.i.i.i3.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i3.i, label %set_cpu_active.exit, label %if.then.i.i.i5.i, !prof !1191

if.then.i.i.i5.i:                                 ; preds = %land.rhs.i.i.i4.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %set_cpu_active.exit

set_cpu_active.exit:                              ; preds = %if.then.i.i.i5.i, %land.rhs.i.i.i4.i, %entry
  tail call void @_clear_bit(i32 noundef %cpu, ptr noundef nonnull @__cpu_active_mask) #33
  tail call fastcc void @balance_push_set(i32 noundef %cpu, i1 noundef zeroext true)
  tail call void @synchronize_rcu() #33
  call fastcc void @rq_lock_irqsave(ptr noundef %2, ptr noundef nonnull %rf)
  %rd = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 35
  %8 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %rd, align 8
  %tobool.not = icmp eq ptr %9, null
  br i1 %tobool.not, label %if.end17, label %if.then

if.then:                                          ; preds = %set_cpu_active.exit
  tail call void @update_rq_clock(ptr noundef %2)
  %10 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %rd, align 8
  %span = getelementptr inbounds %struct.root_domain, ptr %11, i32 0, i32 3
  %12 = ptrtoint ptr %span to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %span, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %14 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %14, %cpu
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.then
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %if.then
  %div3.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i = getelementptr i32, ptr %13, i32 %div3.i.i
  %15 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i = and i32 %cpu, 31
  %17 = shl nuw i32 1, %and.i.i
  %18 = and i32 %16, %17
  %tobool4.not = icmp eq i32 %18, 0
  br i1 %tobool4.not, label %do.body9, label %do.end16, !prof !1192

do.body9:                                         ; preds = %cpumask_test_cpu.exit
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 9116, 0\0A.popsection", ""() #33, !srcloc !1320
  unreachable

do.end16:                                         ; preds = %cpumask_test_cpu.exit
  %online.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 47
  %19 = ptrtoint ptr %online.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %online.i, align 8
  %tobool.not.i = icmp eq i32 %20, 0
  br i1 %tobool.not.i, label %if.end17, label %for.cond.preheader.i

for.cond.preheader.i:                             ; preds = %do.end16
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %for.end.i, label %for.body.i

for.body.i:                                       ; preds = %for.inc.i, %for.cond.preheader.i
  %class.014.i = phi ptr [ %incdec.ptr.i, %for.inc.i ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %for.cond.preheader.i ]
  %rq_offline.i = getelementptr inbounds %struct.sched_class, ptr %class.014.i, i32 0, i32 16
  %21 = ptrtoint ptr %rq_offline.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %rq_offline.i, align 4
  %tobool1.not.i = icmp eq ptr %22, null
  br i1 %tobool1.not.i, label %for.inc.i, label %if.then2.i

if.then2.i:                                       ; preds = %for.body.i
  tail call void %22(ptr noundef %2) #33
  br label %for.inc.i

for.inc.i:                                        ; preds = %if.then2.i, %for.body.i
  %incdec.ptr.i = getelementptr %struct.sched_class, ptr %class.014.i, i32 -1
  %cmp.not.i = icmp eq ptr %incdec.ptr.i, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not.i, label %for.end.i, label %for.body.i

for.end.i:                                        ; preds = %for.inc.i, %for.cond.preheader.i
  %cpu.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 46
  %23 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %cpu.i, align 4
  %25 = ptrtoint ptr %rd to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %rd, align 8
  %online4.i = getelementptr inbounds %struct.root_domain, ptr %26, i32 0, i32 4
  %27 = ptrtoint ptr %online4.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %online4.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %29 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i47 = icmp ugt i32 %29, %24
  br i1 %cmp.not.i.i.i.i47, label %cpumask_clear_cpu.exit.i, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %for.end.i
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpumask_clear_cpu.exit.i, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_clear_cpu.exit.i

cpumask_clear_cpu.exit.i:                         ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %for.end.i
  tail call void @_clear_bit(i32 noundef %24, ptr noundef %28) #33
  %30 = ptrtoint ptr %online.i to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 0, ptr %online.i, align 8
  br label %if.end17

if.end17:                                         ; preds = %cpumask_clear_cpu.exit.i, %do.end16, %set_cpu_active.exit
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 25
  %31 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %32, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end17
  %33 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 4, ptr %6, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end17
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %34 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %35, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i48

if.then.i.i.i48:                                  ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %36 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i48, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %37, %if.then.i.i.i48 ], [ %2, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %38 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %38)
  %.unpack.i.i = load i32, ptr %4, align 4
  %39 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %39) #33
  %40 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_cpu_deactivate, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %42 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %43, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i49

if.then.i.i.i.i49:                                ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %44 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i49, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %45, %if.then.i.i.i.i49 ], [ %2, %land.rhs.i.i.i.i.i ], [ %2, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i = and i32 %41, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %46 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %46, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %41) #33, !srcloc !1218
  %thread_sibling.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %cpu, i32 5
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %47 = load i32, ptr @nr_cpu_ids, align 4
  %call4.i.i = tail call i32 @__bitmap_weight(ptr noundef %thread_sibling.i, i32 noundef %47) #33
  %cmp = icmp eq i32 %call4.i.i, 2
  br i1 %cmp, label %if.then20, label %if.end21

if.then20:                                        ; preds = %rq_unlock_irqrestore.exit
  tail call void @static_key_slow_dec_cpuslocked(ptr noundef nonnull @sched_smt_present) #33
  br label %if.end21

if.end21:                                         ; preds = %if.then20, %rq_unlock_irqrestore.exit
  %48 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx, align 4
  %add.i = add i32 %49, ptrtoint (ptr @runqueues to i32)
  %50 = inttoptr i32 %add.i to ptr
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %flags.i) #33
  %51 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %52 = ptrtoint ptr %flags.i to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 %51, ptr %flags.i, align 4
  %and.i.i.i55 = and i32 %51, 128
  %tobool.not.i.i56 = icmp eq i32 %and.i.i.i55, 0
  br i1 %tobool.not.i.i56, label %if.then.i.i57, label %do.end11.i.i

if.then.i.i57:                                    ; preds = %if.end21
  tail call void @trace_hardirqs_off() #33
  br label %do.end11.i.i

do.end11.i.i:                                     ; preds = %if.then.i.i57, %if.end21
  %call1223.i.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %53 = load i32, ptr @nr_cpu_ids, align 4
  %cmp1324.i.i = icmp ult i32 %call1223.i.i, %53
  br i1 %cmp1324.i.i, label %do.body15.i.i, label %if.end.i.i.i

do.body15.i.i:                                    ; preds = %do.body15.i.i, %do.end11.i.i
  %call1226.i.i = phi i32 [ %call12.i.i, %do.body15.i.i ], [ %call1223.i.i, %do.end11.i.i ]
  %i.025.i.i = phi i32 [ %inc.i.i, %do.body15.i.i ], [ 0, %do.end11.i.i ]
  %arrayidx.i.i58 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call1226.i.i
  %54 = ptrtoint ptr %arrayidx.i.i58 to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load i32, ptr %arrayidx.i.i58, align 4
  %add.i.i = add i32 %55, ptrtoint (ptr @runqueues to i32)
  %56 = inttoptr i32 %add.i.i to ptr
  %inc.i.i = add i32 %i.025.i.i, 1
  tail call void @_raw_spin_lock_nested(ptr noundef %56, i32 noundef %i.025.i.i) #33
  %call12.i.i = tail call i32 @cpumask_next(i32 noundef %call1226.i.i, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %57 = load i32, ptr @nr_cpu_ids, align 4
  %cmp13.i.i = icmp ult i32 %call12.i.i, %57
  br i1 %cmp13.i.i, label %do.body15.i.i, label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %do.body15.i.i, %do.end11.i.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %58 = load i32, ptr @nr_cpu_ids, align 4
  %call4.i.i.i = tail call i32 @__bitmap_weight(ptr noundef %thread_sibling.i, i32 noundef %58) #33
  %cmp.i = icmp eq i32 %call4.i.i.i, 1
  %core.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 79
  %59 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %59)
  %60 = load ptr, ptr %core.i, align 8
  %cmp3.not.i = icmp eq ptr %60, %50
  br i1 %cmp.i, label %if.then.i, label %if.end43.i

if.then.i:                                        ; preds = %if.end.i.i.i
  br i1 %cmp3.not.i, label %sched_core_cpu_deactivate.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then.i
  %.b178.i = load i1, ptr @sched_core_cpu_deactivate.__already_done, align 1
  br i1 %.b178.i, label %sched_core_cpu_deactivate.exit, label %unlock.sink.split.i, !prof !1191

if.end43.i:                                       ; preds = %if.end.i.i.i
  br i1 %cmp3.not.i, label %for.cond.preheader.i64, label %sched_core_cpu_deactivate.exit

for.cond.preheader.i64:                           ; preds = %if.end43.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %61 = load i32, ptr @nr_cpu_ids, align 4
  br label %for.cond.i

for.cond.i:                                       ; preds = %for.body.i65, %for.cond.preheader.i64
  %t.0.i = phi i32 [ %cpu, %for.body.i65 ], [ -1, %for.cond.preheader.i64 ]
  %call48.i = tail call i32 @cpumask_next(i32 noundef %t.0.i, ptr noundef %thread_sibling.i) #37
  %cmp49.i = icmp ult i32 %call48.i, %61
  br i1 %cmp49.i, label %for.body.i65, label %land.rhs72.i

for.body.i65:                                     ; preds = %for.cond.i
  %cmp50.i = icmp eq i32 %call48.i, %cpu
  br i1 %cmp50.i, label %for.cond.i, label %for.end.i66

for.end.i66:                                      ; preds = %for.body.i65
  %arrayidx60.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call48.i
  %62 = ptrtoint ptr %arrayidx60.i to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %arrayidx60.i, align 4
  %add61.i = add i32 %63, ptrtoint (ptr @runqueues to i32)
  %64 = inttoptr i32 %add61.i to ptr
  %tobool63.not.i = icmp eq i32 %add61.i, 0
  br i1 %tobool63.not.i, label %land.rhs72.i, label %if.end120.critedge.i

land.rhs72.i:                                     ; preds = %for.end.i66, %for.cond.i
  %.b176177.i = load i1, ptr @sched_core_cpu_deactivate.__already_done.234, align 1
  br i1 %.b176177.i, label %sched_core_cpu_deactivate.exit, label %unlock.sink.split.i, !prof !1191

if.end120.critedge.i:                             ; preds = %for.end.i66
  %core_task_seq.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 84
  %65 = ptrtoint ptr %core_task_seq.i to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load i32, ptr %core_task_seq.i, align 4
  %core_task_seq121.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 84
  %67 = ptrtoint ptr %core_task_seq121.i to i32
  call void @__asan_store4_noabort(i32 %67)
  store i32 %66, ptr %core_task_seq121.i, align 4
  %core_pick_seq.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 85
  %68 = ptrtoint ptr %core_pick_seq.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load i32, ptr %core_pick_seq.i, align 16
  %core_pick_seq122.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 85
  %70 = ptrtoint ptr %core_pick_seq122.i to i32
  call void @__asan_store4_noabort(i32 %70)
  store i32 %69, ptr %core_pick_seq122.i, align 16
  %core_cookie.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 86
  %71 = ptrtoint ptr %core_cookie.i to i32
  call void @__asan_load4_noabort(i32 %71)
  %72 = load i32, ptr %core_cookie.i, align 4
  %core_cookie123.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 86
  %73 = ptrtoint ptr %core_cookie123.i to i32
  call void @__asan_store4_noabort(i32 %73)
  store i32 %72, ptr %core_cookie123.i, align 4
  %core_forceidle_count.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 87
  %74 = ptrtoint ptr %core_forceidle_count.i to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load i32, ptr %core_forceidle_count.i, align 8
  %core_forceidle_count124.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 87
  %76 = ptrtoint ptr %core_forceidle_count124.i to i32
  call void @__asan_store4_noabort(i32 %76)
  store i32 %75, ptr %core_forceidle_count124.i, align 8
  %core_forceidle_seq.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 88
  %77 = ptrtoint ptr %core_forceidle_seq.i to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %core_forceidle_seq.i, align 4
  %core_forceidle_seq125.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 88
  %79 = ptrtoint ptr %core_forceidle_seq125.i to i32
  call void @__asan_store4_noabort(i32 %79)
  store i32 %78, ptr %core_forceidle_seq125.i, align 4
  %core_forceidle_occupation.i = getelementptr inbounds %struct.rq, ptr %50, i32 0, i32 89
  %80 = ptrtoint ptr %core_forceidle_occupation.i to i32
  call void @__asan_load4_noabort(i32 %80)
  %81 = load i32, ptr %core_forceidle_occupation.i, align 32
  %core_forceidle_occupation126.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 89
  %82 = ptrtoint ptr %core_forceidle_occupation126.i to i32
  call void @__asan_store4_noabort(i32 %82)
  store i32 %81, ptr %core_forceidle_occupation126.i, align 32
  %core_forceidle_start.i = getelementptr inbounds %struct.rq, ptr %64, i32 0, i32 90
  %83 = ptrtoint ptr %core_forceidle_start.i to i32
  call void @__asan_store8_noabort(i32 %83)
  store i64 0, ptr %core_forceidle_start.i, align 8
  %call128185.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  %cmp129186.i = icmp ult i32 %call128185.i, %61
  br i1 %cmp129186.i, label %do.body131.i, label %sched_core_cpu_deactivate.exit

do.body131.i:                                     ; preds = %do.body131.i, %if.end120.critedge.i
  %call128187.i = phi i32 [ %call128.i, %do.body131.i ], [ %call128185.i, %if.end120.critedge.i ]
  %arrayidx138.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call128187.i
  %84 = ptrtoint ptr %arrayidx138.i to i32
  call void @__asan_load4_noabort(i32 %84)
  %85 = load i32, ptr %arrayidx138.i, align 4
  %add139.i = add i32 %85, ptrtoint (ptr @runqueues to i32)
  %86 = inttoptr i32 %add139.i to ptr
  %core140.i = getelementptr inbounds %struct.rq, ptr %86, i32 0, i32 79
  %87 = ptrtoint ptr %core140.i to i32
  call void @__asan_store4_noabort(i32 %87)
  store ptr %64, ptr %core140.i, align 8
  %call128.i = tail call i32 @cpumask_next(i32 noundef %call128187.i, ptr noundef %thread_sibling.i) #37
  %cmp129.i = icmp ult i32 %call128.i, %61
  br i1 %cmp129.i, label %do.body131.i, label %sched_core_cpu_deactivate.exit

unlock.sink.split.i:                              ; preds = %land.rhs72.i, %land.rhs.i
  %sched_core_cpu_deactivate.__already_done.234.sink.i = phi ptr [ @sched_core_cpu_deactivate.__already_done, %land.rhs.i ], [ @sched_core_cpu_deactivate.__already_done.234, %land.rhs72.i ]
  %.sink.i = phi i32 [ 6059, %land.rhs.i ], [ 6075, %land.rhs72.i ]
  %88 = ptrtoint ptr %sched_core_cpu_deactivate.__already_done.234.sink.i to i32
  call void @__asan_store1_noabort(i32 %88)
  store i1 true, ptr %sched_core_cpu_deactivate.__already_done.234.sink.i, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef %.sink.i, i32 noundef 9, ptr noundef null) #33
  br label %sched_core_cpu_deactivate.exit

sched_core_cpu_deactivate.exit:                   ; preds = %unlock.sink.split.i, %do.body131.i, %if.end120.critedge.i, %land.rhs72.i, %if.end43.i, %land.rhs.i, %if.then.i
  call fastcc void @sched_core_unlock(i32 noundef %cpu, ptr noundef nonnull %flags.i) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %flags.i) #33
  %89 = load i8, ptr @sched_smp_initialized, align 1, !range !1318
  %tobool22.not = icmp eq i8 %89, 0
  br i1 %tobool22.not, label %cleanup, label %if.end24

if.end24:                                         ; preds = %sched_core_cpu_deactivate.exit
  call void @__asan_load1_noabort(i32 ptrtoint (ptr @cpuhp_tasks_frozen to i32))
  %90 = load i8, ptr @cpuhp_tasks_frozen, align 1, !range !1318
  %tobool.not.i67 = icmp eq i8 %90, 0
  br i1 %tobool.not.i67, label %if.then.i68, label %if.else.i

if.then.i68:                                      ; preds = %if.end24
  %call.i = tail call zeroext i1 @dl_cpu_busy(i32 noundef %cpu) #33
  br i1 %call.i, label %if.then27, label %if.end.i

if.end.i:                                         ; preds = %if.then.i68
  tail call void @cpuset_update_active_cpus() #33
  br label %cleanup

if.else.i:                                        ; preds = %if.end24
  %91 = load i32, ptr @num_cpus_frozen, align 4
  %inc.i = add i32 %91, 1
  store i32 %inc.i, ptr @num_cpus_frozen, align 4
  tail call void @partition_sched_domains(i32 noundef 1, ptr noundef null, ptr noundef null) #33
  br label %cleanup

if.then27:                                        ; preds = %if.then.i68
  tail call fastcc void @balance_push_set(i32 noundef %cpu, i1 noundef zeroext false)
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %92 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i69 = icmp ugt i32 %92, %cpu
  br i1 %cmp.not.i.i.i.i69, label %set_cpu_active.exit75, label %land.rhs.i.i.i.i72

land.rhs.i.i.i.i72:                               ; preds = %if.then27
  %.b37.i.i.i.i71 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i71, label %set_cpu_active.exit75, label %if.then.i.i.i.i73, !prof !1191

if.then.i.i.i.i73:                                ; preds = %land.rhs.i.i.i.i72
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %set_cpu_active.exit75

set_cpu_active.exit75:                            ; preds = %if.then.i.i.i.i73, %land.rhs.i.i.i.i72, %if.then27
  tail call void @_set_bit(i32 noundef %cpu, ptr noundef nonnull @__cpu_active_mask) #33
  br label %cleanup

cleanup:                                          ; preds = %set_cpu_active.exit75, %if.else.i, %if.end.i, %sched_core_cpu_deactivate.exit
  %retval.0 = phi i32 [ -16, %set_cpu_active.exit75 ], [ 0, %sched_core_cpu_deactivate.exit ], [ 0, %if.else.i ], [ 0, %if.end.i ]
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @nohz_balance_exit_idle(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @synchronize_rcu() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @static_key_slow_dec_cpuslocked(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_starting(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %flags.i = alloca i32, align 4
  %thread_sibling.i.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %cpu, i32 5
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add.i to ptr
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %flags.i) #33
  %3 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %4 = ptrtoint ptr %flags.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %3, ptr %flags.i, align 4
  %and.i.i.i = and i32 %3, 128
  %tobool.not.i.i = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i, label %if.then.i.i, label %do.end11.i.i

if.then.i.i:                                      ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %do.end11.i.i

do.end11.i.i:                                     ; preds = %if.then.i.i, %entry
  %call1223.i.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %5 = load i32, ptr @nr_cpu_ids, align 4
  %cmp1324.i.i = icmp ult i32 %call1223.i.i, %5
  br i1 %cmp1324.i.i, label %do.body15.i.i, label %sched_core_lock.exit.i

do.body15.i.i:                                    ; preds = %do.body15.i.i, %do.end11.i.i
  %call1226.i.i = phi i32 [ %call12.i.i, %do.body15.i.i ], [ %call1223.i.i, %do.end11.i.i ]
  %i.025.i.i = phi i32 [ %inc.i.i, %do.body15.i.i ], [ 0, %do.end11.i.i ]
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call1226.i.i
  %6 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %7, ptrtoint (ptr @runqueues to i32)
  %8 = inttoptr i32 %add.i.i to ptr
  %inc.i.i = add i32 %i.025.i.i, 1
  tail call void @_raw_spin_lock_nested(ptr noundef %8, i32 noundef %i.025.i.i) #33
  %call12.i.i = tail call i32 @cpumask_next(i32 noundef %call1226.i.i, ptr noundef %thread_sibling.i.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %9 = load i32, ptr @nr_cpu_ids, align 4
  %cmp13.i.i = icmp ult i32 %call12.i.i, %9
  br i1 %cmp13.i.i, label %do.body15.i.i, label %sched_core_lock.exit.i

sched_core_lock.exit.i:                           ; preds = %do.body15.i.i, %do.end11.i.i
  %core.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %10 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i, align 8
  %cmp.not.i = icmp eq ptr %11, %2
  br i1 %cmp.not.i, label %if.end.i.i.i, label %land.rhs.i

land.rhs.i:                                       ; preds = %sched_core_lock.exit.i
  %.b226.i = load i1, ptr @sched_core_cpu_starting.__already_done, align 1
  br i1 %.b226.i, label %if.end.i.i.i, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs.i
  store i1 true, ptr @sched_core_cpu_starting.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6014, i32 noundef 9, ptr noundef null) #33
  br label %if.end.i.i.i

if.end.i.i.i:                                     ; preds = %if.then.i, %land.rhs.i, %sched_core_lock.exit.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %12 = load i32, ptr @nr_cpu_ids, align 4
  %call4.i.i.i = tail call i32 @__bitmap_weight(ptr noundef %thread_sibling.i.i, i32 noundef %12) #33
  %cmp41.i = icmp eq i32 %call4.i.i.i, 1
  br i1 %cmp41.i, label %sched_core_cpu_starting.exit, label %for.cond.preheader.i

for.cond.preheader.i:                             ; preds = %if.end.i.i.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %13 = load i32, ptr @nr_cpu_ids, align 4
  %call44232.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i.i) #37
  %cmp45233.i = icmp ult i32 %call44232.i, %13
  br i1 %cmp45233.i, label %for.body.i, label %land.rhs72.i

for.body.i:                                       ; preds = %for.cond.backedge.i, %for.cond.preheader.i
  %call44234.i = phi i32 [ %call44.i, %for.cond.backedge.i ], [ %call44232.i, %for.cond.preheader.i ]
  %cmp46.i = icmp eq i32 %call44234.i, %cpu
  br i1 %cmp46.i, label %for.cond.backedge.i, label %do.body49.i

for.cond.backedge.i:                              ; preds = %do.body49.i, %for.body.i
  %call44.i = tail call i32 @cpumask_next(i32 noundef %call44234.i, ptr noundef %thread_sibling.i.i) #37
  %cmp45.i = icmp ult i32 %call44.i, %13
  br i1 %cmp45.i, label %for.body.i, label %land.rhs72.i

do.body49.i:                                      ; preds = %for.body.i
  %arrayidx56.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call44234.i
  %14 = ptrtoint ptr %arrayidx56.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx56.i, align 4
  %add57.i = add i32 %15, ptrtoint (ptr @runqueues to i32)
  %16 = inttoptr i32 %add57.i to ptr
  %core58.i = getelementptr inbounds %struct.rq, ptr %16, i32 0, i32 79
  %17 = ptrtoint ptr %core58.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core58.i, align 8
  %cmp59.i = icmp eq ptr %18, %16
  br i1 %cmp59.i, label %for.end.i, label %for.cond.backedge.i

for.end.i:                                        ; preds = %do.body49.i
  %19 = inttoptr i32 %add57.i to ptr
  %tobool63.not.i = icmp eq i32 %add57.i, 0
  br i1 %tobool63.not.i, label %land.rhs72.i, label %do.body125.i

land.rhs72.i:                                     ; preds = %for.end.i, %for.cond.backedge.i, %for.cond.preheader.i
  %.b222225.i = load i1, ptr @sched_core_cpu_starting.__already_done.235, align 1
  br i1 %.b222225.i, label %sched_core_cpu_starting.exit, label %if.then83.i, !prof !1191

if.then83.i:                                      ; preds = %land.rhs72.i
  store i1 true, ptr @sched_core_cpu_starting.__already_done.235, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6031, i32 noundef 9, ptr noundef null) #33
  br label %sched_core_cpu_starting.exit

do.body125.i:                                     ; preds = %if.end185.i, %for.end.i
  %call122237.i = phi i32 [ %call122.i, %if.end185.i ], [ %call44232.i, %for.end.i ]
  %arrayidx132.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call122237.i
  %20 = ptrtoint ptr %arrayidx132.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %arrayidx132.i, align 4
  %add133.i = add i32 %21, ptrtoint (ptr @runqueues to i32)
  %22 = inttoptr i32 %add133.i to ptr
  %cmp134.i = icmp eq i32 %call122237.i, %cpu
  br i1 %cmp134.i, label %if.then135.i, label %if.end137.i

if.then135.i:                                     ; preds = %do.body125.i
  %core136.i = getelementptr inbounds %struct.rq, ptr %22, i32 0, i32 79
  %23 = ptrtoint ptr %core136.i to i32
  call void @__asan_store4_noabort(i32 %23)
  store ptr %19, ptr %core136.i, align 8
  br label %if.end137.i

if.end137.i:                                      ; preds = %if.then135.i, %do.body125.i
  %core139.i = getelementptr inbounds %struct.rq, ptr %22, i32 0, i32 79
  %24 = ptrtoint ptr %core139.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %core139.i, align 8
  %cmp140.not.i = icmp eq ptr %25, %19
  br i1 %cmp140.not.i, label %if.end185.i, label %land.rhs147.i

land.rhs147.i:                                    ; preds = %if.end137.i
  %.b223224.i = load i1, ptr @sched_core_cpu_starting.__already_done.236, align 1
  br i1 %.b223224.i, label %if.end185.i, label %if.then158.i, !prof !1191

if.then158.i:                                     ; preds = %land.rhs147.i
  store i1 true, ptr @sched_core_cpu_starting.__already_done.236, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 6041, i32 noundef 9, ptr noundef null) #33
  br label %if.end185.i

if.end185.i:                                      ; preds = %if.then158.i, %land.rhs147.i, %if.end137.i
  %call122.i = tail call i32 @cpumask_next(i32 noundef %call122237.i, ptr noundef %thread_sibling.i.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %26 = load i32, ptr @nr_cpu_ids, align 4
  %cmp123.i = icmp ult i32 %call122.i, %26
  br i1 %cmp123.i, label %do.body125.i, label %sched_core_cpu_starting.exit

sched_core_cpu_starting.exit:                     ; preds = %if.end185.i, %if.then83.i, %land.rhs72.i, %if.end.i.i.i
  call fastcc void @sched_core_unlock(i32 noundef %cpu, ptr noundef nonnull %flags.i) #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %flags.i) #33
  %27 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %arrayidx.i, align 4
  %add.i4 = add i32 %28, ptrtoint (ptr @runqueues to i32)
  %29 = inttoptr i32 %add.i4 to ptr
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @calc_load_update to i32))
  %30 = load i32, ptr @calc_load_update, align 4
  %calc_load_update.i = getelementptr inbounds %struct.rq, ptr %29, i32 0, i32 63
  %31 = ptrtoint ptr %calc_load_update.i to i32
  call void @__asan_store4_noabort(i32 %31)
  store i32 %30, ptr %calc_load_update.i, align 8
  tail call void @update_max_interval() #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_wait_empty(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @balance_hotplug_wait()
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @balance_hotplug_wait() #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %hotplug_wait = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 59
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %7 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %task.i, align 8
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1321
  %9 = ptrtoint ptr %hotplug_wait to i32
  call void @__asan_store4_noabort(i32 %9)
  store volatile ptr %8, ptr %hotplug_wait, align 4
  %nr_pinned.i = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 76
  %nr_running = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 1
  br label %__here

__here:                                           ; preds = %if.end74, %entry
  %10 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %task.i, align 8
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %11, i32 0, i32 212
  %12 = ptrtoint ptr %task_state_change to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 ptrtoint (ptr blockaddress(@balance_hotplug_wait, %__here) to i32), ptr %task_state_change, align 4
  %13 = load ptr, ptr %task.i, align 8
  %14 = ptrtoint ptr %13 to i32
  call void @__asan_store4_noabort(i32 %14)
  store volatile i32 2, ptr %13, align 128
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1322
  %15 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %nr_running, align 4
  %cmp = icmp eq i32 %16, 1
  br i1 %cmp, label %land.lhs.true, label %if.end74

land.lhs.true:                                    ; preds = %__here
  %17 = ptrtoint ptr %nr_pinned.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %nr_pinned.i, align 8
  %tobool.i.not = icmp eq i32 %18, 0
  br i1 %tobool.i.not, label %for.end, label %if.end74

if.end74:                                         ; preds = %land.lhs.true, %__here
  tail call void @schedule()
  br label %__here

for.end:                                          ; preds = %land.lhs.true
  tail call fastcc void @finish_rcuwait(ptr noundef %hotplug_wait)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @sched_cpu_dying(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %3 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %3)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %4 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %5 = ptrtoint ptr %4 to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 -1, ptr %4, align 4, !annotation !1193
  %6 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  call fastcc void @rq_lock_irqsave(ptr noundef %2, ptr noundef nonnull %rf)
  %nr_running = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 1
  %7 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %nr_running, align 4
  %cmp.not = icmp eq i32 %8, 1
  br i1 %cmp.not, label %lor.lhs.false, label %do.end8

lor.lhs.false:                                    ; preds = %entry
  %nr_pinned.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 76
  %9 = ptrtoint ptr %nr_pinned.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %nr_pinned.i, align 8
  %tobool.i.not = icmp eq i32 %10, 0
  br i1 %tobool.i.not, label %if.end21, label %do.end8

do.end8:                                          ; preds = %lor.lhs.false, %entry
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 9225, i32 noundef 9, ptr noundef nonnull @.str.67) #33
  %cpu.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 46
  %11 = ptrtoint ptr %cpu.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu.i.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %13 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i.i, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %do.end8
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %14 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %15, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %16 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i
  %retval.0.i.i.i = phi ptr [ %17, %if.then.i.i.i ], [ %2, %land.rhs.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %do.end8
  %18 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %nr_running, align 4
  %call1.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.238, ptr noundef nonnull @.str.68, i32 noundef %12, i32 noundef %19) #39
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50) to i32))
  %20 = load volatile ptr, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50), align 16
  %add.ptr7.i = getelementptr i8, ptr %20, i32 -1136
  %cmp.not8.i = icmp eq ptr %add.ptr7.i, @init_task
  br i1 %cmp.not8.i, label %if.end21, label %do.body7.i

for.cond.loopexit.i:                              ; preds = %for.inc.i, %do.end14.i
  %21 = ptrtoint ptr %23 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile ptr, ptr %23, align 16
  %add.ptr.i = getelementptr i8, ptr %22, i32 -1136
  %cmp.not.i = icmp eq ptr %add.ptr.i, @init_task
  br i1 %cmp.not.i, label %if.end21, label %do.body7.i

do.body7.i:                                       ; preds = %for.cond.loopexit.i, %lockdep_assert_rq_held.exit.i
  %23 = phi ptr [ %22, %for.cond.loopexit.i ], [ %20, %lockdep_assert_rq_held.exit.i ]
  %call8.i = tail call i32 @rcu_read_lock_any_held() #33
  %tobool.not.i = icmp eq i32 %call8.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %do.end14.i

land.lhs.true.i:                                  ; preds = %do.body7.i
  %call9.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool10.not.i = icmp eq i32 %call9.i, 0
  br i1 %tobool10.not.i, label %do.end14.i, label %land.lhs.true11.i

land.lhs.true11.i:                                ; preds = %land.lhs.true.i
  %.b1.i = load i1, ptr @dump_rq_tasks.__warned, align 1
  br i1 %.b1.i, label %do.end14.i, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true11.i
  store i1 true, ptr @dump_rq_tasks.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 9204, ptr noundef nonnull @.str.4) #33
  br label %do.end14.i

do.end14.i:                                       ; preds = %if.then.i, %land.lhs.true11.i, %land.lhs.true.i, %do.body7.i
  %signal.i = getelementptr i8, ptr %23, i32 544
  %24 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %signal.i, align 16
  %thread_head.i = getelementptr inbounds %struct.signal_struct, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %thread_head.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %.pn3.i = load volatile ptr, ptr %thread_head.i, align 4
  %cmp26.not5.i = icmp eq ptr %.pn3.i, %thread_head.i
  br i1 %cmp26.not5.i, label %for.cond.loopexit.i, label %for.body27.i

for.body27.i:                                     ; preds = %for.inc.i, %do.end14.i
  %.pn6.i = phi ptr [ %.pn.i, %for.inc.i ], [ %.pn3.i, %do.end14.i ]
  %stack.i.i = getelementptr i8, ptr %.pn6.i, i32 -1400
  %27 = ptrtoint ptr %stack.i.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %stack.i.i, align 4
  %cpu.i2.i = getelementptr inbounds %struct.thread_info, ptr %28, i32 0, i32 3
  %29 = ptrtoint ptr %cpu.i2.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %cpu.i2.i, align 4
  %cmp29.not.i = icmp eq i32 %30, %12
  br i1 %cmp29.not.i, label %if.end31.i, label %for.inc.i

if.end31.i:                                       ; preds = %for.body27.i
  %on_rq.i.i = getelementptr i8, ptr %.pn6.i, i32 -1352
  %31 = ptrtoint ptr %on_rq.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %on_rq.i.i, align 4
  %cmp.i.not.i = icmp eq i32 %32, 1
  br i1 %cmp.i.not.i, label %do.end38.i, label %for.inc.i

do.end38.i:                                       ; preds = %if.end31.i
  %pid.i = getelementptr i8, ptr %.pn6.i, i32 -100
  %33 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %pid.i, align 8
  %comm.i = getelementptr i8, ptr %.pn6.i, i32 220
  %call40.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.241, ptr noundef nonnull @.str.68, i32 noundef %34, ptr noundef %comm.i) #39
  br label %for.inc.i

for.inc.i:                                        ; preds = %do.end38.i, %if.end31.i, %for.body27.i
  %35 = ptrtoint ptr %.pn6.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %.pn.i = load volatile ptr, ptr %.pn6.i, align 4
  %36 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %signal.i, align 16
  %thread_head25.i = getelementptr inbounds %struct.signal_struct, ptr %37, i32 0, i32 3
  %cmp26.not.i = icmp eq ptr %.pn.i, %thread_head25.i
  br i1 %cmp26.not.i, label %for.cond.loopexit.i, label %for.body27.i

if.end21:                                         ; preds = %for.cond.loopexit.i, %lockdep_assert_rq_held.exit.i, %lor.lhs.false
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 25
  %38 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %39, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end21
  %40 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %40)
  store i32 4, ptr %6, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end21
  %core_enabled.i.i.i31 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %41 = ptrtoint ptr %core_enabled.i.i.i31 to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %core_enabled.i.i.i31, align 128
  %tobool.not.i.i.i32 = icmp eq i32 %42, 0
  br i1 %tobool.not.i.i.i32, label %rq_unpin_lock.exit.i, label %if.then.i.i.i34

if.then.i.i.i34:                                  ; preds = %if.end.i.i
  %core.i.i.i33 = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %43 = ptrtoint ptr %core.i.i.i33 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %core.i.i.i33, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i34, %if.end.i.i
  %retval.0.i.i.i35 = phi ptr [ %44, %if.then.i.i.i34 ], [ %2, %if.end.i.i ]
  %dep_map.i.i36 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i35, i32 0, i32 4
  %45 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %45)
  %.unpack.i.i = load i32, ptr %4, align 4
  %46 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i36, [1 x i32] %46) #33
  %47 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load i32, ptr %rf, align 4
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_cpu_dying, %land.rhs.i.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i.i [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %49 = ptrtoint ptr %core_enabled.i.i.i31 to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %core_enabled.i.i.i31, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %50, 0
  br i1 %tobool3.i.not.i.i.i.i, label %raw_spin_rq_unlock.exit.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %51 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %core.i.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i.i

raw_spin_rq_unlock.exit.i.i:                      ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %52, %if.then.i.i.i.i ], [ %2, %land.rhs.i.i.i.i.i ], [ %2, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  %and.i.i.i = and i32 %48, 128
  %tobool.not.i.i37 = icmp eq i32 %and.i.i.i, 0
  br i1 %tobool.not.i.i37, label %if.then.i3.i, label %do.body2.i.i

if.then.i3.i:                                     ; preds = %raw_spin_rq_unlock.exit.i.i
  tail call void @trace_hardirqs_on() #33
  br label %do.body2.i.i

do.body2.i.i:                                     ; preds = %if.then.i3.i, %raw_spin_rq_unlock.exit.i.i
  %53 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i.i = and i32 %53, 128
  %tobool10.not.i.i = icmp eq i32 %and.i.i.i.i, 0
  br i1 %tobool10.not.i.i, label %if.then14.i.i, label %rq_unlock_irqrestore.exit, !prof !1192

if.then14.i.i:                                    ; preds = %do.body2.i.i
  tail call void @warn_bogus_irq_restore() #33
  br label %rq_unlock_irqrestore.exit

rq_unlock_irqrestore.exit:                        ; preds = %if.then14.i.i, %do.body2.i.i
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %48) #33, !srcloc !1218
  %call.i = tail call i32 @calc_load_fold_active(ptr noundef %2, i32 noundef 1) #33
  %tobool.not.i38 = icmp eq i32 %call.i, 0
  br i1 %tobool.not.i38, label %calc_load_migrate.exit, label %if.then.i40

if.then.i40:                                      ; preds = %rq_unlock_irqrestore.exit
  %call.i.i.i39 = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @calc_load_tasks, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr nonnull @calc_load_tasks, i32 1, i32 3, i32 1) #33
  %54 = tail call { i32, i32 } asm sideeffect "@ atomic_add\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @calc_load_tasks, ptr nonnull @calc_load_tasks, i32 %call.i, ptr nonnull elementtype(i32) @calc_load_tasks) #33, !srcloc !1200
  br label %calc_load_migrate.exit

calc_load_migrate.exit:                           ; preds = %if.then.i40, %rq_unlock_irqrestore.exit
  tail call void @update_max_interval() #33
  %hrtick_timer.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 66
  %call.i41 = tail call zeroext i1 @hrtimer_active(ptr noundef %hrtick_timer.i) #33
  br i1 %call.i41, label %if.then.i42, label %hrtick_clear.exit

if.then.i42:                                      ; preds = %calc_load_migrate.exit
  %call2.i = tail call i32 @hrtimer_cancel(ptr noundef %hrtick_timer.i) #33
  br label %hrtick_clear.exit

hrtick_clear.exit:                                ; preds = %if.then.i42, %calc_load_migrate.exit
  %55 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load i32, ptr %arrayidx, align 4
  %add.i = add i32 %56, ptrtoint (ptr @runqueues to i32)
  %57 = inttoptr i32 %add.i to ptr
  %core.i = getelementptr inbounds %struct.rq, ptr %57, i32 0, i32 79
  %58 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %core.i, align 8
  %cmp.not.i43 = icmp eq ptr %59, %57
  br i1 %cmp.not.i43, label %sched_core_cpu_dying.exit, label %if.then.i44

if.then.i44:                                      ; preds = %hrtick_clear.exit
  %60 = ptrtoint ptr %core.i to i32
  call void @__asan_store4_noabort(i32 %60)
  store ptr %57, ptr %core.i, align 8
  br label %sched_core_cpu_dying.exit

sched_core_cpu_dying.exit:                        ; preds = %if.then.i44, %hrtick_clear.exit
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @update_max_interval() local_unnamed_addr #2

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_init_smp() local_unnamed_addr #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @mutex_lock_nested(ptr noundef nonnull @sched_domains_mutex, i32 noundef 0) #33
  %call = tail call i32 @sched_init_domains(ptr noundef nonnull @__cpu_active_mask) #33
  tail call void @mutex_unlock(ptr noundef nonnull @sched_domains_mutex) #33
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %call2 = tail call ptr @housekeeping_cpumask(i32 noundef 32) #33
  %call3 = tail call i32 @set_cpus_allowed_ptr(ptr noundef %3, ptr noundef %call2)
  %cmp = icmp slt i32 %call3, 0
  br i1 %cmp, label %do.body, label %if.end

do.body:                                          ; preds = %entry
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 9253, 0\0A.popsection", ""() #33, !srcloc !1323
  unreachable

if.end:                                           ; preds = %entry
  %4 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task, align 8
  %flags = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %flags, align 4
  %and = and i32 %7, -67108865
  store i32 %and, ptr %flags, align 4
  tail call void @sched_init_granularity() #33
  tail call void @init_sched_rt_class() #33
  tail call void @init_sched_dl_class() #33
  store i8 1, ptr @sched_smp_initialized, align 1
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_init_domains(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @sched_init_granularity() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_sched_rt_class() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_sched_dl_class() local_unnamed_addr #2

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define internal i32 @migration_init() #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %call1 = tail call i32 @sched_cpu_starting(i32 noundef %3)
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i32 @in_sched_functions(i32 noundef %addr) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 @in_lock_functions(i32 noundef %addr) #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %lor.rhs, label %lor.end

lor.rhs:                                          ; preds = %entry
  %cmp.not = icmp ult i32 %addr, ptrtoint (ptr @__sched_text_start to i32)
  br i1 %cmp.not, label %lor.end, label %land.rhs

land.rhs:                                         ; preds = %lor.rhs
  %cmp1 = icmp ult i32 %addr, ptrtoint (ptr @__sched_text_end to i32)
  %phi.cast = zext i1 %cmp1 to i32
  br label %lor.end

lor.end:                                          ; preds = %land.rhs, %lor.rhs, %entry
  %0 = phi i32 [ 1, %entry ], [ 0, %lor.rhs ], [ %phi.cast, %land.rhs ]
  ret i32 %0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @in_lock_functions(i32 noundef) local_unnamed_addr #2

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_init() local_unnamed_addr #11 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  br i1 select (i1 icmp ne (ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 1), ptr @fair_sched_class), i1 true, i1 select (i1 icmp ne (ptr getelementptr inbounds (%struct.sched_class, ptr @fair_sched_class, i32 1), ptr @rt_sched_class), i1 true, i1 icmp ne (ptr getelementptr inbounds (%struct.sched_class, ptr @rt_sched_class, i32 1), ptr @dl_sched_class))), label %do.body2, label %do.body8, !prof !1192

do.body2:                                         ; preds = %entry
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 9307, 0\0A.popsection", ""() #33, !srcloc !1324
  unreachable

do.body8:                                         ; preds = %entry
  br i1 icmp ne (ptr getelementptr inbounds (%struct.sched_class, ptr @dl_sched_class, i32 1), ptr @stop_sched_class), label %do.body12, label %do.end20, !prof !1192

do.body12:                                        ; preds = %do.body8
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 9309, 0\0A.popsection", ""() #33, !srcloc !1325
  unreachable

do.end20:                                         ; preds = %do.body8
  tail call void @wait_bit_init() #39
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %add24 = shl i32 %0, 4
  %tobool25.not = icmp eq i32 %add24, 0
  br i1 %tobool25.not, label %if.end35, label %if.end8.i.i

if.end8.i.i:                                      ; preds = %do.end20
  %call9.i.i = tail call noalias align 128 ptr @__kmalloc(i32 noundef %add24, i32 noundef 2304) #38
  %1 = ptrtoint ptr %call9.i.i to i32
  store ptr %call9.i.i, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 1), align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %2 = load i32, ptr @nr_cpu_ids, align 4
  %mul27 = shl i32 %2, 2
  %add28 = add i32 %mul27, %1
  %3 = inttoptr i32 %add28 to ptr
  store ptr %3, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 2), align 4
  %add30 = add i32 %add28, %mul27
  store i32 1024, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 3), align 16
  tail call void @init_cfs_bandwidth(ptr noundef getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 16)) #33
  %4 = inttoptr i32 %add30 to ptr
  store ptr %4, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 7), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %5 = load i32, ptr @nr_cpu_ids, align 4
  %mul31 = shl i32 %5, 2
  %add32 = add i32 %mul31, %add30
  %6 = inttoptr i32 %add32 to ptr
  store ptr %6, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 8), align 8
  br label %if.end35

if.end35:                                         ; preds = %if.end8.i.i, %do.end20
  %call36270 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %cmp271 = icmp ult i32 %call36270, %7
  br i1 %cmp271, label %if.end5.i.i, label %for.end

if.end5.i.i:                                      ; preds = %if.end5.i.i, %if.end35
  %8 = phi i32 [ %20, %if.end5.i.i ], [ %7, %if.end35 ]
  %call36272 = phi i32 [ %call36, %if.end5.i.i ], [ %call36270, %if.end35 ]
  %sub.i = add i32 %8, 31
  %9 = lshr i32 %sub.i, 3
  %mul.i = and i32 %9, 536870908
  %call.i4.i.i = tail call noalias align 128 ptr @__kmalloc(i32 noundef %mul.i, i32 noundef 3520) #38
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call36272
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add43 = add i32 %11, ptrtoint (ptr @load_balance_mask to i32)
  %12 = inttoptr i32 %add43 to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_store4_noabort(i32 %13)
  store ptr %call.i4.i.i, ptr %12, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %14 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i223 = add i32 %14, 31
  %15 = lshr i32 %sub.i223, 3
  %mul.i224 = and i32 %15, 536870908
  %call.i4.i.i246 = tail call noalias align 128 ptr @__kmalloc(i32 noundef %mul.i224, i32 noundef 3520) #38
  %16 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %arrayidx, align 4
  %add54 = add i32 %17, ptrtoint (ptr @select_idle_mask to i32)
  %18 = inttoptr i32 %add54 to ptr
  %19 = ptrtoint ptr %18 to i32
  call void @__asan_store4_noabort(i32 %19)
  store ptr %call.i4.i.i246, ptr %18, align 4
  %call36 = tail call i32 @cpumask_next(i32 noundef %call36272, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %20 = load i32, ptr @nr_cpu_ids, align 4
  %cmp = icmp ult i32 %call36, %20
  br i1 %cmp, label %if.end5.i.i, label %for.end

for.end:                                          ; preds = %if.end5.i.i, %if.end35
  %21 = load i32, ptr @sysctl_sched_rt_period, align 4
  %conv.i = zext i32 %21 to i64
  %mul.i250 = mul nuw nsw i64 %conv.i, 1000
  %22 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %cmp.i = icmp slt i32 %22, 0
  %conv.i251 = sext i32 %22 to i64
  %mul.i252 = mul nsw i64 %conv.i251, 1000
  %retval.0.i = select i1 %cmp.i, i64 -1, i64 %mul.i252
  tail call void @init_rt_bandwidth(ptr noundef nonnull @def_rt_bandwidth, i64 noundef %mul.i250, i64 noundef %retval.0.i) #33
  %23 = load i32, ptr @sysctl_sched_rt_period, align 4
  %conv.i253 = zext i32 %23 to i64
  %mul.i254 = mul nuw nsw i64 %conv.i253, 1000
  %24 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %cmp.i255 = icmp slt i32 %24, 0
  %conv.i256 = sext i32 %24 to i64
  %mul.i257 = mul nsw i64 %conv.i256, 1000
  %retval.0.i258 = select i1 %cmp.i255, i64 -1, i64 %mul.i257
  tail call void @init_dl_bandwidth(ptr noundef nonnull @def_dl_bandwidth, i64 noundef %mul.i254, i64 noundef %retval.0.i258) #33
  tail call void @init_defrootdomain() #33
  %25 = load i32, ptr @sysctl_sched_rt_period, align 4
  %conv.i259 = zext i32 %25 to i64
  %mul.i260 = mul nuw nsw i64 %conv.i259, 1000
  %26 = load i32, ptr @sysctl_sched_rt_runtime, align 4
  %cmp.i261 = icmp slt i32 %26, 0
  %conv.i262 = sext i32 %26 to i64
  %mul.i263 = mul nsw i64 %conv.i262, 1000
  %retval.0.i264 = select i1 %cmp.i261, i64 -1, i64 %mul.i263
  tail call void @init_rt_bandwidth(ptr noundef getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 9), i64 noundef %mul.i260, i64 noundef %retval.0.i264) #33
  %call61 = tail call ptr @kmem_cache_create(ptr noundef nonnull @.str.69, i32 noundef 768, i32 noundef 128, i32 noundef 0, ptr noundef null) #33
  store ptr %call61, ptr @task_group_cache, align 4
  %27 = load ptr, ptr @task_groups, align 4
  %call.i.i265 = tail call zeroext i1 @__list_add_valid(ptr noundef getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 11), ptr noundef nonnull @task_groups, ptr noundef %27) #33
  br i1 %call.i.i265, label %if.end.i.i266, label %list_add.exit

if.end.i.i266:                                    ; preds = %for.end
  %prev1.i.i = getelementptr inbounds %struct.list_head, ptr %27, i32 0, i32 1
  %28 = ptrtoint ptr %prev1.i.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 11), ptr %prev1.i.i, align 4
  store ptr %27, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 11), align 16
  store ptr @task_groups, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 11, i32 1), align 4
  store volatile ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 11), ptr @task_groups, align 4
  br label %list_add.exit

list_add.exit:                                    ; preds = %if.end.i.i266, %for.end
  store volatile ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 14), ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 14), align 4
  store ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 14), ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 14, i32 1), align 8
  store volatile ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 13), ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 13), align 4
  store ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 13), ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 13, i32 1), align 32
  tail call void @autogroup_init(ptr noundef nonnull @init_task) #33
  %call63273 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %29 = load i32, ptr @nr_cpu_ids, align 4
  %cmp64274 = icmp ult i32 %call63273, %29
  br i1 %cmp64274, label %for.body65, label %for.end90

for.body65:                                       ; preds = %for.body65, %list_add.exit
  %call63275 = phi i32 [ %call63, %for.body65 ], [ %call63273, %list_add.exit ]
  %arrayidx73 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call63275
  %30 = ptrtoint ptr %arrayidx73 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx73, align 4
  %add74 = add i32 %31, ptrtoint (ptr @runqueues to i32)
  %32 = inttoptr i32 %add74 to ptr
  tail call void @__raw_spin_lock_init(ptr noundef %32, ptr noundef nonnull @.str.70, ptr noundef nonnull @sched_init.__key, i16 noundef signext 2) #33
  %nr_running = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 1
  %33 = ptrtoint ptr %nr_running to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 0, ptr %nr_running, align 4
  %calc_load_active = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 64
  %34 = ptrtoint ptr %calc_load_active to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 0, ptr %calc_load_active, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %35 = load volatile i32, ptr @jiffies, align 128
  %add78 = add i32 %35, 501
  %calc_load_update = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 63
  %36 = ptrtoint ptr %calc_load_update to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 %add78, ptr %calc_load_update, align 8
  %cfs = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 14
  tail call void @init_cfs_rq(ptr noundef %cfs) #33
  %rt = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 15
  tail call void @init_rt_rq(ptr noundef %rt) #33
  %dl = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 16
  tail call void @init_dl_rq(ptr noundef %dl) #33
  %leaf_cfs_rq_list = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 17
  %37 = ptrtoint ptr %leaf_cfs_rq_list to i32
  call void @__asan_store4_noabort(i32 %37)
  store volatile ptr %leaf_cfs_rq_list, ptr %leaf_cfs_rq_list, align 4
  %prev.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 17, i32 1
  %38 = ptrtoint ptr %prev.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store ptr %leaf_cfs_rq_list, ptr %prev.i, align 4
  %tmp_alone_branch = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 18
  %39 = ptrtoint ptr %tmp_alone_branch to i32
  call void @__asan_store4_noabort(i32 %39)
  store ptr %leaf_cfs_rq_list, ptr %tmp_alone_branch, align 128
  tail call void @init_tg_cfs_entry(ptr noundef nonnull @root_task_group, ptr noundef %cfs, ptr noundef null, i32 noundef %call63275, ptr noundef null) #33
  call void @__asan_load8_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.rt_bandwidth, ptr @def_rt_bandwidth, i32 0, i32 2) to i32))
  %40 = load i64, ptr getelementptr inbounds (%struct.rt_bandwidth, ptr @def_rt_bandwidth, i32 0, i32 2), align 8
  %rt_runtime = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 15, i32 11
  %41 = ptrtoint ptr %rt_runtime to i32
  call void @__asan_store8_noabort(i32 %41)
  store i64 %40, ptr %rt_runtime, align 8
  tail call void @init_tg_rt_entry(ptr noundef nonnull @root_task_group, ptr noundef %rt, ptr noundef null, i32 noundef %call63275, ptr noundef null) #33
  %sd = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 36
  %42 = ptrtoint ptr %sd to i32
  call void @__asan_store4_noabort(i32 %42)
  store ptr null, ptr %sd, align 4
  %rd = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 35
  %43 = ptrtoint ptr %rd to i32
  call void @__asan_store4_noabort(i32 %43)
  store ptr null, ptr %rd, align 8
  %cpu_capacity_orig = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 38
  %44 = ptrtoint ptr %cpu_capacity_orig to i32
  call void @__asan_store4_noabort(i32 %44)
  store i32 1024, ptr %cpu_capacity_orig, align 4
  %cpu_capacity = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 37
  %45 = ptrtoint ptr %cpu_capacity to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 1024, ptr %cpu_capacity, align 16
  %balance_callback = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 39
  %46 = ptrtoint ptr %balance_callback to i32
  call void @__asan_store4_noabort(i32 %46)
  store ptr @balance_push_callback, ptr %balance_callback, align 8
  %active_balance = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 43
  %47 = ptrtoint ptr %active_balance to i32
  call void @__asan_store4_noabort(i32 %47)
  store i32 0, ptr %active_balance, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %48 = load volatile i32, ptr @jiffies, align 128
  %next_balance = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 23
  %49 = ptrtoint ptr %next_balance to i32
  call void @__asan_store4_noabort(i32 %49)
  store i32 %48, ptr %next_balance, align 4
  %push_cpu = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 44
  %50 = ptrtoint ptr %push_cpu to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 0, ptr %push_cpu, align 8
  %cpu = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 46
  %51 = ptrtoint ptr %cpu to i32
  call void @__asan_store4_noabort(i32 %51)
  store i32 %call63275, ptr %cpu, align 4
  %online = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 47
  %52 = ptrtoint ptr %online to i32
  call void @__asan_store4_noabort(i32 %52)
  store i32 0, ptr %online, align 8
  %idle_stamp = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 54
  %53 = ptrtoint ptr %idle_stamp to i32
  call void @__asan_store8_noabort(i32 %53)
  store i64 0, ptr %idle_stamp, align 128
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sysctl_sched_migration_cost to i32))
  %54 = load i32, ptr @sysctl_sched_migration_cost, align 4
  %mul83 = shl i32 %54, 1
  %conv = zext i32 %mul83 to i64
  %avg_idle = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 55
  %55 = ptrtoint ptr %avg_idle to i32
  call void @__asan_store8_noabort(i32 %55)
  store i64 %conv, ptr %avg_idle, align 8
  %56 = load volatile i32, ptr @jiffies, align 128
  %wake_stamp = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 56
  %57 = ptrtoint ptr %wake_stamp to i32
  call void @__asan_store4_noabort(i32 %57)
  store i32 %56, ptr %wake_stamp, align 16
  %wake_avg_idle = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 57
  %58 = ptrtoint ptr %wake_avg_idle to i32
  call void @__asan_store8_noabort(i32 %58)
  store i64 %conv, ptr %wake_avg_idle, align 8
  %conv85 = zext i32 %54 to i64
  %max_idle_balance_cost = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 58
  %59 = ptrtoint ptr %max_idle_balance_cost to i32
  call void @__asan_store8_noabort(i32 %59)
  store i64 %conv85, ptr %max_idle_balance_cost, align 32
  %cfs_tasks = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 48
  %60 = ptrtoint ptr %cfs_tasks to i32
  call void @__asan_store4_noabort(i32 %60)
  store volatile ptr %cfs_tasks, ptr %cfs_tasks, align 4
  %prev.i267 = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 48, i32 1
  %61 = ptrtoint ptr %prev.i267 to i32
  call void @__asan_store4_noabort(i32 %61)
  store ptr %cfs_tasks, ptr %prev.i267, align 4
  tail call void @rq_attach_root(ptr noundef %32, ptr noundef nonnull @def_root_domain) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %62 = load volatile i32, ptr @jiffies, align 128
  %last_blocked_load_update_tick = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 2
  %63 = ptrtoint ptr %last_blocked_load_update_tick to i32
  call void @__asan_store4_noabort(i32 %63)
  store i32 %62, ptr %last_blocked_load_update_tick, align 16
  %nohz_flags = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 7
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %nohz_flags, i32 noundef 4) #33
  %64 = ptrtoint ptr %nohz_flags to i32
  call void @__asan_store4_noabort(i32 %64)
  store volatile i32 0, ptr %nohz_flags, align 4
  %nohz_csd = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 5
  %65 = ptrtoint ptr %nohz_csd to i32
  call void @__asan_store8_noabort(i32 %65)
  store i64 0, ptr %nohz_csd, align 64
  %.compoundliteral.sroa.2.0.nohz_csd.sroa_idx = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 5, i32 1
  %66 = ptrtoint ptr %.compoundliteral.sroa.2.0.nohz_csd.sroa_idx to i32
  call void @__asan_store4_noabort(i32 %66)
  store ptr @nohz_csd_func, ptr %.compoundliteral.sroa.2.0.nohz_csd.sroa_idx, align 8
  %.compoundliteral.sroa.3.0.nohz_csd.sroa_idx = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 5, i32 2
  %67 = ptrtoint ptr %.compoundliteral.sroa.3.0.nohz_csd.sroa_idx to i32
  call void @__asan_store4_noabort(i32 %67)
  store ptr %32, ptr %.compoundliteral.sroa.3.0.nohz_csd.sroa_idx, align 4
  %hotplug_wait = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 59
  %68 = ptrtoint ptr %hotplug_wait to i32
  call void @__asan_store4_noabort(i32 %68)
  store ptr null, ptr %hotplug_wait, align 4
  %hrtick_csd.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 65
  %69 = ptrtoint ptr %hrtick_csd.i to i32
  call void @__asan_store8_noabort(i32 %69)
  store i64 0, ptr %hrtick_csd.i, align 16
  %.compoundliteral.sroa.2.0.hrtick_csd.sroa_idx.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 65, i32 1
  %70 = ptrtoint ptr %.compoundliteral.sroa.2.0.hrtick_csd.sroa_idx.i to i32
  call void @__asan_store4_noabort(i32 %70)
  store ptr @__hrtick_start, ptr %.compoundliteral.sroa.2.0.hrtick_csd.sroa_idx.i, align 8
  %.compoundliteral.sroa.3.0.hrtick_csd.sroa_idx.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 65, i32 2
  %71 = ptrtoint ptr %.compoundliteral.sroa.3.0.hrtick_csd.sroa_idx.i to i32
  call void @__asan_store4_noabort(i32 %71)
  store ptr %32, ptr %.compoundliteral.sroa.3.0.hrtick_csd.sroa_idx.i, align 4
  %hrtick_timer.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 66
  tail call void @hrtimer_init(ptr noundef %hrtick_timer.i, i32 noundef 1, i32 noundef 9) #33
  %function.i = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 66, i32 2
  %72 = ptrtoint ptr %function.i to i32
  call void @__asan_store4_noabort(i32 %72)
  store ptr @hrtick, ptr %function.i, align 32
  %nr_iowait = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 31
  %call.i.i203 = tail call zeroext i1 @__kasan_check_write(ptr noundef %nr_iowait, i32 noundef 4) #33
  %73 = ptrtoint ptr %nr_iowait to i32
  call void @__asan_store4_noabort(i32 %73)
  store volatile i32 0, ptr %nr_iowait, align 4
  %core = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 79
  %74 = ptrtoint ptr %core to i32
  call void @__asan_store4_noabort(i32 %74)
  store ptr %32, ptr %core, align 8
  %core_pick = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 80
  %75 = ptrtoint ptr %core_pick to i32
  call void @__asan_store4_noabort(i32 %75)
  store ptr null, ptr %core_pick, align 4
  %core_enabled = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 81
  %76 = ptrtoint ptr %core_enabled to i32
  call void @__asan_store4_noabort(i32 %76)
  store i32 0, ptr %core_enabled, align 128
  %core_tree = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 83
  %77 = ptrtoint ptr %core_tree to i32
  call void @__asan_store4_noabort(i32 %77)
  store ptr null, ptr %core_tree, align 8
  %core_forceidle_count = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 87
  %78 = ptrtoint ptr %core_forceidle_count to i32
  call void @__asan_store4_noabort(i32 %78)
  store i32 0, ptr %core_forceidle_count, align 8
  %core_forceidle_occupation = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 89
  %79 = ptrtoint ptr %core_forceidle_occupation to i32
  call void @__asan_store4_noabort(i32 %79)
  store i32 0, ptr %core_forceidle_occupation, align 32
  %core_forceidle_start = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 90
  %80 = ptrtoint ptr %core_forceidle_start to i32
  call void @__asan_store8_noabort(i32 %80)
  store i64 0, ptr %core_forceidle_start, align 8
  %core_cookie = getelementptr inbounds %struct.rq, ptr %32, i32 0, i32 86
  %81 = ptrtoint ptr %core_cookie to i32
  call void @__asan_store4_noabort(i32 %81)
  store i32 0, ptr %core_cookie, align 4
  %call63 = tail call i32 @cpumask_next(i32 noundef %call63275, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %82 = load i32, ptr @nr_cpu_ids, align 4
  %cmp64 = icmp ult i32 %call63, %82
  br i1 %cmp64, label %for.body65, label %for.end90

for.end90:                                        ; preds = %for.body65, %list_add.exit
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 31) to i32))
  %83 = load i32, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 31), align 4
  %cmp.i.i.not.i = icmp eq i32 %83, 5
  br i1 %cmp.i.i.not.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %for.end90
  call void @__asan_store4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18) to i32))
  store i32 3, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18), align 128
  br label %set_load_weight.exit

if.end.i:                                         ; preds = %for.end90
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 14) to i32))
  %84 = load i32, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 14), align 4
  %sub.i268 = add i32 %84, -100
  %arrayidx.i = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %sub.i268
  %85 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %85)
  %86 = load i32, ptr %arrayidx.i, align 4
  call void @__asan_store4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18) to i32))
  store i32 %86, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18), align 128
  %arrayidx5.i = getelementptr [40 x i32], ptr @sched_prio_to_wmult, i32 0, i32 %sub.i268
  %87 = ptrtoint ptr %arrayidx5.i to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load i32, ptr %arrayidx5.i, align 4
  br label %set_load_weight.exit

set_load_weight.exit:                             ; preds = %if.end.i, %if.then.i
  %storemerge = phi i32 [ %88, %if.end.i ], [ 1431655765, %if.then.i ]
  call void @__asan_store4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18, i32 0, i32 1) to i32))
  store i32 %storemerge, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 18, i32 0, i32 1), align 4
  %call.i.i.i269 = tail call zeroext i1 @__kasan_check_write(ptr noundef getelementptr inbounds (%struct.mm_struct, ptr @init_mm, i32 0, i32 0, i32 11), i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr getelementptr inbounds (%struct.mm_struct, ptr @init_mm, i32 0, i32 0, i32 11), i32 1, i32 3, i32 1) #33
  %89 = tail call { i32, i32 } asm sideeffect "@ atomic_add\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) getelementptr inbounds (%struct.mm_struct, ptr @init_mm, i32 0, i32 0, i32 11), ptr getelementptr inbounds (%struct.mm_struct, ptr @init_mm, i32 0, i32 0, i32 11), i32 1, ptr elementtype(i32) getelementptr inbounds (%struct.mm_struct, ptr @init_mm, i32 0, i32 0, i32 11)) #33, !srcloc !1200
  %90 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %90, -16384
  %91 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %91, i32 0, i32 2
  %92 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %92)
  %93 = load ptr, ptr %task, align 8
  %call94 = tail call zeroext i1 @set_kthread_struct(ptr noundef %93) #33
  br i1 %call94, label %if.end118, label %do.end112, !prof !1191

do.end112:                                        ; preds = %set_load_weight.exit
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 9471, i32 noundef 9, ptr noundef null) #33
  br label %if.end118

if.end118:                                        ; preds = %do.end112, %set_load_weight.exit
  %94 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %task, align 8
  %cpu129 = getelementptr inbounds %struct.thread_info, ptr %91, i32 0, i32 3
  %96 = ptrtoint ptr %cpu129 to i32
  call void @__asan_load4_noabort(i32 %96)
  %97 = load i32, ptr %cpu129, align 4
  tail call void @init_idle(ptr noundef %95, i32 noundef %97) #41
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %98 = load volatile i32, ptr @jiffies, align 128
  %add130 = add i32 %98, 501
  call void @__asan_store4_noabort(i32 ptrtoint (ptr @calc_load_update to i32))
  store i32 %add130, ptr @calc_load_update, align 4
  tail call void @idle_thread_set_boot_cpu() #33
  %99 = ptrtoint ptr %cpu129 to i32
  call void @__asan_load4_noabort(i32 %99)
  %100 = load i32, ptr %cpu129, align 4
  tail call fastcc void @balance_push_set(i32 noundef %100, i1 noundef zeroext false)
  tail call void @init_sched_fair_class() #33
  tail call void @psi_init() #33
  tail call fastcc void @init_uclamp() #41
  store i32 1, ptr @scheduler_running, align 4
  ret void
}

; Function Attrs: cold null_pointer_is_valid
declare dso_local void @wait_bit_init() local_unnamed_addr #10 section ".init.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_cfs_bandwidth(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_rt_bandwidth(ptr noundef, i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_dl_bandwidth(ptr noundef, i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_defrootdomain() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @kmem_cache_create(ptr noundef, i32 noundef, i32 noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @autogroup_init(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__raw_spin_lock_init(ptr noundef, ptr noundef, ptr noundef, i16 noundef signext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_cfs_rq(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_rt_rq(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_dl_rq(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_tg_cfs_entry(ptr noundef, ptr noundef, ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_tg_rt_entry(ptr noundef, ptr noundef, ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @rq_attach_root(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @nohz_csd_func(ptr nocapture noundef %info) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cpu.i = getelementptr inbounds %struct.rq, ptr %info, i32 0, i32 46
  %0 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %cpu.i, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %1
  %2 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %arrayidx, align 4
  %add = add i32 %3, ptrtoint (ptr @runqueues to i32)
  %4 = inttoptr i32 %add to ptr
  %nohz_flags = getelementptr inbounds %struct.rq, ptr %4, i32 0, i32 7
  %call.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %nohz_flags, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1326
  tail call void @llvm.prefetch.p0(ptr %nohz_flags, i32 1, i32 3, i32 1) #33
  %5 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_andnot\0A1:\09ldrex\09$0, [$4]\0A\09bic\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %nohz_flags, ptr %nohz_flags, i32 15, ptr elementtype(i32) %nohz_flags) #33, !srcloc !1327
  %asmresult.i.i.i = extractvalue { i32, i32, i32 } %5, 0
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1328
  %and = and i32 %asmresult.i.i.i, 11
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %do.end14, label %if.end, !prof !1192

do.end14:                                         ; preds = %entry
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 1120, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end14, %entry
  %6 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %arrayidx, align 4
  %add.i = add i32 %7, ptrtoint (ptr @runqueues to i32)
  %8 = inttoptr i32 %add.i to ptr
  %curr.i = getelementptr inbounds %struct.rq, ptr %8, i32 0, i32 20
  %9 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %curr.i, align 8
  %idle.i = getelementptr inbounds %struct.rq, ptr %8, i32 0, i32 21
  %11 = ptrtoint ptr %idle.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %idle.i, align 4
  %cmp.not.i = icmp eq ptr %10, %12
  br i1 %cmp.not.i, label %if.end.i, label %idle_cpu.exit.thread

if.end.i:                                         ; preds = %if.end
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %8, i32 0, i32 1
  %13 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %nr_running.i, align 4
  %tobool.not.i = icmp eq i32 %14, 0
  br i1 %tobool.not.i, label %idle_cpu.exit, label %idle_cpu.exit.thread

idle_cpu.exit.thread:                             ; preds = %if.end.i, %if.end
  %idle_balance43 = getelementptr inbounds %struct.rq, ptr %info, i32 0, i32 41
  %15 = ptrtoint ptr %idle_balance43 to i32
  call void @__asan_store1_noabort(i32 %15)
  store i8 0, ptr %idle_balance43, align 1
  br label %if.end34

idle_cpu.exit:                                    ; preds = %if.end.i
  %ttwu_pending.i = getelementptr inbounds %struct.rq, ptr %8, i32 0, i32 8
  %16 = ptrtoint ptr %ttwu_pending.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %ttwu_pending.i, align 8
  %tobool4.not.i = icmp eq i32 %17, 0
  %conv = zext i1 %tobool4.not.i to i8
  %idle_balance = getelementptr inbounds %struct.rq, ptr %info, i32 0, i32 41
  %18 = ptrtoint ptr %idle_balance to i32
  call void @__asan_store1_noabort(i32 %18)
  store i8 %conv, ptr %idle_balance, align 1
  br i1 %tobool4.not.i, label %land.lhs.true, label %if.end34

land.lhs.true:                                    ; preds = %idle_cpu.exit
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %21 = ptrtoint ptr %20 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %20, align 16384
  %23 = and i32 %22, 2
  %tobool.i.not = icmp eq i32 %23, 0
  br i1 %tobool.i.not, label %if.then32, label %if.end34

if.then32:                                        ; preds = %land.lhs.true
  %conv33 = trunc i32 %asmresult.i.i.i to i8
  %nohz_idle_balance = getelementptr inbounds %struct.rq, ptr %info, i32 0, i32 40
  %24 = ptrtoint ptr %nohz_idle_balance to i32
  call void @__asan_store1_noabort(i32 %24)
  store i8 %conv33, ptr %nohz_idle_balance, align 4
  tail call void @raise_softirq_irqoff(i32 noundef 7) #33
  br label %if.end34

if.end34:                                         ; preds = %if.then32, %land.lhs.true, %idle_cpu.exit, %idle_cpu.exit.thread
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @set_kthread_struct(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @idle_thread_set_boot_cpu() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_sched_fair_class() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @psi_init() local_unnamed_addr #2

; Function Attrs: cold nofree nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define internal fastcc void @init_uclamp() unnamed_addr #17 section ".init.text" align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call33 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp34 = icmp ult i32 %call33, %0
  br i1 %cmp34, label %do.body, label %for.body4.preheader

do.body:                                          ; preds = %do.body, %entry
  %call35 = phi i32 [ %call, %do.body ], [ %call33, %entry ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call35
  %1 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx, align 4
  %add = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add to ptr
  %uclamp.i = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 11
  %arrayidx.i.c = getelementptr %struct.rq, ptr %3, i32 0, i32 11, i32 1
  %4 = call ptr @memset(ptr %uclamp.i, i32 0, i32 24)
  %5 = ptrtoint ptr %arrayidx.i.c to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 1024, ptr %arrayidx.i.c, align 4
  %.compoundliteral.sroa.3.0.arrayidx.sroa_idx.i.c = getelementptr %struct.rq, ptr %3, i32 0, i32 11, i32 1, i32 1
  %6 = call ptr @memset(ptr %.compoundliteral.sroa.3.0.arrayidx.sroa_idx.i.c, i32 0, i32 20)
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %3, i32 0, i32 12
  %7 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 1, ptr %uclamp_flags.i, align 16
  %call = tail call i32 @cpumask_next(i32 noundef %call35, ptr noundef nonnull @__cpu_possible_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %cmp = icmp ult i32 %call, %8
  br i1 %cmp, label %do.body, label %for.body4.preheader

for.body4.preheader:                              ; preds = %do.body, %entry
  br label %for.body4

for.body4:                                        ; preds = %for.body4, %for.body4.preheader
  %cmp.i = phi i1 [ false, %for.body4 ], [ true, %for.body4.preheader ]
  %clamp_id.036 = phi i32 [ 1, %for.body4 ], [ 0, %for.body4.preheader ]
  %arrayidx5 = getelementptr %struct.task_struct, ptr @init_task, i32 0, i32 26, i32 %clamp_id.036
  %9 = select i1 %cmp.i, i16 0, i16 1024
  %10 = ptrtoint ptr %arrayidx5 to i32
  call void @__asan_load2_noabort(i32 %10)
  %bf.load.i = load i16, ptr %arrayidx5, align 4
  %bf.shl.i = shl nuw i16 %9, 5
  %bf.clear.i = and i16 %bf.load.i, 2
  %bf.set.i = or i16 %bf.clear.i, %bf.shl.i
  %div8.i.i32 = udiv i16 %9, 205
  %.op.i = shl nuw nsw i16 %div8.i.i32, 2
  %.op.op.i = and i16 %.op.i, 28
  %bf.shl3.i = select i1 %cmp.i, i16 %.op.op.i, i16 16
  %bf.set5.i = or i16 %bf.set.i, %bf.shl3.i
  store i16 %bf.set5.i, ptr %arrayidx5, align 4
  br i1 %cmp.i, label %for.body4, label %for.body11

for.body11:                                       ; preds = %for.body4
  store i32 -2146369537, ptr @uclamp_default, align 4
  store i32 -2146369537, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18, i32 0), align 8
  store i32 -2146369537, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 19, i32 0), align 16
  store i32 -2146369537, ptr getelementptr inbounds ([2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 1), align 4
  store i32 -2146369537, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 18, i32 1), align 4
  store i32 -2146369537, ptr getelementptr inbounds (%struct.task_group, ptr @root_task_group, i32 0, i32 19, i32 1), align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @__might_sleep(ptr noundef %file, i32 noundef %line) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task, align 8
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %3, align 128
  %cmp.not = icmp eq i32 %5, 0
  br i1 %cmp.not, label %if.end42, label %land.rhs

land.rhs:                                         ; preds = %entry
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 212
  %6 = ptrtoint ptr %task_state_change to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %task_state_change, align 4
  %tobool.not = icmp eq i32 %7, 0
  br i1 %tobool.not, label %if.end42, label %land.rhs5

land.rhs5:                                        ; preds = %land.rhs
  %.b53 = load i1, ptr @__might_sleep.__already_done, align 1
  br i1 %.b53, label %if.end42, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs5
  store i1 true, ptr @__might_sleep.__already_done, align 1
  %8 = inttoptr i32 %7 to ptr
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 9512, i32 noundef 9, ptr noundef nonnull @.str.71, i32 noundef %5, ptr noundef nonnull %8, ptr noundef nonnull %8) #33
  br label %if.end42

if.end42:                                         ; preds = %if.then, %land.rhs5, %land.rhs, %entry
  tail call void @__might_resched(ptr noundef %file, i32 noundef %line, i32 noundef 0)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @__might_resched(ptr noundef %file, i32 noundef %line, i32 noundef %offsets) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_lock_map, i32 noundef -1) #33
  %tobool.not.i = icmp eq i32 %call.i.i, 0
  br i1 %tobool.not.i, label %rcu_preempt_sleep_check.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool2.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool2.not.i, label %rcu_preempt_sleep_check.exit, label %land.lhs.true3.i

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %.b5.i = load i1, ptr @rcu_preempt_sleep_check.__warned, align 1
  br i1 %.b5.i, label %rcu_preempt_sleep_check.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true3.i
  store i1 true, ptr @rcu_preempt_sleep_check.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 329, ptr noundef nonnull @.str.243) #33
  br label %rcu_preempt_sleep_check.exit

rcu_preempt_sleep_check.exit:                     ; preds = %if.then.i, %land.lhs.true3.i, %land.lhs.true.i, %entry
  %call.i = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_bh_lock_map, i32 noundef -1) #33
  %tobool.not = icmp eq i32 %call.i, 0
  br i1 %tobool.not, label %do.body6, label %land.lhs.true

land.lhs.true:                                    ; preds = %rcu_preempt_sleep_check.exit
  %call2 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %do.body6, label %land.lhs.true4

land.lhs.true4:                                   ; preds = %land.lhs.true
  %.b146 = load i1, ptr @__might_resched.__warned, align 1
  br i1 %.b146, label %do.body6, label %if.then

if.then:                                          ; preds = %land.lhs.true4
  store i1 true, ptr @__might_resched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 9547, ptr noundef nonnull @.str.72) #33
  br label %do.body6

do.body6:                                         ; preds = %if.then, %land.lhs.true4, %land.lhs.true, %rcu_preempt_sleep_check.exit
  %call.i150 = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_sched_lock_map, i32 noundef -1) #33
  %tobool8.not = icmp eq i32 %call.i150, 0
  br i1 %tobool8.not, label %do.end19, label %land.lhs.true9

land.lhs.true9:                                   ; preds = %do.body6
  %call10 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool11.not = icmp eq i32 %call10, 0
  br i1 %tobool11.not, label %do.end19, label %land.lhs.true12

land.lhs.true12:                                  ; preds = %land.lhs.true9
  %.b144145 = load i1, ptr @__might_resched.__warned.73, align 1
  br i1 %.b144145, label %do.end19, label %if.then14

if.then14:                                        ; preds = %land.lhs.true12
  store i1 true, ptr @__might_resched.__warned.73, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 9547, ptr noundef nonnull @.str.74) #33
  br label %do.end19

do.end19:                                         ; preds = %if.then14, %land.lhs.true12, %land.lhs.true9, %do.body6
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %cmp.i = icmp eq i32 %3, %offsets
  br i1 %cmp.i, label %land.lhs.true21, label %lor.lhs.false

land.lhs.true21:                                  ; preds = %do.end19
  %4 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i151 = and i32 %4, 128
  %tobool34.not = icmp eq i32 %and.i151, 0
  br i1 %tobool34.not, label %land.lhs.true35, label %lor.lhs.false

land.lhs.true35:                                  ; preds = %land.lhs.true21
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i152 = and i32 %5, -16384
  %6 = inttoptr i32 %and.i152 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %7 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %task, align 8
  %flags.i = getelementptr inbounds %struct.task_struct, ptr %8, i32 0, i32 3
  %9 = ptrtoint ptr %flags.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %flags.i, align 4
  %and.i = and i32 %10, 2
  %tobool.i.not = icmp eq i32 %and.i, 0
  br i1 %tobool.i.not, label %land.lhs.true38, label %lor.lhs.false

land.lhs.true38:                                  ; preds = %land.lhs.true35
  %non_block_count = getelementptr inbounds %struct.task_struct, ptr %8, i32 0, i32 134
  %11 = ptrtoint ptr %non_block_count to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %non_block_count, align 8
  %tobool41.not = icmp eq i32 %12, 0
  br i1 %tobool41.not, label %cleanup, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %land.lhs.true38, %land.lhs.true35, %land.lhs.true21, %do.end19
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @system_state to i32))
  %13 = load i32, ptr @system_state, align 4
  %14 = add i32 %13, -4
  %15 = icmp ult i32 %14, -3
  br i1 %15, label %cleanup, label %lor.lhs.false47

lor.lhs.false47:                                  ; preds = %lor.lhs.false
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %16 = load i32, ptr @oops_in_progress, align 4
  %tobool48.not = icmp eq i32 %16, 0
  br i1 %tobool48.not, label %if.end50, label %cleanup

if.end50:                                         ; preds = %lor.lhs.false47
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %17 = load volatile i32, ptr @jiffies, align 128
  %18 = load i32, ptr @__might_resched.prev_jiffy, align 4
  %add.neg = add i32 %17, -100
  %sub = sub i32 %add.neg, %18
  %cmp51 = icmp sgt i32 %sub, -1
  %tobool54.not = icmp eq i32 %18, 0
  %or.cond147 = or i1 %cmp51, %tobool54.not
  br i1 %or.cond147, label %if.end56, label %cleanup

if.end56:                                         ; preds = %if.end50
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %19 = load volatile i32, ptr @jiffies, align 128
  store i32 %19, ptr @__might_resched.prev_jiffy, align 4
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i153 = and i32 %20, -16384
  %21 = inttoptr i32 %and.i153 to ptr
  %task58 = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 2
  %call64 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.75, ptr noundef %file, i32 noundef %line) #39
  %22 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %cmp70 = icmp ne i32 %25, 0
  %conv71 = zext i1 %cmp70 to i32
  %26 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i154 = and i32 %26, 128
  %27 = ptrtoint ptr %task58 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task58, align 8
  %non_block_count92 = getelementptr inbounds %struct.task_struct, ptr %28, i32 0, i32 134
  %29 = ptrtoint ptr %non_block_count92 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %non_block_count92, align 8
  %pid = getelementptr inbounds %struct.task_struct, ptr %28, i32 0, i32 68
  %31 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %pid, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %28, i32 0, i32 101
  %call97 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.78, i32 noundef %conv71, i32 noundef %and.i154, i32 noundef %30, i32 noundef %32, ptr noundef %comm) #39
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i148 = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i148 to ptr
  %preempt_count.i149 = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i149 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i149, align 4
  %and = and i32 %offsets, 255
  %call103 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.81, i32 noundef %36, i32 noundef %and) #39
  %37 = ptrtoint ptr %task58 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %task58, align 8
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %38, i32 0, i32 1
  %39 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %stack.i, align 4
  %add.ptr.i = getelementptr %struct.thread_info, ptr %40, i32 1
  %41 = ptrtoint ptr %add.ptr.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %add.ptr.i, align 4
  %cmp107.not = icmp eq i32 %42, 1470918301
  br i1 %cmp107.not, label %if.end115, label %do.end112

do.end112:                                        ; preds = %if.end56
  %call114 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.84) #39
  br label %if.end115

if.end115:                                        ; preds = %do.end112, %if.end56
  %43 = ptrtoint ptr %task58 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %task58, align 8
  tail call void @debug_show_held_locks(ptr noundef %44) #33
  %45 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i155 = and i32 %45, 128
  %tobool136.not = icmp eq i32 %and.i155, 0
  br i1 %tobool136.not, label %if.end140, label %if.then137

if.then137:                                       ; preds = %if.end115
  %46 = ptrtoint ptr %task58 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %task58, align 8
  tail call void @print_irqtrace_events(ptr noundef %47) #33
  br label %if.end140

if.end140:                                        ; preds = %if.then137, %if.end115
  tail call void @dump_stack() #39
  tail call void @add_taint(i32 noundef 9, i32 noundef 0) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end140, %if.end50, %lor.lhs.false47, %lor.lhs.false, %land.lhs.true38
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @debug_show_held_locks(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @print_irqtrace_events(ptr noundef) local_unnamed_addr #2

; Function Attrs: cold null_pointer_is_valid
declare dso_local void @dump_stack() local_unnamed_addr #10

; Function Attrs: null_pointer_is_valid
declare dso_local void @add_taint(i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @__cant_sleep(ptr noundef %file, i32 noundef %line, i32 noundef %preempt_offset) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i = and i32 %0, 128
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i, align 4
  %cmp11 = icmp sgt i32 %4, %preempt_offset
  br i1 %cmp11, label %return, label %if.end14

if.end14:                                         ; preds = %if.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %5 = load volatile i32, ptr @jiffies, align 128
  %6 = load i32, ptr @__cant_sleep.prev_jiffy, align 4
  %add.neg = add i32 %5, -100
  %sub = sub i32 %add.neg, %6
  %cmp15 = icmp sgt i32 %sub, -1
  %tobool17.not = icmp eq i32 %6, 0
  %or.cond = or i1 %cmp15, %tobool17.not
  br i1 %or.cond, label %if.end19, label %return

if.end19:                                         ; preds = %if.end14
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %7 = load volatile i32, ptr @jiffies, align 128
  store i32 %7, ptr @__cant_sleep.prev_jiffy, align 4
  %call24 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.86, ptr noundef %file, i32 noundef %line) #39
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i56 = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i56 to ptr
  %preempt_count.i57 = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i57 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i57, align 4
  %cmp30 = icmp ne i32 %11, 0
  %conv31 = zext i1 %cmp30 to i32
  %12 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i58 = and i32 %12, 128
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i59 = and i32 %13, -16384
  %14 = inttoptr i32 %and.i59 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %pid = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 68
  %17 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %pid, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 101
  %call53 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.89, i32 noundef %conv31, i32 noundef %and.i58, i32 noundef %18, ptr noundef %comm) #39
  %19 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task, align 8
  tail call void @debug_show_held_locks(ptr noundef %20) #33
  tail call void @dump_stack() #39
  tail call void @add_taint(i32 noundef 9, i32 noundef 0) #33
  br label %return

return:                                           ; preds = %if.end19, %if.end14, %if.end, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @__cant_migrate(ptr noundef %file, i32 noundef %line) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i = and i32 %0, 128
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i67 = and i32 %1, -16384
  %2 = inttoptr i32 %and.i67 to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 37
  %5 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %5)
  %6 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %6, 0
  br i1 %tobool.i.not, label %if.end13, label %return

if.end13:                                         ; preds = %if.end
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %7 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %preempt_count.i, align 4
  %cmp15 = icmp sgt i32 %8, 0
  br i1 %cmp15, label %return, label %if.end18

if.end18:                                         ; preds = %if.end13
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %9 = load volatile i32, ptr @jiffies, align 128
  %10 = load i32, ptr @__cant_migrate.prev_jiffy, align 4
  %add.neg = add i32 %9, -100
  %sub = sub i32 %add.neg, %10
  %cmp19 = icmp sgt i32 %sub, -1
  %tobool21.not = icmp eq i32 %10, 0
  %or.cond = or i1 %cmp19, %tobool21.not
  br i1 %or.cond, label %if.end23, label %return

if.end23:                                         ; preds = %if.end18
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %11 = load volatile i32, ptr @jiffies, align 128
  store i32 %11, ptr @__cant_migrate.prev_jiffy, align 4
  %call28 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.91, ptr noundef %file, i32 noundef %line) #39
  %12 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i65 = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i65 to ptr
  %preempt_count.i66 = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i66 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i66, align 4
  %cmp34 = icmp ne i32 %15, 0
  %conv35 = zext i1 %cmp34 to i32
  %16 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i68 = and i32 %16, 128
  %17 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task, align 8
  %migration_disabled.i69 = getelementptr inbounds %struct.task_struct, ptr %18, i32 0, i32 37
  %19 = ptrtoint ptr %migration_disabled.i69 to i32
  call void @__asan_load2_noabort(i32 %19)
  %20 = load i16, ptr %migration_disabled.i69, align 4
  %tobool.i70 = icmp ne i16 %20, 0
  %conv57 = zext i1 %tobool.i70 to i32
  %pid = getelementptr inbounds %struct.task_struct, ptr %18, i32 0, i32 68
  %21 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %pid, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %18, i32 0, i32 101
  %call62 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.94, i32 noundef %conv35, i32 noundef %and.i68, i32 noundef %conv57, i32 noundef %22, ptr noundef %comm) #39
  %23 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %task, align 8
  tail call void @debug_show_held_locks(ptr noundef %24) #33
  tail call void @dump_stack() #39
  tail call void @add_taint(i32 noundef 9, i32 noundef 0) #33
  br label %return

return:                                           ; preds = %if.end23, %if.end18, %if.end13, %if.end, %entry
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @normalize_rt_tasks() local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr = alloca %struct.sched_attr, align 8
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr) #33
  %0 = call ptr @memset(ptr %attr, i32 0, i32 56)
  tail call void @_raw_read_lock(ptr noundef nonnull @tasklist_lock) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50) to i32))
  %1 = load volatile ptr, ptr getelementptr inbounds (%struct.task_struct, ptr @init_task, i32 0, i32 50), align 16
  %add.ptr121 = getelementptr i8, ptr %1, i32 -1136
  %cmp.not122 = icmp eq ptr %add.ptr121, @init_task
  br i1 %cmp.not122, label %for.end90, label %do.body2

for.cond.loopexit:                                ; preds = %for.inc, %do.end8
  %2 = ptrtoint ptr %4 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile ptr, ptr %4, align 16
  %add.ptr = getelementptr i8, ptr %3, i32 -1136
  %cmp.not = icmp eq ptr %add.ptr, @init_task
  br i1 %cmp.not, label %for.end90, label %do.body2

do.body2:                                         ; preds = %for.cond.loopexit, %entry
  %4 = phi ptr [ %3, %for.cond.loopexit ], [ %1, %entry ]
  %call = call i32 @rcu_read_lock_any_held() #33
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %land.lhs.true, label %do.end8

land.lhs.true:                                    ; preds = %do.body2
  %call3 = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool4.not = icmp eq i32 %call3, 0
  br i1 %tobool4.not, label %do.end8, label %land.lhs.true5

land.lhs.true5:                                   ; preds = %land.lhs.true
  %.b104 = load i1, ptr @normalize_rt_tasks.__warned, align 1
  br i1 %.b104, label %do.end8, label %if.then

if.then:                                          ; preds = %land.lhs.true5
  store i1 true, ptr @normalize_rt_tasks.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 9661, ptr noundef nonnull @.str.4) #33
  br label %do.end8

do.end8:                                          ; preds = %if.then, %land.lhs.true5, %land.lhs.true, %do.body2
  %signal = getelementptr i8, ptr %4, i32 544
  %5 = ptrtoint ptr %signal to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %signal, align 16
  %thread_head = getelementptr inbounds %struct.signal_struct, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %thread_head to i32
  call void @__asan_load4_noabort(i32 %7)
  %.pn115 = load volatile ptr, ptr %thread_head, align 4
  %cmp20.not118 = icmp eq ptr %.pn115, %thread_head
  br i1 %cmp20.not118, label %for.cond.loopexit, label %for.body21

for.body21:                                       ; preds = %for.inc, %do.end8
  %.pn119 = phi ptr [ %.pn, %for.inc ], [ %.pn115, %do.end8 ]
  %p.0120 = getelementptr i8, ptr %.pn119, i32 -1404
  %flags = getelementptr i8, ptr %.pn119, i32 -1392
  %8 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %flags, align 4
  %and = and i32 %9, 2097152
  %tobool22.not = icmp eq i32 %and, 0
  br i1 %tobool22.not, label %if.end24, label %for.inc

if.end24:                                         ; preds = %for.body21
  %exec_start = getelementptr i8, ptr %.pn119, i32 -1244
  %10 = ptrtoint ptr %exec_start to i32
  call void @__asan_store8_noabort(i32 %10)
  store i64 0, ptr %exec_start, align 32
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@normalize_rt_tasks, %if.then31)) #33
          to label %do.body35 [label %if.then31], !srcloc !1202

if.then31:                                        ; preds = %if.end24
  %stats = getelementptr i8, ptr %.pn119, i32 -636
  %11 = ptrtoint ptr %stats to i32
  call void @__asan_store8_noabort(i32 %11)
  store i64 0, ptr %stats, align 128
  br label %do.body35

do.body35:                                        ; preds = %if.then31, %if.end24
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@normalize_rt_tasks, %if.then47)) #33
          to label %do.body52 [label %if.then47], !srcloc !1202

if.then47:                                        ; preds = %do.body35
  %sleep_start = getelementptr i8, ptr %.pn119, i32 -588
  %12 = ptrtoint ptr %sleep_start to i32
  call void @__asan_store8_noabort(i32 %12)
  store i64 0, ptr %sleep_start, align 16
  br label %do.body52

do.body52:                                        ; preds = %if.then47, %do.body35
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@normalize_rt_tasks, %if.then64)) #33
          to label %do.end68 [label %if.then64], !srcloc !1202

if.then64:                                        ; preds = %do.body52
  %block_start = getelementptr i8, ptr %.pn119, i32 -564
  %13 = ptrtoint ptr %block_start to i32
  call void @__asan_store8_noabort(i32 %13)
  store i64 0, ptr %block_start, align 8
  br label %do.end68

do.end68:                                         ; preds = %if.then64, %do.body52
  %prio.i = getelementptr i8, ptr %.pn119, i32 -1348
  %14 = ptrtoint ptr %prio.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %prio.i, align 8
  %cmp.i.i = icmp sgt i32 %15, 99
  br i1 %cmp.i.i, label %if.then74, label %if.end79

if.then74:                                        ; preds = %do.end68
  %static_prio.i = getelementptr i8, ptr %.pn119, i32 -1344
  %16 = ptrtoint ptr %static_prio.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %static_prio.i, align 4
  %sub.i = add i32 %17, -120
  %cmp76 = icmp slt i32 %sub.i, 0
  br i1 %cmp76, label %if.then77, label %for.inc

if.then77:                                        ; preds = %if.then74
  call void @set_user_nice(ptr noundef %p.0120, i32 noundef 0)
  br label %for.inc

if.end79:                                         ; preds = %do.end68
  %call80 = call fastcc i32 @__sched_setscheduler(ptr noundef %p.0120, ptr noundef nonnull %attr, i1 noundef zeroext false, i1 noundef zeroext false)
  br label %for.inc

for.inc:                                          ; preds = %if.end79, %if.then77, %if.then74, %for.body21
  %18 = ptrtoint ptr %.pn119 to i32
  call void @__asan_load4_noabort(i32 %18)
  %.pn = load volatile ptr, ptr %.pn119, align 4
  %19 = ptrtoint ptr %signal to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %signal, align 16
  %thread_head19 = getelementptr inbounds %struct.signal_struct, ptr %20, i32 0, i32 3
  %cmp20.not = icmp eq ptr %.pn, %thread_head19
  br i1 %cmp20.not, label %for.cond.loopexit, label %for.body21

for.end90:                                        ; preds = %for.cond.loopexit, %entry
  call void @_raw_read_unlock(ptr noundef nonnull @tasklist_lock) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr) #33
  ret void
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define dso_local ptr @curr_task(i32 noundef %cpu) local_unnamed_addr #4 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %curr = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %3 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %curr, align 8
  ret ptr %4
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local ptr @sched_create_group(ptr noundef %parent) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = load ptr, ptr @task_group_cache, align 4
  %call = tail call noalias align 8 ptr @kmem_cache_alloc(ptr noundef %0, i32 noundef 3520) #33
  %tobool.not = icmp eq ptr %call, null
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %call2 = tail call i32 @alloc_fair_sched_group(ptr noundef nonnull %call, ptr noundef %parent) #33
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %err, label %if.end5

if.end5:                                          ; preds = %if.end
  %call6 = tail call i32 @alloc_rt_sched_group(ptr noundef nonnull %call, ptr noundef %parent) #33
  %tobool7.not = icmp eq i32 %call6, 0
  br i1 %tobool7.not, label %err, label %if.end9

if.end9:                                          ; preds = %if.end5
  %arrayidx.i = getelementptr %struct.task_group, ptr %call, i32 0, i32 18, i32 0
  %1 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load2_noabort(i32 %1)
  %bf.load.i.i = load i16, ptr %arrayidx.i, align 8
  %bf.clear.i.i = and i16 %bf.load.i.i, 2
  store i16 %bf.clear.i.i, ptr %arrayidx.i, align 8
  %arrayidx1.i = getelementptr %struct.task_group, ptr %call, i32 0, i32 19, i32 0
  %arrayidx3.i = getelementptr %struct.task_group, ptr %parent, i32 0, i32 19, i32 0
  %2 = ptrtoint ptr %arrayidx3.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %arrayidx3.i, align 4
  %4 = ptrtoint ptr %arrayidx1.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %3, ptr %arrayidx1.i, align 8
  %arrayidx.1.i = getelementptr %struct.task_group, ptr %call, i32 0, i32 18, i32 1
  %5 = ptrtoint ptr %arrayidx.1.i to i32
  call void @__asan_load2_noabort(i32 %5)
  %bf.load.i.1.i = load i16, ptr %arrayidx.1.i, align 4
  %bf.clear.i.1.i = and i16 %bf.load.i.1.i, 2
  %bf.set5.i.1.i = or i16 %bf.clear.i.1.i, -32752
  store i16 %bf.set5.i.1.i, ptr %arrayidx.1.i, align 4
  %arrayidx1.1.i = getelementptr %struct.task_group, ptr %call, i32 0, i32 19, i32 1
  %arrayidx3.1.i = getelementptr %struct.task_group, ptr %parent, i32 0, i32 19, i32 1
  %6 = ptrtoint ptr %arrayidx3.1.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %arrayidx3.1.i, align 4
  %8 = ptrtoint ptr %arrayidx1.1.i to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 %7, ptr %arrayidx1.1.i, align 4
  br label %cleanup

err:                                              ; preds = %if.end5, %if.end
  tail call void @free_fair_sched_group(ptr noundef nonnull %call) #33
  tail call void @free_rt_sched_group(ptr noundef nonnull %call) #33
  tail call void @autogroup_free(ptr noundef nonnull %call) #33
  %9 = load ptr, ptr @task_group_cache, align 4
  tail call void @kmem_cache_free(ptr noundef %9, ptr noundef nonnull %call) #33
  br label %cleanup

cleanup:                                          ; preds = %err, %if.end9, %entry
  %retval.0 = phi ptr [ %call, %if.end9 ], [ inttoptr (i32 -12 to ptr), %err ], [ inttoptr (i32 -12 to ptr), %entry ]
  ret ptr %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local noalias ptr @kmem_cache_alloc(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @alloc_fair_sched_group(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @alloc_rt_sched_group(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_online_group(ptr noundef %tg, ptr noundef %parent) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call2 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef nonnull @task_group_lock) #33
  %list = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 11
  %0 = load ptr, ptr @task_groups, align 4
  %call.i.i = tail call zeroext i1 @__list_add_valid(ptr noundef %list, ptr noundef nonnull @task_groups, ptr noundef %0) #33
  br i1 %call.i.i, label %if.end.i.i, label %list_add_rcu.exit

if.end.i.i:                                       ; preds = %entry
  %1 = ptrtoint ptr %list to i32
  call void @__asan_store4_noabort(i32 %1)
  store ptr %0, ptr %list, align 4
  %prev2.i.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 11, i32 1
  %2 = ptrtoint ptr %prev2.i.i to i32
  call void @__asan_store4_noabort(i32 %2)
  store ptr @task_groups, ptr %prev2.i.i, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1329
  store volatile ptr %list, ptr @task_groups, align 4
  %prev37.i.i = getelementptr inbounds %struct.list_head, ptr %0, i32 0, i32 1
  %3 = ptrtoint ptr %prev37.i.i to i32
  call void @__asan_store4_noabort(i32 %3)
  store ptr %list, ptr %prev37.i.i, align 4
  br label %list_add_rcu.exit

list_add_rcu.exit:                                ; preds = %if.end.i.i, %entry
  %tobool.not = icmp eq ptr %parent, null
  br i1 %tobool.not, label %do.end16, label %if.end, !prof !1192

do.end16:                                         ; preds = %list_add_rcu.exit
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 9813, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end16, %list_add_rcu.exit
  %parent29 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 12
  %4 = ptrtoint ptr %parent29 to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr %parent, ptr %parent29, align 8
  %children = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 14
  %5 = ptrtoint ptr %children to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile ptr %children, ptr %children, align 4
  %prev.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 14, i32 1
  %6 = ptrtoint ptr %prev.i to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr %children, ptr %prev.i, align 4
  %siblings = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 13
  %children30 = getelementptr inbounds %struct.task_group, ptr %parent, i32 0, i32 14
  %7 = ptrtoint ptr %children30 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %children30, align 4
  %call.i.i38 = tail call zeroext i1 @__list_add_valid(ptr noundef %siblings, ptr noundef %children30, ptr noundef %8) #33
  br i1 %call.i.i38, label %if.end.i.i41, label %list_add_rcu.exit42

if.end.i.i41:                                     ; preds = %if.end
  %9 = ptrtoint ptr %siblings to i32
  call void @__asan_store4_noabort(i32 %9)
  store ptr %8, ptr %siblings, align 4
  %prev2.i.i39 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 13, i32 1
  %10 = ptrtoint ptr %prev2.i.i39 to i32
  call void @__asan_store4_noabort(i32 %10)
  store ptr %children30, ptr %prev2.i.i39, align 4
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1329
  %11 = ptrtoint ptr %children30 to i32
  call void @__asan_store4_noabort(i32 %11)
  store volatile ptr %siblings, ptr %children30, align 4
  %prev37.i.i40 = getelementptr inbounds %struct.list_head, ptr %8, i32 0, i32 1
  %12 = ptrtoint ptr %prev37.i.i40 to i32
  call void @__asan_store4_noabort(i32 %12)
  store ptr %siblings, ptr %prev37.i.i40, align 4
  br label %list_add_rcu.exit42

list_add_rcu.exit42:                              ; preds = %if.end.i.i41, %if.end
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef nonnull @task_group_lock, i32 noundef %call2) #33
  tail call void @online_fair_sched_group(ptr noundef %tg) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @online_fair_sched_group(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_destroy_group(ptr noundef %tg) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rcu = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 10
  tail call void @call_rcu(ptr noundef %rcu, ptr noundef nonnull @sched_unregister_group_rcu) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @call_rcu(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @sched_unregister_group_rcu(ptr noundef %rhp) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %add.ptr = getelementptr i8, ptr %rhp, i32 -392
  tail call void @unregister_fair_sched_group(ptr noundef %add.ptr) #33
  tail call void @unregister_rt_sched_group(ptr noundef %add.ptr) #33
  tail call void @call_rcu(ptr noundef %rhp, ptr noundef nonnull @sched_free_group_rcu) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_release_group(ptr noundef %tg) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call2 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef nonnull @task_group_lock) #33
  %list = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 11
  %call.i.i = tail call zeroext i1 @__list_del_entry_valid(ptr noundef %list) #33
  br i1 %call.i.i, label %if.end.i.i, label %list_del_rcu.exit

if.end.i.i:                                       ; preds = %entry
  %prev.i.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 11, i32 1
  %0 = ptrtoint ptr %prev.i.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %prev.i.i, align 4
  %2 = ptrtoint ptr %list to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %list, align 4
  %prev1.i.i.i = getelementptr inbounds %struct.list_head, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %prev1.i.i.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr %1, ptr %prev1.i.i.i, align 4
  %5 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile ptr %3, ptr %1, align 4
  br label %list_del_rcu.exit

list_del_rcu.exit:                                ; preds = %if.end.i.i, %entry
  %prev.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 11, i32 1
  %6 = ptrtoint ptr %prev.i to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr inttoptr (i32 290 to ptr), ptr %prev.i, align 4
  %siblings = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 13
  %call.i.i6 = tail call zeroext i1 @__list_del_entry_valid(ptr noundef %siblings) #33
  br i1 %call.i.i6, label %if.end.i.i9, label %list_del_rcu.exit11

if.end.i.i9:                                      ; preds = %list_del_rcu.exit
  %prev.i.i7 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 13, i32 1
  %7 = ptrtoint ptr %prev.i.i7 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %prev.i.i7, align 4
  %9 = ptrtoint ptr %siblings to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %siblings, align 4
  %prev1.i.i.i8 = getelementptr inbounds %struct.list_head, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %prev1.i.i.i8 to i32
  call void @__asan_store4_noabort(i32 %11)
  store ptr %8, ptr %prev1.i.i.i8, align 4
  %12 = ptrtoint ptr %8 to i32
  call void @__asan_store4_noabort(i32 %12)
  store volatile ptr %10, ptr %8, align 4
  br label %list_del_rcu.exit11

list_del_rcu.exit11:                              ; preds = %if.end.i.i9, %list_del_rcu.exit
  %prev.i10 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 13, i32 1
  %13 = ptrtoint ptr %prev.i10 to i32
  call void @__asan_store4_noabort(i32 %13)
  store ptr inttoptr (i32 290 to ptr), ptr %prev.i10, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef nonnull @task_group_lock, i32 noundef %call2) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @sched_move_task(ptr noundef %tsk) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call = call ptr @task_rq_lock(ptr noundef %tsk, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call)
  %curr.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 20
  %5 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %curr.i, align 8
  %cmp.i.not = icmp eq ptr %6, %tsk
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 12
  %7 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %on_rq.i, align 4
  %cmp.i30.not = icmp eq i32 %8, 1
  br i1 %cmp.i30.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_move_task, %land.rhs.i.i)) #33
          to label %if.end.i [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %if.then
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %9 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i = icmp eq i32 %10, 0
  br i1 %tobool3.i.not.i, label %if.end.i, label %if.then.i

if.then.i:                                        ; preds = %land.rhs.i.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i, align 8
  %core_task_seq.i.i = getelementptr inbounds %struct.rq, ptr %12, i32 0, i32 84
  %13 = ptrtoint ptr %core_task_seq.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %core_task_seq.i.i, align 4
  %inc.i.i = add i32 %14, 1
  store i32 %inc.i.i, ptr %core_task_seq.i.i, align 4
  %core_node.i.i.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 22
  %15 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_node.i.i.i, align 4
  %17 = ptrtoint ptr %core_node.i.i.i to i32
  %cmp.i.not.i.i = icmp eq i32 %16, %17
  br i1 %cmp.i.not.i.i, label %if.end.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.then.i
  %core_tree.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 83
  tail call void @rb_erase(ptr noundef %core_node.i.i.i, ptr noundef %core_tree.i.i) #33
  %18 = ptrtoint ptr %core_node.i.i.i to i32
  call void @__asan_store4_noabort(i32 %18)
  store i32 %17, ptr %core_node.i.i.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i.i, %if.then.i, %land.rhs.i.i, %if.then
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@sched_move_task, %if.end.i25.i)) #33
          to label %dequeue_task.exit [label %if.end.i25.i], !srcloc !1202

if.end.i25.i:                                     ; preds = %if.end.i
  %sched_class.i.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %19 = ptrtoint ptr %sched_class.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %sched_class.i.i, align 32
  %21 = ptrtoint ptr %20 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %20, align 4
  %tobool3.not.i.i = icmp eq i32 %22, 0
  br i1 %tobool3.not.i.i, label %dequeue_task.exit, label %for.body.preheader.i.i, !prof !1192

for.body.preheader.i.i:                           ; preds = %if.end.i25.i
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call, ptr noundef %tsk, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call, ptr noundef %tsk, i32 noundef 1) #33
  br label %dequeue_task.exit

dequeue_task.exit:                                ; preds = %for.body.preheader.i.i, %if.end.i25.i, %if.end.i
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %23 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %sched_class.i, align 32
  %dequeue_task.i = getelementptr inbounds %struct.sched_class, ptr %24, i32 0, i32 2
  %25 = ptrtoint ptr %dequeue_task.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %dequeue_task.i, align 4
  tail call void %26(ptr noundef %call, ptr noundef %tsk, i32 noundef 14) #33
  br label %if.end

if.end:                                           ; preds = %dequeue_task.exit, %entry
  br i1 %cmp.i.not, label %if.then4, label %if.end5

if.then4:                                         ; preds = %if.end
  %27 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %curr.i, align 8
  %cmp.not.i = icmp eq ptr %28, %tsk
  br i1 %cmp.not.i, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then4
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i33, !prof !1191

if.then.i33:                                      ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i33, %land.rhs.i, %if.then4
  %sched_class.i34 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %29 = ptrtoint ptr %sched_class.i34 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load ptr, ptr %sched_class.i34, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %30, i32 0, i32 7
  %31 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %32(ptr noundef %call, ptr noundef %tsk) #33
  br label %if.end5

if.end5:                                          ; preds = %put_prev_task.exit, %if.end
  tail call fastcc void @sched_change_group(ptr noundef %tsk, i32 noundef 1)
  br i1 %cmp.i30.not, label %if.then7, label %if.end8

if.then7:                                         ; preds = %if.end5
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_uclamp_used, ptr blockaddress(@sched_move_task, %if.end.i22.i)) #33
          to label %uclamp_rq_inc.exit.i [label %if.end.i22.i], !srcloc !1202

if.end.i22.i:                                     ; preds = %if.then7
  %sched_class.i.i36 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %33 = ptrtoint ptr %sched_class.i.i36 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %sched_class.i.i36, align 32
  %35 = ptrtoint ptr %34 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %34, align 4
  %tobool3.not.i.i37 = icmp eq i32 %36, 0
  br i1 %tobool3.not.i.i37, label %uclamp_rq_inc.exit.i, label %for.body.preheader.i.i38, !prof !1192

for.body.preheader.i.i38:                         ; preds = %if.end.i22.i
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call, ptr noundef %tsk, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call, ptr noundef %tsk, i32 noundef 1) #33
  %uclamp_flags.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 12
  %37 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %uclamp_flags.i.i, align 16
  %and.i.i = and i32 %38, 1
  %tobool14.not.i.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool14.not.i.i, label %uclamp_rq_inc.exit.i, label %if.then15.i.i

if.then15.i.i:                                    ; preds = %for.body.preheader.i.i38
  %and17.i.i = and i32 %38, -2
  %39 = ptrtoint ptr %uclamp_flags.i.i to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 %and17.i.i, ptr %uclamp_flags.i.i, align 16
  br label %uclamp_rq_inc.exit.i

uclamp_rq_inc.exit.i:                             ; preds = %if.then15.i.i, %for.body.preheader.i.i38, %if.end.i22.i, %if.then7
  %sched_class.i39 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %40 = ptrtoint ptr %sched_class.i39 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %sched_class.i39, align 32
  %enqueue_task.i = getelementptr inbounds %struct.sched_class, ptr %41, i32 0, i32 1
  %42 = ptrtoint ptr %enqueue_task.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load ptr, ptr %enqueue_task.i, align 4
  tail call void %43(ptr noundef %call, ptr noundef %tsk, i32 noundef 14) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_move_task, %land.rhs.i.i42)) #33
          to label %if.end8 [label %land.rhs.i.i42], !srcloc !1202

land.rhs.i.i42:                                   ; preds = %uclamp_rq_inc.exit.i
  %core_enabled.i.i40 = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %44 = ptrtoint ptr %core_enabled.i.i40 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %core_enabled.i.i40, align 128
  %tobool3.i.not.i41 = icmp eq i32 %45, 0
  br i1 %tobool3.i.not.i41, label %if.end8, label %if.then7.i

if.then7.i:                                       ; preds = %land.rhs.i.i42
  tail call void @sched_core_enqueue(ptr noundef %call, ptr noundef %tsk) #33
  br label %if.end8

if.end8:                                          ; preds = %if.then7.i, %land.rhs.i.i42, %uclamp_rq_inc.exit.i, %if.end5
  br i1 %cmp.i.not, label %if.then10, label %if.end11

if.then10:                                        ; preds = %if.end8
  %sched_class.i43 = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %46 = ptrtoint ptr %sched_class.i43 to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load ptr, ptr %sched_class.i43, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %47, i32 0, i32 8
  %48 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %set_next_task.i, align 4
  tail call void %49(ptr noundef %call, ptr noundef %tsk, i1 noundef zeroext false) #33
  tail call void @resched_curr(ptr noundef %call)
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end8
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %50 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %51, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end11
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %52 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end11
  %retval.0.i.i.i = phi ptr [ %53, %if.then.i.i.i ], [ %call, %if.end11 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %54 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %54)
  %.unpack.i.i = load i32, ptr %1, align 4
  %55 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %55) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_move_task, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %56 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %57, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %58 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %59, %if.then.i.i4.i ], [ %call, %land.rhs.i.i.i.i ], [ %call, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 128
  %60 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %61) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @sched_change_group(ptr noundef %tsk, i32 noundef %type) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cgroups = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 164
  %0 = ptrtoint ptr %cgroups to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load volatile ptr, ptr %cgroups, align 16
  %call.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @cgroup_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool.not = icmp eq i32 %call.i, 0
  br i1 %tobool.not, label %lor.lhs.false, label %do.end15

lor.lhs.false:                                    ; preds = %entry
  %call.i33 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @css_set_lock, i32 0, i32 0, i32 0, i32 4), i32 noundef -1) #33
  br label %do.end15

do.end15:                                         ; preds = %lor.lhs.false, %entry
  %arrayidx = getelementptr [14 x ptr], ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %arrayidx, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @sysctl_sched_autogroup_enabled to i32))
  %4 = load volatile i32, ptr @sysctl_sched_autogroup_enabled, align 4
  %tobool.not.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i, label %autogroup_task_group.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %do.end15
  %call.i34 = tail call zeroext i1 @task_wants_autogroup(ptr noundef %tsk, ptr noundef %3) #33
  br i1 %call.i34, label %if.then.i, label %autogroup_task_group.exit

if.then.i:                                        ; preds = %land.lhs.true.i
  %signal.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 111
  %5 = ptrtoint ptr %signal.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %signal.i, align 16
  %autogroup.i = getelementptr inbounds %struct.signal_struct, ptr %6, i32 0, i32 26
  %7 = ptrtoint ptr %autogroup.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %autogroup.i, align 4
  %tg1.i = getelementptr inbounds %struct.autogroup, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %tg1.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %tg1.i, align 4
  br label %autogroup_task_group.exit

autogroup_task_group.exit:                        ; preds = %if.then.i, %land.lhs.true.i, %do.end15
  %retval.0.i = phi ptr [ %10, %if.then.i ], [ %3, %land.lhs.true.i ], [ %3, %do.end15 ]
  %sched_task_group = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 25
  %11 = ptrtoint ptr %sched_task_group to i32
  call void @__asan_store4_noabort(i32 %11)
  store ptr %retval.0.i, ptr %sched_task_group, align 8
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 21
  %12 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %sched_class, align 32
  %task_change_group = getelementptr inbounds %struct.sched_class, ptr %13, i32 0, i32 26
  %14 = ptrtoint ptr %task_change_group to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task_change_group, align 4
  %tobool19.not = icmp eq ptr %15, null
  br i1 %tobool19.not, label %if.else, label %if.then20

if.then20:                                        ; preds = %autogroup_task_group.exit
  tail call void %15(ptr noundef %tsk, i32 noundef %type) #33
  br label %if.end24

if.else:                                          ; preds = %autogroup_task_group.exit
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 1
  %16 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 3
  %18 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %cpu.i, align 4
  %se.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 18
  %cfs_rq.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 18, i32 11
  %20 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %cfs_rq.i, align 16
  %cfs_rq2.i = getelementptr inbounds %struct.task_group, ptr %retval.0.i, i32 0, i32 2
  %22 = ptrtoint ptr %cfs_rq2.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %cfs_rq2.i, align 4
  %arrayidx.i = getelementptr ptr, ptr %23, i32 %19
  %24 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %arrayidx.i, align 4
  tail call void @set_task_rq_fair(ptr noundef %se.i, ptr noundef %21, ptr noundef %25) #33
  %26 = ptrtoint ptr %cfs_rq2.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %cfs_rq2.i, align 4
  %arrayidx4.i = getelementptr ptr, ptr %27, i32 %19
  %28 = ptrtoint ptr %arrayidx4.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %arrayidx4.i, align 4
  %30 = ptrtoint ptr %cfs_rq.i to i32
  call void @__asan_store4_noabort(i32 %30)
  store ptr %29, ptr %cfs_rq.i, align 16
  %se7.i = getelementptr inbounds %struct.task_group, ptr %retval.0.i, i32 0, i32 1
  %31 = ptrtoint ptr %se7.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %se7.i, align 8
  %arrayidx8.i = getelementptr ptr, ptr %32, i32 %19
  %33 = ptrtoint ptr %arrayidx8.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %arrayidx8.i, align 4
  %parent.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 18, i32 10
  %35 = ptrtoint ptr %parent.i to i32
  call void @__asan_store4_noabort(i32 %35)
  store ptr %34, ptr %parent.i, align 4
  %rt_rq.i = getelementptr inbounds %struct.task_group, ptr %retval.0.i, i32 0, i32 8
  %36 = ptrtoint ptr %rt_rq.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %rt_rq.i, align 8
  %arrayidx10.i = getelementptr ptr, ptr %37, i32 %19
  %38 = ptrtoint ptr %arrayidx10.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %arrayidx10.i, align 4
  %rt_rq11.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 19, i32 8
  %40 = ptrtoint ptr %rt_rq11.i to i32
  call void @__asan_store4_noabort(i32 %40)
  store ptr %39, ptr %rt_rq11.i, align 32
  %rt_se.i = getelementptr inbounds %struct.task_group, ptr %retval.0.i, i32 0, i32 7
  %41 = ptrtoint ptr %rt_se.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %rt_se.i, align 4
  %arrayidx12.i = getelementptr ptr, ptr %42, i32 %19
  %43 = ptrtoint ptr %arrayidx12.i to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %arrayidx12.i, align 4
  %parent14.i = getelementptr inbounds %struct.task_struct, ptr %tsk, i32 0, i32 19, i32 7
  %45 = ptrtoint ptr %parent14.i to i32
  call void @__asan_store4_noabort(i32 %45)
  store ptr %44, ptr %parent14.i, align 4
  br label %if.end24

if.end24:                                         ; preds = %if.else, %if.then20
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal ptr @cpu_cgroup_css_alloc(ptr noundef %parent_css) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %tobool.not = icmp eq ptr %parent_css, null
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %call1 = tail call ptr @sched_create_group(ptr noundef nonnull %parent_css)
  %cmp.i = icmp ugt ptr %call1, inttoptr (i32 -4096 to ptr)
  %spec.select = select i1 %cmp.i, ptr inttoptr (i32 -12 to ptr), ptr %call1
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi ptr [ @root_task_group, %entry ], [ %spec.select, %if.end ]
  ret ptr %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cgroup_css_online(ptr noundef %css) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %parent1 = getelementptr inbounds %struct.cgroup_subsys_state, ptr %css, i32 0, i32 12
  %0 = ptrtoint ptr %parent1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %parent1, align 8
  %tobool.not = icmp eq ptr %1, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  tail call void @sched_online_group(ptr noundef %css, ptr noundef nonnull %1)
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  tail call void @mutex_lock_nested(ptr noundef nonnull @uclamp_mutex, i32 noundef 0) #33
  %2 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %5, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end
  tail call fastcc void @cpu_util_update_eff(ptr noundef %css)
  %call.i6 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i6, label %rcu_read_unlock.exit, label %land.lhs.true.i9

land.lhs.true.i9:                                 ; preds = %rcu_read_lock.exit
  %call1.i7 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i8 = icmp eq i32 %call1.i7, 0
  br i1 %tobool.not.i8, label %rcu_read_unlock.exit, label %land.lhs.true2.i11

land.lhs.true2.i11:                               ; preds = %land.lhs.true.i9
  %.b4.i10 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i10, label %rcu_read_unlock.exit, label %if.then.i12

if.then.i12:                                      ; preds = %land.lhs.true2.i11
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i12, %land.lhs.true2.i11, %land.lhs.true.i9, %rcu_read_lock.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %6 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i13 = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i.i.i.i13 to ptr
  %preempt_count.i.i.i.i14 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 1
  %8 = ptrtoint ptr %preempt_count.i.i.i.i14 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %preempt_count.i.i.i.i14, align 4
  %sub.i.i.i = add i32 %9, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i14, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  tail call void @mutex_unlock(ptr noundef nonnull @uclamp_mutex) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @cpu_cgroup_css_released(ptr noundef %css) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call2.i = tail call i32 @_raw_spin_lock_irqsave(ptr noundef nonnull @task_group_lock) #33
  %list.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 11
  %call.i.i.i = tail call zeroext i1 @__list_del_entry_valid(ptr noundef %list.i) #33
  br i1 %call.i.i.i, label %if.end.i.i.i, label %list_del_rcu.exit.i

if.end.i.i.i:                                     ; preds = %entry
  %prev.i.i.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 11, i32 1
  %0 = ptrtoint ptr %prev.i.i.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %prev.i.i.i, align 4
  %2 = ptrtoint ptr %list.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %list.i, align 4
  %prev1.i.i.i.i = getelementptr inbounds %struct.list_head, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %prev1.i.i.i.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store ptr %1, ptr %prev1.i.i.i.i, align 4
  %5 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %5)
  store volatile ptr %3, ptr %1, align 4
  br label %list_del_rcu.exit.i

list_del_rcu.exit.i:                              ; preds = %if.end.i.i.i, %entry
  %prev.i.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 11, i32 1
  %6 = ptrtoint ptr %prev.i.i to i32
  call void @__asan_store4_noabort(i32 %6)
  store ptr inttoptr (i32 290 to ptr), ptr %prev.i.i, align 4
  %siblings.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 13
  %call.i.i6.i = tail call zeroext i1 @__list_del_entry_valid(ptr noundef %siblings.i) #33
  br i1 %call.i.i6.i, label %if.end.i.i9.i, label %sched_release_group.exit

if.end.i.i9.i:                                    ; preds = %list_del_rcu.exit.i
  %prev.i.i7.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 13, i32 1
  %7 = ptrtoint ptr %prev.i.i7.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %prev.i.i7.i, align 4
  %9 = ptrtoint ptr %siblings.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %siblings.i, align 4
  %prev1.i.i.i8.i = getelementptr inbounds %struct.list_head, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %prev1.i.i.i8.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store ptr %8, ptr %prev1.i.i.i8.i, align 4
  %12 = ptrtoint ptr %8 to i32
  call void @__asan_store4_noabort(i32 %12)
  store volatile ptr %10, ptr %8, align 4
  br label %sched_release_group.exit

sched_release_group.exit:                         ; preds = %if.end.i.i9.i, %list_del_rcu.exit.i
  %prev.i10.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 13, i32 1
  %13 = ptrtoint ptr %prev.i10.i to i32
  call void @__asan_store4_noabort(i32 %13)
  store ptr inttoptr (i32 290 to ptr), ptr %prev.i10.i, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef nonnull @task_group_lock, i32 noundef %call2.i) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @cpu_cgroup_css_free(ptr noundef %css) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @unregister_fair_sched_group(ptr noundef %css) #33
  tail call void @unregister_rt_sched_group(ptr noundef %css) #33
  %rcu.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 10
  tail call void @call_rcu(ptr noundef %rcu.i, ptr noundef nonnull @sched_free_group_rcu) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_extra_stat_show(ptr noundef %sf, ptr nocapture noundef readonly %css) #0 align 64 {
if.end400:
  call void @llvm.arm.gnu.eabi.mcount()
  %throttled_time = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 16
  %0 = ptrtoint ptr %throttled_time to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %throttled_time, align 8
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %1, i32 0) #40, !srcloc !1330
  %asmresult.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %1, i64 %asmresult.i, i32 %asmresult4.i) #40, !srcloc !1331
  %asmresult10.i = extractvalue { i64, i32 } %3, 0
  %burst_time = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 17
  %4 = ptrtoint ptr %burst_time to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %burst_time, align 8
  %6 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %5, i32 0) #40, !srcloc !1330
  %asmresult.i566 = extractvalue { i64, i32 } %6, 0
  %asmresult4.i567 = extractvalue { i64, i32 } %6, 1
  %7 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %5, i64 %asmresult.i566, i32 %asmresult4.i567) #40, !srcloc !1331
  %asmresult10.i568 = extractvalue { i64, i32 } %7, 0
  %burst_usec.0 = lshr i64 %asmresult10.i568, 9
  %throttled_usec.0 = lshr i64 %asmresult10.i, 9
  %nr_periods = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 13
  %8 = ptrtoint ptr %nr_periods to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %nr_periods, align 8
  %nr_throttled = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 14
  %10 = ptrtoint ptr %nr_throttled to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %nr_throttled, align 4
  %nr_burst = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 15
  %12 = ptrtoint ptr %nr_burst to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %nr_burst, align 8
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.245, i32 noundef %9, i32 noundef %11, i64 noundef %throttled_usec.0, i32 noundef %13, i64 noundef %burst_usec.0) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cgroup_can_attach(ptr noundef %tset) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %css = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %css) #33
  %0 = ptrtoint ptr %css to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %css, align 4, !annotation !1193
  %call = call ptr @cgroup_taskset_first(ptr noundef %tset, ptr noundef nonnull %css) #33
  %tobool.not19 = icmp eq ptr %call, null
  br i1 %tobool.not19, label %cleanup, label %for.body

for.body:                                         ; preds = %for.inc, %entry
  %task.020 = phi ptr [ %call10, %for.inc ], [ %call, %entry ]
  %1 = ptrtoint ptr %css to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %css, align 4
  %call2 = call i32 @sched_rt_can_attach(ptr noundef %2, ptr noundef nonnull %task.020) #33
  %tobool3.not = icmp eq i32 %call2, 0
  br i1 %tobool3.not, label %cleanup, label %if.end

if.end:                                           ; preds = %for.body
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %task.020, i32 0, i32 128
  call void @_raw_spin_lock_irq(ptr noundef %pi_lock) #33
  %3 = ptrtoint ptr %task.020 to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %task.020, align 128
  %cmp = icmp eq i32 %4, 2048
  call void @_raw_spin_unlock_irq(ptr noundef %pi_lock) #33
  br i1 %cmp, label %cleanup, label %for.inc

for.inc:                                          ; preds = %if.end
  %call10 = call ptr @cgroup_taskset_next(ptr noundef %tset, ptr noundef nonnull %css) #33
  %tobool.not = icmp eq ptr %call10, null
  br i1 %tobool.not, label %cleanup, label %for.body

cleanup:                                          ; preds = %for.inc, %if.end, %for.body, %entry
  %retval.0 = phi i32 [ 0, %entry ], [ 0, %for.inc ], [ -22, %if.end ], [ -22, %for.body ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %css) #33
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @cpu_cgroup_attach(ptr noundef %tset) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %css = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %css) #33
  %0 = ptrtoint ptr %css to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr inttoptr (i32 -1 to ptr), ptr %css, align 4, !annotation !1193
  %call = call ptr @cgroup_taskset_first(ptr noundef %tset, ptr noundef nonnull %css) #33
  %tobool.not4 = icmp eq ptr %call, null
  br i1 %tobool.not4, label %for.end, label %for.body

for.body:                                         ; preds = %for.body, %entry
  %task.05 = phi ptr [ %call1, %for.body ], [ %call, %entry ]
  call void @sched_move_task(ptr noundef nonnull %task.05)
  %call1 = call ptr @cgroup_taskset_next(ptr noundef %tset, ptr noundef nonnull %css) #33
  %tobool.not = icmp eq ptr %call1, null
  br i1 %tobool.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.body, %entry
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %css) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @cpu_cgroup_fork(ptr noundef %task) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call = call ptr @task_rq_lock(ptr noundef %task, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %call)
  tail call fastcc void @sched_change_group(ptr noundef %task, i32 noundef 0)
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %5 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %6, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %entry
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %7 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %entry
  %retval.0.i.i.i = phi ptr [ %8, %if.then.i.i.i ], [ %call, %entry ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %9 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %9)
  %.unpack.i.i = load i32, ptr %1, align 4
  %10 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %10) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@cpu_cgroup_fork, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %11 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %12, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %13 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %14, %if.then.i.i4.i ], [ %call, %land.rhs.i.i.i.i ], [ %call, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %task, i32 0, i32 128
  %15 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %16) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @dump_cpu_task(i32 noundef %cpu) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.96, i32 noundef %cpu) #39
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %curr = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %3 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %curr, align 8
  tail call void @sched_show_task(ptr noundef %4)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @call_trace_sched_update_nr_running(ptr noundef %rq, i32 noundef %count) local_unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @trace_sched_update_nr_running_tp(ptr noundef %rq, i32 noundef %count)
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_update_nr_running_tp(ptr noundef %rq, i32 noundef %change) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_update_nr_running_tp, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_update_nr_running_tp, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1332
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_update_nr_running_tp, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %rq, i32 noundef %change) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1333
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1333
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_update_nr_running_tp, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_update_nr_running_tp.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_update_nr_running_tp.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 733, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @trace_event_buffer_reserve(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_event_buffer_commit(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__trace_trigger_soft_disabled(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_kthread_stop(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.102, ptr noundef %comm, i32 noundef %3) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @trace_raw_output_prep(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_event_printf(ptr noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @trace_handle_return(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_kthread_stop_ret(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %ret1 = getelementptr inbounds %struct.trace_event_raw_sched_kthread_stop_ret, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %ret1 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %ret1, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.105, i32 noundef %3) #33
  %call2 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call2, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_kthread_work_queue_work(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %work = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %work to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %work, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %function to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %function, align 4
  %worker = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_queue_work, ptr %1, i32 0, i32 3
  %6 = ptrtoint ptr %worker to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %worker, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.110, ptr noundef %3, ptr noundef %5, ptr noundef %7) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_kthread_work_execute_start(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %work = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %work to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %work, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_start, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %function to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %function, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.111, ptr noundef %3, ptr noundef %5) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_kthread_work_execute_end(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %work = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %work to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %work, align 4
  %function = getelementptr inbounds %struct.trace_event_raw_sched_kthread_work_execute_end, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %function to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %function, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.111, ptr noundef %3, ptr noundef %5) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_wakeup_template(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %prio = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %prio, align 4
  %target_cpu = getelementptr inbounds %struct.trace_event_raw_sched_wakeup_template, ptr %1, i32 0, i32 4
  %6 = ptrtoint ptr %target_cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %target_cpu, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.114, ptr noundef %comm, i32 noundef %3, i32 noundef %5, i32 noundef %7) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #18

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_switch(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %tmp_seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 12
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %prev_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 1
  %prev_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %prev_pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %prev_pid, align 4
  %prev_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %prev_prio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %prev_prio, align 4
  %prev_state = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 4
  %6 = ptrtoint ptr %prev_state to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %prev_state, align 4
  %and = and i32 %7, 255
  %tobool.not = icmp eq i32 %and, 0
  br i1 %tobool.not, label %cond.end, label %cond.true

cond.true:                                        ; preds = %if.end
  %call3 = tail call ptr @trace_print_flags_seq(ptr noundef %tmp_seq, ptr noundef nonnull @.str.132, i32 noundef %and, ptr noundef nonnull @trace_raw_output_sched_switch.__flags) #33
  br label %cond.end

cond.end:                                         ; preds = %cond.true, %if.end
  %cond = phi ptr [ %call3, %cond.true ], [ @.str.133, %if.end ]
  %8 = ptrtoint ptr %prev_state to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %prev_state, align 4
  %and5 = and i32 %9, 256
  %tobool6.not = icmp eq i32 %and5, 0
  %cond7 = select i1 %tobool6.not, ptr @.str.135, ptr @.str.134
  %next_comm = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 5
  %next_pid = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 6
  %10 = ptrtoint ptr %next_pid to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %next_pid, align 4
  %next_prio = getelementptr inbounds %struct.trace_event_raw_sched_switch, ptr %1, i32 0, i32 7
  %12 = ptrtoint ptr %next_prio to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %next_prio, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.123, ptr noundef %prev_comm, i32 noundef %3, i32 noundef %5, ptr noundef %cond, ptr noundef nonnull %cond7, ptr noundef %next_comm, i32 noundef %11, i32 noundef %13) #33
  %call9 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %cond.end, %entry
  %retval.0 = phi i32 [ %call9, %cond.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @trace_print_flags_seq(ptr noundef, ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_migrate_task(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %prio = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %prio, align 4
  %orig_cpu = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %1, i32 0, i32 4
  %6 = ptrtoint ptr %orig_cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %orig_cpu, align 4
  %dest_cpu = getelementptr inbounds %struct.trace_event_raw_sched_migrate_task, ptr %1, i32 0, i32 5
  %8 = ptrtoint ptr %dest_cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %dest_cpu, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.138, ptr noundef %comm, i32 noundef %3, i32 noundef %5, i32 noundef %7, i32 noundef %9) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_process_template(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %prio = getelementptr inbounds %struct.trace_event_raw_sched_process_template, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %prio, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.139, ptr noundef %comm, i32 noundef %3, i32 noundef %5) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_process_wait(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %prio = getelementptr inbounds %struct.trace_event_raw_sched_process_wait, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %prio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %prio, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.139, ptr noundef %comm, i32 noundef %3, i32 noundef %5) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_process_fork(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %parent_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %1, i32 0, i32 1
  %parent_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %parent_pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %parent_pid, align 4
  %child_comm = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %1, i32 0, i32 3
  %child_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_fork, ptr %1, i32 0, i32 4
  %4 = ptrtoint ptr %child_pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %child_pid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.144, ptr noundef %parent_comm, i32 noundef %3, ptr noundef %child_comm, i32 noundef %5) #33
  %call2 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call2, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: argmemonly mustprogress nofree nounwind null_pointer_is_valid willreturn
declare dso_local ptr @strcpy(ptr noalias noundef returned writeonly, ptr noalias nocapture noundef readonly) local_unnamed_addr #19

; Function Attrs: argmemonly mustprogress nofree nounwind null_pointer_is_valid readonly willreturn
declare dso_local i32 @strlen(ptr nocapture noundef) local_unnamed_addr #20

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_process_exec(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %__data_loc_filename = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %__data_loc_filename to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %__data_loc_filename, align 4
  %and = and i32 %3, 65535
  %add.ptr = getelementptr i8, ptr %1, i32 %and
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %pid, align 4
  %old_pid = getelementptr inbounds %struct.trace_event_raw_sched_process_exec, ptr %1, i32 0, i32 3
  %6 = ptrtoint ptr %old_pid to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %old_pid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.149, ptr noundef %add.ptr, i32 noundef %5, i32 noundef %7) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_stat_template(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 8
  %delay = getelementptr inbounds %struct.trace_event_raw_sched_stat_template, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %delay to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %delay, align 8
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.152, ptr noundef %comm, i32 noundef %3, i64 noundef %5) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_stat_runtime(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 8
  %runtime = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %runtime to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %runtime, align 8
  %vruntime = getelementptr inbounds %struct.trace_event_raw_sched_stat_runtime, ptr %1, i32 0, i32 4
  %6 = ptrtoint ptr %vruntime to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %vruntime, align 8
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.155, ptr noundef %comm, i32 noundef %3, i64 noundef %5, i64 noundef %7) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_pi_setprio(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %oldprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %1, i32 0, i32 3
  %4 = ptrtoint ptr %oldprio to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %oldprio, align 4
  %newprio = getelementptr inbounds %struct.trace_event_raw_sched_pi_setprio, ptr %1, i32 0, i32 4
  %6 = ptrtoint ptr %newprio to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %newprio, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.158, ptr noundef %comm, i32 noundef %3, i32 noundef %5, i32 noundef %7) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_process_hang(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %comm = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %1, i32 0, i32 1
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_process_hang, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.102, ptr noundef %comm, i32 noundef %3) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_move_numa(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %pid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %pid, align 4
  %tgid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %tgid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %tgid, align 4
  %ngid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 3
  %6 = ptrtoint ptr %ngid to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %ngid, align 4
  %src_cpu = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 4
  %8 = ptrtoint ptr %src_cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %src_cpu, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 5
  %10 = ptrtoint ptr %src_nid to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %src_nid, align 4
  %dst_cpu = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 6
  %12 = ptrtoint ptr %dst_cpu to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %dst_cpu, align 4
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_move_numa, ptr %1, i32 0, i32 7
  %14 = ptrtoint ptr %dst_nid to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %dst_nid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.165, i32 noundef %3, i32 noundef %5, i32 noundef %7, i32 noundef %9, i32 noundef %11, i32 noundef %13, i32 noundef %15) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_numa_pair_template(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %src_pid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %src_pid to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %src_pid, align 4
  %src_tgid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 2
  %4 = ptrtoint ptr %src_tgid to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %src_tgid, align 4
  %src_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 3
  %6 = ptrtoint ptr %src_ngid to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %src_ngid, align 4
  %src_cpu = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 4
  %8 = ptrtoint ptr %src_cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %src_cpu, align 4
  %src_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 5
  %10 = ptrtoint ptr %src_nid to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %src_nid, align 4
  %dst_pid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 6
  %12 = ptrtoint ptr %dst_pid to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %dst_pid, align 4
  %dst_tgid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 7
  %14 = ptrtoint ptr %dst_tgid to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %dst_tgid, align 4
  %dst_ngid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 8
  %16 = ptrtoint ptr %dst_ngid to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %dst_ngid, align 4
  %dst_cpu = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 9
  %18 = ptrtoint ptr %dst_cpu to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %dst_cpu, align 4
  %dst_nid = getelementptr inbounds %struct.trace_event_raw_sched_numa_pair_template, ptr %1, i32 0, i32 10
  %20 = ptrtoint ptr %dst_nid to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %dst_nid, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.172, i32 noundef %3, i32 noundef %5, i32 noundef %7, i32 noundef %9, i32 noundef %11, i32 noundef %13, i32 noundef %15, i32 noundef %17, i32 noundef %19, i32 noundef %21) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @trace_raw_output_sched_wake_idle_without_ipi(ptr noundef %iter, i32 noundef %flags, ptr noundef %trace_event) #0 align 64 {
entry:
  %ent = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 16
  %0 = ptrtoint ptr %ent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %ent, align 8
  %call = tail call i32 @trace_raw_output_prep(ptr noundef %iter, ptr noundef %trace_event) #33
  %cmp.not = icmp eq i32 %call, 1
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %entry
  %seq = getelementptr inbounds %struct.trace_iterator, ptr %iter, i32 0, i32 15
  %cpu = getelementptr inbounds %struct.trace_event_raw_sched_wake_idle_without_ipi, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  tail call void (ptr, ptr, ...) @trace_event_printf(ptr noundef %iter, ptr noundef nonnull @.str.174, i32 noundef %3) #33
  %call1 = tail call i32 @trace_handle_return(ptr noundef %seq) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call1, %if.end ], [ %call, %entry ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @perf_trace_buf_alloc(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @perf_trace_run_bpf_submit(ptr noundef, i32 noundef, i32 noundef, ptr noundef, i64 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nocallback nofree nosync nounwind readnone willreturn
declare ptr @llvm.returnaddress(i32 immarg) #21

; Function Attrs: nocallback nofree nosync nounwind readnone willreturn
declare ptr @llvm.frameaddress.p0(i32 immarg) #21

; Function Attrs: nounwind readonly
declare i32 @llvm.read_register.i32(metadata) #22

; Function Attrs: null_pointer_is_valid
declare dso_local void @bpf_trace_run1(ptr noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @bpf_trace_run2(ptr noundef, i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @bpf_trace_run3(ptr noundef, i64 noundef, i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @bpf_trace_run4(ptr noundef, i64 noundef, i64 noundef, i64 noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @rb_insert_color(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @cfs_prio_less(ptr noundef, ptr noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__kasan_check_write(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.prefetch.p0(ptr nocapture readonly, i32 immarg, i32 immarg, i32) #23

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__kasan_check_read(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__sched_core_flip(i1 noundef zeroext %enabled) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %flags = alloca i32, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %flags) #33
  tail call void @cpus_read_lock() #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %sub.i.i = add i32 %0, 31
  %1 = lshr i32 %sub.i.i, 3
  %mul.i.i = and i32 %1, 536870908
  %2 = call ptr @memcpy(ptr @sched_core_mask, ptr @__cpu_online_mask, i32 %mul.i.i)
  %call66 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @sched_core_mask) #37
  %cmp67 = icmp ult i32 %call66, %0
  br i1 %cmp67, label %for.body.lr.ph, label %for.end17

for.body.lr.ph:                                   ; preds = %entry
  %conv = zext i1 %enabled to i32
  br label %for.body

for.body:                                         ; preds = %do.body7, %for.body.lr.ph
  %call68 = phi i32 [ %call66, %for.body.lr.ph ], [ %call, %do.body7 ]
  %thread_sibling.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %call68, i32 5
  %3 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ arch_local_irq_save\0A\09cpsid\09i", "=r,~{memory},~{cc}"() #33, !srcloc !1216
  %4 = ptrtoint ptr %flags to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 %3, ptr %flags, align 4
  %and.i.i = and i32 %3, 128
  %tobool.not.i = icmp eq i32 %and.i.i, 0
  br i1 %tobool.not.i, label %if.then.i, label %do.end11.i

if.then.i:                                        ; preds = %for.body
  tail call void @trace_hardirqs_off() #33
  br label %do.end11.i

do.end11.i:                                       ; preds = %if.then.i, %for.body
  %call1223.i = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %5 = load i32, ptr @nr_cpu_ids, align 4
  %cmp1324.i = icmp ult i32 %call1223.i, %5
  br i1 %cmp1324.i, label %do.body15.i, label %sched_core_lock.exit

do.body15.i:                                      ; preds = %do.body15.i, %do.end11.i
  %call1226.i = phi i32 [ %call12.i, %do.body15.i ], [ %call1223.i, %do.end11.i ]
  %i.025.i = phi i32 [ %inc.i, %do.body15.i ], [ 0, %do.end11.i ]
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call1226.i
  %6 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %7, ptrtoint (ptr @runqueues to i32)
  %8 = inttoptr i32 %add.i to ptr
  %inc.i = add i32 %i.025.i, 1
  tail call void @_raw_spin_lock_nested(ptr noundef %8, i32 noundef %i.025.i) #33
  %call12.i = tail call i32 @cpumask_next(i32 noundef %call1226.i, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %9 = load i32, ptr @nr_cpu_ids, align 4
  %cmp13.i = icmp ult i32 %call12.i, %9
  br i1 %cmp13.i, label %do.body15.i, label %sched_core_lock.exit

sched_core_lock.exit:                             ; preds = %do.body15.i, %do.end11.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %10 = load i32, ptr @nr_cpu_ids, align 4
  %call363 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  %cmp464 = icmp ult i32 %call363, %10
  br i1 %cmp464, label %for.body5, label %do.body7

for.body5:                                        ; preds = %for.body5, %sched_core_lock.exit
  %call365 = phi i32 [ %call3, %for.body5 ], [ %call363, %sched_core_lock.exit ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call365
  %11 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %arrayidx, align 4
  %add = add i32 %12, ptrtoint (ptr @runqueues to i32)
  %13 = inttoptr i32 %add to ptr
  %core_enabled = getelementptr inbounds %struct.rq, ptr %13, i32 0, i32 81
  %14 = ptrtoint ptr %core_enabled to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %conv, ptr %core_enabled, align 128
  %call3 = tail call i32 @cpumask_next(i32 noundef %call365, ptr noundef %thread_sibling.i) #37
  %cmp4 = icmp ult i32 %call3, %10
  br i1 %cmp4, label %for.body5, label %do.body7

do.body7:                                         ; preds = %for.body5, %sched_core_lock.exit
  %arrayidx14 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call68
  %15 = ptrtoint ptr %arrayidx14 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %arrayidx14, align 4
  %add15 = add i32 %16, ptrtoint (ptr @runqueues to i32)
  %17 = inttoptr i32 %add15 to ptr
  %core = getelementptr inbounds %struct.rq, ptr %17, i32 0, i32 79
  %18 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %core, align 8
  %core_forceidle_start = getelementptr inbounds %struct.rq, ptr %19, i32 0, i32 90
  %20 = ptrtoint ptr %core_forceidle_start to i32
  call void @__asan_store8_noabort(i32 %20)
  store i64 0, ptr %core_forceidle_start, align 8
  call fastcc void @sched_core_unlock(i32 noundef %call68, ptr noundef nonnull %flags)
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %21 = load i32, ptr @nr_cpu_ids, align 4
  %call.i.i = tail call i32 @__bitmap_andnot(ptr noundef nonnull @sched_core_mask, ptr noundef nonnull @sched_core_mask, ptr noundef %thread_sibling.i, i32 noundef %21) #33
  %call = tail call i32 @cpumask_next(i32 noundef %call68, ptr noundef nonnull @sched_core_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %22 = load i32, ptr @nr_cpu_ids, align 4
  %cmp = icmp ult i32 %call, %22
  br i1 %cmp, label %for.body, label %for.end17.loopexit

for.end17.loopexit:                               ; preds = %do.body7
  %.pre = add i32 %22, 31
  %.pre73 = lshr i32 %.pre, 3
  %.pre74 = and i32 %.pre73, 536870908
  br label %for.end17

for.end17:                                        ; preds = %for.end17.loopexit, %entry
  %mul.i.i52.pre-phi = phi i32 [ %.pre74, %for.end17.loopexit ], [ %mul.i.i, %entry ]
  %.lcssa = phi i32 [ %22, %for.end17.loopexit ], [ %0, %entry ]
  %23 = call ptr @memcpy(ptr @sched_core_mask, ptr @__cpu_possible_mask, i32 %mul.i.i52.pre-phi)
  %call.i.i60 = tail call i32 @__bitmap_andnot(ptr noundef nonnull @sched_core_mask, ptr noundef nonnull @sched_core_mask, ptr noundef nonnull @__cpu_online_mask, i32 noundef %.lcssa) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %24 = load i32, ptr @nr_cpu_ids, align 4
  %call2069 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @sched_core_mask) #37
  %cmp2170 = icmp ult i32 %call2069, %24
  br i1 %cmp2170, label %for.body23.lr.ph, label %for.end36

for.body23.lr.ph:                                 ; preds = %for.end17
  %conv25 = zext i1 %enabled to i32
  br label %for.body23

for.body23:                                       ; preds = %for.body23, %for.body23.lr.ph
  %call2071 = phi i32 [ %call2069, %for.body23.lr.ph ], [ %call20, %for.body23 ]
  %arrayidx33 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call2071
  %25 = ptrtoint ptr %arrayidx33 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %arrayidx33, align 4
  %add34 = add i32 %26, ptrtoint (ptr @runqueues to i32)
  %27 = inttoptr i32 %add34 to ptr
  %core_enabled35 = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 81
  %28 = ptrtoint ptr %core_enabled35 to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 %conv25, ptr %core_enabled35, align 128
  %call20 = tail call i32 @cpumask_next(i32 noundef %call2071, ptr noundef nonnull @sched_core_mask) #37
  %cmp21 = icmp ult i32 %call20, %24
  br i1 %cmp21, label %for.body23, label %for.end36

for.end36:                                        ; preds = %for.body23, %for.end17
  tail call void @cpus_read_unlock() #33
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %flags) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @sched_core_unlock(i32 noundef %cpu, ptr nocapture noundef readonly %flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %thread_sibling.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %cpu, i32 5
  %call131 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp32 = icmp ult i32 %call131, %0
  br i1 %cmp32, label %do.body, label %do.body3

do.body:                                          ; preds = %do.body, %entry
  %call133 = phi i32 [ %call1, %do.body ], [ %call131, %entry ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call133
  %1 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %arrayidx, align 4
  %add = add i32 %2, ptrtoint (ptr @runqueues to i32)
  %3 = inttoptr i32 %add to ptr
  tail call void @_raw_spin_unlock(ptr noundef %3) #33
  %call1 = tail call i32 @cpumask_next(i32 noundef %call133, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp = icmp ult i32 %call1, %4
  br i1 %cmp, label %do.body, label %do.body3

do.body3:                                         ; preds = %do.body, %entry
  %5 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %flags, align 4
  %and.i = and i32 %6, 128
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %if.then, label %do.body8

if.then:                                          ; preds = %do.body3
  tail call void @trace_hardirqs_on() #33
  br label %do.body8

do.body8:                                         ; preds = %if.then, %do.body3
  %7 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i = and i32 %7, 128
  %tobool16.not = icmp eq i32 %and.i.i, 0
  br i1 %tobool16.not, label %if.then20, label %do.end23, !prof !1192

if.then20:                                        ; preds = %do.body8
  tail call void @warn_bogus_irq_restore() #33
  br label %do.end23

do.end23:                                         ; preds = %if.then20, %do.body8
  %8 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %flags, align 4
  tail call void asm sideeffect "\09msr\09cpsr_c, $0\09@ local_irq_restore", "r,~{memory},~{cc}"(i32 %9) #33, !srcloc !1218
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_andnot(ptr noundef, ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @atomic_dec_and_mutex_lock(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @static_key_disable(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @queue_work_on(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @lock_pin_lock(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @update_irq_load_avg(ptr noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_acquire(ptr noundef, i32 noundef, i32 noundef, i32 noundef, i32 noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_release(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i64 @rq_clock_task(ptr noundef %rq) unnamed_addr #3 align 64 {
entry:
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %5 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ult i32 %6, 2
  br i1 %cmp.i, label %land.rhs.i3, label %assert_clock_updated.exit

land.rhs.i3:                                      ; preds = %lockdep_assert_rq_held.exit
  %.b37.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i, label %assert_clock_updated.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs.i3
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %assert_clock_updated.exit

assert_clock_updated.exit:                        ; preds = %if.then.i, %land.rhs.i3, %lockdep_assert_rq_held.exit
  %clock_task = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 28
  %7 = ptrtoint ptr %clock_task to i32
  call void @__asan_load8_noabort(i32 %7)
  %8 = load i64, ptr %clock_task, align 128
  ret i64 %8
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @hrtimer_start_range_ns(ptr noundef, i64 noundef, i64 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @refcount_warn_saturate(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__put_task_struct(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_set_bit(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @rcu_read_lock_sched_held() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @housekeeping_test_cpu(i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rcu_lock_acquire(ptr nocapture noundef readnone %map) #3 align 64 {
entry:
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_acquire(ptr noundef nonnull @rcu_lock_map, i32 noundef 0, i32 noundef 0, i32 noundef 2, i32 noundef 0, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@rcu_lock_acquire, %__here) to i32)) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @rcu_is_watching() local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rcu_lock_release(ptr nocapture noundef readnone %map) #3 align 64 {
entry:
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef nonnull @rcu_lock_map, i32 noundef ptrtoint (ptr blockaddress(@rcu_lock_release, %__here) to i32)) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @rcu_read_unlock_strict() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @cpu_util_update_eff(ptr noundef %css) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %it.i = alloca %struct.css_task_iter, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %if.end, label %land.rhs

land.rhs:                                         ; preds = %entry
  %call.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @uclamp_mutex, i32 0, i32 5), i32 noundef -1) #33
  %cmp.not = icmp eq i32 %call.i, 0
  br i1 %cmp.not, label %do.end, label %if.end, !prof !1192

do.end:                                           ; preds = %land.rhs
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 10051, i32 noundef 9, ptr noundef null) #33
  br label %if.end

if.end:                                           ; preds = %do.end, %land.rhs, %entry
  %call24 = tail call i32 @rcu_read_lock_held() #33
  %tobool25.not = icmp eq i32 %call24, 0
  br i1 %tobool25.not, label %land.rhs33, label %if.end71

land.rhs33:                                       ; preds = %if.end
  %.b186 = load i1, ptr @cpu_util_update_eff.__already_done, align 1
  br i1 %.b186, label %if.end71, label %if.then44, !prof !1191

if.then44:                                        ; preds = %land.rhs33
  store i1 true, ptr @cpu_util_update_eff.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 10052, i32 noundef 9, ptr noundef nonnull @.str.186) #33
  br label %if.end71

if.end71:                                         ; preds = %if.then44, %land.rhs33, %if.end
  %call79 = tail call ptr @css_next_descendant_pre(ptr noundef null, ptr noundef %css) #33
  %tobool80.not192 = icmp eq ptr %call79, null
  br i1 %tobool80.not192, label %for.end148, label %for.body

for.body:                                         ; preds = %for.inc146, %if.end71
  %css.addr.0193 = phi ptr [ %call147, %for.inc146 ], [ %call79, %if.end71 ]
  %parent = getelementptr inbounds %struct.task_group, ptr %css.addr.0193, i32 0, i32 12
  %1 = ptrtoint ptr %parent to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %parent, align 8
  %tobool82.not = icmp eq ptr %2, null
  %uclamp = getelementptr inbounds %struct.task_group, ptr %2, i32 0, i32 19
  %tobool90.not207 = icmp eq ptr %uclamp, null
  %tobool90.not = select i1 %tobool82.not, i1 true, i1 %tobool90.not207
  %arrayidx = getelementptr %struct.task_group, ptr %css.addr.0193, i32 0, i32 18, i32 0
  %3 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load2_noabort(i32 %3)
  %bf.load = load i16, ptr %arrayidx, align 4
  %bf.lshr = lshr i16 %bf.load, 5
  br i1 %tobool90.not, label %for.inc, label %land.lhs.true

land.lhs.true:                                    ; preds = %for.body
  %4 = ptrtoint ptr %uclamp to i32
  call void @__asan_load2_noabort(i32 %4)
  %bf.load93 = load i16, ptr %uclamp, align 4
  %bf.lshr94 = lshr i16 %bf.load93, 5
  %5 = call i16 @llvm.umin.i16(i16 %bf.lshr, i16 %bf.lshr94)
  %arrayidx.1197 = getelementptr %struct.task_group, ptr %css.addr.0193, i32 0, i32 18, i32 1
  %6 = ptrtoint ptr %arrayidx.1197 to i32
  call void @__asan_load2_noabort(i32 %6)
  %bf.load.1198 = load i16, ptr %arrayidx.1197, align 4
  %bf.lshr.1199 = lshr i16 %bf.load.1198, 5
  %arrayidx92.1 = getelementptr %struct.task_group, ptr %2, i32 0, i32 19, i32 1
  %7 = ptrtoint ptr %arrayidx92.1 to i32
  call void @__asan_load2_noabort(i32 %7)
  %bf.load93.1 = load i16, ptr %arrayidx92.1, align 4
  %bf.lshr94.1 = lshr i16 %bf.load93.1, 5
  %8 = call i16 @llvm.umin.i16(i16 %bf.lshr.1199, i16 %bf.lshr94.1)
  br label %for.inc.1

for.inc:                                          ; preds = %for.body
  %arrayidx.1 = getelementptr %struct.task_group, ptr %css.addr.0193, i32 0, i32 18, i32 1
  %9 = ptrtoint ptr %arrayidx.1 to i32
  call void @__asan_load2_noabort(i32 %9)
  %bf.load.1 = load i16, ptr %arrayidx.1, align 4
  %bf.lshr.1 = lshr i16 %bf.load.1, 5
  br label %for.inc.1

for.inc.1:                                        ; preds = %for.inc, %land.lhs.true
  %eff.sroa.0.0.in201 = phi i16 [ %bf.lshr, %for.inc ], [ %5, %land.lhs.true ]
  %eff.sroa.8.0.in = phi i16 [ %bf.lshr.1, %for.inc ], [ %8, %land.lhs.true ]
  %10 = call i16 @llvm.umin.i16(i16 %eff.sroa.0.0.in201, i16 %eff.sroa.8.0.in)
  %uclamp114 = getelementptr inbounds %struct.task_group, ptr %css.addr.0193, i32 0, i32 19
  %11 = ptrtoint ptr %uclamp114 to i32
  call void @__asan_load2_noabort(i32 %11)
  %bf.load121 = load i16, ptr %uclamp114, align 4
  %bf.lshr122 = lshr i16 %bf.load121, 5
  %cmp124 = icmp eq i16 %10, %bf.lshr122
  br i1 %cmp124, label %for.inc139, label %if.end126

if.end126:                                        ; preds = %for.inc.1
  %bf.shl = shl nuw i16 %10, 5
  %bf.clear = and i16 %bf.load121, 3
  %bf.set = or i16 %bf.clear, %bf.shl
  %cmp10.i = icmp ult i16 %10, 820
  %12 = udiv i16 %10, 205
  %.op = shl nuw nsw i16 %12, 2
  %.op.op = and i16 %.op, 28
  %bf.shl135 = select i1 %cmp10.i, i16 %.op.op, i16 16
  %bf.set137 = or i16 %bf.shl135, %bf.set
  %13 = ptrtoint ptr %uclamp114 to i32
  call void @__asan_store2_noabort(i32 %13)
  store i16 %bf.set137, ptr %uclamp114, align 4
  br label %for.inc139

for.inc139:                                       ; preds = %if.end126, %for.inc.1
  %arrayidx120.1 = getelementptr %struct.task_group, ptr %css.addr.0193, i32 0, i32 19, i32 1
  %14 = ptrtoint ptr %arrayidx120.1 to i32
  call void @__asan_load2_noabort(i32 %14)
  %bf.load121.1 = load i16, ptr %arrayidx120.1, align 4
  %bf.lshr122.1 = lshr i16 %bf.load121.1, 5
  %cmp124.1 = icmp eq i16 %eff.sroa.8.0.in, %bf.lshr122.1
  br i1 %cmp124.1, label %for.inc139.1, label %for.inc139.1.thread

for.inc139.1.thread:                              ; preds = %for.inc139
  %bf.shl.1 = shl nuw i16 %eff.sroa.8.0.in, 5
  %bf.clear.1 = and i16 %bf.load121.1, 3
  %bf.set.1 = or i16 %bf.clear.1, %bf.shl.1
  %cmp10.i.1 = icmp ult i16 %eff.sroa.8.0.in, 820
  %15 = udiv i16 %eff.sroa.8.0.in, 205
  %.op.1 = shl nuw nsw i16 %15, 2
  %.op.op.1 = and i16 %.op.1, 28
  %bf.shl135.1 = select i1 %cmp10.i.1, i16 %.op.op.1, i16 16
  %bf.set137.1 = or i16 %bf.shl135.1, %bf.set.1
  %16 = ptrtoint ptr %arrayidx120.1 to i32
  call void @__asan_store2_noabort(i32 %16)
  store i16 %bf.set137.1, ptr %arrayidx120.1, align 4
  br label %if.end145

for.inc139.1:                                     ; preds = %for.inc139
  br i1 %cmp124, label %if.then143, label %if.end145

if.then143:                                       ; preds = %for.inc139.1
  %call144 = call ptr @css_rightmost_descendant(ptr noundef nonnull %css.addr.0193) #33
  br label %for.inc146

if.end145:                                        ; preds = %for.inc139.1, %for.inc139.1.thread
  call void @llvm.lifetime.start.p0(i64 52, ptr nonnull %it.i) #33
  %17 = call ptr @memset(ptr %it.i, i32 255, i32 52)
  call void @css_task_iter_start(ptr noundef nonnull %css.addr.0193, i32 noundef 0, ptr noundef nonnull %it.i) #33
  %call1.i = call ptr @css_task_iter_next(ptr noundef nonnull %it.i) #33
  %tobool.not2.i = icmp eq ptr %call1.i, null
  br i1 %tobool.not2.i, label %uclamp_update_active_tasks.exit, label %while.body.i

while.body.i:                                     ; preds = %while.body.i, %if.end145
  %call3.i = phi ptr [ %call.i187, %while.body.i ], [ %call1.i, %if.end145 ]
  call fastcc void @uclamp_update_active(ptr noundef nonnull %call3.i) #33
  %call.i187 = call ptr @css_task_iter_next(ptr noundef nonnull %it.i) #33
  %tobool.not.i = icmp eq ptr %call.i187, null
  br i1 %tobool.not.i, label %uclamp_update_active_tasks.exit, label %while.body.i

uclamp_update_active_tasks.exit:                  ; preds = %while.body.i, %if.end145
  call void @css_task_iter_end(ptr noundef nonnull %it.i) #33
  call void @llvm.lifetime.end.p0(i64 52, ptr nonnull %it.i) #33
  br label %for.inc146

for.inc146:                                       ; preds = %uclamp_update_active_tasks.exit, %if.then143
  %css.addr.1 = phi ptr [ %css.addr.0193, %uclamp_update_active_tasks.exit ], [ %call144, %if.then143 ]
  %call147 = call ptr @css_next_descendant_pre(ptr noundef %css.addr.1, ptr noundef %css) #33
  %tobool80.not = icmp eq ptr %call147, null
  br i1 %tobool80.not, label %for.end148, label %for.body

for.end148:                                       ; preds = %for.inc146, %if.end71
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @css_next_descendant_pre(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @css_rightmost_descendant(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @css_task_iter_start(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @css_task_iter_next(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @uclamp_update_active(ptr noundef %p) unnamed_addr #3 align 64 {
entry:
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 12
  %arrayidx.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 0
  %5 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load2_noabort(i32 %5)
  %bf.load.i = load i16, ptr %arrayidx.i, align 4
  %6 = and i16 %bf.load.i, 2
  %tobool.not.i = icmp eq i16 %6, 0
  br i1 %tobool.not.i, label %uclamp_rq_reinc_id.exit, label %if.end.i

if.end.i:                                         ; preds = %entry
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call, ptr noundef %p, i32 noundef 0) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call, ptr noundef %p, i32 noundef 0) #33
  br label %uclamp_rq_reinc_id.exit

uclamp_rq_reinc_id.exit:                          ; preds = %if.end.i, %entry
  %arrayidx.i.1 = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 1
  %7 = ptrtoint ptr %arrayidx.i.1 to i32
  call void @__asan_load2_noabort(i32 %7)
  %bf.load.i.1 = load i16, ptr %arrayidx.i.1, align 4
  %8 = and i16 %bf.load.i.1, 2
  %tobool.not.i.1 = icmp eq i16 %8, 0
  br i1 %tobool.not.i.1, label %uclamp_rq_reinc_id.exit.1, label %land.lhs.true.i.1

land.lhs.true.i.1:                                ; preds = %uclamp_rq_reinc_id.exit
  tail call fastcc void @uclamp_rq_dec_id(ptr noundef %call, ptr noundef %p, i32 noundef 1) #33
  tail call fastcc void @uclamp_rq_inc_id(ptr noundef %call, ptr noundef %p, i32 noundef 1) #33
  %9 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %uclamp_flags.i, align 16
  %and.i.1 = and i32 %10, 1
  %tobool1.not.i.1 = icmp eq i32 %and.i.1, 0
  br i1 %tobool1.not.i.1, label %uclamp_rq_reinc_id.exit.1, label %if.then2.i.1

if.then2.i.1:                                     ; preds = %land.lhs.true.i.1
  %and4.i.1 = and i32 %10, -2
  %11 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 %and4.i.1, ptr %uclamp_flags.i, align 16
  br label %uclamp_rq_reinc_id.exit.1

uclamp_rq_reinc_id.exit.1:                        ; preds = %if.then2.i.1, %land.lhs.true.i.1, %uclamp_rq_reinc_id.exit
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %12 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %13, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %uclamp_rq_reinc_id.exit.1
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %14 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %uclamp_rq_reinc_id.exit.1
  %retval.0.i.i.i = phi ptr [ %15, %if.then.i.i.i ], [ %call, %uclamp_rq_reinc_id.exit.1 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %16 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %16)
  %.unpack.i.i = load i32, ptr %1, align 4
  %17 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %17) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@uclamp_update_active, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %18 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %19, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %20 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %21, %if.then.i.i4.i ], [ %call, %land.rhs.i.i.i.i ], [ %call, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %22 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %23) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @css_task_iter_end(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @uclamp_rq_dec_id(ptr noundef %rq, ptr nocapture noundef %p, i32 noundef %clamp_id) unnamed_addr #3 align 64 {
entry:
  %arrayidx = getelementptr %struct.rq, ptr %rq, i32 0, i32 11, i32 %clamp_id
  %arrayidx2 = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 %clamp_id
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %5 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %5)
  %bf.load = load i16, ptr %arrayidx2, align 4
  %6 = and i16 %bf.load, 2
  %tobool.not = icmp eq i16 %6, 0
  br i1 %tobool.not, label %cleanup, label %if.end, !prof !1192

if.end:                                           ; preds = %lockdep_assert_rq_held.exit
  %bf.lshr8 = lshr i16 %bf.load, 2
  %bf.clear9 = and i16 %bf.lshr8, 7
  %bf.cast10 = zext i16 %bf.clear9 to i32
  %arrayidx11 = getelementptr %struct.rq, ptr %rq, i32 0, i32 11, i32 %clamp_id, i32 1, i32 %bf.cast10
  %7 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_load4_noabort(i32 %7)
  %bf.load12 = load i32, ptr %arrayidx11, align 4
  %bf.clear13 = and i32 %bf.load12, 2097151
  %tobool14.not = icmp eq i32 %bf.clear13, 0
  br i1 %tobool14.not, label %land.rhs, label %if.end53

land.rhs:                                         ; preds = %if.end
  %.b192 = load i1, ptr @uclamp_rq_dec_id.__already_done, align 1
  br i1 %.b192, label %if.end53, label %if.then31, !prof !1191

if.then31:                                        ; preds = %land.rhs
  store i1 true, ptr @uclamp_rq_dec_id.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 1582, i32 noundef 9, ptr noundef nonnull @.str.187) #33
  br label %if.end53

if.end53:                                         ; preds = %if.then31, %land.rhs, %if.end
  %8 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_load4_noabort(i32 %8)
  %bf.load61 = load i32, ptr %arrayidx11, align 4
  %bf.clear62 = and i32 %bf.load61, 2097151
  %tobool63.not = icmp eq i32 %bf.clear62, 0
  br i1 %tobool63.not, label %if.end75, label %if.then70, !prof !1192

if.then70:                                        ; preds = %if.end53
  %dec = add i32 %bf.load61, 2097151
  %bf.value = and i32 %dec, 2097151
  %bf.clear74 = and i32 %bf.load61, -2097152
  %bf.set = or i32 %bf.value, %bf.clear74
  %9 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %bf.set, ptr %arrayidx11, align 4
  br label %if.end75

if.end75:                                         ; preds = %if.then70, %if.end53
  %10 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %10)
  %bf.load76 = load i16, ptr %arrayidx2, align 4
  %bf.clear77 = and i16 %bf.load76, -3
  store i16 %bf.clear77, ptr %arrayidx2, align 4
  %11 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_load4_noabort(i32 %11)
  %bf.load79 = load i32, ptr %arrayidx11, align 4
  %bf.clear80 = and i32 %bf.load79, 2097151
  %tobool81.not = icmp eq i32 %bf.clear80, 0
  br i1 %tobool81.not, label %do.end92, label %cleanup, !prof !1192

do.end92:                                         ; preds = %if.end75
  %12 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %arrayidx, align 4
  %bf.lshr96 = lshr i32 %bf.load79, 21
  %cmp = icmp ugt i32 %bf.lshr96, %13
  br i1 %cmp, label %land.rhs103, label %if.end141

land.rhs103:                                      ; preds = %do.end92
  %.b190191 = load i1, ptr @uclamp_rq_dec_id.__already_done.188, align 1
  br i1 %.b190191, label %if.end141, label %if.then114, !prof !1191

if.then114:                                       ; preds = %land.rhs103
  store i1 true, ptr @uclamp_rq_dec_id.__already_done.188, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 1602, i32 noundef 9, ptr noundef nonnull @.str.189) #33
  br label %if.end141

if.end141:                                        ; preds = %if.then114, %land.rhs103, %do.end92
  %14 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_load4_noabort(i32 %14)
  %bf.load149 = load i32, ptr %arrayidx11, align 4
  %bf.lshr150 = lshr i32 %bf.load149, 21
  %cmp151.not = icmp ult i32 %bf.lshr150, %13
  br i1 %cmp151.not, label %cleanup, label %if.then152

if.then152:                                       ; preds = %if.end141
  %15 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %15)
  %bf.load153 = load i16, ptr %arrayidx2, align 4
  %bf.lshr154 = lshr i16 %bf.load153, 5
  %bf.cast155 = zext i16 %bf.lshr154 to i32
  %call = tail call fastcc i32 @uclamp_rq_max_value(ptr noundef %rq, i32 noundef %clamp_id, i32 noundef %bf.cast155)
  %16 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %16)
  store volatile i32 %call, ptr %arrayidx, align 4
  br label %cleanup

cleanup:                                          ; preds = %if.then152, %if.end141, %if.end75, %lockdep_assert_rq_held.exit
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @uclamp_rq_inc_id(ptr noundef %rq, ptr nocapture noundef %p, i32 noundef %clamp_id) unnamed_addr #3 align 64 {
entry:
  %arrayidx = getelementptr %struct.rq, ptr %rq, i32 0, i32 11, i32 %clamp_id
  %arrayidx2 = getelementptr %struct.task_struct, ptr %p, i32 0, i32 27, i32 %clamp_id
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %arrayidx.i.i = getelementptr %struct.task_struct, ptr %p, i32 0, i32 26, i32 %clamp_id
  %5 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %arrayidx.i.i, align 4
  %retval.sroa.0.0.extract.shift.i.i = lshr i32 %6, 16
  %retval.sroa.0.0.extract.trunc.i.i = trunc i32 %retval.sroa.0.0.extract.shift.i.i to i16
  %sched_task_group.i.i.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 25
  %7 = ptrtoint ptr %sched_task_group.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %sched_task_group.i.i.i, align 8
  %autogroup.i.i.i = getelementptr inbounds %struct.task_group, ptr %8, i32 0, i32 15
  %9 = ptrtoint ptr %autogroup.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %autogroup.i.i.i, align 4
  %tobool.i.i.i = icmp ne ptr %10, null
  %cmp.i.i = icmp eq ptr %8, @root_task_group
  %or.cond.i.i = select i1 %tobool.i.i.i, i1 true, i1 %cmp.i.i
  br i1 %or.cond.i.i, label %uclamp_tg_restrict.exit.i, label %if.end4.i.i

if.end4.i.i:                                      ; preds = %lockdep_assert_rq_held.exit
  %uclamp.i.i = getelementptr inbounds %struct.task_group, ptr %8, i32 0, i32 19
  %11 = ptrtoint ptr %uclamp.i.i to i32
  call void @__asan_load2_noabort(i32 %11)
  %bf.load.i.i = load i16, ptr %uclamp.i.i, align 16
  %bf.lshr.i.i = lshr i16 %bf.load.i.i, 5
  %arrayidx9.i.i = getelementptr %struct.task_group, ptr %8, i32 0, i32 19, i32 1
  %12 = ptrtoint ptr %arrayidx9.i.i to i32
  call void @__asan_load2_noabort(i32 %12)
  %bf.load10.i.i = load i16, ptr %arrayidx9.i.i, align 4
  %bf.lshr11.i.i = lshr i16 %bf.load10.i.i, 5
  %bf.lshr14.i.i = lshr i16 %retval.sroa.0.0.extract.trunc.i.i, 5
  %13 = tail call i16 @llvm.umax.i16(i16 %bf.lshr14.i.i, i16 %bf.lshr.i.i) #33
  %14 = tail call i16 @llvm.umin.i16(i16 %13, i16 %bf.lshr11.i.i) #33
  %bf.shl.i.i.i = shl nuw i16 %14, 5
  %bf.clear.i.i.i = and i16 %retval.sroa.0.0.extract.trunc.i.i, 2
  %bf.set.i.i.i = or i16 %bf.shl.i.i.i, %bf.clear.i.i.i
  %cmp10.i.i.i.i = icmp ult i16 %14, 820
  %div8.i.i37.i.i = udiv i16 %14, 205
  %.op.i.i.i = shl nuw nsw i16 %div8.i.i37.i.i, 2
  %.op.op.i.i.i = and i16 %.op.i.i.i, 28
  %bf.shl3.i.i.i = select i1 %cmp10.i.i.i.i, i16 %.op.op.i.i.i, i16 16
  %bf.set5.i.i.i = or i16 %bf.shl3.i.i.i, %bf.set.i.i.i
  br label %uclamp_tg_restrict.exit.i

uclamp_tg_restrict.exit.i:                        ; preds = %if.end4.i.i, %lockdep_assert_rq_held.exit
  %retval.sroa.0.0.i.i = phi i16 [ %retval.sroa.0.0.extract.trunc.i.i, %lockdep_assert_rq_held.exit ], [ %bf.set5.i.i.i, %if.end4.i.i ]
  %arrayidx.i = getelementptr [2 x %struct.uclamp_se], ptr @uclamp_default, i32 0, i32 %clamp_id
  %15 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load2_noabort(i32 %15)
  %uc_max.sroa.0.0.copyload.i = load i16, ptr %arrayidx.i, align 4
  %16 = lshr i16 %retval.sroa.0.0.i.i, 5
  %bf.lshr2.i = lshr i16 %uc_max.sroa.0.0.copyload.i, 5
  %cmp.i = icmp ugt i16 %16, %bf.lshr2.i
  br i1 %cmp.i, label %if.then.i, label %if.end.i, !prof !1192

if.then.i:                                        ; preds = %uclamp_tg_restrict.exit.i
  %uc_max.sroa.7.0.arrayidx.sroa_idx.i = getelementptr inbounds i8, ptr %arrayidx.i, i32 3
  %17 = ptrtoint ptr %uc_max.sroa.7.0.arrayidx.sroa_idx.i to i32
  call void @__asan_load1_noabort(i32 %17)
  %uc_max.sroa.7.0.copyload.i = load i8, ptr %uc_max.sroa.7.0.arrayidx.sroa_idx.i, align 1
  %uc_max.sroa.6.0.arrayidx.sroa_idx.i = getelementptr inbounds i8, ptr %arrayidx.i, i32 2
  %18 = ptrtoint ptr %uc_max.sroa.6.0.arrayidx.sroa_idx.i to i32
  call void @__asan_load1_noabort(i32 %18)
  %uc_max.sroa.6.0.copyload.i = load i8, ptr %uc_max.sroa.6.0.arrayidx.sroa_idx.i, align 2
  br label %uclamp_eff_get.exit

if.end.i:                                         ; preds = %uclamp_tg_restrict.exit.i
  %uc_req.sroa.7.0.extract.trunc.i = trunc i32 %6 to i8
  %retval.sroa.6.0.insert.insert.i.i = lshr i32 %6, 8
  %uc_req.sroa.6.0.extract.trunc.i = trunc i32 %retval.sroa.6.0.insert.insert.i.i to i8
  br label %uclamp_eff_get.exit

uclamp_eff_get.exit:                              ; preds = %if.end.i, %if.then.i
  %retval.sroa.0.0.i = phi i16 [ %uc_max.sroa.0.0.copyload.i, %if.then.i ], [ %retval.sroa.0.0.i.i, %if.end.i ]
  %retval.sroa.3.0.i = phi i8 [ %uc_max.sroa.6.0.copyload.i, %if.then.i ], [ %uc_req.sroa.6.0.extract.trunc.i, %if.end.i ]
  %retval.sroa.5.0.i = phi i8 [ %uc_max.sroa.7.0.copyload.i, %if.then.i ], [ %uc_req.sroa.7.0.extract.trunc.i, %if.end.i ]
  %retval.sroa.5.0.insert.ext.i = zext i8 %retval.sroa.5.0.i to i32
  %retval.sroa.3.0.insert.ext.i = zext i8 %retval.sroa.3.0.i to i32
  %retval.sroa.3.0.insert.shift.i = shl nuw nsw i32 %retval.sroa.3.0.insert.ext.i, 8
  %retval.sroa.3.0.insert.insert.i = or i32 %retval.sroa.3.0.insert.shift.i, %retval.sroa.5.0.insert.ext.i
  %retval.sroa.0.0.insert.ext.i = zext i16 %retval.sroa.0.0.i to i32
  %retval.sroa.0.0.insert.shift.i = shl nuw i32 %retval.sroa.0.0.insert.ext.i, 16
  %retval.sroa.0.0.insert.insert.i = or i32 %retval.sroa.3.0.insert.insert.i, %retval.sroa.0.0.insert.shift.i
  %19 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %retval.sroa.0.0.insert.insert.i, ptr %arrayidx2, align 4
  %bf.lshr = lshr i16 %retval.sroa.0.0.i, 2
  %bf.clear = and i16 %bf.lshr, 7
  %bf.cast = zext i16 %bf.clear to i32
  %arrayidx6 = getelementptr %struct.rq, ptr %rq, i32 0, i32 11, i32 %clamp_id, i32 1, i32 %bf.cast
  %20 = ptrtoint ptr %arrayidx6 to i32
  call void @__asan_load4_noabort(i32 %20)
  %bf.load7 = load i32, ptr %arrayidx6, align 4
  %inc = add i32 %bf.load7, 1
  %bf.value = and i32 %inc, 2097151
  %bf.clear10 = and i32 %bf.load7, -2097152
  %bf.set = or i32 %bf.value, %bf.clear10
  store i32 %bf.set, ptr %arrayidx6, align 4
  %bf.load11 = load i16, ptr %arrayidx2, align 4
  %bf.set13 = or i16 %bf.load11, 2
  store i16 %bf.set13, ptr %arrayidx2, align 4
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 12
  %21 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %uclamp_flags.i, align 16
  %and.i = and i32 %22, 1
  %tobool.not.i71 = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i71, label %uclamp_idle_reset.exit, label %do.body2.i

do.body2.i:                                       ; preds = %uclamp_eff_get.exit
  %bf.lshr15 = lshr i16 %bf.load11, 5
  %bf.cast16 = zext i16 %bf.lshr15 to i32
  %23 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %23)
  store volatile i32 %bf.cast16, ptr %arrayidx, align 8
  br label %uclamp_idle_reset.exit

uclamp_idle_reset.exit:                           ; preds = %do.body2.i, %uclamp_eff_get.exit
  %24 = ptrtoint ptr %arrayidx6 to i32
  call void @__asan_load4_noabort(i32 %24)
  %bf.load17 = load i32, ptr %arrayidx6, align 4
  %bf.clear18 = and i32 %bf.load17, 2097151
  %cmp = icmp eq i32 %bf.clear18, 1
  br i1 %cmp, label %if.then, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %uclamp_idle_reset.exit
  %25 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %25)
  %bf.load19 = load i16, ptr %arrayidx2, align 4
  %bf.lshr20 = lshr i16 %bf.load19, 5
  %bf.cast21 = zext i16 %bf.lshr20 to i32
  %bf.lshr23 = lshr i32 %bf.load17, 21
  %cmp24 = icmp ult i32 %bf.lshr23, %bf.cast21
  br i1 %cmp24, label %if.then, label %if.end

if.then:                                          ; preds = %lor.lhs.false, %uclamp_idle_reset.exit
  %26 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %26)
  %bf.load25 = load i16, ptr %arrayidx2, align 4
  %bf.lshr26 = lshr i16 %bf.load25, 5
  %bf.cast27 = zext i16 %bf.lshr26 to i32
  %bf.shl = shl nuw i32 %bf.cast27, 21
  %bf.set31 = or i32 %bf.shl, %bf.clear18
  %27 = ptrtoint ptr %arrayidx6 to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %bf.set31, ptr %arrayidx6, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %lor.lhs.false
  %28 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load2_noabort(i32 %28)
  %bf.load32 = load i16, ptr %arrayidx2, align 4
  %bf.lshr33 = lshr i16 %bf.load32, 5
  %bf.cast34 = zext i16 %bf.lshr33 to i32
  %29 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx, align 4
  %cmp36 = icmp ult i32 %30, %bf.cast34
  br i1 %cmp36, label %do.body42, label %if.end51

do.body42:                                        ; preds = %if.end
  %31 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store4_noabort(i32 %31)
  store volatile i32 %bf.cast34, ptr %arrayidx, align 4
  br label %if.end51

if.end51:                                         ; preds = %do.body42, %if.end
  ret void
}

; Function Attrs: argmemonly inlinehint nofree norecurse nosync nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @uclamp_rq_max_value(ptr nocapture noundef %rq, i32 noundef %clamp_id, i32 noundef %clamp_value) unnamed_addr #24 align 64 {
entry:
  %bucket1 = getelementptr %struct.rq, ptr %rq, i32 0, i32 11, i32 %clamp_id, i32 1
  %arrayidx2 = getelementptr %struct.uclamp_bucket, ptr %bucket1, i32 4
  %0 = ptrtoint ptr %arrayidx2 to i32
  call void @__asan_load4_noabort(i32 %0)
  %bf.load = load i32, ptr %arrayidx2, align 4
  %bf.clear = and i32 %bf.load, 2097151
  %tobool.not = icmp eq i32 %bf.clear, 0
  br i1 %tobool.not, label %for.cond, label %if.end

for.cond:                                         ; preds = %entry
  %arrayidx2.1 = getelementptr %struct.uclamp_bucket, ptr %bucket1, i32 3
  %1 = ptrtoint ptr %arrayidx2.1 to i32
  call void @__asan_load4_noabort(i32 %1)
  %bf.load.1 = load i32, ptr %arrayidx2.1, align 4
  %bf.clear.1 = and i32 %bf.load.1, 2097151
  %tobool.not.1 = icmp eq i32 %bf.clear.1, 0
  br i1 %tobool.not.1, label %for.cond.1, label %if.end

for.cond.1:                                       ; preds = %for.cond
  %arrayidx2.2 = getelementptr %struct.uclamp_bucket, ptr %bucket1, i32 2
  %2 = ptrtoint ptr %arrayidx2.2 to i32
  call void @__asan_load4_noabort(i32 %2)
  %bf.load.2 = load i32, ptr %arrayidx2.2, align 4
  %bf.clear.2 = and i32 %bf.load.2, 2097151
  %tobool.not.2 = icmp eq i32 %bf.clear.2, 0
  br i1 %tobool.not.2, label %for.cond.2, label %if.end

for.cond.2:                                       ; preds = %for.cond.1
  %arrayidx2.3 = getelementptr %struct.uclamp_bucket, ptr %bucket1, i32 1
  %3 = ptrtoint ptr %arrayidx2.3 to i32
  call void @__asan_load4_noabort(i32 %3)
  %bf.load.3 = load i32, ptr %arrayidx2.3, align 4
  %bf.clear.3 = and i32 %bf.load.3, 2097151
  %tobool.not.3 = icmp eq i32 %bf.clear.3, 0
  br i1 %tobool.not.3, label %for.cond.3, label %if.end

for.cond.3:                                       ; preds = %for.cond.2
  %4 = ptrtoint ptr %bucket1 to i32
  call void @__asan_load4_noabort(i32 %4)
  %bf.load.4 = load i32, ptr %bucket1, align 4
  %bf.clear.4 = and i32 %bf.load.4, 2097151
  %tobool.not.4 = icmp eq i32 %bf.clear.4, 0
  br i1 %tobool.not.4, label %for.cond.4, label %if.end

for.cond.4:                                       ; preds = %for.cond.3
  %cmp.i = icmp eq i32 %clamp_id, 1
  br i1 %cmp.i, label %if.then.i, label %cleanup

if.end:                                           ; preds = %for.cond.3, %for.cond.2, %for.cond.1, %for.cond, %entry
  %bf.load.lcssa = phi i32 [ %bf.load, %entry ], [ %bf.load.1, %for.cond ], [ %bf.load.2, %for.cond.1 ], [ %bf.load.3, %for.cond.2 ], [ %bf.load.4, %for.cond.3 ]
  %bf.lshr = lshr i32 %bf.load.lcssa, 21
  br label %cleanup

if.then.i:                                        ; preds = %for.cond.4
  %uclamp_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 12
  %5 = ptrtoint ptr %uclamp_flags.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %uclamp_flags.i, align 16
  %or.i = or i32 %6, 1
  store i32 %or.i, ptr %uclamp_flags.i, align 16
  br label %cleanup

cleanup:                                          ; preds = %if.then.i, %if.end, %for.cond.4
  %retval.0 = phi i32 [ %bf.lshr, %if.end ], [ %clamp_value, %if.then.i ], [ 0, %for.cond.4 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @uclamp_update_util_min_rt_default(ptr noundef %p) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %prio.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 13
  %5 = ptrtoint ptr %prio.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %prio.i, align 8
  %cmp.i.i = icmp sgt i32 %6, 99
  br i1 %cmp.i.i, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %call1 = call ptr @task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %7 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %7, 0
  br i1 %tobool.not.i, label %if.end.i, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.end
  %dep_map.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %if.end.i, !prof !1192

do.end.i:                                         ; preds = %land.rhs.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 1381, i32 noundef 9, ptr noundef null) #33
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i, %if.end
  %uclamp_req.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 26
  %8 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_load2_noabort(i32 %8)
  %bf.load.i = load i16, ptr %uclamp_req.i, align 4
  %bf.clear.i = and i16 %bf.load.i, 1
  %tobool24.not.i = icmp eq i16 %bf.clear.i, 0
  br i1 %tobool24.not.i, label %if.end26.i, label %__uclamp_update_util_min_rt_default.exit

if.end26.i:                                       ; preds = %if.end.i
  %9 = load i32, ptr @sysctl_sched_uclamp_util_min_rt_default, align 4
  %10 = trunc i32 %9 to i16
  %bf.shl.i.i = shl i16 %10, 5
  %bf.clear.i.i = and i16 %bf.load.i, 2
  %bf.set.i.i = or i16 %bf.shl.i.i, %bf.clear.i.i
  %cmp10.i.i.i = icmp ult i32 %9, 820
  %div8.i.i.i = udiv i32 %9, 205
  %11 = trunc i32 %div8.i.i.i to i16
  %.op.i.i = shl i16 %11, 2
  %.op.op.i.i = and i16 %.op.i.i, 28
  %bf.shl3.i.i = select i1 %cmp10.i.i.i, i16 %.op.op.i.i, i16 16
  %bf.set5.i.i = or i16 %bf.shl3.i.i, %bf.set.i.i
  %12 = ptrtoint ptr %uclamp_req.i to i32
  call void @__asan_store2_noabort(i32 %12)
  store i16 %bf.set5.i.i, ptr %uclamp_req.i, align 4
  br label %__uclamp_update_util_min_rt_default.exit

__uclamp_update_util_min_rt_default.exit:         ; preds = %if.end26.i, %if.end.i
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call1, i32 0, i32 81
  %13 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %14, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %__uclamp_update_util_min_rt_default.exit
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call1, i32 0, i32 79
  %15 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %__uclamp_update_util_min_rt_default.exit
  %retval.0.i.i.i = phi ptr [ %16, %if.then.i.i.i ], [ %call1, %__uclamp_update_util_min_rt_default.exit ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %17 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %17)
  %.unpack.i.i = load i32, ptr %1, align 4
  %18 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %18) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@uclamp_update_util_min_rt_default, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %19 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %20, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call1, i32 0, i32 79
  %21 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %22, %if.then.i.i4.i ], [ %call1, %land.rhs.i.i.i.i ], [ %call1, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %23 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %24) #33
  br label %cleanup

cleanup:                                          ; preds = %task_rq_unlock.exit, %entry
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @psi_task_change(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_set_class(ptr noundef, ptr noundef, ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_weight(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid allocsize(0)
declare dso_local noalias ptr @__kmalloc(i32 noundef, i32 noundef) local_unnamed_addr #25

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @__set_cpus_allowed_ptr_locked(ptr noundef %p, ptr noundef %new_mask, i32 noundef %flags, ptr noundef %rq, ptr nocapture noundef %rf) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %flags1 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 3
  %0 = ptrtoint ptr %flags1 to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %flags1, align 4
  %and = and i32 %1, 2097152
  %tobool.not = icmp eq i32 %and, 0
  tail call void @update_rq_clock(ptr noundef %rq)
  br i1 %tobool.not, label %lor.lhs.false, label %if.end7

lor.lhs.false:                                    ; preds = %entry
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %2 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %2)
  %3 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %3, 0
  %spec.select = select i1 %tobool.i.not, ptr @__cpu_active_mask, ptr @__cpu_online_mask
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %call.i.i = tail call i32 @__bitmap_subset(ptr noundef %new_mask, ptr noundef nonnull @__cpu_possible_mask, i32 noundef %4) #33
  %tobool5.not = icmp eq i32 %call.i.i, 0
  br i1 %tobool5.not, label %out, label %if.end7

if.end7:                                          ; preds = %lor.lhs.false, %entry
  %cpu_valid_mask.0135 = phi ptr [ %spec.select, %lor.lhs.false ], [ @__cpu_online_mask, %entry ]
  %and8 = and i32 %flags, 1
  %tobool9.not = icmp eq i32 %and8, 0
  br i1 %tobool9.not, label %if.end15, label %land.lhs.true10

land.lhs.true10:                                  ; preds = %if.end7
  %5 = ptrtoint ptr %flags1 to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %flags1, align 4
  %and12 = and i32 %6, 67108864
  %tobool13.not = icmp eq i32 %and12, 0
  br i1 %tobool13.not, label %if.end15, label %out

if.end15:                                         ; preds = %land.lhs.true10, %if.end7
  %and16 = and i32 %flags, 4
  %tobool17.not = icmp eq i32 %and16, 0
  br i1 %tobool17.not, label %if.then18, label %if.end72

if.then18:                                        ; preds = %if.end15
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %7 = load i32, ptr @nr_cpu_ids, align 4
  %call13.i.i = tail call i32 @__bitmap_equal(ptr noundef %cpus_mask, ptr noundef %new_mask, i32 noundef %7) #33
  %tobool.i126.not = icmp eq i32 %call13.i.i, 0
  br i1 %tobool.i126.not, label %if.end21, label %out

if.end21:                                         ; preds = %if.then18
  %8 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 2
  %10 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %task, align 8
  %cmp = icmp eq ptr %11, %p
  br i1 %cmp, label %land.lhs.true23, label %if.end72

land.lhs.true23:                                  ; preds = %if.end21
  %migration_disabled.i127 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %12 = ptrtoint ptr %migration_disabled.i127 to i32
  call void @__asan_load2_noabort(i32 %12)
  %13 = load i16, ptr %migration_disabled.i127, align 4
  %tobool.i128.not = icmp eq i16 %13, 0
  br i1 %tobool.i128.not, label %if.end72, label %land.rhs

land.rhs:                                         ; preds = %land.lhs.true23
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %14 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 3
  %16 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %cpu.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %18 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %18, %17
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %land.rhs
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %land.rhs
  %div3.i.i = lshr i32 %17, 5
  %arrayidx.i.i = getelementptr i32, ptr %new_mask, i32 %div3.i.i
  %19 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i129 = and i32 %17, 31
  %21 = shl nuw i32 1, %and.i.i129
  %22 = and i32 %20, %21
  %tobool27.not = icmp eq i32 %22, 0
  br i1 %tobool27.not, label %land.rhs32, label %if.end72

land.rhs32:                                       ; preds = %cpumask_test_cpu.exit
  %.b114 = load i1, ptr @__set_cpus_allowed_ptr_locked.__already_done, align 1
  br i1 %.b114, label %out, label %if.then39, !prof !1191

if.then39:                                        ; preds = %land.rhs32
  store i1 true, ptr @__set_cpus_allowed_ptr_locked.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2835, i32 noundef 9, ptr noundef null) #33
  br label %out

if.end72:                                         ; preds = %cpumask_test_cpu.exit, %land.lhs.true23, %if.end21, %if.end15
  %call73 = tail call i32 @cpumask_any_and_distribute(ptr noundef nonnull %cpu_valid_mask.0135, ptr noundef %new_mask) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %23 = load i32, ptr @nr_cpu_ids, align 4
  %cmp74.not = icmp ult i32 %call73, %23
  br i1 %cmp74.not, label %if.end76, label %out

if.end76:                                         ; preds = %if.end72
  tail call fastcc void @__do_set_cpus_allowed(ptr noundef %p, ptr noundef %new_mask, i32 noundef %flags)
  %and77 = and i32 %flags, 8
  %tobool78.not = icmp eq i32 %and77, 0
  br i1 %tobool78.not, label %if.end81, label %if.then79

if.then79:                                        ; preds = %if.end76
  %user_cpus_ptr.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 34
  %24 = ptrtoint ptr %user_cpus_ptr.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load ptr, ptr %user_cpus_ptr.i, align 16
  store ptr null, ptr %user_cpus_ptr.i, align 16
  br label %if.end81

if.end81:                                         ; preds = %if.then79, %if.end76
  %user_mask.0 = phi ptr [ %25, %if.then79 ], [ null, %if.end76 ]
  %call82 = tail call fastcc i32 @affine_move_task(ptr noundef %rq, ptr noundef %p, ptr noundef %rf, i32 noundef %call73, i32 noundef %flags)
  tail call void @kfree(ptr noundef %user_mask.0) #33
  br label %cleanup

out:                                              ; preds = %if.end72, %if.then39, %land.rhs32, %if.then18, %land.lhs.true10, %lor.lhs.false
  %ret.0 = phi i32 [ 0, %if.then18 ], [ -22, %lor.lhs.false ], [ -22, %land.lhs.true10 ], [ -16, %if.then39 ], [ -22, %if.end72 ], [ -16, %land.rhs32 ]
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %26 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %27, 2
  br i1 %cmp.i.i, label %if.then.i.i131, label %if.end.i.i132

if.then.i.i131:                                   ; preds = %out
  %clock_update_flags1.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %28 = ptrtoint ptr %clock_update_flags1.i.i to i32
  call void @__asan_store4_noabort(i32 %28)
  store i32 4, ptr %clock_update_flags1.i.i, align 4
  br label %if.end.i.i132

if.end.i.i132:                                    ; preds = %if.then.i.i131, %out
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %29 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %30, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i133

if.then.i.i.i133:                                 ; preds = %if.end.i.i132
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %31 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i133, %if.end.i.i132
  %retval.0.i.i.i = phi ptr [ %32, %if.then.i.i.i133 ], [ %rq, %if.end.i.i132 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %cookie.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %33 = ptrtoint ptr %cookie.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %.unpack.i.i = load i32, ptr %cookie.i.i, align 4
  %34 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %34) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__set_cpus_allowed_ptr_locked, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %35 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %36, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %37 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %38, %if.then.i.i4.i ], [ %rq, %land.rhs.i.i.i.i ], [ %rq, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %39 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %40) #33
  br label %cleanup

cleanup:                                          ; preds = %task_rq_unlock.exit, %if.end81
  %retval.0 = phi i32 [ %ret.0, %task_rq_unlock.exit ], [ %call82, %if.end81 ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @cpumask_any_and_distribute(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @affine_move_task(ptr noundef %rq, ptr noundef %p, ptr nocapture noundef %rf, i32 noundef %dest_cpu, i32 noundef %flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %my_pending = alloca %struct.set_affinity_pending, align 4
  %__wbq_entry = alloca %struct.wait_bit_queue_entry, align 4
  call void @llvm.lifetime.start.p0(i64 100, ptr nonnull %my_pending) #33
  %0 = call ptr @memset(ptr %my_pending, i32 0, i32 100)
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %1 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 3
  %3 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %cpu.i, align 4
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %5 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %5, %4
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %entry
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %entry
  %div3.i.i = lshr i32 %4, 5
  %arrayidx.i.i = getelementptr i32, ptr %cpus_mask, i32 %div3.i.i
  %6 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i = and i32 %4, 31
  %8 = shl nuw i32 1, %and.i.i
  %9 = and i32 %7, %8
  %tobool.not = icmp eq i32 %9, 0
  %and25 = and i32 %flags, 4
  %tobool26.not = icmp eq i32 %and25, 0
  br i1 %tobool.not, label %if.end24, label %if.then

if.then:                                          ; preds = %cpumask_test_cpu.exit
  br i1 %tobool26.not, label %if.end, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.then
  %migration_flags = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 38
  %10 = ptrtoint ptr %migration_flags to i32
  call void @__asan_load2_noabort(i32 %10)
  %11 = load i16, ptr %migration_flags, align 2
  %12 = and i16 %11, 1
  %tobool4.not = icmp eq i16 %12, 0
  br i1 %tobool4.not, label %if.end, label %land.lhs.true5

land.lhs.true5:                                   ; preds = %land.lhs.true
  %push_busy = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 77
  %13 = ptrtoint ptr %push_busy to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %push_busy, align 4
  %tobool6.not = icmp eq i32 %14, 0
  br i1 %tobool6.not, label %if.then7, label %if.end

if.then7:                                         ; preds = %land.lhs.true5
  %15 = ptrtoint ptr %push_busy to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 1, ptr %push_busy, align 4
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %16 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %16, 0
  %tobool1.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i, label %if.end15.sink.split.i.i.i.i, label %if.else.i.i.i.i, !prof !1192

if.else.i.i.i.i:                                  ; preds = %if.then7
  %add.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i, 1
  %17 = or i32 %add.i.i.i.i, %asmresult.i.i.i.i.i.i
  %.not.i.i.i.i = icmp sgt i32 %17, -1
  br i1 %.not.i.i.i.i, label %if.end, label %if.end15.sink.split.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i:                      ; preds = %if.else.i.i.i.i, %if.then7
  %.sink.i.i.i.i = phi i32 [ 2, %if.then7 ], [ 1, %if.else.i.i.i.i ]
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef %.sink.i.i.i.i) #33
  br label %if.end

if.end:                                           ; preds = %if.end15.sink.split.i.i.i.i, %if.else.i.i.i.i, %land.lhs.true5, %land.lhs.true, %if.then
  %push_task.0 = phi ptr [ null, %land.lhs.true5 ], [ null, %land.lhs.true ], [ null, %if.then ], [ %p, %if.else.i.i.i.i ], [ %p, %if.end15.sink.split.i.i.i.i ]
  %migration_pending = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 36
  %18 = ptrtoint ptr %migration_pending to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %migration_pending, align 8
  %tobool10.not = icmp eq ptr %19, null
  br i1 %tobool10.not, label %if.end16, label %land.lhs.true11

land.lhs.true11:                                  ; preds = %if.end
  %stop_pending12 = getelementptr inbounds %struct.set_affinity_pending, ptr %19, i32 0, i32 1
  %20 = ptrtoint ptr %stop_pending12 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %stop_pending12, align 4
  %tobool13.not = icmp eq i32 %21, 0
  br i1 %tobool13.not, label %if.then14, label %if.end16

if.then14:                                        ; preds = %land.lhs.true11
  %22 = ptrtoint ptr %migration_pending to i32
  call void @__asan_store4_noabort(i32 %22)
  store ptr null, ptr %migration_pending, align 8
  br label %if.end16

if.end16:                                         ; preds = %if.then14, %land.lhs.true11, %if.end
  %complete.0.off0 = phi i1 [ false, %land.lhs.true11 ], [ true, %if.then14 ], [ false, %if.end ]
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %23 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %24, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end16
  %clock_update_flags1.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %25 = ptrtoint ptr %clock_update_flags1.i.i to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 4, ptr %clock_update_flags1.i.i, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end16
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %26 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %27, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i296

if.then.i.i.i296:                                 ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %28 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i296, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %29, %if.then.i.i.i296 ], [ %rq, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %cookie.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %30 = ptrtoint ptr %cookie.i.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %.unpack.i.i = load i32, ptr %cookie.i.i, align 4
  %31 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %31) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@affine_move_task, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %32 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %33, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %34 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %35, %if.then.i.i4.i ], [ %rq, %land.rhs.i.i.i.i ], [ %rq, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %36 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %37) #33
  %tobool17.not = icmp eq ptr %push_task.0, null
  br i1 %tobool17.not, label %if.end20, label %if.then18

if.then18:                                        ; preds = %task_rq_unlock.exit
  %cpu = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %38 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %cpu, align 4
  %push_work = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 78
  %call19 = tail call zeroext i1 @stop_one_cpu_nowait(i32 noundef %39, ptr noundef nonnull @push_cpu_stop, ptr noundef %p, ptr noundef %push_work) #33
  br label %if.end20

if.end20:                                         ; preds = %if.then18, %task_rq_unlock.exit
  br i1 %complete.0.off0, label %if.then22, label %cleanup224

if.then22:                                        ; preds = %if.end20
  %done = getelementptr inbounds %struct.set_affinity_pending, ptr %19, i32 0, i32 2
  tail call void @complete_all(ptr noundef %done) #33
  br label %cleanup224

if.end24:                                         ; preds = %cpumask_test_cpu.exit
  br i1 %tobool26.not, label %if.then27, label %if.end40

if.then27:                                        ; preds = %if.end24
  %migration_pending28 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 36
  %40 = ptrtoint ptr %migration_pending28 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load ptr, ptr %migration_pending28, align 8
  %tobool29.not = icmp eq ptr %41, null
  br i1 %tobool29.not, label %if.then30, label %if.else

if.then30:                                        ; preds = %if.then27
  %call.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef nonnull %my_pending, i32 noundef 4) #33
  %42 = ptrtoint ptr %my_pending to i32
  call void @__asan_store4_noabort(i32 %42)
  store volatile i32 1, ptr %my_pending, align 4
  %done31 = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 2
  %43 = ptrtoint ptr %done31 to i32
  call void @__asan_store4_noabort(i32 %43)
  store i32 0, ptr %done31, align 4
  %wait.i = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 2, i32 1
  call void @__init_swait_queue_head(ptr noundef %wait.i, ptr noundef nonnull @.str.192, ptr noundef nonnull @init_completion.__key) #33
  %arg = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 4
  %44 = ptrtoint ptr %arg to i32
  call void @__asan_store4_noabort(i32 %44)
  store ptr %p, ptr %arg, align 4
  %.compoundliteral.sroa.2.0.arg.sroa_idx = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 4, i32 1
  %45 = ptrtoint ptr %.compoundliteral.sroa.2.0.arg.sroa_idx to i32
  call void @__asan_store4_noabort(i32 %45)
  store i32 %dest_cpu, ptr %.compoundliteral.sroa.2.0.arg.sroa_idx, align 4
  %.compoundliteral.sroa.3.0.arg.sroa_idx = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 4, i32 2
  %46 = ptrtoint ptr %.compoundliteral.sroa.3.0.arg.sroa_idx to i32
  call void @__asan_store4_noabort(i32 %46)
  store ptr %my_pending, ptr %.compoundliteral.sroa.3.0.arg.sroa_idx, align 4
  %47 = ptrtoint ptr %migration_pending28 to i32
  call void @__asan_store4_noabort(i32 %47)
  store ptr %my_pending, ptr %migration_pending28, align 8
  br label %if.end40

if.else:                                          ; preds = %if.then27
  %call.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull %41, i32 noundef 4) #33
  tail call void @llvm.prefetch.p0(ptr nonnull %41, i32 1, i32 3, i32 1) #33
  %48 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) %41, ptr nonnull %41, i32 1, ptr nonnull elementtype(i32) %41) #33, !srcloc !1225
  %asmresult.i.i.i.i.i = extractvalue { i32, i32, i32 } %48, 0
  %tobool1.not.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i, label %if.end15.sink.split.i.i.i, label %if.else.i.i.i, !prof !1192

if.else.i.i.i:                                    ; preds = %if.else
  %add.i.i.i = add i32 %asmresult.i.i.i.i.i, 1
  %49 = or i32 %add.i.i.i, %asmresult.i.i.i.i.i
  %.not.i.i.i = icmp sgt i32 %49, -1
  br i1 %.not.i.i.i, label %refcount_inc.exit, label %if.end15.sink.split.i.i.i, !prof !1191

if.end15.sink.split.i.i.i:                        ; preds = %if.else.i.i.i, %if.else
  %.sink.i.i.i = phi i32 [ 2, %if.else ], [ 1, %if.else.i.i.i ]
  tail call void @refcount_warn_saturate(ptr noundef nonnull %41, i32 noundef %.sink.i.i.i) #33
  br label %refcount_inc.exit

refcount_inc.exit:                                ; preds = %if.end15.sink.split.i.i.i, %if.else.i.i.i
  %dest_cpu38 = getelementptr inbounds %struct.set_affinity_pending, ptr %41, i32 0, i32 4, i32 1
  %50 = ptrtoint ptr %dest_cpu38 to i32
  call void @__asan_store4_noabort(i32 %50)
  store i32 %dest_cpu, ptr %dest_cpu38, align 4
  br label %if.end40

if.end40:                                         ; preds = %refcount_inc.exit, %if.then30, %if.end24
  %migration_pending41 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 36
  %51 = ptrtoint ptr %migration_pending41 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %migration_pending41, align 8
  %tobool42.not = icmp eq ptr %52, null
  br i1 %tobool42.not, label %land.rhs, label %if.end84

land.rhs:                                         ; preds = %if.end40
  %.b293 = load i1, ptr @affine_move_task.__already_done, align 1
  br i1 %.b293, label %if.then83, label %if.then52, !prof !1191

if.then52:                                        ; preds = %land.rhs
  store i1 true, ptr @affine_move_task.__already_done, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2720, i32 noundef 9, ptr noundef null) #33
  br label %if.then83

if.then83:                                        ; preds = %if.then52, %land.rhs
  %clock_update_flags.i.i297 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %53 = ptrtoint ptr %clock_update_flags.i.i297 to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %clock_update_flags.i.i297, align 4
  %cmp.i.i298 = icmp ugt i32 %54, 2
  br i1 %cmp.i.i298, label %if.then.i.i300, label %if.end.i.i303

if.then.i.i300:                                   ; preds = %if.then83
  %clock_update_flags1.i.i299 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %55 = ptrtoint ptr %clock_update_flags1.i.i299 to i32
  call void @__asan_store4_noabort(i32 %55)
  store i32 4, ptr %clock_update_flags1.i.i299, align 4
  br label %if.end.i.i303

if.end.i.i303:                                    ; preds = %if.then.i.i300, %if.then83
  %core_enabled.i.i.i301 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %56 = ptrtoint ptr %core_enabled.i.i.i301 to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load i32, ptr %core_enabled.i.i.i301, align 128
  %tobool.not.i.i.i302 = icmp eq i32 %57, 0
  br i1 %tobool.not.i.i.i302, label %rq_unpin_lock.exit.i310, label %if.then.i.i.i305

if.then.i.i.i305:                                 ; preds = %if.end.i.i303
  %core.i.i.i304 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %58 = ptrtoint ptr %core.i.i.i304 to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %core.i.i.i304, align 8
  br label %rq_unpin_lock.exit.i310

rq_unpin_lock.exit.i310:                          ; preds = %if.then.i.i.i305, %if.end.i.i303
  %retval.0.i.i.i306 = phi ptr [ %59, %if.then.i.i.i305 ], [ %rq, %if.end.i.i303 ]
  %dep_map.i.i307 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i306, i32 0, i32 4
  %cookie.i.i308 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %60 = ptrtoint ptr %cookie.i.i308 to i32
  call void @__asan_load4_noabort(i32 %60)
  %.unpack.i.i309 = load i32, ptr %cookie.i.i308, align 4
  %61 = insertvalue [1 x i32] undef, i32 %.unpack.i.i309, 0
  call void @lock_unpin_lock(ptr noundef %dep_map.i.i307, [1 x i32] %61) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@affine_move_task, %land.rhs.i.i.i.i312)) #33
          to label %task_rq_unlock.exit317 [label %land.rhs.i.i.i.i312], !srcloc !1202

land.rhs.i.i.i.i312:                              ; preds = %rq_unpin_lock.exit.i310
  %62 = ptrtoint ptr %core_enabled.i.i.i301 to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %core_enabled.i.i.i301, align 128
  %tobool3.i.not.i.i.i311 = icmp eq i32 %63, 0
  br i1 %tobool3.i.not.i.i.i311, label %task_rq_unlock.exit317, label %if.then.i.i4.i314

if.then.i.i4.i314:                                ; preds = %land.rhs.i.i.i.i312
  %core.i.i3.i313 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %64 = ptrtoint ptr %core.i.i3.i313 to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load ptr, ptr %core.i.i3.i313, align 8
  br label %task_rq_unlock.exit317

task_rq_unlock.exit317:                           ; preds = %if.then.i.i4.i314, %land.rhs.i.i.i.i312, %rq_unpin_lock.exit.i310
  %retval.0.i.i5.i315 = phi ptr [ %65, %if.then.i.i4.i314 ], [ %rq, %land.rhs.i.i.i.i312 ], [ %rq, %rq_unpin_lock.exit.i310 ]
  call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i315) #33
  %pi_lock.i316 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %66 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %66)
  %67 = load i32, ptr %rf, align 4
  call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i316, i32 noundef %67) #33
  br label %cleanup224

if.end84:                                         ; preds = %if.end40
  %on_cpu.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 5
  %68 = ptrtoint ptr %on_cpu.i to i32
  call void @__asan_load4_noabort(i32 %68)
  %69 = load i32, ptr %on_cpu.i, align 4
  %tobool86.not = icmp eq i32 %69, 0
  br i1 %tobool86.not, label %do.end89, label %if.then92

do.end89:                                         ; preds = %if.end84
  %70 = ptrtoint ptr %p to i32
  call void @__asan_load4_noabort(i32 %70)
  %71 = load volatile i32, ptr %p, align 128
  %cmp = icmp eq i32 %71, 512
  br i1 %cmp, label %if.then92, label %if.else118

if.then92:                                        ; preds = %do.end89, %if.end84
  %stop_pending93 = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 1
  %72 = ptrtoint ptr %stop_pending93 to i32
  call void @__asan_load4_noabort(i32 %72)
  %73 = load i32, ptr %stop_pending93, align 4
  %tobool94.not = icmp eq i32 %73, 0
  br i1 %tobool94.not, label %if.then97, label %if.end99

if.then97:                                        ; preds = %if.then92
  %74 = ptrtoint ptr %stop_pending93 to i32
  call void @__asan_store4_noabort(i32 %74)
  store i32 1, ptr %stop_pending93, align 4
  br label %if.end99

if.end99:                                         ; preds = %if.then97, %if.then92
  br i1 %tobool26.not, label %if.end107, label %if.then102

if.then102:                                       ; preds = %if.end99
  %migration_flags103 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 38
  %75 = ptrtoint ptr %migration_flags103 to i32
  call void @__asan_load2_noabort(i32 %75)
  %76 = load i16, ptr %migration_flags103, align 2
  %77 = and i16 %76, -2
  store i16 %77, ptr %migration_flags103, align 2
  br label %if.end107

if.end107:                                        ; preds = %if.then102, %if.end99
  %clock_update_flags.i.i318 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %78 = ptrtoint ptr %clock_update_flags.i.i318 to i32
  call void @__asan_load4_noabort(i32 %78)
  %79 = load i32, ptr %clock_update_flags.i.i318, align 4
  %cmp.i.i319 = icmp ugt i32 %79, 2
  br i1 %cmp.i.i319, label %if.then.i.i321, label %if.end.i.i324

if.then.i.i321:                                   ; preds = %if.end107
  %clock_update_flags1.i.i320 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %80 = ptrtoint ptr %clock_update_flags1.i.i320 to i32
  call void @__asan_store4_noabort(i32 %80)
  store i32 4, ptr %clock_update_flags1.i.i320, align 4
  br label %if.end.i.i324

if.end.i.i324:                                    ; preds = %if.then.i.i321, %if.end107
  %core_enabled.i.i.i322 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %81 = ptrtoint ptr %core_enabled.i.i.i322 to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %core_enabled.i.i.i322, align 128
  %tobool.not.i.i.i323 = icmp eq i32 %82, 0
  br i1 %tobool.not.i.i.i323, label %rq_unpin_lock.exit.i331, label %if.then.i.i.i326

if.then.i.i.i326:                                 ; preds = %if.end.i.i324
  %core.i.i.i325 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %83 = ptrtoint ptr %core.i.i.i325 to i32
  call void @__asan_load4_noabort(i32 %83)
  %84 = load ptr, ptr %core.i.i.i325, align 8
  br label %rq_unpin_lock.exit.i331

rq_unpin_lock.exit.i331:                          ; preds = %if.then.i.i.i326, %if.end.i.i324
  %retval.0.i.i.i327 = phi ptr [ %84, %if.then.i.i.i326 ], [ %rq, %if.end.i.i324 ]
  %dep_map.i.i328 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i327, i32 0, i32 4
  %cookie.i.i329 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %85 = ptrtoint ptr %cookie.i.i329 to i32
  call void @__asan_load4_noabort(i32 %85)
  %.unpack.i.i330 = load i32, ptr %cookie.i.i329, align 4
  %86 = insertvalue [1 x i32] undef, i32 %.unpack.i.i330, 0
  call void @lock_unpin_lock(ptr noundef %dep_map.i.i328, [1 x i32] %86) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@affine_move_task, %land.rhs.i.i.i.i333)) #33
          to label %task_rq_unlock.exit338 [label %land.rhs.i.i.i.i333], !srcloc !1202

land.rhs.i.i.i.i333:                              ; preds = %rq_unpin_lock.exit.i331
  %87 = ptrtoint ptr %core_enabled.i.i.i322 to i32
  call void @__asan_load4_noabort(i32 %87)
  %88 = load i32, ptr %core_enabled.i.i.i322, align 128
  %tobool3.i.not.i.i.i332 = icmp eq i32 %88, 0
  br i1 %tobool3.i.not.i.i.i332, label %task_rq_unlock.exit338, label %if.then.i.i4.i335

if.then.i.i4.i335:                                ; preds = %land.rhs.i.i.i.i333
  %core.i.i3.i334 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %89 = ptrtoint ptr %core.i.i3.i334 to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load ptr, ptr %core.i.i3.i334, align 8
  br label %task_rq_unlock.exit338

task_rq_unlock.exit338:                           ; preds = %if.then.i.i4.i335, %land.rhs.i.i.i.i333, %rq_unpin_lock.exit.i331
  %retval.0.i.i5.i336 = phi ptr [ %90, %if.then.i.i4.i335 ], [ %rq, %land.rhs.i.i.i.i333 ], [ %rq, %rq_unpin_lock.exit.i331 ]
  call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i336) #33
  %pi_lock.i337 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %91 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load i32, ptr %rf, align 4
  call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i337, i32 noundef %92) #33
  br i1 %tobool94.not, label %if.then109, label %if.end113

if.then109:                                       ; preds = %task_rq_unlock.exit338
  %cpu.i339 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %93 = ptrtoint ptr %cpu.i339 to i32
  call void @__asan_load4_noabort(i32 %93)
  %94 = load i32, ptr %cpu.i339, align 4
  %arg111 = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 4
  %stop_work = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 3
  %call112 = call zeroext i1 @stop_one_cpu_nowait(i32 noundef %94, ptr noundef nonnull @migration_cpu_stop, ptr noundef %arg111, ptr noundef %stop_work) #33
  br label %if.end113

if.end113:                                        ; preds = %if.then109, %task_rq_unlock.exit338
  br i1 %tobool26.not, label %if.end136, label %cleanup224

if.else118:                                       ; preds = %do.end89
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %95 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %95)
  %96 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %96, 0
  br i1 %tobool.i.not, label %if.then120, label %if.end136.critedge

if.then120:                                       ; preds = %if.else118
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %97 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %97)
  %98 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %98, 1
  br i1 %cmp.i.not, label %if.then123, label %if.end125

if.then123:                                       ; preds = %if.then120
  %call124 = call fastcc ptr @move_queued_task(ptr noundef %rq, ptr noundef %rf, ptr noundef %p, i32 noundef %dest_cpu)
  br label %if.end125

if.end125:                                        ; preds = %if.then123, %if.then120
  %rq.addr.0 = phi ptr [ %call124, %if.then123 ], [ %rq, %if.then120 ]
  %stop_pending126 = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 1
  %99 = ptrtoint ptr %stop_pending126 to i32
  call void @__asan_load4_noabort(i32 %99)
  %100 = load i32, ptr %stop_pending126, align 4
  %tobool127.not = icmp eq i32 %100, 0
  br i1 %tobool127.not, label %if.then128, label %if.end136.critedge295

if.then128:                                       ; preds = %if.end125
  %101 = ptrtoint ptr %migration_pending41 to i32
  call void @__asan_store4_noabort(i32 %101)
  store ptr null, ptr %migration_pending41, align 8
  call fastcc void @task_rq_unlock(ptr noundef %rq.addr.0, ptr noundef %p, ptr noundef %rf)
  %done134 = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 2
  call void @complete_all(ptr noundef %done134) #33
  br label %if.end136

if.end136.critedge:                               ; preds = %if.else118
  %clock_update_flags.i.i340 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %102 = ptrtoint ptr %clock_update_flags.i.i340 to i32
  call void @__asan_load4_noabort(i32 %102)
  %103 = load i32, ptr %clock_update_flags.i.i340, align 4
  %cmp.i.i341 = icmp ugt i32 %103, 2
  br i1 %cmp.i.i341, label %if.then.i.i343, label %if.end.i.i346

if.then.i.i343:                                   ; preds = %if.end136.critedge
  %clock_update_flags1.i.i342 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %104 = ptrtoint ptr %clock_update_flags1.i.i342 to i32
  call void @__asan_store4_noabort(i32 %104)
  store i32 4, ptr %clock_update_flags1.i.i342, align 4
  br label %if.end.i.i346

if.end.i.i346:                                    ; preds = %if.then.i.i343, %if.end136.critedge
  %core_enabled.i.i.i344 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %105 = ptrtoint ptr %core_enabled.i.i.i344 to i32
  call void @__asan_load4_noabort(i32 %105)
  %106 = load i32, ptr %core_enabled.i.i.i344, align 128
  %tobool.not.i.i.i345 = icmp eq i32 %106, 0
  br i1 %tobool.not.i.i.i345, label %rq_unpin_lock.exit.i353, label %if.then.i.i.i348

if.then.i.i.i348:                                 ; preds = %if.end.i.i346
  %core.i.i.i347 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %107 = ptrtoint ptr %core.i.i.i347 to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load ptr, ptr %core.i.i.i347, align 8
  br label %rq_unpin_lock.exit.i353

rq_unpin_lock.exit.i353:                          ; preds = %if.then.i.i.i348, %if.end.i.i346
  %retval.0.i.i.i349 = phi ptr [ %108, %if.then.i.i.i348 ], [ %rq, %if.end.i.i346 ]
  %dep_map.i.i350 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i349, i32 0, i32 4
  %cookie.i.i351 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %109 = ptrtoint ptr %cookie.i.i351 to i32
  call void @__asan_load4_noabort(i32 %109)
  %.unpack.i.i352 = load i32, ptr %cookie.i.i351, align 4
  %110 = insertvalue [1 x i32] undef, i32 %.unpack.i.i352, 0
  call void @lock_unpin_lock(ptr noundef %dep_map.i.i350, [1 x i32] %110) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@affine_move_task, %land.rhs.i.i.i.i355)) #33
          to label %task_rq_unlock.exit360 [label %land.rhs.i.i.i.i355], !srcloc !1202

land.rhs.i.i.i.i355:                              ; preds = %rq_unpin_lock.exit.i353
  %111 = ptrtoint ptr %core_enabled.i.i.i344 to i32
  call void @__asan_load4_noabort(i32 %111)
  %112 = load i32, ptr %core_enabled.i.i.i344, align 128
  %tobool3.i.not.i.i.i354 = icmp eq i32 %112, 0
  br i1 %tobool3.i.not.i.i.i354, label %task_rq_unlock.exit360, label %if.then.i.i4.i357

if.then.i.i4.i357:                                ; preds = %land.rhs.i.i.i.i355
  %core.i.i3.i356 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %113 = ptrtoint ptr %core.i.i3.i356 to i32
  call void @__asan_load4_noabort(i32 %113)
  %114 = load ptr, ptr %core.i.i3.i356, align 8
  br label %task_rq_unlock.exit360

task_rq_unlock.exit360:                           ; preds = %if.then.i.i4.i357, %land.rhs.i.i.i.i355, %rq_unpin_lock.exit.i353
  %retval.0.i.i5.i358 = phi ptr [ %114, %if.then.i.i4.i357 ], [ %rq, %land.rhs.i.i.i.i355 ], [ %rq, %rq_unpin_lock.exit.i353 ]
  call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i358) #33
  %pi_lock.i359 = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 128
  %115 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %115)
  %116 = load i32, ptr %rf, align 4
  call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i359, i32 noundef %116) #33
  br label %if.end136

if.end136.critedge295:                            ; preds = %if.end125
  call fastcc void @task_rq_unlock(ptr noundef %rq.addr.0, ptr noundef %p, ptr noundef %rf)
  br label %if.end136

if.end136:                                        ; preds = %if.end136.critedge295, %task_rq_unlock.exit360, %if.then128, %if.end113
  %done137 = getelementptr inbounds %struct.set_affinity_pending, ptr %52, i32 0, i32 2
  call void @wait_for_completion(ptr noundef %done137) #33
  %call.i.i.i.i.i361 = call zeroext i1 @__kasan_check_write(ptr noundef nonnull %52, i32 noundef 4) #33
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  call void @llvm.prefetch.p0(ptr nonnull %52, i32 1, i32 3, i32 1) #33
  %117 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) %52, ptr nonnull %52, i32 1, ptr nonnull elementtype(i32) %52) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i362 = extractvalue { i32, i32, i32 } %117, 0
  %cmp.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i362, 1
  br i1 %cmp.i.i.i, label %if.then140, label %if.end5.i.i.i

if.end5.i.i.i:                                    ; preds = %if.end136
  %.not.i.i.i363 = icmp sgt i32 %asmresult.i.i.i.i.i.i362, 0
  br i1 %.not.i.i.i363, label %do.body144, label %if.then10.i.i.i, !prof !1191

if.then10.i.i.i:                                  ; preds = %if.end5.i.i.i
  call void @refcount_warn_saturate(ptr noundef nonnull %52, i32 noundef 3) #33
  br label %do.body144

if.then140:                                       ; preds = %if.end136
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  call void @wake_up_var(ptr noundef nonnull %52) #33
  br label %do.body144

do.body144:                                       ; preds = %if.then140, %if.then10.i.i.i, %if.end5.i.i.i
  %118 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i364 = and i32 %118, -16384
  %119 = inttoptr i32 %and.i.i364 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %119, i32 0, i32 2
  %120 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load ptr, ptr %task.i, align 8
  %122 = ptrtoint ptr %121 to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load volatile i32, ptr %121, align 128
  %cmp.not.i = icmp eq i32 %123, 0
  br i1 %cmp.not.i, label %__might_sleep.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %do.body144
  %task_state_change.i = getelementptr inbounds %struct.task_struct, ptr %121, i32 0, i32 212
  %124 = ptrtoint ptr %task_state_change.i to i32
  call void @__asan_load4_noabort(i32 %124)
  %125 = load i32, ptr %task_state_change.i, align 4
  %tobool.not.i = icmp eq i32 %125, 0
  br i1 %tobool.not.i, label %__might_sleep.exit, label %land.rhs5.i

land.rhs5.i:                                      ; preds = %land.rhs.i
  %.b53.i = load i1, ptr @__might_sleep.__already_done, align 1
  br i1 %.b53.i, label %__might_sleep.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs5.i
  store i1 true, ptr @__might_sleep.__already_done, align 1
  %126 = inttoptr i32 %125 to ptr
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 9512, i32 noundef 9, ptr noundef nonnull @.str.71, i32 noundef %123, ptr noundef nonnull %126, ptr noundef nonnull %126) #33
  br label %__might_sleep.exit

__might_sleep.exit:                               ; preds = %if.then.i, %land.rhs5.i, %land.rhs.i, %do.body144
  call void @__might_resched(ptr noundef nonnull @.str.1, i32 noundef 2773, i32 noundef 0) #33
  %call.i.i.i365 = call zeroext i1 @__kasan_check_read(ptr noundef nonnull %my_pending, i32 noundef 4) #33
  %127 = ptrtoint ptr %my_pending to i32
  call void @__asan_load4_noabort(i32 %127)
  %128 = load volatile i32, ptr %my_pending, align 4
  %tobool152.not = icmp eq i32 %128, 0
  br i1 %tobool152.not, label %do.end167, label %if.end154

if.end154:                                        ; preds = %__might_sleep.exit
  %call156 = call ptr @__var_waitqueue(ptr noundef nonnull %my_pending) #33
  call void @llvm.lifetime.start.p0(i64 32, ptr nonnull %__wbq_entry) #33
  %129 = getelementptr inbounds %struct.wait_bit_queue_entry, ptr %__wbq_entry, i32 0, i32 1
  %130 = call ptr @memset(ptr %__wbq_entry, i32 255, i32 32)
  call void @init_wait_var_entry(ptr noundef nonnull %__wbq_entry, ptr noundef nonnull %my_pending, i32 noundef 0) #33
  %call158369 = call i32 @prepare_to_wait_event(ptr noundef %call156, ptr noundef %129, i32 noundef 2) #33
  %call.i.i.i366370 = call zeroext i1 @__kasan_check_read(ptr noundef nonnull %my_pending, i32 noundef 4) #33
  %131 = ptrtoint ptr %my_pending to i32
  call void @__asan_load4_noabort(i32 %131)
  %132 = load volatile i32, ptr %my_pending, align 4
  %tobool161.not371 = icmp eq i32 %132, 0
  br i1 %tobool161.not371, label %for.end, label %cleanup

cleanup:                                          ; preds = %cleanup, %if.end154
  call void @schedule()
  %call158 = call i32 @prepare_to_wait_event(ptr noundef %call156, ptr noundef %129, i32 noundef 2) #33
  %call.i.i.i366 = call zeroext i1 @__kasan_check_read(ptr noundef nonnull %my_pending, i32 noundef 4) #33
  %133 = ptrtoint ptr %my_pending to i32
  call void @__asan_load4_noabort(i32 %133)
  %134 = load volatile i32, ptr %my_pending, align 4
  %tobool161.not = icmp eq i32 %134, 0
  br i1 %tobool161.not, label %for.end, label %cleanup

for.end:                                          ; preds = %cleanup, %if.end154
  call void @finish_wait(ptr noundef %call156, ptr noundef %129) #33
  call void @llvm.lifetime.end.p0(i64 32, ptr nonnull %__wbq_entry) #33
  br label %do.end167

do.end167:                                        ; preds = %for.end, %__might_sleep.exit
  %stop_pending169 = getelementptr inbounds %struct.set_affinity_pending, ptr %my_pending, i32 0, i32 1
  %135 = ptrtoint ptr %stop_pending169 to i32
  call void @__asan_load4_noabort(i32 %135)
  %136 = load i32, ptr %stop_pending169, align 4
  %tobool170.not = icmp eq i32 %136, 0
  br i1 %tobool170.not, label %cleanup224, label %land.rhs178

land.rhs178:                                      ; preds = %do.end167
  %.b291292 = load i1, ptr @affine_move_task.__already_done.191, align 1
  br i1 %.b291292, label %cleanup224, label %if.then189, !prof !1191

if.then189:                                       ; preds = %land.rhs178
  store i1 true, ptr @affine_move_task.__already_done.191, align 1
  call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 2776, i32 noundef 9, ptr noundef null) #33
  br label %cleanup224

cleanup224:                                       ; preds = %if.then189, %land.rhs178, %do.end167, %if.end113, %task_rq_unlock.exit317, %if.then22, %if.end20
  %retval.0 = phi i32 [ -22, %task_rq_unlock.exit317 ], [ 0, %if.then22 ], [ 0, %if.end20 ], [ 0, %if.end113 ], [ 0, %do.end167 ], [ 0, %if.then189 ], [ 0, %land.rhs178 ]
  call void @llvm.lifetime.end.p0(i64 100, ptr nonnull %my_pending) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_equal(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @stop_one_cpu_nowait(i32 noundef, ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @complete_all(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc ptr @move_queued_task(ptr noundef %rq, ptr nocapture noundef %rf, ptr noundef %p, i32 noundef %new_cpu) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %5 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 2, ptr %on_rq.i, align 4
  tail call fastcc void @dequeue_task(ptr noundef %rq, ptr noundef %p, i32 noundef 8) #33
  tail call void @set_task_cpu(ptr noundef %p, i32 noundef %new_cpu)
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %6 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %7, 2
  br i1 %cmp.i.i, label %if.then.i.i22, label %if.end.i.i

if.then.i.i22:                                    ; preds = %lockdep_assert_rq_held.exit
  %clock_update_flags1.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %8 = ptrtoint ptr %clock_update_flags1.i.i to i32
  call void @__asan_store4_noabort(i32 %8)
  store i32 4, ptr %clock_update_flags1.i.i, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i22, %lockdep_assert_rq_held.exit
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %9 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %12, %if.then.i.i.i ], [ %rq, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %cookie.i.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %13 = ptrtoint ptr %cookie.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %.unpack.i.i = load i32, ptr %cookie.i.i, align 4
  %14 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %14) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@move_queued_task, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %15 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %16, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %17 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %18, %if.then.i.i3.i ], [ %rq, %land.rhs.i.i.i.i ], [ %rq, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %new_cpu
  %19 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %arrayidx, align 4
  %add = add i32 %20, ptrtoint (ptr @runqueues to i32)
  %21 = inttoptr i32 %add to ptr
  tail call fastcc void @rq_lock(ptr noundef %21, ptr noundef %rf)
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 1
  %22 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 3
  %24 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %cpu.i, align 4
  %cmp.not = icmp eq i32 %25, %new_cpu
  br i1 %cmp.not, label %do.end8, label %do.body4, !prof !1191

do.body4:                                         ; preds = %rq_unlock.exit
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 2275, 0\0A.popsection", ""() #33, !srcloc !1334
  unreachable

do.end8:                                          ; preds = %rq_unlock.exit
  tail call fastcc void @enqueue_task(ptr noundef %21, ptr noundef %p, i32 noundef 0) #33
  %26 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %26)
  store i32 1, ptr %on_rq.i, align 4
  tail call void @check_preempt_curr(ptr noundef %21, ptr noundef %p, i32 noundef 0)
  ret ptr %21
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @wait_for_completion(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @wake_up_var(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @__var_waitqueue(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_wait_var_entry(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @prepare_to_wait_event(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @finish_wait(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__init_swait_queue_head(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @set_task_rq_fair(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_init_map_type(ptr noundef, ptr noundef, ptr noundef, i32 noundef, i8 noundef zeroext, i8 noundef zeroext, i8 noundef zeroext) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @ttwu_do_wakeup(ptr noundef %rq, ptr noundef %p, i32 noundef %wake_flags, ptr nocapture noundef %rf) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call void @check_preempt_curr(ptr noundef %rq, ptr noundef %p, i32 noundef %wake_flags)
  %0 = ptrtoint ptr %p to i32
  call void @__asan_store4_noabort(i32 %0)
  store volatile i32 0, ptr %p, align 128
  tail call fastcc void @trace_sched_wakeup(ptr noundef %p)
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 21
  %1 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %sched_class, align 32
  %task_woken = getelementptr inbounds %struct.sched_class, ptr %2, i32 0, i32 13
  %3 = ptrtoint ptr %task_woken to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task_woken, align 4
  %tobool.not = icmp eq ptr %4, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %5 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ugt i32 %6, 2
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %if.then
  %clock_update_flags1.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %7 = ptrtoint ptr %clock_update_flags1.i to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 4, ptr %clock_update_flags1.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %if.then
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %8 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i.i, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %10 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %if.end.i
  %retval.0.i.i = phi ptr [ %11, %if.then.i.i ], [ %rq, %if.end.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %12 = ptrtoint ptr %cookie.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %.unpack.i = load i32, ptr %cookie.i, align 4
  %13 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %13) #33
  %14 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %sched_class, align 32
  %task_woken6 = getelementptr inbounds %struct.sched_class, ptr %15, i32 0, i32 13
  %16 = ptrtoint ptr %task_woken6 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %task_woken6, align 4
  tail call void %17(ptr noundef %rq, ptr noundef %p) #33
  %18 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i40 = icmp eq i32 %19, 0
  br i1 %tobool.not.i.i40, label %rq_repin_lock.exit, label %if.then.i.i42

if.then.i.i42:                                    ; preds = %rq_unpin_lock.exit
  %core.i.i41 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %20 = ptrtoint ptr %core.i.i41 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %core.i.i41, align 8
  br label %rq_repin_lock.exit

rq_repin_lock.exit:                               ; preds = %if.then.i.i42, %rq_unpin_lock.exit
  %retval.0.i.i43 = phi ptr [ %21, %if.then.i.i42 ], [ %rq, %rq_unpin_lock.exit ]
  %dep_map.i44 = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i43, i32 0, i32 4
  %22 = ptrtoint ptr %cookie.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %.unpack.i46 = load i32, ptr %cookie.i, align 4
  %23 = insertvalue [1 x i32] undef, i32 %.unpack.i46, 0
  tail call void @lock_repin_lock(ptr noundef %dep_map.i44, [1 x i32] %23) #33
  %clock_update_flags.i47 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %24 = ptrtoint ptr %clock_update_flags.i47 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load i32, ptr %clock_update_flags.i47, align 4
  %26 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %clock_update_flags.i, align 4
  %or.i = or i32 %27, %25
  store i32 %or.i, ptr %clock_update_flags.i, align 4
  br label %if.end

if.end:                                           ; preds = %rq_repin_lock.exit, %entry
  %idle_stamp = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 54
  %28 = ptrtoint ptr %idle_stamp to i32
  call void @__asan_load8_noabort(i32 %28)
  %29 = load i64, ptr %idle_stamp, align 128
  %tobool7.not = icmp eq i64 %29, 0
  br i1 %tobool7.not, label %if.end16, label %if.then8

if.then8:                                         ; preds = %if.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %30 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i49 = icmp eq i32 %30, 0
  br i1 %tobool.not.i.i49, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %if.then8
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %31 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %32, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %33 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i
  %retval.0.i.i.i = phi ptr [ %34, %if.then.i.i.i ], [ %rq, %land.rhs.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %if.then8
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %35 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ult i32 %36, 2
  br i1 %cmp.i.i, label %land.rhs.i3.i, label %rq_clock.exit

land.rhs.i3.i:                                    ; preds = %lockdep_assert_rq_held.exit.i
  %.b37.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i, label %rq_clock.exit, label %if.then.i.i50, !prof !1191

if.then.i.i50:                                    ; preds = %land.rhs.i3.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit

rq_clock.exit:                                    ; preds = %if.then.i.i50, %land.rhs.i3.i, %lockdep_assert_rq_held.exit.i
  %clock.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 26
  %37 = ptrtoint ptr %clock.i to i32
  call void @__asan_load8_noabort(i32 %37)
  %38 = load i64, ptr %clock.i, align 32
  %39 = ptrtoint ptr %idle_stamp to i32
  call void @__asan_load8_noabort(i32 %39)
  %40 = load i64, ptr %idle_stamp, align 128
  %max_idle_balance_cost = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 58
  %41 = ptrtoint ptr %max_idle_balance_cost to i32
  call void @__asan_load8_noabort(i32 %41)
  %42 = load i64, ptr %max_idle_balance_cost, align 32
  %mul = shl i64 %42, 1
  %avg_idle = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 55
  %43 = ptrtoint ptr %avg_idle to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %avg_idle, align 8
  %45 = add i64 %40, %44
  %sub.i = sub i64 %38, %45
  %div.i = sdiv i64 %sub.i, 8
  %add.i = add i64 %div.i, %44
  %46 = tail call i64 @llvm.umin.i64(i64 %add.i, i64 %mul)
  %47 = ptrtoint ptr %avg_idle to i32
  call void @__asan_store8_noabort(i32 %47)
  store i64 %46, ptr %avg_idle, align 8
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @jiffies to i32))
  %48 = load volatile i32, ptr @jiffies, align 128
  %wake_stamp = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 56
  %49 = ptrtoint ptr %wake_stamp to i32
  call void @__asan_store4_noabort(i32 %49)
  store i32 %48, ptr %wake_stamp, align 16
  %div38 = lshr i64 %46, 1
  %wake_avg_idle = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 57
  %50 = ptrtoint ptr %wake_avg_idle to i32
  call void @__asan_store8_noabort(i32 %50)
  store i64 %div38, ptr %wake_avg_idle, align 8
  %51 = ptrtoint ptr %idle_stamp to i32
  call void @__asan_store8_noabort(i32 %51)
  store i64 0, ptr %idle_stamp, align 128
  br label %if.end16

if.end16:                                         ; preds = %rq_clock.exit, %if.end
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__delayacct_blkio_end(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_wakeup(ptr noundef %p) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_wakeup, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1335
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %p) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1336
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1336
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_wakeup, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_wakeup.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_wakeup.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 180, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_waking(ptr noundef %p) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_waking, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_waking, %do.body)) #33
          to label %if.end48 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i75 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i75
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end69, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1337
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_waking, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end48.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, ptr noundef %p) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool9.not.i = icmp eq ptr %19, null
  br i1 %tobool9.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1338
  br label %if.end48.sink.split

if.end48.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1338
  br label %if.end48.sink.split

if.end48.sink.split:                              ; preds = %if.end48.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i73.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i73.c to ptr
  %preempt_count.i.i74.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i74.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i74.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i74.c, align 4
  br label %if.end48

if.end48:                                         ; preds = %if.end48.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i76 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i76 to ptr
  %cpu50 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu50 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu50, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i77 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i77, label %cpu_online.exit85, label %land.rhs.i.i.i.i79

land.rhs.i.i.i.i79:                               ; preds = %if.end48
  %.b37.i.i.i.i78 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i78, label %cpu_online.exit85, label %if.then.i.i.i.i80, !prof !1191

if.then.i.i.i.i80:                                ; preds = %land.rhs.i.i.i.i79
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit85

cpu_online.exit85:                                ; preds = %if.then.i.i.i.i80, %land.rhs.i.i.i.i79, %if.end48
  %div3.i.i.i81 = lshr i32 %27, 5
  %arrayidx.i.i.i82 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i81
  %29 = ptrtoint ptr %arrayidx.i.i.i82 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i82, align 4
  %and.i.i.i83 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i83
  %32 = and i32 %30, %31
  %tobool.i84.not = icmp eq i32 %32, 0
  br i1 %tobool.i84.not, label %if.end69, label %if.then52

if.then52:                                        ; preds = %cpu_online.exit85
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_waking, i32 0, i32 7), align 4
  %call58 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool59.not = icmp eq i32 %call58, 0
  br i1 %tobool59.not, label %land.lhs.true, label %do.end67

land.lhs.true:                                    ; preds = %if.then52
  %call60 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool61.not = icmp eq i32 %call60, 0
  br i1 %tobool61.not, label %do.end67, label %land.lhs.true62

land.lhs.true62:                                  ; preds = %land.lhs.true
  %.b72 = load i1, ptr @trace_sched_waking.__warned, align 1
  br i1 %.b72, label %do.end67, label %if.then64

if.then64:                                        ; preds = %land.lhs.true62
  store i1 true, ptr @trace_sched_waking.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 172, ptr noundef nonnull @.str.3) #33
  br label %do.end67

do.end67:                                         ; preds = %if.then64, %land.lhs.true62, %land.lhs.true, %if.then52
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i86 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i86 to ptr
  %preempt_count.i.i.i87 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i87 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i87, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i87, align 4
  br label %if.end69

if.end69:                                         ; preds = %do.end67, %cpu_online.exit85, %cpu_online.exit
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @ttwu_runnable(ptr noundef %p, i32 noundef %wake_flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %call = call ptr @__task_rq_lock(ptr noundef %p, ptr noundef nonnull %rf)
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 12
  %5 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %6, 1
  br i1 %cmp.i.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  tail call void @update_rq_clock(ptr noundef %call)
  call fastcc void @ttwu_do_wakeup(ptr noundef %call, ptr noundef %p, i32 noundef %wake_flags, ptr noundef nonnull %rf)
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %ret.0 = phi i32 [ 1, %if.then ], [ 0, %entry ]
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 81
  %7 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %8, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %9 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end
  %retval.0.i.i.i = phi ptr [ %10, %if.then.i.i.i ], [ %call, %if.end ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %11 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %11)
  %.unpack.i.i = load i32, ptr %1, align 4
  %12 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %12) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@ttwu_runnable, %land.rhs.i.i.i.i)) #33
          to label %__task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %13 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %14, 0
  br i1 %tobool3.i.not.i.i.i, label %__task_rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %call, i32 0, i32 79
  %15 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %core.i.i2.i, align 8
  br label %__task_rq_unlock.exit

__task_rq_unlock.exit:                            ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %16, %if.then.i.i3.i ], [ %call, %land.rhs.i.i.i.i ], [ %call, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %ret.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc zeroext i1 @ttwu_queue_wakelist(ptr noundef %p, i32 noundef %cpu, i32 noundef %wake_flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr (i8, ptr getelementptr inbounds ([25 x %struct.static_key], ptr @sched_feat_keys, i32 0, i32 10), i32 1), ptr blockaddress(@ttwu_queue_wakelist, %return)) #33
          to label %land.lhs.true [label %return], !srcloc !1202

land.lhs.true:                                    ; preds = %entry
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i.i = icmp ugt i32 %0, %cpu
  br i1 %cmp.not.i.i.i.i.i, label %cpu_active.exit.i, label %land.rhs.i.i.i.i.i

land.rhs.i.i.i.i.i:                               ; preds = %land.lhs.true
  %.b37.i.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i.i, label %cpu_active.exit.i, label %if.then.i.i.i.i.i, !prof !1191

if.then.i.i.i.i.i:                                ; preds = %land.rhs.i.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_active.exit.i

cpu_active.exit.i:                                ; preds = %if.then.i.i.i.i.i, %land.rhs.i.i.i.i.i, %land.lhs.true
  %div3.i.i.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i.i.i = getelementptr i32, ptr @__cpu_active_mask, i32 %div3.i.i.i.i
  %1 = ptrtoint ptr %arrayidx.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load volatile i32, ptr %arrayidx.i.i.i.i, align 4
  %and.i.i.i.i = and i32 %cpu, 31
  %3 = shl nuw i32 1, %and.i.i.i.i
  %4 = and i32 %2, %3
  %tobool.i.not.i = icmp eq i32 %4, 0
  br i1 %tobool.i.not.i, label %return, label %if.end.i

if.end.i:                                         ; preds = %cpu_active.exit.i
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i.i to ptr
  %cpu2.i = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu2.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu2.i, align 4
  %cmp.i.i = icmp eq i32 %8, %cpu
  br i1 %cmp.i.i, label %if.end5.i, label %cpus_share_cache.exit.i

cpus_share_cache.exit.i:                          ; preds = %if.end.i
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %10, ptrtoint (ptr @sd_llc_id to i32)
  %11 = inttoptr i32 %add.i.i to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %arrayidx8.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %14 = ptrtoint ptr %arrayidx8.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %arrayidx8.i.i, align 4
  %add9.i.i = add i32 %15, ptrtoint (ptr @sd_llc_id to i32)
  %16 = inttoptr i32 %add9.i.i to ptr
  %17 = ptrtoint ptr %16 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %16, align 4
  %cmp10.i.i = icmp eq i32 %13, %18
  br i1 %cmp10.i.i, label %if.end5.i, label %if.then

if.end5.i:                                        ; preds = %cpus_share_cache.exit.i, %if.end.i
  %and.i = and i32 %wake_flags, 64
  %tobool.not.i = icmp eq i32 %and.i, 0
  br i1 %tobool.not.i, label %return, label %do.body.i

do.body.i:                                        ; preds = %if.end5.i
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %19 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %20, ptrtoint (ptr @runqueues to i32)
  %21 = inttoptr i32 %add.i to ptr
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %nr_running.i, align 4
  %cmp.i = icmp ult i32 %23, 2
  br i1 %cmp.i, label %if.then, label %return

if.then:                                          ; preds = %do.body.i, %cpus_share_cache.exit.i
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i52 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i52 to ptr
  %cpu3 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu3 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu3, align 4
  %cmp = icmp eq i32 %27, %cpu
  br i1 %cmp, label %land.rhs, label %if.end41

land.rhs:                                         ; preds = %if.then
  %.b50 = load i1, ptr @ttwu_queue_wakelist.__already_done, align 1
  br i1 %.b50, label %return, label %if.then10, !prof !1191

if.then10:                                        ; preds = %land.rhs
  store i1 true, ptr @ttwu_queue_wakelist.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 3780, i32 noundef 9, ptr noundef null) #33
  br label %return

if.end41:                                         ; preds = %if.then
  %call42 = tail call i64 @sched_clock_cpu(i32 noundef %cpu) #33
  %arrayidx.i53 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %28 = ptrtoint ptr %arrayidx.i53 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx.i53, align 4
  %add.i54 = add i32 %29, ptrtoint (ptr @runqueues to i32)
  %30 = inttoptr i32 %add.i54 to ptr
  %sched_remote_wakeup.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 65
  %31 = trunc i32 %wake_flags to i16
  %32 = ptrtoint ptr %sched_remote_wakeup.i to i32
  call void @__asan_load2_noabort(i32 %32)
  %bf.load.i = load i16, ptr %sched_remote_wakeup.i, align 8
  %33 = shl i16 %31, 10
  %bf.shl.i = and i16 %33, -32768
  %bf.clear.i = and i16 %bf.load.i, 32767
  %bf.set.i = or i16 %bf.clear.i, %bf.shl.i
  store i16 %bf.set.i, ptr %sched_remote_wakeup.i, align 8
  %ttwu_pending.i = getelementptr inbounds %struct.rq, ptr %30, i32 0, i32 8
  %34 = ptrtoint ptr %ttwu_pending.i to i32
  call void @__asan_store4_noabort(i32 %34)
  store volatile i32 1, ptr %ttwu_pending.i, align 8
  %wake_entry.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 6
  tail call void @__smp_call_single_queue(i32 noundef %cpu, ptr noundef %wake_entry.i) #33
  br label %return

return:                                           ; preds = %if.end41, %if.then10, %land.rhs, %do.body.i, %if.end5.i, %cpu_active.exit.i, %entry
  %retval.0 = phi i1 [ true, %if.end41 ], [ false, %if.then10 ], [ false, %land.rhs ], [ false, %cpu_active.exit.i ], [ false, %entry ], [ false, %do.body.i ], [ false, %if.end5.i ]
  ret i1 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @ttwu_queue(ptr noundef %p, i32 noundef %cpu, i32 noundef %wake_flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %cpu
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %2 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %5 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %6 = ptrtoint ptr %5 to i32
  call void @__asan_store4_noabort(i32 %6)
  store i32 -1, ptr %5, align 4, !annotation !1193
  %call = tail call fastcc zeroext i1 @ttwu_queue_wakelist(ptr noundef %p, i32 noundef %cpu, i32 noundef %wake_flags)
  br i1 %call, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %7 = inttoptr i32 %add to ptr
  call fastcc void @rq_lock(ptr noundef %7, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %7)
  call fastcc void @ttwu_do_activate(ptr noundef %7, ptr noundef %p, i32 noundef %wake_flags, ptr noundef nonnull %rf)
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 81
  %8 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %10 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end
  %retval.0.i.i.i = phi ptr [ %11, %if.then.i.i.i ], [ %7, %if.end ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %12 = ptrtoint ptr %3 to i32
  call void @__asan_load4_noabort(i32 %12)
  %.unpack.i.i = load i32, ptr %3, align 4
  %13 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %13) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@ttwu_queue, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %14 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %15, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %7, i32 0, i32 79
  %16 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %17, %if.then.i.i3.i ], [ %7, %land.rhs.i.i.i.i ], [ %7, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  br label %cleanup

cleanup:                                          ; preds = %rq_unlock.exit, %entry
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @ttwu_stat(ptr nocapture noundef %p, i32 noundef %cpu, i32 noundef %wake_flags) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@ttwu_stat, %do.body)) #33
          to label %cleanup [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu6 = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu6 to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu6, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  %cpu7 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 46
  %7 = ptrtoint ptr %cpu7 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu7, align 4
  %cmp = icmp eq i32 %8, %cpu
  br i1 %cmp, label %do.body9, label %if.else

do.body9:                                         ; preds = %do.body
  %ttwu_local = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 74
  %9 = ptrtoint ptr %ttwu_local to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %ttwu_local, align 16
  %inc = add i32 %10, 1
  store i32 %inc, ptr %ttwu_local, align 16
  %nr_wakeups_local = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29, i32 22
  %11 = ptrtoint ptr %nr_wakeups_local to i32
  call void @__asan_load8_noabort(i32 %11)
  %12 = load i64, ptr %nr_wakeups_local, align 16
  %inc13 = add i64 %12, 1
  store i64 %inc13, ptr %nr_wakeups_local, align 16
  br label %if.end60

if.else:                                          ; preds = %do.body
  %nr_wakeups_remote = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29, i32 23
  %13 = ptrtoint ptr %nr_wakeups_remote to i32
  call void @__asan_load8_noabort(i32 %13)
  %14 = load i64, ptr %nr_wakeups_remote, align 8
  %inc18 = add i64 %14, 1
  store i64 %inc18, ptr %nr_wakeups_remote, align 8
  %15 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %18, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.else
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.else
  %19 = ptrtoint ptr %cpu7 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %cpu7, align 4
  %arrayidx33 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %20
  %21 = ptrtoint ptr %arrayidx33 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %arrayidx33, align 4
  %add34 = add i32 %22, ptrtoint (ptr @runqueues to i32)
  %23 = inttoptr i32 %add34 to ptr
  %sd35 = getelementptr inbounds %struct.rq, ptr %23, i32 0, i32 36
  %24 = ptrtoint ptr %sd35 to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile ptr, ptr %sd35, align 4
  %call.i100 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @sched_domains_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool38.not = icmp eq i32 %call.i100, 0
  br i1 %tobool38.not, label %lor.lhs.false, label %do.end48

lor.lhs.false:                                    ; preds = %rcu_read_lock.exit
  %call39 = tail call i32 @rcu_read_lock_held() #33
  %tobool40.not = icmp eq i32 %call39, 0
  br i1 %tobool40.not, label %land.lhs.true, label %do.end48

land.lhs.true:                                    ; preds = %lor.lhs.false
  %call41 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool42.not = icmp eq i32 %call41, 0
  br i1 %tobool42.not, label %do.end48, label %land.lhs.true43

land.lhs.true43:                                  ; preds = %land.lhs.true
  %.b99 = load i1, ptr @ttwu_stat.__warned, align 1
  br i1 %.b99, label %do.end48, label %if.then45

if.then45:                                        ; preds = %land.lhs.true43
  store i1 true, ptr @ttwu_stat.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 3535, ptr noundef nonnull @.str.3) #33
  br label %do.end48

do.end48:                                         ; preds = %if.then45, %land.lhs.true43, %land.lhs.true, %lor.lhs.false, %rcu_read_lock.exit
  %tobool50.not112 = icmp eq ptr %25, null
  br i1 %tobool50.not112, label %for.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %do.end48
  %div3.i.i = lshr i32 %cpu, 5
  %and.i.i = and i32 %cpu, 31
  %26 = shl nuw i32 1, %and.i.i
  br label %for.body

for.body:                                         ; preds = %for.inc, %for.body.lr.ph
  %sd.0113 = phi ptr [ %25, %for.body.lr.ph ], [ %34, %for.inc ]
  %span.i = getelementptr inbounds %struct.sched_domain, ptr %sd.0113, i32 0, i32 41
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %27 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %27, %cpu
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %for.body
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %for.body
  %arrayidx.i.i = getelementptr i32, ptr %span.i, i32 %div3.i.i
  %28 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load volatile i32, ptr %arrayidx.i.i, align 4
  %30 = and i32 %29, %26
  %tobool53.not = icmp eq i32 %30, 0
  br i1 %tobool53.not, label %for.inc, label %do.body55

do.body55:                                        ; preds = %cpumask_test_cpu.exit
  %ttwu_wake_remote = getelementptr inbounds %struct.sched_domain, ptr %sd.0113, i32 0, i32 34
  %31 = ptrtoint ptr %ttwu_wake_remote to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %ttwu_wake_remote, align 4
  %inc56 = add i32 %32, 1
  store i32 %inc56, ptr %ttwu_wake_remote, align 4
  br label %for.end

for.inc:                                          ; preds = %cpumask_test_cpu.exit
  %33 = ptrtoint ptr %sd.0113 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %sd.0113, align 8
  %tobool50.not = icmp eq ptr %34, null
  br i1 %tobool50.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc, %do.body55, %do.end48
  %call.i101 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i101, label %rcu_read_unlock.exit, label %land.lhs.true.i104

land.lhs.true.i104:                               ; preds = %for.end
  %call1.i102 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i103 = icmp eq i32 %call1.i102, 0
  br i1 %tobool.not.i103, label %rcu_read_unlock.exit, label %land.lhs.true2.i106

land.lhs.true2.i106:                              ; preds = %land.lhs.true.i104
  %.b4.i105 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i105, label %rcu_read_unlock.exit, label %if.then.i107

if.then.i107:                                     ; preds = %land.lhs.true2.i106
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i107, %land.lhs.true2.i106, %land.lhs.true.i104, %for.end
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %35 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i108 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i.i.i108 to ptr
  %preempt_count.i.i.i.i109 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i.i.i109 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i.i.i109, align 4
  %sub.i.i.i = add i32 %38, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i109, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %if.end60

if.end60:                                         ; preds = %rcu_read_unlock.exit, %do.body9
  %and = and i32 %wake_flags, 32
  %tobool61.not = icmp eq i32 %and, 0
  br i1 %tobool61.not, label %do.body69, label %do.body63

do.body63:                                        ; preds = %if.end60
  %nr_wakeups_migrate = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29, i32 21
  %39 = ptrtoint ptr %nr_wakeups_migrate to i32
  call void @__asan_load8_noabort(i32 %39)
  %40 = load i64, ptr %nr_wakeups_migrate, align 8
  %inc65 = add i64 %40, 1
  store i64 %inc65, ptr %nr_wakeups_migrate, align 8
  br label %do.body69

do.body69:                                        ; preds = %do.body63, %if.end60
  %ttwu_count = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 73
  %41 = ptrtoint ptr %ttwu_count to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %ttwu_count, align 4
  %inc70 = add i32 %42, 1
  store i32 %inc70, ptr %ttwu_count, align 4
  %nr_wakeups = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29, i32 19
  %43 = ptrtoint ptr %nr_wakeups to i32
  call void @__asan_load8_noabort(i32 %43)
  %44 = load i64, ptr %nr_wakeups, align 8
  %inc75 = add i64 %44, 1
  store i64 %inc75, ptr %nr_wakeups, align 8
  %and78 = and i32 %wake_flags, 16
  %tobool79.not = icmp eq i32 %and78, 0
  br i1 %tobool79.not, label %cleanup, label %do.body81

do.body81:                                        ; preds = %do.body69
  %nr_wakeups_sync = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 29, i32 20
  %45 = ptrtoint ptr %nr_wakeups_sync to i32
  call void @__asan_load8_noabort(i32 %45)
  %46 = load i64, ptr %nr_wakeups_sync, align 32
  %inc83 = add i64 %46, 1
  store i64 %inc83, ptr %nr_wakeups_sync, align 32
  br label %cleanup

cleanup:                                          ; preds = %do.body81, %do.body69, %entry
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__task_rq_unlock(ptr noundef %rq, ptr nocapture noundef %rf) unnamed_addr #3 align 64 {
entry:
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %0 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ugt i32 %1, 2
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %clock_update_flags1.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %2 = ptrtoint ptr %clock_update_flags1.i to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 4, ptr %clock_update_flags1.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %if.end.i
  %retval.0.i.i = phi ptr [ %6, %if.then.i.i ], [ %rq, %if.end.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %7 = ptrtoint ptr %cookie.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %.unpack.i = load i32, ptr %cookie.i, align 4
  %8 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %8) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__task_rq_unlock, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %rq_unpin_lock.exit
  %9 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %10, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i3

if.then.i.i3:                                     ; preds = %land.rhs.i.i.i
  %core.i.i2 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i.i2 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i.i2, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i3, %land.rhs.i.i.i, %rq_unpin_lock.exit
  %retval.0.i.i4 = phi ptr [ %12, %if.then.i.i3 ], [ %rq, %land.rhs.i.i.i ], [ %rq, %rq_unpin_lock.exit ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__smp_call_single_queue(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: argmemonly mustprogress nofree nounwind null_pointer_is_valid readonly willreturn
declare dso_local i32 @strcmp(ptr nocapture noundef, ptr nocapture noundef) local_unnamed_addr #20

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_dl_task_timer(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @init_dl_inactive_task_timer(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__dl_clear_params(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @reweight_task(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @task_wants_autogroup(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc zeroext i1 @is_cpu_allowed(ptr noundef %p, i32 noundef %cpu) unnamed_addr #3 align 64 {
entry:
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  %0 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %cpus_ptr, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %2 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %2, %cpu
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %entry
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %entry
  %div3.i.i = lshr i32 %cpu, 5
  %arrayidx.i.i = getelementptr i32, ptr %1, i32 %div3.i.i
  %3 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %arrayidx.i.i, align 4
  %and.i.i = and i32 %cpu, 31
  %5 = shl nuw i32 1, %and.i.i
  %6 = and i32 %4, %5
  %tobool.not = icmp eq i32 %6, 0
  br i1 %tobool.not, label %return, label %if.end

if.end:                                           ; preds = %cpumask_test_cpu.exit
  %migration_disabled.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 37
  %7 = ptrtoint ptr %migration_disabled.i to i32
  call void @__asan_load2_noabort(i32 %7)
  %8 = load i16, ptr %migration_disabled.i, align 4
  %tobool.i.not = icmp eq i16 %8, 0
  br i1 %tobool.i.not, label %if.end4, label %if.then2

if.then2:                                         ; preds = %if.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %9 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %9, %cpu
  br i1 %cmp.not.i.i.i.i, label %return.sink.split, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %if.then2
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %return.sink.split, label %return.sink.split.sink.split, !prof !1191

if.end4:                                          ; preds = %if.end
  %flags = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 3
  %10 = ptrtoint ptr %flags to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %flags, align 4
  %and = and i32 %11, 2097152
  %tobool5.not = icmp eq i32 %and, 0
  br i1 %tobool5.not, label %if.then6, label %if.end8

if.then6:                                         ; preds = %if.end4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %12 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i26 = icmp ugt i32 %12, %cpu
  br i1 %cmp.not.i.i.i.i26, label %return.sink.split, label %land.rhs.i.i.i.i28

land.rhs.i.i.i.i28:                               ; preds = %if.then6
  %.b37.i.i.i.i27 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i27, label %return.sink.split, label %return.sink.split.sink.split, !prof !1191

if.end8:                                          ; preds = %if.end4
  %call9 = tail call zeroext i1 @kthread_is_per_cpu(ptr noundef %p) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %13 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i34 = icmp ugt i32 %13, %cpu
  br i1 %call9, label %if.then10, label %if.end12

if.then10:                                        ; preds = %if.end8
  br i1 %cmp.not.i.i.i.i34, label %return.sink.split, label %land.rhs.i.i.i.i36

land.rhs.i.i.i.i36:                               ; preds = %if.then10
  %.b37.i.i.i.i35 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i35, label %return.sink.split, label %return.sink.split.sink.split, !prof !1191

if.end12:                                         ; preds = %if.end8
  br i1 %cmp.not.i.i.i.i34, label %cpu_dying.exit, label %land.rhs.i.i.i.i45

land.rhs.i.i.i.i45:                               ; preds = %if.end12
  %.b37.i.i.i.i44 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i44, label %cpu_dying.exit, label %if.then.i.i.i.i46, !prof !1191

if.then.i.i.i.i46:                                ; preds = %land.rhs.i.i.i.i45
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_dying.exit

cpu_dying.exit:                                   ; preds = %if.then.i.i.i.i46, %land.rhs.i.i.i.i45, %if.end12
  %arrayidx.i.i.i48 = getelementptr i32, ptr @__cpu_dying_mask, i32 %div3.i.i
  %14 = ptrtoint ptr %arrayidx.i.i.i48 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %arrayidx.i.i.i48, align 4
  %16 = and i32 %15, %5
  %tobool.i50.not = icmp eq i32 %16, 0
  br i1 %tobool.i50.not, label %if.end15, label %return

if.end15:                                         ; preds = %cpu_dying.exit
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %17 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i51 = icmp ugt i32 %17, %cpu
  br i1 %cmp.not.i.i.i.i51, label %return.sink.split, label %land.rhs.i.i.i.i53

land.rhs.i.i.i.i53:                               ; preds = %if.end15
  %.b37.i.i.i.i52 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i52, label %return.sink.split, label %return.sink.split.sink.split, !prof !1191

return.sink.split.sink.split:                     ; preds = %land.rhs.i.i.i.i53, %land.rhs.i.i.i.i36, %land.rhs.i.i.i.i28, %land.rhs.i.i.i.i
  %__cpu_online_mask.sink.ph = phi ptr [ @__cpu_online_mask, %land.rhs.i.i.i.i ], [ @__cpu_active_mask, %land.rhs.i.i.i.i28 ], [ @__cpu_online_mask, %land.rhs.i.i.i.i36 ], [ @__cpu_online_mask, %land.rhs.i.i.i.i53 ]
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %return.sink.split

return.sink.split:                                ; preds = %return.sink.split.sink.split, %land.rhs.i.i.i.i53, %if.end15, %land.rhs.i.i.i.i36, %if.then10, %land.rhs.i.i.i.i28, %if.then6, %land.rhs.i.i.i.i, %if.then2
  %__cpu_online_mask.sink = phi ptr [ @__cpu_online_mask, %if.then2 ], [ @__cpu_online_mask, %land.rhs.i.i.i.i ], [ @__cpu_active_mask, %if.then6 ], [ @__cpu_active_mask, %land.rhs.i.i.i.i28 ], [ @__cpu_online_mask, %if.then10 ], [ @__cpu_online_mask, %land.rhs.i.i.i.i36 ], [ @__cpu_online_mask, %if.end15 ], [ @__cpu_online_mask, %land.rhs.i.i.i.i53 ], [ %__cpu_online_mask.sink.ph, %return.sink.split.sink.split ]
  %arrayidx.i.i.i56 = getelementptr i32, ptr %__cpu_online_mask.sink, i32 %div3.i.i
  %18 = ptrtoint ptr %arrayidx.i.i.i56 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %arrayidx.i.i.i56, align 4
  %20 = and i32 %19, %5
  %tobool.i58 = icmp ne i32 %20, 0
  br label %return

return:                                           ; preds = %return.sink.split, %cpu_dying.exit, %cpumask_test_cpu.exit
  %retval.0 = phi i1 [ false, %cpumask_test_cpu.exit ], [ false, %cpu_dying.exit ], [ %tobool.i58, %return.sink.split ]
  ret i1 %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @select_fallback_rq(i32 noundef %cpu, ptr noundef %p) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %dest_cpu.0 = phi i32 [ -1, %entry ], [ %call, %for.body ]
  %call = tail call i32 @cpumask_next(i32 noundef %dest_cpu.0, ptr noundef nonnull @__cpu_online_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %0 = load i32, ptr @nr_cpu_ids, align 4
  %cmp1 = icmp ult i32 %call, %0
  br i1 %cmp1, label %for.body, label %for.cond5.preheader

for.cond5.preheader:                              ; preds = %for.cond
  %cpus_ptr = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 33
  br label %for.cond5.outer

for.body:                                         ; preds = %for.cond
  %call2 = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %p, i32 noundef %call)
  br i1 %call2, label %cleanup, label %for.cond

for.cond5:                                        ; preds = %for.cond5.outer, %for.end13
  br label %for.cond6

for.cond6:                                        ; preds = %for.body9, %for.cond5
  %dest_cpu.1 = phi i32 [ -1, %for.cond5 ], [ %call7, %for.body9 ]
  %1 = ptrtoint ptr %cpus_ptr to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %cpus_ptr, align 4
  %call7 = tail call i32 @cpumask_next(i32 noundef %dest_cpu.1, ptr noundef %2) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %3 = load i32, ptr @nr_cpu_ids, align 4
  %cmp8 = icmp ult i32 %call7, %3
  br i1 %cmp8, label %for.body9, label %for.end13

for.body9:                                        ; preds = %for.cond6
  %call10 = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %p, i32 noundef %call7)
  br i1 %call10, label %out, label %for.cond6

for.end13:                                        ; preds = %for.cond6
  switch i32 %state.0.ph, label %for.cond5 [
    i32 0, label %sw.bb
    i32 1, label %sw.bb17
    i32 2, label %do.body
  ]

sw.bb:                                            ; preds = %for.end13
  %call14 = tail call zeroext i1 @cpuset_cpus_allowed_fallback(ptr noundef %p) #33
  br i1 %call14, label %for.cond5.outer.backedge, label %sw.bb17

for.cond5.outer:                                  ; preds = %for.cond5.outer.backedge, %for.cond5.preheader
  %state.0.ph = phi i32 [ 0, %for.cond5.preheader ], [ %state.0.ph.be, %for.cond5.outer.backedge ]
  br label %for.cond5

sw.bb17:                                          ; preds = %sw.bb, %for.end13
  tail call fastcc void @__do_set_cpus_allowed(ptr noundef %p, ptr noundef nonnull @__cpu_possible_mask, i32 noundef 0) #33
  br label %for.cond5.outer.backedge

for.cond5.outer.backedge:                         ; preds = %sw.bb17, %sw.bb
  %state.0.ph.be = phi i32 [ 1, %sw.bb ], [ 2, %sw.bb17 ]
  br label %for.cond5.outer

do.body:                                          ; preds = %for.end13
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 3403, 0\0A.popsection", ""() #33, !srcloc !1339
  unreachable

out:                                              ; preds = %for.body9
  %cmp22.not = icmp eq i32 %state.0.ph, 0
  br i1 %cmp22.not, label %cleanup, label %if.then23

if.then23:                                        ; preds = %out
  %mm = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 53
  %4 = ptrtoint ptr %mm to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %mm, align 8
  %tobool.not = icmp eq ptr %5, null
  br i1 %tobool.not, label %cleanup, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.then23
  %call24 = tail call i32 @__printk_ratelimit(ptr noundef nonnull @__func__.select_fallback_rq) #33
  %tobool25.not = icmp eq i32 %call24, 0
  br i1 %tobool25.not, label %cleanup, label %do.end29

do.end29:                                         ; preds = %land.lhs.true
  %pid.i = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 68
  %6 = ptrtoint ptr %pid.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %pid.i, align 8
  %comm = getelementptr inbounds %struct.task_struct, ptr %p, i32 0, i32 101
  %call31 = tail call i32 (ptr, ...) @_printk_deferred(ptr noundef nonnull @.str.197, i32 noundef %7, ptr noundef %comm, i32 noundef %cpu) #39
  br label %cleanup

cleanup:                                          ; preds = %do.end29, %land.lhs.true, %if.then23, %out, %for.body
  %retval.0 = phi i32 [ %call7, %if.then23 ], [ %call7, %land.lhs.true ], [ %call7, %do.end29 ], [ %call7, %out ], [ %call, %for.body ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_find_first_bit_be(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @kthread_is_per_cpu(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @cpuset_cpus_allowed_fallback(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_unpin_lock(ptr noundef, [1 x i32]) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_repin_lock(ptr noundef, [1 x i32]) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @finish_lock_switch(ptr noundef %rq) #3 align 64 {
entry:
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i, align 128
  %tobool.not.i = icmp eq i32 %1, 0
  br i1 %tobool.not.i, label %__here, label %if.then.i

if.then.i:                                        ; preds = %entry
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core.i, align 8
  br label %__here

__here:                                           ; preds = %if.then.i, %entry
  %retval.0.i = phi ptr [ %3, %if.then.i ], [ %rq, %entry ]
  %dep_map = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i, i32 0, i32 4
  tail call void @lock_acquire(ptr noundef %dep_map, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@finish_lock_switch, %__here) to i32)) #33
  tail call fastcc void @__balance_callbacks(ptr noundef %rq)
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@finish_lock_switch, %land.rhs.i.i.i.i)) #33
          to label %raw_spin_rq_unlock_irq.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %__here
  %4 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %core_enabled.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %5, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock_irq.exit, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %6 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %core.i.i.i, align 8
  br label %raw_spin_rq_unlock_irq.exit

raw_spin_rq_unlock_irq.exit:                      ; preds = %if.then.i.i.i, %land.rhs.i.i.i.i, %__here
  %retval.0.i.i.i = phi ptr [ %7, %if.then.i.i.i ], [ %rq, %land.rhs.i.i.i.i ], [ %rq, %__here ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @put_task_struct_rcu_user(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__perf_event_task_sched_in(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @___perf_sw_event(i32 noundef, i64 noundef, ptr noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @raw_spin_rq_unlock_irq(ptr noundef %rq) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@raw_spin_rq_unlock_irq, %land.rhs.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit [label %land.rhs.i.i.i], !srcloc !1202

land.rhs.i.i.i:                                   ; preds = %entry
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %0 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i = icmp eq i32 %1, 0
  br i1 %tobool3.i.not.i.i, label %raw_spin_rq_unlock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i.i.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %2 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %core.i.i, align 8
  br label %raw_spin_rq_unlock.exit

raw_spin_rq_unlock.exit:                          ; preds = %if.then.i.i, %land.rhs.i.i.i, %entry
  %retval.0.i.i = phi ptr [ %3, %if.then.i.i ], [ %rq, %land.rhs.i.i.i ], [ %rq, %entry ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__kmap_local_sched_in() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__mmdrop(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__task_pid_nr_ns(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @flush_smp_call_function_from_idle() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock(ptr noundef) local_unnamed_addr #2 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_kstrtol(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__sched_core_tick(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @cpumask_next_wrap(i32 noundef, ptr noundef, i32 noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc zeroext i1 @try_steal_cookie(i32 noundef %this, i32 noundef %that) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %this
  %0 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %arrayidx, align 4
  %add = add i32 %1, ptrtoint (ptr @runqueues to i32)
  %2 = inttoptr i32 %add to ptr
  %arrayidx9 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %that
  %3 = ptrtoint ptr %arrayidx9 to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %arrayidx9, align 4
  %add10 = add i32 %4, ptrtoint (ptr @runqueues to i32)
  %5 = inttoptr i32 %add10 to ptr
  %6 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i = and i32 %6, 128
  %tobool.not = icmp eq i32 %and.i.i, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  tail call void @double_rq_lock(ptr noundef %2, ptr noundef %5)
  %core = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 79
  %7 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core, align 8
  %core_cookie = getelementptr inbounds %struct.rq, ptr %8, i32 0, i32 86
  %9 = ptrtoint ptr %core_cookie to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_cookie, align 4
  %tobool15.not = icmp eq i32 %10, 0
  br i1 %tobool15.not, label %unlock, label %if.end17

if.end17:                                         ; preds = %if.end
  %curr = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 20
  %11 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %curr, align 8
  %idle = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 21
  %13 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %idle, align 4
  %cmp.not = icmp eq ptr %12, %14
  br i1 %cmp.not, label %if.end19, label %unlock

if.end19:                                         ; preds = %if.end17
  %core_tree.i = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 83
  %15 = ptrtoint ptr %core_tree.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %node.01.i.i = load ptr, ptr %core_tree.i, align 4
  %tobool.not2.i.i = icmp eq ptr %node.01.i.i, null
  br i1 %tobool.not2.i.i, label %if.then.i, label %while.body.i.i

while.body.i.i:                                   ; preds = %while.body.i.i, %if.end19
  %node.04.i.i = phi ptr [ %node.0.i.i, %while.body.i.i ], [ %node.01.i.i, %if.end19 ]
  %match.03.i.i = phi ptr [ %match.2.i.i, %while.body.i.i ], [ null, %if.end19 ]
  %core_cookie.i.i.i = getelementptr i8, ptr %node.04.i.i, i32 12
  %16 = ptrtoint ptr %core_cookie.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %core_cookie.i.i.i, align 16
  %cmp.i.i.i = icmp ugt i32 %17, %10
  %cmp2.i.i.i = icmp ult i32 %17, %10
  %..i.i.i = zext i1 %cmp2.i.i.i to i32
  %retval.0.i.i.i = select i1 %cmp.i.i.i, i32 -1, i32 %..i.i.i
  %cmp1.i.i = icmp slt i32 %retval.0.i.i.i, 1
  %tobool2.not.i.i = icmp eq i32 %retval.0.i.i.i, 0
  %rb_left.i.i = getelementptr inbounds %struct.rb_node, ptr %node.04.i.i, i32 0, i32 2
  %rb_right.i.i = getelementptr inbounds %struct.rb_node, ptr %node.04.i.i, i32 0, i32 1
  %node.1.in.i.i = select i1 %cmp1.i.i, ptr %rb_left.i.i, ptr %rb_right.i.i
  %match.2.i.i = select i1 %tobool2.not.i.i, ptr %node.04.i.i, ptr %match.03.i.i
  %18 = ptrtoint ptr %node.1.in.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %node.0.i.i = load ptr, ptr %node.1.in.i.i, align 4
  %tobool.not.i.i = icmp eq ptr %node.0.i.i, null
  br i1 %tobool.not.i.i, label %rb_find_first.exit.i, label %while.body.i.i

rb_find_first.exit.i:                             ; preds = %while.body.i.i
  %tobool.not.i = icmp eq ptr %match.2.i.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %rb_find_first.exit.i, %if.end19
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11) to i32))
  %19 = load ptr, ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11), align 4
  %call1.i = tail call ptr %19(ptr noundef %5) #33
  br label %sched_core_find.exit

if.end.i:                                         ; preds = %rb_find_first.exit.i
  %add.ptr.i = getelementptr i8, ptr %match.2.i.i, i32 -612
  br label %sched_core_find.exit

sched_core_find.exit:                             ; preds = %if.end.i, %if.then.i
  %retval.0.i = phi ptr [ %add.ptr.i, %if.end.i ], [ %call1.i, %if.then.i ]
  %idle21 = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 21
  %20 = ptrtoint ptr %idle21 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %idle21, align 4
  %cmp22 = icmp eq ptr %retval.0.i, %21
  br i1 %cmp22, label %unlock, label %do.body25.preheader

do.body25.preheader:                              ; preds = %sched_core_find.exit
  %core_pick = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 80
  %curr27 = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 20
  %div3.i.i = lshr i32 %this, 5
  %and.i.i74 = and i32 %this, 31
  %22 = shl nuw i32 1, %and.i.i74
  br label %do.body25

do.body25:                                        ; preds = %if.end.i78, %do.body25.preheader
  %p.0 = phi ptr [ %add.ptr.i77, %if.end.i78 ], [ %retval.0.i, %do.body25.preheader ]
  %23 = ptrtoint ptr %core_pick to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %core_pick, align 4
  %cmp26 = icmp eq ptr %p.0, %24
  br i1 %cmp26, label %next, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %do.body25
  %25 = ptrtoint ptr %curr27 to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %curr27, align 8
  %cmp28 = icmp eq ptr %p.0, %26
  br i1 %cmp28, label %next, label %if.end30

if.end30:                                         ; preds = %lor.lhs.false
  %cpus_mask = getelementptr inbounds %struct.task_struct, ptr %p.0, i32 0, i32 35
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %27 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i = icmp ugt i32 %27, %this
  br i1 %cmp.not.i.i.i, label %cpumask_test_cpu.exit, label %land.rhs.i.i.i

land.rhs.i.i.i:                                   ; preds = %if.end30
  %.b37.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i, label %cpumask_test_cpu.exit, label %if.then.i.i.i, !prof !1191

if.then.i.i.i:                                    ; preds = %land.rhs.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpumask_test_cpu.exit

cpumask_test_cpu.exit:                            ; preds = %if.then.i.i.i, %land.rhs.i.i.i, %if.end30
  %arrayidx.i.i = getelementptr i32, ptr %cpus_mask, i32 %div3.i.i
  %28 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load volatile i32, ptr %arrayidx.i.i, align 4
  %30 = and i32 %29, %22
  %tobool32.not = icmp eq i32 %30, 0
  br i1 %tobool32.not, label %next, label %if.end34

if.end34:                                         ; preds = %cpumask_test_cpu.exit
  %core_occupation = getelementptr inbounds %struct.task_struct, ptr %p.0, i32 0, i32 24
  %31 = ptrtoint ptr %core_occupation to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %core_occupation, align 4
  %33 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %idle, align 4
  %core_occupation36 = getelementptr inbounds %struct.task_struct, ptr %34, i32 0, i32 24
  %35 = ptrtoint ptr %core_occupation36 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %core_occupation36, align 4
  %cmp37 = icmp ugt i32 %32, %36
  br i1 %cmp37, label %next, label %if.end39

if.end39:                                         ; preds = %if.end34
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %p.0, i32 0, i32 12
  %37 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %37)
  store i32 2, ptr %on_rq.i, align 4
  tail call fastcc void @dequeue_task(ptr noundef %5, ptr noundef %p.0, i32 noundef 0) #33
  tail call void @set_task_cpu(ptr noundef %p.0, i32 noundef %this)
  tail call fastcc void @enqueue_task(ptr noundef %2, ptr noundef %p.0, i32 noundef 0) #33
  %38 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 1, ptr %on_rq.i, align 4
  tail call void @resched_curr(ptr noundef %2)
  br label %unlock

next:                                             ; preds = %if.end34, %cpumask_test_cpu.exit, %lor.lhs.false, %do.body25
  %core_node.i = getelementptr inbounds %struct.task_struct, ptr %p.0, i32 0, i32 22
  %call.i = tail call ptr @rb_next(ptr noundef %core_node.i) #33
  %tobool.not.i76 = icmp eq ptr %call.i, null
  br i1 %tobool.not.i76, label %unlock, label %if.end.i78

if.end.i78:                                       ; preds = %next
  %core_cookie.i = getelementptr i8, ptr %call.i, i32 12
  %39 = ptrtoint ptr %core_cookie.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %core_cookie.i, align 16
  %cmp.not.i = icmp ne i32 %40, %10
  %add.ptr.i77 = getelementptr i8, ptr %call.i, i32 -612
  %tobool42.not = icmp eq ptr %add.ptr.i77, null
  %or.cond = select i1 %cmp.not.i, i1 true, i1 %tobool42.not
  br i1 %or.cond, label %unlock, label %do.body25

unlock:                                           ; preds = %if.end.i78, %next, %if.end39, %sched_core_find.exit, %if.end17, %if.end
  %success.0.off0 = phi i1 [ false, %if.end17 ], [ false, %sched_core_find.exit ], [ true, %if.end39 ], [ false, %if.end ], [ false, %next ], [ false, %if.end.i78 ]
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %2, i32 0, i32 81
  %41 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i80 = icmp eq i32 %42, 0
  br i1 %tobool.not.i.i80, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %unlock
  %43 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %core, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %unlock
  %retval.0.i.i = phi ptr [ %44, %if.then.i.i ], [ %2, %unlock ]
  %core_enabled.i4.i = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 81
  %45 = ptrtoint ptr %core_enabled.i4.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %core_enabled.i4.i, align 128
  %tobool.not.i5.i = icmp eq i32 %46, 0
  br i1 %tobool.not.i5.i, label %__rq_lockp.exit9.i, label %if.then.i7.i

if.then.i7.i:                                     ; preds = %__rq_lockp.exit.i
  %core.i6.i = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 79
  %47 = ptrtoint ptr %core.i6.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load ptr, ptr %core.i6.i, align 8
  br label %__rq_lockp.exit9.i

__rq_lockp.exit9.i:                               ; preds = %if.then.i7.i, %__rq_lockp.exit.i
  %retval.0.i8.i = phi ptr [ %48, %if.then.i7.i ], [ %5, %__rq_lockp.exit.i ]
  %cmp.not.i81 = icmp eq ptr %retval.0.i.i, %retval.0.i8.i
  br i1 %cmp.not.i81, label %if.end.i85, label %if.then.i82

if.then.i82:                                      ; preds = %__rq_lockp.exit9.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@try_steal_cookie, %land.rhs.i.i.i.i)) #33
          to label %raw_spin_rq_unlock.exit.i [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %if.then.i82
  %49 = ptrtoint ptr %core_enabled.i4.i to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load i32, ptr %core_enabled.i4.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %50, 0
  br i1 %tobool3.i.not.i.i.i, label %raw_spin_rq_unlock.exit.i, label %if.then.i.i.i83

if.then.i.i.i83:                                  ; preds = %land.rhs.i.i.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %5, i32 0, i32 79
  %51 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %core.i.i.i, align 8
  br label %raw_spin_rq_unlock.exit.i

raw_spin_rq_unlock.exit.i:                        ; preds = %if.then.i.i.i83, %land.rhs.i.i.i.i, %if.then.i82
  %retval.0.i.i.i84 = phi ptr [ %52, %if.then.i.i.i83 ], [ %5, %land.rhs.i.i.i.i ], [ %5, %if.then.i82 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i84) #33
  br label %if.end.i85

if.end.i85:                                       ; preds = %raw_spin_rq_unlock.exit.i, %__rq_lockp.exit9.i
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@try_steal_cookie, %land.rhs.i.i.i12.i)) #33
          to label %double_rq_unlock.exit [label %land.rhs.i.i.i12.i], !srcloc !1202

land.rhs.i.i.i12.i:                               ; preds = %if.end.i85
  %53 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i.i11.i = icmp eq i32 %54, 0
  br i1 %tobool3.i.not.i.i11.i, label %double_rq_unlock.exit, label %if.then.i.i14.i

if.then.i.i14.i:                                  ; preds = %land.rhs.i.i.i12.i
  %55 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load ptr, ptr %core, align 8
  br label %double_rq_unlock.exit

double_rq_unlock.exit:                            ; preds = %if.then.i.i14.i, %land.rhs.i.i.i12.i, %if.end.i85
  %retval.0.i.i15.i = phi ptr [ %56, %if.then.i.i14.i ], [ %2, %land.rhs.i.i.i12.i ], [ %2, %if.end.i85 ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i15.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  ret i1 %success.0.off0
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @rb_next(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @schedule_debug(ptr noundef %prev, i1 noundef zeroext %preempt) unnamed_addr #3 align 64 {
entry:
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 1
  %0 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %stack.i, align 4
  %add.ptr.i = getelementptr %struct.thread_info, ptr %1, i32 1
  %2 = ptrtoint ptr %add.ptr.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %add.ptr.i, align 4
  %cmp.not = icmp eq i32 %3, 1470918301
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  call void @__asan_handle_no_return()
  tail call void (ptr, ...) @panic(ptr noundef nonnull @.str.202) #42
  unreachable

if.end:                                           ; preds = %entry
  br i1 %preempt, label %if.end13, label %do.end

do.end:                                           ; preds = %if.end
  %4 = ptrtoint ptr %prev to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %prev, align 128
  %tobool4.not = icmp eq i32 %5, 0
  br i1 %tobool4.not, label %if.end13, label %land.lhs.true5

land.lhs.true5:                                   ; preds = %do.end
  %non_block_count = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 134
  %6 = ptrtoint ptr %non_block_count to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %non_block_count, align 8
  %tobool6.not = icmp eq i32 %7, 0
  br i1 %tobool6.not, label %if.end13, label %do.end9

do.end9:                                          ; preds = %land.lhs.true5
  %comm = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 101
  %pid = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 68
  %8 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %pid, align 8
  %call12 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.204, ptr noundef %comm, i32 noundef %9, i32 noundef %7) #39
  tail call void @dump_stack() #39
  tail call void @add_taint(i32 noundef 9, i32 noundef 0) #33
  br label %if.end13

if.end13:                                         ; preds = %do.end9, %land.lhs.true5, %do.end, %if.end
  %10 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 1
  %12 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load volatile i32, ptr %preempt_count.i, align 4
  %cmp15.not = icmp eq i32 %13, 1
  br i1 %cmp15.not, label %do.body20, label %if.then18, !prof !1191

if.then18:                                        ; preds = %if.end13
  tail call fastcc void @__schedule_bug(ptr noundef %prev)
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_store4_noabort(i32 %16)
  store volatile i32 1, ptr %preempt_count.i.i, align 4
  br label %do.body20

do.body20:                                        ; preds = %if.then18, %if.end13
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_lock_map, i32 noundef -1) #33
  %tobool.not.i = icmp eq i32 %call.i.i, 0
  br i1 %tobool.not.i, label %rcu_preempt_sleep_check.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %do.body20
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool2.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool2.not.i, label %rcu_preempt_sleep_check.exit, label %land.lhs.true3.i

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %.b5.i = load i1, ptr @rcu_preempt_sleep_check.__warned, align 1
  br i1 %.b5.i, label %rcu_preempt_sleep_check.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true3.i
  store i1 true, ptr @rcu_preempt_sleep_check.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 329, ptr noundef nonnull @.str.243) #33
  br label %rcu_preempt_sleep_check.exit

rcu_preempt_sleep_check.exit:                     ; preds = %if.then.i, %land.lhs.true3.i, %land.lhs.true.i, %do.body20
  %call.i = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_bh_lock_map, i32 noundef -1) #33
  %tobool23.not = icmp eq i32 %call.i, 0
  br i1 %tobool23.not, label %do.body32, label %land.lhs.true24

land.lhs.true24:                                  ; preds = %rcu_preempt_sleep_check.exit
  %call25 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool26.not = icmp eq i32 %call25, 0
  br i1 %tobool26.not, label %do.body32, label %land.lhs.true27

land.lhs.true27:                                  ; preds = %land.lhs.true24
  %.b126 = load i1, ptr @schedule_debug.__warned, align 1
  br i1 %.b126, label %do.body32, label %if.then29

if.then29:                                        ; preds = %land.lhs.true27
  store i1 true, ptr @schedule_debug.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 5569, ptr noundef nonnull @.str.72) #33
  br label %do.body32

do.body32:                                        ; preds = %if.then29, %land.lhs.true27, %land.lhs.true24, %rcu_preempt_sleep_check.exit
  %call.i127 = tail call i32 @lock_is_held_type(ptr noundef nonnull @rcu_sched_lock_map, i32 noundef -1) #33
  %tobool34.not = icmp eq i32 %call.i127, 0
  br i1 %tobool34.not, label %do.end43, label %land.lhs.true35

land.lhs.true35:                                  ; preds = %do.body32
  %call36 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool37.not = icmp eq i32 %call36, 0
  br i1 %tobool37.not, label %do.end43, label %land.lhs.true38

land.lhs.true38:                                  ; preds = %land.lhs.true35
  %.b124125 = load i1, ptr @schedule_debug.__warned.206, align 1
  br i1 %.b124125, label %do.end43, label %if.then40

if.then40:                                        ; preds = %land.lhs.true38
  store i1 true, ptr @schedule_debug.__warned.206, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 5569, ptr noundef nonnull @.str.74) #33
  br label %do.end43

do.end43:                                         ; preds = %if.then40, %land.lhs.true38, %land.lhs.true35, %do.body32
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @prof_on to i32))
  %17 = load i32, ptr @prof_on, align 4
  %cmp.i = icmp eq i32 %17, 2
  br i1 %cmp.i, label %if.then.i128, label %profile_hit.exit, !prof !1192

if.then.i128:                                     ; preds = %do.end43
  %18 = tail call ptr @llvm.returnaddress(i32 0)
  tail call void @profile_hits(i32 noundef 2, ptr noundef %18, i32 noundef 1) #33
  br label %profile_hit.exit

profile_hit.exit:                                 ; preds = %if.then.i128, %do.end43
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@schedule_debug, %do.body106)) #33
          to label %do.end114 [label %do.body106], !srcloc !1202

do.body106:                                       ; preds = %profile_hit.exit
  %19 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 3
  %21 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %22
  %23 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %arrayidx, align 4
  %add = add i32 %24, ptrtoint (ptr @runqueues to i32)
  %25 = inttoptr i32 %add to ptr
  %sched_count = getelementptr inbounds %struct.rq, ptr %25, i32 0, i32 71
  %26 = ptrtoint ptr %sched_count to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %sched_count, align 4
  %inc = add i32 %27, 1
  store i32 %inc, ptr %sched_count, align 4
  br label %do.end114

do.end114:                                        ; preds = %do.body106, %profile_hit.exit
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @rcu_note_context_switch(i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc ptr @pick_next_task(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %core = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %0 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %core, align 8
  %cmp = icmp eq ptr %1, %rq
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@pick_next_task, %land.rhs.i)) #33
          to label %if.then [label %land.rhs.i], !srcloc !1202

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %2 = ptrtoint ptr %core_enabled.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %core_enabled.i, align 128
  %tobool3.i.not = icmp eq i32 %3, 0
  br i1 %tobool3.i.not, label %if.then, label %if.end

if.then:                                          ; preds = %land.rhs.i, %entry
  %sched_class.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %4 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %sched_class.i, align 32
  %cmp.not.i = icmp ugt ptr %5, @fair_sched_class
  br i1 %cmp.not.i, label %restart.i, label %land.rhs.i508, !prof !1192

land.rhs.i508:                                    ; preds = %if.then
  %nr_running.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %6 = ptrtoint ptr %nr_running.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %nr_running.i, align 4
  %h_nr_running.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 14, i32 2
  %8 = ptrtoint ptr %h_nr_running.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %h_nr_running.i, align 4
  %cmp1.i = icmp eq i32 %7, %9
  br i1 %cmp1.i, label %if.then.i, label %restart.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs.i508
  %call.i = tail call ptr @pick_next_task_fair(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) #33
  %magicptr.i = ptrtoint ptr %call.i to i32
  switch i32 %magicptr.i, label %cleanup [
    i32 -1, label %restart.i
    i32 0, label %if.then12.i
  ], !prof !1340

if.then12.i:                                      ; preds = %if.then.i
  %curr.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %10 = ptrtoint ptr %curr.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %curr.i.i, align 8
  %cmp.not.i.i = icmp eq ptr %11, %prev
  br i1 %cmp.not.i.i, label %put_prev_task.exit.i, label %land.rhs.i.i

land.rhs.i.i:                                     ; preds = %if.then12.i
  %.b40.i.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i.i, label %put_prev_task.exit.i, label %if.then.i.i, !prof !1191

if.then.i.i:                                      ; preds = %land.rhs.i.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit.i

put_prev_task.exit.i:                             ; preds = %if.then.i.i, %land.rhs.i.i, %if.then12.i
  %12 = ptrtoint ptr %sched_class.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %sched_class.i, align 32
  %put_prev_task.i.i = getelementptr inbounds %struct.sched_class, ptr %13, i32 0, i32 7
  %14 = ptrtoint ptr %put_prev_task.i.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %put_prev_task.i.i, align 4
  tail call void %15(ptr noundef %rq, ptr noundef %prev) #33
  %call13.i = tail call ptr @pick_next_task_idle(ptr noundef %rq) #33
  br label %cleanup

restart.i:                                        ; preds = %if.then.i, %land.rhs.i508, %if.then
  tail call fastcc void @put_prev_task_balance(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) #33
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %do.body.i, label %for.body.i

for.cond.i:                                       ; preds = %for.body.i
  %incdec.ptr.i = getelementptr %struct.sched_class, ptr %class.041.i, i32 -1
  %cmp16.not.i = icmp eq ptr %incdec.ptr.i, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp16.not.i, label %do.body.i, label %for.body.i

for.body.i:                                       ; preds = %for.cond.i, %restart.i
  %class.041.i = phi ptr [ %incdec.ptr.i, %for.cond.i ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %restart.i ]
  %pick_next_task.i = getelementptr inbounds %struct.sched_class, ptr %class.041.i, i32 0, i32 6
  %16 = ptrtoint ptr %pick_next_task.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %pick_next_task.i, align 4
  %call17.i = tail call ptr %17(ptr noundef %rq) #33
  %tobool18.not.i = icmp eq ptr %call17.i, null
  br i1 %tobool18.not.i, label %for.cond.i, label %cleanup

do.body.i:                                        ; preds = %for.cond.i, %restart.i
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 5639, 0\0A.popsection", ""() #33, !srcloc !1341
  unreachable

if.end:                                           ; preds = %land.rhs.i
  %cpu.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 46
  %18 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load i32, ptr %cpu.i, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %20 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %20, %19
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %if.end
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %if.end
  %div3.i.i.i = lshr i32 %19, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %21 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i = and i32 %19, 31
  %23 = shl nuw i32 1, %and.i.i.i
  %24 = and i32 %22, %23
  %tobool.i.not = icmp eq i32 %24, 0
  br i1 %tobool.i.not, label %if.then6, label %if.end8, !prof !1192

if.then6:                                         ; preds = %cpu_online.exit
  %core_pick = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 80
  %25 = ptrtoint ptr %core_pick to i32
  call void @__asan_store4_noabort(i32 %25)
  store ptr null, ptr %core_pick, align 4
  %call7 = tail call fastcc ptr @__pick_next_task(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf)
  br label %cleanup

if.end8:                                          ; preds = %cpu_online.exit
  %26 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %core, align 8
  %core_pick_seq = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 85
  %28 = ptrtoint ptr %core_pick_seq to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %core_pick_seq, align 16
  %core_task_seq = getelementptr inbounds %struct.rq, ptr %27, i32 0, i32 84
  %30 = ptrtoint ptr %core_task_seq to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %core_task_seq, align 4
  %cmp11 = icmp eq i32 %29, %31
  br i1 %cmp11, label %land.lhs.true, label %if.end33

land.lhs.true:                                    ; preds = %if.end8
  %core_sched_seq = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 82
  %32 = ptrtoint ptr %core_sched_seq to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_sched_seq, align 4
  %cmp14.not = icmp eq i32 %29, %33
  br i1 %cmp14.not, label %if.end33, label %land.lhs.true15

land.lhs.true15:                                  ; preds = %land.lhs.true
  %core_pick16 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 80
  %34 = ptrtoint ptr %core_pick16 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %core_pick16, align 4
  %tobool17.not = icmp eq ptr %35, null
  br i1 %tobool17.not, label %if.end33, label %do.body20

do.body20:                                        ; preds = %land.lhs.true15
  %36 = ptrtoint ptr %core_sched_seq to i32
  call void @__asan_store4_noabort(i32 %36)
  store volatile i32 %29, ptr %core_sched_seq, align 4
  %cmp29.not = icmp eq ptr %35, %prev
  br i1 %cmp29.not, label %if.end31, label %if.then30

if.then30:                                        ; preds = %do.body20
  %curr.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %37 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %curr.i, align 8
  %cmp.not.i510 = icmp eq ptr %38, %prev
  br i1 %cmp.not.i510, label %put_prev_task.exit, label %land.rhs.i511

land.rhs.i511:                                    ; preds = %if.then30
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i512, !prof !1191

if.then.i512:                                     ; preds = %land.rhs.i511
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i512, %land.rhs.i511, %if.then30
  %sched_class.i513 = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %39 = ptrtoint ptr %sched_class.i513 to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load ptr, ptr %sched_class.i513, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %40, i32 0, i32 7
  %41 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %41)
  %42 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %42(ptr noundef %rq, ptr noundef %prev) #33
  %sched_class.i514 = getelementptr inbounds %struct.task_struct, ptr %35, i32 0, i32 21
  %43 = ptrtoint ptr %sched_class.i514 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %sched_class.i514, align 32
  %set_next_task.i = getelementptr inbounds %struct.sched_class, ptr %44, i32 0, i32 8
  %45 = ptrtoint ptr %set_next_task.i to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load ptr, ptr %set_next_task.i, align 4
  tail call void %46(ptr noundef %rq, ptr noundef nonnull %35, i1 noundef zeroext false) #33
  br label %if.end31

if.end31:                                         ; preds = %put_prev_task.exit, %do.body20
  %47 = ptrtoint ptr %core_pick16 to i32
  call void @__asan_store4_noabort(i32 %47)
  store ptr null, ptr %core_pick16, align 4
  br label %cleanup

if.end33:                                         ; preds = %land.lhs.true15, %land.lhs.true, %if.end8
  %sched_class.i515 = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %48 = ptrtoint ptr %sched_class.i515 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %sched_class.i515, align 32
  %cmp.not6.i = icmp eq ptr %49, @idle_sched_class
  br i1 %cmp.not6.i, label %for.end.i, label %for.body.i519

for.body.i519:                                    ; preds = %for.body.i519, %if.end33
  %class.07.i = phi ptr [ %incdec.ptr.i517, %for.body.i519 ], [ %49, %if.end33 ]
  %balance.i = getelementptr inbounds %struct.sched_class, ptr %class.07.i, i32 0, i32 9
  %50 = ptrtoint ptr %balance.i to i32
  call void @__asan_load4_noabort(i32 %50)
  %51 = load ptr, ptr %balance.i, align 4
  %call.i516 = tail call i32 %51(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) #33
  %tobool.not.i = icmp ne i32 %call.i516, 0
  %incdec.ptr.i517 = getelementptr %struct.sched_class, ptr %class.07.i, i32 -1
  %cmp.not.i518 = icmp eq ptr %incdec.ptr.i517, @idle_sched_class
  %or.cond.i = select i1 %tobool.not.i, i1 true, i1 %cmp.not.i518
  br i1 %or.cond.i, label %for.end.i, label %for.body.i519

for.end.i:                                        ; preds = %for.body.i519, %if.end33
  %curr.i.i520 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %52 = ptrtoint ptr %curr.i.i520 to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load ptr, ptr %curr.i.i520, align 8
  %cmp.not.i.i521 = icmp eq ptr %53, %prev
  br i1 %cmp.not.i.i521, label %put_prev_task_balance.exit, label %land.rhs.i.i523

land.rhs.i.i523:                                  ; preds = %for.end.i
  %.b40.i.i522 = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i.i522, label %put_prev_task_balance.exit, label %if.then.i.i524, !prof !1191

if.then.i.i524:                                   ; preds = %land.rhs.i.i523
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task_balance.exit

put_prev_task_balance.exit:                       ; preds = %if.then.i.i524, %land.rhs.i.i523, %for.end.i
  %54 = ptrtoint ptr %sched_class.i515 to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %sched_class.i515, align 32
  %put_prev_task.i.i525 = getelementptr inbounds %struct.sched_class, ptr %55, i32 0, i32 7
  %56 = ptrtoint ptr %put_prev_task.i.i525 to i32
  call void @__asan_load4_noabort(i32 %56)
  %57 = load ptr, ptr %put_prev_task.i.i525, align 4
  tail call void %57(ptr noundef %rq, ptr noundef %prev) #33
  %thread_sibling.i = getelementptr [4 x %struct.cpu_topology], ptr @cpu_topology, i32 0, i32 %19, i32 5
  %58 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %58)
  %59 = load ptr, ptr %core, align 8
  %core_cookie = getelementptr inbounds %struct.rq, ptr %59, i32 0, i32 86
  %60 = ptrtoint ptr %core_cookie to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load i32, ptr %core_cookie, align 4
  store i32 0, ptr %core_cookie, align 4
  %62 = load ptr, ptr %core, align 8
  %core_forceidle_count = getelementptr inbounds %struct.rq, ptr %62, i32 0, i32 87
  %63 = ptrtoint ptr %core_forceidle_count to i32
  call void @__asan_load4_noabort(i32 %63)
  %64 = load i32, ptr %core_forceidle_count, align 8
  %tobool45.not = icmp eq i32 %64, 0
  br i1 %tobool45.not, label %if.end55, label %if.then46

if.then46:                                        ; preds = %put_prev_task_balance.exit
  br i1 %cmp, label %if.end50, label %if.then48

if.then48:                                        ; preds = %if.then46
  tail call void @update_rq_clock(ptr noundef %62)
  br label %if.end50

if.end50:                                         ; preds = %if.then48, %if.then46
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@pick_next_task, %if.then.i527)) #33
          to label %if.end55.thread [label %if.then.i527], !srcloc !1202

if.then.i527:                                     ; preds = %if.end50
  tail call void @__sched_core_account_forceidle(ptr noundef %rq) #33
  br label %if.end55.thread

if.end55.thread:                                  ; preds = %if.then.i527, %if.end50
  %65 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %65)
  %66 = load ptr, ptr %core, align 8
  %core_forceidle_start = getelementptr inbounds %struct.rq, ptr %66, i32 0, i32 90
  %67 = ptrtoint ptr %core_forceidle_start to i32
  call void @__asan_store8_noabort(i32 %67)
  store i64 0, ptr %core_forceidle_start, align 8
  %68 = load ptr, ptr %core, align 8
  %core_forceidle_count53 = getelementptr inbounds %struct.rq, ptr %68, i32 0, i32 87
  %69 = ptrtoint ptr %core_forceidle_count53 to i32
  call void @__asan_store4_noabort(i32 %69)
  store i32 0, ptr %core_forceidle_count53, align 8
  %70 = load ptr, ptr %core, align 8
  %core_forceidle_occupation = getelementptr inbounds %struct.rq, ptr %70, i32 0, i32 89
  %71 = ptrtoint ptr %core_forceidle_occupation to i32
  call void @__asan_store4_noabort(i32 %71)
  store i32 0, ptr %core_forceidle_occupation, align 32
  %72 = load ptr, ptr %core, align 8
  %core_task_seq57575 = getelementptr inbounds %struct.rq, ptr %72, i32 0, i32 84
  %73 = ptrtoint ptr %core_task_seq57575 to i32
  call void @__asan_load4_noabort(i32 %73)
  %74 = load i32, ptr %core_task_seq57575, align 4
  %inc576 = add i32 %74, 1
  store i32 %inc576, ptr %core_task_seq57575, align 4
  br label %if.end115

if.end55:                                         ; preds = %put_prev_task_balance.exit
  %tobool36.not = icmp eq i32 %61, 0
  %75 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %75)
  %76 = load ptr, ptr %core, align 8
  %core_task_seq57 = getelementptr inbounds %struct.rq, ptr %76, i32 0, i32 84
  %77 = ptrtoint ptr %core_task_seq57 to i32
  call void @__asan_load4_noabort(i32 %77)
  %78 = load i32, ptr %core_task_seq57, align 4
  %inc = add i32 %78, 1
  store i32 %inc, ptr %core_task_seq57, align 4
  br i1 %tobool36.not, label %if.then59, label %if.end115

if.then59:                                        ; preds = %if.end55
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %do.body.i535, label %for.body.i533

for.cond.i530:                                    ; preds = %for.body.i533
  %incdec.ptr.i528 = getelementptr %struct.sched_class, ptr %class.08.i, i32 -1
  %cmp.not.i529 = icmp eq ptr %incdec.ptr.i528, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not.i529, label %do.body.i535, label %for.body.i533

for.body.i533:                                    ; preds = %for.cond.i530, %if.then59
  %class.08.i = phi ptr [ %incdec.ptr.i528, %for.cond.i530 ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %if.then59 ]
  %pick_task.i = getelementptr inbounds %struct.sched_class, ptr %class.08.i, i32 0, i32 11
  %79 = ptrtoint ptr %pick_task.i to i32
  call void @__asan_load4_noabort(i32 %79)
  %80 = load ptr, ptr %pick_task.i, align 4
  %call.i531 = tail call ptr %80(ptr noundef %rq) #33
  %tobool.not.i532 = icmp eq ptr %call.i531, null
  br i1 %tobool.not.i532, label %for.cond.i530, label %pick_task.exit

do.body.i535:                                     ; preds = %for.cond.i530, %if.then59
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 5672, 0\0A.popsection", ""() #33, !srcloc !1342
  unreachable

pick_task.exit:                                   ; preds = %for.body.i533
  %core_cookie61 = getelementptr inbounds %struct.task_struct, ptr %call.i531, i32 0, i32 23
  %81 = ptrtoint ptr %core_cookie61 to i32
  call void @__asan_load4_noabort(i32 %81)
  %82 = load i32, ptr %core_cookie61, align 16
  %tobool62.not = icmp eq i32 %82, 0
  br i1 %tobool62.not, label %if.end106, label %if.end115

if.end106:                                        ; preds = %pick_task.exit
  %core_pick64 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 80
  %83 = ptrtoint ptr %core_pick64 to i32
  call void @__asan_store4_noabort(i32 %83)
  store ptr null, ptr %core_pick64, align 4
  tail call void @task_vruntime_update(ptr noundef %rq, ptr noundef nonnull %call.i531, i1 noundef zeroext false) #33
  br label %done

if.end115:                                        ; preds = %pick_task.exit, %if.end55, %if.end55.thread
  %core_clock_updated.1.off0577 = phi i1 [ true, %if.end55.thread ], [ %cmp, %pick_task.exit ], [ %cmp, %if.end55 ]
  %84 = xor i1 %tobool45.not, true
  %sub = add i32 %19, -1
  %call116 = tail call i32 @cpumask_next_wrap(i32 noundef %sub, ptr noundef %thread_sibling.i, i32 noundef %19, i1 noundef zeroext false) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %85 = load i32, ptr @nr_cpu_ids, align 4
  %cmp117591 = icmp ult i32 %call116, %85
  br i1 %cmp117591, label %do.body118.lr.ph, label %for.end

do.body118.lr.ph:                                 ; preds = %if.end115
  %core_clock_updated.1.off0.not = xor i1 %core_clock_updated.1.off0577, true
  br label %do.body118

do.body118:                                       ; preds = %for.inc, %do.body118.lr.ph
  %max.0593 = phi ptr [ null, %do.body118.lr.ph ], [ %max.1, %for.inc ]
  %i.0592 = phi i32 [ %call116, %do.body118.lr.ph ], [ %call138, %for.inc ]
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %i.0592
  %86 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %86)
  %87 = load i32, ptr %arrayidx, align 4
  %add = add i32 %87, ptrtoint (ptr @runqueues to i32)
  %88 = inttoptr i32 %add to ptr
  %cmp123.not = icmp eq i32 %i.0592, %19
  br i1 %cmp123.not, label %if.end129, label %land.lhs.true124

land.lhs.true124:                                 ; preds = %do.body118
  %89 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %89)
  %90 = load ptr, ptr %core, align 8
  %cmp126.not = icmp ne ptr %90, %88
  %brmerge = select i1 %cmp126.not, i1 true, i1 %core_clock_updated.1.off0.not
  br i1 %brmerge, label %if.then128, label %if.end129

if.then128:                                       ; preds = %land.lhs.true124
  tail call void @update_rq_clock(ptr noundef %88)
  br label %if.end129

if.end129:                                        ; preds = %if.then128, %land.lhs.true124, %do.body118
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %do.body.i545, label %for.body.i543

for.cond.i538:                                    ; preds = %for.body.i543
  %incdec.ptr.i536 = getelementptr %struct.sched_class, ptr %class.08.i539, i32 -1
  %cmp.not.i537 = icmp eq ptr %incdec.ptr.i536, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp.not.i537, label %do.body.i545, label %for.body.i543

for.body.i543:                                    ; preds = %for.cond.i538, %if.end129
  %class.08.i539 = phi ptr [ %incdec.ptr.i536, %for.cond.i538 ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %if.end129 ]
  %pick_task.i540 = getelementptr inbounds %struct.sched_class, ptr %class.08.i539, i32 0, i32 11
  %91 = ptrtoint ptr %pick_task.i540 to i32
  call void @__asan_load4_noabort(i32 %91)
  %92 = load ptr, ptr %pick_task.i540, align 4
  %call.i541 = tail call ptr %92(ptr noundef %88) #33
  %tobool.not.i542 = icmp eq ptr %call.i541, null
  br i1 %tobool.not.i542, label %for.cond.i538, label %pick_task.exit546

do.body.i545:                                     ; preds = %for.cond.i538, %if.end129
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 5672, 0\0A.popsection", ""() #33, !srcloc !1342
  unreachable

pick_task.exit546:                                ; preds = %for.body.i543
  %core_pick131 = getelementptr inbounds %struct.rq, ptr %88, i32 0, i32 80
  %93 = ptrtoint ptr %core_pick131 to i32
  call void @__asan_store4_noabort(i32 %93)
  store ptr %call.i541, ptr %core_pick131, align 4
  %tobool132.not = icmp eq ptr %max.0593, null
  br i1 %tobool132.not, label %if.then136, label %lor.lhs.false133

lor.lhs.false133:                                 ; preds = %pick_task.exit546
  %sched_class.i.i = getelementptr inbounds %struct.task_struct, ptr %max.0593, i32 0, i32 21
  %94 = ptrtoint ptr %sched_class.i.i to i32
  call void @__asan_load4_noabort(i32 %94)
  %95 = load ptr, ptr %sched_class.i.i, align 32
  %cmp.i.i = icmp eq ptr %95, @stop_sched_class
  br i1 %cmp.i.i, label %__task_prio.exit.i, label %if.end.i.i

if.end.i.i:                                       ; preds = %lor.lhs.false133
  %prio.i.i = getelementptr inbounds %struct.task_struct, ptr %max.0593, i32 0, i32 13
  %96 = ptrtoint ptr %prio.i.i to i32
  call void @__asan_load4_noabort(i32 %96)
  %97 = load i32, ptr %prio.i.i, align 8
  %cmp.i.i.i = icmp sgt i32 %97, 99
  br i1 %cmp.i.i.i, label %if.end3.i.i, label %__task_prio.exit.i

if.end3.i.i:                                      ; preds = %if.end.i.i
  %cmp5.i.i = icmp eq ptr %95, @idle_sched_class
  %..i.i = select i1 %cmp5.i.i, i32 140, i32 119
  br label %__task_prio.exit.i

__task_prio.exit.i:                               ; preds = %if.end3.i.i, %if.end.i.i, %lor.lhs.false133
  %retval.0.i.i = phi i32 [ -2, %lor.lhs.false133 ], [ %..i.i, %if.end3.i.i ], [ %97, %if.end.i.i ]
  %sched_class.i27.i = getelementptr inbounds %struct.task_struct, ptr %call.i541, i32 0, i32 21
  %98 = ptrtoint ptr %sched_class.i27.i to i32
  call void @__asan_load4_noabort(i32 %98)
  %99 = load ptr, ptr %sched_class.i27.i, align 32
  %cmp.i28.i = icmp eq ptr %99, @stop_sched_class
  br i1 %cmp.i28.i, label %__task_prio.exit36.i, label %if.end.i31.i

if.end.i31.i:                                     ; preds = %__task_prio.exit.i
  %prio.i29.i = getelementptr inbounds %struct.task_struct, ptr %call.i541, i32 0, i32 13
  %100 = ptrtoint ptr %prio.i29.i to i32
  call void @__asan_load4_noabort(i32 %100)
  %101 = load i32, ptr %prio.i29.i, align 8
  %cmp.i.i30.i = icmp sgt i32 %101, 99
  br i1 %cmp.i.i30.i, label %if.end3.i34.i, label %__task_prio.exit36.i

if.end3.i34.i:                                    ; preds = %if.end.i31.i
  %cmp5.i32.i = icmp eq ptr %99, @idle_sched_class
  %..i33.i = select i1 %cmp5.i32.i, i32 140, i32 119
  br label %__task_prio.exit36.i

__task_prio.exit36.i:                             ; preds = %if.end3.i34.i, %if.end.i31.i, %__task_prio.exit.i
  %retval.0.i35.i = phi i32 [ -2, %__task_prio.exit.i ], [ %..i33.i, %if.end3.i34.i ], [ %101, %if.end.i31.i ]
  %sub.i = sub i32 0, %retval.0.i.i
  %sub2.i = sub i32 0, %retval.0.i35.i
  %cmp.i = icmp slt i32 %sub.i, %sub2.i
  br i1 %cmp.i, label %if.then136, label %if.end.i

if.end.i:                                         ; preds = %__task_prio.exit36.i
  %cmp5.i = icmp slt i32 %sub2.i, %sub.i
  br i1 %cmp5.i, label %for.inc, label %if.end7.i

if.end7.i:                                        ; preds = %if.end.i
  switch i32 %retval.0.i.i, label %for.inc [
    i32 -1, label %if.then9.i
    i32 119, label %prio_less.exit
  ]

if.then9.i:                                       ; preds = %if.end7.i
  %deadline.i = getelementptr inbounds %struct.task_struct, ptr %max.0593, i32 0, i32 20, i32 7
  %102 = ptrtoint ptr %deadline.i to i32
  call void @__asan_load8_noabort(i32 %102)
  %103 = load i64, ptr %deadline.i, align 8
  %deadline11.i = getelementptr inbounds %struct.task_struct, ptr %call.i541, i32 0, i32 20, i32 7
  %104 = ptrtoint ptr %deadline11.i to i32
  call void @__asan_load8_noabort(i32 %104)
  %105 = load i64, ptr %deadline11.i, align 8
  %sub.i.i = sub i64 %103, %105
  %cmp.i37.i = icmp sgt i64 %sub.i.i, -1
  br i1 %cmp.i37.i, label %if.then136, label %for.inc

prio_less.exit:                                   ; preds = %if.end7.i
  %call16.i = tail call zeroext i1 @cfs_prio_less(ptr noundef nonnull %max.0593, ptr noundef nonnull %call.i541, i1 noundef zeroext %84) #33
  br i1 %call16.i, label %if.then136, label %for.inc

if.then136:                                       ; preds = %prio_less.exit, %if.then9.i, %__task_prio.exit36.i, %pick_task.exit546
  br label %for.inc

for.inc:                                          ; preds = %if.then136, %prio_less.exit, %if.then9.i, %if.end7.i, %if.end.i
  %max.1 = phi ptr [ %call.i541, %if.then136 ], [ %max.0593, %prio_less.exit ], [ %max.0593, %if.then9.i ], [ %max.0593, %if.end.i ], [ %max.0593, %if.end7.i ]
  %call138 = tail call i32 @cpumask_next_wrap(i32 noundef %i.0592, ptr noundef %thread_sibling.i, i32 noundef %19, i1 noundef zeroext true) #33
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %106 = load i32, ptr @nr_cpu_ids, align 4
  %cmp117 = icmp ult i32 %call138, %106
  br i1 %cmp117, label %do.body118, label %for.end

for.end:                                          ; preds = %for.inc, %if.end115
  %max.0.lcssa = phi ptr [ null, %if.end115 ], [ %max.1, %for.inc ]
  %core_cookie139 = getelementptr inbounds %struct.task_struct, ptr %max.0.lcssa, i32 0, i32 23
  %107 = ptrtoint ptr %core_cookie139 to i32
  call void @__asan_load4_noabort(i32 %107)
  %108 = load i32, ptr %core_cookie139, align 16
  %109 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %109)
  %110 = load ptr, ptr %core, align 8
  %core_cookie141 = getelementptr inbounds %struct.rq, ptr %110, i32 0, i32 86
  %111 = ptrtoint ptr %core_cookie141 to i32
  call void @__asan_store4_noabort(i32 %111)
  store i32 %108, ptr %core_cookie141, align 4
  %call143594 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %112 = load i32, ptr @nr_cpu_ids, align 4
  %cmp144595 = icmp ult i32 %call143594, %112
  br i1 %cmp144595, label %do.body146.lr.ph, label %for.end183

do.body146.lr.ph:                                 ; preds = %for.end
  %tobool158.not = icmp eq i32 %108, 0
  br label %do.body146

do.body146:                                       ; preds = %if.end182, %do.body146.lr.ph
  %call143597 = phi i32 [ %call143594, %do.body146.lr.ph ], [ %call143, %if.end182 ]
  %occ.0596 = phi i32 [ 0, %do.body146.lr.ph ], [ %occ.1, %if.end182 ]
  %arrayidx153 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call143597
  %113 = ptrtoint ptr %arrayidx153 to i32
  call void @__asan_load4_noabort(i32 %113)
  %114 = load i32, ptr %arrayidx153, align 4
  %add154 = add i32 %114, ptrtoint (ptr @runqueues to i32)
  %115 = inttoptr i32 %add154 to ptr
  %core_pick155 = getelementptr inbounds %struct.rq, ptr %115, i32 0, i32 80
  %116 = ptrtoint ptr %core_pick155 to i32
  call void @__asan_load4_noabort(i32 %116)
  %117 = load ptr, ptr %core_pick155, align 4
  %stack.i.i.i = getelementptr inbounds %struct.task_struct, ptr %117, i32 0, i32 1
  %118 = ptrtoint ptr %stack.i.i.i to i32
  call void @__asan_load4_noabort(i32 %118)
  %119 = load ptr, ptr %stack.i.i.i, align 4
  %cpu.i.i.i = getelementptr inbounds %struct.thread_info, ptr %119, i32 0, i32 3
  %120 = ptrtoint ptr %cpu.i.i.i to i32
  call void @__asan_load4_noabort(i32 %120)
  %121 = load volatile i32, ptr %cpu.i.i.i, align 4
  %arrayidx.i.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %121
  %122 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_load4_noabort(i32 %122)
  %123 = load i32, ptr %arrayidx.i.i, align 4
  %add.i.i = add i32 %123, ptrtoint (ptr @runqueues to i32)
  %124 = inttoptr i32 %add.i.i to ptr
  %idle.i.i = getelementptr inbounds %struct.rq, ptr %124, i32 0, i32 21
  %125 = ptrtoint ptr %idle.i.i to i32
  call void @__asan_load4_noabort(i32 %125)
  %126 = load ptr, ptr %idle.i.i, align 4
  %cmp.i.i548 = icmp eq ptr %126, %117
  br i1 %cmp.i.i548, label %if.end166, label %cookie_equals.exit

cookie_equals.exit:                               ; preds = %do.body146
  %core_cookie.i = getelementptr inbounds %struct.task_struct, ptr %117, i32 0, i32 23
  %127 = ptrtoint ptr %core_cookie.i to i32
  call void @__asan_load4_noabort(i32 %127)
  %128 = load i32, ptr %core_cookie.i, align 16
  %cmp.i549 = icmp eq i32 %128, %108
  br i1 %cmp.i549, label %if.end166, label %if.then157

if.then157:                                       ; preds = %cookie_equals.exit
  br i1 %tobool158.not, label %if.then163, label %if.then159

if.then159:                                       ; preds = %if.then157
  %core_tree.i = getelementptr inbounds %struct.rq, ptr %115, i32 0, i32 83
  %129 = ptrtoint ptr %core_tree.i to i32
  call void @__asan_load4_noabort(i32 %129)
  %node.01.i.i = load ptr, ptr %core_tree.i, align 4
  %tobool.not2.i.i = icmp eq ptr %node.01.i.i, null
  br i1 %tobool.not2.i.i, label %if.then.i552, label %while.body.i.i

while.body.i.i:                                   ; preds = %while.body.i.i, %if.then159
  %node.04.i.i = phi ptr [ %node.0.i.i, %while.body.i.i ], [ %node.01.i.i, %if.then159 ]
  %match.03.i.i = phi ptr [ %match.2.i.i, %while.body.i.i ], [ null, %if.then159 ]
  %core_cookie.i.i.i = getelementptr i8, ptr %node.04.i.i, i32 12
  %130 = ptrtoint ptr %core_cookie.i.i.i to i32
  call void @__asan_load4_noabort(i32 %130)
  %131 = load i32, ptr %core_cookie.i.i.i, align 16
  %cmp.i.i.i550 = icmp ugt i32 %131, %108
  %cmp2.i.i.i = icmp ult i32 %131, %108
  %..i.i.i = zext i1 %cmp2.i.i.i to i32
  %retval.0.i.i.i = select i1 %cmp.i.i.i550, i32 -1, i32 %..i.i.i
  %cmp1.i.i = icmp slt i32 %retval.0.i.i.i, 1
  %tobool2.not.i.i = icmp eq i32 %retval.0.i.i.i, 0
  %rb_left.i.i = getelementptr inbounds %struct.rb_node, ptr %node.04.i.i, i32 0, i32 2
  %rb_right.i.i = getelementptr inbounds %struct.rb_node, ptr %node.04.i.i, i32 0, i32 1
  %node.1.in.i.i = select i1 %cmp1.i.i, ptr %rb_left.i.i, ptr %rb_right.i.i
  %match.2.i.i = select i1 %tobool2.not.i.i, ptr %node.04.i.i, ptr %match.03.i.i
  %132 = ptrtoint ptr %node.1.in.i.i to i32
  call void @__asan_load4_noabort(i32 %132)
  %node.0.i.i = load ptr, ptr %node.1.in.i.i, align 4
  %tobool.not.i.i = icmp eq ptr %node.0.i.i, null
  br i1 %tobool.not.i.i, label %rb_find_first.exit.i, label %while.body.i.i

rb_find_first.exit.i:                             ; preds = %while.body.i.i
  %tobool.not.i551 = icmp eq ptr %match.2.i.i, null
  br i1 %tobool.not.i551, label %if.then.i552, label %if.end.i553

if.then.i552:                                     ; preds = %rb_find_first.exit.i, %if.then159
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11) to i32))
  %133 = load ptr, ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11), align 4
  %call1.i = tail call ptr %133(ptr noundef %115) #33
  br label %if.end161

if.end.i553:                                      ; preds = %rb_find_first.exit.i
  %add.ptr.i = getelementptr i8, ptr %match.2.i.i, i32 -612
  br label %if.end161

if.end161:                                        ; preds = %if.end.i553, %if.then.i552
  %p.0 = phi ptr [ %add.ptr.i, %if.end.i553 ], [ %call1.i, %if.then.i552 ]
  %tobool162.not = icmp eq ptr %p.0, null
  br i1 %tobool162.not, label %if.then163, label %if.end166

if.then163:                                       ; preds = %if.end161, %if.then157
  call void @__asan_load4_noabort(i32 ptrtoint (ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11) to i32))
  %134 = load ptr, ptr getelementptr inbounds (%struct.sched_class, ptr @idle_sched_class, i32 0, i32 11), align 4
  %call164 = tail call ptr %134(ptr noundef %115) #33
  br label %if.end166

if.end166:                                        ; preds = %if.then163, %if.end161, %cookie_equals.exit, %do.body146
  %p.1 = phi ptr [ %117, %cookie_equals.exit ], [ %p.0, %if.end161 ], [ %call164, %if.then163 ], [ %117, %do.body146 ]
  %135 = ptrtoint ptr %core_pick155 to i32
  call void @__asan_store4_noabort(i32 %135)
  store ptr %p.1, ptr %core_pick155, align 4
  %idle = getelementptr inbounds %struct.rq, ptr %115, i32 0, i32 21
  %136 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %136)
  %137 = load ptr, ptr %idle, align 4
  %cmp168 = icmp eq ptr %p.1, %137
  br i1 %cmp168, label %if.then169, label %if.else

if.then169:                                       ; preds = %if.end166
  %nr_running = getelementptr inbounds %struct.rq, ptr %115, i32 0, i32 1
  %138 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %138)
  %139 = load i32, ptr %nr_running, align 4
  %tobool170.not = icmp eq i32 %139, 0
  br i1 %tobool170.not, label %if.end182, label %if.then171

if.then171:                                       ; preds = %if.then169
  %140 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %140)
  %141 = load ptr, ptr %core, align 8
  %core_forceidle_count173 = getelementptr inbounds %struct.rq, ptr %141, i32 0, i32 87
  %142 = ptrtoint ptr %core_forceidle_count173 to i32
  call void @__asan_load4_noabort(i32 %142)
  %143 = load i32, ptr %core_forceidle_count173, align 8
  %inc174 = add i32 %143, 1
  store i32 %inc174, ptr %core_forceidle_count173, align 8
  br i1 %tobool45.not, label %if.then176, label %if.end182

if.then176:                                       ; preds = %if.then171
  %144 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %144)
  %145 = load ptr, ptr %core, align 8
  %core_forceidle_seq = getelementptr inbounds %struct.rq, ptr %145, i32 0, i32 88
  %146 = ptrtoint ptr %core_forceidle_seq to i32
  call void @__asan_load4_noabort(i32 %146)
  %147 = load i32, ptr %core_forceidle_seq, align 4
  %inc178 = add i32 %147, 1
  store i32 %inc178, ptr %core_forceidle_seq, align 4
  br label %if.end182

if.else:                                          ; preds = %if.end166
  %inc181 = add i32 %occ.0596, 1
  br label %if.end182

if.end182:                                        ; preds = %if.else, %if.then176, %if.then171, %if.then169
  %occ.1 = phi i32 [ %occ.0596, %if.then171 ], [ %occ.0596, %if.then176 ], [ %occ.0596, %if.then169 ], [ %inc181, %if.else ]
  %call143 = tail call i32 @cpumask_next(i32 noundef %call143597, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %148 = load i32, ptr @nr_cpu_ids, align 4
  %cmp144 = icmp ult i32 %call143, %148
  br i1 %cmp144, label %do.body146, label %for.end183

for.end183:                                       ; preds = %if.end182, %for.end
  %occ.0.lcssa = phi i32 [ 0, %for.end ], [ %occ.1, %if.end182 ]
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@pick_next_task, %land.lhs.true194)) #33
          to label %if.end205 [label %land.lhs.true194], !srcloc !1202

land.lhs.true194:                                 ; preds = %for.end183
  %149 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %149)
  %150 = load ptr, ptr %core, align 8
  %core_forceidle_count196 = getelementptr inbounds %struct.rq, ptr %150, i32 0, i32 87
  %151 = ptrtoint ptr %core_forceidle_count196 to i32
  call void @__asan_load4_noabort(i32 %151)
  %152 = load i32, ptr %core_forceidle_count196, align 8
  %tobool197.not = icmp eq i32 %152, 0
  br i1 %tobool197.not, label %if.end205, label %if.then198

if.then198:                                       ; preds = %land.lhs.true194
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %153 = load i32, ptr @debug_locks, align 4
  %tobool.not.i.i555 = icmp eq i32 %153, 0
  br i1 %tobool.not.i.i555, label %lockdep_assert_rq_held.exit.i, label %land.rhs.i.i556

land.rhs.i.i556:                                  ; preds = %if.then198
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %150, i32 0, i32 81
  %154 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %154)
  %155 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %155, 0
  br i1 %tobool.not.i.i.i, label %__rq_lockp.exit.i.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %land.rhs.i.i556
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %150, i32 0, i32 79
  %156 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %156)
  %157 = load ptr, ptr %core.i.i.i, align 8
  br label %__rq_lockp.exit.i.i

__rq_lockp.exit.i.i:                              ; preds = %if.then.i.i.i, %land.rhs.i.i556
  %retval.0.i.i.i557 = phi ptr [ %157, %if.then.i.i.i ], [ %150, %land.rhs.i.i556 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i557, i32 0, i32 4
  %call.i.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i.i, i32 noundef -1) #33
  %cmp.not.i.i558 = icmp eq i32 %call.i.i.i, 0
  br i1 %cmp.not.i.i558, label %do.end.i.i, label %lockdep_assert_rq_held.exit.i, !prof !1192

do.end.i.i:                                       ; preds = %__rq_lockp.exit.i.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit.i

lockdep_assert_rq_held.exit.i:                    ; preds = %do.end.i.i, %__rq_lockp.exit.i.i, %if.then198
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %150, i32 0, i32 25
  %158 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %158)
  %159 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i559 = icmp ult i32 %159, 2
  br i1 %cmp.i.i559, label %land.rhs.i3.i, label %rq_clock.exit

land.rhs.i3.i:                                    ; preds = %lockdep_assert_rq_held.exit.i
  %.b37.i.i = load i1, ptr @assert_clock_updated.__already_done, align 1
  br i1 %.b37.i.i, label %rq_clock.exit, label %if.then.i.i560, !prof !1191

if.then.i.i560:                                   ; preds = %land.rhs.i3.i
  store i1 true, ptr @assert_clock_updated.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1459, i32 noundef 9, ptr noundef nonnull @.str.179) #33
  br label %rq_clock.exit

rq_clock.exit:                                    ; preds = %if.then.i.i560, %land.rhs.i3.i, %lockdep_assert_rq_held.exit.i
  %clock.i = getelementptr inbounds %struct.rq, ptr %150, i32 0, i32 26
  %160 = ptrtoint ptr %clock.i to i32
  call void @__asan_load8_noabort(i32 %160)
  %161 = load i64, ptr %clock.i, align 32
  %162 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %162)
  %163 = load ptr, ptr %core, align 8
  %core_forceidle_start202 = getelementptr inbounds %struct.rq, ptr %163, i32 0, i32 90
  %164 = ptrtoint ptr %core_forceidle_start202 to i32
  call void @__asan_store8_noabort(i32 %164)
  store i64 %161, ptr %core_forceidle_start202, align 8
  %165 = load ptr, ptr %core, align 8
  %core_forceidle_occupation204 = getelementptr inbounds %struct.rq, ptr %165, i32 0, i32 89
  %166 = ptrtoint ptr %core_forceidle_occupation204 to i32
  call void @__asan_store4_noabort(i32 %166)
  store i32 %occ.0.lcssa, ptr %core_forceidle_occupation204, align 32
  br label %if.end205

if.end205:                                        ; preds = %rq_clock.exit, %land.lhs.true194, %for.end183
  %167 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %167)
  %168 = load ptr, ptr %core, align 8
  %core_task_seq207 = getelementptr inbounds %struct.rq, ptr %168, i32 0, i32 84
  %169 = ptrtoint ptr %core_task_seq207 to i32
  call void @__asan_load4_noabort(i32 %169)
  %170 = load i32, ptr %core_task_seq207, align 4
  %core_pick_seq209 = getelementptr inbounds %struct.rq, ptr %168, i32 0, i32 85
  %171 = ptrtoint ptr %core_pick_seq209 to i32
  call void @__asan_store4_noabort(i32 %171)
  store i32 %170, ptr %core_pick_seq209, align 16
  %core_pick210 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 80
  %172 = ptrtoint ptr %core_pick210 to i32
  call void @__asan_load4_noabort(i32 %172)
  %173 = load ptr, ptr %core_pick210, align 4
  %174 = load ptr, ptr %core, align 8
  %core_pick_seq212 = getelementptr inbounds %struct.rq, ptr %174, i32 0, i32 85
  %175 = ptrtoint ptr %core_pick_seq212 to i32
  call void @__asan_load4_noabort(i32 %175)
  %176 = load i32, ptr %core_pick_seq212, align 16
  %core_sched_seq213 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 82
  %177 = ptrtoint ptr %core_sched_seq213 to i32
  call void @__asan_store4_noabort(i32 %177)
  store i32 %176, ptr %core_sched_seq213, align 4
  %tobool215.not = icmp eq ptr %173, null
  br i1 %tobool215.not, label %land.rhs224, label %if.end262

land.rhs224:                                      ; preds = %if.end205
  %.b502507 = load i1, ptr @pick_next_task.__already_done.211, align 1
  br i1 %.b502507, label %if.end262, label %if.then235, !prof !1191

if.then235:                                       ; preds = %land.rhs224
  store i1 true, ptr @pick_next_task.__already_done.211, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 5843, i32 noundef 9, ptr noundef null) #33
  br label %if.end262

if.end262:                                        ; preds = %if.then235, %land.rhs224, %if.end205
  %call271599 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %178 = load i32, ptr @nr_cpu_ids, align 4
  %cmp272600 = icmp ult i32 %call271599, %178
  br i1 %cmp272600, label %do.body274.lr.ph, label %done

do.body274.lr.ph:                                 ; preds = %if.end262
  %stack.i.i.i561 = getelementptr inbounds %struct.task_struct, ptr %173, i32 0, i32 1
  %core_cookie.i567 = getelementptr inbounds %struct.task_struct, ptr %173, i32 0, i32 23
  br label %do.body274

do.body274:                                       ; preds = %for.cond270.backedge, %do.body274.lr.ph
  %call271601 = phi i32 [ %call271599, %do.body274.lr.ph ], [ %call271, %for.cond270.backedge ]
  %arrayidx281 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %call271601
  %179 = ptrtoint ptr %arrayidx281 to i32
  call void @__asan_load4_noabort(i32 %179)
  %180 = load i32, ptr %arrayidx281, align 4
  %add282 = add i32 %180, ptrtoint (ptr @runqueues to i32)
  %181 = inttoptr i32 %add282 to ptr
  %core_pick283 = getelementptr inbounds %struct.rq, ptr %181, i32 0, i32 80
  %182 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_load4_noabort(i32 %182)
  %183 = load ptr, ptr %core_pick283, align 4
  %tobool284.not = icmp eq ptr %183, null
  br i1 %tobool284.not, label %for.cond270.backedge, label %if.end286

if.end286:                                        ; preds = %do.body274
  br i1 %tobool45.not, label %if.then292, label %land.lhs.true288

land.lhs.true288:                                 ; preds = %if.end286
  %184 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %184)
  %185 = load ptr, ptr %core, align 8
  %core_forceidle_count290 = getelementptr inbounds %struct.rq, ptr %185, i32 0, i32 87
  %186 = ptrtoint ptr %core_forceidle_count290 to i32
  call void @__asan_load4_noabort(i32 %186)
  %187 = load i32, ptr %core_forceidle_count290, align 8
  %tobool291.not = icmp eq i32 %187, 0
  br i1 %tobool291.not, label %if.then292, label %if.end301

if.then292:                                       ; preds = %land.lhs.true288, %if.end286
  %188 = ptrtoint ptr %core to i32
  call void @__asan_load4_noabort(i32 %188)
  %189 = load ptr, ptr %core, align 8
  %core_forceidle_count295 = getelementptr inbounds %struct.rq, ptr %189, i32 0, i32 87
  %190 = ptrtoint ptr %core_forceidle_count295 to i32
  call void @__asan_load4_noabort(i32 %190)
  %191 = load i32, ptr %core_forceidle_count295, align 8
  %tobool296 = icmp ne i32 %191, 0
  tail call void @task_vruntime_update(ptr noundef %181, ptr noundef nonnull %183, i1 noundef zeroext %tobool296) #33
  br label %if.end301

if.end301:                                        ; preds = %if.then292, %land.lhs.true288
  %192 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_load4_noabort(i32 %192)
  %193 = load ptr, ptr %core_pick283, align 4
  %core_occupation = getelementptr inbounds %struct.task_struct, ptr %193, i32 0, i32 24
  %194 = ptrtoint ptr %core_occupation to i32
  call void @__asan_store4_noabort(i32 %194)
  store i32 %occ.0.lcssa, ptr %core_occupation, align 4
  %cmp303 = icmp eq i32 %call271601, %19
  br i1 %cmp303, label %if.then304, label %if.end306

if.then304:                                       ; preds = %if.end301
  %195 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_store4_noabort(i32 %195)
  store ptr null, ptr %core_pick283, align 4
  br label %for.cond270.backedge

for.cond270.backedge:                             ; preds = %if.end368, %if.then366, %if.then304, %do.body274
  %call271 = tail call i32 @cpumask_next(i32 noundef %call271601, ptr noundef %thread_sibling.i) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %196 = load i32, ptr @nr_cpu_ids, align 4
  %cmp272 = icmp ult i32 %call271, %196
  br i1 %cmp272, label %do.body274, label %done

if.end306:                                        ; preds = %if.end301
  %197 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_load4_noabort(i32 %197)
  %198 = load ptr, ptr %core_pick283, align 4
  %199 = ptrtoint ptr %stack.i.i.i561 to i32
  call void @__asan_load4_noabort(i32 %199)
  %200 = load ptr, ptr %stack.i.i.i561, align 4
  %cpu.i.i.i562 = getelementptr inbounds %struct.thread_info, ptr %200, i32 0, i32 3
  %201 = ptrtoint ptr %cpu.i.i.i562 to i32
  call void @__asan_load4_noabort(i32 %201)
  %202 = load volatile i32, ptr %cpu.i.i.i562, align 4
  %arrayidx.i.i563 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %202
  %203 = ptrtoint ptr %arrayidx.i.i563 to i32
  call void @__asan_load4_noabort(i32 %203)
  %204 = load i32, ptr %arrayidx.i.i563, align 4
  %add.i.i564 = add i32 %204, ptrtoint (ptr @runqueues to i32)
  %205 = inttoptr i32 %add.i.i564 to ptr
  %idle.i.i565 = getelementptr inbounds %struct.rq, ptr %205, i32 0, i32 21
  %206 = ptrtoint ptr %idle.i.i565 to i32
  call void @__asan_load4_noabort(i32 %206)
  %207 = load ptr, ptr %idle.i.i565, align 4
  %cmp.i.i566 = icmp eq ptr %207, %173
  br i1 %cmp.i.i566, label %if.end356, label %lor.lhs.false.i

lor.lhs.false.i:                                  ; preds = %if.end306
  %stack.i.i5.i = getelementptr inbounds %struct.task_struct, ptr %198, i32 0, i32 1
  %208 = ptrtoint ptr %stack.i.i5.i to i32
  call void @__asan_load4_noabort(i32 %208)
  %209 = load ptr, ptr %stack.i.i5.i, align 4
  %cpu.i.i6.i = getelementptr inbounds %struct.thread_info, ptr %209, i32 0, i32 3
  %210 = ptrtoint ptr %cpu.i.i6.i to i32
  call void @__asan_load4_noabort(i32 %210)
  %211 = load volatile i32, ptr %cpu.i.i6.i, align 4
  %arrayidx.i7.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %211
  %212 = ptrtoint ptr %arrayidx.i7.i to i32
  call void @__asan_load4_noabort(i32 %212)
  %213 = load i32, ptr %arrayidx.i7.i, align 4
  %add.i8.i = add i32 %213, ptrtoint (ptr @runqueues to i32)
  %214 = inttoptr i32 %add.i8.i to ptr
  %idle.i9.i = getelementptr inbounds %struct.rq, ptr %214, i32 0, i32 21
  %215 = ptrtoint ptr %idle.i9.i to i32
  call void @__asan_load4_noabort(i32 %215)
  %216 = load ptr, ptr %idle.i9.i, align 4
  %cmp.i10.i = icmp eq ptr %216, %198
  br i1 %cmp.i10.i, label %if.end356, label %cookie_match.exit

cookie_match.exit:                                ; preds = %lor.lhs.false.i
  %217 = ptrtoint ptr %core_cookie.i567 to i32
  call void @__asan_load4_noabort(i32 %217)
  %218 = load i32, ptr %core_cookie.i567, align 16
  %core_cookie2.i = getelementptr inbounds %struct.task_struct, ptr %198, i32 0, i32 23
  %219 = ptrtoint ptr %core_cookie2.i to i32
  call void @__asan_load4_noabort(i32 %219)
  %220 = load i32, ptr %core_cookie2.i, align 16
  %cmp.i568 = icmp eq i32 %218, %220
  br i1 %cmp.i568, label %if.end356, label %land.rhs318

land.rhs318:                                      ; preds = %cookie_match.exit
  %.b503506 = load i1, ptr @pick_next_task.__already_done.212, align 1
  br i1 %.b503506, label %if.end356, label %if.then329, !prof !1191

if.then329:                                       ; preds = %land.rhs318
  store i1 true, ptr @pick_next_task.__already_done.212, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 5885, i32 noundef 9, ptr noundef null) #33
  br label %if.end356

if.end356:                                        ; preds = %if.then329, %land.rhs318, %cookie_match.exit, %lor.lhs.false.i, %if.end306
  %curr = getelementptr inbounds %struct.rq, ptr %181, i32 0, i32 20
  %221 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %221)
  %222 = load ptr, ptr %curr, align 8
  %223 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_load4_noabort(i32 %223)
  %224 = load ptr, ptr %core_pick283, align 4
  %cmp365 = icmp eq ptr %222, %224
  br i1 %cmp365, label %if.then366, label %if.end368

if.then366:                                       ; preds = %if.end356
  %225 = ptrtoint ptr %core_pick283 to i32
  call void @__asan_store4_noabort(i32 %225)
  store ptr null, ptr %core_pick283, align 4
  br label %for.cond270.backedge

if.end368:                                        ; preds = %if.end356
  tail call void @resched_curr(ptr noundef %181)
  br label %for.cond270.backedge

done:                                             ; preds = %for.cond270.backedge, %if.end262, %if.end106
  %next.0 = phi ptr [ %call.i531, %if.end106 ], [ %173, %if.end262 ], [ %173, %for.cond270.backedge ]
  %sched_class.i571 = getelementptr inbounds %struct.task_struct, ptr %next.0, i32 0, i32 21
  %226 = ptrtoint ptr %sched_class.i571 to i32
  call void @__asan_load4_noabort(i32 %226)
  %227 = load ptr, ptr %sched_class.i571, align 32
  %set_next_task.i572 = getelementptr inbounds %struct.sched_class, ptr %227, i32 0, i32 8
  %228 = ptrtoint ptr %set_next_task.i572 to i32
  call void @__asan_load4_noabort(i32 %228)
  %229 = load ptr, ptr %set_next_task.i572, align 4
  tail call void %229(ptr noundef %rq, ptr noundef %next.0, i1 noundef zeroext false) #33
  br label %cleanup

cleanup:                                          ; preds = %done, %if.end31, %if.then6, %for.body.i, %put_prev_task.exit.i, %if.then.i
  %retval.0 = phi ptr [ %call7, %if.then6 ], [ %35, %if.end31 ], [ %next.0, %done ], [ %call13.i, %put_prev_task.exit.i ], [ %call.i, %if.then.i ], [ %call17.i, %for.body.i ]
  ret ptr %retval.0
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @trace_sched_switch(i1 noundef zeroext %preempt, ptr noundef %prev, ptr noundef %next) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_switch, i32 0, i32 1, i32 0, i32 0), ptr blockaddress(@trace_sched_switch, %do.body)) #33
          to label %if.end49 [label %do.body], !srcloc !1202

do.body:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %4 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i = icmp ugt i32 %4, %3
  br i1 %cmp.not.i.i.i.i, label %cpu_online.exit, label %land.rhs.i.i.i.i

land.rhs.i.i.i.i:                                 ; preds = %do.body
  %.b37.i.i.i.i = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i, label %cpu_online.exit, label %if.then.i.i.i.i, !prof !1191

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit

cpu_online.exit:                                  ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i, %do.body
  %div3.i.i.i = lshr i32 %3, 5
  %arrayidx.i.i.i = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i
  %5 = ptrtoint ptr %arrayidx.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %arrayidx.i.i.i, align 4
  %and.i.i.i76 = and i32 %3, 31
  %7 = shl nuw i32 1, %and.i.i.i76
  %8 = and i32 %6, %7
  %tobool.i.not = icmp eq i32 %8, 0
  br i1 %tobool.i.not, label %if.end70, label %if.end31

if.end31:                                         ; preds = %cpu_online.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 1
  %11 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %12, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1343
  %13 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_switch, i32 0, i32 7), align 4
  %tobool.not.i = icmp eq ptr %13, null
  br i1 %tobool.not.i, label %if.end49.critedge, label %do.body2.i

do.body2.i:                                       ; preds = %do.body2.i, %if.end31
  %it_func_ptr.0.i = phi ptr [ %incdec.ptr.i, %do.body2.i ], [ %13, %if.end31 ]
  %14 = ptrtoint ptr %it_func_ptr.0.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile ptr, ptr %it_func_ptr.0.i, align 4
  %data.i = getelementptr inbounds %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 0, i32 1
  %16 = ptrtoint ptr %data.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load ptr, ptr %data.i, align 4
  tail call void %15(ptr noundef %17, i1 noundef zeroext %preempt, ptr noundef %prev, ptr noundef %next) #33
  %incdec.ptr.i = getelementptr %struct.tracepoint_func, ptr %it_func_ptr.0.i, i32 1
  %18 = ptrtoint ptr %incdec.ptr.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %incdec.ptr.i, align 4
  %tobool10.not.i = icmp eq ptr %19, null
  br i1 %tobool10.not.i, label %cleanup, label %do.body2.i

cleanup:                                          ; preds = %do.body2.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1344
  br label %if.end49.sink.split

if.end49.critedge:                                ; preds = %if.end31
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1344
  br label %if.end49.sink.split

if.end49.sink.split:                              ; preds = %if.end49.critedge, %cleanup
  %20 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i74.c = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i74.c to ptr
  %preempt_count.i.i75.c = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i75.c to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i75.c, align 4
  %sub.i = add i32 %23, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i75.c, align 4
  br label %if.end49

if.end49:                                         ; preds = %if.end49.sink.split, %entry
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i77 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i77 to ptr
  %cpu51 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu51 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu51, align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %28 = load i32, ptr @nr_cpu_ids, align 4
  %cmp.not.i.i.i.i78 = icmp ugt i32 %28, %27
  br i1 %cmp.not.i.i.i.i78, label %cpu_online.exit86, label %land.rhs.i.i.i.i80

land.rhs.i.i.i.i80:                               ; preds = %if.end49
  %.b37.i.i.i.i79 = load i1, ptr @cpu_max_bits_warn.__already_done, align 1
  br i1 %.b37.i.i.i.i79, label %cpu_online.exit86, label %if.then.i.i.i.i81, !prof !1191

if.then.i.i.i.i81:                                ; preds = %land.rhs.i.i.i.i80
  store i1 true, ptr @cpu_max_bits_warn.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.233, i32 noundef 108, i32 noundef 9, ptr noundef null) #33
  br label %cpu_online.exit86

cpu_online.exit86:                                ; preds = %if.then.i.i.i.i81, %land.rhs.i.i.i.i80, %if.end49
  %div3.i.i.i82 = lshr i32 %27, 5
  %arrayidx.i.i.i83 = getelementptr i32, ptr @__cpu_online_mask, i32 %div3.i.i.i82
  %29 = ptrtoint ptr %arrayidx.i.i.i83 to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %arrayidx.i.i.i83, align 4
  %and.i.i.i84 = and i32 %27, 31
  %31 = shl nuw i32 1, %and.i.i.i84
  %32 = and i32 %30, %31
  %tobool.i85.not = icmp eq i32 %32, 0
  br i1 %tobool.i85.not, label %if.end70, label %if.then53

if.then53:                                        ; preds = %cpu_online.exit86
  %33 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i = and i32 %33, -16384
  %34 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %34, i32 0, i32 1
  %35 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %36, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1241
  %37 = load volatile ptr, ptr getelementptr inbounds ({ ptr, { %struct.atomic_t, { ptr } }, ptr, ptr, ptr, ptr, ptr, ptr }, ptr @__tracepoint_sched_switch, i32 0, i32 7), align 4
  %call59 = tail call i32 @rcu_read_lock_sched_held() #33
  %tobool60.not = icmp eq i32 %call59, 0
  br i1 %tobool60.not, label %land.lhs.true, label %do.end68

land.lhs.true:                                    ; preds = %if.then53
  %call61 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool62.not = icmp eq i32 %call61, 0
  br i1 %tobool62.not, label %do.end68, label %land.lhs.true63

land.lhs.true63:                                  ; preds = %land.lhs.true
  %.b73 = load i1, ptr @trace_sched_switch.__warned, align 1
  br i1 %.b73, label %do.end68, label %if.then65

if.then65:                                        ; preds = %land.lhs.true63
  store i1 true, ptr @trace_sched_switch.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.180, i32 noundef 266, ptr noundef nonnull @.str.3) #33
  br label %do.end68

do.end68:                                         ; preds = %if.then65, %land.lhs.true63, %land.lhs.true, %if.then53
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1242
  %38 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i87 = and i32 %38, -16384
  %39 = inttoptr i32 %and.i.i.i.i87 to ptr
  %preempt_count.i.i.i88 = getelementptr inbounds %struct.thread_info, ptr %39, i32 0, i32 1
  %40 = ptrtoint ptr %preempt_count.i.i.i88 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load volatile i32, ptr %preempt_count.i.i.i88, align 4
  %sub.i.i = add i32 %41, -1
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i88, align 4
  br label %if.end70

if.end70:                                         ; preds = %do.end68, %cpu_online.exit86, %cpu_online.exit
  ret void
}

; Function Attrs: cold noreturn null_pointer_is_valid
declare dso_local void @panic(ptr noundef, ...) local_unnamed_addr #26

; Function Attrs: noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @__schedule_bug(ptr noundef %prev) unnamed_addr #27 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %0 = load i32, ptr @oops_in_progress, align 4
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %do.end, label %cleanup

do.end:                                           ; preds = %entry
  %comm = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 101
  %pid = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 68
  %1 = ptrtoint ptr %pid to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %pid, align 8
  %3 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %3, -16384
  %4 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %4, i32 0, i32 1
  %5 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load volatile i32, ptr %preempt_count.i, align 4
  %call3 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.208, ptr noundef %comm, i32 noundef %2, i32 noundef %6) #39
  tail call void @debug_show_held_locks(ptr noundef %prev) #33
  tail call void @print_modules() #33
  %7 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i = and i32 %7, 128
  %tobool17.not = icmp eq i32 %and.i, 0
  br i1 %tobool17.not, label %if.end19, label %if.then18

if.then18:                                        ; preds = %do.end
  tail call void @print_irqtrace_events(ptr noundef %prev) #33
  br label %if.end19

if.end19:                                         ; preds = %if.then18, %do.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @panic_on_warn to i32))
  %8 = load i32, ptr @panic_on_warn, align 4
  %tobool20.not = icmp eq i32 %8, 0
  br i1 %tobool20.not, label %if.end22, label %if.then21

if.then21:                                        ; preds = %if.end19
  call void @__asan_handle_no_return()
  tail call void (ptr, ...) @panic(ptr noundef nonnull @.str.210) #42
  unreachable

if.end22:                                         ; preds = %if.end19
  tail call void @dump_stack() #39
  tail call void @add_taint(i32 noundef 9, i32 noundef 0) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end22, %entry
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @print_modules() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @profile_hits(i32 noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__delayacct_blkio_start() local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc ptr @__pick_next_task(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) unnamed_addr #3 align 64 {
entry:
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %0 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %sched_class, align 32
  %cmp.not = icmp ugt ptr %1, @fair_sched_class
  br i1 %cmp.not, label %restart, label %land.rhs, !prof !1192

land.rhs:                                         ; preds = %entry
  %nr_running = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 1
  %2 = ptrtoint ptr %nr_running to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %nr_running, align 4
  %h_nr_running = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 14, i32 2
  %4 = ptrtoint ptr %h_nr_running to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %h_nr_running, align 4
  %cmp1 = icmp eq i32 %3, %5
  br i1 %cmp1, label %if.then, label %restart, !prof !1191

if.then:                                          ; preds = %land.rhs
  %call = tail call ptr @pick_next_task_fair(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) #33
  %magicptr = ptrtoint ptr %call to i32
  switch i32 %magicptr, label %cleanup [
    i32 -1, label %restart
    i32 0, label %if.then12
  ], !prof !1340

if.then12:                                        ; preds = %if.then
  %curr.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %6 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %curr.i, align 8
  %cmp.not.i = icmp eq ptr %7, %prev
  br i1 %cmp.not.i, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %if.then12
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i, %land.rhs.i, %if.then12
  %8 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %sched_class, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %9, i32 0, i32 7
  %10 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %11(ptr noundef %rq, ptr noundef %prev) #33
  %call13 = tail call ptr @pick_next_task_idle(ptr noundef %rq) #33
  br label %cleanup

restart:                                          ; preds = %if.then, %land.rhs, %entry
  tail call fastcc void @put_prev_task_balance(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf)
  br i1 icmp eq (ptr getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), ptr getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)), label %do.body, label %for.body

for.cond:                                         ; preds = %for.body
  %incdec.ptr = getelementptr %struct.sched_class, ptr %class.041, i32 -1
  %cmp16.not = icmp eq ptr %incdec.ptr, getelementptr ([0 x %struct.sched_class], ptr @__begin_sched_classes, i32 0, i32 -1)
  br i1 %cmp16.not, label %do.body, label %for.body

for.body:                                         ; preds = %for.cond, %restart
  %class.041 = phi ptr [ %incdec.ptr, %for.cond ], [ getelementptr ([0 x %struct.sched_class], ptr @__end_sched_classes, i32 0, i32 -1), %restart ]
  %pick_next_task = getelementptr inbounds %struct.sched_class, ptr %class.041, i32 0, i32 6
  %12 = ptrtoint ptr %pick_next_task to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %pick_next_task, align 4
  %call17 = tail call ptr %13(ptr noundef %rq) #33
  %tobool18.not = icmp eq ptr %call17, null
  br i1 %tobool18.not, label %for.cond, label %cleanup

do.body:                                          ; preds = %for.cond, %restart
  tail call void asm sideeffect "1:\09.long ( (((0xe7f001f2) << 24) & 0xFF000000) | (((0xe7f001f2) << 8) & 0x00FF0000) | (((0xe7f001f2) >> 8) & 0x0000FF00) | (((0xe7f001f2) >> 24) & 0x000000FF) )\0A\09\0A.pushsection .rodata.str, \22aMS\22, %progbits, 1\0A2:\09.asciz \22kernel/sched/core.c\22\0A.popsection\0A.pushsection __bug_table,\22aw\22\0A.align 2\0A3:\09.word 1b, 2b\0A\09.hword 5639, 0\0A.popsection", ""() #33, !srcloc !1341
  unreachable

cleanup:                                          ; preds = %for.body, %put_prev_task.exit, %if.then
  %retval.0 = phi ptr [ %call13, %put_prev_task.exit ], [ %call, %if.then ], [ %call17, %for.body ]
  ret ptr %retval.0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @put_prev_task_balance(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 21
  %0 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %sched_class, align 32
  %cmp.not6 = icmp eq ptr %1, @idle_sched_class
  br i1 %cmp.not6, label %for.end, label %for.body

for.body:                                         ; preds = %for.body, %entry
  %class.07 = phi ptr [ %incdec.ptr, %for.body ], [ %1, %entry ]
  %balance = getelementptr inbounds %struct.sched_class, ptr %class.07, i32 0, i32 9
  %2 = ptrtoint ptr %balance to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %balance, align 4
  %call = tail call i32 %3(ptr noundef %rq, ptr noundef %prev, ptr noundef %rf) #33
  %tobool.not = icmp ne i32 %call, 0
  %incdec.ptr = getelementptr %struct.sched_class, ptr %class.07, i32 -1
  %cmp.not = icmp eq ptr %incdec.ptr, @idle_sched_class
  %or.cond = select i1 %tobool.not, i1 true, i1 %cmp.not
  br i1 %or.cond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body, %entry
  %curr.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 20
  %4 = ptrtoint ptr %curr.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %curr.i, align 8
  %cmp.not.i = icmp eq ptr %5, %prev
  br i1 %cmp.not.i, label %put_prev_task.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %for.end
  %.b40.i = load i1, ptr @put_prev_task.__already_done, align 1
  br i1 %.b40.i, label %put_prev_task.exit, label %if.then.i, !prof !1191

if.then.i:                                        ; preds = %land.rhs.i
  store i1 true, ptr @put_prev_task.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 2190, i32 noundef 9, ptr noundef null) #33
  br label %put_prev_task.exit

put_prev_task.exit:                               ; preds = %if.then.i, %land.rhs.i, %for.end
  %6 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %sched_class, align 32
  %put_prev_task.i = getelementptr inbounds %struct.sched_class, ptr %7, i32 0, i32 7
  %8 = ptrtoint ptr %put_prev_task.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %put_prev_task.i, align 4
  tail call void %9(ptr noundef %rq, ptr noundef %prev) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @task_vruntime_update(ptr noundef, ptr noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @pick_next_task_fair(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @pick_next_task_idle(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__sched_core_account_forceidle(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @_clear_bit(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @psi_task_switch(ptr noundef, ptr noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @prepare_lock_switch(ptr noundef %rq, ptr noundef %next, ptr nocapture noundef %rf) #3 align 64 {
entry:
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %0 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %clock_update_flags.i, align 4
  %cmp.i = icmp ugt i32 %1, 2
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %clock_update_flags1.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %2 = ptrtoint ptr %clock_update_flags1.i to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 4, ptr %clock_update_flags1.i, align 4
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %3 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %4, 0
  br i1 %tobool.not.i.i, label %rq_unpin_lock.exit, label %if.then.i.i

if.then.i.i:                                      ; preds = %if.end.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %5 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %core.i.i, align 8
  br label %rq_unpin_lock.exit

rq_unpin_lock.exit:                               ; preds = %if.then.i.i, %if.end.i
  %retval.0.i.i = phi ptr [ %6, %if.then.i.i ], [ %rq, %if.end.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %7 = ptrtoint ptr %cookie.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %.unpack.i = load i32, ptr %cookie.i, align 4
  %8 = insertvalue [1 x i32] undef, i32 %.unpack.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i, [1 x i32] %8) #33
  %9 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i, label %__here, label %if.then.i4

if.then.i4:                                       ; preds = %rq_unpin_lock.exit
  %core.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i, align 8
  br label %__here

__here:                                           ; preds = %if.then.i4, %rq_unpin_lock.exit
  %retval.0.i = phi ptr [ %12, %if.then.i4 ], [ %rq, %rq_unpin_lock.exit ]
  %dep_map = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i, i32 0, i32 4
  tail call void @lock_release(ptr noundef %dep_map, i32 noundef ptrtoint (ptr blockaddress(@prepare_lock_switch, %__here) to i32)) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@prepare_lock_switch, %land.rhs.i.i)) #33
          to label %rq_lockp.exit [label %land.rhs.i.i], !srcloc !1202

land.rhs.i.i:                                     ; preds = %__here
  %13 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %core_enabled.i.i, align 128
  %tobool3.i.not.i = icmp eq i32 %14, 0
  br i1 %tobool3.i.not.i, label %rq_lockp.exit, label %if.then.i7

if.then.i7:                                       ; preds = %land.rhs.i.i
  %core.i6 = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %15 = ptrtoint ptr %core.i6 to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %core.i6, align 8
  br label %rq_lockp.exit

rq_lockp.exit:                                    ; preds = %if.then.i7, %land.rhs.i.i, %__here
  %retval.0.i8 = phi ptr [ %16, %if.then.i7 ], [ %rq, %land.rhs.i.i ], [ %rq, %__here ]
  %owner = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i8, i32 0, i32 3
  %17 = ptrtoint ptr %owner to i32
  call void @__asan_store4_noabort(i32 %17)
  store ptr %next, ptr %owner, align 4
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @__switch_to(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @perf_event_task_sched_out(ptr noundef %prev, ptr noundef %next) unnamed_addr #3 align 64 {
entry:
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([12 x %struct.static_key], ptr @perf_swevent_enabled, i32 0, i32 3), ptr blockaddress(@perf_event_task_sched_out, %if.then)) #33
          to label %if.end [label %if.then], !srcloc !1202

if.then:                                          ; preds = %entry
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %5, ptrtoint (ptr @__perf_regs to i32)
  %6 = inttoptr i32 %add.i to ptr
  %7 = tail call ptr @llvm.returnaddress(i32 0) #33
  %8 = ptrtoint ptr %7 to i32
  %arrayidx.i.i = getelementptr [18 x i32], ptr %6, i32 0, i32 15
  %9 = ptrtoint ptr %arrayidx.i.i to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 %8, ptr %arrayidx.i.i, align 4
  %10 = tail call ptr @llvm.frameaddress.p0(i32 0) #33
  %11 = ptrtoint ptr %10 to i32
  %arrayidx2.i.i = getelementptr [18 x i32], ptr %6, i32 0, i32 11
  %12 = ptrtoint ptr %arrayidx2.i.i to i32
  call void @__asan_store4_noabort(i32 %12)
  store i32 %11, ptr %arrayidx2.i.i, align 4
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i.i = getelementptr [18 x i32], ptr %6, i32 0, i32 13
  %14 = ptrtoint ptr %arrayidx4.i.i to i32
  call void @__asan_store4_noabort(i32 %14)
  store i32 %13, ptr %arrayidx4.i.i, align 4
  %arrayidx6.i.i = getelementptr [18 x i32], ptr %6, i32 0, i32 16
  %15 = ptrtoint ptr %arrayidx6.i.i to i32
  call void @__asan_store4_noabort(i32 %15)
  store i32 19, ptr %arrayidx6.i.i, align 4
  tail call void @___perf_sw_event(i32 noundef 3, i64 noundef 1, ptr noundef %6, i64 noundef 0) #33
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds ([12 x %struct.static_key], ptr @perf_swevent_enabled, i32 0, i32 11), ptr blockaddress(@perf_event_task_sched_out, %land.lhs.true)) #33
          to label %if.end5 [label %land.lhs.true], !srcloc !1202

land.lhs.true:                                    ; preds = %if.end
  %cgroups.i = getelementptr inbounds %struct.task_struct, ptr %prev, i32 0, i32 164
  %16 = ptrtoint ptr %cgroups.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile ptr, ptr %cgroups.i, align 16
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @cgroup_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool.not.i = icmp eq i32 %call.i.i, 0
  br i1 %tobool.not.i, label %lor.lhs.false.i, label %perf_cgroup_from_task.exit

lor.lhs.false.i:                                  ; preds = %land.lhs.true
  %call.i1.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @css_set_lock, i32 0, i32 0, i32 0, i32 4), i32 noundef -1) #33
  br label %perf_cgroup_from_task.exit

perf_cgroup_from_task.exit:                       ; preds = %lor.lhs.false.i, %land.lhs.true
  %arrayidx.i24 = getelementptr [14 x ptr], ptr %17, i32 0, i32 8
  %18 = ptrtoint ptr %arrayidx.i24 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %arrayidx.i24, align 4
  %cgroups.i25 = getelementptr inbounds %struct.task_struct, ptr %next, i32 0, i32 164
  %20 = ptrtoint ptr %cgroups.i25 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load volatile ptr, ptr %cgroups.i25, align 16
  %call.i.i26 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.mutex, ptr @cgroup_mutex, i32 0, i32 5), i32 noundef -1) #33
  %tobool.not.i27 = icmp eq i32 %call.i.i26, 0
  br i1 %tobool.not.i27, label %lor.lhs.false.i29, label %perf_cgroup_from_task.exit31

lor.lhs.false.i29:                                ; preds = %perf_cgroup_from_task.exit
  %call.i1.i28 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @css_set_lock, i32 0, i32 0, i32 0, i32 4), i32 noundef -1) #33
  br label %perf_cgroup_from_task.exit31

perf_cgroup_from_task.exit31:                     ; preds = %lor.lhs.false.i29, %perf_cgroup_from_task.exit
  %arrayidx.i30 = getelementptr [14 x ptr], ptr %21, i32 0, i32 8
  %22 = ptrtoint ptr %arrayidx.i30 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %arrayidx.i30, align 4
  %cmp.not = icmp eq ptr %19, %23
  br i1 %cmp.not, label %if.end5, label %if.then4

if.then4:                                         ; preds = %perf_cgroup_from_task.exit31
  %24 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i16 = and i32 %24, -16384
  %25 = inttoptr i32 %and.i.i16 to ptr
  %cpu.i17 = getelementptr inbounds %struct.thread_info, ptr %25, i32 0, i32 3
  %26 = ptrtoint ptr %cpu.i17 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %cpu.i17, align 4
  %arrayidx.i18 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %27
  %28 = ptrtoint ptr %arrayidx.i18 to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %arrayidx.i18, align 4
  %add.i19 = add i32 %29, ptrtoint (ptr @__perf_regs to i32)
  %30 = inttoptr i32 %add.i19 to ptr
  %31 = tail call ptr @llvm.returnaddress(i32 0) #33
  %32 = ptrtoint ptr %31 to i32
  %arrayidx.i.i20 = getelementptr [18 x i32], ptr %30, i32 0, i32 15
  %33 = ptrtoint ptr %arrayidx.i.i20 to i32
  call void @__asan_store4_noabort(i32 %33)
  store i32 %32, ptr %arrayidx.i.i20, align 4
  %34 = tail call ptr @llvm.frameaddress.p0(i32 0) #33
  %35 = ptrtoint ptr %34 to i32
  %arrayidx2.i.i21 = getelementptr [18 x i32], ptr %30, i32 0, i32 11
  %36 = ptrtoint ptr %arrayidx2.i.i21 to i32
  call void @__asan_store4_noabort(i32 %36)
  store i32 %35, ptr %arrayidx2.i.i21, align 4
  %37 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %arrayidx4.i.i22 = getelementptr [18 x i32], ptr %30, i32 0, i32 13
  %38 = ptrtoint ptr %arrayidx4.i.i22 to i32
  call void @__asan_store4_noabort(i32 %38)
  store i32 %37, ptr %arrayidx4.i.i22, align 4
  %arrayidx6.i.i23 = getelementptr [18 x i32], ptr %30, i32 0, i32 16
  %39 = ptrtoint ptr %arrayidx6.i.i23 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 19, ptr %arrayidx6.i.i23, align 4
  tail call void @___perf_sw_event(i32 noundef 11, i64 noundef 1, ptr noundef %30, i64 noundef 0) #33
  br label %if.end5

if.end5:                                          ; preds = %if.then4, %perf_cgroup_from_task.exit31, %if.end
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @perf_sched_events, ptr blockaddress(@perf_event_task_sched_out, %if.then9)) #33
          to label %if.end10 [label %if.then9], !srcloc !1202

if.then9:                                         ; preds = %if.end5
  tail call void @__perf_event_task_sched_out(ptr noundef %prev, ptr noundef %next) #33
  br label %if.end10

if.end10:                                         ; preds = %if.then9, %if.end5
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__perf_event_task_sched_out(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__kmap_local_sched_out() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @wq_worker_sleeping(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @io_wq_worker_sleeping(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @wq_worker_running(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @io_wq_worker_running(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @do_balance_callbacks(ptr noundef %rq, ptr noundef %head) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  %tobool.not.i = icmp eq i32 %0, 0
  br i1 %tobool.not.i, label %lockdep_assert_rq_held.exit, label %land.rhs.i

land.rhs.i:                                       ; preds = %entry
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %1 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %2, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.rhs.i
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %3 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %land.rhs.i
  %retval.0.i.i = phi ptr [ %4, %if.then.i.i ], [ %rq, %land.rhs.i ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef %dep_map.i, i32 noundef -1) #33
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %lockdep_assert_rq_held.exit, !prof !1192

do.end.i:                                         ; preds = %__rq_lockp.exit.i
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1309, i32 noundef 9, ptr noundef null) #33
  br label %lockdep_assert_rq_held.exit

lockdep_assert_rq_held.exit:                      ; preds = %do.end.i, %__rq_lockp.exit.i, %entry
  %tobool.not8 = icmp eq ptr %head, null
  br i1 %tobool.not8, label %while.end, label %while.body

while.body:                                       ; preds = %while.body, %lockdep_assert_rq_held.exit
  %head.addr.09 = phi ptr [ %8, %while.body ], [ %head, %lockdep_assert_rq_held.exit ]
  %func1 = getelementptr inbounds %struct.callback_head, ptr %head.addr.09, i32 0, i32 1
  %5 = ptrtoint ptr %func1 to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %func1, align 4
  %7 = ptrtoint ptr %head.addr.09 to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %head.addr.09, align 4
  store ptr null, ptr %head.addr.09, align 4
  tail call void %6(ptr noundef %rq) #33
  %tobool.not = icmp eq ptr %8, null
  br i1 %tobool.not, label %while.end, label %while.body

while.end:                                        ; preds = %while.body, %lockdep_assert_rq_held.exit
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @security_task_setnice(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__checkparam_dl(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpuset_read_lock() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @dl_param_changed(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpuset_read_unlock() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_dl_overflow(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @rt_mutex_adjust_pi(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__setparam_dl(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @do_sched_setscheduler(i32 noundef %pid, i32 noundef %policy, ptr noundef %param) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %attr.i.i = alloca %struct.sched_attr, align 8
  %lparam = alloca %struct.sched_param, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %lparam) #33
  %0 = ptrtoint ptr %lparam to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %lparam, align 4, !annotation !1193
  %tobool.not = icmp eq ptr %param, null
  %cmp = icmp slt i32 %pid, 0
  %or.cond = or i1 %cmp, %tobool.not
  br i1 %or.cond, label %cleanup, label %if.end59.i.i

if.end59.i.i:                                     ; preds = %entry
  tail call void @__might_fault(ptr noundef nonnull @.str.220, i32 noundef 156) #33
  %call.i.i = tail call zeroext i1 @should_fail_usercopy() #33
  br i1 %call.i.i, label %if.then11.i.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end59.i.i
  %1 = tail call { i32, i32 } asm ".syntax unified\0Aadds $1, $2, $3; sbcscc $1, $1, $0; movcc $0, #0", "=&r,=&r,r,Ir,0,~{cc}"(ptr nonnull %param, i32 4, i32 -1226833920) #40, !srcloc !1298
  %asmresult.i.i = extractvalue { i32, i32 } %1, 0
  %cmp.i6.i = icmp eq i32 %asmresult.i.i, 0
  br i1 %cmp.i6.i, label %if.end.i.i, label %if.then11.i.i, !prof !1191

if.end.i.i:                                       ; preds = %land.lhs.true.i.i
  %call.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef nonnull %lparam, i32 noundef 4) #33
  %2 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %cpu_domain.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 4
  %4 = call i32 asm "mrc\09p15, 0, $0, c3, c0\09@ get domain", "=r,*m"(ptr elementtype(i32) %cpu_domain.i.i.i.i.i) #22, !srcloc !1268
  %and.i.i.i.i = and i32 %4, -13
  %or.i.i.i.i = or i32 %and.i.i.i.i, 4
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %or.i.i.i.i) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %call1.i.i.i = call i32 @arm_copy_from_user(ptr noundef nonnull %lparam, ptr noundef nonnull %param, i32 noundef 4) #33
  call void asm sideeffect "mcr\09p15, 0, $0, c3, c0\09@ set domain", "r,~{memory}"(i32 %4) #33, !srcloc !1269
  call void asm sideeffect "mcr p15, 0, $0, c7, c5, 4", "r,~{memory}"(i32 0) #33, !srcloc !1270
  %tobool4.not.i.i = icmp eq i32 %call1.i.i.i, 0
  br i1 %tobool4.not.i.i, label %if.end4, label %if.then11.i.i, !prof !1191

if.then11.i.i:                                    ; preds = %if.end.i.i, %land.lhs.true.i.i, %if.end59.i.i
  %res.0.i.i51 = phi i32 [ %call1.i.i.i, %if.end.i.i ], [ 4, %if.end59.i.i ], [ 4, %land.lhs.true.i.i ]
  %sub.i.i = sub i32 4, %res.0.i.i51
  %add.ptr.i.i = getelementptr i8, ptr %lparam, i32 %sub.i.i
  %5 = call ptr @memset(ptr %add.ptr.i.i, i32 0, i32 %res.0.i.i51)
  br label %cleanup

if.end4:                                          ; preds = %if.end.i.i
  %6 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 1
  %8 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %9, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end4
  %call1.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end4
  %tobool.not.i30 = icmp eq i32 %pid, 0
  br i1 %tobool.not.i30, label %cond.false.i, label %cond.true.i

cond.true.i:                                      ; preds = %rcu_read_lock.exit
  %call.i31 = call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit

cond.false.i:                                     ; preds = %rcu_read_lock.exit
  %10 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %10, -16384
  %11 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %11, i32 0, i32 2
  %12 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task.i, align 8
  br label %find_process_by_pid.exit

find_process_by_pid.exit:                         ; preds = %cond.false.i, %cond.true.i
  %cond.i = phi ptr [ %call.i31, %cond.true.i ], [ %13, %cond.false.i ]
  %tobool6.not = icmp eq ptr %cond.i, null
  br i1 %tobool6.not, label %if.end21.critedge, label %if.then9, !prof !1192

if.then9:                                         ; preds = %find_process_by_pid.exit
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 2
  %call.i.i.i.i.i.i = call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %14 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_add\0A1:\09ldrex\09$0, [$4]\0A\09add\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1225
  %asmresult.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %14, 0
  %tobool1.not.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i, 0
  br i1 %tobool1.not.i.i.i.i, label %if.end15.sink.split.i.i.i.i, label %if.else.i.i.i.i, !prof !1192

if.else.i.i.i.i:                                  ; preds = %if.then9
  %add.i.i.i.i = add i32 %asmresult.i.i.i.i.i.i, 1
  %15 = or i32 %add.i.i.i.i, %asmresult.i.i.i.i.i.i
  %.not.i.i.i.i = icmp sgt i32 %15, -1
  br i1 %.not.i.i.i.i, label %get_task_struct.exit, label %if.end15.sink.split.i.i.i.i, !prof !1191

if.end15.sink.split.i.i.i.i:                      ; preds = %if.else.i.i.i.i, %if.then9
  %.sink.i.i.i.i = phi i32 [ 2, %if.then9 ], [ 1, %if.else.i.i.i.i ]
  call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef %.sink.i.i.i.i) #33
  br label %get_task_struct.exit

get_task_struct.exit:                             ; preds = %if.end15.sink.split.i.i.i.i, %if.else.i.i.i.i
  %call.i32 = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i32, label %rcu_read_unlock.exit, label %land.lhs.true.i35

land.lhs.true.i35:                                ; preds = %get_task_struct.exit
  %call1.i33 = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i34 = icmp eq i32 %call1.i33, 0
  br i1 %tobool.not.i34, label %rcu_read_unlock.exit, label %land.lhs.true2.i37

land.lhs.true2.i37:                               ; preds = %land.lhs.true.i35
  %.b4.i36 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i36, label %rcu_read_unlock.exit, label %if.then.i38

if.then.i38:                                      ; preds = %land.lhs.true2.i37
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i38, %land.lhs.true2.i37, %land.lhs.true.i35, %get_task_struct.exit
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %16 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i39 = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i.i.i39 to ptr
  %preempt_count.i.i.i.i40 = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i.i.i40 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i.i.i40, align 4
  %sub.i.i.i = add i32 %19, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i40, align 4
  call void @rcu_read_unlock_strict() #33
  call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  call void @llvm.lifetime.start.p0(i64 56, ptr nonnull %attr.i.i) #33
  %20 = call ptr @memset(ptr %attr.i.i, i32 0, i32 56)
  %sched_policy.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 1
  %21 = ptrtoint ptr %sched_policy.i.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %policy, ptr %sched_policy.i.i, align 4
  %sched_nice.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 3
  %static_prio.i.i = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 14
  %22 = ptrtoint ptr %static_prio.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %static_prio.i.i, align 4
  %sub.i.i41 = add i32 %23, -120
  %24 = ptrtoint ptr %sched_nice.i.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 %sub.i.i41, ptr %sched_nice.i.i, align 8
  %sched_priority.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 4
  %25 = ptrtoint ptr %lparam to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %lparam, align 4
  %27 = ptrtoint ptr %sched_priority.i.i to i32
  call void @__asan_store4_noabort(i32 %27)
  store i32 %26, ptr %sched_priority.i.i, align 4
  %cmp.not.i.i = icmp eq i32 %policy, -1
  %and.i.i42 = and i32 %policy, 1073741824
  %tobool.not.i.i = icmp eq i32 %and.i.i42, 0
  %or.cond.i.i = or i1 %cmp.not.i.i, %tobool.not.i.i
  br i1 %or.cond.i.i, label %sched_setscheduler.exit, label %if.then.i.i43

if.then.i.i43:                                    ; preds = %rcu_read_unlock.exit
  %sched_flags.i.i = getelementptr inbounds %struct.sched_attr, ptr %attr.i.i, i32 0, i32 2
  %28 = ptrtoint ptr %sched_flags.i.i to i32
  call void @__asan_load8_noabort(i32 %28)
  %29 = load i64, ptr %sched_flags.i.i, align 8
  %or.i.i = or i64 %29, 1
  store i64 %or.i.i, ptr %sched_flags.i.i, align 8
  %and2.i.i = and i32 %policy, -1073741825
  %30 = ptrtoint ptr %sched_policy.i.i to i32
  call void @__asan_store4_noabort(i32 %30)
  store i32 %and2.i.i, ptr %sched_policy.i.i, align 4
  br label %sched_setscheduler.exit

sched_setscheduler.exit:                          ; preds = %if.then.i.i43, %rcu_read_unlock.exit
  %call.i.i44 = call fastcc i32 @__sched_setscheduler(ptr noundef nonnull %cond.i, ptr noundef nonnull %attr.i.i, i1 noundef zeroext true, i1 noundef zeroext true) #33
  call void @llvm.lifetime.end.p0(i64 56, ptr nonnull %attr.i.i) #33
  %call.i.i.i.i.i.i46 = call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %31 = call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %31, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i48, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %sched_setscheduler.exit
  %.not.i.i.i.i47 = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i47, label %cleanup, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %cleanup

if.then.i48:                                      ; preds = %sched_setscheduler.exit
  call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  call void @__put_task_struct(ptr noundef nonnull %cond.i) #33
  br label %cleanup

if.end21.critedge:                                ; preds = %find_process_by_pid.exit
  call fastcc void @rcu_read_unlock()
  br label %cleanup

cleanup:                                          ; preds = %if.end21.critedge, %if.then.i48, %if.then10.i.i.i.i, %if.end5.i.i.i.i, %if.then11.i.i, %entry
  %retval.0 = phi i32 [ -22, %entry ], [ -3, %if.end21.critedge ], [ %call.i.i44, %if.end5.i.i.i.i ], [ %call.i.i44, %if.then10.i.i.i.i ], [ %call.i.i44, %if.then.i48 ], [ -14, %if.then11.i.i ]
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %lparam) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__check_object_size(ptr noundef, i32 noundef, i1 noundef zeroext) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @should_fail_usercopy() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @arm_copy_from_user(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @check_zeroed_user(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__getparam_dl(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @arm_copy_to_user(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_subset(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @find_task_by_vpid(i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_and(ptr noundef, ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @sched_rr_get_interval(i32 noundef %pid, ptr noundef %t) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %3 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %4 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -1, ptr %3, align 4, !annotation !1193
  %cmp = icmp slt i32 %pid, 0
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 1
  %7 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %8, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end
  %tobool.not.i28 = icmp eq i32 %pid, 0
  br i1 %tobool.not.i28, label %cond.false.i, label %cond.true.i

cond.true.i:                                      ; preds = %rcu_read_lock.exit
  %call.i29 = tail call ptr @find_task_by_vpid(i32 noundef %pid) #33
  br label %find_process_by_pid.exit

cond.false.i:                                     ; preds = %rcu_read_lock.exit
  %9 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 2
  %11 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task.i, align 8
  br label %find_process_by_pid.exit

find_process_by_pid.exit:                         ; preds = %cond.false.i, %cond.true.i
  %cond.i = phi ptr [ %call.i29, %cond.true.i ], [ %12, %cond.false.i ]
  %tobool.not = icmp eq ptr %cond.i, null
  br i1 %tobool.not, label %out_unlock, label %if.end3

if.end3:                                          ; preds = %find_process_by_pid.exit
  %call4 = tail call i32 @security_task_getscheduler(ptr noundef nonnull %cond.i) #33
  %tobool5.not = icmp eq i32 %call4, 0
  br i1 %tobool5.not, label %if.end7, label %out_unlock

if.end7:                                          ; preds = %if.end3
  %call8 = call ptr @task_rq_lock(ptr noundef nonnull %cond.i, ptr noundef nonnull %rf)
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 21
  %13 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %sched_class, align 32
  %get_rr_interval = getelementptr inbounds %struct.sched_class, ptr %14, i32 0, i32 24
  %15 = ptrtoint ptr %get_rr_interval to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %get_rr_interval, align 4
  %tobool9.not = icmp eq ptr %16, null
  br i1 %tobool9.not, label %if.end14, label %if.then10

if.then10:                                        ; preds = %if.end7
  %call13 = tail call i32 %16(ptr noundef %call8, ptr noundef nonnull %cond.i) #33
  br label %if.end14

if.end14:                                         ; preds = %if.then10, %if.end7
  %time_slice.0 = phi i32 [ %call13, %if.then10 ], [ 0, %if.end7 ]
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %call8, i32 0, i32 25
  %17 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %18, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end14
  %19 = ptrtoint ptr %3 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 4, ptr %3, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end14
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %call8, i32 0, i32 81
  %20 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %21, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %call8, i32 0, i32 79
  %22 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %23, %if.then.i.i.i ], [ %call8, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %24 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %24)
  %.unpack.i.i = load i32, ptr %1, align 4
  %25 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %25) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@sched_rr_get_interval, %land.rhs.i.i.i.i)) #33
          to label %task_rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %26 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %27, 0
  br i1 %tobool3.i.not.i.i.i, label %task_rq_unlock.exit, label %if.then.i.i4.i

if.then.i.i4.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i3.i = getelementptr inbounds %struct.rq, ptr %call8, i32 0, i32 79
  %28 = ptrtoint ptr %core.i.i3.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %core.i.i3.i, align 8
  br label %task_rq_unlock.exit

task_rq_unlock.exit:                              ; preds = %if.then.i.i4.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i5.i = phi ptr [ %29, %if.then.i.i4.i ], [ %call8, %land.rhs.i.i.i.i ], [ %call8, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i5.i) #33
  %pi_lock.i = getelementptr inbounds %struct.task_struct, ptr %cond.i, i32 0, i32 128
  %30 = ptrtoint ptr %rf to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %rf, align 4
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %pi_lock.i, i32 noundef %31) #33
  %call.i30 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i30, label %rcu_read_unlock.exit, label %land.lhs.true.i33

land.lhs.true.i33:                                ; preds = %task_rq_unlock.exit
  %call1.i31 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i32 = icmp eq i32 %call1.i31, 0
  br i1 %tobool.not.i32, label %rcu_read_unlock.exit, label %land.lhs.true2.i35

land.lhs.true2.i35:                               ; preds = %land.lhs.true.i33
  %.b4.i34 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i34, label %rcu_read_unlock.exit, label %if.then.i36

if.then.i36:                                      ; preds = %land.lhs.true2.i35
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i36, %land.lhs.true2.i35, %land.lhs.true.i33, %task_rq_unlock.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %32 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i37 = and i32 %32, -16384
  %33 = inttoptr i32 %and.i.i.i.i.i37 to ptr
  %preempt_count.i.i.i.i38 = getelementptr inbounds %struct.thread_info, ptr %33, i32 0, i32 1
  %34 = ptrtoint ptr %preempt_count.i.i.i.i38 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load volatile i32, ptr %preempt_count.i.i.i.i38, align 4
  %sub.i.i.i = add i32 %35, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i38, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  tail call void @jiffies_to_timespec64(i32 noundef %time_slice.0, ptr noundef %t) #33
  br label %cleanup

out_unlock:                                       ; preds = %if.end3, %find_process_by_pid.exit
  %retval1.0 = phi i32 [ %call4, %if.end3 ], [ -3, %find_process_by_pid.exit ]
  %call.i39 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i39, label %rcu_read_unlock.exit49, label %land.lhs.true.i42

land.lhs.true.i42:                                ; preds = %out_unlock
  %call1.i40 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i41 = icmp eq i32 %call1.i40, 0
  br i1 %tobool.not.i41, label %rcu_read_unlock.exit49, label %land.lhs.true2.i44

land.lhs.true2.i44:                               ; preds = %land.lhs.true.i42
  %.b4.i43 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i43, label %rcu_read_unlock.exit49, label %if.then.i45

if.then.i45:                                      ; preds = %land.lhs.true2.i44
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit49

rcu_read_unlock.exit49:                           ; preds = %if.then.i45, %land.lhs.true2.i44, %land.lhs.true.i42, %out_unlock
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %36 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i46 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i.i.i46 to ptr
  %preempt_count.i.i.i.i47 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i.i.i47 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i.i.i47, align 4
  %sub.i.i.i48 = add i32 %39, -1
  store volatile i32 %sub.i.i.i48, ptr %preempt_count.i.i.i.i47, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  br label %cleanup

cleanup:                                          ; preds = %rcu_read_unlock.exit49, %rcu_read_unlock.exit, %entry
  %retval.0 = phi i32 [ %retval1.0, %rcu_read_unlock.exit49 ], [ 0, %rcu_read_unlock.exit ], [ -22, %entry ]
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @put_timespec64(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @jiffies_to_timespec64(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @put_old_timespec32(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @touch_softlockup_watchdog() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @__bitmap_intersects(ptr noundef, ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @check_and_switch_context(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_test_and_set_bit(i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @rcuwait_wake_up(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @__balance_push_cpu_stop(ptr noundef %arg) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 3
  %2 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %3
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %add = add i32 %5, ptrtoint (ptr @runqueues to i32)
  %6 = inttoptr i32 %add to ptr
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %7 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %7)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %8 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %9 = ptrtoint ptr %8 to i32
  call void @__asan_store4_noabort(i32 %9)
  store i32 -1, ptr %8, align 4, !annotation !1193
  %10 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %11 = ptrtoint ptr %10 to i32
  call void @__asan_store4_noabort(i32 %11)
  store i32 -1, ptr %10, align 4, !annotation !1193
  %pi_lock = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 128
  tail call void @_raw_spin_lock_irq(ptr noundef %pi_lock) #33
  call fastcc void @rq_lock(ptr noundef %6, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %6)
  %stack.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 1
  %12 = ptrtoint ptr %stack.i to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %stack.i, align 4
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 3
  %14 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %cpu.i, align 4
  %arrayidx11 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %15
  %16 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load i32, ptr %arrayidx11, align 4
  %add12 = add i32 %17, ptrtoint (ptr @runqueues to i32)
  %18 = inttoptr i32 %add12 to ptr
  %cmp = icmp eq ptr %18, %6
  br i1 %cmp, label %land.lhs.true, label %if.end

land.lhs.true:                                    ; preds = %entry
  %on_rq.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 12
  %19 = ptrtoint ptr %on_rq.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load i32, ptr %on_rq.i, align 4
  %cmp.i.not = icmp eq i32 %20, 1
  br i1 %cmp.i.not, label %if.then, label %if.end

if.then:                                          ; preds = %land.lhs.true
  %cpu14 = getelementptr inbounds %struct.rq, ptr %6, i32 0, i32 46
  %21 = ptrtoint ptr %cpu14 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %cpu14, align 4
  %call15 = tail call fastcc i32 @select_fallback_rq(i32 noundef %22, ptr noundef %arg)
  %call.i = tail call fastcc zeroext i1 @is_cpu_allowed(ptr noundef %arg, i32 noundef %call15) #33
  br i1 %call.i, label %if.end.i, label %if.end

if.end.i:                                         ; preds = %if.then
  tail call void @update_rq_clock(ptr noundef %6) #33
  %call1.i = call fastcc ptr @move_queued_task(ptr noundef %6, ptr noundef nonnull %rf, ptr noundef %arg, i32 noundef %call15) #33
  br label %if.end

if.end:                                           ; preds = %if.end.i, %if.then, %land.lhs.true, %entry
  %rq.0 = phi ptr [ %6, %land.lhs.true ], [ %6, %entry ], [ %call1.i, %if.end.i ], [ %6, %if.then ]
  %clock_update_flags.i.i = getelementptr inbounds %struct.rq, ptr %rq.0, i32 0, i32 25
  %23 = ptrtoint ptr %clock_update_flags.i.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %clock_update_flags.i.i, align 4
  %cmp.i.i = icmp ugt i32 %24, 2
  br i1 %cmp.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %if.end
  %25 = ptrtoint ptr %10 to i32
  call void @__asan_store4_noabort(i32 %25)
  store i32 4, ptr %10, align 4
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %if.end
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %rq.0, i32 0, i32 81
  %26 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %27, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end.i.i
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %rq.0, i32 0, i32 79
  %28 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end.i.i
  %retval.0.i.i.i = phi ptr [ %29, %if.then.i.i.i ], [ %rq.0, %if.end.i.i ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %30 = ptrtoint ptr %8 to i32
  call void @__asan_load4_noabort(i32 %30)
  %.unpack.i.i = load i32, ptr %8, align 4
  %31 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %31) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__balance_push_cpu_stop, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %32 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %33, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %rq.0, i32 0, i32 79
  %34 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %35, %if.then.i.i3.i ], [ %rq.0, %land.rhs.i.i.i.i ], [ %rq.0, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  tail call void @_raw_spin_unlock_irq(ptr noundef %pi_lock) #33
  %usage.i = getelementptr inbounds %struct.task_struct, ptr %arg, i32 0, i32 2
  %call.i.i.i.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef %usage.i, i32 noundef 4) #33
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1226
  tail call void @llvm.prefetch.p0(ptr %usage.i, i32 1, i32 3, i32 1) #33
  %36 = tail call { i32, i32, i32 } asm sideeffect "@ atomic_fetch_sub\0A1:\09ldrex\09$0, [$4]\0A\09sub\09$1, $0, $5\0A\09strex\09$2, $1, [$4]\0A\09teq\09$2, #0\0A\09bne\091b", "=&r,=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr elementtype(i32) %usage.i, ptr %usage.i, i32 1, ptr elementtype(i32) %usage.i) #33, !srcloc !1227
  %asmresult.i.i.i.i.i.i.i = extractvalue { i32, i32, i32 } %36, 0
  %cmp.i.i.i.i = icmp eq i32 %asmresult.i.i.i.i.i.i.i, 1
  br i1 %cmp.i.i.i.i, label %if.then.i, label %if.end5.i.i.i.i

if.end5.i.i.i.i:                                  ; preds = %rq_unlock.exit
  %.not.i.i.i.i = icmp sgt i32 %asmresult.i.i.i.i.i.i.i, 0
  br i1 %.not.i.i.i.i, label %put_task_struct.exit, label %if.then10.i.i.i.i, !prof !1191

if.then10.i.i.i.i:                                ; preds = %if.end5.i.i.i.i
  tail call void @refcount_warn_saturate(ptr noundef %usage.i, i32 noundef 3) #33
  br label %put_task_struct.exit

if.then.i:                                        ; preds = %rq_unlock.exit
  tail call void asm sideeffect "mcr p15, 0, $0, c7, c10, 5", "r,~{memory}"(i32 0) #33, !srcloc !1228
  tail call void @__put_task_struct(ptr noundef %arg) #33
  br label %put_task_struct.exit

put_task_struct.exit:                             ; preds = %if.then.i, %if.then10.i.i.i.i, %if.end5.i.i.i.i
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @partition_sched_domains(i32 noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpuset_force_rebuild() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cpuset_update_active_cpus() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @dl_cpu_busy(i32 noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nofree nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @finish_rcuwait(ptr noundef %w) #28 align 64 {
entry:
  %0 = ptrtoint ptr %w to i32
  call void @__asan_store4_noabort(i32 %0)
  store volatile ptr null, ptr %w, align 4
  br label %__here

__here:                                           ; preds = %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task72 = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task72 to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task72, align 8
  %task_state_change = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 212
  %5 = ptrtoint ptr %task_state_change to i32
  call void @__asan_store4_noabort(i32 %5)
  store i32 ptrtoint (ptr blockaddress(@finish_rcuwait, %__here) to i32), ptr %task_state_change, align 4
  %6 = load ptr, ptr %task72, align 8
  %7 = ptrtoint ptr %6 to i32
  call void @__asan_store4_noabort(i32 %7)
  store volatile i32 0, ptr %6, align 128
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @calc_load_fold_active(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @hrtimer_active(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @hrtimer_cancel(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__list_add_valid(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @raise_softirq_irqoff(i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @__hrtick_start(ptr noundef %arg) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  call fastcc void @rq_lock(ptr noundef %arg, ptr noundef nonnull %rf)
  %hrtick_timer.i = getelementptr inbounds %struct.rq, ptr %arg, i32 0, i32 66
  %hrtick_time.i = getelementptr inbounds %struct.rq, ptr %arg, i32 0, i32 67
  %3 = ptrtoint ptr %hrtick_time.i to i32
  call void @__asan_load8_noabort(i32 %3)
  %4 = load i64, ptr %hrtick_time.i, align 16
  tail call void @hrtimer_start_range_ns(ptr noundef %hrtick_timer.i, i64 noundef %4, i64 noundef 0, i32 noundef 10) #33
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %arg, i32 0, i32 81
  %5 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %6, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %entry
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %arg, i32 0, i32 79
  %7 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %entry
  %retval.0.i.i.i = phi ptr [ %8, %if.then.i.i.i ], [ %arg, %entry ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %9 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %9)
  %.unpack.i.i = load i32, ptr %1, align 4
  %10 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %10) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@__hrtick_start, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %11 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %12, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr inbounds %struct.rq, ptr %arg, i32 0, i32 79
  %13 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %14, %if.then.i.i3.i ], [ %arg, %land.rhs.i.i.i.i ], [ %arg, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @hrtimer_init(ptr noundef, i32 noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @hrtick(ptr noundef %timer) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %rf = alloca %struct.rq_flags, align 4
  %add.ptr = getelementptr i8, ptr %timer, i32 -2784
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %0 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %0)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %1 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %2 = ptrtoint ptr %1 to i32
  call void @__asan_store4_noabort(i32 %2)
  store i32 -1, ptr %1, align 4, !annotation !1193
  %cpu.i = getelementptr i8, ptr %timer, i32 -636
  %3 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load i32, ptr %cpu.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %cmp.not = icmp eq i32 %4, %8
  br i1 %cmp.not, label %if.end29, label %land.rhs

land.rhs:                                         ; preds = %entry
  %.b46 = load i1, ptr @hrtick.__already_done, align 1
  br i1 %.b46, label %if.end29, label %if.then, !prof !1191

if.then:                                          ; preds = %land.rhs
  store i1 true, ptr @hrtick.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.1, i32 noundef 721, i32 noundef 9, ptr noundef null) #33
  br label %if.end29

if.end29:                                         ; preds = %if.then, %land.rhs, %entry
  call fastcc void @rq_lock(ptr noundef %add.ptr, ptr noundef nonnull %rf)
  tail call void @update_rq_clock(ptr noundef %add.ptr)
  %curr = getelementptr i8, ptr %timer, i32 -856
  %9 = ptrtoint ptr %curr to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %curr, align 8
  %sched_class = getelementptr inbounds %struct.task_struct, ptr %10, i32 0, i32 21
  %11 = ptrtoint ptr %sched_class to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %sched_class, align 32
  %task_tick = getelementptr inbounds %struct.sched_class, ptr %12, i32 0, i32 18
  %13 = ptrtoint ptr %task_tick to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %task_tick, align 4
  tail call void %14(ptr noundef %add.ptr, ptr noundef %10, i32 noundef 1) #33
  %core_enabled.i.i.i = getelementptr i8, ptr %timer, i32 160
  %15 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i = icmp eq i32 %16, 0
  br i1 %tobool.not.i.i.i, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end29
  %core.i.i.i = getelementptr i8, ptr %timer, i32 152
  %17 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end29
  %retval.0.i.i.i = phi ptr [ %18, %if.then.i.i.i ], [ %add.ptr, %if.end29 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %19 = ptrtoint ptr %1 to i32
  call void @__asan_load4_noabort(i32 %19)
  %.unpack.i.i = load i32, ptr %1, align 4
  %20 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %20) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@hrtick, %land.rhs.i.i.i.i)) #33
          to label %rq_unlock.exit [label %land.rhs.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i:                                 ; preds = %rq_unpin_lock.exit.i
  %21 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i = icmp eq i32 %22, 0
  br i1 %tobool3.i.not.i.i.i, label %rq_unlock.exit, label %if.then.i.i3.i

if.then.i.i3.i:                                   ; preds = %land.rhs.i.i.i.i
  %core.i.i2.i = getelementptr i8, ptr %timer, i32 152
  %23 = ptrtoint ptr %core.i.i2.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load ptr, ptr %core.i.i2.i, align 8
  br label %rq_unlock.exit

rq_unlock.exit:                                   ; preds = %if.then.i.i3.i, %land.rhs.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i4.i = phi ptr [ %24, %if.then.i.i3.i ], [ %add.ptr, %land.rhs.i.i.i.i ], [ %add.ptr, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i4.i) #33
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  ret i32 0
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @free_fair_sched_group(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @free_rt_sched_group(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @autogroup_free(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @kmem_cache_free(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @unregister_fair_sched_group(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @unregister_rt_sched_group(ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @sched_free_group_rcu(ptr noundef %rcu) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %add.ptr = getelementptr i8, ptr %rcu, i32 -392
  tail call void @free_fair_sched_group(ptr noundef %add.ptr) #33
  tail call void @free_rt_sched_group(ptr noundef %add.ptr) #33
  tail call void @autogroup_free(ptr noundef %add.ptr) #33
  %0 = load ptr, ptr @task_group_cache, align 4
  tail call void @kmem_cache_free(ptr noundef %0, ptr noundef %add.ptr) #33
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__list_del_entry_valid(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @seq_printf(ptr noundef, ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @cgroup_taskset_first(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_rt_can_attach(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @cgroup_taskset_next(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: argmemonly nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_weight_read_u64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #29 align 64 {
if.end185:
  call void @llvm.arm.gnu.eabi.mcount()
  %shares = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 3
  %0 = ptrtoint ptr %shares to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %shares, align 16
  %conv = zext i32 %1 to i64
  %mul = mul nuw nsw i64 %conv, 100
  %add = add nuw nsw i64 %mul, 512
  %shr = lshr i64 %add, 10
  ret i64 %shr
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_weight_write_u64(ptr noundef %css, ptr nocapture noundef readnone %cft, i64 noundef %weight) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = add i64 %weight, -10001
  %1 = icmp ult i64 %0, -10000
  br i1 %1, label %return, label %if.end187

if.end187:                                        ; preds = %entry
  %mul = shl nuw nsw i64 %weight, 10
  %add = or i64 %mul, 50
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -6640827866535438582, i64 %add, i32 0) #40, !srcloc !1330
  %asmresult.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -6640827866535438582, i64 %add, i64 %asmresult.i, i32 %asmresult4.i) #40, !srcloc !1331
  %asmresult10.i = extractvalue { i64, i32 } %3, 0
  %extract277 = lshr i64 %asmresult10.i, 6
  %extract.t278 = trunc i64 %extract277 to i32
  %call192 = tail call i32 @sched_group_set_shares(ptr noundef %css, i32 noundef %extract.t278) #33
  br label %return

return:                                           ; preds = %if.end187, %entry
  %retval.0 = phi i32 [ %call192, %if.end187 ], [ -34, %entry ]
  ret i32 %retval.0
}

; Function Attrs: argmemonly nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_weight_nice_read_s64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #30 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %shares = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 3
  %0 = ptrtoint ptr %shares to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %shares, align 16
  br label %for.body

for.body:                                         ; preds = %if.end, %entry
  %prio.013 = phi i32 [ 0, %entry ], [ %inc, %if.end ]
  %last_delta.012 = phi i32 [ 2147483647, %entry ], [ %4, %if.end ]
  %arrayidx = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %prio.013
  %2 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %arrayidx, align 4
  %sub = sub i32 %3, %1
  %4 = tail call i32 @llvm.abs.i32(i32 %sub, i1 false)
  %cmp3.not = icmp slt i32 %4, %last_delta.012
  br i1 %cmp3.not, label %if.end, label %for.end

if.end:                                           ; preds = %for.body
  %inc = add nuw nsw i32 %prio.013, 1
  %exitcond.not = icmp eq i32 %inc, 40
  br i1 %exitcond.not, label %for.end, label %for.body

for.end:                                          ; preds = %if.end, %for.body
  %prio.0.lcssa = phi i32 [ %prio.013, %for.body ], [ 40, %if.end ]
  %sub5 = add nsw i32 %prio.0.lcssa, -21
  %conv = sext i32 %sub5 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_weight_nice_write_s64(ptr noundef %css, ptr nocapture noundef readnone %cft, i64 noundef %nice) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = add i64 %nice, -20
  %1 = icmp ult i64 %0, -40
  br i1 %1, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %2 = trunc i64 %nice to i32
  %conv = add nsw i32 %2, 20
  %3 = tail call i32 asm sideeffect "cmp\09$1, $2\0A\09sbc\09$0, $1, $1\0A", "=r,r,Ir,~{cc}"(i32 %conv, i32 40) #33, !srcloc !1345
  %and = and i32 %3, %conv
  %arrayidx = getelementptr [40 x i32], ptr @sched_prio_to_weight, i32 0, i32 %and
  %4 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %arrayidx, align 4
  %call6 = tail call i32 @sched_group_set_shares(ptr noundef %css, i32 noundef %5) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i32 [ %call6, %if.end ], [ -34, %entry ]
  ret i32 %retval.0
}

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define internal i64 @cpu_idle_read_s64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #8 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %idle = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 4
  %0 = ptrtoint ptr %idle to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %idle, align 4
  %conv = sext i32 %1 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_idle_write_s64(ptr noundef %css, ptr nocapture noundef readnone %cft, i64 noundef %idle) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %conv = trunc i64 %idle to i32
  %call1 = tail call i32 @sched_group_set_idle(ptr noundef %css, i32 noundef %conv) #33
  ret i32 %call1
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_max_show(ptr noundef %sf, ptr nocapture noundef readnone %v) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %private.i = getelementptr inbounds %struct.seq_file, ptr %sf, i32 0, i32 11
  %0 = ptrtoint ptr %private.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %private.i, align 8
  %call.i = tail call ptr @of_css(ptr noundef %1) #33
  %period.i = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 1
  %2 = ptrtoint ptr %period.i to i32
  call void @__asan_load8_noabort(i32 %2)
  %3 = load i64, ptr %period.i, align 16
  %4 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %3, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %4, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %4, 1
  %5 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %3, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %quota.i = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 2
  %6 = ptrtoint ptr %quota.i to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %quota.i, align 8
  %cmp.i = icmp eq i64 %7, -1
  br i1 %cmp.i, label %if.then.i, label %tg_get_cfs_quota.exit

tg_get_cfs_quota.exit:                            ; preds = %entry
  %8 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %7, i32 0) #40, !srcloc !1330
  %asmresult.i.i6 = extractvalue { i64, i32 } %8, 0
  %asmresult4.i.i7 = extractvalue { i64, i32 } %8, 1
  %9 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %7, i64 %asmresult.i.i6, i32 %asmresult4.i.i7) #40, !srcloc !1331
  %asmresult10.i.i8 = extractvalue { i64, i32 } %9, 0
  %extract267.i = lshr i64 %asmresult10.i.i8, 9
  %extract.t268.i = trunc i64 %extract267.i to i32
  %cmp.i9 = icmp slt i32 %extract.t268.i, 0
  br i1 %cmp.i9, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %tg_get_cfs_quota.exit, %entry
  tail call void @seq_puts(ptr noundef %sf, ptr noundef nonnull @.str.246) #33
  br label %cpu_period_quota_print.exit

if.else.i:                                        ; preds = %tg_get_cfs_quota.exit
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.247, i32 noundef %extract.t268.i) #33
  br label %cpu_period_quota_print.exit

cpu_period_quota_print.exit:                      ; preds = %if.else.i, %if.then.i
  %asmresult10.i.i = extractvalue { i64, i32 } %5, 0
  %extract262.i = lshr i64 %asmresult10.i.i, 9
  %extract.t263.i = trunc i64 %extract262.i to i32
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.248, i32 noundef %extract.t263.i) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_max_write(ptr noundef %of, ptr nocapture noundef readonly %buf, i32 noundef %nbytes, i64 noundef %off) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %tok.i = alloca [21 x i8], align 1
  %period = alloca i64, align 8
  %quota = alloca i64, align 8
  %call = tail call ptr @of_css(ptr noundef %of) #33
  call void @llvm.lifetime.start.p0(i64 8, ptr nonnull %period) #33
  %period.i = getelementptr inbounds %struct.task_group, ptr %call, i32 0, i32 16, i32 1
  %0 = ptrtoint ptr %period.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %period.i, align 16
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %1, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %1, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %3, 0
  %4 = shl i64 %asmresult10.i.i, 23
  %conv = ashr i64 %4, 32
  %5 = ptrtoint ptr %period to i32
  call void @__asan_store8_noabort(i32 %5)
  store i64 %conv, ptr %period, align 8
  %burst.i = getelementptr inbounds %struct.task_group, ptr %call, i32 0, i32 16, i32 4
  %6 = ptrtoint ptr %burst.i to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %burst.i, align 8
  %8 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %7, i32 0) #40, !srcloc !1330
  %asmresult.i.i11 = extractvalue { i64, i32 } %8, 0
  %asmresult4.i.i12 = extractvalue { i64, i32 } %8, 1
  %9 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %7, i64 %asmresult.i.i11, i32 %asmresult4.i.i12) #40, !srcloc !1331
  %asmresult10.i.i13 = extractvalue { i64, i32 } %9, 0
  call void @llvm.lifetime.start.p0(i64 8, ptr nonnull %quota) #33
  %10 = ptrtoint ptr %quota to i32
  call void @__asan_store8_noabort(i32 %10)
  store i64 -1, ptr %quota, align 8, !annotation !1193
  call void @llvm.lifetime.start.p0(i64 21, ptr nonnull %tok.i) #33
  %11 = call ptr @memset(ptr %tok.i, i32 255, i32 21)
  %call.i = call i32 (ptr, ptr, ...) @sscanf(ptr noundef %buf, ptr noundef nonnull @.str.249, ptr noundef nonnull %tok.i, ptr noundef nonnull %period) #33
  %cmp.i = icmp slt i32 %call.i, 1
  br i1 %cmp.i, label %if.end.thread, label %if.end.i

if.end.i:                                         ; preds = %entry
  %12 = ptrtoint ptr %period to i32
  call void @__asan_load8_noabort(i32 %12)
  %13 = load i64, ptr %period, align 8
  %mul.i = mul i64 %13, 1000
  store i64 %mul.i, ptr %period, align 8
  %call2.i = call i32 (ptr, ptr, ...) @sscanf(ptr noundef nonnull %tok.i, ptr noundef nonnull @.str.250, ptr noundef nonnull %quota) #33
  %tobool.not.i = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i, label %if.else.i, label %if.then3.i

if.then3.i:                                       ; preds = %if.end.i
  %14 = ptrtoint ptr %quota to i32
  call void @__asan_load8_noabort(i32 %14)
  %15 = load i64, ptr %quota, align 8
  %mul4.i = mul i64 %15, 1000
  br label %if.end

if.else.i:                                        ; preds = %if.end.i
  %bcmp.i = call i32 @bcmp(ptr noundef nonnull dereferenceable(4) %tok.i, ptr noundef nonnull dereferenceable(4) @.str.246, i32 4) #35
  %tobool7.not.i = icmp eq i32 %bcmp.i, 0
  br i1 %tobool7.not.i, label %if.end, label %if.end.thread

if.end.thread:                                    ; preds = %if.else.i, %entry
  call void @llvm.lifetime.end.p0(i64 21, ptr nonnull %tok.i) #33
  br label %20

if.end:                                           ; preds = %if.else.i, %if.then3.i
  %storemerge.i = phi i64 [ %mul4.i, %if.then3.i ], [ -1, %if.else.i ]
  %16 = ptrtoint ptr %quota to i32
  call void @__asan_store8_noabort(i32 %16)
  store i64 %storemerge.i, ptr %quota, align 8
  call void @llvm.lifetime.end.p0(i64 21, ptr nonnull %tok.i) #33
  %17 = shl i64 %asmresult10.i.i13, 23
  %conv4 = ashr i64 %17, 32
  %18 = ptrtoint ptr %period to i32
  call void @__asan_load8_noabort(i32 %18)
  %19 = load i64, ptr %period, align 8
  %call6 = call fastcc i32 @tg_set_cfs_bandwidth(ptr noundef %call, i64 noundef %19, i64 noundef %storemerge.i, i64 noundef %conv4)
  %tobool7.not = icmp eq i32 %call6, 0
  %spec.select = select i1 %tobool7.not, i32 %nbytes, i32 %call6
  br label %20

20:                                               ; preds = %if.end, %if.end.thread
  %21 = phi i32 [ -22, %if.end.thread ], [ %spec.select, %if.end ]
  call void @llvm.lifetime.end.p0(i64 8, ptr nonnull %quota) #33
  call void @llvm.lifetime.end.p0(i64 8, ptr nonnull %period) #33
  ret i32 %21
}

; Function Attrs: argmemonly nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_cfs_burst_read_u64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #29 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %burst.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 4
  %0 = ptrtoint ptr %burst.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %burst.i, align 8
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %1, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %1, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %3, 0
  %4 = shl i64 %asmresult10.i.i, 23
  %conv = ashr i64 %4, 32
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cfs_burst_write_u64(ptr noundef %css, ptr nocapture noundef readnone %cftype, i64 noundef %cfs_burst_us) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = and i64 %cfs_burst_us, 2147483648
  %cmp.i.not = icmp eq i64 %0, 0
  br i1 %cmp.i.not, label %if.end.i, label %tg_set_cfs_burst.exit

if.end.i:                                         ; preds = %entry
  %conv12.i = and i64 %cfs_burst_us, 4294967295
  %mul.i = mul nuw nsw i64 %conv12.i, 1000
  %period3.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 1
  %1 = ptrtoint ptr %period3.i to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %period3.i, align 16
  %quota5.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 2
  %3 = ptrtoint ptr %quota5.i to i32
  call void @__asan_load8_noabort(i32 %3)
  %4 = load i64, ptr %quota5.i, align 8
  %call6.i = tail call fastcc i32 @tg_set_cfs_bandwidth(ptr noundef %css, i64 noundef %2, i64 noundef %4, i64 noundef %mul.i) #33
  br label %tg_set_cfs_burst.exit

tg_set_cfs_burst.exit:                            ; preds = %if.end.i, %entry
  %retval.0.i = phi i32 [ %call6.i, %if.end.i ], [ -22, %entry ]
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_uclamp_min_show(ptr noundef %sf, ptr nocapture noundef readnone %v) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @cpu_uclamp_print(ptr noundef %sf, i32 noundef 0)
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_uclamp_min_write(ptr noundef %of, ptr noundef %buf, i32 noundef %nbytes, i64 noundef %off) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @cpu_uclamp_write(ptr noundef %of, ptr noundef %buf, i32 noundef %nbytes, i32 noundef 0)
  ret i32 %call
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_uclamp_max_show(ptr noundef %sf, ptr nocapture noundef readnone %v) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  tail call fastcc void @cpu_uclamp_print(ptr noundef %sf, i32 noundef 1)
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_uclamp_max_write(ptr noundef %of, ptr noundef %buf, i32 noundef %nbytes, i64 noundef %off) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call = tail call fastcc i32 @cpu_uclamp_write(ptr noundef %of, ptr noundef %buf, i32 noundef %nbytes, i32 noundef 1)
  ret i32 %call
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_set_shares(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_set_idle(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @of_css(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @seq_puts(ptr noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @tg_set_cfs_bandwidth(ptr noundef %tg, i64 noundef %period, i64 noundef %quota, i64 noundef %burst) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %data.i = alloca %struct.cfs_schedulable_data, align 8
  %rf = alloca %struct.rq_flags, align 4
  %cfs_bandwidth = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16
  %cmp = icmp eq ptr %tg, @root_task_group
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %cmp1 = icmp ult i64 %quota, 1000000
  %0 = add i64 %period, -1000000001
  %1 = icmp ult i64 %0, -999000001
  %2 = or i1 %1, %cmp1
  br i1 %2, label %cleanup, label %if.end7

if.end7:                                          ; preds = %if.end
  %cmp8 = icmp ne i64 %quota, -1
  %3 = add i64 %quota, -17592186044415001
  %4 = icmp ult i64 %3, -17592186044415002
  br i1 %4, label %cleanup, label %if.end11

if.end11:                                         ; preds = %if.end7
  br i1 %cmp8, label %land.lhs.true13, label %if.end18

land.lhs.true13:                                  ; preds = %if.end11
  %cmp14 = icmp ugt i64 %burst, %quota
  %add = add i64 %burst, %quota
  %cmp16 = icmp ugt i64 %add, 17592186044415000
  %or.cond92 = or i1 %cmp14, %cmp16
  br i1 %or.cond92, label %cleanup, label %if.end18

if.end18:                                         ; preds = %land.lhs.true13, %if.end11
  tail call void @cpus_read_lock() #33
  tail call void @mutex_lock_nested(ptr noundef nonnull @cfs_constraints_mutex, i32 noundef 0) #33
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %data.i) #33
  %5 = ptrtoint ptr %data.i to i32
  call void @__asan_store8_noabort(i32 %5)
  store i64 -1, ptr %data.i, align 8
  store ptr %tg, ptr %data.i, align 8
  %period2.i = getelementptr inbounds %struct.cfs_schedulable_data, ptr %data.i, i32 0, i32 1
  %6 = ptrtoint ptr %period2.i to i32
  call void @__asan_store8_noabort(i32 %6)
  store i64 %period, ptr %period2.i, align 8
  %quota3.i = getelementptr inbounds %struct.cfs_schedulable_data, ptr %data.i, i32 0, i32 2
  %7 = ptrtoint ptr %quota3.i to i32
  call void @__asan_store8_noabort(i32 %7)
  store i64 %quota, ptr %quota3.i, align 8
  %cmp.not.i = icmp eq i64 %quota, -1
  br i1 %cmp.not.i, label %if.end428.i, label %if.end426.i

if.end426.i:                                      ; preds = %if.end18
  %8 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %period, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %8, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %8, 1
  %9 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %period, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %9, 0
  %storemerge.i = lshr i64 %asmresult10.i.i, 9
  %10 = ptrtoint ptr %period2.i to i32
  call void @__asan_store8_noabort(i32 %10)
  store i64 %storemerge.i, ptr %period2.i, align 8
  %11 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %quota, i32 0) #40, !srcloc !1330
  %asmresult.i592.i = extractvalue { i64, i32 } %11, 0
  %asmresult4.i593.i = extractvalue { i64, i32 } %11, 1
  %12 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %quota, i64 %asmresult.i592.i, i32 %asmresult4.i593.i) #40, !srcloc !1331
  %asmresult10.i594.i = extractvalue { i64, i32 } %12, 0
  %storemerge591.i = lshr i64 %asmresult10.i594.i, 9
  %13 = ptrtoint ptr %quota3.i to i32
  call void @__asan_store8_noabort(i32 %13)
  store i64 %storemerge591.i, ptr %quota3.i, align 8
  br label %if.end428.i

if.end428.i:                                      ; preds = %if.end426.i, %if.end18
  %14 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %14, -16384
  %15 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %15, i32 0, i32 1
  %16 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %16)
  %17 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %17, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true.i.i

land.lhs.true.i.i:                                ; preds = %if.end428.i
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %rcu_read_lock.exit.i, label %land.lhs.true2.i.i

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i.i, label %rcu_read_lock.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit.i

rcu_read_lock.exit.i:                             ; preds = %if.then.i.i, %land.lhs.true2.i.i, %land.lhs.true.i.i, %if.end428.i
  %call55.i.i.i = call fastcc i32 @tg_cfs_schedulable_down(ptr noundef nonnull @root_task_group, ptr noundef nonnull %data.i) #33
  %tobool.not56.i.i.i = icmp eq i32 %call55.i.i.i, 0
  br i1 %tobool.not56.i.i.i, label %do.body.i.i.i, label %walk_tg_tree.exit.i

do.body.i.i.i:                                    ; preds = %for.body.i.i.i, %rcu_read_lock.exit.i
  %parent.057.i.i.i = phi ptr [ %child.0.i.i.i, %for.body.i.i.i ], [ @root_task_group, %rcu_read_lock.exit.i ]
  %call2.i.i.i = tail call i32 @rcu_read_lock_any_held() #33
  %tobool3.not.i.i.i = icmp eq i32 %call2.i.i.i, 0
  br i1 %tobool3.not.i.i.i, label %land.lhs.true.i.i.i, label %do.end.i.i.i

land.lhs.true.i.i.i:                              ; preds = %do.body.i.i.i
  %call4.i.i.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool5.not.i.i.i = icmp eq i32 %call4.i.i.i, 0
  br i1 %tobool5.not.i.i.i, label %do.end.i.i.i, label %land.lhs.true6.i.i.i

land.lhs.true6.i.i.i:                             ; preds = %land.lhs.true.i.i.i
  %.b47.i.i.i = load i1, ptr @walk_tg_tree_from.__warned, align 1
  br i1 %.b47.i.i.i, label %do.end.i.i.i, label %if.then8.i.i.i

if.then8.i.i.i:                                   ; preds = %land.lhs.true6.i.i.i
  store i1 true, ptr @walk_tg_tree_from.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.1, i32 noundef 1192, ptr noundef nonnull @.str.4) #33
  br label %do.end.i.i.i

do.end.i.i.i:                                     ; preds = %if.then8.i.i.i, %land.lhs.true6.i.i.i, %land.lhs.true.i.i.i, %do.body.i.i.i
  %children.i.i.i = getelementptr inbounds %struct.task_group, ptr %parent.057.i.i.i, i32 0, i32 14
  %18 = ptrtoint ptr %children.i.i.i to i32
  call void @__asan_load4_noabort(i32 %18)
  %.pn51.i.i.i = load volatile ptr, ptr %children.i.i.i, align 4
  %cmp.not53.i.i.i = icmp eq ptr %.pn51.i.i.i, %children.i.i.i
  br i1 %cmp.not53.i.i.i, label %lor.lhs.false.i.i.i, label %for.body.i.i.i

for.cond.i.i.i:                                   ; preds = %if.end29.i.i.i
  %siblings21.i.i.i = getelementptr inbounds %struct.task_group, ptr %parent.154.i.i.i, i32 0, i32 13
  %19 = ptrtoint ptr %siblings21.i.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %.pn.i.i.i = load volatile ptr, ptr %siblings21.i.i.i, align 4
  %children14.i.i.i = getelementptr inbounds %struct.task_group, ptr %21, i32 0, i32 14
  %cmp.not.i.i.i = icmp eq ptr %.pn.i.i.i, %children14.i.i.i
  br i1 %cmp.not.i.i.i, label %lor.lhs.false.i.i.i, label %for.body.i.i.i

for.body.i.i.i:                                   ; preds = %for.cond.i.i.i, %do.end.i.i.i
  %.pn.lcssa.i.i.i = phi ptr [ %.pn51.i.i.i, %do.end.i.i.i ], [ %.pn.i.i.i, %for.cond.i.i.i ]
  %child.0.i.i.i = getelementptr i8, ptr %.pn.lcssa.i.i.i, i32 -412
  %call.i.i.i = call fastcc i32 @tg_cfs_schedulable_down(ptr noundef %child.0.i.i.i, ptr noundef nonnull %data.i) #33
  %tobool.not.i.i.i = icmp eq i32 %call.i.i.i, 0
  br i1 %tobool.not.i.i.i, label %do.body.i.i.i, label %walk_tg_tree.exit.i

lor.lhs.false.i.i.i:                              ; preds = %for.cond.i.i.i, %do.end.i.i.i
  %parent.154.i.i.i = phi ptr [ %21, %for.cond.i.i.i ], [ %parent.057.i.i.i, %do.end.i.i.i ]
  %cmp27.i.i.i = icmp eq ptr %parent.154.i.i.i, @root_task_group
  br i1 %cmp27.i.i.i, label %walk_tg_tree.exit.i, label %if.end29.i.i.i

if.end29.i.i.i:                                   ; preds = %lor.lhs.false.i.i.i
  %parent30.i.i.i = getelementptr inbounds %struct.task_group, ptr %parent.154.i.i.i, i32 0, i32 12
  %20 = ptrtoint ptr %parent30.i.i.i to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %parent30.i.i.i, align 8
  %tobool31.not.i.i.i = icmp eq ptr %21, null
  br i1 %tobool31.not.i.i.i, label %walk_tg_tree.exit.i, label %for.cond.i.i.i

walk_tg_tree.exit.i:                              ; preds = %if.end29.i.i.i, %lor.lhs.false.i.i.i, %for.body.i.i.i, %rcu_read_lock.exit.i
  %ret.0.i.i.i = phi i32 [ %call55.i.i.i, %rcu_read_lock.exit.i ], [ 0, %lor.lhs.false.i.i.i ], [ 0, %if.end29.i.i.i ], [ %call.i.i.i, %for.body.i.i.i ]
  %call.i595.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i595.i, label %__cfs_schedulable.exit, label %land.lhs.true.i598.i

land.lhs.true.i598.i:                             ; preds = %walk_tg_tree.exit.i
  %call1.i596.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i597.i = icmp eq i32 %call1.i596.i, 0
  br i1 %tobool.not.i597.i, label %__cfs_schedulable.exit, label %land.lhs.true2.i600.i

land.lhs.true2.i600.i:                            ; preds = %land.lhs.true.i598.i
  %.b4.i599.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i599.i, label %__cfs_schedulable.exit, label %if.then.i601.i

if.then.i601.i:                                   ; preds = %land.lhs.true2.i600.i
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %__cfs_schedulable.exit

__cfs_schedulable.exit:                           ; preds = %if.then.i601.i, %land.lhs.true2.i600.i, %land.lhs.true.i598.i, %walk_tg_tree.exit.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %22 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i602.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i.i.i.i602.i to ptr
  %preempt_count.i.i.i.i603.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i.i.i.i603.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i.i.i.i603.i, align 4
  %sub.i.i.i.i = add i32 %25, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i603.i, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %data.i) #33
  %tobool.not = icmp eq i32 %ret.0.i.i.i, 0
  br i1 %tobool.not, label %if.end20, label %out_unlock

if.end20:                                         ; preds = %__cfs_schedulable.exit
  %conv = zext i1 %cmp8 to i32
  %quota22 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 2
  %26 = ptrtoint ptr %quota22 to i32
  call void @__asan_load8_noabort(i32 %26)
  %27 = load i64, ptr %quota22, align 8
  %cmp23.not = icmp eq i64 %27, -1
  %28 = select i1 %cmp8, i1 %cmp23.not, i1 false
  br i1 %28, label %if.then28, label %if.end29

if.then28:                                        ; preds = %if.end20
  tail call void @cfs_bandwidth_usage_inc() #33
  br label %if.end29

if.end29:                                         ; preds = %if.then28, %if.end20
  tail call void @_raw_spin_lock_irq(ptr noundef %cfs_bandwidth) #33
  %period31 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 1
  %29 = ptrtoint ptr %period31 to i32
  call void @__asan_store8_noabort(i32 %29)
  store i64 %period, ptr %period31, align 8
  %30 = ptrtoint ptr %quota22 to i32
  call void @__asan_store8_noabort(i32 %30)
  store i64 %quota, ptr %quota22, align 8
  %burst33 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 4
  %31 = ptrtoint ptr %burst33 to i32
  call void @__asan_store8_noabort(i32 %31)
  store i64 %burst, ptr %burst33, align 8
  tail call void @__refill_cfs_bandwidth_runtime(ptr noundef %cfs_bandwidth) #33
  br i1 %cmp8, label %if.then35, label %if.end36

if.then35:                                        ; preds = %if.end29
  tail call void @start_cfs_bandwidth(ptr noundef %cfs_bandwidth) #33
  br label %if.end36

if.end36:                                         ; preds = %if.then35, %if.end29
  tail call void @_raw_spin_unlock_irq(ptr noundef %cfs_bandwidth) #33
  %call3898 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_online_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %32 = load i32, ptr @nr_cpu_ids, align 4
  %cmp3999 = icmp ult i32 %call3898, %32
  br i1 %cmp3999, label %for.body.lr.ph, label %for.end

for.body.lr.ph:                                   ; preds = %if.end36
  %cfs_rq41 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 2
  %33 = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  br label %for.body

for.body:                                         ; preds = %rq_unlock_irq.exit, %for.body.lr.ph
  %call38100 = phi i32 [ %call3898, %for.body.lr.ph ], [ %call38, %rq_unlock_irq.exit ]
  %34 = ptrtoint ptr %cfs_rq41 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load ptr, ptr %cfs_rq41, align 4
  %arrayidx = getelementptr ptr, ptr %35, i32 %call38100
  %36 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %arrayidx, align 4
  %rq42 = getelementptr inbounds %struct.cfs_rq, ptr %37, i32 0, i32 27
  %38 = ptrtoint ptr %rq42 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load ptr, ptr %rq42, align 4
  call void @llvm.lifetime.start.p0(i64 12, ptr nonnull %rf) #33
  %40 = ptrtoint ptr %rf to i32
  call void @__asan_store4_noabort(i32 %40)
  store i32 -1, ptr %rf, align 4, !annotation !1193
  %41 = ptrtoint ptr %33 to i32
  call void @__asan_store4_noabort(i32 %41)
  store i32 -1, ptr %33, align 4, !annotation !1193
  call fastcc void @rq_lock_irq(ptr noundef %39, ptr noundef nonnull %rf)
  %runtime_enabled43 = getelementptr inbounds %struct.cfs_rq, ptr %37, i32 0, i32 32
  %42 = ptrtoint ptr %runtime_enabled43 to i32
  call void @__asan_store4_noabort(i32 %42)
  store i32 %conv, ptr %runtime_enabled43, align 4
  %runtime_remaining = getelementptr inbounds %struct.cfs_rq, ptr %37, i32 0, i32 33
  %43 = ptrtoint ptr %runtime_remaining to i32
  call void @__asan_store8_noabort(i32 %43)
  store i64 0, ptr %runtime_remaining, align 8
  %throttled = getelementptr inbounds %struct.cfs_rq, ptr %37, i32 0, i32 37
  %44 = ptrtoint ptr %throttled to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %throttled, align 8
  %tobool44.not = icmp eq i32 %45, 0
  br i1 %tobool44.not, label %if.end46, label %if.then45

if.then45:                                        ; preds = %for.body
  tail call void @unthrottle_cfs_rq(ptr noundef %37) #33
  br label %if.end46

if.end46:                                         ; preds = %if.then45, %for.body
  %core_enabled.i.i.i = getelementptr inbounds %struct.rq, ptr %39, i32 0, i32 81
  %46 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool.not.i.i.i96 = icmp eq i32 %47, 0
  br i1 %tobool.not.i.i.i96, label %rq_unpin_lock.exit.i, label %if.then.i.i.i

if.then.i.i.i:                                    ; preds = %if.end46
  %core.i.i.i = getelementptr inbounds %struct.rq, ptr %39, i32 0, i32 79
  %48 = ptrtoint ptr %core.i.i.i to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load ptr, ptr %core.i.i.i, align 8
  br label %rq_unpin_lock.exit.i

rq_unpin_lock.exit.i:                             ; preds = %if.then.i.i.i, %if.end46
  %retval.0.i.i.i = phi ptr [ %49, %if.then.i.i.i ], [ %39, %if.end46 ]
  %dep_map.i.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i.i, i32 0, i32 4
  %50 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %50)
  %.unpack.i.i = load i32, ptr %33, align 4
  %51 = insertvalue [1 x i32] undef, i32 %.unpack.i.i, 0
  tail call void @lock_unpin_lock(ptr noundef %dep_map.i.i, [1 x i32] %51) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@tg_set_cfs_bandwidth, %land.rhs.i.i.i.i.i)) #33
          to label %rq_unlock_irq.exit [label %land.rhs.i.i.i.i.i], !srcloc !1202

land.rhs.i.i.i.i.i:                               ; preds = %rq_unpin_lock.exit.i
  %52 = ptrtoint ptr %core_enabled.i.i.i to i32
  call void @__asan_load4_noabort(i32 %52)
  %53 = load i32, ptr %core_enabled.i.i.i, align 128
  %tobool3.i.not.i.i.i.i = icmp eq i32 %53, 0
  br i1 %tobool3.i.not.i.i.i.i, label %rq_unlock_irq.exit, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %land.rhs.i.i.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %39, i32 0, i32 79
  %54 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %54)
  %55 = load ptr, ptr %core.i.i.i.i, align 8
  br label %rq_unlock_irq.exit

rq_unlock_irq.exit:                               ; preds = %if.then.i.i.i.i, %land.rhs.i.i.i.i.i, %rq_unpin_lock.exit.i
  %retval.0.i.i.i.i = phi ptr [ %55, %if.then.i.i.i.i ], [ %39, %land.rhs.i.i.i.i.i ], [ %39, %rq_unpin_lock.exit.i ]
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  tail call void @trace_hardirqs_on() #33
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #33, !srcloc !1278
  call void @llvm.lifetime.end.p0(i64 12, ptr nonnull %rf) #33
  %call38 = tail call i32 @cpumask_next(i32 noundef %call38100, ptr noundef nonnull @__cpu_online_mask) #37
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %56 = load i32, ptr @nr_cpu_ids, align 4
  %cmp39 = icmp ult i32 %call38, %56
  br i1 %cmp39, label %for.body, label %for.end

for.end:                                          ; preds = %rq_unlock_irq.exit, %if.end36
  %brmerge93 = or i1 %cmp8, %cmp23.not
  br i1 %brmerge93, label %out_unlock, label %if.then50

if.then50:                                        ; preds = %for.end
  tail call void @cfs_bandwidth_usage_dec() #33
  br label %out_unlock

out_unlock:                                       ; preds = %if.then50, %for.end, %__cfs_schedulable.exit
  tail call void @mutex_unlock(ptr noundef nonnull @cfs_constraints_mutex) #33
  tail call void @cpus_read_unlock() #33
  br label %cleanup

cleanup:                                          ; preds = %out_unlock, %land.lhs.true13, %if.end7, %if.end, %entry
  %retval.0 = phi i32 [ %ret.0.i.i.i, %out_unlock ], [ -22, %entry ], [ -22, %if.end ], [ -22, %if.end7 ], [ -22, %land.lhs.true13 ]
  ret i32 %retval.0
}

; Function Attrs: nofree nounwind null_pointer_is_valid
declare dso_local noundef i32 @sscanf(ptr nocapture noundef readonly, ptr nocapture noundef readonly, ...) local_unnamed_addr #16

; Function Attrs: null_pointer_is_valid
declare dso_local void @cfs_bandwidth_usage_inc() local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @__refill_cfs_bandwidth_runtime(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @start_cfs_bandwidth(ptr noundef) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rq_lock_irq(ptr noundef %rq, ptr nocapture noundef writeonly %rf) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #33, !srcloc !1217
  %and.i.i.i = and i32 %0, 128
  %tobool.not.i = icmp eq i32 %and.i.i.i, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #33, !srcloc !1279
  br i1 %tobool.not.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  tail call void @trace_hardirqs_off() #33
  br label %if.end.i

if.end.i:                                         ; preds = %if.then.i, %entry
  %1 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %add.i.i.i.i = add i32 %4, 1
  store volatile i32 %add.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1201
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @__sched_core_enabled, ptr blockaddress(@rq_lock_irq, %for.cond.i.i.i)) #33
          to label %if.then.i.i.i [label %for.cond.i.i.i], !srcloc !1202

if.then.i.i.i:                                    ; preds = %if.end.i
  tail call void @_raw_spin_lock_nested(ptr noundef %rq, i32 noundef 0) #33
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1203
  br label %raw_spin_rq_lock_irq.exit

for.cond.i.i.i:                                   ; preds = %if.end11.i.i.i, %if.end.i
  %core_enabled.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %5 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i.i.i.i = icmp eq i32 %6, 0
  br i1 %tobool.not.i.i.i.i, label %__rq_lockp.exit.i.i.i, label %if.then.i.i.i.i

if.then.i.i.i.i:                                  ; preds = %for.cond.i.i.i
  %core.i.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %7 = ptrtoint ptr %core.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load ptr, ptr %core.i.i.i.i, align 8
  br label %__rq_lockp.exit.i.i.i

__rq_lockp.exit.i.i.i:                            ; preds = %if.then.i.i.i.i, %for.cond.i.i.i
  %retval.0.i.i.i.i = phi ptr [ %8, %if.then.i.i.i.i ], [ %rq, %for.cond.i.i.i ]
  tail call void @_raw_spin_lock_nested(ptr noundef %retval.0.i.i.i.i, i32 noundef 0) #33
  %9 = ptrtoint ptr %core_enabled.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %core_enabled.i.i.i.i, align 128
  %tobool.not.i23.i.i.i = icmp eq i32 %10, 0
  br i1 %tobool.not.i23.i.i.i, label %__rq_lockp.exit27.i.i.i, label %if.then.i25.i.i.i

if.then.i25.i.i.i:                                ; preds = %__rq_lockp.exit.i.i.i
  %core.i24.i.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %11 = ptrtoint ptr %core.i24.i.i.i to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %core.i24.i.i.i, align 8
  br label %__rq_lockp.exit27.i.i.i

__rq_lockp.exit27.i.i.i:                          ; preds = %if.then.i25.i.i.i, %__rq_lockp.exit.i.i.i
  %retval.0.i26.i.i.i = phi ptr [ %12, %if.then.i25.i.i.i ], [ %rq, %__rq_lockp.exit.i.i.i ]
  %cmp.i.i.i = icmp eq ptr %retval.0.i.i.i.i, %retval.0.i26.i.i.i
  br i1 %cmp.i.i.i, label %do.body8.i.i.i, label %if.end11.i.i.i, !prof !1191

do.body8.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1204
  br label %raw_spin_rq_lock_irq.exit

if.end11.i.i.i:                                   ; preds = %__rq_lockp.exit27.i.i.i
  tail call void @_raw_spin_unlock(ptr noundef %retval.0.i.i.i.i) #33
  br label %for.cond.i.i.i

raw_spin_rq_lock_irq.exit:                        ; preds = %do.body8.i.i.i, %if.then.i.i.i
  %13 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i19.i.i.i = and i32 %13, -16384
  %14 = inttoptr i32 %and.i.i.i19.i.i.i to ptr
  %preempt_count.i.i20.i.i.i = getelementptr inbounds %struct.thread_info, ptr %14, i32 0, i32 1
  %15 = ptrtoint ptr %preempt_count.i.i20.i.i.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load volatile i32, ptr %preempt_count.i.i20.i.i.i, align 4
  %sub.i21.i.i.i = add i32 %16, -1
  store volatile i32 %sub.i21.i.i.i, ptr %preempt_count.i.i20.i.i.i, align 4
  %cookie.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 1
  %core_enabled.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 81
  %17 = ptrtoint ptr %core_enabled.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %core_enabled.i.i, align 128
  %tobool.not.i.i = icmp eq i32 %18, 0
  br i1 %tobool.not.i.i, label %__rq_lockp.exit.i, label %if.then.i.i

if.then.i.i:                                      ; preds = %raw_spin_rq_lock_irq.exit
  %core.i.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 79
  %19 = ptrtoint ptr %core.i.i to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %core.i.i, align 8
  br label %__rq_lockp.exit.i

__rq_lockp.exit.i:                                ; preds = %if.then.i.i, %raw_spin_rq_lock_irq.exit
  %retval.0.i.i = phi ptr [ %20, %if.then.i.i ], [ %rq, %raw_spin_rq_lock_irq.exit ]
  %dep_map.i = getelementptr inbounds %struct.raw_spinlock, ptr %retval.0.i.i, i32 0, i32 4
  %call1.i = tail call i32 @lock_pin_lock(ptr noundef %dep_map.i) #33
  %21 = ptrtoint ptr %cookie.i to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 %call1.i, ptr %cookie.i, align 4
  %clock_update_flags.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 25
  %22 = ptrtoint ptr %clock_update_flags.i to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load i32, ptr %clock_update_flags.i, align 4
  %and.i = and i32 %23, 3
  store i32 %and.i, ptr %clock_update_flags.i, align 4
  %clock_update_flags2.i = getelementptr inbounds %struct.rq_flags, ptr %rf, i32 0, i32 2
  %24 = ptrtoint ptr %clock_update_flags2.i to i32
  call void @__asan_store4_noabort(i32 %24)
  store i32 0, ptr %clock_update_flags2.i, align 4
  %balance_callback.i = getelementptr inbounds %struct.rq, ptr %rq, i32 0, i32 39
  %25 = ptrtoint ptr %balance_callback.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %balance_callback.i, align 8
  %tobool.not.i2 = icmp ne ptr %26, null
  %cmp.i = icmp ne ptr %26, @balance_push_callback
  %spec.select.i = and i1 %tobool.not.i2, %cmp.i
  br i1 %spec.select.i, label %land.rhs6.i, label %rq_pin_lock.exit

land.rhs6.i:                                      ; preds = %__rq_lockp.exit.i
  %.b48.i = load i1, ptr @rq_pin_lock.__already_done, align 1
  br i1 %.b48.i, label %rq_pin_lock.exit, label %if.then.i3, !prof !1191

if.then.i3:                                       ; preds = %land.rhs6.i
  store i1 true, ptr @rq_pin_lock.__already_done, align 1
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.177, i32 noundef 1545, i32 noundef 9, ptr noundef nonnull @.str.178) #33
  br label %rq_pin_lock.exit

rq_pin_lock.exit:                                 ; preds = %if.then.i3, %land.rhs6.i, %__rq_lockp.exit.i
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @unthrottle_cfs_rq(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local void @cfs_bandwidth_usage_dec() local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @tg_cfs_schedulable_down(ptr noundef %tg, ptr nocapture noundef readonly %data) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %parent = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 12
  %0 = ptrtoint ptr %parent to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %parent, align 8
  %tobool.not = icmp eq ptr %1, null
  br i1 %tobool.not, label %if.end19, label %if.else

if.else:                                          ; preds = %entry
  %2 = ptrtoint ptr %data to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %data, align 8
  %cmp.i = icmp eq ptr %3, %tg
  br i1 %cmp.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %if.else
  %period2.i = getelementptr inbounds %struct.cfs_schedulable_data, ptr %data, i32 0, i32 1
  %4 = ptrtoint ptr %period2.i to i32
  call void @__asan_load8_noabort(i32 %4)
  %5 = load i64, ptr %period2.i, align 8
  %quota3.i = getelementptr inbounds %struct.cfs_schedulable_data, ptr %data, i32 0, i32 2
  %6 = ptrtoint ptr %quota3.i to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %quota3.i, align 8
  br label %if.end.i

if.else.i:                                        ; preds = %if.else
  %period.i.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 1
  %8 = ptrtoint ptr %period.i.i to i32
  call void @__asan_load8_noabort(i32 %8)
  %9 = load i64, ptr %period.i.i, align 16
  %10 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %9, i32 0) #40, !srcloc !1330
  %asmresult.i.i.i = extractvalue { i64, i32 } %10, 0
  %asmresult4.i.i.i = extractvalue { i64, i32 } %10, 1
  %11 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %9, i64 %asmresult.i.i.i, i32 %asmresult4.i.i.i) #40, !srcloc !1331
  %asmresult10.i.i.i = extractvalue { i64, i32 } %11, 0
  %12 = shl i64 %asmresult10.i.i.i, 23
  %conv.i = ashr i64 %12, 32
  %quota.i.i = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 2
  %13 = ptrtoint ptr %quota.i.i to i32
  call void @__asan_load8_noabort(i32 %13)
  %14 = load i64, ptr %quota.i.i, align 8
  %cmp.i.i = icmp eq i64 %14, -1
  br i1 %cmp.i.i, label %tg_get_cfs_quota.exit.i, label %if.end159.i.i

if.end159.i.i:                                    ; preds = %if.else.i
  %15 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %14, i32 0) #40, !srcloc !1330
  %asmresult.i.i21.i = extractvalue { i64, i32 } %15, 0
  %asmresult4.i.i22.i = extractvalue { i64, i32 } %15, 1
  %16 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %14, i64 %asmresult.i.i21.i, i32 %asmresult4.i.i22.i) #40, !srcloc !1331
  %asmresult10.i.i23.i = extractvalue { i64, i32 } %16, 0
  %extract267.i.i = lshr i64 %asmresult10.i.i23.i, 9
  %extract.t268.i.i = trunc i64 %extract267.i.i to i32
  br label %tg_get_cfs_quota.exit.i

tg_get_cfs_quota.exit.i:                          ; preds = %if.end159.i.i, %if.else.i
  %retval.0.i.i = phi i32 [ -1, %if.else.i ], [ %extract.t268.i.i, %if.end159.i.i ]
  %conv5.i = sext i32 %retval.0.i.i to i64
  br label %if.end.i

if.end.i:                                         ; preds = %tg_get_cfs_quota.exit.i, %if.then.i
  %quota.0.i = phi i64 [ %7, %if.then.i ], [ %conv5.i, %tg_get_cfs_quota.exit.i ]
  %period.0.i = phi i64 [ %5, %if.then.i ], [ %conv.i, %tg_get_cfs_quota.exit.i ]
  %cmp6.i = icmp eq i64 %quota.0.i, -1
  br i1 %cmp6.i, label %normalize_cfs_quota.exit, label %if.end.i.i

if.end.i.i:                                       ; preds = %if.end.i
  %cmp1.i.i = icmp eq i64 %period.0.i, 0
  br i1 %cmp1.i.i, label %to_ratio.exit.i, label %if.end3.i.i

if.end3.i.i:                                      ; preds = %if.end.i.i
  %shl.i.i = shl i64 %quota.0.i, 20
  %call.i.i = tail call i64 @div64_u64(i64 noundef %shl.i.i, i64 noundef %period.0.i) #33
  %conv.i.i = trunc i64 %call.i.i to i32
  br label %to_ratio.exit.i

to_ratio.exit.i:                                  ; preds = %if.end3.i.i, %if.end.i.i
  %retval.0.i25.i = phi i32 [ %conv.i.i, %if.end3.i.i ], [ 0, %if.end.i.i ]
  %conv13.i = zext i32 %retval.0.i25.i to i64
  br label %normalize_cfs_quota.exit

normalize_cfs_quota.exit:                         ; preds = %to_ratio.exit.i, %if.end.i
  %retval.0.i38 = phi i64 [ %conv13.i, %to_ratio.exit.i ], [ -1, %if.end.i ]
  %hierarchical_quota = getelementptr inbounds %struct.task_group, ptr %1, i32 0, i32 16, i32 6
  %17 = ptrtoint ptr %hierarchical_quota to i32
  call void @__asan_load8_noabort(i32 %17)
  %18 = load i64, ptr %hierarchical_quota, align 8
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr getelementptr inbounds (i8, ptr @cpu_cgrp_subsys_on_dfl_key, i32 1), ptr blockaddress(@tg_cfs_schedulable_down, %if.else10)) #33
          to label %if.then8 [label %if.else10], !srcloc !1202

if.then8:                                         ; preds = %normalize_cfs_quota.exit
  %19 = tail call i64 @llvm.smin.i64(i64 %retval.0.i38, i64 %18)
  br label %if.end19

if.else10:                                        ; preds = %normalize_cfs_quota.exit
  %cmp11 = icmp eq i64 %retval.0.i38, -1
  br i1 %cmp11, label %if.end19, label %if.else13

if.else13:                                        ; preds = %if.else10
  %cmp14.not = icmp ne i64 %18, -1
  %cmp15 = icmp sgt i64 %retval.0.i38, %18
  %or.cond = select i1 %cmp14.not, i1 %cmp15, i1 false
  br i1 %or.cond, label %cleanup21, label %if.end19

if.end19:                                         ; preds = %if.else13, %if.else10, %if.then8, %entry
  %quota.2 = phi i64 [ -1, %entry ], [ %19, %if.then8 ], [ %retval.0.i38, %if.else13 ], [ %18, %if.else10 ]
  %hierarchical_quota20 = getelementptr inbounds %struct.task_group, ptr %tg, i32 0, i32 16, i32 6
  %20 = ptrtoint ptr %hierarchical_quota20 to i32
  call void @__asan_store8_noabort(i32 %20)
  store i64 %quota.2, ptr %hierarchical_quota20, align 8
  br label %cleanup21

cleanup21:                                        ; preds = %if.end19, %if.else13
  %retval.1 = phi i32 [ 0, %if.end19 ], [ -22, %if.else13 ]
  ret i32 %retval.1
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @cpu_uclamp_print(ptr noundef %sf, i32 noundef %clamp_id) unnamed_addr #3 align 64 {
entry:
  %0 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %entry
  %private.i = getelementptr inbounds %struct.seq_file, ptr %sf, i32 0, i32 11
  %4 = ptrtoint ptr %private.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %private.i, align 8
  %call.i14 = tail call ptr @of_css(ptr noundef %5) #33
  %arrayidx = getelementptr %struct.task_group, ptr %call.i14, i32 0, i32 18, i32 %clamp_id
  %6 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load2_noabort(i32 %6)
  %bf.load = load i16, ptr %arrayidx, align 4
  %call.i15 = tail call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i15, label %rcu_read_unlock.exit, label %land.lhs.true.i18

land.lhs.true.i18:                                ; preds = %rcu_read_lock.exit
  %call1.i16 = tail call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i17 = icmp eq i32 %call1.i16, 0
  br i1 %tobool.not.i17, label %rcu_read_unlock.exit, label %land.lhs.true2.i20

land.lhs.true2.i20:                               ; preds = %land.lhs.true.i18
  %.b4.i19 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i19, label %rcu_read_unlock.exit, label %if.then.i21

if.then.i21:                                      ; preds = %land.lhs.true2.i20
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i21, %land.lhs.true2.i20, %land.lhs.true.i18, %rcu_read_lock.exit
  tail call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %7 = tail call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i22 = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i.i.i.i22 to ptr
  %preempt_count.i.i.i.i23 = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i.i.i.i23 to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i.i.i.i23, align 4
  %sub.i.i.i = add i32 %10, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i23, align 4
  tail call void @rcu_read_unlock_strict() #33
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  %bf.lshr.mask = and i16 %bf.load, -32
  %cmp = icmp eq i16 %bf.lshr.mask, -32768
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %rcu_read_unlock.exit
  tail call void @seq_puts(ptr noundef %sf, ptr noundef nonnull @.str.253) #33
  br label %cleanup

if.end:                                           ; preds = %rcu_read_unlock.exit
  %arrayidx3 = getelementptr %struct.task_group, ptr %call.i14, i32 0, i32 17, i32 %clamp_id
  %11 = ptrtoint ptr %arrayidx3 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %arrayidx3, align 4
  %conv4 = zext i32 %12 to i64
  %13 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -6640827866535438582, i64 %conv4, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %13, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %13, 1
  %14 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -6640827866535438582, i64 %conv4, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %14, 0
  %div1581.i = lshr i64 %asmresult10.i.i, 6
  %conv159.i = trunc i64 %div1581.i to i32
  %mul160.neg.i = mul i32 %conv159.i, -100
  %sub161.i = add i32 %mul160.neg.i, %12
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.254, i64 noundef %div1581.i, i32 noundef 2, i32 noundef %sub161.i) #33
  br label %cleanup

cleanup:                                          ; preds = %if.end, %if.then
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc i32 @cpu_uclamp_write(ptr noundef %of, ptr noundef %buf, i32 noundef %nbytes, i32 noundef %clamp_id) unnamed_addr #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %tmp = alloca %struct.uclamp_request, align 8
  call void @llvm.lifetime.start.p0(i64 24, ptr nonnull %tmp) #33
  tail call void @llvm.experimental.noalias.scope.decl(metadata !1346)
  %0 = call ptr @memcpy(ptr %tmp, ptr @__const.capacity_from_percent.req, i32 24)
  %call.i1 = tail call ptr @strim(ptr noundef %buf) #33, !noalias !1346
  %call1.i2 = tail call i32 @strcmp(ptr noundef %call.i1, ptr noundef nonnull dereferenceable(4) @.str.246) #35, !noalias !1346
  %tobool.not.i3 = icmp eq i32 %call1.i2, 0
  br i1 %tobool.not.i3, label %capacity_from_percent.exit, label %if.then.i4

if.then.i4:                                       ; preds = %entry
  %call2.i = call i32 @cgroup_parse_float(ptr noundef %call.i1, i32 noundef 2, ptr noundef nonnull %tmp) #33
  %ret.i = getelementptr inbounds %struct.uclamp_request, ptr %tmp, i32 0, i32 2
  %1 = ptrtoint ptr %ret.i to i32
  call void @__asan_store4_noabort(i32 %1)
  store i32 %call2.i, ptr %ret.i, align 8, !alias.scope !1346
  %tobool4.not.i = icmp eq i32 %call2.i, 0
  br i1 %tobool4.not.i, label %if.end.i, label %capacity_from_percent.exit

if.end.i:                                         ; preds = %if.then.i4
  %2 = ptrtoint ptr %tmp to i32
  call void @__asan_load8_noabort(i32 %2)
  %3 = load i64, ptr %tmp, align 8, !alias.scope !1346
  %cmp.i = icmp ugt i64 %3, 10000
  br i1 %cmp.i, label %if.then7.i, label %if.end199.i

if.then7.i:                                       ; preds = %if.end.i
  %4 = ptrtoint ptr %ret.i to i32
  call void @__asan_store4_noabort(i32 %4)
  store i32 -34, ptr %ret.i, align 8, !alias.scope !1346
  br label %capacity_from_percent.exit

if.end199.i:                                      ; preds = %if.end.i
  %shl.i = shl nuw nsw i64 %3, 10
  %util.i = getelementptr inbounds %struct.uclamp_request, ptr %tmp, i32 0, i32 1
  %add.i = add nuw nsw i64 %shl.i, 5000
  %5 = call i64 asm "umull\09${0:Q}, ${0:R}, ${1:Q}, ${2:Q}\0A\09mov\09${0:Q}, #0", "=&r,r,r,~{cc}"(i64 3777893186295716171, i64 %add.i) #40, !srcloc !1349
  %6 = call i64 asm "umlal\09${0:R}, ${0:Q}, ${1:R}, ${2:Q}\0A\09umlal\09${0:R}, ${0:Q}, ${1:Q}, ${2:R}\0A\09mov\09${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${1:R}, ${2:R}", "=&r,r,r,0,~{cc}"(i64 3777893186295716171, i64 %add.i, i64 %5) #40, !srcloc !1350
  %div179286.i = lshr i64 %6, 11
  %7 = ptrtoint ptr %util.i to i32
  call void @__asan_store8_noabort(i32 %7)
  store i64 %div179286.i, ptr %util.i, align 8, !alias.scope !1346
  br label %capacity_from_percent.exit

capacity_from_percent.exit:                       ; preds = %if.end199.i, %if.then7.i, %if.then.i4, %entry
  %8 = ptrtoint ptr %tmp to i32
  call void @__asan_load8_noabort(i32 %8)
  %req.sroa.0.0.copyload16 = load i64, ptr %tmp, align 8
  %req.sroa.5.0.tmp.sroa_idx = getelementptr inbounds i8, ptr %tmp, i32 8
  %9 = ptrtoint ptr %req.sroa.5.0.tmp.sroa_idx to i32
  call void @__asan_load8_noabort(i32 %9)
  %req.sroa.5.0.copyload17 = load i64, ptr %req.sroa.5.0.tmp.sroa_idx, align 8
  %req.sroa.7.0.tmp.sroa_idx = getelementptr inbounds i8, ptr %tmp, i32 16
  %10 = ptrtoint ptr %req.sroa.7.0.tmp.sroa_idx to i32
  call void @__asan_load4_noabort(i32 %10)
  %req.sroa.7.0.copyload19 = load i32, ptr %req.sroa.7.0.tmp.sroa_idx, align 8
  call void @llvm.lifetime.end.p0(i64 24, ptr nonnull %tmp) #33
  %tobool.not = icmp eq i32 %req.sroa.7.0.copyload19, 0
  br i1 %tobool.not, label %if.end, label %cleanup

if.end:                                           ; preds = %capacity_from_percent.exit
  call void @static_key_enable(ptr noundef nonnull @sched_uclamp_used) #33
  call void @mutex_lock_nested(ptr noundef nonnull @uclamp_mutex, i32 noundef 0) #33
  %11 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %14, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1229
  call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #33
  %call.i = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i, label %rcu_read_lock.exit, label %land.lhs.true.i

land.lhs.true.i:                                  ; preds = %if.end
  %call1.i = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %rcu_read_lock.exit, label %land.lhs.true2.i

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %rcu_read_lock.exit, label %if.then.i

if.then.i:                                        ; preds = %land.lhs.true2.i
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 696, ptr noundef nonnull @.str.182) #33
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i, %land.lhs.true.i, %if.end
  %call = call ptr @of_css(ptr noundef %of) #33
  %arrayidx = getelementptr %struct.task_group, ptr %call, i32 0, i32 18, i32 %clamp_id
  %15 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load2_noabort(i32 %15)
  %bf.load = load i16, ptr %arrayidx, align 4
  %bf.lshr = lshr i16 %bf.load, 5
  %conv = zext i16 %bf.lshr to i64
  %cmp.not = icmp eq i64 %req.sroa.5.0.copyload17, %conv
  br i1 %cmp.not, label %if.end9, label %if.then4

if.then4:                                         ; preds = %rcu_read_lock.exit
  %conv8 = trunc i64 %req.sroa.5.0.copyload17 to i32
  %16 = trunc i64 %req.sroa.5.0.copyload17 to i16
  %bf.shl.i = shl i16 %16, 5
  %bf.clear.i = and i16 %bf.load, 2
  %bf.set.i = or i16 %bf.clear.i, %bf.shl.i
  %cmp10.i.i = icmp ult i32 %conv8, 820
  %div8.i.i = udiv i32 %conv8, 205
  %17 = trunc i32 %div8.i.i to i16
  %.op.i = shl i16 %17, 2
  %.op.op.i = and i16 %.op.i, 28
  %bf.shl3.i = select i1 %cmp10.i.i, i16 %.op.op.i, i16 16
  %bf.set5.i = or i16 %bf.set.i, %bf.shl3.i
  %18 = ptrtoint ptr %arrayidx to i32
  call void @__asan_store2_noabort(i32 %18)
  store i16 %bf.set5.i, ptr %arrayidx, align 4
  br label %if.end9

if.end9:                                          ; preds = %if.then4, %rcu_read_lock.exit
  %conv10 = trunc i64 %req.sroa.0.0.copyload16 to i32
  %arrayidx11 = getelementptr %struct.task_group, ptr %call, i32 0, i32 17, i32 %clamp_id
  %19 = ptrtoint ptr %arrayidx11 to i32
  call void @__asan_store4_noabort(i32 %19)
  store i32 %conv10, ptr %arrayidx11, align 4
  %call12 = call ptr @of_css(ptr noundef %of) #33
  call fastcc void @cpu_util_update_eff(ptr noundef %call12)
  %call.i5 = call zeroext i1 @rcu_is_watching() #33
  br i1 %call.i5, label %rcu_read_unlock.exit, label %land.lhs.true.i8

land.lhs.true.i8:                                 ; preds = %if.end9
  %call1.i6 = call i32 @debug_lockdep_rcu_enabled() #33
  %tobool.not.i7 = icmp eq i32 %call1.i6, 0
  br i1 %tobool.not.i7, label %rcu_read_unlock.exit, label %land.lhs.true2.i10

land.lhs.true2.i10:                               ; preds = %land.lhs.true.i8
  %.b4.i9 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i9, label %rcu_read_unlock.exit, label %if.then.i11

if.then.i11:                                      ; preds = %land.lhs.true2.i10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.181, i32 noundef 724, ptr noundef nonnull @.str.183) #33
  br label %rcu_read_unlock.exit

rcu_read_unlock.exit:                             ; preds = %if.then.i11, %land.lhs.true2.i10, %land.lhs.true.i8, %if.end9
  call void asm sideeffect "", "~{memory}"() #33, !srcloc !1230
  %20 = call i32 @llvm.read_register.i32(metadata !1181) #33
  %and.i.i.i.i.i12 = and i32 %20, -16384
  %21 = inttoptr i32 %and.i.i.i.i.i12 to ptr
  %preempt_count.i.i.i.i13 = getelementptr inbounds %struct.thread_info, ptr %21, i32 0, i32 1
  %22 = ptrtoint ptr %preempt_count.i.i.i.i13 to i32
  call void @__asan_load4_noabort(i32 %22)
  %23 = load volatile i32, ptr %preempt_count.i.i.i.i13, align 4
  %sub.i.i.i = add i32 %23, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i13, align 4
  call void @rcu_read_unlock_strict() #33
  call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #33
  call void @mutex_unlock(ptr noundef nonnull @uclamp_mutex) #33
  br label %cleanup

cleanup:                                          ; preds = %rcu_read_unlock.exit, %capacity_from_percent.exit
  %retval.0 = phi i32 [ %nbytes, %rcu_read_unlock.exit ], [ %req.sroa.7.0.copyload19, %capacity_from_percent.exit ]
  ret i32 %retval.0
}

; Function Attrs: null_pointer_is_valid
declare dso_local ptr @strim(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @cgroup_parse_float(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #2

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync)
define internal i64 @cpu_shares_read_u64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #8 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %shares = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 3
  %0 = ptrtoint ptr %shares to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load i32, ptr %shares, align 16
  %conv = zext i32 %1 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_shares_write_u64(ptr noundef %css, ptr nocapture noundef readnone %cftype, i64 noundef %shareval) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %cmp = icmp ugt i64 %shareval, 4294967295
  %0 = trunc i64 %shareval to i32
  %conv = select i1 %cmp, i32 262144, i32 %0
  %call1 = tail call i32 @sched_group_set_shares(ptr noundef %css, i32 noundef %conv) #33
  ret i32 %call1
}

; Function Attrs: argmemonly nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_cfs_quota_read_s64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #29 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %quota.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 2
  %0 = ptrtoint ptr %quota.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %quota.i, align 8
  %cmp.i = icmp eq i64 %1, -1
  br i1 %cmp.i, label %tg_get_cfs_quota.exit, label %if.end159.i

if.end159.i:                                      ; preds = %entry
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %1, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %1, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %3, 0
  %extract267.i = lshr i64 %asmresult10.i.i, 9
  %extract.t268.i = trunc i64 %extract267.i to i32
  br label %tg_get_cfs_quota.exit

tg_get_cfs_quota.exit:                            ; preds = %if.end159.i, %entry
  %retval.0.i = phi i32 [ -1, %entry ], [ %extract.t268.i, %if.end159.i ]
  %conv = sext i32 %retval.0.i to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cfs_quota_write_s64(ptr noundef %css, ptr nocapture noundef readnone %cftype, i64 noundef %cfs_quota_us) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %conv = trunc i64 %cfs_quota_us to i32
  %period1.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 1
  %0 = ptrtoint ptr %period1.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %period1.i, align 16
  %burst3.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 4
  %2 = ptrtoint ptr %burst3.i to i32
  call void @__asan_load8_noabort(i32 %2)
  %3 = load i64, ptr %burst3.i, align 8
  %cmp.i = icmp slt i32 %conv, 0
  %conv.i = sext i32 %conv to i64
  %mul.i = mul nsw i64 %conv.i, 1000
  %quota.0.i = select i1 %cmp.i, i64 -1, i64 %mul.i
  %call10.i = tail call fastcc i32 @tg_set_cfs_bandwidth(ptr noundef %css, i64 noundef %1, i64 noundef %quota.0.i, i64 noundef %3) #33
  ret i32 %call10.i
}

; Function Attrs: argmemonly nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_cfs_period_read_u64(ptr nocapture noundef readonly %css, ptr nocapture noundef readnone %cft) #29 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %period.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 1
  %0 = ptrtoint ptr %period.i to i32
  call void @__asan_load8_noabort(i32 %0)
  %1 = load i64, ptr %period.i, align 16
  %2 = tail call { i64, i32 } asm "umull\09${0:Q}, ${0:R}, ${2:Q}, ${3:Q}\0A\09cmn\09${0:Q}, ${2:Q}\0A\09adcs\09${0:R}, ${0:R}, ${2:R}\0A\09adc\09${0:Q}, $1, #0", "=&r,=&{r12},r,r,1,~{cc}"(i64 -9002011107970261189, i64 %1, i32 0) #40, !srcloc !1330
  %asmresult.i.i = extractvalue { i64, i32 } %2, 0
  %asmresult4.i.i = extractvalue { i64, i32 } %2, 1
  %3 = tail call { i64, i32 } asm "umlal\09${0:R}, ${0:Q}, ${2:R}, ${3:Q}\0A\09umlal\09${0:R}, $1, ${2:Q}, ${3:R}\0A\09mov\09${0:R}, #0\0A\09adds\09${0:Q}, $1, ${0:Q}\0A\09adc\09${0:R}, ${0:R}, #0\0A\09umlal\09${0:Q}, ${0:R}, ${2:R}, ${3:R}", "=&r,=&{r12},r,r,0,1,~{cc}"(i64 -9002011107970261189, i64 %1, i64 %asmresult.i.i, i32 %asmresult4.i.i) #40, !srcloc !1331
  %asmresult10.i.i = extractvalue { i64, i32 } %3, 0
  %4 = shl i64 %asmresult10.i.i, 23
  %conv = ashr i64 %4, 32
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cfs_period_write_u64(ptr noundef %css, ptr nocapture noundef readnone %cftype, i64 noundef %cfs_period_us) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %0 = and i64 %cfs_period_us, 2147483648
  %cmp.i.not = icmp eq i64 %0, 0
  br i1 %cmp.i.not, label %if.end.i, label %tg_set_cfs_period.exit

if.end.i:                                         ; preds = %entry
  %conv11.i = and i64 %cfs_period_us, 4294967295
  %mul.i = mul nuw nsw i64 %conv11.i, 1000
  %quota3.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 2
  %1 = ptrtoint ptr %quota3.i to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %quota3.i, align 8
  %burst5.i = getelementptr inbounds %struct.task_group, ptr %css, i32 0, i32 16, i32 4
  %3 = ptrtoint ptr %burst5.i to i32
  call void @__asan_load8_noabort(i32 %3)
  %4 = load i64, ptr %burst5.i, align 8
  %call.i = tail call fastcc i32 @tg_set_cfs_bandwidth(ptr noundef %css, i64 noundef %mul.i, i64 noundef %2, i64 noundef %4) #33
  br label %tg_set_cfs_period.exit

tg_set_cfs_period.exit:                           ; preds = %if.end.i, %entry
  %retval.0.i = phi i32 [ %call.i, %if.end.i ], [ -22, %entry ]
  ret i32 %retval.0.i
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_cfs_stat_show(ptr noundef %sf, ptr nocapture noundef readnone %v) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %private.i = getelementptr inbounds %struct.seq_file, ptr %sf, i32 0, i32 11
  %0 = ptrtoint ptr %private.i to i32
  call void @__asan_load4_noabort(i32 %0)
  %1 = load ptr, ptr %private.i, align 8
  %call.i = tail call ptr @of_css(ptr noundef %1) #33
  %nr_periods = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 13
  %2 = ptrtoint ptr %nr_periods to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load i32, ptr %nr_periods, align 8
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.255, i32 noundef %3) #33
  %nr_throttled = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 14
  %4 = ptrtoint ptr %nr_throttled to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %nr_throttled, align 4
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.256, i32 noundef %5) #33
  %throttled_time = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 16
  %6 = ptrtoint ptr %throttled_time to i32
  call void @__asan_load8_noabort(i32 %6)
  %7 = load i64, ptr %throttled_time, align 8
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.257, i64 noundef %7) #33
  callbr void asm sideeffect "1:\0A\09nop\0A\09.pushsection __jump_table,  \22aw\22\0A\09.word 1b, ${1:l}, ${0:c}\0A\09.popsection\0A\09", "i,i"(ptr nonnull @sched_schedstats, ptr blockaddress(@cpu_cfs_stat_show, %l_yes.i)) #33
          to label %arch_static_branch.exit [label %l_yes.i], !srcloc !1202

l_yes.i:                                          ; preds = %entry
  br label %arch_static_branch.exit

arch_static_branch.exit:                          ; preds = %l_yes.i, %entry
  %retval.0.i = phi i1 [ false, %l_yes.i ], [ true, %entry ]
  %cmp.not = icmp eq ptr %call.i, @root_task_group
  %or.cond = select i1 %retval.0.i, i1 true, i1 %cmp.not
  br i1 %or.cond, label %if.end, label %for.cond.preheader

for.cond.preheader:                               ; preds = %arch_static_branch.exit
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @nr_cpu_ids to i32))
  %8 = load i32, ptr @nr_cpu_ids, align 4
  %call524 = tail call i32 @cpumask_next(i32 noundef -1, ptr noundef nonnull @__cpu_possible_mask) #37
  %cmp625 = icmp ult i32 %call524, %8
  br i1 %cmp625, label %for.body.lr.ph, label %for.end

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %se = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 1
  %9 = ptrtoint ptr %se to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load ptr, ptr %se, align 8
  br label %for.body

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %call527 = phi i32 [ %call524, %for.body.lr.ph ], [ %call5, %for.body ]
  %ws.026 = phi i64 [ 0, %for.body.lr.ph ], [ %add, %for.body ]
  %arrayidx = getelementptr ptr, ptr %10, i32 %call527
  %11 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %arrayidx, align 4
  %my_q.i = getelementptr inbounds %struct.sched_entity, ptr %12, i32 0, i32 12
  %13 = ptrtoint ptr %my_q.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %my_q.i, align 4
  %tobool.not.i = icmp eq ptr %14, null
  %stats.i = getelementptr inbounds %struct.sched_entity_stats, ptr %12, i32 0, i32 1
  %stats1.i = getelementptr i8, ptr %12, i32 640
  %retval.0.i23 = select i1 %tobool.not.i, ptr %stats1.i, ptr %stats.i
  %wait_sum = getelementptr inbounds %struct.sched_statistics, ptr %retval.0.i23, i32 0, i32 3
  %15 = ptrtoint ptr %wait_sum to i32
  call void @__asan_load8_noabort(i32 %15)
  %16 = load i64, ptr %wait_sum, align 8
  %add = add i64 %16, %ws.026
  %call5 = tail call i32 @cpumask_next(i32 noundef %call527, ptr noundef nonnull @__cpu_possible_mask) #37
  %cmp6 = icmp ult i32 %call5, %8
  br i1 %cmp6, label %for.body, label %for.end

for.end:                                          ; preds = %for.body, %for.cond.preheader
  %ws.0.lcssa = phi i64 [ 0, %for.cond.preheader ], [ %add, %for.body ]
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.258, i64 noundef %ws.0.lcssa) #33
  br label %if.end

if.end:                                           ; preds = %for.end, %arch_static_branch.exit
  %nr_burst = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 15
  %17 = ptrtoint ptr %nr_burst to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load i32, ptr %nr_burst, align 8
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.259, i32 noundef %18) #33
  %burst_time = getelementptr inbounds %struct.task_group, ptr %call.i, i32 0, i32 16, i32 17
  %19 = ptrtoint ptr %burst_time to i32
  call void @__asan_load8_noabort(i32 %19)
  %20 = load i64, ptr %burst_time, align 8
  tail call void (ptr, ptr, ...) @seq_printf(ptr noundef %sf, ptr noundef nonnull @.str.260, i64 noundef %20) #33
  ret i32 0
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_rt_runtime_read(ptr noundef %css, ptr nocapture noundef readnone %cft) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call1 = tail call i32 @sched_group_rt_runtime(ptr noundef %css) #33
  %conv = sext i32 %call1 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_rt_runtime_write(ptr noundef %css, ptr nocapture noundef readnone %cft, i64 noundef %val) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %conv = trunc i64 %val to i32
  %call1 = tail call i32 @sched_group_set_rt_runtime(ptr noundef %css, i32 noundef %conv) #33
  ret i32 %call1
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i64 @cpu_rt_period_read_uint(ptr noundef %css, ptr nocapture noundef readnone %cft) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call1 = tail call i32 @sched_group_rt_period(ptr noundef %css) #33
  %conv = sext i32 %call1 to i64
  ret i64 %conv
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal i32 @cpu_rt_period_write_uint(ptr noundef %css, ptr nocapture noundef readnone %cftype, i64 noundef %rt_period_us) #0 align 64 {
entry:
  call void @llvm.arm.gnu.eabi.mcount()
  %call1 = tail call i32 @sched_group_set_rt_period(ptr noundef %css, i64 noundef %rt_period_us) #33
  ret i32 %call1
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_rt_runtime(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_set_rt_runtime(ptr noundef, i32 noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_rt_period(ptr noundef) local_unnamed_addr #2

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @sched_group_set_rt_period(ptr noundef, i64 noundef) local_unnamed_addr #2

; Function Attrs: argmemonly nofree nounwind readonly willreturn
declare i32 @bcmp(ptr nocapture, ptr nocapture, i32) local_unnamed_addr #31

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i64 @llvm.smin.i64(i64, i64) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i16 @llvm.umax.i16(i16, i16) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i16 @llvm.umin.i16(i16, i16) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i64 @llvm.smax.i64(i64, i64) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i64 @llvm.umin.i64(i64, i64) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.umin.i32(i32, i32) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.smin.i32(i32, i32) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.smax.i32(i32, i32) #18

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.umax.i32(i32, i32) #18

; Function Attrs: inaccessiblememonly nocallback nofree nosync nounwind willreturn
declare void @llvm.experimental.noalias.scope.decl(metadata) #32

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.abs.i32(i32, i1 immarg) #18

; Function Attrs: nounwind
declare void @llvm.arm.gnu.eabi.mcount() #33

declare void @__asan_load1_noabort(i32)

declare void @__asan_load2_noabort(i32)

declare void @__asan_load4_noabort(i32)

declare void @__asan_load8_noabort(i32)

declare void @__asan_store1_noabort(i32)

declare void @__asan_store2_noabort(i32)

declare void @__asan_store4_noabort(i32)

declare void @__asan_store8_noabort(i32)

declare ptr @memcpy(ptr, ptr, i32)

declare ptr @memset(ptr, i32, i32)

declare void @__asan_handle_no_return()

declare void @__asan_register_globals(i32, i32)

declare void @__asan_unregister_globals(i32, i32)

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_ctor() #34 {
  call void @__asan_register_globals(i32 ptrtoint (ptr @0 to i32), i32 409)
  ret void
}

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_dtor() #34 {
  call void @__asan_unregister_globals(i32 ptrtoint (ptr @0 to i32), i32 409)
  ret void
}

attributes #0 = { nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #1 = { argmemonly nocallback nofree nosync nounwind willreturn }
attributes #2 = { null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #3 = { inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #4 = { mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #5 = { mustprogress nofree nounwind null_pointer_is_valid readonly willreturn "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #6 = { mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readnone sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #7 = { mustprogress nofree nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #8 = { argmemonly mustprogress nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #9 = { inlinehint mustprogress nofree norecurse nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #10 = { cold null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #11 = { cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #12 = { nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #13 = { mustprogress nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #14 = { noreturn nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #15 = { mustprogress nofree nounwind null_pointer_is_valid sanitize_address sspstrong willreturn uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #16 = { nofree nounwind null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #17 = { cold nofree nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #18 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
attributes #19 = { argmemonly mustprogress nofree nounwind null_pointer_is_valid willreturn "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #20 = { argmemonly mustprogress nofree nounwind null_pointer_is_valid readonly willreturn "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #21 = { nocallback nofree nosync nounwind readnone willreturn }
attributes #22 = { nounwind readonly }
attributes #23 = { inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn }
attributes #24 = { argmemonly inlinehint nofree norecurse nosync nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #25 = { null_pointer_is_valid allocsize(0) "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #26 = { cold noreturn null_pointer_is_valid "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #27 = { noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #28 = { inlinehint nofree nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #29 = { argmemonly nofree nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #30 = { argmemonly nofree norecurse nosync nounwind null_pointer_is_valid readonly sanitize_address sspstrong uwtable(sync) "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #31 = { argmemonly nofree nounwind readonly willreturn }
attributes #32 = { inaccessiblememonly nocallback nofree nosync nounwind willreturn }
attributes #33 = { nounwind }
attributes #34 = { nounwind uwtable(sync) "frame-pointer"="all" }
attributes #35 = { nobuiltin nounwind }
attributes #36 = { nobuiltin }
attributes #37 = { nounwind readonly willreturn }
attributes #38 = { nounwind allocsize(0) }
attributes #39 = { cold nounwind }
attributes #40 = { nounwind readnone }
attributes #41 = { cold }
attributes #42 = { cold noreturn nounwind }

!llvm.asan.globals = !{!0, !2, !3, !4, !6, !7, !8, !10, !11, !12, !14, !15, !16, !18, !19, !20, !22, !23, !24, !26, !27, !28, !30, !31, !32, !34, !35, !36, !38, !39, !40, !42, !43, !44, !46, !47, !48, !50, !51, !52, !54, !55, !56, !58, !59, !60, !62, !63, !64, !66, !67, !68, !70, !71, !72, !74, !75, !76, !78, !79, !80, !82, !83, !84, !86, !87, !88, !90, !91, !92, !94, !95, !96, !98, !99, !100, !102, !103, !104, !106, !107, !108, !110, !111, !112, !114, !115, !116, !118, !119, !120, !122, !123, !124, !126, !127, !128, !130, !131, !132, !134, !135, !136, !138, !139, !140, !142, !143, !144, !146, !147, !148, !150, !151, !152, !153, !154, !155, !156, !157, !158, !159, !160, !161, !162, !163, !164, !165, !166, !167, !169, !170, !171, !172, !173, !174, !175, !176, !177, !178, !179, !180, !181, !183, !184, !185, !186, !187, !188, !189, !190, !191, !192, !193, !194, !195, !196, !197, !198, !200, !201, !202, !203, !204, !205, !206, !207, !208, !210, !211, !212, !213, !214, !215, !216, !217, !218, !219, !220, !221, !223, !224, !225, !226, !227, !228, !229, !230, !231, !232, !233, !234, !235, !236, !237, !238, !239, !240, !241, !242, !243, !244, !245, !246, !247, !248, !249, !250, !251, !252, !253, !254, !255, !256, !257, !258, !259, !260, !261, !262, !263, !264, !265, !266, !267, !268, !270, !271, !272, !274, !275, !276, !278, !279, !280, !282, !283, !284, !286, !287, !288, !290, !291, !292, !294, !295, !296, !298, !299, !300, !302, !303, !304, !306, !307, !308, !310, !312, !314, !316, !318, !320, !322, !323, !325, !327, !328, !330, !331, !333, !334, !336, !337, !339, !341, !343, !345, !347, !349, !351, !353, !355, !357, !358, !359, !361, !363, !365, !367, !369, !371, !373, !375, !377, !379, !381, !383, !385, !387, !389, !391, !392, !393, !394, !396, !398, !400, !402, !404, !406, !408, !410, !412, !414, !416, !418, !420, !421, !422, !423, !424, !425, !426, !427, !428, !430, !432, !434, !436, !438, !440, !442, !444, !445, !446, !447, !448, !449, !450, !451, !452, !454, !455, !456, !457, !458, !459, !460, !461, !462, !464, !465, !466, !467, !468, !469, !470, !471, !472, !474, !475, !476, !477, !478, !479, !480, !481, !482, !484, !485, !486, !487, !488, !489, !490, !491, !492, !494, !495, !496, !497, !498, !499, !500, !501, !502, !504, !506, !507, !508, !509, !510, !511, !512, !513, !514, !516, !517, !518, !519, !520, !521, !522, !523, !524, !526, !527, !528, !529, !530, !531, !532, !533, !534, !536, !538, !540, !542, !544, !546, !548, !550, !552, !554, !555, !556, !557, !558, !559, !560, !561, !562, !564, !565, !566, !567, !568, !569, !570, !571, !572, !574, !575, !576, !577, !578, !579, !580, !581, !582, !584, !585, !586, !587, !588, !589, !590, !591, !592, !594, !595, !596, !597, !599, !600, !601, !603, !605, !606, !607, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !630, !632, !633, !635, !637, !639, !640, !641, !642, !644, !645, !646, !647, !649, !650, !651, !653, !654, !655, !657, !658, !659, !661, !663, !665, !666, !667, !668, !670, !671, !672, !674, !676, !678, !679, !680, !681, !683, !684, !685, !687, !689, !691, !693, !695, !696, !697, !698, !700, !702, !704, !705, !706, !708, !710, !712, !714, !715, !716, !718, !719, !720, !722, !723, !725, !727, !728, !730, !732, !733, !734, !735, !736, !737, !738, !739, !740, !741, !742, !743, !744, !745, !746, !747, !748, !749, !750, !751, !752, !753, !754, !755, !756, !757, !758, !759, !760, !761, !762, !763, !764, !765, !766, !767, !768, !769, !770, !772, !773, !774, !775, !776, !777, !778, !779, !780, !781, !782, !783, !784, !785, !786, !787, !788, !789, !790, !791, !792, !793, !794, !795, !796, !797, !798, !799, !800, !801, !802, !803, !804, !805, !806, !807, !808, !809, !810, !811, !812, !813, !814, !815, !816, !817, !818, !819, !820, !821, !822, !823, !824, !825, !826, !827, !828, !829, !830, !831, !832, !833, !834, !835, !836, !837, !838, !839, !840, !841, !842, !843, !844, !845, !846, !847, !848, !849, !850, !851, !852, !853, !854, !855, !856, !857, !858, !859, !860, !861, !862, !863, !864, !865, !866, !867, !868, !869, !870, !871, !872, !873, !874, !875, !876, !877, !878, !879, !880, !881, !882, !883, !884, !885, !886, !887, !888, !889, !890, !891, !892, !893, !894, !895, !896, !897, !898, !899, !900, !901, !902, !903, !904, !905, !906, !907, !909, !910, !911, !913, !915, !917, !918, !919, !921, !922, !923, !924, !925, !927, !928, !929, !931, !932, !934, !935, !936, !938, !939, !941, !942, !944, !945, !947, !949, !950, !952, !954, !956, !958, !959, !960, !961, !962, !963, !964, !965, !966, !967, !969, !971, !972, !974, !976, !978, !979, !980, !981, !983, !985, !986, !987, !988, !989, !991, !992, !994, !996, !997, !999, !1000, !1001, !1002, !1004, !1006, !1008, !1010, !1012, !1013, !1014, !1015, !1017, !1018, !1020, !1021, !1023, !1024, !1025, !1026, !1028, !1030, !1032, !1034, !1035, !1036, !1038, !1039, !1040, !1041, !1043, !1044, !1045, !1046, !1047, !1048, !1049, !1050, !1051, !1053, !1054, !1056, !1058, !1059, !1060, !1061, !1062, !1063, !1064, !1065, !1066, !1067, !1068, !1069, !1070, !1071, !1072, !1073, !1075, !1077, !1078, !1079, !1080, !1081, !1082, !1083, !1084, !1085, !1086, !1087, !1088, !1089, !1090, !1091, !1092, !1093, !1094, !1095, !1097, !1099, !1100, !1102, !1104, !1106, !1108, !1110, !1112, !1114, !1116, !1118, !1119, !1121, !1122, !1123, !1124, !1126, !1128, !1129, !1130, !1132, !1134, !1135, !1137, !1138, !1140, !1142, !1144, !1146, !1148, !1150, !1152, !1154, !1156, !1157, !1158, !1160, !1162, !1164, !1166, !1168, !1170, !1172, !1174, !1176, !1178, !1179, !1180}
!llvm.named.register.sp = !{!1181}
!llvm.module.flags = !{!1182, !1183, !1184, !1185, !1186, !1187, !1188, !1189}
!llvm.ident = !{!1190}

!0 = !{ptr @__tracepoint_sched_kthread_stop, !1, !"__tracepoint_sched_kthread_stop", i1 false, i1 false}
!1 = !{!"../include/trace/events/sched.h", i32 16, i32 1}
!2 = !{ptr @__tracepoint_ptr_sched_kthread_stop, !1, !"__tracepoint_ptr_sched_kthread_stop", i1 false, i1 false}
!3 = !{ptr @__SCK__tp_func_sched_kthread_stop, !1, !"__SCK__tp_func_sched_kthread_stop", i1 false, i1 false}
!4 = !{ptr @__tracepoint_sched_kthread_stop_ret, !5, !"__tracepoint_sched_kthread_stop_ret", i1 false, i1 false}
!5 = !{!"../include/trace/events/sched.h", i32 38, i32 1}
!6 = !{ptr @__tracepoint_ptr_sched_kthread_stop_ret, !5, !"__tracepoint_ptr_sched_kthread_stop_ret", i1 false, i1 false}
!7 = !{ptr @__SCK__tp_func_sched_kthread_stop_ret, !5, !"__SCK__tp_func_sched_kthread_stop_ret", i1 false, i1 false}
!8 = !{ptr @__tracepoint_sched_kthread_work_queue_work, !9, !"__tracepoint_sched_kthread_work_queue_work", i1 false, i1 false}
!9 = !{!"../include/trace/events/sched.h", i32 64, i32 1}
!10 = !{ptr @__tracepoint_ptr_sched_kthread_work_queue_work, !9, !"__tracepoint_ptr_sched_kthread_work_queue_work", i1 false, i1 false}
!11 = !{ptr @__SCK__tp_func_sched_kthread_work_queue_work, !9, !"__SCK__tp_func_sched_kthread_work_queue_work", i1 false, i1 false}
!12 = !{ptr @__tracepoint_sched_kthread_work_execute_start, !13, !"__tracepoint_sched_kthread_work_execute_start", i1 false, i1 false}
!13 = !{!"../include/trace/events/sched.h", i32 93, i32 1}
!14 = !{ptr @__tracepoint_ptr_sched_kthread_work_execute_start, !13, !"__tracepoint_ptr_sched_kthread_work_execute_start", i1 false, i1 false}
!15 = !{ptr @__SCK__tp_func_sched_kthread_work_execute_start, !13, !"__SCK__tp_func_sched_kthread_work_execute_start", i1 false, i1 false}
!16 = !{ptr @__tracepoint_sched_kthread_work_execute_end, !17, !"__tracepoint_sched_kthread_work_execute_end", i1 false, i1 false}
!17 = !{!"../include/trace/events/sched.h", i32 119, i32 1}
!18 = !{ptr @__tracepoint_ptr_sched_kthread_work_execute_end, !17, !"__tracepoint_ptr_sched_kthread_work_execute_end", i1 false, i1 false}
!19 = !{ptr @__SCK__tp_func_sched_kthread_work_execute_end, !17, !"__SCK__tp_func_sched_kthread_work_execute_end", i1 false, i1 false}
!20 = !{ptr @__tracepoint_sched_waking, !21, !"__tracepoint_sched_waking", i1 false, i1 false}
!21 = !{!"../include/trace/events/sched.h", i32 170, i32 1}
!22 = !{ptr @__tracepoint_ptr_sched_waking, !21, !"__tracepoint_ptr_sched_waking", i1 false, i1 false}
!23 = !{ptr @__SCK__tp_func_sched_waking, !21, !"__SCK__tp_func_sched_waking", i1 false, i1 false}
!24 = !{ptr @__tracepoint_sched_wakeup, !25, !"__tracepoint_sched_wakeup", i1 false, i1 false}
!25 = !{!"../include/trace/events/sched.h", i32 178, i32 1}
!26 = !{ptr @__tracepoint_ptr_sched_wakeup, !25, !"__tracepoint_ptr_sched_wakeup", i1 false, i1 false}
!27 = !{ptr @__SCK__tp_func_sched_wakeup, !25, !"__SCK__tp_func_sched_wakeup", i1 false, i1 false}
!28 = !{ptr @__tracepoint_sched_wakeup_new, !29, !"__tracepoint_sched_wakeup_new", i1 false, i1 false}
!29 = !{!"../include/trace/events/sched.h", i32 185, i32 1}
!30 = !{ptr @__tracepoint_ptr_sched_wakeup_new, !29, !"__tracepoint_ptr_sched_wakeup_new", i1 false, i1 false}
!31 = !{ptr @__SCK__tp_func_sched_wakeup_new, !29, !"__SCK__tp_func_sched_wakeup_new", i1 false, i1 false}
!32 = !{ptr @__tracepoint_sched_switch, !33, !"__tracepoint_sched_switch", i1 false, i1 false}
!33 = !{!"../include/trace/events/sched.h", i32 220, i32 1}
!34 = !{ptr @__tracepoint_ptr_sched_switch, !33, !"__tracepoint_ptr_sched_switch", i1 false, i1 false}
!35 = !{ptr @__SCK__tp_func_sched_switch, !33, !"__SCK__tp_func_sched_switch", i1 false, i1 false}
!36 = !{ptr @__tracepoint_sched_migrate_task, !37, !"__tracepoint_sched_migrate_task", i1 false, i1 false}
!37 = !{!"../include/trace/events/sched.h", i32 271, i32 1}
!38 = !{ptr @__tracepoint_ptr_sched_migrate_task, !37, !"__tracepoint_ptr_sched_migrate_task", i1 false, i1 false}
!39 = !{ptr @__SCK__tp_func_sched_migrate_task, !37, !"__SCK__tp_func_sched_migrate_task", i1 false, i1 false}
!40 = !{ptr @__tracepoint_sched_process_free, !41, !"__tracepoint_sched_process_free", i1 false, i1 false}
!41 = !{!"../include/trace/events/sched.h", i32 323, i32 1}
!42 = !{ptr @__tracepoint_ptr_sched_process_free, !41, !"__tracepoint_ptr_sched_process_free", i1 false, i1 false}
!43 = !{ptr @__SCK__tp_func_sched_process_free, !41, !"__SCK__tp_func_sched_process_free", i1 false, i1 false}
!44 = !{ptr @__tracepoint_sched_process_exit, !45, !"__tracepoint_sched_process_exit", i1 false, i1 false}
!45 = !{!"../include/trace/events/sched.h", i32 330, i32 1}
!46 = !{ptr @__tracepoint_ptr_sched_process_exit, !45, !"__tracepoint_ptr_sched_process_exit", i1 false, i1 false}
!47 = !{ptr @__SCK__tp_func_sched_process_exit, !45, !"__SCK__tp_func_sched_process_exit", i1 false, i1 false}
!48 = !{ptr @__tracepoint_sched_wait_task, !49, !"__tracepoint_sched_wait_task", i1 false, i1 false}
!49 = !{!"../include/trace/events/sched.h", i32 337, i32 1}
!50 = !{ptr @__tracepoint_ptr_sched_wait_task, !49, !"__tracepoint_ptr_sched_wait_task", i1 false, i1 false}
!51 = !{ptr @__SCK__tp_func_sched_wait_task, !49, !"__SCK__tp_func_sched_wait_task", i1 false, i1 false}
!52 = !{ptr @__tracepoint_sched_process_wait, !53, !"__tracepoint_sched_process_wait", i1 false, i1 false}
!53 = !{!"../include/trace/events/sched.h", i32 344, i32 1}
!54 = !{ptr @__tracepoint_ptr_sched_process_wait, !53, !"__tracepoint_ptr_sched_process_wait", i1 false, i1 false}
!55 = !{ptr @__SCK__tp_func_sched_process_wait, !53, !"__SCK__tp_func_sched_process_wait", i1 false, i1 false}
!56 = !{ptr @__tracepoint_sched_process_fork, !57, !"__tracepoint_sched_process_fork", i1 false, i1 false}
!57 = !{!"../include/trace/events/sched.h", i32 369, i32 1}
!58 = !{ptr @__tracepoint_ptr_sched_process_fork, !57, !"__tracepoint_ptr_sched_process_fork", i1 false, i1 false}
!59 = !{ptr @__SCK__tp_func_sched_process_fork, !57, !"__SCK__tp_func_sched_process_fork", i1 false, i1 false}
!60 = !{ptr @__tracepoint_sched_process_exec, !61, !"__tracepoint_sched_process_exec", i1 false, i1 false}
!61 = !{!"../include/trace/events/sched.h", i32 397, i32 1}
!62 = !{ptr @__tracepoint_ptr_sched_process_exec, !61, !"__tracepoint_ptr_sched_process_exec", i1 false, i1 false}
!63 = !{ptr @__SCK__tp_func_sched_process_exec, !61, !"__SCK__tp_func_sched_process_exec", i1 false, i1 false}
!64 = !{ptr @__tracepoint_sched_stat_wait, !65, !"__tracepoint_sched_stat_wait", i1 false, i1 false}
!65 = !{!"../include/trace/events/sched.h", i32 460, i32 1}
!66 = !{ptr @__tracepoint_ptr_sched_stat_wait, !65, !"__tracepoint_ptr_sched_stat_wait", i1 false, i1 false}
!67 = !{ptr @__SCK__tp_func_sched_stat_wait, !65, !"__SCK__tp_func_sched_stat_wait", i1 false, i1 false}
!68 = !{ptr @__tracepoint_sched_stat_sleep, !69, !"__tracepoint_sched_stat_sleep", i1 false, i1 false}
!69 = !{!"../include/trace/events/sched.h", i32 468, i32 1}
!70 = !{ptr @__tracepoint_ptr_sched_stat_sleep, !69, !"__tracepoint_ptr_sched_stat_sleep", i1 false, i1 false}
!71 = !{ptr @__SCK__tp_func_sched_stat_sleep, !69, !"__SCK__tp_func_sched_stat_sleep", i1 false, i1 false}
!72 = !{ptr @__tracepoint_sched_stat_iowait, !73, !"__tracepoint_sched_stat_iowait", i1 false, i1 false}
!73 = !{!"../include/trace/events/sched.h", i32 476, i32 1}
!74 = !{ptr @__tracepoint_ptr_sched_stat_iowait, !73, !"__tracepoint_ptr_sched_stat_iowait", i1 false, i1 false}
!75 = !{ptr @__SCK__tp_func_sched_stat_iowait, !73, !"__SCK__tp_func_sched_stat_iowait", i1 false, i1 false}
!76 = !{ptr @__tracepoint_sched_stat_blocked, !77, !"__tracepoint_sched_stat_blocked", i1 false, i1 false}
!77 = !{!"../include/trace/events/sched.h", i32 483, i32 1}
!78 = !{ptr @__tracepoint_ptr_sched_stat_blocked, !77, !"__tracepoint_ptr_sched_stat_blocked", i1 false, i1 false}
!79 = !{ptr @__SCK__tp_func_sched_stat_blocked, !77, !"__SCK__tp_func_sched_stat_blocked", i1 false, i1 false}
!80 = !{ptr @__tracepoint_sched_stat_runtime, !81, !"__tracepoint_sched_stat_runtime", i1 false, i1 false}
!81 = !{!"../include/trace/events/sched.h", i32 517, i32 1}
!82 = !{ptr @__tracepoint_ptr_sched_stat_runtime, !81, !"__tracepoint_ptr_sched_stat_runtime", i1 false, i1 false}
!83 = !{ptr @__SCK__tp_func_sched_stat_runtime, !81, !"__SCK__tp_func_sched_stat_runtime", i1 false, i1 false}
!84 = !{ptr @__tracepoint_sched_pi_setprio, !85, !"__tracepoint_sched_pi_setprio", i1 false, i1 false}
!85 = !{!"../include/trace/events/sched.h", i32 525, i32 1}
!86 = !{ptr @__tracepoint_ptr_sched_pi_setprio, !85, !"__tracepoint_ptr_sched_pi_setprio", i1 false, i1 false}
!87 = !{ptr @__SCK__tp_func_sched_pi_setprio, !85, !"__SCK__tp_func_sched_pi_setprio", i1 false, i1 false}
!88 = !{ptr @__tracepoint_sched_process_hang, !89, !"__tracepoint_sched_process_hang", i1 false, i1 false}
!89 = !{!"../include/trace/events/sched.h", i32 554, i32 1}
!90 = !{ptr @__tracepoint_ptr_sched_process_hang, !89, !"__tracepoint_ptr_sched_process_hang", i1 false, i1 false}
!91 = !{ptr @__SCK__tp_func_sched_process_hang, !89, !"__SCK__tp_func_sched_process_hang", i1 false, i1 false}
!92 = !{ptr @__tracepoint_sched_move_numa, !93, !"__tracepoint_sched_move_numa", i1 false, i1 false}
!93 = !{!"../include/trace/events/sched.h", i32 576, i32 1}
!94 = !{ptr @__tracepoint_ptr_sched_move_numa, !93, !"__tracepoint_ptr_sched_move_numa", i1 false, i1 false}
!95 = !{ptr @__SCK__tp_func_sched_move_numa, !93, !"__SCK__tp_func_sched_move_numa", i1 false, i1 false}
!96 = !{ptr @__tracepoint_sched_stick_numa, !97, !"__tracepoint_sched_stick_numa", i1 false, i1 false}
!97 = !{!"../include/trace/events/sched.h", i32 648, i32 1}
!98 = !{ptr @__tracepoint_ptr_sched_stick_numa, !97, !"__tracepoint_ptr_sched_stick_numa", i1 false, i1 false}
!99 = !{ptr @__SCK__tp_func_sched_stick_numa, !97, !"__SCK__tp_func_sched_stick_numa", i1 false, i1 false}
!100 = !{ptr @__tracepoint_sched_swap_numa, !101, !"__tracepoint_sched_swap_numa", i1 false, i1 false}
!101 = !{!"../include/trace/events/sched.h", i32 656, i32 1}
!102 = !{ptr @__tracepoint_ptr_sched_swap_numa, !101, !"__tracepoint_ptr_sched_swap_numa", i1 false, i1 false}
!103 = !{ptr @__SCK__tp_func_sched_swap_numa, !101, !"__SCK__tp_func_sched_swap_numa", i1 false, i1 false}
!104 = !{ptr @__tracepoint_sched_wake_idle_without_ipi, !105, !"__tracepoint_sched_wake_idle_without_ipi", i1 false, i1 false}
!105 = !{!"../include/trace/events/sched.h", i32 668, i32 1}
!106 = !{ptr @__tracepoint_ptr_sched_wake_idle_without_ipi, !105, !"__tracepoint_ptr_sched_wake_idle_without_ipi", i1 false, i1 false}
!107 = !{ptr @__SCK__tp_func_sched_wake_idle_without_ipi, !105, !"__SCK__tp_func_sched_wake_idle_without_ipi", i1 false, i1 false}
!108 = !{ptr @__tracepoint_pelt_cfs_tp, !109, !"__tracepoint_pelt_cfs_tp", i1 false, i1 false}
!109 = !{!"../include/trace/events/sched.h", i32 691, i32 1}
!110 = !{ptr @__tracepoint_ptr_pelt_cfs_tp, !109, !"__tracepoint_ptr_pelt_cfs_tp", i1 false, i1 false}
!111 = !{ptr @__SCK__tp_func_pelt_cfs_tp, !109, !"__SCK__tp_func_pelt_cfs_tp", i1 false, i1 false}
!112 = !{ptr @__tracepoint_pelt_rt_tp, !113, !"__tracepoint_pelt_rt_tp", i1 false, i1 false}
!113 = !{!"../include/trace/events/sched.h", i32 695, i32 1}
!114 = !{ptr @__tracepoint_ptr_pelt_rt_tp, !113, !"__tracepoint_ptr_pelt_rt_tp", i1 false, i1 false}
!115 = !{ptr @__SCK__tp_func_pelt_rt_tp, !113, !"__SCK__tp_func_pelt_rt_tp", i1 false, i1 false}
!116 = !{ptr @__tracepoint_pelt_dl_tp, !117, !"__tracepoint_pelt_dl_tp", i1 false, i1 false}
!117 = !{!"../include/trace/events/sched.h", i32 699, i32 1}
!118 = !{ptr @__tracepoint_ptr_pelt_dl_tp, !117, !"__tracepoint_ptr_pelt_dl_tp", i1 false, i1 false}
!119 = !{ptr @__SCK__tp_func_pelt_dl_tp, !117, !"__SCK__tp_func_pelt_dl_tp", i1 false, i1 false}
!120 = !{ptr @__tracepoint_pelt_thermal_tp, !121, !"__tracepoint_pelt_thermal_tp", i1 false, i1 false}
!121 = !{!"../include/trace/events/sched.h", i32 703, i32 1}
!122 = !{ptr @__tracepoint_ptr_pelt_thermal_tp, !121, !"__tracepoint_ptr_pelt_thermal_tp", i1 false, i1 false}
!123 = !{ptr @__SCK__tp_func_pelt_thermal_tp, !121, !"__SCK__tp_func_pelt_thermal_tp", i1 false, i1 false}
!124 = !{ptr @__tracepoint_pelt_irq_tp, !125, !"__tracepoint_pelt_irq_tp", i1 false, i1 false}
!125 = !{!"../include/trace/events/sched.h", i32 707, i32 1}
!126 = !{ptr @__tracepoint_ptr_pelt_irq_tp, !125, !"__tracepoint_ptr_pelt_irq_tp", i1 false, i1 false}
!127 = !{ptr @__SCK__tp_func_pelt_irq_tp, !125, !"__SCK__tp_func_pelt_irq_tp", i1 false, i1 false}
!128 = !{ptr @__tracepoint_pelt_se_tp, !129, !"__tracepoint_pelt_se_tp", i1 false, i1 false}
!129 = !{!"../include/trace/events/sched.h", i32 711, i32 1}
!130 = !{ptr @__tracepoint_ptr_pelt_se_tp, !129, !"__tracepoint_ptr_pelt_se_tp", i1 false, i1 false}
!131 = !{ptr @__SCK__tp_func_pelt_se_tp, !129, !"__SCK__tp_func_pelt_se_tp", i1 false, i1 false}
!132 = !{ptr @__tracepoint_sched_cpu_capacity_tp, !133, !"__tracepoint_sched_cpu_capacity_tp", i1 false, i1 false}
!133 = !{!"../include/trace/events/sched.h", i32 715, i32 1}
!134 = !{ptr @__tracepoint_ptr_sched_cpu_capacity_tp, !133, !"__tracepoint_ptr_sched_cpu_capacity_tp", i1 false, i1 false}
!135 = !{ptr @__SCK__tp_func_sched_cpu_capacity_tp, !133, !"__SCK__tp_func_sched_cpu_capacity_tp", i1 false, i1 false}
!136 = !{ptr @__tracepoint_sched_overutilized_tp, !137, !"__tracepoint_sched_overutilized_tp", i1 false, i1 false}
!137 = !{!"../include/trace/events/sched.h", i32 719, i32 1}
!138 = !{ptr @__tracepoint_ptr_sched_overutilized_tp, !137, !"__tracepoint_ptr_sched_overutilized_tp", i1 false, i1 false}
!139 = !{ptr @__SCK__tp_func_sched_overutilized_tp, !137, !"__SCK__tp_func_sched_overutilized_tp", i1 false, i1 false}
!140 = !{ptr @__tracepoint_sched_util_est_cfs_tp, !141, !"__tracepoint_sched_util_est_cfs_tp", i1 false, i1 false}
!141 = !{!"../include/trace/events/sched.h", i32 723, i32 1}
!142 = !{ptr @__tracepoint_ptr_sched_util_est_cfs_tp, !141, !"__tracepoint_ptr_sched_util_est_cfs_tp", i1 false, i1 false}
!143 = !{ptr @__SCK__tp_func_sched_util_est_cfs_tp, !141, !"__SCK__tp_func_sched_util_est_cfs_tp", i1 false, i1 false}
!144 = !{ptr @__tracepoint_sched_util_est_se_tp, !145, !"__tracepoint_sched_util_est_se_tp", i1 false, i1 false}
!145 = !{!"../include/trace/events/sched.h", i32 727, i32 1}
!146 = !{ptr @__tracepoint_ptr_sched_util_est_se_tp, !145, !"__tracepoint_ptr_sched_util_est_se_tp", i1 false, i1 false}
!147 = !{ptr @__SCK__tp_func_sched_util_est_se_tp, !145, !"__SCK__tp_func_sched_util_est_se_tp", i1 false, i1 false}
!148 = !{ptr @__tracepoint_sched_update_nr_running_tp, !149, !"__tracepoint_sched_update_nr_running_tp", i1 false, i1 false}
!149 = !{!"../include/trace/events/sched.h", i32 731, i32 1}
!150 = !{ptr @__tracepoint_ptr_sched_update_nr_running_tp, !149, !"__tracepoint_ptr_sched_update_nr_running_tp", i1 false, i1 false}
!151 = !{ptr @__SCK__tp_func_sched_update_nr_running_tp, !149, !"__SCK__tp_func_sched_update_nr_running_tp", i1 false, i1 false}
!152 = !{ptr @event_class_sched_kthread_stop, !1, !"event_class_sched_kthread_stop", i1 false, i1 false}
!153 = !{ptr @event_sched_kthread_stop, !1, !"event_sched_kthread_stop", i1 false, i1 false}
!154 = !{ptr @__event_sched_kthread_stop, !1, !"__event_sched_kthread_stop", i1 false, i1 false}
!155 = !{ptr @event_class_sched_kthread_stop_ret, !5, !"event_class_sched_kthread_stop_ret", i1 false, i1 false}
!156 = !{ptr @event_sched_kthread_stop_ret, !5, !"event_sched_kthread_stop_ret", i1 false, i1 false}
!157 = !{ptr @__event_sched_kthread_stop_ret, !5, !"__event_sched_kthread_stop_ret", i1 false, i1 false}
!158 = !{ptr @event_class_sched_kthread_work_queue_work, !9, !"event_class_sched_kthread_work_queue_work", i1 false, i1 false}
!159 = !{ptr @event_sched_kthread_work_queue_work, !9, !"event_sched_kthread_work_queue_work", i1 false, i1 false}
!160 = !{ptr @__event_sched_kthread_work_queue_work, !9, !"__event_sched_kthread_work_queue_work", i1 false, i1 false}
!161 = !{ptr @event_class_sched_kthread_work_execute_start, !13, !"event_class_sched_kthread_work_execute_start", i1 false, i1 false}
!162 = !{ptr @event_sched_kthread_work_execute_start, !13, !"event_sched_kthread_work_execute_start", i1 false, i1 false}
!163 = !{ptr @__event_sched_kthread_work_execute_start, !13, !"__event_sched_kthread_work_execute_start", i1 false, i1 false}
!164 = !{ptr @event_class_sched_kthread_work_execute_end, !17, !"event_class_sched_kthread_work_execute_end", i1 false, i1 false}
!165 = !{ptr @event_sched_kthread_work_execute_end, !17, !"event_sched_kthread_work_execute_end", i1 false, i1 false}
!166 = !{ptr @__event_sched_kthread_work_execute_end, !17, !"__event_sched_kthread_work_execute_end", i1 false, i1 false}
!167 = !{ptr @event_class_sched_wakeup_template, !168, !"event_class_sched_wakeup_template", i1 false, i1 false}
!168 = !{!"../include/trace/events/sched.h", i32 141, i32 1}
!169 = !{ptr @event_sched_waking, !21, !"event_sched_waking", i1 false, i1 false}
!170 = !{ptr @__event_sched_waking, !21, !"__event_sched_waking", i1 false, i1 false}
!171 = !{ptr @event_sched_wakeup, !25, !"event_sched_wakeup", i1 false, i1 false}
!172 = !{ptr @__event_sched_wakeup, !25, !"__event_sched_wakeup", i1 false, i1 false}
!173 = !{ptr @event_sched_wakeup_new, !29, !"event_sched_wakeup_new", i1 false, i1 false}
!174 = !{ptr @__event_sched_wakeup_new, !29, !"__event_sched_wakeup_new", i1 false, i1 false}
!175 = !{ptr @event_class_sched_switch, !33, !"event_class_sched_switch", i1 false, i1 false}
!176 = !{ptr @event_sched_switch, !33, !"event_sched_switch", i1 false, i1 false}
!177 = !{ptr @__event_sched_switch, !33, !"__event_sched_switch", i1 false, i1 false}
!178 = !{ptr @event_class_sched_migrate_task, !37, !"event_class_sched_migrate_task", i1 false, i1 false}
!179 = !{ptr @event_sched_migrate_task, !37, !"event_sched_migrate_task", i1 false, i1 false}
!180 = !{ptr @__event_sched_migrate_task, !37, !"__event_sched_migrate_task", i1 false, i1 false}
!181 = !{ptr @event_class_sched_process_template, !182, !"event_class_sched_process_template", i1 false, i1 false}
!182 = !{!"../include/trace/events/sched.h", i32 298, i32 1}
!183 = !{ptr @event_sched_process_free, !41, !"event_sched_process_free", i1 false, i1 false}
!184 = !{ptr @__event_sched_process_free, !41, !"__event_sched_process_free", i1 false, i1 false}
!185 = !{ptr @event_sched_process_exit, !45, !"event_sched_process_exit", i1 false, i1 false}
!186 = !{ptr @__event_sched_process_exit, !45, !"__event_sched_process_exit", i1 false, i1 false}
!187 = !{ptr @event_sched_wait_task, !49, !"event_sched_wait_task", i1 false, i1 false}
!188 = !{ptr @__event_sched_wait_task, !49, !"__event_sched_wait_task", i1 false, i1 false}
!189 = !{ptr @event_class_sched_process_wait, !53, !"event_class_sched_process_wait", i1 false, i1 false}
!190 = !{ptr @event_sched_process_wait, !53, !"event_sched_process_wait", i1 false, i1 false}
!191 = !{ptr @__event_sched_process_wait, !53, !"__event_sched_process_wait", i1 false, i1 false}
!192 = !{ptr @event_class_sched_process_fork, !57, !"event_class_sched_process_fork", i1 false, i1 false}
!193 = !{ptr @event_sched_process_fork, !57, !"event_sched_process_fork", i1 false, i1 false}
!194 = !{ptr @__event_sched_process_fork, !57, !"__event_sched_process_fork", i1 false, i1 false}
!195 = !{ptr @event_class_sched_process_exec, !61, !"event_class_sched_process_exec", i1 false, i1 false}
!196 = !{ptr @event_sched_process_exec, !61, !"event_sched_process_exec", i1 false, i1 false}
!197 = !{ptr @__event_sched_process_exec, !61, !"__event_sched_process_exec", i1 false, i1 false}
!198 = !{ptr @event_class_sched_stat_template, !199, !"event_class_sched_stat_template", i1 false, i1 false}
!199 = !{!"../include/trace/events/sched.h", i32 433, i32 1}
!200 = !{ptr @event_sched_stat_wait, !65, !"event_sched_stat_wait", i1 false, i1 false}
!201 = !{ptr @__event_sched_stat_wait, !65, !"__event_sched_stat_wait", i1 false, i1 false}
!202 = !{ptr @event_sched_stat_sleep, !69, !"event_sched_stat_sleep", i1 false, i1 false}
!203 = !{ptr @__event_sched_stat_sleep, !69, !"__event_sched_stat_sleep", i1 false, i1 false}
!204 = !{ptr @event_sched_stat_iowait, !73, !"event_sched_stat_iowait", i1 false, i1 false}
!205 = !{ptr @__event_sched_stat_iowait, !73, !"__event_sched_stat_iowait", i1 false, i1 false}
!206 = !{ptr @event_sched_stat_blocked, !77, !"event_sched_stat_blocked", i1 false, i1 false}
!207 = !{ptr @__event_sched_stat_blocked, !77, !"__event_sched_stat_blocked", i1 false, i1 false}
!208 = !{ptr @event_class_sched_stat_runtime, !209, !"event_class_sched_stat_runtime", i1 false, i1 false}
!209 = !{!"../include/trace/events/sched.h", i32 491, i32 1}
!210 = !{ptr @event_sched_stat_runtime, !81, !"event_sched_stat_runtime", i1 false, i1 false}
!211 = !{ptr @__event_sched_stat_runtime, !81, !"__event_sched_stat_runtime", i1 false, i1 false}
!212 = !{ptr @event_class_sched_pi_setprio, !85, !"event_class_sched_pi_setprio", i1 false, i1 false}
!213 = !{ptr @event_sched_pi_setprio, !85, !"event_sched_pi_setprio", i1 false, i1 false}
!214 = !{ptr @__event_sched_pi_setprio, !85, !"__event_sched_pi_setprio", i1 false, i1 false}
!215 = !{ptr @event_class_sched_process_hang, !89, !"event_class_sched_process_hang", i1 false, i1 false}
!216 = !{ptr @event_sched_process_hang, !89, !"event_sched_process_hang", i1 false, i1 false}
!217 = !{ptr @__event_sched_process_hang, !89, !"__event_sched_process_hang", i1 false, i1 false}
!218 = !{ptr @event_class_sched_move_numa, !93, !"event_class_sched_move_numa", i1 false, i1 false}
!219 = !{ptr @event_sched_move_numa, !93, !"event_sched_move_numa", i1 false, i1 false}
!220 = !{ptr @__event_sched_move_numa, !93, !"__event_sched_move_numa", i1 false, i1 false}
!221 = !{ptr @event_class_sched_numa_pair_template, !222, !"event_class_sched_numa_pair_template", i1 false, i1 false}
!222 = !{!"../include/trace/events/sched.h", i32 608, i32 1}
!223 = !{ptr @event_sched_stick_numa, !97, !"event_sched_stick_numa", i1 false, i1 false}
!224 = !{ptr @__event_sched_stick_numa, !97, !"__event_sched_stick_numa", i1 false, i1 false}
!225 = !{ptr @event_sched_swap_numa, !101, !"event_sched_swap_numa", i1 false, i1 false}
!226 = !{ptr @__event_sched_swap_numa, !101, !"__event_sched_swap_numa", i1 false, i1 false}
!227 = !{ptr @event_class_sched_wake_idle_without_ipi, !105, !"event_class_sched_wake_idle_without_ipi", i1 false, i1 false}
!228 = !{ptr @event_sched_wake_idle_without_ipi, !105, !"event_sched_wake_idle_without_ipi", i1 false, i1 false}
!229 = !{ptr @__event_sched_wake_idle_without_ipi, !105, !"__event_sched_wake_idle_without_ipi", i1 false, i1 false}
!230 = !{ptr @__bpf_trace_tp_map_sched_kthread_stop, !1, !"__bpf_trace_tp_map_sched_kthread_stop", i1 false, i1 false}
!231 = !{ptr @__bpf_trace_tp_map_sched_kthread_stop_ret, !5, !"__bpf_trace_tp_map_sched_kthread_stop_ret", i1 false, i1 false}
!232 = !{ptr @__bpf_trace_tp_map_sched_kthread_work_queue_work, !9, !"__bpf_trace_tp_map_sched_kthread_work_queue_work", i1 false, i1 false}
!233 = !{ptr @__bpf_trace_tp_map_sched_kthread_work_execute_start, !13, !"__bpf_trace_tp_map_sched_kthread_work_execute_start", i1 false, i1 false}
!234 = !{ptr @__bpf_trace_tp_map_sched_kthread_work_execute_end, !17, !"__bpf_trace_tp_map_sched_kthread_work_execute_end", i1 false, i1 false}
!235 = !{ptr @__bpf_trace_tp_map_sched_waking, !21, !"__bpf_trace_tp_map_sched_waking", i1 false, i1 false}
!236 = !{ptr @__bpf_trace_tp_map_sched_wakeup, !25, !"__bpf_trace_tp_map_sched_wakeup", i1 false, i1 false}
!237 = !{ptr @__bpf_trace_tp_map_sched_wakeup_new, !29, !"__bpf_trace_tp_map_sched_wakeup_new", i1 false, i1 false}
!238 = !{ptr @__bpf_trace_tp_map_sched_switch, !33, !"__bpf_trace_tp_map_sched_switch", i1 false, i1 false}
!239 = !{ptr @__bpf_trace_tp_map_sched_migrate_task, !37, !"__bpf_trace_tp_map_sched_migrate_task", i1 false, i1 false}
!240 = !{ptr @__bpf_trace_tp_map_sched_process_free, !41, !"__bpf_trace_tp_map_sched_process_free", i1 false, i1 false}
!241 = !{ptr @__bpf_trace_tp_map_sched_process_exit, !45, !"__bpf_trace_tp_map_sched_process_exit", i1 false, i1 false}
!242 = !{ptr @__bpf_trace_tp_map_sched_wait_task, !49, !"__bpf_trace_tp_map_sched_wait_task", i1 false, i1 false}
!243 = !{ptr @__bpf_trace_tp_map_sched_process_wait, !53, !"__bpf_trace_tp_map_sched_process_wait", i1 false, i1 false}
!244 = !{ptr @__bpf_trace_tp_map_sched_process_fork, !57, !"__bpf_trace_tp_map_sched_process_fork", i1 false, i1 false}
!245 = !{ptr @__bpf_trace_tp_map_sched_process_exec, !61, !"__bpf_trace_tp_map_sched_process_exec", i1 false, i1 false}
!246 = !{ptr @__bpf_trace_tp_map_sched_stat_wait, !65, !"__bpf_trace_tp_map_sched_stat_wait", i1 false, i1 false}
!247 = !{ptr @__bpf_trace_tp_map_sched_stat_sleep, !69, !"__bpf_trace_tp_map_sched_stat_sleep", i1 false, i1 false}
!248 = !{ptr @__bpf_trace_tp_map_sched_stat_iowait, !73, !"__bpf_trace_tp_map_sched_stat_iowait", i1 false, i1 false}
!249 = !{ptr @__bpf_trace_tp_map_sched_stat_blocked, !77, !"__bpf_trace_tp_map_sched_stat_blocked", i1 false, i1 false}
!250 = !{ptr @__bpf_trace_tp_map_sched_stat_runtime, !81, !"__bpf_trace_tp_map_sched_stat_runtime", i1 false, i1 false}
!251 = !{ptr @__bpf_trace_tp_map_sched_pi_setprio, !85, !"__bpf_trace_tp_map_sched_pi_setprio", i1 false, i1 false}
!252 = !{ptr @__bpf_trace_tp_map_sched_process_hang, !89, !"__bpf_trace_tp_map_sched_process_hang", i1 false, i1 false}
!253 = !{ptr @__bpf_trace_tp_map_sched_move_numa, !93, !"__bpf_trace_tp_map_sched_move_numa", i1 false, i1 false}
!254 = !{ptr @__bpf_trace_tp_map_sched_stick_numa, !97, !"__bpf_trace_tp_map_sched_stick_numa", i1 false, i1 false}
!255 = !{ptr @__bpf_trace_tp_map_sched_swap_numa, !101, !"__bpf_trace_tp_map_sched_swap_numa", i1 false, i1 false}
!256 = !{ptr @__bpf_trace_tp_map_sched_wake_idle_without_ipi, !105, !"__bpf_trace_tp_map_sched_wake_idle_without_ipi", i1 false, i1 false}
!257 = !{ptr @__bpf_trace_tp_map_pelt_cfs_tp, !109, !"__bpf_trace_tp_map_pelt_cfs_tp", i1 false, i1 false}
!258 = !{ptr @__bpf_trace_tp_map_pelt_rt_tp, !113, !"__bpf_trace_tp_map_pelt_rt_tp", i1 false, i1 false}
!259 = !{ptr @__bpf_trace_tp_map_pelt_dl_tp, !117, !"__bpf_trace_tp_map_pelt_dl_tp", i1 false, i1 false}
!260 = !{ptr @__bpf_trace_tp_map_pelt_thermal_tp, !121, !"__bpf_trace_tp_map_pelt_thermal_tp", i1 false, i1 false}
!261 = !{ptr @__bpf_trace_tp_map_pelt_irq_tp, !125, !"__bpf_trace_tp_map_pelt_irq_tp", i1 false, i1 false}
!262 = !{ptr @__bpf_trace_tp_map_pelt_se_tp, !129, !"__bpf_trace_tp_map_pelt_se_tp", i1 false, i1 false}
!263 = !{ptr @__bpf_trace_tp_map_sched_cpu_capacity_tp, !133, !"__bpf_trace_tp_map_sched_cpu_capacity_tp", i1 false, i1 false}
!264 = !{ptr @__bpf_trace_tp_map_sched_overutilized_tp, !137, !"__bpf_trace_tp_map_sched_overutilized_tp", i1 false, i1 false}
!265 = !{ptr @__bpf_trace_tp_map_sched_util_est_cfs_tp, !141, !"__bpf_trace_tp_map_sched_util_est_cfs_tp", i1 false, i1 false}
!266 = !{ptr @__bpf_trace_tp_map_sched_util_est_se_tp, !145, !"__bpf_trace_tp_map_sched_util_est_se_tp", i1 false, i1 false}
!267 = !{ptr @__bpf_trace_tp_map_sched_update_nr_running_tp, !149, !"__bpf_trace_tp_map_sched_update_nr_running_tp", i1 false, i1 false}
!268 = !{ptr @__ksymtab___tracepoint_pelt_cfs_tp, !269, !"__ksymtab___tracepoint_pelt_cfs_tp", i1 false, i1 false}
!269 = !{!"../kernel/sched/core.c", i32 34, i32 1}
!270 = !{ptr @__ksymtab___traceiter_pelt_cfs_tp, !269, !"__ksymtab___traceiter_pelt_cfs_tp", i1 false, i1 false}
!271 = !{ptr @__ksymtab___SCK__tp_func_pelt_cfs_tp, !269, !"__ksymtab___SCK__tp_func_pelt_cfs_tp", i1 false, i1 false}
!272 = !{ptr @__ksymtab___tracepoint_pelt_rt_tp, !273, !"__ksymtab___tracepoint_pelt_rt_tp", i1 false, i1 false}
!273 = !{!"../kernel/sched/core.c", i32 35, i32 1}
!274 = !{ptr @__ksymtab___traceiter_pelt_rt_tp, !273, !"__ksymtab___traceiter_pelt_rt_tp", i1 false, i1 false}
!275 = !{ptr @__ksymtab___SCK__tp_func_pelt_rt_tp, !273, !"__ksymtab___SCK__tp_func_pelt_rt_tp", i1 false, i1 false}
!276 = !{ptr @__ksymtab___tracepoint_pelt_dl_tp, !277, !"__ksymtab___tracepoint_pelt_dl_tp", i1 false, i1 false}
!277 = !{!"../kernel/sched/core.c", i32 36, i32 1}
!278 = !{ptr @__ksymtab___traceiter_pelt_dl_tp, !277, !"__ksymtab___traceiter_pelt_dl_tp", i1 false, i1 false}
!279 = !{ptr @__ksymtab___SCK__tp_func_pelt_dl_tp, !277, !"__ksymtab___SCK__tp_func_pelt_dl_tp", i1 false, i1 false}
!280 = !{ptr @__ksymtab___tracepoint_pelt_irq_tp, !281, !"__ksymtab___tracepoint_pelt_irq_tp", i1 false, i1 false}
!281 = !{!"../kernel/sched/core.c", i32 37, i32 1}
!282 = !{ptr @__ksymtab___traceiter_pelt_irq_tp, !281, !"__ksymtab___traceiter_pelt_irq_tp", i1 false, i1 false}
!283 = !{ptr @__ksymtab___SCK__tp_func_pelt_irq_tp, !281, !"__ksymtab___SCK__tp_func_pelt_irq_tp", i1 false, i1 false}
!284 = !{ptr @__ksymtab___tracepoint_pelt_se_tp, !285, !"__ksymtab___tracepoint_pelt_se_tp", i1 false, i1 false}
!285 = !{!"../kernel/sched/core.c", i32 38, i32 1}
!286 = !{ptr @__ksymtab___traceiter_pelt_se_tp, !285, !"__ksymtab___traceiter_pelt_se_tp", i1 false, i1 false}
!287 = !{ptr @__ksymtab___SCK__tp_func_pelt_se_tp, !285, !"__ksymtab___SCK__tp_func_pelt_se_tp", i1 false, i1 false}
!288 = !{ptr @__ksymtab___tracepoint_sched_cpu_capacity_tp, !289, !"__ksymtab___tracepoint_sched_cpu_capacity_tp", i1 false, i1 false}
!289 = !{!"../kernel/sched/core.c", i32 39, i32 1}
!290 = !{ptr @__ksymtab___traceiter_sched_cpu_capacity_tp, !289, !"__ksymtab___traceiter_sched_cpu_capacity_tp", i1 false, i1 false}
!291 = !{ptr @__ksymtab___SCK__tp_func_sched_cpu_capacity_tp, !289, !"__ksymtab___SCK__tp_func_sched_cpu_capacity_tp", i1 false, i1 false}
!292 = !{ptr @__ksymtab___tracepoint_sched_overutilized_tp, !293, !"__ksymtab___tracepoint_sched_overutilized_tp", i1 false, i1 false}
!293 = !{!"../kernel/sched/core.c", i32 40, i32 1}
!294 = !{ptr @__ksymtab___traceiter_sched_overutilized_tp, !293, !"__ksymtab___traceiter_sched_overutilized_tp", i1 false, i1 false}
!295 = !{ptr @__ksymtab___SCK__tp_func_sched_overutilized_tp, !293, !"__ksymtab___SCK__tp_func_sched_overutilized_tp", i1 false, i1 false}
!296 = !{ptr @__ksymtab___tracepoint_sched_util_est_cfs_tp, !297, !"__ksymtab___tracepoint_sched_util_est_cfs_tp", i1 false, i1 false}
!297 = !{!"../kernel/sched/core.c", i32 41, i32 1}
!298 = !{ptr @__ksymtab___traceiter_sched_util_est_cfs_tp, !297, !"__ksymtab___traceiter_sched_util_est_cfs_tp", i1 false, i1 false}
!299 = !{ptr @__ksymtab___SCK__tp_func_sched_util_est_cfs_tp, !297, !"__ksymtab___SCK__tp_func_sched_util_est_cfs_tp", i1 false, i1 false}
!300 = !{ptr @__ksymtab___tracepoint_sched_util_est_se_tp, !301, !"__ksymtab___tracepoint_sched_util_est_se_tp", i1 false, i1 false}
!301 = !{!"../kernel/sched/core.c", i32 42, i32 1}
!302 = !{ptr @__ksymtab___traceiter_sched_util_est_se_tp, !301, !"__ksymtab___traceiter_sched_util_est_se_tp", i1 false, i1 false}
!303 = !{ptr @__ksymtab___SCK__tp_func_sched_util_est_se_tp, !301, !"__ksymtab___SCK__tp_func_sched_util_est_se_tp", i1 false, i1 false}
!304 = !{ptr @__ksymtab___tracepoint_sched_update_nr_running_tp, !305, !"__ksymtab___tracepoint_sched_update_nr_running_tp", i1 false, i1 false}
!305 = !{!"../kernel/sched/core.c", i32 43, i32 1}
!306 = !{ptr @__ksymtab___traceiter_sched_update_nr_running_tp, !305, !"__ksymtab___traceiter_sched_update_nr_running_tp", i1 false, i1 false}
!307 = !{ptr @__ksymtab___SCK__tp_func_sched_update_nr_running_tp, !305, !"__ksymtab___SCK__tp_func_sched_update_nr_running_tp", i1 false, i1 false}
!308 = !{ptr @sysctl_sched_features, !309, !"sysctl_sched_features", i1 false, i1 false}
!309 = !{!"../kernel/sched/core.c", i32 57, i32 26}
!310 = !{ptr @sysctl_resched_latency_warn_ms, !311, !"sysctl_resched_latency_warn_ms", i1 false, i1 false}
!311 = !{!"../kernel/sched/core.c", i32 69, i32 19}
!312 = !{ptr @sysctl_resched_latency_warn_once, !313, !"sysctl_resched_latency_warn_once", i1 false, i1 false}
!313 = !{!"../kernel/sched/core.c", i32 70, i32 19}
!314 = !{ptr @sysctl_sched_nr_migrate, !315, !"sysctl_sched_nr_migrate", i1 false, i1 false}
!315 = !{!"../kernel/sched/core.c", i32 80, i32 26}
!316 = !{ptr @sysctl_sched_rt_period, !317, !"sysctl_sched_rt_period", i1 false, i1 false}
!317 = !{!"../kernel/sched/core.c", i32 87, i32 14}
!318 = !{ptr @__sched_core_enabled, !319, !"__sched_core_enabled", i1 false, i1 false}
!319 = !{!"../kernel/sched/core.c", i32 93, i32 1}
!320 = !{ptr @.str, !321, !"<string literal>", i1 false, i1 false}
!321 = !{!"../kernel/sched/core.c", i32 361, i32 9}
!322 = !{ptr @sched_core_put._work, !321, !"_work", i1 false, i1 false}
!323 = !{ptr @sysctl_sched_rt_runtime, !324, !"sysctl_sched_rt_runtime", i1 false, i1 false}
!324 = !{!"../kernel/sched/core.c", i32 386, i32 5}
!325 = distinct !{null, !326, !"__already_done", i1 false, i1 false}
!326 = !{!"../kernel/sched/core.c", i32 542, i32 2}
!327 = !{ptr @.str.1, !326, !"<string literal>", i1 false, i1 false}
!328 = distinct !{null, !329, !"__already_done", i1 false, i1 false}
!329 = !{!"../kernel/sched/core.c", i32 690, i32 3}
!330 = !{ptr @.str.2, !329, !"<string literal>", i1 false, i1 false}
!331 = distinct !{null, !332, !"__warned", i1 false, i1 false}
!332 = !{!"../kernel/sched/core.c", i32 1036, i32 2}
!333 = !{ptr @.str.3, !332, !"<string literal>", i1 false, i1 false}
!334 = distinct !{null, !335, !"__warned", i1 false, i1 false}
!335 = !{!"../kernel/sched/core.c", i32 1192, i32 2}
!336 = !{ptr @.str.4, !335, !"<string literal>", i1 false, i1 false}
!337 = !{ptr @sysctl_sched_uclamp_util_min, !338, !"sysctl_sched_uclamp_util_min", i1 false, i1 false}
!338 = !{!"../kernel/sched/core.c", i32 1257, i32 14}
!339 = !{ptr @sysctl_sched_uclamp_util_max, !340, !"sysctl_sched_uclamp_util_max", i1 false, i1 false}
!340 = !{!"../kernel/sched/core.c", i32 1260, i32 14}
!341 = !{ptr @sysctl_sched_uclamp_util_min_rt_default, !342, !"sysctl_sched_uclamp_util_min_rt_default", i1 false, i1 false}
!342 = !{!"../kernel/sched/core.c", i32 1277, i32 14}
!343 = !{ptr @sched_uclamp_used, !344, !"sched_uclamp_used", i1 false, i1 false}
!344 = !{!"../kernel/sched/core.c", i32 1300, i32 1}
!345 = !{ptr @__ksymtab_migrate_disable, !346, !"__ksymtab_migrate_disable", i1 false, i1 false}
!346 = !{!"../kernel/sched/core.c", i32 2176, i32 1}
!347 = distinct !{null, !348, !"__already_done", i1 false, i1 false}
!348 = !{!"../kernel/sched/core.c", i32 2187, i32 6}
!349 = !{ptr @__ksymtab_migrate_enable, !350, !"__ksymtab_migrate_enable", i1 false, i1 false}
!350 = !{!"../kernel/sched/core.c", i32 2207, i32 1}
!351 = !{ptr @__ksymtab_set_cpus_allowed_ptr, !352, !"__ksymtab_set_cpus_allowed_ptr", i1 false, i1 false}
!352 = !{!"../kernel/sched/core.c", i32 2892, i32 1}
!353 = !{ptr @__func__.force_compatible_cpus_allowed_ptr, !354, !"<string literal>", i1 false, i1 false}
!354 = !{!"../kernel/sched/core.c", i32 2983, i32 6}
!355 = !{ptr @.str.5, !356, !"<string literal>", i1 false, i1 false}
!356 = !{!"../kernel/sched/core.c", i32 2984, i32 3}
!357 = !{ptr @force_compatible_cpus_allowed_ptr._entry, !356, !"_entry", i1 false, i1 false}
!358 = !{ptr @force_compatible_cpus_allowed_ptr._entry_ptr, !356, !"_entry_ptr", i1 false, i1 false}
!359 = distinct !{null, !360, !"__already_done", i1 false, i1 false}
!360 = !{!"../kernel/sched/core.c", i32 3035, i32 2}
!361 = distinct !{null, !362, !"__already_done", i1 false, i1 false}
!362 = !{!"../kernel/sched/core.c", i32 3042, i32 2}
!363 = distinct !{null, !364, !"__already_done", i1 false, i1 false}
!364 = !{!"../kernel/sched/core.c", i32 3057, i32 2}
!365 = distinct !{null, !366, !"__already_done", i1 false, i1 false}
!366 = !{!"../kernel/sched/core.c", i32 3063, i32 2}
!367 = distinct !{null, !368, !"__already_done", i1 false, i1 false}
!368 = !{!"../kernel/sched/core.c", i32 3065, i32 2}
!369 = distinct !{null, !370, !"__already_done", i1 false, i1 false}
!370 = !{!"../kernel/sched/core.c", i32 3290, i32 4}
!371 = !{ptr @__ksymtab_kick_process, !372, !"__ksymtab_kick_process", i1 false, i1 false}
!372 = !{!"../kernel/sched/core.c", i32 3329, i32 1}
!373 = !{ptr @sched_set_stop_task.stop_pi_lock, !374, !"stop_pi_lock", i1 false, i1 false}
!374 = !{!"../kernel/sched/core.c", i32 3455, i32 31}
!375 = !{ptr @.str.10, !376, !"<string literal>", i1 false, i1 false}
!376 = !{!"../kernel/sched/core.c", i32 3484, i32 3}
!377 = distinct !{null, !378, !"__already_done", i1 false, i1 false}
!378 = !{!"../kernel/sched/core.c", i32 3683, i32 7}
!379 = distinct !{null, !380, !"__already_done", i1 false, i1 false}
!380 = !{!"../kernel/sched/core.c", i32 3686, i32 7}
!381 = distinct !{null, !382, !"__warned", i1 false, i1 false}
!382 = !{!"../kernel/sched/core.c", i32 3728, i32 20}
!383 = !{ptr @__ksymtab_wake_up_process, !384, !"__ksymtab_wake_up_process", i1 false, i1 false}
!384 = !{!"../kernel/sched/core.c", i32 4219, i32 1}
!385 = !{ptr @sched_numa_balancing, !386, !"sched_numa_balancing", i1 false, i1 false}
!386 = !{!"../kernel/sched/core.c", i32 4278, i32 1}
!387 = !{ptr @sched_schedstats, !388, !"sched_schedstats", i1 false, i1 false}
!388 = !{!"../kernel/sched/core.c", i32 4315, i32 1}
!389 = !{ptr @.str.12, !390, !"<string literal>", i1 false, i1 false}
!390 = !{!"../kernel/sched/core.c", i32 4328, i32 3}
!391 = !{ptr @.str.13, !390, !"<string literal>", i1 false, i1 false}
!392 = !{ptr @force_schedstat_enabled._entry, !390, !"_entry", i1 false, i1 false}
!393 = !{ptr @force_schedstat_enabled._entry_ptr, !390, !"_entry_ptr", i1 false, i1 false}
!394 = !{ptr @__setup_setup_schedstats, !395, !"__setup_setup_schedstats", i1 false, i1 false}
!395 = !{!"../kernel/sched/core.c", i32 4352, i32 1}
!396 = !{ptr @balance_push_callback, !397, !"balance_push_callback", i1 false, i1 false}
!397 = !{!"../kernel/sched/core.c", i32 4680, i32 22}
!398 = !{ptr @__ksymtab_single_task_running, !399, !"__ksymtab_single_task_running", i1 false, i1 false}
!399 = !{!"../kernel/sched/core.c", i32 5034, i32 1}
!400 = !{ptr @__ksymtab_kstat, !401, !"__ksymtab_kstat", i1 false, i1 false}
!401 = !{!"../kernel/sched/core.c", i32 5132, i32 1}
!402 = !{ptr @__ksymtab_kernel_cpustat, !403, !"__ksymtab_kernel_cpustat", i1 false, i1 false}
!403 = !{!"../kernel/sched/core.c", i32 5133, i32 1}
!404 = !{ptr @__setup_setup_resched_latency_warn_ms, !405, !"__setup_setup_resched_latency_warn_ms", i1 false, i1 false}
!405 = !{!"../kernel/sched/core.c", i32 5240, i32 1}
!406 = distinct !{null, !407, !"__already_done", i1 false, i1 false}
!407 = !{!"../kernel/sched/core.c", i32 6317, i32 2}
!408 = !{ptr @__ksymtab_schedule, !409, !"__ksymtab_schedule", i1 false, i1 false}
!409 = !{!"../kernel/sched/core.c", i32 6382, i32 1}
!410 = distinct !{null, !411, !"__already_done", i1 false, i1 false}
!411 = !{!"../kernel/sched/core.c", i32 6403, i32 2}
!412 = distinct !{null, !413, !"__already_done", i1 false, i1 false}
!413 = !{!"../kernel/sched/core.c", i32 6730, i32 2}
!414 = !{ptr @__ksymtab_default_wake_function, !415, !"__ksymtab_default_wake_function", i1 false, i1 false}
!415 = !{!"../kernel/sched/core.c", i32 6733, i32 1}
!416 = !{ptr @__ksymtab_set_user_nice, !417, !"__ksymtab_set_user_nice", i1 false, i1 false}
!417 = !{!"../kernel/sched/core.c", i32 6951, i32 1}
!418 = !{ptr @.str.14, !419, !"<string literal>", i1 false, i1 false}
!419 = !{!"../kernel/sched/core.c", i32 6976, i32 1}
!420 = !{ptr @event_enter__nice, !419, !"event_enter__nice", i1 false, i1 false}
!421 = !{ptr @__event_enter__nice, !419, !"__event_enter__nice", i1 false, i1 false}
!422 = !{ptr @.str.15, !419, !"<string literal>", i1 false, i1 false}
!423 = !{ptr @event_exit__nice, !419, !"event_exit__nice", i1 false, i1 false}
!424 = !{ptr @__event_exit__nice, !419, !"__event_exit__nice", i1 false, i1 false}
!425 = !{ptr @.str.16, !419, !"<string literal>", i1 false, i1 false}
!426 = !{ptr @__syscall_meta__nice, !419, !"__syscall_meta__nice", i1 false, i1 false}
!427 = !{ptr @__p_syscall_meta__nice, !419, !"__p_syscall_meta__nice", i1 false, i1 false}
!428 = !{ptr @__ksymtab_sched_setattr_nocheck, !429, !"__ksymtab_sched_setattr_nocheck", i1 false, i1 false}
!429 = !{!"../kernel/sched/core.c", i32 7558, i32 1}
!430 = distinct !{null, !431, !"__already_done", i1 false, i1 false}
!431 = !{!"../kernel/sched/core.c", i32 7600, i32 2}
!432 = !{ptr @__ksymtab_sched_set_fifo, !433, !"__ksymtab_sched_set_fifo", i1 false, i1 false}
!433 = !{!"../kernel/sched/core.c", i32 7602, i32 1}
!434 = distinct !{null, !435, !"__already_done", i1 false, i1 false}
!435 = !{!"../kernel/sched/core.c", i32 7610, i32 2}
!436 = !{ptr @__ksymtab_sched_set_fifo_low, !437, !"__ksymtab_sched_set_fifo_low", i1 false, i1 false}
!437 = !{!"../kernel/sched/core.c", i32 7612, i32 1}
!438 = distinct !{null, !439, !"__already_done", i1 false, i1 false}
!439 = !{!"../kernel/sched/core.c", i32 7620, i32 2}
!440 = !{ptr @__ksymtab_sched_set_normal, !441, !"__ksymtab_sched_set_normal", i1 false, i1 false}
!441 = !{!"../kernel/sched/core.c", i32 7622, i32 1}
!442 = !{ptr @.str.17, !443, !"<string literal>", i1 false, i1 false}
!443 = !{!"../kernel/sched/core.c", i32 7714, i32 1}
!444 = !{ptr @event_enter__sched_setscheduler, !443, !"event_enter__sched_setscheduler", i1 false, i1 false}
!445 = !{ptr @__event_enter__sched_setscheduler, !443, !"__event_enter__sched_setscheduler", i1 false, i1 false}
!446 = !{ptr @.str.18, !443, !"<string literal>", i1 false, i1 false}
!447 = !{ptr @event_exit__sched_setscheduler, !443, !"event_exit__sched_setscheduler", i1 false, i1 false}
!448 = !{ptr @__event_exit__sched_setscheduler, !443, !"__event_exit__sched_setscheduler", i1 false, i1 false}
!449 = !{ptr @.str.19, !443, !"<string literal>", i1 false, i1 false}
!450 = !{ptr @__syscall_meta__sched_setscheduler, !443, !"__syscall_meta__sched_setscheduler", i1 false, i1 false}
!451 = !{ptr @__p_syscall_meta__sched_setscheduler, !443, !"__p_syscall_meta__sched_setscheduler", i1 false, i1 false}
!452 = !{ptr @.str.20, !453, !"<string literal>", i1 false, i1 false}
!453 = !{!"../kernel/sched/core.c", i32 7729, i32 1}
!454 = !{ptr @event_enter__sched_setparam, !453, !"event_enter__sched_setparam", i1 false, i1 false}
!455 = !{ptr @__event_enter__sched_setparam, !453, !"__event_enter__sched_setparam", i1 false, i1 false}
!456 = !{ptr @.str.21, !453, !"<string literal>", i1 false, i1 false}
!457 = !{ptr @event_exit__sched_setparam, !453, !"event_exit__sched_setparam", i1 false, i1 false}
!458 = !{ptr @__event_exit__sched_setparam, !453, !"__event_exit__sched_setparam", i1 false, i1 false}
!459 = !{ptr @.str.22, !453, !"<string literal>", i1 false, i1 false}
!460 = !{ptr @__syscall_meta__sched_setparam, !453, !"__syscall_meta__sched_setparam", i1 false, i1 false}
!461 = !{ptr @__p_syscall_meta__sched_setparam, !453, !"__p_syscall_meta__sched_setparam", i1 false, i1 false}
!462 = !{ptr @.str.23, !463, !"<string literal>", i1 false, i1 false}
!463 = !{!"../kernel/sched/core.c", i32 7740, i32 1}
!464 = !{ptr @event_enter__sched_setattr, !463, !"event_enter__sched_setattr", i1 false, i1 false}
!465 = !{ptr @__event_enter__sched_setattr, !463, !"__event_enter__sched_setattr", i1 false, i1 false}
!466 = !{ptr @.str.24, !463, !"<string literal>", i1 false, i1 false}
!467 = !{ptr @event_exit__sched_setattr, !463, !"event_exit__sched_setattr", i1 false, i1 false}
!468 = !{ptr @__event_exit__sched_setattr, !463, !"__event_exit__sched_setattr", i1 false, i1 false}
!469 = !{ptr @.str.25, !463, !"<string literal>", i1 false, i1 false}
!470 = !{ptr @__syscall_meta__sched_setattr, !463, !"__syscall_meta__sched_setattr", i1 false, i1 false}
!471 = !{ptr @__p_syscall_meta__sched_setattr, !463, !"__p_syscall_meta__sched_setattr", i1 false, i1 false}
!472 = !{ptr @.str.26, !473, !"<string literal>", i1 false, i1 false}
!473 = !{!"../kernel/sched/core.c", i32 7783, i32 1}
!474 = !{ptr @event_enter__sched_getscheduler, !473, !"event_enter__sched_getscheduler", i1 false, i1 false}
!475 = !{ptr @__event_enter__sched_getscheduler, !473, !"__event_enter__sched_getscheduler", i1 false, i1 false}
!476 = !{ptr @.str.27, !473, !"<string literal>", i1 false, i1 false}
!477 = !{ptr @event_exit__sched_getscheduler, !473, !"event_exit__sched_getscheduler", i1 false, i1 false}
!478 = !{ptr @__event_exit__sched_getscheduler, !473, !"__event_exit__sched_getscheduler", i1 false, i1 false}
!479 = !{ptr @.str.28, !473, !"<string literal>", i1 false, i1 false}
!480 = !{ptr @__syscall_meta__sched_getscheduler, !473, !"__syscall_meta__sched_getscheduler", i1 false, i1 false}
!481 = !{ptr @__p_syscall_meta__sched_getscheduler, !473, !"__p_syscall_meta__sched_getscheduler", i1 false, i1 false}
!482 = !{ptr @.str.29, !483, !"<string literal>", i1 false, i1 false}
!483 = !{!"../kernel/sched/core.c", i32 7812, i32 1}
!484 = !{ptr @event_enter__sched_getparam, !483, !"event_enter__sched_getparam", i1 false, i1 false}
!485 = !{ptr @__event_enter__sched_getparam, !483, !"__event_enter__sched_getparam", i1 false, i1 false}
!486 = !{ptr @.str.30, !483, !"<string literal>", i1 false, i1 false}
!487 = !{ptr @event_exit__sched_getparam, !483, !"event_exit__sched_getparam", i1 false, i1 false}
!488 = !{ptr @__event_exit__sched_getparam, !483, !"__event_exit__sched_getparam", i1 false, i1 false}
!489 = !{ptr @.str.31, !483, !"<string literal>", i1 false, i1 false}
!490 = !{ptr @__syscall_meta__sched_getparam, !483, !"__syscall_meta__sched_getparam", i1 false, i1 false}
!491 = !{ptr @__p_syscall_meta__sched_getparam, !483, !"__p_syscall_meta__sched_getparam", i1 false, i1 false}
!492 = !{ptr @.str.32, !493, !"<string literal>", i1 false, i1 false}
!493 = !{!"../kernel/sched/core.c", i32 7893, i32 1}
!494 = !{ptr @event_enter__sched_getattr, !493, !"event_enter__sched_getattr", i1 false, i1 false}
!495 = !{ptr @__event_enter__sched_getattr, !493, !"__event_enter__sched_getattr", i1 false, i1 false}
!496 = !{ptr @.str.33, !493, !"<string literal>", i1 false, i1 false}
!497 = !{ptr @event_exit__sched_getattr, !493, !"event_exit__sched_getattr", i1 false, i1 false}
!498 = !{ptr @__event_exit__sched_getattr, !493, !"__event_exit__sched_getattr", i1 false, i1 false}
!499 = !{ptr @.str.34, !493, !"<string literal>", i1 false, i1 false}
!500 = !{ptr @__syscall_meta__sched_getattr, !493, !"__syscall_meta__sched_getattr", i1 false, i1 false}
!501 = !{ptr @__p_syscall_meta__sched_getattr, !493, !"__p_syscall_meta__sched_getattr", i1 false, i1 false}
!502 = distinct !{null, !503, !"__warned", i1 false, i1 false}
!503 = !{!"../kernel/sched/core.c", i32 8031, i32 19}
!504 = !{ptr @.str.35, !505, !"<string literal>", i1 false, i1 false}
!505 = !{!"../kernel/sched/core.c", i32 8068, i32 1}
!506 = !{ptr @event_enter__sched_setaffinity, !505, !"event_enter__sched_setaffinity", i1 false, i1 false}
!507 = !{ptr @__event_enter__sched_setaffinity, !505, !"__event_enter__sched_setaffinity", i1 false, i1 false}
!508 = !{ptr @.str.36, !505, !"<string literal>", i1 false, i1 false}
!509 = !{ptr @event_exit__sched_setaffinity, !505, !"event_exit__sched_setaffinity", i1 false, i1 false}
!510 = !{ptr @__event_exit__sched_setaffinity, !505, !"__event_exit__sched_setaffinity", i1 false, i1 false}
!511 = !{ptr @.str.37, !505, !"<string literal>", i1 false, i1 false}
!512 = !{ptr @__syscall_meta__sched_setaffinity, !505, !"__syscall_meta__sched_setaffinity", i1 false, i1 false}
!513 = !{ptr @__p_syscall_meta__sched_setaffinity, !505, !"__p_syscall_meta__sched_setaffinity", i1 false, i1 false}
!514 = !{ptr @.str.38, !515, !"<string literal>", i1 false, i1 false}
!515 = !{!"../kernel/sched/core.c", i32 8120, i32 1}
!516 = !{ptr @event_enter__sched_getaffinity, !515, !"event_enter__sched_getaffinity", i1 false, i1 false}
!517 = !{ptr @__event_enter__sched_getaffinity, !515, !"__event_enter__sched_getaffinity", i1 false, i1 false}
!518 = !{ptr @.str.39, !515, !"<string literal>", i1 false, i1 false}
!519 = !{ptr @event_exit__sched_getaffinity, !515, !"event_exit__sched_getaffinity", i1 false, i1 false}
!520 = !{ptr @__event_exit__sched_getaffinity, !515, !"__event_exit__sched_getaffinity", i1 false, i1 false}
!521 = !{ptr @.str.40, !515, !"<string literal>", i1 false, i1 false}
!522 = !{ptr @__syscall_meta__sched_getaffinity, !515, !"__syscall_meta__sched_getaffinity", i1 false, i1 false}
!523 = !{ptr @__p_syscall_meta__sched_getaffinity, !515, !"__p_syscall_meta__sched_getaffinity", i1 false, i1 false}
!524 = !{ptr @.str.41, !525, !"<string literal>", i1 false, i1 false}
!525 = !{!"../kernel/sched/core.c", i32 8173, i32 1}
!526 = !{ptr @event_enter__sched_yield, !525, !"event_enter__sched_yield", i1 false, i1 false}
!527 = !{ptr @__event_enter__sched_yield, !525, !"__event_enter__sched_yield", i1 false, i1 false}
!528 = !{ptr @.str.42, !525, !"<string literal>", i1 false, i1 false}
!529 = !{ptr @event_exit__sched_yield, !525, !"event_exit__sched_yield", i1 false, i1 false}
!530 = !{ptr @__event_exit__sched_yield, !525, !"__event_exit__sched_yield", i1 false, i1 false}
!531 = !{ptr @.str.43, !525, !"<string literal>", i1 false, i1 false}
!532 = !{ptr @__syscall_meta__sched_yield, !525, !"__syscall_meta__sched_yield", i1 false, i1 false}
!533 = !{ptr @__p_syscall_meta__sched_yield, !525, !"__p_syscall_meta__sched_yield", i1 false, i1 false}
!534 = !{ptr @__ksymtab___cond_resched, !535, !"__ksymtab___cond_resched", i1 false, i1 false}
!535 = !{!"../kernel/sched/core.c", i32 8202, i32 1}
!536 = !{ptr @__ksymtab___cond_resched_lock, !537, !"__ksymtab___cond_resched_lock", i1 false, i1 false}
!537 = !{!"../kernel/sched/core.c", i32 8237, i32 1}
!538 = !{ptr @__ksymtab___cond_resched_rwlock_read, !539, !"__ksymtab___cond_resched_rwlock_read", i1 false, i1 false}
!539 = !{!"../kernel/sched/core.c", i32 8255, i32 1}
!540 = !{ptr @__ksymtab___cond_resched_rwlock_write, !541, !"__ksymtab___cond_resched_rwlock_write", i1 false, i1 false}
!541 = !{!"../kernel/sched/core.c", i32 8273, i32 1}
!542 = distinct !{null, !543, !"__already_done", i1 false, i1 false}
!543 = !{!"../kernel/sched/core.c", i32 8299, i32 2}
!544 = !{ptr @__ksymtab_yield, !545, !"__ksymtab_yield", i1 false, i1 false}
!545 = !{!"../kernel/sched/core.c", i32 8302, i32 1}
!546 = !{ptr @__ksymtab_yield_to, !547, !"__ksymtab_yield_to", i1 false, i1 false}
!547 = !{!"../kernel/sched/core.c", i32 8376, i32 1}
!548 = !{ptr @__ksymtab_io_schedule_timeout, !549, !"__ksymtab_io_schedule_timeout", i1 false, i1 false}
!549 = !{!"../kernel/sched/core.c", i32 8409, i32 1}
!550 = !{ptr @__ksymtab_io_schedule, !551, !"__ksymtab_io_schedule", i1 false, i1 false}
!551 = !{!"../kernel/sched/core.c", i32 8419, i32 1}
!552 = !{ptr @.str.44, !553, !"<string literal>", i1 false, i1 false}
!553 = !{!"../kernel/sched/core.c", i32 8429, i32 1}
!554 = !{ptr @event_enter__sched_get_priority_max, !553, !"event_enter__sched_get_priority_max", i1 false, i1 false}
!555 = !{ptr @__event_enter__sched_get_priority_max, !553, !"__event_enter__sched_get_priority_max", i1 false, i1 false}
!556 = !{ptr @.str.45, !553, !"<string literal>", i1 false, i1 false}
!557 = !{ptr @event_exit__sched_get_priority_max, !553, !"event_exit__sched_get_priority_max", i1 false, i1 false}
!558 = !{ptr @__event_exit__sched_get_priority_max, !553, !"__event_exit__sched_get_priority_max", i1 false, i1 false}
!559 = !{ptr @.str.46, !553, !"<string literal>", i1 false, i1 false}
!560 = !{ptr @__syscall_meta__sched_get_priority_max, !553, !"__syscall_meta__sched_get_priority_max", i1 false, i1 false}
!561 = !{ptr @__p_syscall_meta__sched_get_priority_max, !553, !"__p_syscall_meta__sched_get_priority_max", i1 false, i1 false}
!562 = !{ptr @.str.47, !563, !"<string literal>", i1 false, i1 false}
!563 = !{!"../kernel/sched/core.c", i32 8456, i32 1}
!564 = !{ptr @event_enter__sched_get_priority_min, !563, !"event_enter__sched_get_priority_min", i1 false, i1 false}
!565 = !{ptr @__event_enter__sched_get_priority_min, !563, !"__event_enter__sched_get_priority_min", i1 false, i1 false}
!566 = !{ptr @.str.48, !563, !"<string literal>", i1 false, i1 false}
!567 = !{ptr @event_exit__sched_get_priority_min, !563, !"event_exit__sched_get_priority_min", i1 false, i1 false}
!568 = !{ptr @__event_exit__sched_get_priority_min, !563, !"__event_exit__sched_get_priority_min", i1 false, i1 false}
!569 = !{ptr @.str.49, !563, !"<string literal>", i1 false, i1 false}
!570 = !{ptr @__syscall_meta__sched_get_priority_min, !563, !"__syscall_meta__sched_get_priority_min", i1 false, i1 false}
!571 = !{ptr @__p_syscall_meta__sched_get_priority_min, !563, !"__p_syscall_meta__sched_get_priority_min", i1 false, i1 false}
!572 = !{ptr @.str.50, !573, !"<string literal>", i1 false, i1 false}
!573 = !{!"../kernel/sched/core.c", i32 8521, i32 1}
!574 = !{ptr @event_enter__sched_rr_get_interval, !573, !"event_enter__sched_rr_get_interval", i1 false, i1 false}
!575 = !{ptr @__event_enter__sched_rr_get_interval, !573, !"__event_enter__sched_rr_get_interval", i1 false, i1 false}
!576 = !{ptr @.str.51, !573, !"<string literal>", i1 false, i1 false}
!577 = !{ptr @event_exit__sched_rr_get_interval, !573, !"event_exit__sched_rr_get_interval", i1 false, i1 false}
!578 = !{ptr @__event_exit__sched_rr_get_interval, !573, !"__event_exit__sched_rr_get_interval", i1 false, i1 false}
!579 = !{ptr @.str.52, !573, !"<string literal>", i1 false, i1 false}
!580 = !{ptr @__syscall_meta__sched_rr_get_interval, !573, !"__syscall_meta__sched_rr_get_interval", i1 false, i1 false}
!581 = !{ptr @__p_syscall_meta__sched_rr_get_interval, !573, !"__p_syscall_meta__sched_rr_get_interval", i1 false, i1 false}
!582 = !{ptr @.str.53, !583, !"<string literal>", i1 false, i1 false}
!583 = !{!"../kernel/sched/core.c", i32 8534, i32 1}
!584 = !{ptr @event_enter__sched_rr_get_interval_time32, !583, !"event_enter__sched_rr_get_interval_time32", i1 false, i1 false}
!585 = !{ptr @__event_enter__sched_rr_get_interval_time32, !583, !"__event_enter__sched_rr_get_interval_time32", i1 false, i1 false}
!586 = !{ptr @.str.54, !583, !"<string literal>", i1 false, i1 false}
!587 = !{ptr @event_exit__sched_rr_get_interval_time32, !583, !"event_exit__sched_rr_get_interval_time32", i1 false, i1 false}
!588 = !{ptr @__event_exit__sched_rr_get_interval_time32, !583, !"__event_exit__sched_rr_get_interval_time32", i1 false, i1 false}
!589 = !{ptr @.str.55, !583, !"<string literal>", i1 false, i1 false}
!590 = !{ptr @__syscall_meta__sched_rr_get_interval_time32, !583, !"__syscall_meta__sched_rr_get_interval_time32", i1 false, i1 false}
!591 = !{ptr @__p_syscall_meta__sched_rr_get_interval_time32, !583, !"__p_syscall_meta__sched_rr_get_interval_time32", i1 false, i1 false}
!592 = !{ptr @.str.56, !593, !"<string literal>", i1 false, i1 false}
!593 = !{!"../kernel/sched/core.c", i32 8554, i32 2}
!594 = !{ptr @.str.57, !593, !"<string literal>", i1 false, i1 false}
!595 = !{ptr @sched_show_task._entry, !593, !"_entry", i1 false, i1 false}
!596 = !{ptr @sched_show_task._entry_ptr, !593, !"_entry_ptr", i1 false, i1 false}
!597 = !{ptr @.str.59, !598, !"<string literal>", i1 false, i1 false}
!598 = !{!"../kernel/sched/core.c", i32 8557, i32 3}
!599 = !{ptr @sched_show_task._entry.58, !598, !"_entry", i1 false, i1 false}
!600 = !{ptr @sched_show_task._entry_ptr.60, !598, !"_entry_ptr", i1 false, i1 false}
!601 = distinct !{null, !602, !"__warned", i1 false, i1 false}
!602 = !{!"../kernel/sched/core.c", i32 8564, i32 22}
!603 = !{ptr @.str.62, !604, !"<string literal>", i1 false, i1 false}
!604 = !{!"../kernel/sched/core.c", i32 8566, i32 2}
!605 = !{ptr @sched_show_task._entry.61, !604, !"_entry", i1 false, i1 false}
!606 = !{ptr @sched_show_task._entry_ptr.63, !604, !"_entry_ptr", i1 false, i1 false}
!607 = !{ptr @.str.64, !608, !"<string literal>", i1 false, i1 false}
!608 = !{!"../kernel/sched/core.c", i32 8570, i32 20}
!609 = !{ptr @__ksymtab_sched_show_task, !610, !"__ksymtab_sched_show_task", i1 false, i1 false}
!610 = !{!"../kernel/sched/core.c", i32 8575, i32 1}
!611 = distinct !{null, !612, !"__warned", i1 false, i1 false}
!612 = !{!"../kernel/sched/core.c", i32 8606, i32 2}
!613 = !{ptr @.str.65, !614, !"<string literal>", i1 false, i1 false}
!614 = !{!"../kernel/sched/core.c", i32 8701, i32 22}
!615 = !{ptr @.str.66, !616, !"<string literal>", i1 false, i1 false}
!616 = !{!"../kernel/sched/core.c", i32 8701, i32 31}
!617 = !{ptr @.str.67, !618, !"<string literal>", i1 false, i1 false}
!618 = !{!"../kernel/sched/core.c", i32 9225, i32 3}
!619 = !{ptr @.str.68, !620, !"<string literal>", i1 false, i1 false}
!620 = !{!"../kernel/sched/core.c", i32 9226, i32 21}
!621 = !{ptr @__initcall__kmod_core__743_9268_migration_initearly, !622, !"__initcall__kmod_core__743_9268_migration_initearly", i1 false, i1 false}
!622 = !{!"../kernel/sched/core.c", i32 9268, i32 1}
!623 = !{ptr @task_groups, !624, !"task_groups", i1 false, i1 false}
!624 = !{!"../kernel/sched/core.c", i32 9290, i32 1}
!625 = !{ptr @.str.69, !626, !"<string literal>", i1 false, i1 false}
!626 = !{!"../kernel/sched/core.c", i32 9364, i32 21}
!627 = !{ptr @sched_init.__key, !628, !"__key", i1 false, i1 false}
!628 = !{!"../kernel/sched/core.c", i32 9376, i32 3}
!629 = !{ptr @.str.70, !628, !"<string literal>", i1 false, i1 false}
!630 = distinct !{null, !631, !"__already_done", i1 false, i1 false}
!631 = !{!"../kernel/sched/core.c", i32 9508, i32 2}
!632 = !{ptr @.str.71, !631, !"<string literal>", i1 false, i1 false}
!633 = !{ptr @__ksymtab___might_sleep, !634, !"__ksymtab___might_sleep", i1 false, i1 false}
!634 = !{!"../kernel/sched/core.c", i32 9516, i32 1}
!635 = !{ptr @__might_resched.prev_jiffy, !636, !"prev_jiffy", i1 false, i1 false}
!636 = !{!"../kernel/sched/core.c", i32 9542, i32 23}
!637 = distinct !{null, !638, !"__warned", i1 false, i1 false}
!638 = !{!"../kernel/sched/core.c", i32 9547, i32 2}
!639 = !{ptr @.str.72, !638, !"<string literal>", i1 false, i1 false}
!640 = distinct !{null, !638, !"__warned", i1 false, i1 false}
!641 = !{ptr @.str.74, !638, !"<string literal>", i1 false, i1 false}
!642 = !{ptr @.str.75, !643, !"<string literal>", i1 false, i1 false}
!643 = !{!"../kernel/sched/core.c", i32 9562, i32 2}
!644 = !{ptr @.str.76, !643, !"<string literal>", i1 false, i1 false}
!645 = !{ptr @__might_resched._entry, !643, !"_entry", i1 false, i1 false}
!646 = !{ptr @__might_resched._entry_ptr, !643, !"_entry_ptr", i1 false, i1 false}
!647 = !{ptr @.str.78, !648, !"<string literal>", i1 false, i1 false}
!648 = !{!"../kernel/sched/core.c", i32 9564, i32 2}
!649 = !{ptr @__might_resched._entry.77, !648, !"_entry", i1 false, i1 false}
!650 = !{ptr @__might_resched._entry_ptr.79, !648, !"_entry_ptr", i1 false, i1 false}
!651 = !{ptr @.str.81, !652, !"<string literal>", i1 false, i1 false}
!652 = !{!"../kernel/sched/core.c", i32 9567, i32 2}
!653 = !{ptr @__might_resched._entry.80, !652, !"_entry", i1 false, i1 false}
!654 = !{ptr @__might_resched._entry_ptr.82, !652, !"_entry_ptr", i1 false, i1 false}
!655 = !{ptr @.str.84, !656, !"<string literal>", i1 false, i1 false}
!656 = !{!"../kernel/sched/core.c", i32 9576, i32 3}
!657 = !{ptr @__might_resched._entry.83, !656, !"_entry", i1 false, i1 false}
!658 = !{ptr @__might_resched._entry_ptr.85, !656, !"_entry_ptr", i1 false, i1 false}
!659 = !{ptr @__ksymtab___might_resched, !660, !"__ksymtab___might_resched", i1 false, i1 false}
!660 = !{!"../kernel/sched/core.c", i32 9588, i32 1}
!661 = !{ptr @__cant_sleep.prev_jiffy, !662, !"prev_jiffy", i1 false, i1 false}
!662 = !{!"../kernel/sched/core.c", i32 9592, i32 23}
!663 = !{ptr @.str.86, !664, !"<string literal>", i1 false, i1 false}
!664 = !{!"../kernel/sched/core.c", i32 9607, i32 2}
!665 = !{ptr @.str.87, !664, !"<string literal>", i1 false, i1 false}
!666 = !{ptr @__cant_sleep._entry, !664, !"_entry", i1 false, i1 false}
!667 = !{ptr @__cant_sleep._entry_ptr, !664, !"_entry_ptr", i1 false, i1 false}
!668 = !{ptr @.str.89, !669, !"<string literal>", i1 false, i1 false}
!669 = !{!"../kernel/sched/core.c", i32 9608, i32 2}
!670 = !{ptr @__cant_sleep._entry.88, !669, !"_entry", i1 false, i1 false}
!671 = !{ptr @__cant_sleep._entry_ptr.90, !669, !"_entry_ptr", i1 false, i1 false}
!672 = !{ptr @__ksymtab___cant_sleep, !673, !"__ksymtab___cant_sleep", i1 false, i1 false}
!673 = !{!"../kernel/sched/core.c", i32 9616, i32 1}
!674 = !{ptr @__cant_migrate.prev_jiffy, !675, !"prev_jiffy", i1 false, i1 false}
!675 = !{!"../kernel/sched/core.c", i32 9621, i32 23}
!676 = !{ptr @.str.91, !677, !"<string literal>", i1 false, i1 false}
!677 = !{!"../kernel/sched/core.c", i32 9639, i32 2}
!678 = !{ptr @.str.92, !677, !"<string literal>", i1 false, i1 false}
!679 = !{ptr @__cant_migrate._entry, !677, !"_entry", i1 false, i1 false}
!680 = !{ptr @__cant_migrate._entry_ptr, !677, !"_entry_ptr", i1 false, i1 false}
!681 = !{ptr @.str.94, !682, !"<string literal>", i1 false, i1 false}
!682 = !{!"../kernel/sched/core.c", i32 9640, i32 2}
!683 = !{ptr @__cant_migrate._entry.93, !682, !"_entry", i1 false, i1 false}
!684 = !{ptr @__cant_migrate._entry_ptr.95, !682, !"_entry_ptr", i1 false, i1 false}
!685 = !{ptr @__ksymtab___cant_migrate, !686, !"__ksymtab___cant_migrate", i1 false, i1 false}
!686 = !{!"../kernel/sched/core.c", i32 9648, i32 1}
!687 = distinct !{null, !688, !"__warned", i1 false, i1 false}
!688 = !{!"../kernel/sched/core.c", i32 9661, i32 2}
!689 = !{ptr @max_cfs_quota_period, !690, !"max_cfs_quota_period", i1 false, i1 false}
!690 = !{!"../kernel/sched/core.c", i32 10238, i32 11}
!691 = !{ptr @cpu_cgrp_subsys, !692, !"cpu_cgrp_subsys", i1 false, i1 false}
!692 = !{!"../kernel/sched/core.c", i32 10860, i32 22}
!693 = !{ptr @.str.96, !694, !"<string literal>", i1 false, i1 false}
!694 = !{!"../kernel/sched/core.c", i32 10879, i32 2}
!695 = !{ptr @.str.97, !694, !"<string literal>", i1 false, i1 false}
!696 = !{ptr @dump_cpu_task._entry, !694, !"_entry", i1 false, i1 false}
!697 = !{ptr @dump_cpu_task._entry_ptr, !694, !"_entry_ptr", i1 false, i1 false}
!698 = !{ptr @sched_prio_to_weight, !699, !"sched_prio_to_weight", i1 false, i1 false}
!699 = !{!"../kernel/sched/core.c", i32 10895, i32 11}
!700 = !{ptr @sched_prio_to_wmult, !701, !"sched_prio_to_wmult", i1 false, i1 false}
!701 = !{!"../kernel/sched/core.c", i32 10913, i32 11}
!702 = !{ptr @__pcpu_scope_runqueues, !703, !"__pcpu_scope_runqueues", i1 false, i1 false}
!703 = !{!"../kernel/sched/core.c", i32 45, i32 1}
!704 = !{ptr @__pcpu_unique_runqueues, !703, !"__pcpu_unique_runqueues", i1 false, i1 false}
!705 = !{ptr @runqueues, !703, !"runqueues", i1 false, i1 false}
!706 = !{ptr @scheduler_running, !707, !"scheduler_running", i1 false, i1 false}
!707 = !{!"../kernel/sched/core.c", i32 89, i32 19}
!708 = !{ptr @sched_core_count, !709, !"sched_core_count", i1 false, i1 false}
!709 = !{!"../kernel/sched/core.c", i32 249, i32 17}
!710 = !{ptr @uclamp_default, !711, !"uclamp_default", i1 false, i1 false}
!711 = !{!"../kernel/sched/core.c", i32 1280, i32 25}
!712 = !{ptr @__pcpu_scope_kstat, !713, !"__pcpu_scope_kstat", i1 false, i1 false}
!713 = !{!"../kernel/sched/core.c", i32 5129, i32 1}
!714 = !{ptr @__pcpu_unique_kstat, !713, !"__pcpu_unique_kstat", i1 false, i1 false}
!715 = !{ptr @kstat, !713, !"kstat", i1 false, i1 false}
!716 = !{ptr @__pcpu_scope_kernel_cpustat, !717, !"__pcpu_scope_kernel_cpustat", i1 false, i1 false}
!717 = !{!"../kernel/sched/core.c", i32 5130, i32 1}
!718 = !{ptr @__pcpu_unique_kernel_cpustat, !717, !"__pcpu_unique_kernel_cpustat", i1 false, i1 false}
!719 = !{ptr @kernel_cpustat, !717, !"kernel_cpustat", i1 false, i1 false}
!720 = !{ptr @__pcpu_unique_core_balance_head, !721, !"__pcpu_unique_core_balance_head", i1 false, i1 false}
!721 = !{!"../kernel/sched/core.c", i32 5989, i32 8}
!722 = !{ptr @core_balance_head, !721, !"core_balance_head", i1 false, i1 false}
!723 = !{ptr @sched_smp_initialized, !724, !"sched_smp_initialized", i1 false, i1 false}
!724 = !{!"../kernel/sched/core.c", i32 8747, i32 6}
!725 = !{ptr @__pcpu_unique_push_work, !726, !"__pcpu_unique_push_work", i1 false, i1 false}
!726 = !{!"../kernel/sched/core.c", i32 8842, i32 8}
!727 = !{ptr @push_work, !726, !"push_work", i1 false, i1 false}
!728 = !{ptr @root_task_group, !729, !"root_task_group", i1 false, i1 false}
!729 = !{!"../kernel/sched/core.c", i32 9289, i32 19}
!730 = !{ptr @task_group_cache, !731, !"task_group_cache", i1 false, i1 false}
!731 = !{!"../kernel/sched/core.c", i32 9293, i32 27}
!732 = !{ptr @__tpstrtab_sched_kthread_stop, !1, !"__tpstrtab_sched_kthread_stop", i1 false, i1 false}
!733 = !{ptr @__tpstrtab_sched_kthread_stop_ret, !5, !"__tpstrtab_sched_kthread_stop_ret", i1 false, i1 false}
!734 = !{ptr @__tpstrtab_sched_kthread_work_queue_work, !9, !"__tpstrtab_sched_kthread_work_queue_work", i1 false, i1 false}
!735 = !{ptr @__tpstrtab_sched_kthread_work_execute_start, !13, !"__tpstrtab_sched_kthread_work_execute_start", i1 false, i1 false}
!736 = !{ptr @__tpstrtab_sched_kthread_work_execute_end, !17, !"__tpstrtab_sched_kthread_work_execute_end", i1 false, i1 false}
!737 = !{ptr @__tpstrtab_sched_waking, !21, !"__tpstrtab_sched_waking", i1 false, i1 false}
!738 = !{ptr @__tpstrtab_sched_wakeup, !25, !"__tpstrtab_sched_wakeup", i1 false, i1 false}
!739 = !{ptr @__tpstrtab_sched_wakeup_new, !29, !"__tpstrtab_sched_wakeup_new", i1 false, i1 false}
!740 = !{ptr @__tpstrtab_sched_switch, !33, !"__tpstrtab_sched_switch", i1 false, i1 false}
!741 = !{ptr @__tpstrtab_sched_migrate_task, !37, !"__tpstrtab_sched_migrate_task", i1 false, i1 false}
!742 = !{ptr @__tpstrtab_sched_process_free, !41, !"__tpstrtab_sched_process_free", i1 false, i1 false}
!743 = !{ptr @__tpstrtab_sched_process_exit, !45, !"__tpstrtab_sched_process_exit", i1 false, i1 false}
!744 = !{ptr @__tpstrtab_sched_wait_task, !49, !"__tpstrtab_sched_wait_task", i1 false, i1 false}
!745 = !{ptr @__tpstrtab_sched_process_wait, !53, !"__tpstrtab_sched_process_wait", i1 false, i1 false}
!746 = !{ptr @__tpstrtab_sched_process_fork, !57, !"__tpstrtab_sched_process_fork", i1 false, i1 false}
!747 = !{ptr @__tpstrtab_sched_process_exec, !61, !"__tpstrtab_sched_process_exec", i1 false, i1 false}
!748 = !{ptr @__tpstrtab_sched_stat_wait, !65, !"__tpstrtab_sched_stat_wait", i1 false, i1 false}
!749 = !{ptr @__tpstrtab_sched_stat_sleep, !69, !"__tpstrtab_sched_stat_sleep", i1 false, i1 false}
!750 = !{ptr @__tpstrtab_sched_stat_iowait, !73, !"__tpstrtab_sched_stat_iowait", i1 false, i1 false}
!751 = !{ptr @__tpstrtab_sched_stat_blocked, !77, !"__tpstrtab_sched_stat_blocked", i1 false, i1 false}
!752 = !{ptr @__tpstrtab_sched_stat_runtime, !81, !"__tpstrtab_sched_stat_runtime", i1 false, i1 false}
!753 = !{ptr @__tpstrtab_sched_pi_setprio, !85, !"__tpstrtab_sched_pi_setprio", i1 false, i1 false}
!754 = !{ptr @__tpstrtab_sched_process_hang, !89, !"__tpstrtab_sched_process_hang", i1 false, i1 false}
!755 = !{ptr @__tpstrtab_sched_move_numa, !93, !"__tpstrtab_sched_move_numa", i1 false, i1 false}
!756 = !{ptr @__tpstrtab_sched_stick_numa, !97, !"__tpstrtab_sched_stick_numa", i1 false, i1 false}
!757 = !{ptr @__tpstrtab_sched_swap_numa, !101, !"__tpstrtab_sched_swap_numa", i1 false, i1 false}
!758 = !{ptr @__tpstrtab_sched_wake_idle_without_ipi, !105, !"__tpstrtab_sched_wake_idle_without_ipi", i1 false, i1 false}
!759 = !{ptr @__tpstrtab_pelt_cfs_tp, !109, !"__tpstrtab_pelt_cfs_tp", i1 false, i1 false}
!760 = !{ptr @__tpstrtab_pelt_rt_tp, !113, !"__tpstrtab_pelt_rt_tp", i1 false, i1 false}
!761 = !{ptr @__tpstrtab_pelt_dl_tp, !117, !"__tpstrtab_pelt_dl_tp", i1 false, i1 false}
!762 = !{ptr @__tpstrtab_pelt_thermal_tp, !121, !"__tpstrtab_pelt_thermal_tp", i1 false, i1 false}
!763 = !{ptr @__tpstrtab_pelt_irq_tp, !125, !"__tpstrtab_pelt_irq_tp", i1 false, i1 false}
!764 = !{ptr @__tpstrtab_pelt_se_tp, !129, !"__tpstrtab_pelt_se_tp", i1 false, i1 false}
!765 = !{ptr @__tpstrtab_sched_cpu_capacity_tp, !133, !"__tpstrtab_sched_cpu_capacity_tp", i1 false, i1 false}
!766 = !{ptr @__tpstrtab_sched_overutilized_tp, !137, !"__tpstrtab_sched_overutilized_tp", i1 false, i1 false}
!767 = !{ptr @__tpstrtab_sched_util_est_cfs_tp, !141, !"__tpstrtab_sched_util_est_cfs_tp", i1 false, i1 false}
!768 = !{ptr @__tpstrtab_sched_util_est_se_tp, !145, !"__tpstrtab_sched_util_est_se_tp", i1 false, i1 false}
!769 = !{ptr @__tpstrtab_sched_update_nr_running_tp, !149, !"__tpstrtab_sched_update_nr_running_tp", i1 false, i1 false}
!770 = !{ptr @str__sched__trace_system_name, !771, !"str__sched__trace_system_name", i1 false, i1 false}
!771 = !{!"../include/trace/trace_events.h", i32 36, i32 1}
!772 = !{ptr @.str.98, !1, !"<string literal>", i1 false, i1 false}
!773 = !{ptr @.str.99, !1, !"<string literal>", i1 false, i1 false}
!774 = !{ptr @.str.100, !1, !"<string literal>", i1 false, i1 false}
!775 = !{ptr @.str.101, !1, !"<string literal>", i1 false, i1 false}
!776 = !{ptr @trace_event_fields_sched_kthread_stop, !1, !"trace_event_fields_sched_kthread_stop", i1 false, i1 false}
!777 = !{ptr @trace_event_type_funcs_sched_kthread_stop, !1, !"trace_event_type_funcs_sched_kthread_stop", i1 false, i1 false}
!778 = !{ptr @.str.102, !1, !"<string literal>", i1 false, i1 false}
!779 = !{ptr @print_fmt_sched_kthread_stop, !1, !"print_fmt_sched_kthread_stop", i1 false, i1 false}
!780 = !{ptr @.str.103, !5, !"<string literal>", i1 false, i1 false}
!781 = !{ptr @.str.104, !5, !"<string literal>", i1 false, i1 false}
!782 = !{ptr @trace_event_fields_sched_kthread_stop_ret, !5, !"trace_event_fields_sched_kthread_stop_ret", i1 false, i1 false}
!783 = !{ptr @trace_event_type_funcs_sched_kthread_stop_ret, !5, !"trace_event_type_funcs_sched_kthread_stop_ret", i1 false, i1 false}
!784 = !{ptr @.str.105, !5, !"<string literal>", i1 false, i1 false}
!785 = !{ptr @print_fmt_sched_kthread_stop_ret, !5, !"print_fmt_sched_kthread_stop_ret", i1 false, i1 false}
!786 = !{ptr @.str.106, !9, !"<string literal>", i1 false, i1 false}
!787 = !{ptr @.str.107, !9, !"<string literal>", i1 false, i1 false}
!788 = !{ptr @.str.108, !9, !"<string literal>", i1 false, i1 false}
!789 = !{ptr @.str.109, !9, !"<string literal>", i1 false, i1 false}
!790 = !{ptr @trace_event_fields_sched_kthread_work_queue_work, !9, !"trace_event_fields_sched_kthread_work_queue_work", i1 false, i1 false}
!791 = !{ptr @trace_event_type_funcs_sched_kthread_work_queue_work, !9, !"trace_event_type_funcs_sched_kthread_work_queue_work", i1 false, i1 false}
!792 = !{ptr @.str.110, !9, !"<string literal>", i1 false, i1 false}
!793 = !{ptr @print_fmt_sched_kthread_work_queue_work, !9, !"print_fmt_sched_kthread_work_queue_work", i1 false, i1 false}
!794 = !{ptr @trace_event_fields_sched_kthread_work_execute_start, !13, !"trace_event_fields_sched_kthread_work_execute_start", i1 false, i1 false}
!795 = !{ptr @trace_event_type_funcs_sched_kthread_work_execute_start, !13, !"trace_event_type_funcs_sched_kthread_work_execute_start", i1 false, i1 false}
!796 = !{ptr @.str.111, !13, !"<string literal>", i1 false, i1 false}
!797 = !{ptr @print_fmt_sched_kthread_work_execute_start, !13, !"print_fmt_sched_kthread_work_execute_start", i1 false, i1 false}
!798 = !{ptr @trace_event_fields_sched_kthread_work_execute_end, !17, !"trace_event_fields_sched_kthread_work_execute_end", i1 false, i1 false}
!799 = !{ptr @trace_event_type_funcs_sched_kthread_work_execute_end, !17, !"trace_event_type_funcs_sched_kthread_work_execute_end", i1 false, i1 false}
!800 = !{ptr @print_fmt_sched_kthread_work_execute_end, !17, !"print_fmt_sched_kthread_work_execute_end", i1 false, i1 false}
!801 = !{ptr @.str.112, !168, !"<string literal>", i1 false, i1 false}
!802 = !{ptr @.str.113, !168, !"<string literal>", i1 false, i1 false}
!803 = !{ptr @trace_event_fields_sched_wakeup_template, !168, !"trace_event_fields_sched_wakeup_template", i1 false, i1 false}
!804 = !{ptr @trace_event_type_funcs_sched_wakeup_template, !168, !"trace_event_type_funcs_sched_wakeup_template", i1 false, i1 false}
!805 = !{ptr @.str.114, !168, !"<string literal>", i1 false, i1 false}
!806 = !{ptr @print_fmt_sched_wakeup_template, !168, !"print_fmt_sched_wakeup_template", i1 false, i1 false}
!807 = !{ptr @.str.115, !33, !"<string literal>", i1 false, i1 false}
!808 = !{ptr @.str.116, !33, !"<string literal>", i1 false, i1 false}
!809 = !{ptr @.str.117, !33, !"<string literal>", i1 false, i1 false}
!810 = !{ptr @.str.118, !33, !"<string literal>", i1 false, i1 false}
!811 = !{ptr @.str.119, !33, !"<string literal>", i1 false, i1 false}
!812 = !{ptr @.str.120, !33, !"<string literal>", i1 false, i1 false}
!813 = !{ptr @.str.121, !33, !"<string literal>", i1 false, i1 false}
!814 = !{ptr @.str.122, !33, !"<string literal>", i1 false, i1 false}
!815 = !{ptr @trace_event_fields_sched_switch, !33, !"trace_event_fields_sched_switch", i1 false, i1 false}
!816 = !{ptr @trace_event_type_funcs_sched_switch, !33, !"trace_event_type_funcs_sched_switch", i1 false, i1 false}
!817 = !{ptr @.str.123, !33, !"<string literal>", i1 false, i1 false}
!818 = !{ptr @.str.124, !33, !"<string literal>", i1 false, i1 false}
!819 = !{ptr @.str.125, !33, !"<string literal>", i1 false, i1 false}
!820 = !{ptr @.str.126, !33, !"<string literal>", i1 false, i1 false}
!821 = !{ptr @.str.127, !33, !"<string literal>", i1 false, i1 false}
!822 = !{ptr @.str.128, !33, !"<string literal>", i1 false, i1 false}
!823 = !{ptr @.str.129, !33, !"<string literal>", i1 false, i1 false}
!824 = !{ptr @.str.130, !33, !"<string literal>", i1 false, i1 false}
!825 = !{ptr @.str.131, !33, !"<string literal>", i1 false, i1 false}
!826 = !{ptr @trace_raw_output_sched_switch.__flags, !33, !"__flags", i1 false, i1 false}
!827 = !{ptr @.str.132, !33, !"<string literal>", i1 false, i1 false}
!828 = !{ptr @.str.133, !33, !"<string literal>", i1 false, i1 false}
!829 = !{ptr @.str.134, !33, !"<string literal>", i1 false, i1 false}
!830 = !{ptr @.str.135, !33, !"<string literal>", i1 false, i1 false}
!831 = !{ptr @print_fmt_sched_switch, !33, !"print_fmt_sched_switch", i1 false, i1 false}
!832 = !{ptr @.str.136, !37, !"<string literal>", i1 false, i1 false}
!833 = !{ptr @.str.137, !37, !"<string literal>", i1 false, i1 false}
!834 = !{ptr @trace_event_fields_sched_migrate_task, !37, !"trace_event_fields_sched_migrate_task", i1 false, i1 false}
!835 = !{ptr @trace_event_type_funcs_sched_migrate_task, !37, !"trace_event_type_funcs_sched_migrate_task", i1 false, i1 false}
!836 = !{ptr @.str.138, !37, !"<string literal>", i1 false, i1 false}
!837 = !{ptr @print_fmt_sched_migrate_task, !37, !"print_fmt_sched_migrate_task", i1 false, i1 false}
!838 = !{ptr @trace_event_fields_sched_process_template, !182, !"trace_event_fields_sched_process_template", i1 false, i1 false}
!839 = !{ptr @trace_event_type_funcs_sched_process_template, !182, !"trace_event_type_funcs_sched_process_template", i1 false, i1 false}
!840 = !{ptr @.str.139, !182, !"<string literal>", i1 false, i1 false}
!841 = !{ptr @print_fmt_sched_process_template, !182, !"print_fmt_sched_process_template", i1 false, i1 false}
!842 = !{ptr @trace_event_fields_sched_process_wait, !53, !"trace_event_fields_sched_process_wait", i1 false, i1 false}
!843 = !{ptr @trace_event_type_funcs_sched_process_wait, !53, !"trace_event_type_funcs_sched_process_wait", i1 false, i1 false}
!844 = !{ptr @print_fmt_sched_process_wait, !53, !"print_fmt_sched_process_wait", i1 false, i1 false}
!845 = !{ptr @.str.140, !57, !"<string literal>", i1 false, i1 false}
!846 = !{ptr @.str.141, !57, !"<string literal>", i1 false, i1 false}
!847 = !{ptr @.str.142, !57, !"<string literal>", i1 false, i1 false}
!848 = !{ptr @.str.143, !57, !"<string literal>", i1 false, i1 false}
!849 = !{ptr @trace_event_fields_sched_process_fork, !57, !"trace_event_fields_sched_process_fork", i1 false, i1 false}
!850 = !{ptr @trace_event_type_funcs_sched_process_fork, !57, !"trace_event_type_funcs_sched_process_fork", i1 false, i1 false}
!851 = !{ptr @.str.144, !57, !"<string literal>", i1 false, i1 false}
!852 = !{ptr @print_fmt_sched_process_fork, !57, !"print_fmt_sched_process_fork", i1 false, i1 false}
!853 = !{ptr @.str.145, !61, !"<string literal>", i1 false, i1 false}
!854 = !{ptr @.str.146, !61, !"<string literal>", i1 false, i1 false}
!855 = !{ptr @.str.147, !61, !"<string literal>", i1 false, i1 false}
!856 = !{ptr @.str.148, !61, !"<string literal>", i1 false, i1 false}
!857 = !{ptr @trace_event_fields_sched_process_exec, !61, !"trace_event_fields_sched_process_exec", i1 false, i1 false}
!858 = !{ptr @trace_event_type_funcs_sched_process_exec, !61, !"trace_event_type_funcs_sched_process_exec", i1 false, i1 false}
!859 = !{ptr @.str.149, !61, !"<string literal>", i1 false, i1 false}
!860 = !{ptr @print_fmt_sched_process_exec, !61, !"print_fmt_sched_process_exec", i1 false, i1 false}
!861 = !{ptr @.str.150, !199, !"<string literal>", i1 false, i1 false}
!862 = !{ptr @.str.151, !199, !"<string literal>", i1 false, i1 false}
!863 = !{ptr @trace_event_fields_sched_stat_template, !199, !"trace_event_fields_sched_stat_template", i1 false, i1 false}
!864 = !{ptr @trace_event_type_funcs_sched_stat_template, !199, !"trace_event_type_funcs_sched_stat_template", i1 false, i1 false}
!865 = !{ptr @.str.152, !199, !"<string literal>", i1 false, i1 false}
!866 = !{ptr @print_fmt_sched_stat_template, !199, !"print_fmt_sched_stat_template", i1 false, i1 false}
!867 = !{ptr @.str.153, !209, !"<string literal>", i1 false, i1 false}
!868 = !{ptr @.str.154, !209, !"<string literal>", i1 false, i1 false}
!869 = !{ptr @trace_event_fields_sched_stat_runtime, !209, !"trace_event_fields_sched_stat_runtime", i1 false, i1 false}
!870 = !{ptr @trace_event_type_funcs_sched_stat_runtime, !209, !"trace_event_type_funcs_sched_stat_runtime", i1 false, i1 false}
!871 = !{ptr @.str.155, !209, !"<string literal>", i1 false, i1 false}
!872 = !{ptr @print_fmt_sched_stat_runtime, !209, !"print_fmt_sched_stat_runtime", i1 false, i1 false}
!873 = !{ptr @.str.156, !85, !"<string literal>", i1 false, i1 false}
!874 = !{ptr @.str.157, !85, !"<string literal>", i1 false, i1 false}
!875 = !{ptr @trace_event_fields_sched_pi_setprio, !85, !"trace_event_fields_sched_pi_setprio", i1 false, i1 false}
!876 = !{ptr @trace_event_type_funcs_sched_pi_setprio, !85, !"trace_event_type_funcs_sched_pi_setprio", i1 false, i1 false}
!877 = !{ptr @.str.158, !85, !"<string literal>", i1 false, i1 false}
!878 = !{ptr @print_fmt_sched_pi_setprio, !85, !"print_fmt_sched_pi_setprio", i1 false, i1 false}
!879 = !{ptr @trace_event_fields_sched_process_hang, !89, !"trace_event_fields_sched_process_hang", i1 false, i1 false}
!880 = !{ptr @trace_event_type_funcs_sched_process_hang, !89, !"trace_event_type_funcs_sched_process_hang", i1 false, i1 false}
!881 = !{ptr @print_fmt_sched_process_hang, !89, !"print_fmt_sched_process_hang", i1 false, i1 false}
!882 = !{ptr @.str.159, !93, !"<string literal>", i1 false, i1 false}
!883 = !{ptr @.str.160, !93, !"<string literal>", i1 false, i1 false}
!884 = !{ptr @.str.161, !93, !"<string literal>", i1 false, i1 false}
!885 = !{ptr @.str.162, !93, !"<string literal>", i1 false, i1 false}
!886 = !{ptr @.str.163, !93, !"<string literal>", i1 false, i1 false}
!887 = !{ptr @.str.164, !93, !"<string literal>", i1 false, i1 false}
!888 = !{ptr @trace_event_fields_sched_move_numa, !93, !"trace_event_fields_sched_move_numa", i1 false, i1 false}
!889 = !{ptr @trace_event_type_funcs_sched_move_numa, !93, !"trace_event_type_funcs_sched_move_numa", i1 false, i1 false}
!890 = !{ptr @.str.165, !93, !"<string literal>", i1 false, i1 false}
!891 = !{ptr @print_fmt_sched_move_numa, !93, !"print_fmt_sched_move_numa", i1 false, i1 false}
!892 = !{ptr @.str.166, !222, !"<string literal>", i1 false, i1 false}
!893 = !{ptr @.str.167, !222, !"<string literal>", i1 false, i1 false}
!894 = !{ptr @.str.168, !222, !"<string literal>", i1 false, i1 false}
!895 = !{ptr @.str.169, !222, !"<string literal>", i1 false, i1 false}
!896 = !{ptr @.str.170, !222, !"<string literal>", i1 false, i1 false}
!897 = !{ptr @.str.171, !222, !"<string literal>", i1 false, i1 false}
!898 = !{ptr @trace_event_fields_sched_numa_pair_template, !222, !"trace_event_fields_sched_numa_pair_template", i1 false, i1 false}
!899 = !{ptr @trace_event_type_funcs_sched_numa_pair_template, !222, !"trace_event_type_funcs_sched_numa_pair_template", i1 false, i1 false}
!900 = !{ptr @.str.172, !222, !"<string literal>", i1 false, i1 false}
!901 = !{ptr @print_fmt_sched_numa_pair_template, !222, !"print_fmt_sched_numa_pair_template", i1 false, i1 false}
!902 = !{ptr @.str.173, !105, !"<string literal>", i1 false, i1 false}
!903 = !{ptr @trace_event_fields_sched_wake_idle_without_ipi, !105, !"trace_event_fields_sched_wake_idle_without_ipi", i1 false, i1 false}
!904 = !{ptr @trace_event_type_funcs_sched_wake_idle_without_ipi, !105, !"trace_event_type_funcs_sched_wake_idle_without_ipi", i1 false, i1 false}
!905 = !{ptr @.str.174, !105, !"<string literal>", i1 false, i1 false}
!906 = !{ptr @print_fmt_sched_wake_idle_without_ipi, !105, !"print_fmt_sched_wake_idle_without_ipi", i1 false, i1 false}
!907 = !{ptr @.str.175, !908, !"<string literal>", i1 false, i1 false}
!908 = !{!"../kernel/sched/core.c", i32 248, i32 8}
!909 = !{ptr @.str.176, !908, !"<string literal>", i1 false, i1 false}
!910 = !{ptr @sched_core_mutex, !908, !"sched_core_mutex", i1 false, i1 false}
!911 = !{ptr @sched_core_mask, !912, !"sched_core_mask", i1 false, i1 false}
!912 = !{!"../kernel/sched/core.c", i32 250, i32 23}
!913 = distinct !{null, !914, !"__already_done", i1 false, i1 false}
!914 = !{!"../kernel/sched/core.c", i32 315, i32 3}
!915 = distinct !{null, !916, !"__already_done", i1 false, i1 false}
!916 = !{!"../kernel/sched/sched.h", i32 1545, i32 2}
!917 = !{ptr @.str.177, !916, !"<string literal>", i1 false, i1 false}
!918 = !{ptr @.str.178, !916, !"<string literal>", i1 false, i1 false}
!919 = distinct !{null, !920, !"__already_done", i1 false, i1 false}
!920 = !{!"../kernel/sched/sched.h", i32 1459, i32 2}
!921 = !{ptr @.str.179, !920, !"<string literal>", i1 false, i1 false}
!922 = distinct !{null, !105, !"__already_done", i1 false, i1 false}
!923 = !{ptr @.str.180, !105, !"<string literal>", i1 false, i1 false}
!924 = distinct !{null, !105, !"__warned", i1 false, i1 false}
!925 = distinct !{null, !926, !"__warned", i1 false, i1 false}
!926 = !{!"../include/linux/rcupdate.h", i32 695, i32 2}
!927 = !{ptr @.str.181, !926, !"<string literal>", i1 false, i1 false}
!928 = !{ptr @.str.182, !926, !"<string literal>", i1 false, i1 false}
!929 = distinct !{null, !930, !"__warned", i1 false, i1 false}
!930 = !{!"../include/linux/rcupdate.h", i32 723, i32 2}
!931 = !{ptr @.str.183, !930, !"<string literal>", i1 false, i1 false}
!932 = !{ptr @.str.184, !933, !"<string literal>", i1 false, i1 false}
!933 = !{!"../kernel/sched/core.c", i32 1254, i32 8}
!934 = !{ptr @.str.185, !933, !"<string literal>", i1 false, i1 false}
!935 = !{ptr @uclamp_mutex, !933, !"uclamp_mutex", i1 false, i1 false}
!936 = distinct !{null, !937, !"__already_done", i1 false, i1 false}
!937 = !{!"../kernel/sched/core.c", i32 10052, i32 2}
!938 = !{ptr @.str.186, !937, !"<string literal>", i1 false, i1 false}
!939 = distinct !{null, !940, !"__already_done", i1 false, i1 false}
!940 = !{!"../kernel/sched/core.c", i32 1582, i32 2}
!941 = !{ptr @.str.187, !940, !"<string literal>", i1 false, i1 false}
!942 = distinct !{null, !943, !"__already_done", i1 false, i1 false}
!943 = !{!"../kernel/sched/core.c", i32 1602, i32 2}
!944 = !{ptr @.str.189, !943, !"<string literal>", i1 false, i1 false}
!945 = distinct !{null, !946, !"__warned", i1 false, i1 false}
!946 = !{!"../kernel/sched/core.c", i32 1429, i32 2}
!947 = distinct !{null, !948, !"__already_done", i1 false, i1 false}
!948 = !{!"../kernel/sched/core.c", i32 2506, i32 3}
!949 = !{ptr @.str.190, !948, !"<string literal>", i1 false, i1 false}
!950 = distinct !{null, !951, !"__already_done", i1 false, i1 false}
!951 = !{!"../kernel/sched/core.c", i32 2833, i32 7}
!952 = distinct !{null, !953, !"__already_done", i1 false, i1 false}
!953 = !{!"../kernel/sched/core.c", i32 2720, i32 6}
!954 = distinct !{null, !955, !"__already_done", i1 false, i1 false}
!955 = !{!"../kernel/sched/core.c", i32 2776, i32 2}
!956 = !{ptr @init_completion.__key, !957, !"__key", i1 false, i1 false}
!957 = !{!"../include/linux/completion.h", i32 87, i32 2}
!958 = !{ptr @.str.192, !957, !"<string literal>", i1 false, i1 false}
!959 = distinct !{null, !37, !"__already_done", i1 false, i1 false}
!960 = distinct !{null, !37, !"__warned", i1 false, i1 false}
!961 = distinct !{null, !49, !"__already_done", i1 false, i1 false}
!962 = distinct !{null, !49, !"__warned", i1 false, i1 false}
!963 = distinct !{null, !25, !"__already_done", i1 false, i1 false}
!964 = distinct !{null, !25, !"__warned", i1 false, i1 false}
!965 = distinct !{null, !21, !"__already_done", i1 false, i1 false}
!966 = distinct !{null, !21, !"__warned", i1 false, i1 false}
!967 = distinct !{null, !968, !"__already_done", i1 false, i1 false}
!968 = !{!"../kernel/sched/core.c", i32 3780, i32 7}
!969 = distinct !{null, !970, !"__warned", i1 false, i1 false}
!970 = !{!"../kernel/sched/core.c", i32 3535, i32 3}
!971 = !{ptr @__setup_str_setup_schedstats, !395, !"__setup_str_setup_schedstats", i1 false, i1 false}
!972 = !{ptr @.str.193, !973, !"<string literal>", i1 false, i1 false}
!973 = !{!"../kernel/sched/core.c", i32 4339, i32 19}
!974 = !{ptr @.str.194, !975, !"<string literal>", i1 false, i1 false}
!975 = !{!"../kernel/sched/core.c", i32 4342, i32 26}
!976 = !{ptr @.str.195, !977, !"<string literal>", i1 false, i1 false}
!977 = !{!"../kernel/sched/core.c", i32 4348, i32 3}
!978 = !{ptr @.str.196, !977, !"<string literal>", i1 false, i1 false}
!979 = !{ptr @setup_schedstats._entry, !977, !"_entry", i1 false, i1 false}
!980 = !{ptr @setup_schedstats._entry_ptr, !977, !"_entry_ptr", i1 false, i1 false}
!981 = !{ptr @__func__.select_fallback_rq, !982, !"<string literal>", i1 false, i1 false}
!982 = !{!"../kernel/sched/core.c", i32 3415, i32 16}
!983 = !{ptr @.str.197, !984, !"<string literal>", i1 false, i1 false}
!984 = !{!"../kernel/sched/core.c", i32 3416, i32 4}
!985 = !{ptr @select_fallback_rq._entry, !984, !"_entry", i1 false, i1 false}
!986 = !{ptr @select_fallback_rq._entry_ptr, !984, !"_entry_ptr", i1 false, i1 false}
!987 = distinct !{null, !29, !"__already_done", i1 false, i1 false}
!988 = distinct !{null, !29, !"__warned", i1 false, i1 false}
!989 = distinct !{null, !990, !"__already_done", i1 false, i1 false}
!990 = !{!"../kernel/sched/core.c", i32 4850, i32 6}
!991 = !{ptr @.str.198, !990, !"<string literal>", i1 false, i1 false}
!992 = distinct !{null, !993, !"__already_done", i1 false, i1 false}
!993 = !{!"../kernel/sched/core.c", i32 2355, i32 2}
!994 = distinct !{null, !995, !"__already_done", i1 false, i1 false}
!995 = !{!"../kernel/sched/core.c", i32 2412, i32 3}
!996 = !{ptr @__setup_str_setup_resched_latency_warn_ms, !405, !"__setup_str_setup_resched_latency_warn_ms", i1 false, i1 false}
!997 = !{ptr @.str.200, !998, !"<string literal>", i1 false, i1 false}
!998 = !{!"../kernel/sched/core.c", i32 5233, i32 3}
!999 = !{ptr @.str.201, !998, !"<string literal>", i1 false, i1 false}
!1000 = !{ptr @setup_resched_latency_warn_ms._entry, !998, !"_entry", i1 false, i1 false}
!1001 = !{ptr @setup_resched_latency_warn_ms._entry_ptr, !998, !"_entry_ptr", i1 false, i1 false}
!1002 = distinct !{null, !1003, !"warned_once", i1 false, i1 false}
!1003 = !{!"../kernel/sched/core.c", i32 5201, i32 14}
!1004 = distinct !{null, !1005, !"__warned", i1 false, i1 false}
!1005 = !{!"../kernel/sched/core.c", i32 5977, i32 2}
!1006 = !{ptr @.str.202, !1007, !"<string literal>", i1 false, i1 false}
!1007 = !{!"../kernel/sched/core.c", i32 5550, i32 9}
!1008 = distinct !{null, !1009, !"<string literal>", i1 false, i1 false}
!1009 = !{!"../kernel/sched/core.c", i32 5553, i32 9}
!1010 = !{ptr @.str.204, !1011, !"<string literal>", i1 false, i1 false}
!1011 = !{!"../kernel/sched/core.c", i32 5558, i32 3}
!1012 = !{ptr @.str.205, !1011, !"<string literal>", i1 false, i1 false}
!1013 = !{ptr @schedule_debug._entry, !1011, !"_entry", i1 false, i1 false}
!1014 = !{ptr @schedule_debug._entry_ptr, !1011, !"_entry_ptr", i1 false, i1 false}
!1015 = distinct !{null, !1016, !"__warned", i1 false, i1 false}
!1016 = !{!"../kernel/sched/core.c", i32 5569, i32 2}
!1017 = distinct !{null, !1016, !"__warned", i1 false, i1 false}
!1018 = distinct !{null, !1019, !"__already_done", i1 false, i1 false}
!1019 = !{!"../kernel/sched/core.c", i32 5570, i32 2}
!1020 = distinct !{null, !1019, !"<string literal>", i1 false, i1 false}
!1021 = !{ptr @.str.208, !1022, !"<string literal>", i1 false, i1 false}
!1022 = !{!"../kernel/sched/core.c", i32 5524, i32 2}
!1023 = !{ptr @.str.209, !1022, !"<string literal>", i1 false, i1 false}
!1024 = !{ptr @__schedule_bug._entry, !1022, !"_entry", i1 false, i1 false}
!1025 = !{ptr @__schedule_bug._entry_ptr, !1022, !"_entry_ptr", i1 false, i1 false}
!1026 = !{ptr @.str.210, !1027, !"<string literal>", i1 false, i1 false}
!1027 = !{!"../kernel/sched/core.c", i32 5537, i32 9}
!1028 = distinct !{null, !1029, !"__already_done", i1 false, i1 false}
!1029 = !{!"../kernel/sched/core.c", i32 5774, i32 4}
!1030 = distinct !{null, !1031, !"__already_done", i1 false, i1 false}
!1031 = !{!"../kernel/sched/core.c", i32 5843, i32 2}
!1032 = distinct !{null, !1033, !"__already_done", i1 false, i1 false}
!1033 = !{!"../kernel/sched/core.c", i32 5885, i32 3}
!1034 = distinct !{null, !33, !"__already_done", i1 false, i1 false}
!1035 = distinct !{null, !33, !"__warned", i1 false, i1 false}
!1036 = distinct !{null, !1037, !"__warned", i1 false, i1 false}
!1037 = !{!"../include/linux/perf_event.h", i32 943, i32 9}
!1038 = distinct !{null, !1037, !"<string literal>", i1 false, i1 false}
!1039 = distinct !{null, !85, !"__already_done", i1 false, i1 false}
!1040 = distinct !{null, !85, !"__warned", i1 false, i1 false}
!1041 = distinct !{null, !1042, !"__already_done", i1 false, i1 false}
!1042 = !{!"../kernel/sched/sched.h", i32 2190, i32 2}
!1043 = !{ptr @types__nice, !419, !"types__nice", i1 false, i1 false}
!1044 = !{ptr @.str.214, !419, !"<string literal>", i1 false, i1 false}
!1045 = !{ptr @args__nice, !419, !"args__nice", i1 false, i1 false}
!1046 = !{ptr @.str.215, !443, !"<string literal>", i1 false, i1 false}
!1047 = !{ptr @types__sched_setscheduler, !443, !"types__sched_setscheduler", i1 false, i1 false}
!1048 = !{ptr @.str.216, !443, !"<string literal>", i1 false, i1 false}
!1049 = !{ptr @.str.217, !443, !"<string literal>", i1 false, i1 false}
!1050 = !{ptr @args__sched_setscheduler, !443, !"args__sched_setscheduler", i1 false, i1 false}
!1051 = distinct !{null, !1052, !"__already_done", i1 false, i1 false}
!1052 = !{!"../include/linux/thread_info.h", i32 230, i32 6}
!1053 = !{ptr @.str.218, !1052, !"<string literal>", i1 false, i1 false}
!1054 = !{ptr @.str.219, !1055, !"<string literal>", i1 false, i1 false}
!1055 = !{!"../include/linux/thread_info.h", i32 214, i32 2}
!1056 = !{ptr @.str.220, !1057, !"<string literal>", i1 false, i1 false}
!1057 = !{!"../include/linux/uaccess.h", i32 156, i32 2}
!1058 = !{ptr @types__sched_setparam, !453, !"types__sched_setparam", i1 false, i1 false}
!1059 = !{ptr @args__sched_setparam, !453, !"args__sched_setparam", i1 false, i1 false}
!1060 = !{ptr @.str.221, !463, !"<string literal>", i1 false, i1 false}
!1061 = !{ptr @.str.222, !463, !"<string literal>", i1 false, i1 false}
!1062 = !{ptr @types__sched_setattr, !463, !"types__sched_setattr", i1 false, i1 false}
!1063 = !{ptr @.str.223, !463, !"<string literal>", i1 false, i1 false}
!1064 = !{ptr @.str.224, !463, !"<string literal>", i1 false, i1 false}
!1065 = !{ptr @args__sched_setattr, !463, !"args__sched_setattr", i1 false, i1 false}
!1066 = !{ptr @types__sched_getscheduler, !473, !"types__sched_getscheduler", i1 false, i1 false}
!1067 = !{ptr @args__sched_getscheduler, !473, !"args__sched_getscheduler", i1 false, i1 false}
!1068 = !{ptr @types__sched_getparam, !483, !"types__sched_getparam", i1 false, i1 false}
!1069 = !{ptr @args__sched_getparam, !483, !"args__sched_getparam", i1 false, i1 false}
!1070 = !{ptr @types__sched_getattr, !493, !"types__sched_getattr", i1 false, i1 false}
!1071 = !{ptr @.str.225, !493, !"<string literal>", i1 false, i1 false}
!1072 = !{ptr @args__sched_getattr, !493, !"args__sched_getattr", i1 false, i1 false}
!1073 = distinct !{null, !1074, !"__warned", i1 false, i1 false}
!1074 = !{!"../kernel/sched/core.c", i32 7232, i32 28}
!1075 = distinct !{null, !1076, !"__warned", i1 false, i1 false}
!1076 = !{!"../kernel/sched/core.c", i32 7236, i32 10}
!1077 = !{ptr @.str.227, !505, !"<string literal>", i1 false, i1 false}
!1078 = !{ptr @types__sched_setaffinity, !505, !"types__sched_setaffinity", i1 false, i1 false}
!1079 = !{ptr @.str.228, !505, !"<string literal>", i1 false, i1 false}
!1080 = !{ptr @.str.229, !505, !"<string literal>", i1 false, i1 false}
!1081 = !{ptr @args__sched_setaffinity, !505, !"args__sched_setaffinity", i1 false, i1 false}
!1082 = !{ptr @types__sched_getaffinity, !515, !"types__sched_getaffinity", i1 false, i1 false}
!1083 = !{ptr @args__sched_getaffinity, !515, !"args__sched_getaffinity", i1 false, i1 false}
!1084 = !{ptr @types__sched_get_priority_max, !553, !"types__sched_get_priority_max", i1 false, i1 false}
!1085 = !{ptr @args__sched_get_priority_max, !553, !"args__sched_get_priority_max", i1 false, i1 false}
!1086 = !{ptr @types__sched_get_priority_min, !563, !"types__sched_get_priority_min", i1 false, i1 false}
!1087 = !{ptr @args__sched_get_priority_min, !563, !"args__sched_get_priority_min", i1 false, i1 false}
!1088 = !{ptr @.str.230, !573, !"<string literal>", i1 false, i1 false}
!1089 = !{ptr @types__sched_rr_get_interval, !573, !"types__sched_rr_get_interval", i1 false, i1 false}
!1090 = !{ptr @.str.231, !573, !"<string literal>", i1 false, i1 false}
!1091 = !{ptr @args__sched_rr_get_interval, !573, !"args__sched_rr_get_interval", i1 false, i1 false}
!1092 = !{ptr @.str.232, !583, !"<string literal>", i1 false, i1 false}
!1093 = !{ptr @types__sched_rr_get_interval_time32, !583, !"types__sched_rr_get_interval_time32", i1 false, i1 false}
!1094 = !{ptr @args__sched_rr_get_interval_time32, !583, !"args__sched_rr_get_interval_time32", i1 false, i1 false}
!1095 = !{ptr @task_index_to_char.state_char, !1096, !"state_char", i1 false, i1 false}
!1096 = !{!"../include/linux/sched.h", i32 1638, i32 20}
!1097 = distinct !{null, !1098, !"__already_done", i1 false, i1 false}
!1098 = !{!"../include/linux/cpumask.h", i32 108, i32 2}
!1099 = !{ptr @.str.233, !1098, !"<string literal>", i1 false, i1 false}
!1100 = distinct !{null, !1101, !"__already_done", i1 false, i1 false}
!1101 = !{!"../kernel/sched/core.c", i32 8918, i32 3}
!1102 = !{ptr @num_cpus_frozen, !1103, !"num_cpus_frozen", i1 false, i1 false}
!1103 = !{!"../kernel/sched/core.c", i32 8990, i32 12}
!1104 = distinct !{null, !1105, !"__already_done", i1 false, i1 false}
!1105 = !{!"../kernel/sched/core.c", i32 6059, i32 3}
!1106 = distinct !{null, !1107, !"__already_done", i1 false, i1 false}
!1107 = !{!"../kernel/sched/core.c", i32 6075, i32 6}
!1108 = distinct !{null, !1109, !"__already_done", i1 false, i1 false}
!1109 = !{!"../kernel/sched/core.c", i32 6014, i32 2}
!1110 = distinct !{null, !1111, !"__already_done", i1 false, i1 false}
!1111 = !{!"../kernel/sched/core.c", i32 6031, i32 6}
!1112 = distinct !{null, !1113, !"__already_done", i1 false, i1 false}
!1113 = !{!"../kernel/sched/core.c", i32 6041, i32 3}
!1114 = distinct !{null, !1115, !"__already_done", i1 false, i1 false}
!1115 = !{!"../kernel/sched/core.c", i32 8936, i32 2}
!1116 = distinct !{null, !1117, !"__already_done", i1 false, i1 false}
!1117 = !{!"../include/linux/rcuwait.h", i32 53, i32 2}
!1118 = distinct !{null, !1117, !"<string literal>", i1 false, i1 false}
!1119 = !{ptr @.str.238, !1120, !"<string literal>", i1 false, i1 false}
!1120 = !{!"../kernel/sched/core.c", i32 9203, i32 2}
!1121 = !{ptr @.str.239, !1120, !"<string literal>", i1 false, i1 false}
!1122 = !{ptr @dump_rq_tasks._entry, !1120, !"_entry", i1 false, i1 false}
!1123 = !{ptr @dump_rq_tasks._entry_ptr, !1120, !"_entry_ptr", i1 false, i1 false}
!1124 = distinct !{null, !1125, !"__warned", i1 false, i1 false}
!1125 = !{!"../kernel/sched/core.c", i32 9204, i32 2}
!1126 = !{ptr @.str.241, !1127, !"<string literal>", i1 false, i1 false}
!1127 = !{!"../kernel/sched/core.c", i32 9211, i32 3}
!1128 = !{ptr @dump_rq_tasks._entry.240, !1127, !"_entry", i1 false, i1 false}
!1129 = !{ptr @dump_rq_tasks._entry_ptr.242, !1127, !"_entry_ptr", i1 false, i1 false}
!1130 = distinct !{null, !1131, !"__already_done", i1 false, i1 false}
!1131 = !{!"../kernel/sched/core.c", i32 721, i32 2}
!1132 = distinct !{null, !1133, !"__warned", i1 false, i1 false}
!1133 = !{!"../include/linux/rcupdate.h", i32 328, i32 2}
!1134 = !{ptr @.str.243, !1133, !"<string literal>", i1 false, i1 false}
!1135 = !{ptr @.str.244, !1136, !"<string literal>", i1 false, i1 false}
!1136 = !{!"../kernel/sched/core.c", i32 9741, i32 8}
!1137 = !{ptr @task_group_lock, !1136, !"task_group_lock", i1 false, i1 false}
!1138 = distinct !{null, !1139, !"__warned", i1 false, i1 false}
!1139 = !{!"../kernel/sched/core.c", i32 9868, i32 7}
!1140 = !{ptr @.str.245, !1141, !"<string literal>", i1 false, i1 false}
!1141 = !{!"../kernel/sched/core.c", i32 10676, i32 18}
!1142 = !{ptr @cpu_files, !1143, !"cpu_files", i1 false, i1 false}
!1143 = !{!"../kernel/sched/core.c", i32 10808, i32 22}
!1144 = !{ptr @.str.246, !1145, !"<string literal>", i1 false, i1 false}
!1145 = !{!"../kernel/sched/core.c", i32 10755, i32 16}
!1146 = !{ptr @.str.247, !1147, !"<string literal>", i1 false, i1 false}
!1147 = !{!"../kernel/sched/core.c", i32 10757, i32 18}
!1148 = !{ptr @.str.248, !1149, !"<string literal>", i1 false, i1 false}
!1149 = !{!"../kernel/sched/core.c", i32 10759, i32 17}
!1150 = !{ptr @.str.249, !1151, !"<string literal>", i1 false, i1 false}
!1151 = !{!"../kernel/sched/core.c", i32 10768, i32 18}
!1152 = !{ptr @.str.250, !1153, !"<string literal>", i1 false, i1 false}
!1153 = !{!"../kernel/sched/core.c", i32 10773, i32 18}
!1154 = !{ptr @.str.251, !1155, !"<string literal>", i1 false, i1 false}
!1155 = !{!"../kernel/sched/core.c", i32 10236, i32 8}
!1156 = !{ptr @.str.252, !1155, !"<string literal>", i1 false, i1 false}
!1157 = !{ptr @cfs_constraints_mutex, !1155, !"cfs_constraints_mutex", i1 false, i1 false}
!1158 = !{ptr @.str.253, !1159, !"<string literal>", i1 false, i1 false}
!1159 = !{!"../kernel/sched/core.c", i32 10196, i32 16}
!1160 = !{ptr @.str.254, !1161, !"<string literal>", i1 false, i1 false}
!1161 = !{!"../kernel/sched/core.c", i32 10202, i32 17}
!1162 = !{ptr @cpu_legacy_files, !1163, !"cpu_legacy_files", i1 false, i1 false}
!1163 = !{!"../kernel/sched/core.c", i32 10599, i32 22}
!1164 = !{ptr @.str.255, !1165, !"<string literal>", i1 false, i1 false}
!1165 = !{!"../kernel/sched/core.c", i32 10534, i32 17}
!1166 = !{ptr @.str.256, !1167, !"<string literal>", i1 false, i1 false}
!1167 = !{!"../kernel/sched/core.c", i32 10535, i32 17}
!1168 = !{ptr @.str.257, !1169, !"<string literal>", i1 false, i1 false}
!1169 = !{!"../kernel/sched/core.c", i32 10536, i32 17}
!1170 = !{ptr @.str.258, !1171, !"<string literal>", i1 false, i1 false}
!1171 = !{!"../kernel/sched/core.c", i32 10548, i32 18}
!1172 = !{ptr @.str.259, !1173, !"<string literal>", i1 false, i1 false}
!1173 = !{!"../kernel/sched/core.c", i32 10551, i32 17}
!1174 = !{ptr @.str.260, !1175, !"<string literal>", i1 false, i1 false}
!1175 = !{!"../kernel/sched/core.c", i32 10552, i32 17}
!1176 = distinct !{null, !1177, !"__already_done", i1 false, i1 false}
!1177 = !{!"../kernel/sched/sched.h", i32 1376, i32 2}
!1178 = distinct !{null, !1177, !"<string literal>", i1 false, i1 false}
!1179 = distinct !{null, !149, !"__already_done", i1 false, i1 false}
!1180 = distinct !{null, !149, !"__warned", i1 false, i1 false}
!1181 = !{!"sp"}
!1182 = !{i32 1, !"wchar_size", i32 2}
!1183 = !{i32 1, !"min_enum_size", i32 4}
!1184 = !{i32 8, !"branch-target-enforcement", i32 0}
!1185 = !{i32 8, !"sign-return-address", i32 0}
!1186 = !{i32 8, !"sign-return-address-all", i32 0}
!1187 = !{i32 8, !"sign-return-address-with-bkey", i32 0}
!1188 = !{i32 7, !"uwtable", i32 1}
!1189 = !{i32 7, !"frame-pointer", i32 2}
!1190 = !{!"clang version 15.0.0 (git@github.com:linkeLi0421/llvm-project15-IRDumperPass.git 23ab625cb005cd08da083f9b643a7feed9af8abe)"}
!1191 = !{!"branch_weights", i32 2000, i32 1}
!1192 = !{!"branch_weights", i32 1, i32 2000}
!1193 = !{!"auto-init"}
!1194 = !{i64 2152799914, i64 2152800407, i64 2152799951, i64 2152800007, i64 2152800041, i64 2152800065, i64 2152800106, i64 2152800127, i64 2152800155, i64 2152800189}
!1195 = !{i32 0, i32 33}
!1196 = !{i64 2148735316}
!1197 = !{i64 1221916, i64 1221941, i64 1221963, i64 1221979, i64 1221991, i64 1222011, i64 1222035, i64 1222051, i64 1222063}
!1198 = !{i64 2148735504}
!1199 = !{i64 2160612099}
!1200 = !{i64 2148735897, i64 2148735923, i64 2148735952, i64 2148735986, i64 2148736017, i64 2148736040}
!1201 = !{i64 2160612908}
!1202 = !{i64 2148549290, i64 2148549295, i64 2148549308, i64 2148549352, i64 2148549386, i64 2148549407}
!1203 = !{i64 2160613098}
!1204 = !{i64 2160613379}
!1205 = !{i64 2160613600}
!1206 = !{i64 2160613801}
!1207 = !{i64 2160614079}
!1208 = !{i64 2160840871}
!1209 = !{i64 2160845805}
!1210 = !{i64 2160867487}
!1211 = !{i64 2160872381}
!1212 = !{i64 2160884387}
!1213 = !{i64 2160884229}
!1214 = !{i64 2160887580}
!1215 = !{i64 2160887422}
!1216 = !{i64 1130155, i64 1130216}
!1217 = !{i64 1132887}
!1218 = !{i64 1133172}
!1219 = !{i64 2156099839}
!1220 = !{i64 2156099681}
!1221 = !{i64 2156100009}
!1222 = !{i64 2150480458}
!1223 = !{i64 2160894425}
!1224 = !{i64 1245389, i64 1245410, i64 1245433, i64 1245452, i64 1245471}
!1225 = !{i64 2148737427, i64 2148737459, i64 2148737488, i64 2148737522, i64 2148737553, i64 2148737576}
!1226 = !{i64 2148825428}
!1227 = !{i64 2148739892, i64 2148739924, i64 2148739953, i64 2148739987, i64 2148740018, i64 2148740041}
!1228 = !{i64 2149860914}
!1229 = !{i64 2149552927}
!1230 = !{i64 2149553193}
!1231 = !{i64 2161064069}
!1232 = !{i64 2148549693, i64 2148549698, i64 2148549719, i64 2148549763, i64 2148549797, i64 2148549818}
!1233 = !{i64 2161066619}
!1234 = !{i64 2161067605}
!1235 = !{i64 2161070300}
!1236 = !{i64 2161070343}
!1237 = !{i64 2161071329}
!1238 = !{i64 2159881195}
!1239 = !{i64 2152824582}
!1240 = !{i64 2152824803}
!1241 = !{i64 2149561486}
!1242 = !{i64 2149562522}
!1243 = !{i64 2161118439}
!1244 = !{i64 2161118281}
!1245 = !{i64 2161121586}
!1246 = !{i64 2161121428}
!1247 = !{i64 2161126371}
!1248 = !{i64 2152877420}
!1249 = !{i64 2152877615}
!1250 = !{i64 2161126562}
!1251 = !{i64 2161126733}
!1252 = !{i64 2161172668}
!1253 = !{i64 2161172510}
!1254 = !{i64 2161172843}
!1255 = !{i64 2148738362, i64 2148738388, i64 2148738417, i64 2148738451, i64 2148738482, i64 2148738505}
!1256 = !{i64 2161215023}
!1257 = !{i64 2161192340}
!1258 = !{i64 2161194821}
!1259 = !{i64 2161197710}
!1260 = !{i64 2161205379}
!1261 = !{i64 2161210345}
!1262 = !{i64 2161210187}
!1263 = !{i64 2161210520}
!1264 = !{i64 2161211832}
!1265 = !{i64 2152789226}
!1266 = !{i64 2152789423}
!1267 = !{i64 2161243237}
!1268 = !{i64 7307373}
!1269 = !{i64 7307570}
!1270 = !{i64 2154792803}
!1271 = !{i64 2161249532, i64 2161249812, i64 2161250146, i64 2161250480}
!1272 = !{i64 2161232969}
!1273 = !{i64 2148824349}
!1274 = !{i64 2148739082, i64 2148739114, i64 2148739143, i64 2148739177, i64 2148739208, i64 2148739231}
!1275 = !{i64 2148824578}
!1276 = !{i64 1235165}
!1277 = !{i64 2161314276}
!1278 = !{i64 1130400}
!1279 = !{i64 1130590}
!1280 = !{i64 2161335142}
!1281 = !{i64 2161362832, i64 2161363317, i64 2161362869, i64 2161362925, i64 2161362959, i64 2161362983, i64 2161363024, i64 2161363045, i64 2161363073, i64 2161363107}
!1282 = !{i64 2161259230}
!1283 = !{i64 2161367900}
!1284 = !{i64 2161368001}
!1285 = !{i64 2161370637}
!1286 = !{i64 2161370830}
!1287 = !{i64 2161373070, i64 2161373555, i64 2161373107, i64 2161373163, i64 2161373197, i64 2161373221, i64 2161373262, i64 2161373283, i64 2161373311, i64 2161373345}
!1288 = !{i64 2161374506}
!1289 = !{i64 2161374958}
!1290 = !{i64 2161381083}
!1291 = !{i64 2161381180}
!1292 = !{i64 2153039661}
!1293 = !{i64 2153039880}
!1294 = !{i64 2161429319, i64 2161429804, i64 2161429356, i64 2161429412, i64 2161429446, i64 2161429470, i64 2161429511, i64 2161429532, i64 2161429560, i64 2161429594}
!1295 = !{i64 2161431419}
!1296 = !{i64 2161431516}
!1297 = !{i64 2161449498, i64 2161449778, i64 2161450112, i64 2161450446}
!1298 = !{i64 2154811818, i64 2154811843}
!1299 = !{i64 2161469630, i64 2161469910, i64 2161470244, i64 2161470578}
!1300 = !{i64 2154812499, i64 2154812524}
!1301 = !{i64 2161541683, i64 2161541708}
!1302 = !{i64 2161605229}
!1303 = !{i64 2161605326}
!1304 = !{i64 2161371073}
!1305 = !{i64 2161371176}
!1306 = !{i64 2161611475}
!1307 = !{i64 2161611317}
!1308 = !{i64 2161614097}
!1309 = !{i64 2161613939}
!1310 = !{i64 2161616921}
!1311 = !{i64 2161616763}
!1312 = !{i64 2161623467}
!1313 = !{i64 2161767942}
!1314 = !{i64 2161772221, i64 2161772706, i64 2161772258, i64 2161772314, i64 2161772348, i64 2161772372, i64 2161772413, i64 2161772434, i64 2161772462, i64 2161772496}
!1315 = !{i64 2161775659, i64 2161776144, i64 2161775696, i64 2161775752, i64 2161775786, i64 2161775810, i64 2161775851, i64 2161775872, i64 2161775900, i64 2161775934}
!1316 = !{i64 2155964913}
!1317 = !{i64 2158087536}
!1318 = !{i8 0, i8 2}
!1319 = !{i64 2161791519, i64 2161792004, i64 2161791556, i64 2161791612, i64 2161791646, i64 2161791670, i64 2161791711, i64 2161791732, i64 2161791760, i64 2161791794}
!1320 = !{i64 2161793986, i64 2161794471, i64 2161794023, i64 2161794079, i64 2161794113, i64 2161794137, i64 2161794178, i64 2161794199, i64 2161794227, i64 2161794261}
!1321 = !{i64 2154922471}
!1322 = !{i64 2161789653}
!1323 = !{i64 2161863087, i64 2161863572, i64 2161863124, i64 2161863180, i64 2161863214, i64 2161863238, i64 2161863279, i64 2161863300, i64 2161863328, i64 2161863362}
!1324 = !{i64 2161868836, i64 2161869321, i64 2161868873, i64 2161868929, i64 2161868963, i64 2161868987, i64 2161869028, i64 2161869049, i64 2161869077, i64 2161869111}
!1325 = !{i64 2161870475, i64 2161870960, i64 2161870512, i64 2161870568, i64 2161870602, i64 2161870626, i64 2161870667, i64 2161870688, i64 2161870716, i64 2161870750}
!1326 = !{i64 2148833167}
!1327 = !{i64 2148743142, i64 2148743174, i64 2148743203, i64 2148743237, i64 2148743268, i64 2148743291}
!1328 = !{i64 2148833398}
!1329 = !{i64 2149578319}
!1330 = !{i64 1088933, i64 1088960, i64 1088982, i64 1089010}
!1331 = !{i64 1089341, i64 1089368, i64 1089401, i64 1089422, i64 1089449, i64 1089475}
!1332 = !{i64 2153316596}
!1333 = !{i64 2153316831}
!1334 = !{i64 2161074328, i64 2161074813, i64 2161074365, i64 2161074421, i64 2161074455, i64 2161074479, i64 2161074520, i64 2161074541, i64 2161074569, i64 2161074603}
!1335 = !{i64 2152773365}
!1336 = !{i64 2152773554}
!1337 = !{i64 2152753595}
!1338 = !{i64 2152753784}
!1339 = !{i64 2161128817, i64 2161129302, i64 2161128854, i64 2161128910, i64 2161128944, i64 2161128968, i64 2161129009, i64 2161129030, i64 2161129058, i64 2161129092}
!1340 = !{!"branch_weights", i32 2000, i32 2, i32 2000}
!1341 = !{i64 2161298331, i64 2161298816, i64 2161298368, i64 2161298424, i64 2161298458, i64 2161298482, i64 2161298523, i64 2161298544, i64 2161298572, i64 2161298606}
!1342 = !{i64 2161301649, i64 2161302134, i64 2161301686, i64 2161301742, i64 2161301776, i64 2161301800, i64 2161301841, i64 2161301862, i64 2161301890, i64 2161301924}
!1343 = !{i64 2152808117}
!1344 = !{i64 2152808342}
!1345 = !{i64 1185679, i64 1185696}
!1346 = !{!1347}
!1347 = distinct !{!1347, !1348, !"capacity_from_percent: %agg.result"}
!1348 = distinct !{!1348, !"capacity_from_percent"}
!1349 = !{i64 1088646, i64 1088673}
!1350 = !{i64 1089156, i64 1089183, i64 1089217, i64 1089238}
