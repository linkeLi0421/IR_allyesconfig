; ModuleID = '/llk/IR_all_yes/lib/atomic64.c_pt.bc'
source_filename = "../lib/atomic64.c"
target datalayout = "E-m:e-p:32:32-Fi8-i64:64-v128:64:128-a:0:32-n32-S64"
target triple = "armebv6k-unknown-linux-gnueabi"

module asm ".syntax unified"
module asm "\09.section \22___kcrctab+generic_atomic64_read\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_read\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_read\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_read:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_read\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_read:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_set\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_set\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_set\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_set:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_set\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_set:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_add\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_add\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_add\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_add:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_add\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_add:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_add_return\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_add_return\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_add_return\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_add_return:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_add_return\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_add_return:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_add\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_add\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_add\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_add:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_add\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_add:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_sub\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_sub\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_sub\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_sub:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_sub\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_sub:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_sub_return\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_sub_return\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_sub_return\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_sub_return:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_sub_return\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_sub_return:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_sub\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_sub\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_sub\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_sub:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_sub\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_sub:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_and\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_and\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_and\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_and:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_and\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_and:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_and\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_and\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_and\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_and:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_and\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_and:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_or\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_or\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_or\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_or:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_or\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_or:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_or\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_or\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_or\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_or:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_or\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_or:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_xor\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_xor\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_xor\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_xor:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_xor\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_xor:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_xor\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_xor\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_xor\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_xor:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_xor\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_xor:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_dec_if_positive\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_dec_if_positive\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_dec_if_positive\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_dec_if_positive:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_dec_if_positive\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_dec_if_positive:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_cmpxchg\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_cmpxchg\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_cmpxchg\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_cmpxchg:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_cmpxchg\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_cmpxchg:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_xchg\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_xchg\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_xchg\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_xchg:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_xchg\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_xchg:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"
module asm "\09.section \22___kcrctab+generic_atomic64_fetch_add_unless\22, \22a\22\09"
module asm "\09.weak\09__crc_generic_atomic64_fetch_add_unless\09\09\09\09"
module asm "\09.long\09__crc_generic_atomic64_fetch_add_unless\09\09\09\09"
module asm "\09.previous\09\09\09\09\09"
module asm "\09.section \22__ksymtab_strings\22,\22aMS\22,%progbits,1\09"
module asm "__kstrtab_generic_atomic64_fetch_add_unless:\09\09\09\09\09"
module asm "\09.asciz \09\22generic_atomic64_fetch_add_unless\22\09\09\09\09\09"
module asm "__kstrtabns_generic_atomic64_fetch_add_unless:\09\09\09\09\09"
module asm "\09.asciz \09\22\22\09\09\09\09\09"
module asm "\09.previous\09\09\09\09\09\09"

%struct.kernel_symbol = type { i32, ptr, ptr }
%union.anon.1 = type { %struct.raw_spinlock, [84 x i8] }
%struct.raw_spinlock = type { %struct.arch_spinlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_spinlock_t = type { %union.anon }
%union.anon = type { i32 }
%struct.lockdep_map = type { ptr, [2 x ptr], ptr, i8, i8, i8, i32, i32 }

@__kstrtab_generic_atomic64_read = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_read = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_read = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_read to i32), ptr @__kstrtab_generic_atomic64_read, ptr @__kstrtabns_generic_atomic64_read }, section "___ksymtab+generic_atomic64_read", align 4
@__kstrtab_generic_atomic64_set = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_set = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_set = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_set to i32), ptr @__kstrtab_generic_atomic64_set, ptr @__kstrtabns_generic_atomic64_set }, section "___ksymtab+generic_atomic64_set", align 4
@__kstrtab_generic_atomic64_add = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_add = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_add = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_add to i32), ptr @__kstrtab_generic_atomic64_add, ptr @__kstrtabns_generic_atomic64_add }, section "___ksymtab+generic_atomic64_add", align 4
@__kstrtab_generic_atomic64_add_return = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_add_return = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_add_return = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_add_return to i32), ptr @__kstrtab_generic_atomic64_add_return, ptr @__kstrtabns_generic_atomic64_add_return }, section "___ksymtab+generic_atomic64_add_return", align 4
@__kstrtab_generic_atomic64_fetch_add = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_add = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_add = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_add to i32), ptr @__kstrtab_generic_atomic64_fetch_add, ptr @__kstrtabns_generic_atomic64_fetch_add }, section "___ksymtab+generic_atomic64_fetch_add", align 4
@__kstrtab_generic_atomic64_sub = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_sub = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_sub = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_sub to i32), ptr @__kstrtab_generic_atomic64_sub, ptr @__kstrtabns_generic_atomic64_sub }, section "___ksymtab+generic_atomic64_sub", align 4
@__kstrtab_generic_atomic64_sub_return = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_sub_return = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_sub_return = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_sub_return to i32), ptr @__kstrtab_generic_atomic64_sub_return, ptr @__kstrtabns_generic_atomic64_sub_return }, section "___ksymtab+generic_atomic64_sub_return", align 4
@__kstrtab_generic_atomic64_fetch_sub = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_sub = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_sub = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_sub to i32), ptr @__kstrtab_generic_atomic64_fetch_sub, ptr @__kstrtabns_generic_atomic64_fetch_sub }, section "___ksymtab+generic_atomic64_fetch_sub", align 4
@__kstrtab_generic_atomic64_and = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_and = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_and = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_and to i32), ptr @__kstrtab_generic_atomic64_and, ptr @__kstrtabns_generic_atomic64_and }, section "___ksymtab+generic_atomic64_and", align 4
@__kstrtab_generic_atomic64_fetch_and = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_and = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_and = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_and to i32), ptr @__kstrtab_generic_atomic64_fetch_and, ptr @__kstrtabns_generic_atomic64_fetch_and }, section "___ksymtab+generic_atomic64_fetch_and", align 4
@__kstrtab_generic_atomic64_or = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_or = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_or = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_or to i32), ptr @__kstrtab_generic_atomic64_or, ptr @__kstrtabns_generic_atomic64_or }, section "___ksymtab+generic_atomic64_or", align 4
@__kstrtab_generic_atomic64_fetch_or = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_or = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_or = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_or to i32), ptr @__kstrtab_generic_atomic64_fetch_or, ptr @__kstrtabns_generic_atomic64_fetch_or }, section "___ksymtab+generic_atomic64_fetch_or", align 4
@__kstrtab_generic_atomic64_xor = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_xor = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_xor = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_xor to i32), ptr @__kstrtab_generic_atomic64_xor, ptr @__kstrtabns_generic_atomic64_xor }, section "___ksymtab+generic_atomic64_xor", align 4
@__kstrtab_generic_atomic64_fetch_xor = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_xor = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_xor = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_xor to i32), ptr @__kstrtab_generic_atomic64_fetch_xor, ptr @__kstrtabns_generic_atomic64_fetch_xor }, section "___ksymtab+generic_atomic64_fetch_xor", align 4
@__kstrtab_generic_atomic64_dec_if_positive = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_dec_if_positive = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_dec_if_positive = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_dec_if_positive to i32), ptr @__kstrtab_generic_atomic64_dec_if_positive, ptr @__kstrtabns_generic_atomic64_dec_if_positive }, section "___ksymtab+generic_atomic64_dec_if_positive", align 4
@__kstrtab_generic_atomic64_cmpxchg = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_cmpxchg = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_cmpxchg = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_cmpxchg to i32), ptr @__kstrtab_generic_atomic64_cmpxchg, ptr @__kstrtabns_generic_atomic64_cmpxchg }, section "___ksymtab+generic_atomic64_cmpxchg", align 4
@__kstrtab_generic_atomic64_xchg = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_xchg = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_xchg = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_xchg to i32), ptr @__kstrtab_generic_atomic64_xchg, ptr @__kstrtabns_generic_atomic64_xchg }, section "___ksymtab+generic_atomic64_xchg", align 4
@__kstrtab_generic_atomic64_fetch_add_unless = external dso_local constant [0 x i8], align 1
@__kstrtabns_generic_atomic64_fetch_add_unless = external dso_local constant [0 x i8], align 1
@__ksymtab_generic_atomic64_fetch_add_unless = internal constant %struct.kernel_symbol { i32 ptrtoint (ptr @generic_atomic64_fetch_add_unless to i32), ptr @__kstrtab_generic_atomic64_fetch_add_unless, ptr @__kstrtabns_generic_atomic64_fetch_add_unless }, section "___ksymtab+generic_atomic64_fetch_add_unless", align 4
@atomic64_lock = internal global [16 x %union.anon.1] [%union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }, %union.anon.1 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [84 x i8] undef }], section ".data..cacheline_aligned", align 128
@.str = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"atomic64_lock.lock\00", [45 x i8] zeroinitializer }, align 32
@___asan_gen_.1 = private unnamed_addr constant [17 x i8] c"<string literal>\00", align 1
@___asan_gen_.2 = private constant [18 x i8] c"../lib/atomic64.c\00", align 1
@___asan_gen_.3 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2, i32 32, i32 12 }
@llvm.compiler.used = appending global [19 x ptr] [ptr @__ksymtab_generic_atomic64_add, ptr @__ksymtab_generic_atomic64_add_return, ptr @__ksymtab_generic_atomic64_and, ptr @__ksymtab_generic_atomic64_cmpxchg, ptr @__ksymtab_generic_atomic64_dec_if_positive, ptr @__ksymtab_generic_atomic64_fetch_add, ptr @__ksymtab_generic_atomic64_fetch_add_unless, ptr @__ksymtab_generic_atomic64_fetch_and, ptr @__ksymtab_generic_atomic64_fetch_or, ptr @__ksymtab_generic_atomic64_fetch_sub, ptr @__ksymtab_generic_atomic64_fetch_xor, ptr @__ksymtab_generic_atomic64_or, ptr @__ksymtab_generic_atomic64_read, ptr @__ksymtab_generic_atomic64_set, ptr @__ksymtab_generic_atomic64_sub, ptr @__ksymtab_generic_atomic64_sub_return, ptr @__ksymtab_generic_atomic64_xchg, ptr @__ksymtab_generic_atomic64_xor, ptr @.str], section "llvm.metadata"
@0 = internal global [1 x { i32, i32, i32, i32, i32, i32, i32, i32 }] [{ i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.1 to i32), i32 ptrtoint (ptr @___asan_gen_.2 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.3 to i32), i32 -1 }]
@llvm.used = appending global [2 x ptr] [ptr @asan.module_ctor, ptr @asan.module_dtor], section "llvm.metadata"
@llvm.global_ctors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_ctor, ptr null }]
@llvm.global_dtors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_dtor, ptr null }]

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_read(ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @_raw_spin_lock_irqsave(ptr noundef) local_unnamed_addr #1 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock_irqrestore(ptr noundef, i32 noundef) local_unnamed_addr #1 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_set(ptr noundef %v, i64 noundef %i) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_store8_noabort(i32 %1)
  store i64 %i, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_add(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %add = add i64 %2, %a
  store i64 %add, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_add_return(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %add = add i64 %2, %a
  store i64 %add, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %add
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_add(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %add = add i64 %2, %a
  store i64 %add, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_sub(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %sub = sub i64 %2, %a
  store i64 %sub, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_sub_return(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %sub = sub i64 %2, %a
  store i64 %sub, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %sub
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_sub(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %sub = sub i64 %2, %a
  store i64 %sub, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_and(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %and = and i64 %2, %a
  store i64 %and, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_and(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %and = and i64 %2, %a
  store i64 %and, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_or(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %or = or i64 %2, %a
  store i64 %or, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_or(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %or = or i64 %2, %a
  store i64 %or, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @generic_atomic64_xor(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %xor = xor i64 %2, %a
  store i64 %xor, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_xor(i64 noundef %a, ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %xor = xor i64 %2, %a
  store i64 %xor, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_dec_if_positive(ptr noundef %v) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  %sub = add i64 %2, -1
  call void @__sanitizer_cov_trace_const_cmp8(i64 -1, i64 %sub)
  %cmp2 = icmp sgt i64 %sub, -1
  br i1 %cmp2, label %if.then, label %entry.do.body5_crit_edge

entry.do.body5_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  br label %do.body5

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  %3 = ptrtoint ptr %v to i32
  call void @__asan_store8_noabort(i32 %3)
  store i64 %sub, ptr %v, align 8
  br label %do.body5

do.body5:                                         ; preds = %if.then, %entry.do.body5_crit_edge
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %sub
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_cmpxchg(ptr noundef %v, i64 noundef %o, i64 noundef %n) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  call void @__sanitizer_cov_trace_cmp8(i64 %2, i64 %o)
  %cmp2 = icmp eq i64 %2, %o
  br i1 %cmp2, label %if.then, label %entry.do.body5_crit_edge

entry.do.body5_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  br label %do.body5

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  %3 = ptrtoint ptr %v to i32
  call void @__asan_store8_noabort(i32 %3)
  store i64 %n, ptr %v, align 8
  br label %do.body5

do.body5:                                         ; preds = %if.then, %entry.do.body5_crit_edge
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_xchg(ptr noundef %v, i64 noundef %new) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  store i64 %new, ptr %v, align 8
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local i64 @generic_atomic64_fetch_add_unless(ptr noundef %v, i64 noundef %a, i64 noundef %u) #0 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #3
  %0 = ptrtoint ptr %v to i32
  %shr.i = lshr i32 %0, 7
  %shr1.i = lshr i32 %0, 15
  %shr2.i = lshr i32 %0, 23
  %xor.i = xor i32 %shr1.i, %shr2.i
  %xor3.i = xor i32 %xor.i, %shr.i
  %and.i = and i32 %xor3.i, 15
  %arrayidx.i = getelementptr [16 x %union.anon.1], ptr @atomic64_lock, i32 0, i32 %and.i
  %call1 = tail call i32 @_raw_spin_lock_irqsave(ptr noundef %arrayidx.i) #4
  %1 = ptrtoint ptr %v to i32
  call void @__asan_load8_noabort(i32 %1)
  %2 = load i64, ptr %v, align 8
  call void @__sanitizer_cov_trace_cmp8(i64 %2, i64 %u)
  %cmp2.not = icmp eq i64 %2, %u
  br i1 %cmp2.not, label %entry.do.body5_crit_edge, label %if.then

entry.do.body5_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  br label %do.body5

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #3
  %add = add i64 %2, %a
  %3 = ptrtoint ptr %v to i32
  call void @__asan_store8_noabort(i32 %3)
  store i64 %add, ptr %v, align 8
  br label %do.body5

do.body5:                                         ; preds = %if.then, %entry.do.body5_crit_edge
  tail call void @_raw_spin_unlock_irqrestore(ptr noundef %arrayidx.i, i32 noundef %call1) #4
  ret i64 %2
}

declare void @__sanitizer_cov_trace_cmp8(i64, i64)

declare void @__sanitizer_cov_trace_const_cmp8(i64, i64)

declare void @__sanitizer_cov_trace_pc()

declare void @__asan_load8_noabort(i32)

declare void @__asan_store8_noabort(i32)

declare void @__asan_register_globals(i32, i32)

declare void @__asan_unregister_globals(i32, i32)

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_ctor() #2 {
  call void @__asan_register_globals(i32 ptrtoint (ptr @0 to i32), i32 1)
  ret void
}

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_dtor() #2 {
  call void @__asan_unregister_globals(i32 ptrtoint (ptr @0 to i32), i32 1)
  ret void
}

attributes #0 = { nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #1 = { null_pointer_is_valid "frame-pointer"="none" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #2 = { nounwind uwtable(sync) }
attributes #3 = { nomerge }
attributes #4 = { nounwind }

!llvm.asan.globals = !{!0, !2, !4, !6, !7, !8, !10, !11, !12, !14, !15, !17, !18, !20, !21, !23, !25, !27, !29, !31}
!llvm.module.flags = !{!33, !34, !35, !36, !37, !38, !39}
!llvm.ident = !{!40}

!0 = !{ptr @__ksymtab_generic_atomic64_read, !1, !"__ksymtab_generic_atomic64_read", i1 false, i1 false}
!1 = !{!"../lib/atomic64.c", i32 56, i32 1}
!2 = !{ptr @__ksymtab_generic_atomic64_set, !3, !"__ksymtab_generic_atomic64_set", i1 false, i1 false}
!3 = !{!"../lib/atomic64.c", i32 67, i32 1}
!4 = !{ptr @__ksymtab_generic_atomic64_add, !5, !"__ksymtab_generic_atomic64_add", i1 false, i1 false}
!5 = !{!"../lib/atomic64.c", i32 115, i32 1}
!6 = !{ptr @__ksymtab_generic_atomic64_add_return, !5, !"__ksymtab_generic_atomic64_add_return", i1 false, i1 false}
!7 = !{ptr @__ksymtab_generic_atomic64_fetch_add, !5, !"__ksymtab_generic_atomic64_fetch_add", i1 false, i1 false}
!8 = !{ptr @__ksymtab_generic_atomic64_sub, !9, !"__ksymtab_generic_atomic64_sub", i1 false, i1 false}
!9 = !{!"../lib/atomic64.c", i32 116, i32 1}
!10 = !{ptr @__ksymtab_generic_atomic64_sub_return, !9, !"__ksymtab_generic_atomic64_sub_return", i1 false, i1 false}
!11 = !{ptr @__ksymtab_generic_atomic64_fetch_sub, !9, !"__ksymtab_generic_atomic64_fetch_sub", i1 false, i1 false}
!12 = !{ptr @__ksymtab_generic_atomic64_and, !13, !"__ksymtab_generic_atomic64_and", i1 false, i1 false}
!13 = !{!"../lib/atomic64.c", i32 123, i32 1}
!14 = !{ptr @__ksymtab_generic_atomic64_fetch_and, !13, !"__ksymtab_generic_atomic64_fetch_and", i1 false, i1 false}
!15 = !{ptr @__ksymtab_generic_atomic64_or, !16, !"__ksymtab_generic_atomic64_or", i1 false, i1 false}
!16 = !{!"../lib/atomic64.c", i32 124, i32 1}
!17 = !{ptr @__ksymtab_generic_atomic64_fetch_or, !16, !"__ksymtab_generic_atomic64_fetch_or", i1 false, i1 false}
!18 = !{ptr @__ksymtab_generic_atomic64_xor, !19, !"__ksymtab_generic_atomic64_xor", i1 false, i1 false}
!19 = !{!"../lib/atomic64.c", i32 125, i32 1}
!20 = !{ptr @__ksymtab_generic_atomic64_fetch_xor, !19, !"__ksymtab_generic_atomic64_fetch_xor", i1 false, i1 false}
!21 = !{ptr @__ksymtab_generic_atomic64_dec_if_positive, !22, !"__ksymtab_generic_atomic64_dec_if_positive", i1 false, i1 false}
!22 = !{!"../lib/atomic64.c", i32 144, i32 1}
!23 = !{ptr @__ksymtab_generic_atomic64_cmpxchg, !24, !"__ksymtab_generic_atomic64_cmpxchg", i1 false, i1 false}
!24 = !{!"../lib/atomic64.c", i32 159, i32 1}
!25 = !{ptr @__ksymtab_generic_atomic64_xchg, !26, !"__ksymtab_generic_atomic64_xchg", i1 false, i1 false}
!26 = !{!"../lib/atomic64.c", i32 173, i32 1}
!27 = !{ptr @__ksymtab_generic_atomic64_fetch_add_unless, !28, !"__ksymtab_generic_atomic64_fetch_add_unless", i1 false, i1 false}
!28 = !{!"../lib/atomic64.c", i32 189, i32 1}
!29 = !{ptr @.str, !30, !"<string literal>", i1 false, i1 false}
!30 = !{!"../lib/atomic64.c", i32 32, i32 12}
!31 = !{ptr @atomic64_lock, !32, !"atomic64_lock", i1 false, i1 false}
!32 = !{!"../lib/atomic64.c", i32 30, i32 3}
!33 = !{i32 1, !"wchar_size", i32 2}
!34 = !{i32 1, !"min_enum_size", i32 4}
!35 = !{i32 8, !"branch-target-enforcement", i32 0}
!36 = !{i32 8, !"sign-return-address", i32 0}
!37 = !{i32 8, !"sign-return-address-all", i32 0}
!38 = !{i32 8, !"sign-return-address-with-bkey", i32 0}
!39 = !{i32 7, !"uwtable", i32 1}
!40 = !{!"clang version 15.0.0 (git@github.com:linkeLi0421/llvm-project15-IRDumperPass.git 23ab625cb005cd08da083f9b643a7feed9af8abe)"}
