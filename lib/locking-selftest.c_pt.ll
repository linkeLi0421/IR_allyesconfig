; ModuleID = '/llk/IR_all_yes/lib/locking-selftest.c_pt.bc'
source_filename = "../lib/locking-selftest.c"
target datalayout = "E-m:e-p:32:32-Fi8-i64:64-v128:64:128-a:0:32-n32-S64"
target triple = "armebv6k-unknown-linux-gnueabi"

module asm ".syntax unified"

%struct.obs_kernel_param = type { ptr, ptr, i32 }
%struct.pi_entry = type { ptr, ptr, ptr, i32, ptr, ptr }
%struct.local_lock_t = type { %struct.lockdep_map, ptr }
%struct.lockdep_map = type { ptr, [2 x ptr], ptr, i8, i8, i8, i32, i32 }
%struct.lock_class_key = type { %union.anon.0 }
%union.anon.0 = type { %struct.hlist_node }
%struct.hlist_node = type { ptr, ptr }
%struct.rt_mutex = type { %struct.rt_mutex_base, %struct.lockdep_map }
%struct.rt_mutex_base = type { %struct.raw_spinlock, %struct.rb_root_cached, ptr }
%struct.raw_spinlock = type { %struct.arch_spinlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_spinlock_t = type { %union.anon.1 }
%union.anon.1 = type { i32 }
%struct.rb_root_cached = type { %struct.rb_root, ptr }
%struct.rb_root = type { ptr }
%struct.spinlock = type { %union.anon.9 }
%union.anon.9 = type { %struct.raw_spinlock }
%struct.rwlock_t = type { %struct.arch_rwlock_t, i32, i32, ptr, %struct.lockdep_map }
%struct.arch_rwlock_t = type { i32 }
%struct.mutex = type { %struct.atomic_t, %struct.raw_spinlock, %struct.optimistic_spin_queue, %struct.list_head, ptr, %struct.lockdep_map }
%struct.atomic_t = type { i32 }
%struct.optimistic_spin_queue = type { %struct.atomic_t }
%struct.list_head = type { ptr, ptr }
%struct.rw_semaphore = type { %struct.atomic_t, %struct.atomic_t, %struct.optimistic_spin_queue, %struct.raw_spinlock, %struct.list_head, ptr, %struct.lockdep_map }
%struct.ww_class = type { %struct.atomic_t, %struct.lock_class_key, %struct.lock_class_key, ptr, ptr, i32 }
%struct.ww_acquire_ctx = type { ptr, i32, i32, i16, i16, i32, ptr, ptr, %struct.lockdep_map, i32, i32 }
%struct.ww_mutex = type { %struct.mutex, ptr, ptr }
%struct.thread_info = type { i32, i32, ptr, i32, i32, %struct.cpu_context_save, i32, [16 x i8], [2 x i32], %union.fp_state, %union.vfp_state, i32 }
%struct.cpu_context_save = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [2 x i32] }
%union.fp_state = type { %struct.iwmmxt_struct }
%struct.iwmmxt_struct = type { [38 x i32] }
%union.vfp_state = type { %struct.vfp_hard_struct }
%struct.vfp_hard_struct = type { [32 x i64], i32, i32, i32, i32, i32 }
%struct.task_struct = type { i32, ptr, %struct.refcount_struct, i32, i32, i32, %struct.__call_single_node, i32, i32, ptr, i32, i32, i32, i32, i32, i32, i32, [56 x i8], %struct.sched_entity, %struct.sched_rt_entity, %struct.sched_dl_entity, ptr, %struct.rb_node, i32, i32, ptr, [2 x %struct.uclamp_se], [2 x %struct.uclamp_se], [116 x i8], %struct.sched_statistics, i32, i32, i32, ptr, ptr, %struct.cpumask, ptr, i16, i16, i32, i8, i8, i32, %struct.list_head, i32, i32, %union.rcu_special, i8, %struct.list_head, %struct.sched_info, %struct.list_head, %struct.plist_node, %struct.rb_node, ptr, ptr, %struct.vmacache, %struct.task_rss_stat, i32, i32, i32, i32, i32, i32, i8, [3 x i8], i16, i32, %struct.restart_block, i32, i32, i32, ptr, ptr, %struct.list_head, %struct.list_head, ptr, %struct.list_head, %struct.list_head, ptr, [4 x %struct.hlist_node], %struct.list_head, %struct.list_head, ptr, ptr, ptr, ptr, i64, i64, i64, %struct.prev_cputime, i32, i32, i64, i64, i32, i32, %struct.posix_cputimers, ptr, ptr, ptr, ptr, [16 x i8], ptr, %struct.sysv_sem, %struct.sysv_shm, i32, i32, ptr, ptr, ptr, ptr, ptr, ptr, %struct.sigset_t, %struct.sigset_t, %struct.sigset_t, %struct.sigpending, i32, i32, i32, ptr, %struct.kuid_t, i32, %struct.seccomp, %struct.syscall_user_dispatch, i64, i64, %struct.spinlock, %struct.raw_spinlock, %struct.wake_q_node, %struct.rb_root_cached, ptr, ptr, ptr, i32, %struct.irqtrace_events, i32, i64, i32, i32, i32, i64, i32, i32, [48 x %struct.held_lock], i32, ptr, ptr, ptr, ptr, ptr, ptr, ptr, i32, ptr, %struct.task_io_accounting, i32, i64, i64, i64, %struct.nodemask_t, %struct.seqcount_spinlock, i32, i32, ptr, %struct.list_head, ptr, %struct.list_head, ptr, %struct.mutex, i32, [2 x ptr], %struct.mutex, %struct.list_head, ptr, i32, i32, %struct.tlbflush_unmap_batch, %union.anon.63, ptr, %struct.page_frag, ptr, i32, i32, i32, i32, i32, i32, [32 x %struct.latency_record], i64, i64, i32, ptr, i32, i32, i32, i32, ptr, ptr, i64, i32, i32, ptr, i32, i32, i32, ptr, ptr, ptr, i32, i32, %struct.kmap_ctrl, i32, i32, ptr, ptr, ptr, ptr, %struct.llist_head, %struct.thread_struct, [84 x i8] }
%struct.refcount_struct = type { %struct.atomic_t }
%struct.__call_single_node = type { %struct.llist_node, %union.anon }
%struct.llist_node = type { ptr }
%union.anon = type { i32 }
%struct.sched_entity = type { %struct.load_weight, %struct.rb_node, %struct.list_head, i32, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, [36 x i8], %struct.sched_avg }
%struct.load_weight = type { i32, i32 }
%struct.sched_avg = type { i64, i64, i64, i32, i32, i32, i32, i32, [4 x i8], %struct.util_est, [72 x i8] }
%struct.util_est = type { i32, i32 }
%struct.sched_rt_entity = type { %struct.list_head, i32, i32, i32, i16, i16, ptr, ptr, ptr, ptr }
%struct.sched_dl_entity = type { %struct.rb_node, i64, i64, i64, i64, i64, i64, i64, i32, i8, %struct.hrtimer, %struct.hrtimer, ptr }
%struct.hrtimer = type { %struct.timerqueue_node, i64, ptr, ptr, i8, i8, i8, i8 }
%struct.timerqueue_node = type { %struct.rb_node, i64 }
%struct.uclamp_se = type { i16, [2 x i8] }
%struct.sched_statistics = type { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, [24 x i8] }
%struct.cpumask = type { [1 x i32] }
%union.rcu_special = type { i32 }
%struct.sched_info = type { i32, i64, i64, i64 }
%struct.plist_node = type { i32, %struct.list_head, %struct.list_head }
%struct.rb_node = type { i32, ptr, ptr }
%struct.vmacache = type { i64, [4 x ptr] }
%struct.task_rss_stat = type { i32, [4 x i32] }
%struct.restart_block = type { i32, ptr, %union.anon.42 }
%union.anon.42 = type { %struct.anon.43 }
%struct.anon.43 = type { ptr, i32, i32, i32, i64, ptr }
%struct.prev_cputime = type { i64, i64, %struct.raw_spinlock }
%struct.posix_cputimers = type { [3 x %struct.posix_cputimer_base], i32, i32 }
%struct.posix_cputimer_base = type { i64, %struct.timerqueue_head }
%struct.timerqueue_head = type { %struct.rb_root_cached }
%struct.sysv_sem = type { ptr }
%struct.sysv_shm = type { %struct.list_head }
%struct.sigset_t = type { [2 x i32] }
%struct.sigpending = type { %struct.list_head, %struct.sigset_t }
%struct.kuid_t = type { i32 }
%struct.seccomp = type { i32, %struct.atomic_t, ptr }
%struct.syscall_user_dispatch = type {}
%struct.wake_q_node = type { ptr }
%struct.irqtrace_events = type { i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.held_lock = type { i64, i32, ptr, ptr, i64, i64, i32, i32 }
%struct.task_io_accounting = type { i64, i64, i64, i64, i64, i64, i64 }
%struct.nodemask_t = type { [1 x i32] }
%struct.seqcount_spinlock = type { %struct.seqcount, ptr }
%struct.seqcount = type { i32, %struct.lockdep_map }
%struct.tlbflush_unmap_batch = type {}
%union.anon.63 = type { %struct.callback_head }
%struct.callback_head = type { ptr, ptr }
%struct.page_frag = type { ptr, i16, i16 }
%struct.latency_record = type { [12 x i32], i32, i32, i32 }
%struct.kmap_ctrl = type { i32, [33 x i32] }
%struct.llist_head = type { ptr }
%struct.thread_struct = type { i32, i32, i32, %struct.debug_info }
%struct.debug_info = type { [32 x ptr] }

@__setup_str_setup_debug_locks_verbose = internal constant [21 x i8] c"debug_locks_verbose=\00", section ".init.rodata", align 1
@__setup_setup_debug_locks_verbose = internal global %struct.obs_kernel_param { ptr @__setup_str_setup_debug_locks_verbose, ptr @setup_debug_locks_verbose, i32 0 }, section ".init.setup", align 4
@debug_locks = external dso_local local_unnamed_addr global i32, section ".data..read_mostly", align 4
@locking_selftest._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str, ptr @.str.1, ptr @.str.2, i32 2863, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"----------------------------------\0A\00", [60 x i8] zeroinitializer }, align 32
@.str.1 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"locking_selftest\00", [47 x i8] zeroinitializer }, align 32
@.str.2 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"lib/locking-selftest.c\00", [41 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr = internal global ptr @locking_selftest._entry, section ".printk_index", align 4
@locking_selftest._entry.3 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.4, ptr @.str.1, ptr @.str.2, i32 2864, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.4 = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"| Locking API testsuite disabled |\0A\00", [60 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.5 = internal global ptr @locking_selftest._entry.3, section ".printk_index", align 4
@locking_selftest._entry.6 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str, ptr @.str.1, ptr @.str.2, i32 2865, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.7 = internal global ptr @locking_selftest._entry.6, section ".printk_index", align 4
@force_read_lock_recursive = dso_local global { i32, [28 x i8] } zeroinitializer, align 32
@locking_selftest._entry.8 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.9, ptr @.str.1, ptr @.str.2, i32 2877, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.9 = internal constant { [26 x i8], [38 x i8] } { [26 x i8] c"------------------------\0A\00", [38 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.10 = internal global ptr @locking_selftest._entry.8, section ".printk_index", align 4
@locking_selftest._entry.11 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.12, ptr @.str.1, ptr @.str.2, i32 2878, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.12 = internal constant { [26 x i8], [38 x i8] } { [26 x i8] c"| Locking API testsuite:\0A\00", [38 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.13 = internal global ptr @locking_selftest._entry.11, section ".printk_index", align 4
@locking_selftest._entry.14 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.15, ptr @.str.1, ptr @.str.2, i32 2879, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.15 = internal constant { [78 x i8], [50 x i8] } { [78 x i8] c"----------------------------------------------------------------------------\0A\00", [50 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.16 = internal global ptr @locking_selftest._entry.14, section ".printk_index", align 4
@locking_selftest._entry.17 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.18, ptr @.str.1, ptr @.str.2, i32 2880, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.18 = internal constant { [85 x i8], [43 x i8] } { [85 x i8] c"                                 | spin |wlock |rlock |mutex | wsem | rsem |rtmutex\0A\00", [43 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.19 = internal global ptr @locking_selftest._entry.17, section ".printk_index", align 4
@locking_selftest._entry.20 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.1, ptr @.str.2, i32 2881, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.21 = internal constant { [78 x i8], [50 x i8] } { [78 x i8] c"  --------------------------------------------------------------------------\0A\00", [50 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.22 = internal global ptr @locking_selftest._entry.20, section ".printk_index", align 4
@.str.23 = internal constant { [13 x i8], [19 x i8] } { [13 x i8] c"A-A deadlock\00", [19 x i8] zeroinitializer }, align 32
@locking_selftest._entry.24 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2886, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.25 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"\01c\0A\00", [28 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.26 = internal global ptr @locking_selftest._entry.24, section ".printk_index", align 4
@.str.27 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"A-B-B-A deadlock\00", [47 x i8] zeroinitializer }, align 32
@locking_selftest._entry.28 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2887, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.29 = internal global ptr @locking_selftest._entry.28, section ".printk_index", align 4
@.str.30 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"A-B-B-C-C-A deadlock\00", [43 x i8] zeroinitializer }, align 32
@locking_selftest._entry.31 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2888, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.32 = internal global ptr @locking_selftest._entry.31, section ".printk_index", align 4
@.str.33 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"A-B-C-A-B-C deadlock\00", [43 x i8] zeroinitializer }, align 32
@locking_selftest._entry.34 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2889, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.35 = internal global ptr @locking_selftest._entry.34, section ".printk_index", align 4
@.str.36 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"A-B-B-C-C-D-D-A deadlock\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.37 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2890, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.38 = internal global ptr @locking_selftest._entry.37, section ".printk_index", align 4
@.str.39 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"A-B-C-D-B-D-D-A deadlock\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.40 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2891, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.41 = internal global ptr @locking_selftest._entry.40, section ".printk_index", align 4
@.str.42 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"A-B-C-D-B-C-D-A deadlock\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.43 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2892, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.44 = internal global ptr @locking_selftest._entry.43, section ".printk_index", align 4
@.str.45 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"double unlock\00", [18 x i8] zeroinitializer }, align 32
@locking_selftest._entry.46 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2893, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.47 = internal global ptr @locking_selftest._entry.46, section ".printk_index", align 4
@.str.48 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"initialize held\00", [16 x i8] zeroinitializer }, align 32
@locking_selftest._entry.49 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2894, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.50 = internal global ptr @locking_selftest._entry.49, section ".printk_index", align 4
@locking_selftest._entry.51 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.1, ptr @.str.2, i32 2896, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.52 = internal global ptr @locking_selftest._entry.51, section ".printk_index", align 4
@.str.53 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"recursive read-lock\00", [44 x i8] zeroinitializer }, align 32
@locking_selftest._entry.54 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2898, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.55 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"\01c             |\00", [47 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.56 = internal global ptr @locking_selftest._entry.54, section ".printk_index", align 4
@locking_selftest._entry.57 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2900, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.58 = internal global ptr @locking_selftest._entry.57, section ".printk_index", align 4
@locking_selftest._entry.59 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2902, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.60 = internal global ptr @locking_selftest._entry.59, section ".printk_index", align 4
@.str.61 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"recursive read-lock #2\00", [41 x i8] zeroinitializer }, align 32
@locking_selftest._entry.62 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2905, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.63 = internal global ptr @locking_selftest._entry.62, section ".printk_index", align 4
@locking_selftest._entry.64 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2907, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.65 = internal global ptr @locking_selftest._entry.64, section ".printk_index", align 4
@locking_selftest._entry.66 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2909, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.67 = internal global ptr @locking_selftest._entry.66, section ".printk_index", align 4
@.str.68 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"mixed read-write-lock\00", [42 x i8] zeroinitializer }, align 32
@locking_selftest._entry.69 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2912, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.70 = internal global ptr @locking_selftest._entry.69, section ".printk_index", align 4
@locking_selftest._entry.71 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2914, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.72 = internal global ptr @locking_selftest._entry.71, section ".printk_index", align 4
@locking_selftest._entry.73 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2916, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.74 = internal global ptr @locking_selftest._entry.73, section ".printk_index", align 4
@.str.75 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"mixed write-read-lock\00", [42 x i8] zeroinitializer }, align 32
@locking_selftest._entry.76 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2919, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.77 = internal global ptr @locking_selftest._entry.76, section ".printk_index", align 4
@locking_selftest._entry.78 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2921, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.79 = internal global ptr @locking_selftest._entry.78, section ".printk_index", align 4
@locking_selftest._entry.80 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2923, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.81 = internal global ptr @locking_selftest._entry.80, section ".printk_index", align 4
@.str.82 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"mixed read-lock/lock-write ABBA\00", [32 x i8] zeroinitializer }, align 32
@locking_selftest._entry.83 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2926, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.84 = internal global ptr @locking_selftest._entry.83, section ".printk_index", align 4
@locking_selftest._entry.85 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2928, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.86 = internal global ptr @locking_selftest._entry.85, section ".printk_index", align 4
@.str.87 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"mixed read-lock/lock-read ABBA\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.88 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2932, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.89 = internal global ptr @locking_selftest._entry.88, section ".printk_index", align 4
@locking_selftest._entry.90 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2934, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.91 = internal global ptr @locking_selftest._entry.90, section ".printk_index", align 4
@.str.92 = internal constant { [33 x i8], [63 x i8] } { [33 x i8] c"mixed write-lock/lock-write ABBA\00", [63 x i8] zeroinitializer }, align 32
@locking_selftest._entry.93 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2938, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.94 = internal global ptr @locking_selftest._entry.93, section ".printk_index", align 4
@locking_selftest._entry.95 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2940, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.96 = internal global ptr @locking_selftest._entry.95, section ".printk_index", align 4
@.str.97 = internal constant { [32 x i8], [32 x i8] } { [32 x i8] c"chain cached mixed R-L/L-W ABBA\00", [32 x i8] zeroinitializer }, align 32
@locking_selftest._entry.98 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2944, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.99 = internal global ptr @locking_selftest._entry.98, section ".printk_index", align 4
@.str.100 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/123\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.101 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.102 = internal global ptr @locking_selftest._entry.101, section ".printk_index", align 4
@locking_selftest._entry.103 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.104 = internal global ptr @locking_selftest._entry.103, section ".printk_index", align 4
@.str.105 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/132\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.106 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.107 = internal global ptr @locking_selftest._entry.106, section ".printk_index", align 4
@locking_selftest._entry.108 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.109 = internal global ptr @locking_selftest._entry.108, section ".printk_index", align 4
@.str.110 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/213\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.111 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.112 = internal global ptr @locking_selftest._entry.111, section ".printk_index", align 4
@locking_selftest._entry.113 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.114 = internal global ptr @locking_selftest._entry.113, section ".printk_index", align 4
@.str.115 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/231\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.116 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.117 = internal global ptr @locking_selftest._entry.116, section ".printk_index", align 4
@locking_selftest._entry.118 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.119 = internal global ptr @locking_selftest._entry.118, section ".printk_index", align 4
@.str.120 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/312\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.121 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.122 = internal global ptr @locking_selftest._entry.121, section ".printk_index", align 4
@locking_selftest._entry.123 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.124 = internal global ptr @locking_selftest._entry.123, section ".printk_index", align 4
@.str.125 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/W2R3/W3R1/321\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.126 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.127 = internal global ptr @locking_selftest._entry.126, section ".printk_index", align 4
@locking_selftest._entry.128 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2947, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.129 = internal global ptr @locking_selftest._entry.128, section ".printk_index", align 4
@.str.130 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/123\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.131 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.132 = internal global ptr @locking_selftest._entry.131, section ".printk_index", align 4
@locking_selftest._entry.133 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.134 = internal global ptr @locking_selftest._entry.133, section ".printk_index", align 4
@.str.135 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/132\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.136 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.137 = internal global ptr @locking_selftest._entry.136, section ".printk_index", align 4
@locking_selftest._entry.138 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.139 = internal global ptr @locking_selftest._entry.138, section ".printk_index", align 4
@.str.140 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/213\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.141 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.142 = internal global ptr @locking_selftest._entry.141, section ".printk_index", align 4
@locking_selftest._entry.143 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.144 = internal global ptr @locking_selftest._entry.143, section ".printk_index", align 4
@.str.145 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/231\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.146 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.147 = internal global ptr @locking_selftest._entry.146, section ".printk_index", align 4
@locking_selftest._entry.148 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.149 = internal global ptr @locking_selftest._entry.148, section ".printk_index", align 4
@.str.150 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/312\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.151 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.152 = internal global ptr @locking_selftest._entry.151, section ".printk_index", align 4
@locking_selftest._entry.153 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.154 = internal global ptr @locking_selftest._entry.153, section ".printk_index", align 4
@.str.155 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/W3R1/321\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.156 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.157 = internal global ptr @locking_selftest._entry.156, section ".printk_index", align 4
@locking_selftest._entry.158 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2948, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.159 = internal global ptr @locking_selftest._entry.158, section ".printk_index", align 4
@.str.160 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/123\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.161 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.162 = internal global ptr @locking_selftest._entry.161, section ".printk_index", align 4
@locking_selftest._entry.163 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.164 = internal global ptr @locking_selftest._entry.163, section ".printk_index", align 4
@.str.165 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/132\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.166 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.167 = internal global ptr @locking_selftest._entry.166, section ".printk_index", align 4
@locking_selftest._entry.168 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.169 = internal global ptr @locking_selftest._entry.168, section ".printk_index", align 4
@.str.170 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/213\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.171 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.172 = internal global ptr @locking_selftest._entry.171, section ".printk_index", align 4
@locking_selftest._entry.173 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.174 = internal global ptr @locking_selftest._entry.173, section ".printk_index", align 4
@.str.175 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/231\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.176 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.177 = internal global ptr @locking_selftest._entry.176, section ".printk_index", align 4
@locking_selftest._entry.178 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.179 = internal global ptr @locking_selftest._entry.178, section ".printk_index", align 4
@.str.180 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/312\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.181 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.182 = internal global ptr @locking_selftest._entry.181, section ".printk_index", align 4
@locking_selftest._entry.183 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.184 = internal global ptr @locking_selftest._entry.183, section ".printk_index", align 4
@.str.185 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1W2/R2R3/R3W1/321\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.186 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.187 = internal global ptr @locking_selftest._entry.186, section ".printk_index", align 4
@locking_selftest._entry.188 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2949, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.189 = internal global ptr @locking_selftest._entry.188, section ".printk_index", align 4
@.str.190 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/123\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.191 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.192 = internal global ptr @locking_selftest._entry.191, section ".printk_index", align 4
@locking_selftest._entry.193 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.194 = internal global ptr @locking_selftest._entry.193, section ".printk_index", align 4
@.str.195 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/132\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.196 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.197 = internal global ptr @locking_selftest._entry.196, section ".printk_index", align 4
@locking_selftest._entry.198 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.199 = internal global ptr @locking_selftest._entry.198, section ".printk_index", align 4
@.str.200 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/213\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.201 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.202 = internal global ptr @locking_selftest._entry.201, section ".printk_index", align 4
@locking_selftest._entry.203 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.204 = internal global ptr @locking_selftest._entry.203, section ".printk_index", align 4
@.str.205 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/231\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.206 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.207 = internal global ptr @locking_selftest._entry.206, section ".printk_index", align 4
@locking_selftest._entry.208 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.209 = internal global ptr @locking_selftest._entry.208, section ".printk_index", align 4
@.str.210 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/312\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.211 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.212 = internal global ptr @locking_selftest._entry.211, section ".printk_index", align 4
@locking_selftest._entry.213 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.214 = internal global ptr @locking_selftest._entry.213, section ".printk_index", align 4
@.str.215 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"rlock W1R2/R2R3/W3W1/321\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.216 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.55, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.217 = internal global ptr @locking_selftest._entry.216, section ".printk_index", align 4
@locking_selftest._entry.218 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2950, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.219 = internal global ptr @locking_selftest._entry.218, section ".printk_index", align 4
@locking_selftest._entry.220 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.1, ptr @.str.2, i32 2952, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.221 = internal global ptr @locking_selftest._entry.220, section ".printk_index", align 4
@.str.222 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"hard-irqs-on + irq-safe-A/12\00", [35 x i8] zeroinitializer }, align 32
@locking_selftest._entry.223 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2956, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.224 = internal global ptr @locking_selftest._entry.223, section ".printk_index", align 4
@.str.225 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"soft-irqs-on + irq-safe-A/12\00", [35 x i8] zeroinitializer }, align 32
@locking_selftest._entry.226 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2956, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.227 = internal global ptr @locking_selftest._entry.226, section ".printk_index", align 4
@.str.228 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"hard-irqs-on + irq-safe-A/21\00", [35 x i8] zeroinitializer }, align 32
@locking_selftest._entry.229 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2956, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.230 = internal global ptr @locking_selftest._entry.229, section ".printk_index", align 4
@.str.231 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"soft-irqs-on + irq-safe-A/21\00", [35 x i8] zeroinitializer }, align 32
@locking_selftest._entry.232 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2956, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.233 = internal global ptr @locking_selftest._entry.232, section ".printk_index", align 4
@.str.234 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sirq-safe-A => hirqs-on/12\00", [37 x i8] zeroinitializer }, align 32
@locking_selftest._entry.235 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2957, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.236 = internal global ptr @locking_selftest._entry.235, section ".printk_index", align 4
@.str.237 = internal constant { [27 x i8], [37 x i8] } { [27 x i8] c"sirq-safe-A => hirqs-on/21\00", [37 x i8] zeroinitializer }, align 32
@locking_selftest._entry.238 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2957, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.239 = internal global ptr @locking_selftest._entry.238, section ".printk_index", align 4
@.str.240 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"hard-safe-A + irqs-on/12\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.241 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2958, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.242 = internal global ptr @locking_selftest._entry.241, section ".printk_index", align 4
@.str.243 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"soft-safe-A + irqs-on/12\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.244 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2958, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.245 = internal global ptr @locking_selftest._entry.244, section ".printk_index", align 4
@.str.246 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"hard-safe-A + irqs-on/21\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.247 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2958, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.248 = internal global ptr @locking_selftest._entry.247, section ".printk_index", align 4
@.str.249 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"soft-safe-A + irqs-on/21\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry.250 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2958, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.251 = internal global ptr @locking_selftest._entry.250, section ".printk_index", align 4
@.str.252 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/123\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.253 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.254 = internal global ptr @locking_selftest._entry.253, section ".printk_index", align 4
@.str.255 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/123\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.256 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.257 = internal global ptr @locking_selftest._entry.256, section ".printk_index", align 4
@.str.258 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/132\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.259 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.260 = internal global ptr @locking_selftest._entry.259, section ".printk_index", align 4
@.str.261 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/132\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.262 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.263 = internal global ptr @locking_selftest._entry.262, section ".printk_index", align 4
@.str.264 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/213\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.265 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.266 = internal global ptr @locking_selftest._entry.265, section ".printk_index", align 4
@.str.267 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/213\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.268 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.269 = internal global ptr @locking_selftest._entry.268, section ".printk_index", align 4
@.str.270 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/231\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.271 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.272 = internal global ptr @locking_selftest._entry.271, section ".printk_index", align 4
@.str.273 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/231\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.274 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.275 = internal global ptr @locking_selftest._entry.274, section ".printk_index", align 4
@.str.276 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/312\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.277 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.278 = internal global ptr @locking_selftest._entry.277, section ".printk_index", align 4
@.str.279 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/312\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.280 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.281 = internal global ptr @locking_selftest._entry.280, section ".printk_index", align 4
@.str.282 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #1/321\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.283 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.284 = internal global ptr @locking_selftest._entry.283, section ".printk_index", align 4
@.str.285 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #1/321\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.286 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2959, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.287 = internal global ptr @locking_selftest._entry.286, section ".printk_index", align 4
@.str.288 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/123\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.289 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.290 = internal global ptr @locking_selftest._entry.289, section ".printk_index", align 4
@.str.291 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/123\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.292 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.293 = internal global ptr @locking_selftest._entry.292, section ".printk_index", align 4
@.str.294 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/132\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.295 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.296 = internal global ptr @locking_selftest._entry.295, section ".printk_index", align 4
@.str.297 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/132\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.298 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.299 = internal global ptr @locking_selftest._entry.298, section ".printk_index", align 4
@.str.300 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/213\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.301 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.302 = internal global ptr @locking_selftest._entry.301, section ".printk_index", align 4
@.str.303 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/213\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.304 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.305 = internal global ptr @locking_selftest._entry.304, section ".printk_index", align 4
@.str.306 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/231\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.307 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.308 = internal global ptr @locking_selftest._entry.307, section ".printk_index", align 4
@.str.309 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/231\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.310 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.311 = internal global ptr @locking_selftest._entry.310, section ".printk_index", align 4
@.str.312 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/312\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.313 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.314 = internal global ptr @locking_selftest._entry.313, section ".printk_index", align 4
@.str.315 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/312\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.316 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.317 = internal global ptr @locking_selftest._entry.316, section ".printk_index", align 4
@.str.318 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"hard-safe-A + unsafe-B #2/321\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.319 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.320 = internal global ptr @locking_selftest._entry.319, section ".printk_index", align 4
@.str.321 = internal constant { [30 x i8], [34 x i8] } { [30 x i8] c"soft-safe-A + unsafe-B #2/321\00", [34 x i8] zeroinitializer }, align 32
@locking_selftest._entry.322 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2960, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.323 = internal global ptr @locking_selftest._entry.322, section ".printk_index", align 4
@.str.324 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/123\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.325 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.326 = internal global ptr @locking_selftest._entry.325, section ".printk_index", align 4
@.str.327 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/123\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.328 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.329 = internal global ptr @locking_selftest._entry.328, section ".printk_index", align 4
@.str.330 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/132\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.331 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.332 = internal global ptr @locking_selftest._entry.331, section ".printk_index", align 4
@.str.333 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/132\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.334 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.335 = internal global ptr @locking_selftest._entry.334, section ".printk_index", align 4
@.str.336 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/213\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.337 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.338 = internal global ptr @locking_selftest._entry.337, section ".printk_index", align 4
@.str.339 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/213\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.340 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.341 = internal global ptr @locking_selftest._entry.340, section ".printk_index", align 4
@.str.342 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/231\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.343 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.344 = internal global ptr @locking_selftest._entry.343, section ".printk_index", align 4
@.str.345 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/231\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.346 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.347 = internal global ptr @locking_selftest._entry.346, section ".printk_index", align 4
@.str.348 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/312\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.349 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.350 = internal global ptr @locking_selftest._entry.349, section ".printk_index", align 4
@.str.351 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/312\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.352 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.353 = internal global ptr @locking_selftest._entry.352, section ".printk_index", align 4
@.str.354 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq lock-inversion/321\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.355 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.356 = internal global ptr @locking_selftest._entry.355, section ".printk_index", align 4
@.str.357 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq lock-inversion/321\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.358 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2961, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.359 = internal global ptr @locking_selftest._entry.358, section ".printk_index", align 4
@.str.360 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/123\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.361 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.362 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"\01c      |\00", [22 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.363 = internal global ptr @locking_selftest._entry.361, section ".printk_index", align 4
@locking_selftest._entry.364 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.365 = internal global ptr @locking_selftest._entry.364, section ".printk_index", align 4
@.str.366 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/123\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.367 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.368 = internal global ptr @locking_selftest._entry.367, section ".printk_index", align 4
@locking_selftest._entry.369 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.370 = internal global ptr @locking_selftest._entry.369, section ".printk_index", align 4
@.str.371 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/132\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.372 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.373 = internal global ptr @locking_selftest._entry.372, section ".printk_index", align 4
@locking_selftest._entry.374 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.375 = internal global ptr @locking_selftest._entry.374, section ".printk_index", align 4
@.str.376 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/132\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.377 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.378 = internal global ptr @locking_selftest._entry.377, section ".printk_index", align 4
@locking_selftest._entry.379 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.380 = internal global ptr @locking_selftest._entry.379, section ".printk_index", align 4
@.str.381 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/213\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.382 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.383 = internal global ptr @locking_selftest._entry.382, section ".printk_index", align 4
@locking_selftest._entry.384 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.385 = internal global ptr @locking_selftest._entry.384, section ".printk_index", align 4
@.str.386 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/213\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.387 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.388 = internal global ptr @locking_selftest._entry.387, section ".printk_index", align 4
@locking_selftest._entry.389 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.390 = internal global ptr @locking_selftest._entry.389, section ".printk_index", align 4
@.str.391 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/231\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.392 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.393 = internal global ptr @locking_selftest._entry.392, section ".printk_index", align 4
@locking_selftest._entry.394 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.395 = internal global ptr @locking_selftest._entry.394, section ".printk_index", align 4
@.str.396 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/231\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.397 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.398 = internal global ptr @locking_selftest._entry.397, section ".printk_index", align 4
@locking_selftest._entry.399 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.400 = internal global ptr @locking_selftest._entry.399, section ".printk_index", align 4
@.str.401 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/312\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.402 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.403 = internal global ptr @locking_selftest._entry.402, section ".printk_index", align 4
@locking_selftest._entry.404 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.405 = internal global ptr @locking_selftest._entry.404, section ".printk_index", align 4
@.str.406 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/312\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.407 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.408 = internal global ptr @locking_selftest._entry.407, section ".printk_index", align 4
@locking_selftest._entry.409 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.410 = internal global ptr @locking_selftest._entry.409, section ".printk_index", align 4
@.str.411 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hard-irq read-recursion/321\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.412 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.413 = internal global ptr @locking_selftest._entry.412, section ".printk_index", align 4
@locking_selftest._entry.414 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.415 = internal global ptr @locking_selftest._entry.414, section ".printk_index", align 4
@.str.416 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"soft-irq read-recursion/321\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.417 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.418 = internal global ptr @locking_selftest._entry.417, section ".printk_index", align 4
@locking_selftest._entry.419 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2963, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.420 = internal global ptr @locking_selftest._entry.419, section ".printk_index", align 4
@.str.421 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/123\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.422 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.423 = internal global ptr @locking_selftest._entry.422, section ".printk_index", align 4
@locking_selftest._entry.424 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.425 = internal global ptr @locking_selftest._entry.424, section ".printk_index", align 4
@.str.426 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/123\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.427 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.428 = internal global ptr @locking_selftest._entry.427, section ".printk_index", align 4
@locking_selftest._entry.429 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.430 = internal global ptr @locking_selftest._entry.429, section ".printk_index", align 4
@.str.431 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/132\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.432 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.433 = internal global ptr @locking_selftest._entry.432, section ".printk_index", align 4
@locking_selftest._entry.434 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.435 = internal global ptr @locking_selftest._entry.434, section ".printk_index", align 4
@.str.436 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/132\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.437 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.438 = internal global ptr @locking_selftest._entry.437, section ".printk_index", align 4
@locking_selftest._entry.439 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.440 = internal global ptr @locking_selftest._entry.439, section ".printk_index", align 4
@.str.441 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/213\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.442 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.443 = internal global ptr @locking_selftest._entry.442, section ".printk_index", align 4
@locking_selftest._entry.444 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.445 = internal global ptr @locking_selftest._entry.444, section ".printk_index", align 4
@.str.446 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/213\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.447 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.448 = internal global ptr @locking_selftest._entry.447, section ".printk_index", align 4
@locking_selftest._entry.449 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.450 = internal global ptr @locking_selftest._entry.449, section ".printk_index", align 4
@.str.451 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/231\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.452 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.453 = internal global ptr @locking_selftest._entry.452, section ".printk_index", align 4
@locking_selftest._entry.454 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.455 = internal global ptr @locking_selftest._entry.454, section ".printk_index", align 4
@.str.456 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/231\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.457 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.458 = internal global ptr @locking_selftest._entry.457, section ".printk_index", align 4
@locking_selftest._entry.459 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.460 = internal global ptr @locking_selftest._entry.459, section ".printk_index", align 4
@.str.461 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/312\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.462 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.463 = internal global ptr @locking_selftest._entry.462, section ".printk_index", align 4
@locking_selftest._entry.464 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.465 = internal global ptr @locking_selftest._entry.464, section ".printk_index", align 4
@.str.466 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/312\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.467 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.468 = internal global ptr @locking_selftest._entry.467, section ".printk_index", align 4
@locking_selftest._entry.469 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.470 = internal global ptr @locking_selftest._entry.469, section ".printk_index", align 4
@.str.471 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #2/321\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.472 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.473 = internal global ptr @locking_selftest._entry.472, section ".printk_index", align 4
@locking_selftest._entry.474 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.475 = internal global ptr @locking_selftest._entry.474, section ".printk_index", align 4
@.str.476 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #2/321\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.477 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.478 = internal global ptr @locking_selftest._entry.477, section ".printk_index", align 4
@locking_selftest._entry.479 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2964, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.480 = internal global ptr @locking_selftest._entry.479, section ".printk_index", align 4
@.str.481 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/123\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.482 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.483 = internal global ptr @locking_selftest._entry.482, section ".printk_index", align 4
@locking_selftest._entry.484 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.485 = internal global ptr @locking_selftest._entry.484, section ".printk_index", align 4
@.str.486 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/123\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.487 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.488 = internal global ptr @locking_selftest._entry.487, section ".printk_index", align 4
@locking_selftest._entry.489 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.490 = internal global ptr @locking_selftest._entry.489, section ".printk_index", align 4
@.str.491 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/132\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.492 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.493 = internal global ptr @locking_selftest._entry.492, section ".printk_index", align 4
@locking_selftest._entry.494 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.495 = internal global ptr @locking_selftest._entry.494, section ".printk_index", align 4
@.str.496 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/132\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.497 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.498 = internal global ptr @locking_selftest._entry.497, section ".printk_index", align 4
@locking_selftest._entry.499 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.500 = internal global ptr @locking_selftest._entry.499, section ".printk_index", align 4
@.str.501 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/213\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.502 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.503 = internal global ptr @locking_selftest._entry.502, section ".printk_index", align 4
@locking_selftest._entry.504 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.505 = internal global ptr @locking_selftest._entry.504, section ".printk_index", align 4
@.str.506 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/213\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.507 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.508 = internal global ptr @locking_selftest._entry.507, section ".printk_index", align 4
@locking_selftest._entry.509 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.510 = internal global ptr @locking_selftest._entry.509, section ".printk_index", align 4
@.str.511 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/231\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.512 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.513 = internal global ptr @locking_selftest._entry.512, section ".printk_index", align 4
@locking_selftest._entry.514 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.515 = internal global ptr @locking_selftest._entry.514, section ".printk_index", align 4
@.str.516 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/231\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.517 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.518 = internal global ptr @locking_selftest._entry.517, section ".printk_index", align 4
@locking_selftest._entry.519 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.520 = internal global ptr @locking_selftest._entry.519, section ".printk_index", align 4
@.str.521 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/312\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.522 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.523 = internal global ptr @locking_selftest._entry.522, section ".printk_index", align 4
@locking_selftest._entry.524 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.525 = internal global ptr @locking_selftest._entry.524, section ".printk_index", align 4
@.str.526 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/312\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.527 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.528 = internal global ptr @locking_selftest._entry.527, section ".printk_index", align 4
@locking_selftest._entry.529 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.530 = internal global ptr @locking_selftest._entry.529, section ".printk_index", align 4
@.str.531 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"hard-irq read-recursion #3/321\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.532 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.533 = internal global ptr @locking_selftest._entry.532, section ".printk_index", align 4
@locking_selftest._entry.534 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.535 = internal global ptr @locking_selftest._entry.534, section ".printk_index", align 4
@.str.536 = internal constant { [31 x i8], [33 x i8] } { [31 x i8] c"soft-irq read-recursion #3/321\00", [33 x i8] zeroinitializer }, align 32
@locking_selftest._entry.537 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.362, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.538 = internal global ptr @locking_selftest._entry.537, section ".printk_index", align 4
@locking_selftest._entry.539 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2965, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.540 = internal global ptr @locking_selftest._entry.539, section ".printk_index", align 4
@.str.541 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"hardirq_unsafe_softirq_safe\00", [36 x i8] zeroinitializer }, align 32
@locking_selftest._entry.542 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.1, ptr @.str.2, i32 2986, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.543 = internal global ptr @locking_selftest._entry.542, section ".printk_index", align 4
@unexpected_testcase_failures = internal global { i32, [28 x i8] } zeroinitializer, align 32
@locking_selftest._entry.544 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.545, ptr @.str.1, ptr @.str.2, i32 2989, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.545 = internal constant { [67 x i8], [61 x i8] } { [67 x i8] c"-----------------------------------------------------------------\0A\00", [61 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.546 = internal global ptr @locking_selftest._entry.544, section ".printk_index", align 4
@locking_selftest._entry.547 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.548, ptr @.str.1, ptr @.str.2, i32 2992, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.548 = internal constant { [67 x i8], [61 x i8] } { [67 x i8] c"BUG: %3d unexpected failures (out of %3d) - debugging disabled! |\0A\00", [61 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.549 = internal global ptr @locking_selftest._entry.547, section ".printk_index", align 4
@testcase_total = internal global { i32, [28 x i8] } zeroinitializer, align 32
@locking_selftest._entry.550 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.545, ptr @.str.1, ptr @.str.2, i32 2993, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.551 = internal global ptr @locking_selftest._entry.550, section ".printk_index", align 4
@testcase_successes = internal global { i32, [28 x i8] } zeroinitializer, align 32
@locking_selftest._entry.552 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.553, ptr @.str.1, ptr @.str.2, i32 2995, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.553 = internal constant { [58 x i8], [38 x i8] } { [58 x i8] c"--------------------------------------------------------\0A\00", [38 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.554 = internal global ptr @locking_selftest._entry.552, section ".printk_index", align 4
@locking_selftest._entry.555 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.556, ptr @.str.1, ptr @.str.2, i32 2997, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.556 = internal constant { [49 x i8], [47 x i8] } { [49 x i8] c"%3d out of %3d testcases failed, as expected. |\0A\00", [47 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.557 = internal global ptr @locking_selftest._entry.555, section ".printk_index", align 4
@locking_selftest._entry.558 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.559, ptr @.str.1, ptr @.str.2, i32 2998, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.559 = internal constant { [54 x i8], [42 x i8] } { [54 x i8] c"----------------------------------------------------\0A\00", [42 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.560 = internal global ptr @locking_selftest._entry.558, section ".printk_index", align 4
@locking_selftest._entry.561 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.553, ptr @.str.1, ptr @.str.2, i32 3001, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.562 = internal global ptr @locking_selftest._entry.561, section ".printk_index", align 4
@locking_selftest._entry.563 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.564, ptr @.str.1, ptr @.str.2, i32 3003, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.564 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"All %3d testcases failed, as expected. |\0A\00", [54 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.565 = internal global ptr @locking_selftest._entry.563, section ".printk_index", align 4
@locking_selftest._entry.566 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.567, ptr @.str.1, ptr @.str.2, i32 3004, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.567 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"----------------------------------------\0A\00", [54 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.568 = internal global ptr @locking_selftest._entry.566, section ".printk_index", align 4
@locking_selftest._entry.569 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.570, ptr @.str.1, ptr @.str.2, i32 3007, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.570 = internal constant { [57 x i8], [39 x i8] } { [57 x i8] c"-------------------------------------------------------\0A\00", [39 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.571 = internal global ptr @locking_selftest._entry.569, section ".printk_index", align 4
@locking_selftest._entry.572 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.573, ptr @.str.1, ptr @.str.2, i32 3009, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.573 = internal constant { [35 x i8], [61 x i8] } { [35 x i8] c"Good, all %3d testcases passed! |\0A\00", [61 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.574 = internal global ptr @locking_selftest._entry.572, section ".printk_index", align 4
@locking_selftest._entry.575 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.576, ptr @.str.1, ptr @.str.2, i32 3010, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.576 = internal constant { [35 x i8], [61 x i8] } { [35 x i8] c"---------------------------------\0A\00", [61 x i8] zeroinitializer }, align 32
@locking_selftest._entry_ptr.577 = internal global ptr @locking_selftest._entry.575, section ".printk_index", align 4
@debug_locks_silent = external dso_local local_unnamed_addr global i32, section ".data..read_mostly", align 4
@__pcpu_unique_local_A = dso_local local_unnamed_addr global i8 0, section ".discard", align 1
@local_A = weak dso_local global %struct.local_lock_t zeroinitializer, section ".data..percpu", align 4
@debug_locks_verbose = internal global { i32, [28 x i8] } zeroinitializer, align 32
@init_shared_classes.rt_X = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_shared_classes.rt_Y = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_shared_classes.rt_Z = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@rtmutex_X1 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.578, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.579, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@__func__.init_shared_classes = private unnamed_addr constant [20 x i8] c"init_shared_classes\00", align 1
@rtmutex_X2 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.580, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.581, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@rtmutex_Y1 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.582, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.583, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@rtmutex_Y2 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.584, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.585, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@rtmutex_Z1 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.586, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.587, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@rtmutex_Z2 = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.588, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.589, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@lock_X1 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.597, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_X1 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.598, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_X1 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.599, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_X1, i64 52), ptr getelementptr (i8, ptr @mutex_X1, i64 52) }, ptr @mutex_X1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.600, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_X1 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.601, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_X1, i64 56), ptr getelementptr (i8, ptr @rwsem_X1, i64 56) }, ptr @rwsem_X1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.602, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@lock_X2 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.603, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_X2 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.604, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_X2 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.605, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_X2, i64 52), ptr getelementptr (i8, ptr @mutex_X2, i64 52) }, ptr @mutex_X2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.606, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_X2 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.607, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_X2, i64 56), ptr getelementptr (i8, ptr @rwsem_X2, i64 56) }, ptr @rwsem_X2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.608, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@lock_Y1 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.612, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_Y1 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.613, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_Y1 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.614, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_Y1, i64 52), ptr getelementptr (i8, ptr @mutex_Y1, i64 52) }, ptr @mutex_Y1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.615, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_Y1 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.616, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_Y1, i64 56), ptr getelementptr (i8, ptr @rwsem_Y1, i64 56) }, ptr @rwsem_Y1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.617, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@lock_Y2 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.618, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_Y2 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.619, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_Y2 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.620, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_Y2, i64 52), ptr getelementptr (i8, ptr @mutex_Y2, i64 52) }, ptr @mutex_Y2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.621, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_Y2 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.622, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_Y2, i64 56), ptr getelementptr (i8, ptr @rwsem_Y2, i64 56) }, ptr @rwsem_Y2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.623, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@lock_Z1 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.627, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_Z1 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.628, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_Z1 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.629, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_Z1, i64 52), ptr getelementptr (i8, ptr @mutex_Z1, i64 52) }, ptr @mutex_Z1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.630, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_Z1 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.631, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_Z1, i64 56), ptr getelementptr (i8, ptr @rwsem_Z1, i64 56) }, ptr @rwsem_Z1, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.632, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@lock_Z2 = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.633, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_Z2 = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.634, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_Z2 = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.635, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_Z2, i64 52), ptr getelementptr (i8, ptr @mutex_Z2, i64 52) }, ptr @mutex_Z2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.636, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_Z2 = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.637, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_Z2, i64 56), ptr getelementptr (i8, ptr @rwsem_Z2, i64 56) }, ptr @rwsem_Z2, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.638, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@.str.578 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_X1.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.579 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_X1\00", [21 x i8] zeroinitializer }, align 32
@.str.580 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_X2.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.581 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_X2\00", [21 x i8] zeroinitializer }, align 32
@.str.582 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_Y1.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.583 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_Y1\00", [21 x i8] zeroinitializer }, align 32
@.str.584 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_Y2.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.585 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_Y2\00", [21 x i8] zeroinitializer }, align 32
@.str.586 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_Z1.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.587 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_Z1\00", [21 x i8] zeroinitializer }, align 32
@.str.588 = internal constant { [29 x i8], [35 x i8] } { [29 x i8] c"rtmutex_Z2.rtmutex.wait_lock\00", [35 x i8] zeroinitializer }, align 32
@.str.589 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"rtmutex_Z2\00", [21 x i8] zeroinitializer }, align 32
@init_class_X.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.590 = internal constant { [5 x i8], [27 x i8] } { [5 x i8] c"lock\00", [27 x i8] zeroinitializer }, align 32
@init_class_X.__key.591 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.592 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"rwlock\00", [25 x i8] zeroinitializer }, align 32
@init_class_X.__key.593 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.594 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"mutex\00", [26 x i8] zeroinitializer }, align 32
@init_class_X.__key.595 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.596 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"rwsem\00", [26 x i8] zeroinitializer }, align 32
@.str.597 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_X1\00", [24 x i8] zeroinitializer }, align 32
@.str.598 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_X1\00", [22 x i8] zeroinitializer }, align 32
@.str.599 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_X1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.600 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_X1\00", [23 x i8] zeroinitializer }, align 32
@.str.601 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_X1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.602 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_X1\00", [23 x i8] zeroinitializer }, align 32
@.str.603 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_X2\00", [24 x i8] zeroinitializer }, align 32
@.str.604 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_X2\00", [22 x i8] zeroinitializer }, align 32
@.str.605 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_X2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.606 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_X2\00", [23 x i8] zeroinitializer }, align 32
@.str.607 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_X2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.608 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_X2\00", [23 x i8] zeroinitializer }, align 32
@init_class_Y.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Y.__key.609 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Y.__key.610 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Y.__key.611 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.612 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_Y1\00", [24 x i8] zeroinitializer }, align 32
@.str.613 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_Y1\00", [22 x i8] zeroinitializer }, align 32
@.str.614 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_Y1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.615 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_Y1\00", [23 x i8] zeroinitializer }, align 32
@.str.616 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_Y1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.617 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_Y1\00", [23 x i8] zeroinitializer }, align 32
@.str.618 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_Y2\00", [24 x i8] zeroinitializer }, align 32
@.str.619 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_Y2\00", [22 x i8] zeroinitializer }, align 32
@.str.620 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_Y2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.621 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_Y2\00", [23 x i8] zeroinitializer }, align 32
@.str.622 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_Y2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.623 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_Y2\00", [23 x i8] zeroinitializer }, align 32
@init_class_Z.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Z.__key.624 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Z.__key.625 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_class_Z.__key.626 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.627 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_Z1\00", [24 x i8] zeroinitializer }, align 32
@.str.628 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_Z1\00", [22 x i8] zeroinitializer }, align 32
@.str.629 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_Z1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.630 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_Z1\00", [23 x i8] zeroinitializer }, align 32
@.str.631 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_Z1.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.632 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_Z1\00", [23 x i8] zeroinitializer }, align 32
@.str.633 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"lock_Z2\00", [24 x i8] zeroinitializer }, align 32
@.str.634 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rwlock_Z2\00", [22 x i8] zeroinitializer }, align 32
@.str.635 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"mutex_Z2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.636 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"mutex_Z2\00", [23 x i8] zeroinitializer }, align 32
@.str.637 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"rwsem_Z2.wait_lock\00", [45 x i8] zeroinitializer }, align 32
@.str.638 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwsem_Z2\00", [23 x i8] zeroinitializer }, align 32
@print_testname._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.639, ptr @.str.640, ptr @.str.2, i32 1502, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.639 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"%33s:\00", [26 x i8] zeroinitializer }, align 32
@.str.640 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"print_testname\00", [17 x i8] zeroinitializer }, align 32
@print_testname._entry_ptr = internal global ptr @print_testname._entry, section ".printk_index", align 4
@dotest._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.641, ptr @.str.642, ptr @.str.2, i32 1457, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.641 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"\01cFAILED|\00", [22 x i8] zeroinitializer }, align 32
@.str.642 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"dotest\00", [25 x i8] zeroinitializer }, align 32
@dotest._entry_ptr = internal global ptr @dotest._entry, section ".printk_index", align 4
@dotest._entry.643 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.644, ptr @.str.642, ptr @.str.2, i32 1460, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.644 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"\01c  ok  |\00", [22 x i8] zeroinitializer }, align 32
@dotest._entry_ptr.645 = internal global ptr @dotest._entry.643, section ".printk_index", align 4
@dotest._entry.646 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.647, ptr @.str.642, ptr @.str.2, i32 1466, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.647 = internal constant { [54 x i8], [42 x i8] } { [54 x i8] c"\01c lockclass mask: %x, debug_locks: %d, expected: %d\0A\00", [42 x i8] zeroinitializer }, align 32
@dotest._entry_ptr.648 = internal global ptr @dotest._entry.646, section ".printk_index", align 4
@ww_lockdep = internal global { %struct.ww_class, [32 x i8] } { %struct.ww_class { %struct.atomic_t zeroinitializer, %struct.lock_class_key zeroinitializer, %struct.lock_class_key zeroinitializer, ptr @.str.690, ptr @.str.691, i32 1 }, [32 x i8] zeroinitializer }, align 32
@lock_A = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.692, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_A = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.693, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_A = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.694, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_A, i64 52), ptr getelementptr (i8, ptr @mutex_A, i64 52) }, ptr @mutex_A, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.695, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_A = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.696, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_A, i64 56), ptr getelementptr (i8, ptr @rwsem_A, i64 56) }, ptr @rwsem_A, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.697, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@rtmutex_A = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.698, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.699, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@lock_B = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.700, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_B = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.701, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_B = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.702, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_B, i64 52), ptr getelementptr (i8, ptr @mutex_B, i64 52) }, ptr @mutex_B, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.703, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_B = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.704, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_B, i64 56), ptr getelementptr (i8, ptr @rwsem_B, i64 56) }, ptr @rwsem_B, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.705, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@rtmutex_B = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.706, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.707, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@lock_C = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.708, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_C = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.709, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_C = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.710, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_C, i64 52), ptr getelementptr (i8, ptr @mutex_C, i64 52) }, ptr @mutex_C, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.711, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_C = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.712, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_C, i64 56), ptr getelementptr (i8, ptr @rwsem_C, i64 56) }, ptr @rwsem_C, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.713, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@rtmutex_C = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.714, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.715, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@lock_D = internal global { %struct.spinlock, [52 x i8] } { %struct.spinlock { %union.anon.9 { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.716, i8 0, i8 3, i8 0, i32 0, i32 0 } } } }, [52 x i8] zeroinitializer }, align 32
@rwlock_D = internal global { %struct.rwlock_t, [52 x i8] } { %struct.rwlock_t { %struct.arch_rwlock_t zeroinitializer, i32 -558948627, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.717, i8 0, i8 3, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@mutex_D = internal global { %struct.mutex, [36 x i8] } { %struct.mutex { %struct.atomic_t zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.718, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.optimistic_spin_queue zeroinitializer, %struct.list_head { ptr getelementptr (i8, ptr @mutex_D, i64 52), ptr getelementptr (i8, ptr @mutex_D, i64 52) }, ptr @mutex_D, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.719, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [36 x i8] zeroinitializer }, align 32
@rwsem_D = internal global { %struct.rw_semaphore, [32 x i8] } { %struct.rw_semaphore { %struct.atomic_t zeroinitializer, %struct.atomic_t zeroinitializer, %struct.optimistic_spin_queue zeroinitializer, %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.720, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.list_head { ptr getelementptr (i8, ptr @rwsem_D, i64 56), ptr getelementptr (i8, ptr @rwsem_D, i64 56) }, ptr @rwsem_D, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.721, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [32 x i8] zeroinitializer }, align 32
@rtmutex_D = internal global { %struct.rt_mutex, [44 x i8] } { %struct.rt_mutex { %struct.rt_mutex_base { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.722, i8 0, i8 2, i8 0, i32 0, i32 0 } }, %struct.rb_root_cached zeroinitializer, ptr null }, %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.723, i8 0, i8 4, i8 0, i32 0, i32 0 } }, [44 x i8] zeroinitializer }, align 32
@t = internal global { %struct.ww_acquire_ctx, [32 x i8] } zeroinitializer, align 32
@t2 = internal global { %struct.ww_acquire_ctx, [32 x i8] } zeroinitializer, align 32
@o = internal global { %struct.ww_mutex, [60 x i8] } zeroinitializer, align 32
@o2 = internal global { %struct.ww_mutex, [60 x i8] } zeroinitializer, align 32
@o3 = internal global { %struct.ww_mutex, [60 x i8] } zeroinitializer, align 32
@raw_lock_A = internal global { %struct.raw_spinlock, [52 x i8] } { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.724, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@raw_lock_B = internal global { %struct.raw_spinlock, [52 x i8] } { %struct.raw_spinlock { %struct.arch_spinlock_t zeroinitializer, i32 -559067475, i32 -1, ptr inttoptr (i32 -1 to ptr), %struct.lockdep_map { ptr null, [2 x ptr] zeroinitializer, ptr @.str.725, i8 0, i8 2, i8 0, i32 0, i32 0 } }, [52 x i8] zeroinitializer }, align 32
@__per_cpu_offset = external dso_local local_unnamed_addr global [4 x i32], align 4
@reset_locks.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.649 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"&lock_A\00", [24 x i8] zeroinitializer }, align 32
@reset_locks.__key.650 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.651 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"&rwlock_A\00", [22 x i8] zeroinitializer }, align 32
@reset_locks.__key.652 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.653 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&mutex_A\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.654 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.655 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&rwsem_A\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.656 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@__func__.reset_locks = private unnamed_addr constant [12 x i8] c"reset_locks\00", align 1
@reset_locks.__key.657 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.658 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"&lock_B\00", [24 x i8] zeroinitializer }, align 32
@reset_locks.__key.659 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.660 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"&rwlock_B\00", [22 x i8] zeroinitializer }, align 32
@reset_locks.__key.661 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.662 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&mutex_B\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.663 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.664 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&rwsem_B\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.665 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@reset_locks.__key.666 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.667 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"&lock_C\00", [24 x i8] zeroinitializer }, align 32
@reset_locks.__key.668 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.669 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"&rwlock_C\00", [22 x i8] zeroinitializer }, align 32
@reset_locks.__key.670 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.671 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&mutex_C\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.672 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.673 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&rwsem_C\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.674 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@reset_locks.__key.675 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.676 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"&lock_D\00", [24 x i8] zeroinitializer }, align 32
@reset_locks.__key.677 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.678 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"&rwlock_D\00", [22 x i8] zeroinitializer }, align 32
@reset_locks.__key.679 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.680 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&mutex_D\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.681 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.682 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"&rwsem_D\00", [23 x i8] zeroinitializer }, align 32
@reset_locks.__key.683 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@reset_locks.__key.684 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.685 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"&raw_lock_A\00", [20 x i8] zeroinitializer }, align 32
@reset_locks.__key.686 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.687 = internal constant { [12 x i8], [20 x i8] } { [12 x i8] c"&raw_lock_B\00", [20 x i8] zeroinitializer }, align 32
@reset_locks.__key.688 = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@.str.689 = internal constant { [305 x i8], [79 x i8] } { [305 x i8] c"({ do { const void *__vpp_verify = (typeof((&local_A) + 0))((void *)0); (void)__vpp_verify; } while (0); ({ unsigned long __ptr; __ptr = (unsigned long) ((typeof(*(&local_A)) *)(&local_A)); (typeof((typeof(*(&local_A)) *)(&local_A))) (__ptr + (((__per_cpu_offset[(current_thread_info()->cpu)])))); }); })\00", [79 x i8] zeroinitializer }, align 32
@.str.690 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"ww_lockdep_acquire\00", [45 x i8] zeroinitializer }, align 32
@.str.691 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"ww_lockdep_mutex\00", [47 x i8] zeroinitializer }, align 32
@.str.692 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"lock_A\00", [25 x i8] zeroinitializer }, align 32
@.str.693 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwlock_A\00", [23 x i8] zeroinitializer }, align 32
@.str.694 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"mutex_A.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.695 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"mutex_A\00", [24 x i8] zeroinitializer }, align 32
@.str.696 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"rwsem_A.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.697 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"rwsem_A\00", [24 x i8] zeroinitializer }, align 32
@.str.698 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"rtmutex_A.rtmutex.wait_lock\00", [36 x i8] zeroinitializer }, align 32
@.str.699 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rtmutex_A\00", [22 x i8] zeroinitializer }, align 32
@.str.700 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"lock_B\00", [25 x i8] zeroinitializer }, align 32
@.str.701 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwlock_B\00", [23 x i8] zeroinitializer }, align 32
@.str.702 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"mutex_B.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.703 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"mutex_B\00", [24 x i8] zeroinitializer }, align 32
@.str.704 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"rwsem_B.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.705 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"rwsem_B\00", [24 x i8] zeroinitializer }, align 32
@.str.706 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"rtmutex_B.rtmutex.wait_lock\00", [36 x i8] zeroinitializer }, align 32
@.str.707 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rtmutex_B\00", [22 x i8] zeroinitializer }, align 32
@.str.708 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"lock_C\00", [25 x i8] zeroinitializer }, align 32
@.str.709 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwlock_C\00", [23 x i8] zeroinitializer }, align 32
@.str.710 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"mutex_C.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.711 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"mutex_C\00", [24 x i8] zeroinitializer }, align 32
@.str.712 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"rwsem_C.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.713 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"rwsem_C\00", [24 x i8] zeroinitializer }, align 32
@.str.714 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"rtmutex_C.rtmutex.wait_lock\00", [36 x i8] zeroinitializer }, align 32
@.str.715 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rtmutex_C\00", [22 x i8] zeroinitializer }, align 32
@.str.716 = internal constant { [7 x i8], [25 x i8] } { [7 x i8] c"lock_D\00", [25 x i8] zeroinitializer }, align 32
@.str.717 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"rwlock_D\00", [23 x i8] zeroinitializer }, align 32
@.str.718 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"mutex_D.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.719 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"mutex_D\00", [24 x i8] zeroinitializer }, align 32
@.str.720 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"rwsem_D.wait_lock\00", [46 x i8] zeroinitializer }, align 32
@.str.721 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"rwsem_D\00", [24 x i8] zeroinitializer }, align 32
@.str.722 = internal constant { [28 x i8], [36 x i8] } { [28 x i8] c"rtmutex_D.rtmutex.wait_lock\00", [36 x i8] zeroinitializer }, align 32
@.str.723 = internal constant { [10 x i8], [22 x i8] } { [10 x i8] c"rtmutex_D\00", [22 x i8] zeroinitializer }, align 32
@.str.724 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"raw_lock_A\00", [21 x i8] zeroinitializer }, align 32
@.str.725 = internal constant { [11 x i8], [21 x i8] } { [11 x i8] c"raw_lock_B\00", [21 x i8] zeroinitializer }, align 32
@init_held_spin.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_wlock.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_rlock.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_mutex.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_wsem.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_rsem.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@init_held_rtmutex.__key = internal global { %struct.lock_class_key, [24 x i8] } zeroinitializer, align 32
@__func__.init_held_rtmutex = private unnamed_addr constant [18 x i8] c"init_held_rtmutex\00", align 1
@hardirq_context = external dso_local global i32, section ".data..percpu", align 4
@ww_tests._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.728, ptr @.str.2, i32 2285, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.728 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"ww_tests\00", [23 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr = internal global ptr @ww_tests._entry, section ".printk_index", align 4
@ww_tests._entry.729 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.730, ptr @.str.728, ptr @.str.2, i32 2286, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.730 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"  | Wound/wait tests |\0A\00", [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.731 = internal global ptr @ww_tests._entry.729, section ".printk_index", align 4
@ww_tests._entry.732 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.733, ptr @.str.728, ptr @.str.2, i32 2287, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.733 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"  ---------------------\0A\00", [39 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.734 = internal global ptr @ww_tests._entry.732, section ".printk_index", align 4
@.str.735 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"ww api failures\00", [16 x i8] zeroinitializer }, align 32
@ww_tests._entry.736 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2293, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.737 = internal global ptr @ww_tests._entry.736, section ".printk_index", align 4
@.str.738 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"ww contexts mixing\00", [45 x i8] zeroinitializer }, align 32
@ww_tests._entry.739 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2298, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.740 = internal global ptr @ww_tests._entry.739, section ".printk_index", align 4
@.str.741 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"finishing ww context\00", [43 x i8] zeroinitializer }, align 32
@ww_tests._entry.742 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2305, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.743 = internal global ptr @ww_tests._entry.742, section ".printk_index", align 4
@.str.744 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"locking mismatches\00", [45 x i8] zeroinitializer }, align 32
@ww_tests._entry.745 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2311, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.746 = internal global ptr @ww_tests._entry.745, section ".printk_index", align 4
@.str.747 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"EDEADLK handling\00", [47 x i8] zeroinitializer }, align 32
@ww_tests._entry.748 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2324, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.749 = internal global ptr @ww_tests._entry.748, section ".printk_index", align 4
@.str.750 = internal constant { [23 x i8], [41 x i8] } { [23 x i8] c"spinlock nest unlocked\00", [41 x i8] zeroinitializer }, align 32
@ww_tests._entry.751 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2328, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.752 = internal global ptr @ww_tests._entry.751, section ".printk_index", align 4
@.str.753 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"spinlock nest test\00", [45 x i8] zeroinitializer }, align 32
@ww_tests._entry.754 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2332, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.755 = internal global ptr @ww_tests._entry.754, section ".printk_index", align 4
@ww_tests._entry.756 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.757, ptr @.str.728, ptr @.str.2, i32 2334, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.757 = internal constant { [57 x i8], [39 x i8] } { [57 x i8] c"  -----------------------------------------------------\0A\00", [39 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.758 = internal global ptr @ww_tests._entry.756, section ".printk_index", align 4
@ww_tests._entry.759 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.760, ptr @.str.728, ptr @.str.2, i32 2335, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.760 = internal constant { [58 x i8], [38 x i8] } { [58 x i8] c"                                 |block | try  |context|\0A\00", [38 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.761 = internal global ptr @ww_tests._entry.759, section ".printk_index", align 4
@ww_tests._entry.762 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.757, ptr @.str.728, ptr @.str.2, i32 2336, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.763 = internal global ptr @ww_tests._entry.762, section ".printk_index", align 4
@.str.764 = internal constant { [8 x i8], [24 x i8] } { [8 x i8] c"context\00", [24 x i8] zeroinitializer }, align 32
@ww_tests._entry.765 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2342, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.766 = internal global ptr @ww_tests._entry.765, section ".printk_index", align 4
@.str.767 = internal constant { [4 x i8], [28 x i8] } { [4 x i8] c"try\00", [28 x i8] zeroinitializer }, align 32
@ww_tests._entry.768 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2348, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.769 = internal global ptr @ww_tests._entry.768, section ".printk_index", align 4
@.str.770 = internal constant { [6 x i8], [26 x i8] } { [6 x i8] c"block\00", [26 x i8] zeroinitializer }, align 32
@ww_tests._entry.771 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2354, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.772 = internal global ptr @ww_tests._entry.771, section ".printk_index", align 4
@.str.773 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"spinlock\00", [23 x i8] zeroinitializer }, align 32
@ww_tests._entry.774 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.728, ptr @.str.2, i32 2360, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@ww_tests._entry_ptr.775 = internal global ptr @ww_tests._entry.774, section ".printk_index", align 4
@oops_in_progress = external dso_local local_unnamed_addr global i32, align 4
@.str.776 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"DEBUG_LOCKS_WARN_ON(%s)\00", [40 x i8] zeroinitializer }, align 32
@.str.777 = internal constant { [2 x i8], [30 x i8] } { [2 x i8] c"1\00", [30 x i8] zeroinitializer }, align 32
@.str.778 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"include/linux/ww_mutex.h\00", [39 x i8] zeroinitializer }, align 32
@.str.779 = internal constant { [22 x i8], [42 x i8] } { [22 x i8] c"!ctx->contending_lock\00", [42 x i8] zeroinitializer }, align 32
@.str.780 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"ctx->done_acquire\00", [46 x i8] zeroinitializer }, align 32
@.str.781 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"ctx->acquired\00", [18 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.782, ptr @.str.783, ptr @.str.2, i32 2492, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.782 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"  --------------------\0A\00", [40 x i8] zeroinitializer }, align 32
@.str.783 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"fs_reclaim_tests\00", [47 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr = internal global ptr @fs_reclaim_tests._entry, section ".printk_index", align 4
@fs_reclaim_tests._entry.784 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.785, ptr @.str.783, ptr @.str.2, i32 2493, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.785 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"  | fs_reclaim tests |\0A\00", [40 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr.786 = internal global ptr @fs_reclaim_tests._entry.784, section ".printk_index", align 4
@fs_reclaim_tests._entry.787 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.782, ptr @.str.783, ptr @.str.2, i32 2494, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr.788 = internal global ptr @fs_reclaim_tests._entry.787, section ".printk_index", align 4
@.str.789 = internal constant { [16 x i8], [16 x i8] } { [16 x i8] c"correct nesting\00", [16 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry.790 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.783, ptr @.str.2, i32 2498, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr.791 = internal global ptr @fs_reclaim_tests._entry.790, section ".printk_index", align 4
@.str.792 = internal constant { [14 x i8], [18 x i8] } { [14 x i8] c"wrong nesting\00", [18 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry.793 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.783, ptr @.str.2, i32 2502, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr.794 = internal global ptr @fs_reclaim_tests._entry.793, section ".printk_index", align 4
@.str.795 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"protected nesting\00", [46 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry.796 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.783, ptr @.str.2, i32 2506, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@fs_reclaim_tests._entry_ptr.797 = internal global ptr @fs_reclaim_tests._entry.796, section ".printk_index", align 4
@.str.798 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"include/linux/sched/mm.h\00", [39 x i8] zeroinitializer }, align 32
@wait_context_tests._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.799, ptr @.str.2, i32 2670, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.799 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"wait_context_tests\00", [45 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr = internal global ptr @wait_context_tests._entry, section ".printk_index", align 4
@wait_context_tests._entry.800 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.801, ptr @.str.799, ptr @.str.2, i32 2671, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.801 = internal constant { [26 x i8], [38 x i8] } { [26 x i8] c"  | wait context tests |\0A\00", [38 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.802 = internal global ptr @wait_context_tests._entry.800, section ".printk_index", align 4
@wait_context_tests._entry.803 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.799, ptr @.str.2, i32 2672, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.804 = internal global ptr @wait_context_tests._entry.803, section ".printk_index", align 4
@wait_context_tests._entry.805 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.806, ptr @.str.799, ptr @.str.2, i32 2673, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.806 = internal constant { [64 x i8], [32 x i8] } { [64 x i8] c"                                 | rcu  | raw  | spin |mutex |\0A\00", [32 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.807 = internal global ptr @wait_context_tests._entry.805, section ".printk_index", align 4
@wait_context_tests._entry.808 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.799, ptr @.str.2, i32 2674, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.809 = internal global ptr @wait_context_tests._entry.808, section ".printk_index", align 4
@.str.810 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"in hardirq context\00", [45 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.811 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2677, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.812 = internal global ptr @wait_context_tests._entry.811, section ".printk_index", align 4
@.str.813 = internal constant { [34 x i8], [62 x i8] } { [34 x i8] c"in hardirq context (not threaded)\00", [62 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.814 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2681, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.815 = internal global ptr @wait_context_tests._entry.814, section ".printk_index", align 4
@.str.816 = internal constant { [19 x i8], [45 x i8] } { [19 x i8] c"in softirq context\00", [45 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.817 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2685, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.818 = internal global ptr @wait_context_tests._entry.817, section ".printk_index", align 4
@.str.819 = internal constant { [15 x i8], [17 x i8] } { [15 x i8] c"in RCU context\00", [17 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.820 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2689, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.821 = internal global ptr @wait_context_tests._entry.820, section ".printk_index", align 4
@.str.822 = internal constant { [18 x i8], [46 x i8] } { [18 x i8] c"in RCU-bh context\00", [46 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.823 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2693, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.824 = internal global ptr @wait_context_tests._entry.823, section ".printk_index", align 4
@.str.825 = internal constant { [21 x i8], [43 x i8] } { [21 x i8] c"in RCU-sched context\00", [43 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.826 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2697, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.827 = internal global ptr @wait_context_tests._entry.826, section ".printk_index", align 4
@.str.828 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"in RAW_SPINLOCK context\00", [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.829 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2701, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.830 = internal global ptr @wait_context_tests._entry.829, section ".printk_index", align 4
@.str.831 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"in SPINLOCK context\00", [44 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.832 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2705, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.833 = internal global ptr @wait_context_tests._entry.832, section ".printk_index", align 4
@.str.834 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"in MUTEX context\00", [47 x i8] zeroinitializer }, align 32
@wait_context_tests._entry.835 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.799, ptr @.str.2, i32 2709, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@wait_context_tests._entry_ptr.836 = internal global ptr @wait_context_tests._entry.835, section ".printk_index", align 4
@rcu_read_unlock.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.837 = internal constant { [25 x i8], [39 x i8] } { [25 x i8] c"include/linux/rcupdate.h\00", [39 x i8] zeroinitializer }, align 32
@.str.838 = internal constant { [44 x i8], [52 x i8] } { [44 x i8] c"rcu_read_unlock() used illegally while idle\00", [52 x i8] zeroinitializer }, align 32
@rcu_lock_map = external dso_local global %struct.lockdep_map, align 4
@rcu_read_lock.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.839 = internal constant { [42 x i8], [54 x i8] } { [42 x i8] c"rcu_read_lock() used illegally while idle\00", [54 x i8] zeroinitializer }, align 32
@rcu_read_unlock_bh.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.840 = internal constant { [47 x i8], [49 x i8] } { [47 x i8] c"rcu_read_unlock_bh() used illegally while idle\00", [49 x i8] zeroinitializer }, align 32
@rcu_bh_lock_map = external dso_local global %struct.lockdep_map, align 4
@rcu_read_lock_bh.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.841 = internal constant { [45 x i8], [51 x i8] } { [45 x i8] c"rcu_read_lock_bh() used illegally while idle\00", [51 x i8] zeroinitializer }, align 32
@rcu_read_unlock_sched.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.842 = internal constant { [50 x i8], [46 x i8] } { [50 x i8] c"rcu_read_unlock_sched() used illegally while idle\00", [46 x i8] zeroinitializer }, align 32
@rcu_sched_lock_map = external dso_local global %struct.lockdep_map, align 4
@rcu_read_lock_sched.__warned = internal unnamed_addr global i1 false, section ".data.unlikely", align 1
@.str.843 = internal constant { [48 x i8], [48 x i8] } { [48 x i8] c"rcu_read_lock_sched() used illegally while idle\00", [48 x i8] zeroinitializer }, align 32
@local_lock_tests._entry = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.21, ptr @.str.844, ptr @.str.2, i32 2780, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.844 = internal constant { [17 x i8], [47 x i8] } { [17 x i8] c"local_lock_tests\00", [47 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr = internal global ptr @local_lock_tests._entry, section ".printk_index", align 4
@local_lock_tests._entry.845 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.846, ptr @.str.844, ptr @.str.2, i32 2781, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@.str.846 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"  | local_lock tests |\0A\00", [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr.847 = internal global ptr @local_lock_tests._entry.845, section ".printk_index", align 4
@local_lock_tests._entry.848 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.733, ptr @.str.844, ptr @.str.2, i32 2782, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr.849 = internal global ptr @local_lock_tests._entry.848, section ".printk_index", align 4
@.str.850 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"local_lock inversion  2\00", [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry.851 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.844, ptr @.str.2, i32 2786, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr.852 = internal global ptr @local_lock_tests._entry.851, section ".printk_index", align 4
@.str.853 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"local_lock inversion 3A\00", [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry.854 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.844, ptr @.str.2, i32 2790, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr.855 = internal global ptr @local_lock_tests._entry.854, section ".printk_index", align 4
@.str.856 = internal constant { [24 x i8], [40 x i8] } { [24 x i8] c"local_lock inversion 3B\00", [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry.857 = internal constant { %struct.pi_entry, [40 x i8] } { %struct.pi_entry { ptr @.str.25, ptr @.str.844, ptr @.str.2, i32 2794, ptr null, ptr null }, [40 x i8] zeroinitializer }, align 32
@local_lock_tests._entry_ptr.858 = internal global ptr @local_lock_tests._entry.857, section ".printk_index", align 4
@.str.859 = internal constant { [36 x i8], [60 x i8] } { [36 x i8] c"include/linux/local_lock_internal.h\00", [60 x i8] zeroinitializer }, align 32
@.str.860 = internal constant { [9 x i8], [23 x i8] } { [9 x i8] c"l->owner\00", [23 x i8] zeroinitializer }, align 32
@.str.861 = internal constant { [20 x i8], [44 x i8] } { [20 x i8] c"l->owner != current\00", [44 x i8] zeroinitializer }, align 32
@___asan_gen_.873 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2863, i32 3 }
@___asan_gen_.879 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2864, i32 3 }
@___asan_gen_.882 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2865, i32 3 }
@___asan_gen_.883 = private unnamed_addr constant [26 x i8] c"force_read_lock_recursive\00", align 1
@___asan_gen_.885 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 39, i32 14 }
@___asan_gen_.891 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2877, i32 2 }
@___asan_gen_.897 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2878, i32 2 }
@___asan_gen_.903 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2879, i32 2 }
@___asan_gen_.909 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2880, i32 2 }
@___asan_gen_.915 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2881, i32 2 }
@___asan_gen_.924 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2886, i32 2 }
@___asan_gen_.930 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2887, i32 2 }
@___asan_gen_.936 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2888, i32 2 }
@___asan_gen_.942 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2889, i32 2 }
@___asan_gen_.948 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2890, i32 2 }
@___asan_gen_.954 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2891, i32 2 }
@___asan_gen_.960 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2892, i32 2 }
@___asan_gen_.966 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2893, i32 2 }
@___asan_gen_.972 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2894, i32 2 }
@___asan_gen_.975 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2896, i32 2 }
@___asan_gen_.978 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2897, i32 17 }
@___asan_gen_.984 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2898, i32 2 }
@___asan_gen_.987 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2900, i32 2 }
@___asan_gen_.990 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2902, i32 2 }
@___asan_gen_.993 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2904, i32 17 }
@___asan_gen_.996 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2905, i32 2 }
@___asan_gen_.999 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2907, i32 2 }
@___asan_gen_.1002 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2909, i32 2 }
@___asan_gen_.1005 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2911, i32 17 }
@___asan_gen_.1008 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2912, i32 2 }
@___asan_gen_.1011 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2914, i32 2 }
@___asan_gen_.1014 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2916, i32 2 }
@___asan_gen_.1017 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2918, i32 17 }
@___asan_gen_.1020 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2919, i32 2 }
@___asan_gen_.1023 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2921, i32 2 }
@___asan_gen_.1026 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2923, i32 2 }
@___asan_gen_.1029 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2925, i32 17 }
@___asan_gen_.1032 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2926, i32 2 }
@___asan_gen_.1035 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2928, i32 2 }
@___asan_gen_.1038 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2931, i32 17 }
@___asan_gen_.1041 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2932, i32 2 }
@___asan_gen_.1044 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2934, i32 2 }
@___asan_gen_.1047 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2937, i32 17 }
@___asan_gen_.1050 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2938, i32 2 }
@___asan_gen_.1053 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2940, i32 2 }
@___asan_gen_.1056 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2943, i32 17 }
@___asan_gen_.1059 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2944, i32 2 }
@___asan_gen_.1113 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2947, i32 2 }
@___asan_gen_.1167 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2948, i32 2 }
@___asan_gen_.1221 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2949, i32 2 }
@___asan_gen_.1275 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2950, i32 2 }
@___asan_gen_.1278 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2952, i32 2 }
@___asan_gen_.1302 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2956, i32 2 }
@___asan_gen_.1314 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2957, i32 2 }
@___asan_gen_.1338 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2958, i32 2 }
@___asan_gen_.1410 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2959, i32 2 }
@___asan_gen_.1482 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2960, i32 2 }
@___asan_gen_.1554 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2961, i32 2 }
@___asan_gen_.1665 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2963, i32 2 }
@___asan_gen_.1773 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2964, i32 2 }
@___asan_gen_.1881 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2965, i32 2 }
@___asan_gen_.1884 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2984, i32 17 }
@___asan_gen_.1887 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2986, i32 2 }
@___asan_gen_.1888 = private unnamed_addr constant [29 x i8] c"unexpected_testcase_failures\00", align 1
@___asan_gen_.1890 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1428, i32 12 }
@___asan_gen_.1896 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2989, i32 3 }
@___asan_gen_.1902 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2991, i32 3 }
@___asan_gen_.1903 = private unnamed_addr constant [15 x i8] c"testcase_total\00", align 1
@___asan_gen_.1905 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1425, i32 12 }
@___asan_gen_.1908 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2993, i32 3 }
@___asan_gen_.1909 = private unnamed_addr constant [19 x i8] c"testcase_successes\00", align 1
@___asan_gen_.1911 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1426, i32 12 }
@___asan_gen_.1917 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2995, i32 3 }
@___asan_gen_.1923 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2996, i32 3 }
@___asan_gen_.1929 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2998, i32 3 }
@___asan_gen_.1932 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3001, i32 3 }
@___asan_gen_.1938 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3002, i32 3 }
@___asan_gen_.1944 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3004, i32 3 }
@___asan_gen_.1950 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3007, i32 3 }
@___asan_gen_.1956 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3008, i32 3 }
@___asan_gen_.1962 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 3010, i32 3 }
@___asan_gen_.1963 = private unnamed_addr constant [20 x i8] c"debug_locks_verbose\00", align 1
@___asan_gen_.1965 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 38, i32 21 }
@___asan_gen_.1966 = private unnamed_addr constant [5 x i8] c"rt_X\00", align 1
@___asan_gen_.1968 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 172, i32 31 }
@___asan_gen_.1969 = private unnamed_addr constant [5 x i8] c"rt_Y\00", align 1
@___asan_gen_.1971 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 172, i32 37 }
@___asan_gen_.1972 = private unnamed_addr constant [5 x i8] c"rt_Z\00", align 1
@___asan_gen_.1974 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 172, i32 43 }
@___asan_gen_.1975 = private unnamed_addr constant [11 x i8] c"rtmutex_X1\00", align 1
@___asan_gen_.1978 = private unnamed_addr constant [11 x i8] c"rtmutex_X2\00", align 1
@___asan_gen_.1981 = private unnamed_addr constant [11 x i8] c"rtmutex_Y1\00", align 1
@___asan_gen_.1984 = private unnamed_addr constant [11 x i8] c"rtmutex_Y2\00", align 1
@___asan_gen_.1987 = private unnamed_addr constant [11 x i8] c"rtmutex_Z1\00", align 1
@___asan_gen_.1990 = private unnamed_addr constant [11 x i8] c"rtmutex_Z2\00", align 1
@___asan_gen_.1993 = private unnamed_addr constant [8 x i8] c"lock_X1\00", align 1
@___asan_gen_.1996 = private unnamed_addr constant [10 x i8] c"rwlock_X1\00", align 1
@___asan_gen_.1999 = private unnamed_addr constant [9 x i8] c"mutex_X1\00", align 1
@___asan_gen_.2002 = private unnamed_addr constant [9 x i8] c"rwsem_X1\00", align 1
@___asan_gen_.2005 = private unnamed_addr constant [8 x i8] c"lock_X2\00", align 1
@___asan_gen_.2008 = private unnamed_addr constant [10 x i8] c"rwlock_X2\00", align 1
@___asan_gen_.2011 = private unnamed_addr constant [9 x i8] c"mutex_X2\00", align 1
@___asan_gen_.2014 = private unnamed_addr constant [9 x i8] c"rwsem_X2\00", align 1
@___asan_gen_.2017 = private unnamed_addr constant [8 x i8] c"lock_Y1\00", align 1
@___asan_gen_.2020 = private unnamed_addr constant [10 x i8] c"rwlock_Y1\00", align 1
@___asan_gen_.2023 = private unnamed_addr constant [9 x i8] c"mutex_Y1\00", align 1
@___asan_gen_.2026 = private unnamed_addr constant [9 x i8] c"rwsem_Y1\00", align 1
@___asan_gen_.2029 = private unnamed_addr constant [8 x i8] c"lock_Y2\00", align 1
@___asan_gen_.2032 = private unnamed_addr constant [10 x i8] c"rwlock_Y2\00", align 1
@___asan_gen_.2035 = private unnamed_addr constant [9 x i8] c"mutex_Y2\00", align 1
@___asan_gen_.2038 = private unnamed_addr constant [9 x i8] c"rwsem_Y2\00", align 1
@___asan_gen_.2041 = private unnamed_addr constant [8 x i8] c"lock_Z1\00", align 1
@___asan_gen_.2044 = private unnamed_addr constant [10 x i8] c"rwlock_Z1\00", align 1
@___asan_gen_.2047 = private unnamed_addr constant [9 x i8] c"mutex_Z1\00", align 1
@___asan_gen_.2050 = private unnamed_addr constant [9 x i8] c"rwsem_Z1\00", align 1
@___asan_gen_.2053 = private unnamed_addr constant [8 x i8] c"lock_Z2\00", align 1
@___asan_gen_.2056 = private unnamed_addr constant [10 x i8] c"rwlock_Z2\00", align 1
@___asan_gen_.2059 = private unnamed_addr constant [9 x i8] c"mutex_Z2\00", align 1
@___asan_gen_.2062 = private unnamed_addr constant [9 x i8] c"rwsem_Z2\00", align 1
@___asan_gen_.2070 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 139, i32 8 }
@___asan_gen_.2076 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 140, i32 8 }
@___asan_gen_.2082 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 141, i32 8 }
@___asan_gen_.2088 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 142, i32 8 }
@___asan_gen_.2094 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 143, i32 8 }
@___asan_gen_.2100 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 144, i32 8 }
@___asan_gen_.2124 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 165, i32 1 }
@___asan_gen_.2127 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 109, i32 8 }
@___asan_gen_.2130 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 116, i32 8 }
@___asan_gen_.2136 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 123, i32 8 }
@___asan_gen_.2142 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 130, i32 8 }
@___asan_gen_.2145 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 110, i32 8 }
@___asan_gen_.2148 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 117, i32 8 }
@___asan_gen_.2154 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 124, i32 8 }
@___asan_gen_.2160 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 131, i32 8 }
@___asan_gen_.2172 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 166, i32 1 }
@___asan_gen_.2175 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 111, i32 8 }
@___asan_gen_.2178 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 118, i32 8 }
@___asan_gen_.2184 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 125, i32 8 }
@___asan_gen_.2190 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 132, i32 8 }
@___asan_gen_.2193 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 112, i32 8 }
@___asan_gen_.2196 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 119, i32 8 }
@___asan_gen_.2202 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 126, i32 8 }
@___asan_gen_.2208 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 133, i32 8 }
@___asan_gen_.2220 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 167, i32 1 }
@___asan_gen_.2223 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 113, i32 8 }
@___asan_gen_.2226 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 120, i32 8 }
@___asan_gen_.2232 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 127, i32 8 }
@___asan_gen_.2238 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 134, i32 8 }
@___asan_gen_.2241 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 114, i32 8 }
@___asan_gen_.2244 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 121, i32 8 }
@___asan_gen_.2250 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 128, i32 8 }
@___asan_gen_.2256 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 135, i32 8 }
@___asan_gen_.2265 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1502, i32 2 }
@___asan_gen_.2274 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1457, i32 3 }
@___asan_gen_.2280 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1460, i32 3 }
@___asan_gen_.2286 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1465, i32 3 }
@___asan_gen_.2287 = private unnamed_addr constant [11 x i8] c"ww_lockdep\00", align 1
@___asan_gen_.2290 = private unnamed_addr constant [7 x i8] c"lock_A\00", align 1
@___asan_gen_.2293 = private unnamed_addr constant [9 x i8] c"rwlock_A\00", align 1
@___asan_gen_.2296 = private unnamed_addr constant [8 x i8] c"mutex_A\00", align 1
@___asan_gen_.2299 = private unnamed_addr constant [8 x i8] c"rwsem_A\00", align 1
@___asan_gen_.2302 = private unnamed_addr constant [10 x i8] c"rtmutex_A\00", align 1
@___asan_gen_.2305 = private unnamed_addr constant [7 x i8] c"lock_B\00", align 1
@___asan_gen_.2308 = private unnamed_addr constant [9 x i8] c"rwlock_B\00", align 1
@___asan_gen_.2311 = private unnamed_addr constant [8 x i8] c"mutex_B\00", align 1
@___asan_gen_.2314 = private unnamed_addr constant [8 x i8] c"rwsem_B\00", align 1
@___asan_gen_.2317 = private unnamed_addr constant [10 x i8] c"rtmutex_B\00", align 1
@___asan_gen_.2320 = private unnamed_addr constant [7 x i8] c"lock_C\00", align 1
@___asan_gen_.2323 = private unnamed_addr constant [9 x i8] c"rwlock_C\00", align 1
@___asan_gen_.2326 = private unnamed_addr constant [8 x i8] c"mutex_C\00", align 1
@___asan_gen_.2329 = private unnamed_addr constant [8 x i8] c"rwsem_C\00", align 1
@___asan_gen_.2332 = private unnamed_addr constant [10 x i8] c"rtmutex_C\00", align 1
@___asan_gen_.2335 = private unnamed_addr constant [7 x i8] c"lock_D\00", align 1
@___asan_gen_.2338 = private unnamed_addr constant [9 x i8] c"rwlock_D\00", align 1
@___asan_gen_.2341 = private unnamed_addr constant [8 x i8] c"mutex_D\00", align 1
@___asan_gen_.2344 = private unnamed_addr constant [8 x i8] c"rwsem_D\00", align 1
@___asan_gen_.2347 = private unnamed_addr constant [10 x i8] c"rtmutex_D\00", align 1
@___asan_gen_.2350 = private unnamed_addr constant [2 x i8] c"t\00", align 1
@___asan_gen_.2352 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 64, i32 30 }
@___asan_gen_.2353 = private unnamed_addr constant [3 x i8] c"t2\00", align 1
@___asan_gen_.2355 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 64, i32 33 }
@___asan_gen_.2356 = private unnamed_addr constant [2 x i8] c"o\00", align 1
@___asan_gen_.2358 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 65, i32 24 }
@___asan_gen_.2359 = private unnamed_addr constant [3 x i8] c"o2\00", align 1
@___asan_gen_.2361 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 65, i32 27 }
@___asan_gen_.2362 = private unnamed_addr constant [3 x i8] c"o3\00", align 1
@___asan_gen_.2364 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 65, i32 31 }
@___asan_gen_.2365 = private unnamed_addr constant [11 x i8] c"raw_lock_A\00", align 1
@___asan_gen_.2368 = private unnamed_addr constant [11 x i8] c"raw_lock_B\00", align 1
@___asan_gen_.2397 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1410, i32 2 }
@___asan_gen_.2424 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1410, i32 9 }
@___asan_gen_.2451 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1410, i32 16 }
@___asan_gen_.2478 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1410, i32 23 }
@___asan_gen_.2484 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1412, i32 2 }
@___asan_gen_.2490 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1413, i32 2 }
@___asan_gen_.2496 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1414, i32 2 }
@___asan_gen_.2502 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 41, i32 8 }
@___asan_gen_.2505 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 71, i32 8 }
@___asan_gen_.2508 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 79, i32 8 }
@___asan_gen_.2514 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 84, i32 8 }
@___asan_gen_.2520 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 89, i32 8 }
@___asan_gen_.2526 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 96, i32 8 }
@___asan_gen_.2529 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 72, i32 8 }
@___asan_gen_.2532 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 80, i32 8 }
@___asan_gen_.2538 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 85, i32 8 }
@___asan_gen_.2544 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 90, i32 8 }
@___asan_gen_.2550 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 97, i32 8 }
@___asan_gen_.2553 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 73, i32 8 }
@___asan_gen_.2556 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 81, i32 8 }
@___asan_gen_.2562 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 86, i32 8 }
@___asan_gen_.2568 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 91, i32 8 }
@___asan_gen_.2574 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 98, i32 8 }
@___asan_gen_.2577 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 74, i32 8 }
@___asan_gen_.2580 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 82, i32 8 }
@___asan_gen_.2586 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 87, i32 8 }
@___asan_gen_.2592 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 92, i32 8 }
@___asan_gen_.2598 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 99, i32 8 }
@___asan_gen_.2601 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 76, i32 8 }
@___asan_gen_.2604 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 77, i32 8 }
@___asan_gen_.2607 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 771, i32 1 }
@___asan_gen_.2610 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 773, i32 1 }
@___asan_gen_.2613 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 775, i32 1 }
@___asan_gen_.2616 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 777, i32 1 }
@___asan_gen_.2619 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 779, i32 1 }
@___asan_gen_.2622 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 781, i32 1 }
@___asan_gen_.2623 = private unnamed_addr constant [6 x i8] c"__key\00", align 1
@___asan_gen_.2625 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 785, i32 1 }
@___asan_gen_.2631 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2285, i32 2 }
@___asan_gen_.2637 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2286, i32 2 }
@___asan_gen_.2643 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2287, i32 2 }
@___asan_gen_.2646 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2289, i32 17 }
@___asan_gen_.2649 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2293, i32 2 }
@___asan_gen_.2652 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2295, i32 17 }
@___asan_gen_.2655 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2298, i32 2 }
@___asan_gen_.2658 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2300, i32 17 }
@___asan_gen_.2661 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2305, i32 2 }
@___asan_gen_.2664 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2307, i32 17 }
@___asan_gen_.2667 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2311, i32 2 }
@___asan_gen_.2670 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2313, i32 17 }
@___asan_gen_.2673 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2324, i32 2 }
@___asan_gen_.2676 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2326, i32 17 }
@___asan_gen_.2679 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2328, i32 2 }
@___asan_gen_.2682 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2330, i32 17 }
@___asan_gen_.2685 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2332, i32 2 }
@___asan_gen_.2691 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2334, i32 2 }
@___asan_gen_.2697 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2335, i32 2 }
@___asan_gen_.2700 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2336, i32 2 }
@___asan_gen_.2703 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2338, i32 17 }
@___asan_gen_.2706 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2342, i32 2 }
@___asan_gen_.2709 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2344, i32 17 }
@___asan_gen_.2712 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2348, i32 2 }
@___asan_gen_.2715 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2350, i32 17 }
@___asan_gen_.2718 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2354, i32 2 }
@___asan_gen_.2721 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2356, i32 17 }
@___asan_gen_.2724 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2360, i32 2 }
@___asan_gen_.2730 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 1699, i32 3 }
@___asan_gen_.2736 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2741, i32 297, i32 2 }
@___asan_gen_.2739 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2741, i32 173, i32 2 }
@___asan_gen_.2741 = private unnamed_addr constant [28 x i8] c"../include/linux/ww_mutex.h\00", align 1
@___asan_gen_.2742 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2741, i32 191, i32 2 }
@___asan_gen_.2751 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2492, i32 2 }
@___asan_gen_.2757 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2493, i32 2 }
@___asan_gen_.2760 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2494, i32 2 }
@___asan_gen_.2763 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2496, i32 17 }
@___asan_gen_.2766 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2498, i32 2 }
@___asan_gen_.2769 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2500, i32 17 }
@___asan_gen_.2772 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2502, i32 2 }
@___asan_gen_.2775 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2504, i32 17 }
@___asan_gen_.2778 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2506, i32 2 }
@___asan_gen_.2780 = private unnamed_addr constant [28 x i8] c"../include/linux/sched/mm.h\00", align 1
@___asan_gen_.2781 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2780, i32 256, i32 2 }
@___asan_gen_.2787 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2670, i32 2 }
@___asan_gen_.2793 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2671, i32 2 }
@___asan_gen_.2796 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2672, i32 2 }
@___asan_gen_.2802 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2673, i32 2 }
@___asan_gen_.2805 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2674, i32 2 }
@___asan_gen_.2808 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2675, i32 17 }
@___asan_gen_.2811 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2677, i32 2 }
@___asan_gen_.2814 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2679, i32 17 }
@___asan_gen_.2817 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2681, i32 2 }
@___asan_gen_.2820 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2683, i32 17 }
@___asan_gen_.2823 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2685, i32 2 }
@___asan_gen_.2826 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2687, i32 17 }
@___asan_gen_.2829 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2689, i32 2 }
@___asan_gen_.2832 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2691, i32 17 }
@___asan_gen_.2835 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2693, i32 2 }
@___asan_gen_.2838 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2695, i32 17 }
@___asan_gen_.2841 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2697, i32 2 }
@___asan_gen_.2844 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2699, i32 17 }
@___asan_gen_.2847 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2701, i32 2 }
@___asan_gen_.2850 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2703, i32 17 }
@___asan_gen_.2853 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2705, i32 2 }
@___asan_gen_.2856 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2707, i32 17 }
@___asan_gen_.2859 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2709, i32 2 }
@___asan_gen_.2865 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 723, i32 2 }
@___asan_gen_.2868 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 695, i32 2 }
@___asan_gen_.2871 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 760, i32 2 }
@___asan_gen_.2874 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 749, i32 2 }
@___asan_gen_.2877 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 805, i32 2 }
@___asan_gen_.2879 = private unnamed_addr constant [28 x i8] c"../include/linux/rcupdate.h\00", align 1
@___asan_gen_.2880 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2879, i32 787, i32 2 }
@___asan_gen_.2886 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2780, i32 2 }
@___asan_gen_.2892 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2781, i32 2 }
@___asan_gen_.2895 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2782, i32 2 }
@___asan_gen_.2898 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2784, i32 17 }
@___asan_gen_.2901 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2786, i32 2 }
@___asan_gen_.2904 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2788, i32 17 }
@___asan_gen_.2907 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2790, i32 2 }
@___asan_gen_.2910 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2792, i32 17 }
@___asan_gen_.2911 = private unnamed_addr constant [7 x i8] c"_entry\00", align 1
@___asan_gen_.2912 = private constant [26 x i8] c"../lib/locking-selftest.c\00", align 1
@___asan_gen_.2913 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2912, i32 2794, i32 2 }
@___asan_gen_.2919 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2921, i32 30, i32 2 }
@___asan_gen_.2920 = private unnamed_addr constant [17 x i8] c"<string literal>\00", align 1
@___asan_gen_.2921 = private unnamed_addr constant [39 x i8] c"../include/linux/local_lock_internal.h\00", align 1
@___asan_gen_.2922 = private unnamed_addr constant { ptr, i32, i32 } { ptr @___asan_gen_.2921, i32 36, i32 2 }
@llvm.compiler.used = appending global [952 x ptr] [ptr @__setup_setup_debug_locks_verbose, ptr @dotest._entry, ptr @dotest._entry.643, ptr @dotest._entry.646, ptr @dotest._entry_ptr, ptr @dotest._entry_ptr.645, ptr @dotest._entry_ptr.648, ptr @fs_reclaim_tests._entry, ptr @fs_reclaim_tests._entry.784, ptr @fs_reclaim_tests._entry.787, ptr @fs_reclaim_tests._entry.790, ptr @fs_reclaim_tests._entry.793, ptr @fs_reclaim_tests._entry.796, ptr @fs_reclaim_tests._entry_ptr, ptr @fs_reclaim_tests._entry_ptr.786, ptr @fs_reclaim_tests._entry_ptr.788, ptr @fs_reclaim_tests._entry_ptr.791, ptr @fs_reclaim_tests._entry_ptr.794, ptr @fs_reclaim_tests._entry_ptr.797, ptr @local_lock_tests._entry, ptr @local_lock_tests._entry.845, ptr @local_lock_tests._entry.848, ptr @local_lock_tests._entry.851, ptr @local_lock_tests._entry.854, ptr @local_lock_tests._entry.857, ptr @local_lock_tests._entry_ptr, ptr @local_lock_tests._entry_ptr.847, ptr @local_lock_tests._entry_ptr.849, ptr @local_lock_tests._entry_ptr.852, ptr @local_lock_tests._entry_ptr.855, ptr @local_lock_tests._entry_ptr.858, ptr @locking_selftest._entry, ptr @locking_selftest._entry.101, ptr @locking_selftest._entry.103, ptr @locking_selftest._entry.106, ptr @locking_selftest._entry.108, ptr @locking_selftest._entry.11, ptr @locking_selftest._entry.111, ptr @locking_selftest._entry.113, ptr @locking_selftest._entry.116, ptr @locking_selftest._entry.118, ptr @locking_selftest._entry.121, ptr @locking_selftest._entry.123, ptr @locking_selftest._entry.126, ptr @locking_selftest._entry.128, ptr @locking_selftest._entry.131, ptr @locking_selftest._entry.133, ptr @locking_selftest._entry.136, ptr @locking_selftest._entry.138, ptr @locking_selftest._entry.14, ptr @locking_selftest._entry.141, ptr @locking_selftest._entry.143, ptr @locking_selftest._entry.146, ptr @locking_selftest._entry.148, ptr @locking_selftest._entry.151, ptr @locking_selftest._entry.153, ptr @locking_selftest._entry.156, ptr @locking_selftest._entry.158, ptr @locking_selftest._entry.161, ptr @locking_selftest._entry.163, ptr @locking_selftest._entry.166, ptr @locking_selftest._entry.168, ptr @locking_selftest._entry.17, ptr @locking_selftest._entry.171, ptr @locking_selftest._entry.173, ptr @locking_selftest._entry.176, ptr @locking_selftest._entry.178, ptr @locking_selftest._entry.181, ptr @locking_selftest._entry.183, ptr @locking_selftest._entry.186, ptr @locking_selftest._entry.188, ptr @locking_selftest._entry.191, ptr @locking_selftest._entry.193, ptr @locking_selftest._entry.196, ptr @locking_selftest._entry.198, ptr @locking_selftest._entry.20, ptr @locking_selftest._entry.201, ptr @locking_selftest._entry.203, ptr @locking_selftest._entry.206, ptr @locking_selftest._entry.208, ptr @locking_selftest._entry.211, ptr @locking_selftest._entry.213, ptr @locking_selftest._entry.216, ptr @locking_selftest._entry.218, ptr @locking_selftest._entry.220, ptr @locking_selftest._entry.223, ptr @locking_selftest._entry.226, ptr @locking_selftest._entry.229, ptr @locking_selftest._entry.232, ptr @locking_selftest._entry.235, ptr @locking_selftest._entry.238, ptr @locking_selftest._entry.24, ptr @locking_selftest._entry.241, ptr @locking_selftest._entry.244, ptr @locking_selftest._entry.247, ptr @locking_selftest._entry.250, ptr @locking_selftest._entry.253, ptr @locking_selftest._entry.256, ptr @locking_selftest._entry.259, ptr @locking_selftest._entry.262, ptr @locking_selftest._entry.265, ptr @locking_selftest._entry.268, ptr @locking_selftest._entry.271, ptr @locking_selftest._entry.274, ptr @locking_selftest._entry.277, ptr @locking_selftest._entry.28, ptr @locking_selftest._entry.280, ptr @locking_selftest._entry.283, ptr @locking_selftest._entry.286, ptr @locking_selftest._entry.289, ptr @locking_selftest._entry.292, ptr @locking_selftest._entry.295, ptr @locking_selftest._entry.298, ptr @locking_selftest._entry.3, ptr @locking_selftest._entry.301, ptr @locking_selftest._entry.304, ptr @locking_selftest._entry.307, ptr @locking_selftest._entry.31, ptr @locking_selftest._entry.310, ptr @locking_selftest._entry.313, ptr @locking_selftest._entry.316, ptr @locking_selftest._entry.319, ptr @locking_selftest._entry.322, ptr @locking_selftest._entry.325, ptr @locking_selftest._entry.328, ptr @locking_selftest._entry.331, ptr @locking_selftest._entry.334, ptr @locking_selftest._entry.337, ptr @locking_selftest._entry.34, ptr @locking_selftest._entry.340, ptr @locking_selftest._entry.343, ptr @locking_selftest._entry.346, ptr @locking_selftest._entry.349, ptr @locking_selftest._entry.352, ptr @locking_selftest._entry.355, ptr @locking_selftest._entry.358, ptr @locking_selftest._entry.361, ptr @locking_selftest._entry.364, ptr @locking_selftest._entry.367, ptr @locking_selftest._entry.369, ptr @locking_selftest._entry.37, ptr @locking_selftest._entry.372, ptr @locking_selftest._entry.374, ptr @locking_selftest._entry.377, ptr @locking_selftest._entry.379, ptr @locking_selftest._entry.382, ptr @locking_selftest._entry.384, ptr @locking_selftest._entry.387, ptr @locking_selftest._entry.389, ptr @locking_selftest._entry.392, ptr @locking_selftest._entry.394, ptr @locking_selftest._entry.397, ptr @locking_selftest._entry.399, ptr @locking_selftest._entry.40, ptr @locking_selftest._entry.402, ptr @locking_selftest._entry.404, ptr @locking_selftest._entry.407, ptr @locking_selftest._entry.409, ptr @locking_selftest._entry.412, ptr @locking_selftest._entry.414, ptr @locking_selftest._entry.417, ptr @locking_selftest._entry.419, ptr @locking_selftest._entry.422, ptr @locking_selftest._entry.424, ptr @locking_selftest._entry.427, ptr @locking_selftest._entry.429, ptr @locking_selftest._entry.43, ptr @locking_selftest._entry.432, ptr @locking_selftest._entry.434, ptr @locking_selftest._entry.437, ptr @locking_selftest._entry.439, ptr @locking_selftest._entry.442, ptr @locking_selftest._entry.444, ptr @locking_selftest._entry.447, ptr @locking_selftest._entry.449, ptr @locking_selftest._entry.452, ptr @locking_selftest._entry.454, ptr @locking_selftest._entry.457, ptr @locking_selftest._entry.459, ptr @locking_selftest._entry.46, ptr @locking_selftest._entry.462, ptr @locking_selftest._entry.464, ptr @locking_selftest._entry.467, ptr @locking_selftest._entry.469, ptr @locking_selftest._entry.472, ptr @locking_selftest._entry.474, ptr @locking_selftest._entry.477, ptr @locking_selftest._entry.479, ptr @locking_selftest._entry.482, ptr @locking_selftest._entry.484, ptr @locking_selftest._entry.487, ptr @locking_selftest._entry.489, ptr @locking_selftest._entry.49, ptr @locking_selftest._entry.492, ptr @locking_selftest._entry.494, ptr @locking_selftest._entry.497, ptr @locking_selftest._entry.499, ptr @locking_selftest._entry.502, ptr @locking_selftest._entry.504, ptr @locking_selftest._entry.507, ptr @locking_selftest._entry.509, ptr @locking_selftest._entry.51, ptr @locking_selftest._entry.512, ptr @locking_selftest._entry.514, ptr @locking_selftest._entry.517, ptr @locking_selftest._entry.519, ptr @locking_selftest._entry.522, ptr @locking_selftest._entry.524, ptr @locking_selftest._entry.527, ptr @locking_selftest._entry.529, ptr @locking_selftest._entry.532, ptr @locking_selftest._entry.534, ptr @locking_selftest._entry.537, ptr @locking_selftest._entry.539, ptr @locking_selftest._entry.54, ptr @locking_selftest._entry.542, ptr @locking_selftest._entry.544, ptr @locking_selftest._entry.547, ptr @locking_selftest._entry.550, ptr @locking_selftest._entry.552, ptr @locking_selftest._entry.555, ptr @locking_selftest._entry.558, ptr @locking_selftest._entry.561, ptr @locking_selftest._entry.563, ptr @locking_selftest._entry.566, ptr @locking_selftest._entry.569, ptr @locking_selftest._entry.57, ptr @locking_selftest._entry.572, ptr @locking_selftest._entry.575, ptr @locking_selftest._entry.59, ptr @locking_selftest._entry.6, ptr @locking_selftest._entry.62, ptr @locking_selftest._entry.64, ptr @locking_selftest._entry.66, ptr @locking_selftest._entry.69, ptr @locking_selftest._entry.71, ptr @locking_selftest._entry.73, ptr @locking_selftest._entry.76, ptr @locking_selftest._entry.78, ptr @locking_selftest._entry.8, ptr @locking_selftest._entry.80, ptr @locking_selftest._entry.83, ptr @locking_selftest._entry.85, ptr @locking_selftest._entry.88, ptr @locking_selftest._entry.90, ptr @locking_selftest._entry.93, ptr @locking_selftest._entry.95, ptr @locking_selftest._entry.98, ptr @locking_selftest._entry_ptr, ptr @locking_selftest._entry_ptr.10, ptr @locking_selftest._entry_ptr.102, ptr @locking_selftest._entry_ptr.104, ptr @locking_selftest._entry_ptr.107, ptr @locking_selftest._entry_ptr.109, ptr @locking_selftest._entry_ptr.112, ptr @locking_selftest._entry_ptr.114, ptr @locking_selftest._entry_ptr.117, ptr @locking_selftest._entry_ptr.119, ptr @locking_selftest._entry_ptr.122, ptr @locking_selftest._entry_ptr.124, ptr @locking_selftest._entry_ptr.127, ptr @locking_selftest._entry_ptr.129, ptr @locking_selftest._entry_ptr.13, ptr @locking_selftest._entry_ptr.132, ptr @locking_selftest._entry_ptr.134, ptr @locking_selftest._entry_ptr.137, ptr @locking_selftest._entry_ptr.139, ptr @locking_selftest._entry_ptr.142, ptr @locking_selftest._entry_ptr.144, ptr @locking_selftest._entry_ptr.147, ptr @locking_selftest._entry_ptr.149, ptr @locking_selftest._entry_ptr.152, ptr @locking_selftest._entry_ptr.154, ptr @locking_selftest._entry_ptr.157, ptr @locking_selftest._entry_ptr.159, ptr @locking_selftest._entry_ptr.16, ptr @locking_selftest._entry_ptr.162, ptr @locking_selftest._entry_ptr.164, ptr @locking_selftest._entry_ptr.167, ptr @locking_selftest._entry_ptr.169, ptr @locking_selftest._entry_ptr.172, ptr @locking_selftest._entry_ptr.174, ptr @locking_selftest._entry_ptr.177, ptr @locking_selftest._entry_ptr.179, ptr @locking_selftest._entry_ptr.182, ptr @locking_selftest._entry_ptr.184, ptr @locking_selftest._entry_ptr.187, ptr @locking_selftest._entry_ptr.189, ptr @locking_selftest._entry_ptr.19, ptr @locking_selftest._entry_ptr.192, ptr @locking_selftest._entry_ptr.194, ptr @locking_selftest._entry_ptr.197, ptr @locking_selftest._entry_ptr.199, ptr @locking_selftest._entry_ptr.202, ptr @locking_selftest._entry_ptr.204, ptr @locking_selftest._entry_ptr.207, ptr @locking_selftest._entry_ptr.209, ptr @locking_selftest._entry_ptr.212, ptr @locking_selftest._entry_ptr.214, ptr @locking_selftest._entry_ptr.217, ptr @locking_selftest._entry_ptr.219, ptr @locking_selftest._entry_ptr.22, ptr @locking_selftest._entry_ptr.221, ptr @locking_selftest._entry_ptr.224, ptr @locking_selftest._entry_ptr.227, ptr @locking_selftest._entry_ptr.230, ptr @locking_selftest._entry_ptr.233, ptr @locking_selftest._entry_ptr.236, ptr @locking_selftest._entry_ptr.239, ptr @locking_selftest._entry_ptr.242, ptr @locking_selftest._entry_ptr.245, ptr @locking_selftest._entry_ptr.248, ptr @locking_selftest._entry_ptr.251, ptr @locking_selftest._entry_ptr.254, ptr @locking_selftest._entry_ptr.257, ptr @locking_selftest._entry_ptr.26, ptr @locking_selftest._entry_ptr.260, ptr @locking_selftest._entry_ptr.263, ptr @locking_selftest._entry_ptr.266, ptr @locking_selftest._entry_ptr.269, ptr @locking_selftest._entry_ptr.272, ptr @locking_selftest._entry_ptr.275, ptr @locking_selftest._entry_ptr.278, ptr @locking_selftest._entry_ptr.281, ptr @locking_selftest._entry_ptr.284, ptr @locking_selftest._entry_ptr.287, ptr @locking_selftest._entry_ptr.29, ptr @locking_selftest._entry_ptr.290, ptr @locking_selftest._entry_ptr.293, ptr @locking_selftest._entry_ptr.296, ptr @locking_selftest._entry_ptr.299, ptr @locking_selftest._entry_ptr.302, ptr @locking_selftest._entry_ptr.305, ptr @locking_selftest._entry_ptr.308, ptr @locking_selftest._entry_ptr.311, ptr @locking_selftest._entry_ptr.314, ptr @locking_selftest._entry_ptr.317, ptr @locking_selftest._entry_ptr.32, ptr @locking_selftest._entry_ptr.320, ptr @locking_selftest._entry_ptr.323, ptr @locking_selftest._entry_ptr.326, ptr @locking_selftest._entry_ptr.329, ptr @locking_selftest._entry_ptr.332, ptr @locking_selftest._entry_ptr.335, ptr @locking_selftest._entry_ptr.338, ptr @locking_selftest._entry_ptr.341, ptr @locking_selftest._entry_ptr.344, ptr @locking_selftest._entry_ptr.347, ptr @locking_selftest._entry_ptr.35, ptr @locking_selftest._entry_ptr.350, ptr @locking_selftest._entry_ptr.353, ptr @locking_selftest._entry_ptr.356, ptr @locking_selftest._entry_ptr.359, ptr @locking_selftest._entry_ptr.363, ptr @locking_selftest._entry_ptr.365, ptr @locking_selftest._entry_ptr.368, ptr @locking_selftest._entry_ptr.370, ptr @locking_selftest._entry_ptr.373, ptr @locking_selftest._entry_ptr.375, ptr @locking_selftest._entry_ptr.378, ptr @locking_selftest._entry_ptr.38, ptr @locking_selftest._entry_ptr.380, ptr @locking_selftest._entry_ptr.383, ptr @locking_selftest._entry_ptr.385, ptr @locking_selftest._entry_ptr.388, ptr @locking_selftest._entry_ptr.390, ptr @locking_selftest._entry_ptr.393, ptr @locking_selftest._entry_ptr.395, ptr @locking_selftest._entry_ptr.398, ptr @locking_selftest._entry_ptr.400, ptr @locking_selftest._entry_ptr.403, ptr @locking_selftest._entry_ptr.405, ptr @locking_selftest._entry_ptr.408, ptr @locking_selftest._entry_ptr.41, ptr @locking_selftest._entry_ptr.410, ptr @locking_selftest._entry_ptr.413, ptr @locking_selftest._entry_ptr.415, ptr @locking_selftest._entry_ptr.418, ptr @locking_selftest._entry_ptr.420, ptr @locking_selftest._entry_ptr.423, ptr @locking_selftest._entry_ptr.425, ptr @locking_selftest._entry_ptr.428, ptr @locking_selftest._entry_ptr.430, ptr @locking_selftest._entry_ptr.433, ptr @locking_selftest._entry_ptr.435, ptr @locking_selftest._entry_ptr.438, ptr @locking_selftest._entry_ptr.44, ptr @locking_selftest._entry_ptr.440, ptr @locking_selftest._entry_ptr.443, ptr @locking_selftest._entry_ptr.445, ptr @locking_selftest._entry_ptr.448, ptr @locking_selftest._entry_ptr.450, ptr @locking_selftest._entry_ptr.453, ptr @locking_selftest._entry_ptr.455, ptr @locking_selftest._entry_ptr.458, ptr @locking_selftest._entry_ptr.460, ptr @locking_selftest._entry_ptr.463, ptr @locking_selftest._entry_ptr.465, ptr @locking_selftest._entry_ptr.468, ptr @locking_selftest._entry_ptr.47, ptr @locking_selftest._entry_ptr.470, ptr @locking_selftest._entry_ptr.473, ptr @locking_selftest._entry_ptr.475, ptr @locking_selftest._entry_ptr.478, ptr @locking_selftest._entry_ptr.480, ptr @locking_selftest._entry_ptr.483, ptr @locking_selftest._entry_ptr.485, ptr @locking_selftest._entry_ptr.488, ptr @locking_selftest._entry_ptr.490, ptr @locking_selftest._entry_ptr.493, ptr @locking_selftest._entry_ptr.495, ptr @locking_selftest._entry_ptr.498, ptr @locking_selftest._entry_ptr.5, ptr @locking_selftest._entry_ptr.50, ptr @locking_selftest._entry_ptr.500, ptr @locking_selftest._entry_ptr.503, ptr @locking_selftest._entry_ptr.505, ptr @locking_selftest._entry_ptr.508, ptr @locking_selftest._entry_ptr.510, ptr @locking_selftest._entry_ptr.513, ptr @locking_selftest._entry_ptr.515, ptr @locking_selftest._entry_ptr.518, ptr @locking_selftest._entry_ptr.52, ptr @locking_selftest._entry_ptr.520, ptr @locking_selftest._entry_ptr.523, ptr @locking_selftest._entry_ptr.525, ptr @locking_selftest._entry_ptr.528, ptr @locking_selftest._entry_ptr.530, ptr @locking_selftest._entry_ptr.533, ptr @locking_selftest._entry_ptr.535, ptr @locking_selftest._entry_ptr.538, ptr @locking_selftest._entry_ptr.540, ptr @locking_selftest._entry_ptr.543, ptr @locking_selftest._entry_ptr.546, ptr @locking_selftest._entry_ptr.549, ptr @locking_selftest._entry_ptr.551, ptr @locking_selftest._entry_ptr.554, ptr @locking_selftest._entry_ptr.557, ptr @locking_selftest._entry_ptr.56, ptr @locking_selftest._entry_ptr.560, ptr @locking_selftest._entry_ptr.562, ptr @locking_selftest._entry_ptr.565, ptr @locking_selftest._entry_ptr.568, ptr @locking_selftest._entry_ptr.571, ptr @locking_selftest._entry_ptr.574, ptr @locking_selftest._entry_ptr.577, ptr @locking_selftest._entry_ptr.58, ptr @locking_selftest._entry_ptr.60, ptr @locking_selftest._entry_ptr.63, ptr @locking_selftest._entry_ptr.65, ptr @locking_selftest._entry_ptr.67, ptr @locking_selftest._entry_ptr.7, ptr @locking_selftest._entry_ptr.70, ptr @locking_selftest._entry_ptr.72, ptr @locking_selftest._entry_ptr.74, ptr @locking_selftest._entry_ptr.77, ptr @locking_selftest._entry_ptr.79, ptr @locking_selftest._entry_ptr.81, ptr @locking_selftest._entry_ptr.84, ptr @locking_selftest._entry_ptr.86, ptr @locking_selftest._entry_ptr.89, ptr @locking_selftest._entry_ptr.91, ptr @locking_selftest._entry_ptr.94, ptr @locking_selftest._entry_ptr.96, ptr @locking_selftest._entry_ptr.99, ptr @print_testname._entry, ptr @print_testname._entry_ptr, ptr @wait_context_tests._entry, ptr @wait_context_tests._entry.800, ptr @wait_context_tests._entry.803, ptr @wait_context_tests._entry.805, ptr @wait_context_tests._entry.808, ptr @wait_context_tests._entry.811, ptr @wait_context_tests._entry.814, ptr @wait_context_tests._entry.817, ptr @wait_context_tests._entry.820, ptr @wait_context_tests._entry.823, ptr @wait_context_tests._entry.826, ptr @wait_context_tests._entry.829, ptr @wait_context_tests._entry.832, ptr @wait_context_tests._entry.835, ptr @wait_context_tests._entry_ptr, ptr @wait_context_tests._entry_ptr.802, ptr @wait_context_tests._entry_ptr.804, ptr @wait_context_tests._entry_ptr.807, ptr @wait_context_tests._entry_ptr.809, ptr @wait_context_tests._entry_ptr.812, ptr @wait_context_tests._entry_ptr.815, ptr @wait_context_tests._entry_ptr.818, ptr @wait_context_tests._entry_ptr.821, ptr @wait_context_tests._entry_ptr.824, ptr @wait_context_tests._entry_ptr.827, ptr @wait_context_tests._entry_ptr.830, ptr @wait_context_tests._entry_ptr.833, ptr @wait_context_tests._entry_ptr.836, ptr @ww_tests._entry, ptr @ww_tests._entry.729, ptr @ww_tests._entry.732, ptr @ww_tests._entry.736, ptr @ww_tests._entry.739, ptr @ww_tests._entry.742, ptr @ww_tests._entry.745, ptr @ww_tests._entry.748, ptr @ww_tests._entry.751, ptr @ww_tests._entry.754, ptr @ww_tests._entry.756, ptr @ww_tests._entry.759, ptr @ww_tests._entry.762, ptr @ww_tests._entry.765, ptr @ww_tests._entry.768, ptr @ww_tests._entry.771, ptr @ww_tests._entry.774, ptr @ww_tests._entry_ptr, ptr @ww_tests._entry_ptr.731, ptr @ww_tests._entry_ptr.734, ptr @ww_tests._entry_ptr.737, ptr @ww_tests._entry_ptr.740, ptr @ww_tests._entry_ptr.743, ptr @ww_tests._entry_ptr.746, ptr @ww_tests._entry_ptr.749, ptr @ww_tests._entry_ptr.752, ptr @ww_tests._entry_ptr.755, ptr @ww_tests._entry_ptr.758, ptr @ww_tests._entry_ptr.761, ptr @ww_tests._entry_ptr.763, ptr @ww_tests._entry_ptr.766, ptr @ww_tests._entry_ptr.769, ptr @ww_tests._entry_ptr.772, ptr @ww_tests._entry_ptr.775, ptr @.str, ptr @.str.1, ptr @.str.2, ptr @.str.4, ptr @force_read_lock_recursive, ptr @.str.9, ptr @.str.12, ptr @.str.15, ptr @.str.18, ptr @.str.21, ptr @.str.23, ptr @.str.25, ptr @.str.27, ptr @.str.30, ptr @.str.33, ptr @.str.36, ptr @.str.39, ptr @.str.42, ptr @.str.45, ptr @.str.48, ptr @.str.53, ptr @.str.55, ptr @.str.61, ptr @.str.68, ptr @.str.75, ptr @.str.82, ptr @.str.87, ptr @.str.92, ptr @.str.97, ptr @.str.100, ptr @.str.105, ptr @.str.110, ptr @.str.115, ptr @.str.120, ptr @.str.125, ptr @.str.130, ptr @.str.135, ptr @.str.140, ptr @.str.145, ptr @.str.150, ptr @.str.155, ptr @.str.160, ptr @.str.165, ptr @.str.170, ptr @.str.175, ptr @.str.180, ptr @.str.185, ptr @.str.190, ptr @.str.195, ptr @.str.200, ptr @.str.205, ptr @.str.210, ptr @.str.215, ptr @.str.222, ptr @.str.225, ptr @.str.228, ptr @.str.231, ptr @.str.234, ptr @.str.237, ptr @.str.240, ptr @.str.243, ptr @.str.246, ptr @.str.249, ptr @.str.252, ptr @.str.255, ptr @.str.258, ptr @.str.261, ptr @.str.264, ptr @.str.267, ptr @.str.270, ptr @.str.273, ptr @.str.276, ptr @.str.279, ptr @.str.282, ptr @.str.285, ptr @.str.288, ptr @.str.291, ptr @.str.294, ptr @.str.297, ptr @.str.300, ptr @.str.303, ptr @.str.306, ptr @.str.309, ptr @.str.312, ptr @.str.315, ptr @.str.318, ptr @.str.321, ptr @.str.324, ptr @.str.327, ptr @.str.330, ptr @.str.333, ptr @.str.336, ptr @.str.339, ptr @.str.342, ptr @.str.345, ptr @.str.348, ptr @.str.351, ptr @.str.354, ptr @.str.357, ptr @.str.360, ptr @.str.362, ptr @.str.366, ptr @.str.371, ptr @.str.376, ptr @.str.381, ptr @.str.386, ptr @.str.391, ptr @.str.396, ptr @.str.401, ptr @.str.406, ptr @.str.411, ptr @.str.416, ptr @.str.421, ptr @.str.426, ptr @.str.431, ptr @.str.436, ptr @.str.441, ptr @.str.446, ptr @.str.451, ptr @.str.456, ptr @.str.461, ptr @.str.466, ptr @.str.471, ptr @.str.476, ptr @.str.481, ptr @.str.486, ptr @.str.491, ptr @.str.496, ptr @.str.501, ptr @.str.506, ptr @.str.511, ptr @.str.516, ptr @.str.521, ptr @.str.526, ptr @.str.531, ptr @.str.536, ptr @.str.541, ptr @unexpected_testcase_failures, ptr @.str.545, ptr @.str.548, ptr @testcase_total, ptr @testcase_successes, ptr @.str.553, ptr @.str.556, ptr @.str.559, ptr @.str.564, ptr @.str.567, ptr @.str.570, ptr @.str.573, ptr @.str.576, ptr @debug_locks_verbose, ptr @init_shared_classes.rt_X, ptr @init_shared_classes.rt_Y, ptr @init_shared_classes.rt_Z, ptr @rtmutex_X1, ptr @rtmutex_X2, ptr @rtmutex_Y1, ptr @rtmutex_Y2, ptr @rtmutex_Z1, ptr @rtmutex_Z2, ptr @lock_X1, ptr @rwlock_X1, ptr @mutex_X1, ptr @rwsem_X1, ptr @lock_X2, ptr @rwlock_X2, ptr @mutex_X2, ptr @rwsem_X2, ptr @lock_Y1, ptr @rwlock_Y1, ptr @mutex_Y1, ptr @rwsem_Y1, ptr @lock_Y2, ptr @rwlock_Y2, ptr @mutex_Y2, ptr @rwsem_Y2, ptr @lock_Z1, ptr @rwlock_Z1, ptr @mutex_Z1, ptr @rwsem_Z1, ptr @lock_Z2, ptr @rwlock_Z2, ptr @mutex_Z2, ptr @rwsem_Z2, ptr @.str.578, ptr @.str.579, ptr @.str.580, ptr @.str.581, ptr @.str.582, ptr @.str.583, ptr @.str.584, ptr @.str.585, ptr @.str.586, ptr @.str.587, ptr @.str.588, ptr @.str.589, ptr @init_class_X.__key, ptr @.str.590, ptr @init_class_X.__key.591, ptr @.str.592, ptr @init_class_X.__key.593, ptr @.str.594, ptr @init_class_X.__key.595, ptr @.str.596, ptr @.str.597, ptr @.str.598, ptr @.str.599, ptr @.str.600, ptr @.str.601, ptr @.str.602, ptr @.str.603, ptr @.str.604, ptr @.str.605, ptr @.str.606, ptr @.str.607, ptr @.str.608, ptr @init_class_Y.__key, ptr @init_class_Y.__key.609, ptr @init_class_Y.__key.610, ptr @init_class_Y.__key.611, ptr @.str.612, ptr @.str.613, ptr @.str.614, ptr @.str.615, ptr @.str.616, ptr @.str.617, ptr @.str.618, ptr @.str.619, ptr @.str.620, ptr @.str.621, ptr @.str.622, ptr @.str.623, ptr @init_class_Z.__key, ptr @init_class_Z.__key.624, ptr @init_class_Z.__key.625, ptr @init_class_Z.__key.626, ptr @.str.627, ptr @.str.628, ptr @.str.629, ptr @.str.630, ptr @.str.631, ptr @.str.632, ptr @.str.633, ptr @.str.634, ptr @.str.635, ptr @.str.636, ptr @.str.637, ptr @.str.638, ptr @.str.639, ptr @.str.640, ptr @.str.641, ptr @.str.642, ptr @.str.644, ptr @.str.647, ptr @ww_lockdep, ptr @lock_A, ptr @rwlock_A, ptr @mutex_A, ptr @rwsem_A, ptr @rtmutex_A, ptr @lock_B, ptr @rwlock_B, ptr @mutex_B, ptr @rwsem_B, ptr @rtmutex_B, ptr @lock_C, ptr @rwlock_C, ptr @mutex_C, ptr @rwsem_C, ptr @rtmutex_C, ptr @lock_D, ptr @rwlock_D, ptr @mutex_D, ptr @rwsem_D, ptr @rtmutex_D, ptr @t, ptr @t2, ptr @o, ptr @o2, ptr @o3, ptr @raw_lock_A, ptr @raw_lock_B, ptr @reset_locks.__key, ptr @.str.649, ptr @reset_locks.__key.650, ptr @.str.651, ptr @reset_locks.__key.652, ptr @.str.653, ptr @reset_locks.__key.654, ptr @.str.655, ptr @reset_locks.__key.656, ptr @reset_locks.__key.657, ptr @.str.658, ptr @reset_locks.__key.659, ptr @.str.660, ptr @reset_locks.__key.661, ptr @.str.662, ptr @reset_locks.__key.663, ptr @.str.664, ptr @reset_locks.__key.665, ptr @reset_locks.__key.666, ptr @.str.667, ptr @reset_locks.__key.668, ptr @.str.669, ptr @reset_locks.__key.670, ptr @.str.671, ptr @reset_locks.__key.672, ptr @.str.673, ptr @reset_locks.__key.674, ptr @reset_locks.__key.675, ptr @.str.676, ptr @reset_locks.__key.677, ptr @.str.678, ptr @reset_locks.__key.679, ptr @.str.680, ptr @reset_locks.__key.681, ptr @.str.682, ptr @reset_locks.__key.683, ptr @reset_locks.__key.684, ptr @.str.685, ptr @reset_locks.__key.686, ptr @.str.687, ptr @reset_locks.__key.688, ptr @.str.689, ptr @.str.690, ptr @.str.691, ptr @.str.692, ptr @.str.693, ptr @.str.694, ptr @.str.695, ptr @.str.696, ptr @.str.697, ptr @.str.698, ptr @.str.699, ptr @.str.700, ptr @.str.701, ptr @.str.702, ptr @.str.703, ptr @.str.704, ptr @.str.705, ptr @.str.706, ptr @.str.707, ptr @.str.708, ptr @.str.709, ptr @.str.710, ptr @.str.711, ptr @.str.712, ptr @.str.713, ptr @.str.714, ptr @.str.715, ptr @.str.716, ptr @.str.717, ptr @.str.718, ptr @.str.719, ptr @.str.720, ptr @.str.721, ptr @.str.722, ptr @.str.723, ptr @.str.724, ptr @.str.725, ptr @init_held_spin.__key, ptr @init_held_wlock.__key, ptr @init_held_rlock.__key, ptr @init_held_mutex.__key, ptr @init_held_wsem.__key, ptr @init_held_rsem.__key, ptr @init_held_rtmutex.__key, ptr @.str.728, ptr @.str.730, ptr @.str.733, ptr @.str.735, ptr @.str.738, ptr @.str.741, ptr @.str.744, ptr @.str.747, ptr @.str.750, ptr @.str.753, ptr @.str.757, ptr @.str.760, ptr @.str.764, ptr @.str.767, ptr @.str.770, ptr @.str.773, ptr @.str.776, ptr @.str.777, ptr @.str.778, ptr @.str.779, ptr @.str.780, ptr @.str.781, ptr @.str.782, ptr @.str.783, ptr @.str.785, ptr @.str.789, ptr @.str.792, ptr @.str.795, ptr @.str.798, ptr @.str.799, ptr @.str.801, ptr @.str.806, ptr @.str.810, ptr @.str.813, ptr @.str.816, ptr @.str.819, ptr @.str.822, ptr @.str.825, ptr @.str.828, ptr @.str.831, ptr @.str.834, ptr @.str.837, ptr @.str.838, ptr @.str.839, ptr @.str.840, ptr @.str.841, ptr @.str.842, ptr @.str.843, ptr @.str.844, ptr @.str.846, ptr @.str.850, ptr @.str.853, ptr @.str.856, ptr @.str.859, ptr @.str.860, ptr @.str.861], section "llvm.metadata"
@0 = internal global [687 x { i32, i32, i32, i32, i32, i32, i32, i32 }] [{ i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.873 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.873 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.1 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.873 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.2 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.873 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.3 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.879 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.4 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.879 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.6 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.882 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @force_read_lock_recursive to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.883 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.885 to i32), i32 0 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.8 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.891 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.9 to i32), i32 26, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.891 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.11 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.897 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.12 to i32), i32 26, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.897 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.14 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.903 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.15 to i32), i32 78, i32 128, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.903 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.17 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.909 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.18 to i32), i32 85, i32 128, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.909 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.20 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.915 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.21 to i32), i32 78, i32 128, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.915 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.23 to i32), i32 13, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.924 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.24 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.924 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.25 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.924 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.27 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.930 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.28 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.930 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.30 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.936 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.31 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.936 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.33 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.942 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.34 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.942 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.36 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.948 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.37 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.948 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.39 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.954 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.40 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.954 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.42 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.960 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.43 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.960 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.45 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.966 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.46 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.966 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.48 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.972 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.49 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.972 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.51 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.975 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.53 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.978 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.54 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.984 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.55 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.984 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.57 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.987 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.59 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.990 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.61 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.993 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.62 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.996 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.64 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.999 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.66 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1002 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.68 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1005 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.69 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1008 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.71 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1011 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.73 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1014 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.75 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1017 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.76 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1020 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.78 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1023 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.80 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1026 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.82 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1029 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.83 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1032 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.85 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1035 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.87 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1038 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.88 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1041 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.90 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1044 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.92 to i32), i32 33, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1047 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.93 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1050 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.95 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1053 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.97 to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1056 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.98 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1059 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.100 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.101 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.103 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.105 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.106 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.108 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.110 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.111 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.113 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.115 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.116 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.118 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.120 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.121 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.123 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.125 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.126 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.128 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1113 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.130 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.131 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.133 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.135 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.136 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.138 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.140 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.141 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.143 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.145 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.146 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.148 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.150 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.151 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.153 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.155 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.156 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.158 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1167 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.160 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.161 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.163 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.165 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.166 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.168 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.170 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.171 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.173 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.175 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.176 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.178 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.180 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.181 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.183 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.185 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.186 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.188 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1221 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.190 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.191 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.193 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.195 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.196 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.198 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.200 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.201 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.203 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.205 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.206 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.208 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.210 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.211 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.213 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.215 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.216 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.218 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1275 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.220 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1278 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.222 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.223 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.225 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.226 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.228 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.229 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.231 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.232 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1302 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.234 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1314 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.235 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1314 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.237 to i32), i32 27, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1314 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.238 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1314 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.240 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.241 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.243 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.244 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.246 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.247 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.249 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.250 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1338 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.252 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.253 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.255 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.256 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.258 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.259 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.261 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.262 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.264 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.265 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.267 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.268 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.270 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.271 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.273 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.274 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.276 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.277 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.279 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.280 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.282 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.283 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.285 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.286 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1410 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.288 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.289 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.291 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.292 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.294 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.295 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.297 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.298 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.300 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.301 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.303 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.304 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.306 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.307 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.309 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.310 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.312 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.313 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.315 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.316 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.318 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.319 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.321 to i32), i32 30, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.322 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1482 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.324 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.325 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.327 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.328 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.330 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.331 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.333 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.334 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.336 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.337 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.339 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.340 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.342 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.343 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.345 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.346 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.348 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.349 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.351 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.352 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.354 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.355 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.357 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.358 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1554 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.360 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.361 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.362 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.364 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.366 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.367 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.369 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.371 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.372 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.374 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.376 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.377 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.379 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.381 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.382 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.384 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.386 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.387 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.389 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.391 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.392 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.394 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.396 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.397 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.399 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.401 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.402 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.404 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.406 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.407 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.409 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.411 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.412 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.414 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.416 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.417 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.419 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1665 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.421 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.422 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.424 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.426 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.427 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.429 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.431 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.432 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.434 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.436 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.437 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.439 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.441 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.442 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.444 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.446 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.447 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.449 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.451 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.452 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.454 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.456 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.457 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.459 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.461 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.462 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.464 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.466 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.467 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.469 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.471 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.472 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.474 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.476 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.477 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.479 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1773 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.481 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.482 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.484 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.486 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.487 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.489 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.491 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.492 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.494 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.496 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.497 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.499 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.501 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.502 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.504 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.506 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.507 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.509 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.511 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.512 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.514 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.516 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.517 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.519 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.521 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.522 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.524 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.526 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.527 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.529 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.531 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.532 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.534 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.536 to i32), i32 31, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.537 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.539 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1881 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.541 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1884 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.542 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1887 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @unexpected_testcase_failures to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1888 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1890 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.544 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1896 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.545 to i32), i32 67, i32 128, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1896 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.547 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1902 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.548 to i32), i32 67, i32 128, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1902 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @testcase_total to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1903 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1905 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.550 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1908 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @testcase_successes to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1909 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1911 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.552 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1917 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.553 to i32), i32 58, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1917 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.555 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1923 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.556 to i32), i32 49, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1923 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.558 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1929 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.559 to i32), i32 54, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1929 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.561 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1932 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.563 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1938 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.564 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1938 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.566 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1944 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.567 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1944 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.569 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1950 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.570 to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1950 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.572 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1956 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.573 to i32), i32 35, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1956 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @locking_selftest._entry.575 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1962 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.576 to i32), i32 35, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1962 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @debug_locks_verbose to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.1963 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1965 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_shared_classes.rt_X to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1966 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1968 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_shared_classes.rt_Y to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1969 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1971 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_shared_classes.rt_Z to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.1972 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.1974 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_X1 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1975 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2070 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_X2 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1978 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2076 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_Y1 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1981 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2082 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_Y2 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1984 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2088 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_Z1 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1987 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2094 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_Z2 to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.1990 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2100 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_X1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.1993 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2127 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_X1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.1996 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2130 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_X1 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.1999 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2136 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_X1 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2002 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2142 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_X2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2005 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2145 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_X2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2008 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2148 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_X2 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2011 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2154 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_X2 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2014 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2160 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_Y1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2017 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2175 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_Y1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2020 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2178 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_Y1 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2023 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2184 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_Y1 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2026 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2190 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_Y2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2029 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2193 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_Y2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2032 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2196 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_Y2 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2035 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2202 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_Y2 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2038 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2208 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_Z1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2041 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2223 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_Z1 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2044 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2226 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_Z1 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2047 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2232 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_Z1 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2050 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2238 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_Z2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2053 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2241 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_Z2 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2056 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2244 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_Z2 to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2059 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2250 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_Z2 to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2062 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2256 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.578 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2070 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.579 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2070 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.580 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2076 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.581 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2076 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.582 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2082 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.583 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2082 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.584 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2088 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.585 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2088 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.586 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2094 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.587 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2094 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.588 to i32), i32 29, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2100 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.589 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2100 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_X.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.590 to i32), i32 5, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_X.__key.591 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.592 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_X.__key.593 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.594 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_X.__key.595 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.596 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2124 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.597 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2127 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.598 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2130 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.599 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2136 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.600 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2136 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.601 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2142 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.602 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2142 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.603 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2145 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.604 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2148 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.605 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2154 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.606 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2154 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.607 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2160 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.608 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2160 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Y.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2172 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Y.__key.609 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2172 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Y.__key.610 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2172 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Y.__key.611 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2172 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.612 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2175 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.613 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2178 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.614 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2184 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.615 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2184 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.616 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2190 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.617 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2190 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.618 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2193 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.619 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2196 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.620 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2202 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.621 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2202 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.622 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2208 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.623 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2208 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Z.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2220 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Z.__key.624 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2220 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Z.__key.625 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2220 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_class_Z.__key.626 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2220 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.627 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2223 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.628 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2226 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.629 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2232 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.630 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2232 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.631 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2238 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.632 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2238 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.633 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2241 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.634 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2244 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.635 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2250 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.636 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2250 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.637 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2256 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.638 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2256 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @print_testname._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2265 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.639 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2265 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.640 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2265 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dotest._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2274 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.641 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2274 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.642 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2274 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dotest._entry.643 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2280 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.644 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2280 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @dotest._entry.646 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2286 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.647 to i32), i32 54, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2286 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_lockdep to i32), i32 32, i32 64, i32 ptrtoint (ptr @___asan_gen_.2287 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2502 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_A to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2290 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2505 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_A to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2293 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2508 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_A to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2296 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2514 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_A to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2299 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2520 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_A to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.2302 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2526 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_B to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2305 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2529 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_B to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2308 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2532 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_B to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2311 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2538 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_B to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2314 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2544 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_B to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.2317 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2550 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_C to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2320 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2553 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_C to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2323 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2556 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_C to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2326 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2562 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_C to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2329 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2568 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_C to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.2332 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2574 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @lock_D to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2335 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2577 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwlock_D to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2338 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2580 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @mutex_D to i32), i32 92, i32 128, i32 ptrtoint (ptr @___asan_gen_.2341 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2586 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rwsem_D to i32), i32 96, i32 128, i32 ptrtoint (ptr @___asan_gen_.2344 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2592 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @rtmutex_D to i32), i32 84, i32 128, i32 ptrtoint (ptr @___asan_gen_.2347 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2598 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @t to i32), i32 64, i32 96, i32 ptrtoint (ptr @___asan_gen_.2350 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2352 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @t2 to i32), i32 64, i32 96, i32 ptrtoint (ptr @___asan_gen_.2353 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2355 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @o to i32), i32 100, i32 160, i32 ptrtoint (ptr @___asan_gen_.2356 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2358 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @o2 to i32), i32 100, i32 160, i32 ptrtoint (ptr @___asan_gen_.2359 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2361 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @o3 to i32), i32 100, i32 160, i32 ptrtoint (ptr @___asan_gen_.2362 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2364 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @raw_lock_A to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2365 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2601 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @raw_lock_B to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2368 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2604 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.649 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.650 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.651 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.652 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.653 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.654 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.655 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.656 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2397 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.657 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.658 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.659 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.660 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.661 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.662 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.663 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.664 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.665 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2424 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.666 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.667 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.668 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.669 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.670 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.671 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.672 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.673 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.674 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2451 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.675 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.676 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.677 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.678 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.679 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.680 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.681 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.682 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.683 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2478 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.684 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2484 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.685 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2484 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.686 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2490 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.687 to i32), i32 12, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2490 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @reset_locks.__key.688 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2496 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.689 to i32), i32 305, i32 384, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2496 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.690 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2502 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.691 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2502 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.692 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2505 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.693 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2508 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.694 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2514 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.695 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2514 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.696 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2520 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.697 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2520 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.698 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2526 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.699 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2526 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.700 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2529 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.701 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2532 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.702 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2538 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.703 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2538 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.704 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2544 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.705 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2544 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.706 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2550 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.707 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2550 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.708 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2553 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.709 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2556 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.710 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2562 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.711 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2562 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.712 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2568 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.713 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2568 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.714 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2574 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.715 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2574 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.716 to i32), i32 7, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2577 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.717 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2580 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.718 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2586 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.719 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2586 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.720 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2592 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.721 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2592 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.722 to i32), i32 28, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2598 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.723 to i32), i32 10, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2598 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.724 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2601 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.725 to i32), i32 11, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2604 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_spin.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2607 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_wlock.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2610 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_rlock.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2613 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_mutex.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2616 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_wsem.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2619 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_rsem.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2622 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @init_held_rtmutex.__key to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2623 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2625 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2631 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.728 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2631 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.729 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2637 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.730 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2637 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.732 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2643 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.733 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2643 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.735 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2646 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.736 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2649 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.738 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2652 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.739 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2655 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.741 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2658 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.742 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2661 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.744 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2664 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.745 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2667 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.747 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2670 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.748 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2673 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.750 to i32), i32 23, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2676 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.751 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2679 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.753 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2682 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.754 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2685 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.756 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2691 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.757 to i32), i32 57, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2691 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.759 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2697 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.760 to i32), i32 58, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2697 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.762 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2700 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.764 to i32), i32 8, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2703 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.765 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2706 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.767 to i32), i32 4, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2709 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.768 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2712 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.770 to i32), i32 6, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2715 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.771 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2718 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.773 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2721 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @ww_tests._entry.774 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2724 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.776 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2730 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.777 to i32), i32 2, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2730 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.778 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2736 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.779 to i32), i32 22, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2736 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.780 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2739 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.781 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2742 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2751 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.782 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2751 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.783 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2751 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry.784 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2757 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.785 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2757 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry.787 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2760 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.789 to i32), i32 16, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2763 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry.790 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2766 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.792 to i32), i32 14, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2769 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry.793 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2772 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.795 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2775 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @fs_reclaim_tests._entry.796 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2778 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.798 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2781 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2787 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.799 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2787 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.800 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2793 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.801 to i32), i32 26, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2793 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.803 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2796 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.805 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2802 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.806 to i32), i32 64, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2802 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.808 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2805 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.810 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2808 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.811 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2811 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.813 to i32), i32 34, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2814 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.814 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2817 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.816 to i32), i32 19, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2820 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.817 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2823 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.819 to i32), i32 15, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2826 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.820 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2829 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.822 to i32), i32 18, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2832 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.823 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2835 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.825 to i32), i32 21, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2838 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.826 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2841 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.828 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2844 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.829 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2847 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.831 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2850 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.832 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2853 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.834 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2856 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @wait_context_tests._entry.835 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2859 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.837 to i32), i32 25, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2865 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.838 to i32), i32 44, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2865 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.839 to i32), i32 42, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2868 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.840 to i32), i32 47, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2871 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.841 to i32), i32 45, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2874 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.842 to i32), i32 50, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2877 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.843 to i32), i32 48, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2880 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2886 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.844 to i32), i32 17, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2886 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry.845 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2892 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.846 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2892 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry.848 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2895 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.850 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2898 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry.851 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2901 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.853 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2904 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry.854 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2907 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.856 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2910 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @local_lock_tests._entry.857 to i32), i32 24, i32 64, i32 ptrtoint (ptr @___asan_gen_.2911 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2913 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.859 to i32), i32 36, i32 96, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2919 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.860 to i32), i32 9, i32 32, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2919 to i32), i32 -1 }, { i32, i32, i32, i32, i32, i32, i32, i32 } { i32 ptrtoint (ptr @.str.861 to i32), i32 20, i32 64, i32 ptrtoint (ptr @___asan_gen_.2920 to i32), i32 ptrtoint (ptr @___asan_gen_.2912 to i32), i32 0, i32 ptrtoint (ptr @___asan_gen_.2922 to i32), i32 -1 }]
@llvm.used = appending global [2 x ptr] [ptr @asan.module_ctor, ptr @asan.module_dtor], section "llvm.metadata"
@llvm.global_ctors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_ctor, ptr null }]
@llvm.global_dtors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 1, ptr @asan.module_dtor, ptr null }]

; Function Attrs: cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync)
define internal i32 @setup_debug_locks_verbose(ptr noundef %str) #0 section ".init.text" align 64 {
entry:
  %str.addr = alloca ptr, align 4
  call void @__sanitizer_cov_trace_pc() #10
  %0 = ptrtoint ptr %str.addr to i32
  call void @__asan_store4_noabort(i32 %0)
  store ptr %str, ptr %str.addr, align 4
  %call = call i32 @get_option(ptr noundef nonnull %str.addr, ptr noundef nonnull @debug_locks_verbose) #11
  ret i32 1
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define dso_local void @locking_selftest() local_unnamed_addr #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %0 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %0)
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %do.end, label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str) #12
  %call4 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.4) #12
  %call8 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str) #12
  br label %return

if.end:                                           ; preds = %entry
  store i32 1, ptr @force_read_lock_recursive, align 4
  %call12 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.9) #12
  %call16 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.12) #12
  %call20 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.15) #12
  %call24 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.18) #12
  %call28 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  tail call fastcc void @init_shared_classes()
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  tail call void @lockdep_set_selftest_task(ptr noundef %4) #11
  %call.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.23) #12
  tail call fastcc void @dotest(ptr noundef nonnull @AA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @AA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call33 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i880 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.27) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call37 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i881 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.30) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call41 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i882 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.33) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCABC_rtmutex, i32 noundef 0, i32 noundef 32)
  %call45 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i883 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.36) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABBCCDDA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call49 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i884 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.39) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBDDA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call53 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i885 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.42) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_rlock, i32 noundef 1, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @ABCDBCDA_rtmutex, i32 noundef 0, i32 noundef 32)
  %call57 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i886 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.45) #12
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_rlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @double_unlock_rtmutex, i32 noundef 0, i32 noundef 32)
  %call61 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i887 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.48) #12
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_spin, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_wlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_rlock, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_mutex, i32 noundef 0, i32 noundef 4)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_wsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_rsem, i32 noundef 0, i32 noundef 8)
  tail call fastcc void @dotest(ptr noundef nonnull @init_held_rtmutex, i32 noundef 0, i32 noundef 32)
  %call65 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call69 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call.i888 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.53) #12
  %call73 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_AA1, i32 noundef 1, i32 noundef 2)
  %call77 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rsem_AA1, i32 noundef 0, i32 noundef 8)
  %call81 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i889 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.61) #12
  %call85 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_AA1B, i32 noundef 1, i32 noundef 2)
  %call89 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rsem_AA1B, i32 noundef 0, i32 noundef 8)
  %call93 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i890 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.68) #12
  %call97 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_AA2, i32 noundef 0, i32 noundef 2)
  %call101 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rsem_AA2, i32 noundef 0, i32 noundef 8)
  %call105 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i891 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.75) #12
  %call109 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_AA3, i32 noundef 0, i32 noundef 2)
  %call113 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rsem_AA3, i32 noundef 0, i32 noundef 8)
  %call117 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i892 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.82) #12
  %call121 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_ABBA1, i32 noundef 0, i32 noundef 2)
  %call125 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rwsem_ABBA1, i32 noundef 0, i32 noundef 8)
  %call.i893 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.87) #12
  %call129 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_ABBA2, i32 noundef 1, i32 noundef 2)
  %call133 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rwsem_ABBA2, i32 noundef 0, i32 noundef 8)
  %call.i894 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.92) #12
  %call137 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_ABBA3, i32 noundef 0, i32 noundef 2)
  %call141 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rwsem_ABBA3, i32 noundef 0, i32 noundef 8)
  %call.i895 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.97) #12
  %call145 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @rlock_chaincache_ABBA1, i32 noundef 0, i32 noundef 2)
  %call.i896 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.100) #12
  %call149 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_123, i32 noundef 0, i32 noundef 2)
  %call153 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i897 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.105) #12
  %call157 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_132, i32 noundef 0, i32 noundef 2)
  %call161 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i898 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.110) #12
  %call165 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_213, i32 noundef 0, i32 noundef 2)
  %call169 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i899 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.115) #12
  %call173 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_231, i32 noundef 0, i32 noundef 2)
  %call177 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i900 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.120) #12
  %call181 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_312, i32 noundef 0, i32 noundef 2)
  %call185 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i901 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.125) #12
  %call189 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_W2R3_W3R1_321, i32 noundef 0, i32 noundef 2)
  %call193 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i902 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.130) #12
  %call197 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_123, i32 noundef 0, i32 noundef 2)
  %call201 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i903 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.135) #12
  %call205 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_132, i32 noundef 0, i32 noundef 2)
  %call209 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i904 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.140) #12
  %call213 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_213, i32 noundef 0, i32 noundef 2)
  %call217 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i905 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.145) #12
  %call221 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_231, i32 noundef 0, i32 noundef 2)
  %call225 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i906 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.150) #12
  %call229 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_312, i32 noundef 0, i32 noundef 2)
  %call233 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i907 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.155) #12
  %call237 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_W3R1_321, i32 noundef 0, i32 noundef 2)
  %call241 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i908 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.160) #12
  %call245 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_123, i32 noundef 1, i32 noundef 2)
  %call249 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i909 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.165) #12
  %call253 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_132, i32 noundef 1, i32 noundef 2)
  %call257 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i910 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.170) #12
  %call261 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_213, i32 noundef 1, i32 noundef 2)
  %call265 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i911 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.175) #12
  %call269 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_231, i32 noundef 1, i32 noundef 2)
  %call273 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i912 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.180) #12
  %call277 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_312, i32 noundef 1, i32 noundef 2)
  %call281 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i913 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.185) #12
  %call285 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1W2_R2R3_R3W1_321, i32 noundef 1, i32 noundef 2)
  %call289 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i914 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.190) #12
  %call293 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_123, i32 noundef 1, i32 noundef 2)
  %call297 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i915 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.195) #12
  %call301 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_132, i32 noundef 1, i32 noundef 2)
  %call305 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i916 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.200) #12
  %call309 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_213, i32 noundef 1, i32 noundef 2)
  %call313 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i917 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.205) #12
  %call317 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_231, i32 noundef 1, i32 noundef 2)
  %call321 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i918 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.210) #12
  %call325 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_312, i32 noundef 1, i32 noundef 2)
  %call329 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i919 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.215) #12
  %call333 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.55) #12
  tail call fastcc void @dotest(ptr noundef nonnull @W1R2_R2R3_W3W1_321, i32 noundef 1, i32 noundef 2)
  %call337 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call341 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call.i920 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.222) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_spin_12, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_wlock_12, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_rlock_12, i32 noundef 1, i32 noundef 2)
  %call345 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i921 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.225) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_spin_12, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_wlock_12, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_rlock_12, i32 noundef 1, i32 noundef 2)
  %call349 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i922 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.228) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_spin_21, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_wlock_21, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_hard_rlock_21, i32 noundef 1, i32 noundef 2)
  %call353 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i923 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.231) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_spin_21, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_wlock_21, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe1_soft_rlock_21, i32 noundef 1, i32 noundef 2)
  %call357 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i924 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.234) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_spin_12, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_wlock_12, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_rlock_12, i32 noundef 1, i32 noundef 2)
  %call361 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i925 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.237) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_spin_21, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_wlock_21, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2A_rlock_21, i32 noundef 1, i32 noundef 2)
  %call365 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i926 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.240) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_spin_12, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_wlock_12, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_rlock_12, i32 noundef 1, i32 noundef 2)
  %call369 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i927 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.243) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_spin_12, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_wlock_12, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_rlock_12, i32 noundef 1, i32 noundef 2)
  %call373 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i928 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.246) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_spin_21, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_wlock_21, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_hard_rlock_21, i32 noundef 1, i32 noundef 2)
  %call377 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i929 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.249) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_spin_21, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_wlock_21, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe2B_soft_rlock_21, i32 noundef 1, i32 noundef 2)
  %call381 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i930 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.252) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_123, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call385 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i931 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.255) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_123, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call389 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i932 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.258) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_132, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call393 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i933 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.261) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_132, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call397 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i934 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.264) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_213, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call401 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i935 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.267) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_213, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call405 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i936 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.270) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_231, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call409 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i937 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.273) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_231, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call413 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i938 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.276) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_312, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call417 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i939 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.279) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_312, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call421 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i940 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.282) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_spin_321, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call425 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i941 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.285) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_spin_321, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe3_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call429 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i942 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.288) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_123, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call433 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i943 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.291) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_123, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call437 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i944 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.294) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_132, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call441 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i945 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.297) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_132, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call445 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i946 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.300) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_213, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call449 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i947 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.303) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_213, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call453 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i948 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.306) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_231, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call457 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i949 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.309) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_231, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call461 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i950 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.312) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_312, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call465 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i951 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.315) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_312, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call469 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i952 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.318) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_spin_321, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call473 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i953 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.321) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_spin_321, i32 noundef 0, i32 noundef 1)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irqsafe4_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call477 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i954 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.324) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_123, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call481 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i955 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.327) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_123, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call485 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i956 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.330) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_132, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call489 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i957 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.333) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_132, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call493 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i958 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.336) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_213, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call497 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i959 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.339) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_213, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call501 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i960 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.342) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_231, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call505 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i961 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.345) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_231, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call509 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i962 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.348) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_312, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call513 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i963 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.351) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_312, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call517 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i964 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.354) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_spin_321, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call521 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i965 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.357) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_spin_321, i32 noundef 0, i32 noundef 3)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_inversion_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call525 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i966 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.360) #12
  %call529 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call533 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i967 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.366) #12
  %call537 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call541 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i968 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.371) #12
  %call545 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call549 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i969 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.376) #12
  %call553 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call557 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i970 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.381) #12
  %call561 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call565 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i971 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.386) #12
  %call569 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call573 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i972 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.391) #12
  %call577 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call581 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i973 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.396) #12
  %call585 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call589 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i974 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.401) #12
  %call593 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call597 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i975 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.406) #12
  %call601 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call605 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i976 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.411) #12
  %call609 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call613 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i977 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.416) #12
  %call617 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call621 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i978 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.421) #12
  %call625 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call629 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i979 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.426) #12
  %call633 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call637 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i980 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.431) #12
  %call641 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call645 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i981 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.436) #12
  %call649 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call653 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i982 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.441) #12
  %call657 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call661 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i983 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.446) #12
  %call665 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call669 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i984 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.451) #12
  %call673 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call677 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i985 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.456) #12
  %call681 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call685 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i986 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.461) #12
  %call689 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call693 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i987 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.466) #12
  %call697 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call701 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i988 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.471) #12
  %call705 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call709 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i989 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.476) #12
  %call713 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion2_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call717 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i990 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.481) #12
  %call721 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_123, i32 noundef 1, i32 noundef 2)
  %call725 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i991 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.486) #12
  %call729 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_123, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_123, i32 noundef 1, i32 noundef 2)
  %call733 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i992 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.491) #12
  %call737 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_132, i32 noundef 1, i32 noundef 2)
  %call741 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i993 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.496) #12
  %call745 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_132, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_132, i32 noundef 1, i32 noundef 2)
  %call749 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i994 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.501) #12
  %call753 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_213, i32 noundef 1, i32 noundef 2)
  %call757 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i995 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.506) #12
  %call761 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_213, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_213, i32 noundef 1, i32 noundef 2)
  %call765 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i996 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.511) #12
  %call769 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_231, i32 noundef 1, i32 noundef 2)
  %call773 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i997 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.516) #12
  %call777 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_231, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_231, i32 noundef 1, i32 noundef 2)
  %call781 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i998 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.521) #12
  %call785 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_312, i32 noundef 1, i32 noundef 2)
  %call789 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i999 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.526) #12
  %call793 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_312, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_312, i32 noundef 1, i32 noundef 2)
  %call797 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1000 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.531) #12
  %call801 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_hard_rlock_321, i32 noundef 1, i32 noundef 2)
  %call805 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1001 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.536) #12
  %call809 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.362) #12
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_wlock_321, i32 noundef 0, i32 noundef 2)
  tail call fastcc void @dotest(ptr noundef nonnull @irq_read_recursion3_soft_rlock_321, i32 noundef 1, i32 noundef 2)
  %call813 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1002 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call4.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.730) #12
  %call8.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.733) #12
  %call.i.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.735) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_fail_acquire, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_normal, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_unneeded_slow, i32 noundef 0, i32 noundef 16) #11
  %call12.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i65.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.738) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_two_contexts, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_diff_class, i32 noundef 0, i32 noundef 16) #11
  %call16.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i66.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.741) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_done_twice, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_unlock_twice, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_fini_early, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_lock_after_done, i32 noundef 0, i32 noundef 16) #11
  %call20.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i67.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.744) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_object_unlock_twice, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_object_lock_unbalanced, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_object_lock_stale_context, i32 noundef 0, i32 noundef 16) #11
  %call24.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i68.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.747) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_normal, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_normal_slow, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_no_unlock, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_no_unlock_slow, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_more, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_more_slow, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_more_edeadlk, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_more_edeadlk_slow, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_wrong, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_edeadlk_acquire_wrong_slow, i32 noundef 0, i32 noundef 16) #11
  %call28.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i69.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.750) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_spin_nest_unlocked, i32 noundef 0, i32 noundef 16) #11
  %call32.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i70.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.753) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_spin_nest_lock, i32 noundef 1, i32 noundef 16) #11
  %call36.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call40.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.757) #12
  %call44.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.760) #12
  %call48.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.757) #12
  %call.i71.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.764) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_block, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_try, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_context_context, i32 noundef 1, i32 noundef 16) #11
  %call52.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i72.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.767) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_try_block, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_try_try, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_try_context, i32 noundef 0, i32 noundef 16) #11
  %call56.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i73.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.770) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_block_block, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_block_try, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_block_context, i32 noundef 0, i32 noundef 16) #11
  %call60.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i74.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.773) #12
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_spin_block, i32 noundef 0, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_spin_try, i32 noundef 1, i32 noundef 16) #11
  tail call fastcc void @dotest(ptr noundef nonnull @ww_test_spin_context, i32 noundef 0, i32 noundef 16) #11
  %call64.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  store i32 0, ptr @force_read_lock_recursive, align 4
  %call.i1003 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.782) #12
  %call4.i1004 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.785) #12
  %call8.i1005 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.782) #12
  %call.i.i1006 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.789) #12
  tail call fastcc void @dotest(ptr noundef nonnull @fs_reclaim_correct_nesting, i32 noundef 1, i32 noundef 0) #11
  %call12.i1007 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i21.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.792) #12
  tail call fastcc void @dotest(ptr noundef nonnull @fs_reclaim_wrong_nesting, i32 noundef 0, i32 noundef 0) #11
  %call16.i1008 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i22.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.795) #12
  tail call fastcc void @dotest(ptr noundef nonnull @fs_reclaim_protected_nesting, i32 noundef 1, i32 noundef 0) #11
  %call20.i1009 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1010 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call4.i1011 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.801) #12
  %call8.i1012 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call12.i1013 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.806) #12
  %call16.i1014 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call.i.i1015 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.810) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_HARDIRQ, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_HARDIRQ, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_HARDIRQ, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_HARDIRQ, i32 noundef 0, i32 noundef 4) #11
  %call20.i1016 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i53.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.813) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_NOTTHREADED_HARDIRQ, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_NOTTHREADED_HARDIRQ, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_NOTTHREADED_HARDIRQ, i32 noundef 0, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_NOTTHREADED_HARDIRQ, i32 noundef 0, i32 noundef 4) #11
  %call24.i1017 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i54.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.816) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_SOFTIRQ, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_SOFTIRQ, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_SOFTIRQ, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_SOFTIRQ, i32 noundef 0, i32 noundef 4) #11
  %call28.i1018 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i55.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.819) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_RCU, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_RCU, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_RCU, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_RCU, i32 noundef 0, i32 noundef 4) #11
  %call32.i1019 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i56.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.822) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_RCU_BH, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_RCU_BH, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_RCU_BH, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_RCU_BH, i32 noundef 0, i32 noundef 4) #11
  %call36.i1020 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i57.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.825) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_RCU_SCHED, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_RCU_SCHED, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_RCU_SCHED, i32 noundef 0, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_RCU_SCHED, i32 noundef 0, i32 noundef 4) #11
  %call40.i1021 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i58.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.828) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_RAW_SPINLOCK, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_RAW_SPINLOCK, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_RAW_SPINLOCK, i32 noundef 0, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_RAW_SPINLOCK, i32 noundef 0, i32 noundef 4) #11
  %call44.i1022 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i59.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.831) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_SPINLOCK, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_SPINLOCK, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_SPINLOCK, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_SPINLOCK, i32 noundef 0, i32 noundef 4) #11
  %call48.i1023 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i60.i = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.834) #12
  tail call fastcc void @dotest(ptr noundef nonnull @RCU_in_MUTEX, i32 noundef 1, i32 noundef 2) #11
  tail call fastcc void @dotest(ptr noundef nonnull @RAW_SPINLOCK_in_MUTEX, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @SPINLOCK_in_MUTEX, i32 noundef 1, i32 noundef 1) #11
  tail call fastcc void @dotest(ptr noundef nonnull @MUTEX_in_MUTEX, i32 noundef 1, i32 noundef 4) #11
  %call52.i1024 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1025 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.21) #12
  %call4.i1026 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.846) #12
  %call8.i1027 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.733) #12
  %call.i.i1028 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.850) #12
  tail call fastcc void @dotest(ptr noundef nonnull @local_lock_2, i32 noundef 1, i32 noundef 64) #11
  %call12.i1029 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i21.i1030 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.853) #12
  tail call fastcc void @dotest(ptr noundef nonnull @local_lock_3A, i32 noundef 1, i32 noundef 64) #11
  %call16.i1031 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i22.i1032 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.856) #12
  tail call fastcc void @dotest(ptr noundef nonnull @local_lock_3B, i32 noundef 0, i32 noundef 64) #11
  %call20.i1033 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %call.i1034 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.639, ptr noundef nonnull @.str.541) #12
  tail call fastcc void @dotest(ptr noundef nonnull @hardirq_deadlock_softirq_not_deadlock, i32 noundef 0, i32 noundef 128)
  %call817 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.25) #12
  %5 = load i32, ptr @unexpected_testcase_failures, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %5)
  %tobool818.not = icmp eq i32 %5, 0
  br i1 %tobool818.not, label %do.end866, label %do.end821

do.end821:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %call823 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.545) #12
  call void @__asan_store4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  store i32 0, ptr @debug_locks, align 4
  %6 = load i32, ptr @unexpected_testcase_failures, align 4
  %7 = load i32, ptr @testcase_total, align 4
  %call827 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.548, i32 noundef %6, i32 noundef %7) #12
  %call831 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.545) #12
  br label %if.end879

do.end866:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %call868 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.570) #12
  %8 = load i32, ptr @testcase_successes, align 4
  %call872 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.573, i32 noundef %8) #12
  %call876 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.576) #12
  call void @__asan_store4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  store i32 1, ptr @debug_locks, align 4
  br label %if.end879

if.end879:                                        ; preds = %do.end866, %do.end821
  tail call void @lockdep_set_selftest_task(ptr noundef null) #11
  call void @__asan_store4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  store i32 0, ptr @debug_locks_silent, align 4
  br label %return

return:                                           ; preds = %if.end879, %do.end
  ret void
}

; Function Attrs: cold null_pointer_is_valid
declare dso_local i32 @_printk(ptr noundef, ...) local_unnamed_addr #2

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @init_shared_classes() unnamed_addr #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_X1, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_X) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_X2, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_X) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_Y1, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_Y) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_Y2, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_Y) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_Z1, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_Z) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_Z2, ptr noundef nonnull @__func__.init_shared_classes, ptr noundef nonnull @init_shared_classes.rt_Z) #11
  tail call fastcc void @init_class_X(ptr noundef nonnull @lock_X1, ptr noundef nonnull @rwlock_X1, ptr noundef nonnull @mutex_X1, ptr noundef nonnull @rwsem_X1)
  tail call fastcc void @init_class_X(ptr noundef nonnull @lock_X2, ptr noundef nonnull @rwlock_X2, ptr noundef nonnull @mutex_X2, ptr noundef nonnull @rwsem_X2)
  tail call fastcc void @init_class_Y(ptr noundef nonnull @lock_Y1, ptr noundef nonnull @rwlock_Y1, ptr noundef nonnull @mutex_Y1, ptr noundef nonnull @rwsem_Y1)
  tail call fastcc void @init_class_Y(ptr noundef nonnull @lock_Y2, ptr noundef nonnull @rwlock_Y2, ptr noundef nonnull @mutex_Y2, ptr noundef nonnull @rwsem_Y2)
  tail call fastcc void @init_class_Z(ptr noundef nonnull @lock_Z1, ptr noundef nonnull @rwlock_Z1, ptr noundef nonnull @mutex_Z1, ptr noundef nonnull @rwsem_Z1)
  tail call fastcc void @init_class_Z(ptr noundef nonnull @lock_Z2, ptr noundef nonnull @rwlock_Z2, ptr noundef nonnull @mutex_Z2, ptr noundef nonnull @rwsem_Z2)
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_set_selftest_task(ptr noundef) local_unnamed_addr #3

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @dotest(ptr nocapture noundef readonly %testcase_fn, i32 noundef %expected, i32 noundef %lockclass_mask) unnamed_addr #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i, align 4
  %4 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i = and i32 %4, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i)
  %tobool.not = icmp eq i32 %and.i, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end20, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end20:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1440, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end20, %entry.if.end_crit_edge
  %5 = load i32, ptr @debug_locks_verbose, align 4
  %and = and i32 %5, %lockclass_mask
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool33.not = icmp eq i32 %and, 0
  %lnot.ext35 = zext i1 %tobool33.not to i32
  call void @__asan_store4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  store i32 %lnot.ext35, ptr @debug_locks_silent, align 4
  tail call void %testcase_fn() #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %6 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_cmp4(i32 %6, i32 %expected)
  %cmp36.not = icmp eq i32 %6, %expected
  %testcase_successes.unexpected_testcase_failures = select i1 %cmp36.not, ptr @testcase_successes, ptr @unexpected_testcase_failures
  %.str.644..str.641 = select i1 %cmp36.not, ptr @.str.644, ptr @.str.641
  %7 = ptrtoint ptr %testcase_successes.unexpected_testcase_failures to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %testcase_successes.unexpected_testcase_failures, align 4
  %inc44 = add i32 %8, 1
  store i32 %inc44, ptr %testcase_successes.unexpected_testcase_failures, align 4
  %call49 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull %.str.644..str.641) #12
  %9 = load i32, ptr @testcase_total, align 4
  %inc51 = add i32 %9, 1
  store i32 %inc51, ptr @testcase_total, align 4
  %10 = load i32, ptr @debug_locks_verbose, align 4
  %and52 = and i32 %10, %lockclass_mask
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and52)
  %tobool53.not = icmp eq i32 %and52, 0
  br i1 %tobool53.not, label %if.end.if.end60_crit_edge, label %do.end57

if.end.if.end60_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end60

do.end57:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %11 = load i32, ptr @debug_locks, align 4
  %call59 = tail call i32 (ptr, ...) @_printk(ptr noundef nonnull @.str.647, i32 noundef %lockclass_mask, i32 noundef %11, i32 noundef %expected) #12
  br label %if.end60

if.end60:                                         ; preds = %do.end57, %if.end.if.end60_crit_edge
  %12 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_store4_noabort(i32 %14)
  store volatile i32 %3, ptr %preempt_count.i.i, align 4
  %15 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i75 = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i75 to ptr
  %preempt_count.i76 = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i76 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i76, align 4
  %and62 = and i32 %18, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and62)
  %tobool63.not = icmp eq i32 %and62, 0
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i78 = and i32 %19, -16384
  %20 = inttoptr i32 %and.i78 to ptr
  %task68 = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 2
  %21 = ptrtoint ptr %task68 to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %task68, align 8
  %softirqs_enabled69 = getelementptr inbounds %struct.task_struct, ptr %22, i32 0, i32 138
  %. = zext i1 %tobool63.not to i32
  %23 = ptrtoint ptr %softirqs_enabled69 to i32
  call void @__asan_store4_noabort(i32 %23)
  store i32 %., ptr %softirqs_enabled69, align 32
  %24 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i.i79 = and i32 %24, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i.i79)
  %tobool.not.i = icmp eq i32 %and.i.i.i79, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not.i, label %if.then.i, label %if.end60.reset_locks.exit_crit_edge

if.end60.reset_locks.exit_crit_edge:              ; preds = %if.end60
  call void @__sanitizer_cov_trace_pc() #10
  br label %reset_locks.exit

if.then.i:                                        ; preds = %if.end60
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %reset_locks.exit

reset_locks.exit:                                 ; preds = %if.then.i, %if.end60.reset_locks.exit_crit_edge
  tail call void @lockdep_free_key_range(ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 1) #11
  tail call void @lockdep_free_key_range(ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 2), i32 noundef 1) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_A, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_A, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_A, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_A, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_A, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_B, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_B, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_B, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_B, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_B, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_C, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_C, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_C, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_C, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_C, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_D, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_D, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_D, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_D, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_D, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_X1, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_X1, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_X1, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_X1, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_X1, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_X2, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_X2, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_X2, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_X2, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_X2, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_Y1, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_Y1, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_Y1, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_Y1, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_Y1, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_Y2, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_Y2, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_Y2, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_Y2, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_Y2, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_Z1, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_Z1, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_Z1, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_Z1, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_Z1, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_Z2, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rwlock_t, ptr @rwlock_Z2, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.mutex, ptr @mutex_Z2, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rw_semaphore, ptr @rwsem_Z2, i32 0, i32 6)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.rt_mutex, ptr @rtmutex_Z2, i32 0, i32 1)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 8)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 0, i32 5)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.raw_spinlock, ptr @raw_lock_A, i32 0, i32 4)) #11
  tail call void @lockdep_reset_lock(ptr noundef getelementptr inbounds (%struct.raw_spinlock, ptr @raw_lock_B, i32 0, i32 4)) #11
  %25 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i80 = and i32 %25, -16384
  %26 = inttoptr i32 %and.i.i80 to ptr
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %26, i32 0, i32 3
  %27 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %28
  %29 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %arrayidx.i, align 4
  %add.i = add i32 %30, ptrtoint (ptr @local_A to i32)
  %31 = inttoptr i32 %add.i to ptr
  tail call void @lockdep_reset_lock(ptr noundef %31) #11
  tail call void @lockdep_reset() #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @lock_A, ptr noundef nonnull @.str.649, ptr noundef nonnull @reset_locks.__key, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_A, ptr noundef nonnull @.str.651, ptr noundef nonnull @reset_locks.__key.650) #11
  tail call void @__mutex_init(ptr noundef nonnull @mutex_A, ptr noundef nonnull @.str.653, ptr noundef nonnull @reset_locks.__key.652) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_A, ptr noundef nonnull @.str.655, ptr noundef nonnull @reset_locks.__key.654) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_A, ptr noundef nonnull @__func__.reset_locks, ptr noundef nonnull @reset_locks.__key.656) #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @lock_B, ptr noundef nonnull @.str.658, ptr noundef nonnull @reset_locks.__key.657, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_B, ptr noundef nonnull @.str.660, ptr noundef nonnull @reset_locks.__key.659) #11
  tail call void @__mutex_init(ptr noundef nonnull @mutex_B, ptr noundef nonnull @.str.662, ptr noundef nonnull @reset_locks.__key.661) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_B, ptr noundef nonnull @.str.664, ptr noundef nonnull @reset_locks.__key.663) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_B, ptr noundef nonnull @__func__.reset_locks, ptr noundef nonnull @reset_locks.__key.665) #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @lock_C, ptr noundef nonnull @.str.667, ptr noundef nonnull @reset_locks.__key.666, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_C, ptr noundef nonnull @.str.669, ptr noundef nonnull @reset_locks.__key.668) #11
  tail call void @__mutex_init(ptr noundef nonnull @mutex_C, ptr noundef nonnull @.str.671, ptr noundef nonnull @reset_locks.__key.670) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_C, ptr noundef nonnull @.str.673, ptr noundef nonnull @reset_locks.__key.672) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_C, ptr noundef nonnull @__func__.reset_locks, ptr noundef nonnull @reset_locks.__key.674) #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @lock_D, ptr noundef nonnull @.str.676, ptr noundef nonnull @reset_locks.__key.675, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_D, ptr noundef nonnull @.str.678, ptr noundef nonnull @reset_locks.__key.677) #11
  tail call void @__mutex_init(ptr noundef nonnull @mutex_D, ptr noundef nonnull @.str.680, ptr noundef nonnull @reset_locks.__key.679) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_D, ptr noundef nonnull @.str.682, ptr noundef nonnull @reset_locks.__key.681) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_D, ptr noundef nonnull @__func__.reset_locks, ptr noundef nonnull @reset_locks.__key.683) #11
  tail call fastcc void @init_shared_classes() #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @raw_lock_A, ptr noundef nonnull @.str.685, ptr noundef nonnull @reset_locks.__key.684, i16 noundef signext 2) #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @raw_lock_B, ptr noundef nonnull @.str.687, ptr noundef nonnull @reset_locks.__key.686, i16 noundef signext 2) #11
  %32 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %cpu.i, align 4
  %arrayidx91.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %33
  %34 = ptrtoint ptr %arrayidx91.i to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %arrayidx91.i, align 4
  %add92.i = add i32 %35, ptrtoint (ptr @local_A to i32)
  %36 = inttoptr i32 %add92.i to ptr
  tail call void @debug_check_no_locks_freed(ptr noundef %36, i32 noundef 32) #11
  %37 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %cpu.i, align 4
  %arrayidx101.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %38
  %39 = ptrtoint ptr %arrayidx101.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load i32, ptr %arrayidx101.i, align 4
  %add102.i = add i32 %40, ptrtoint (ptr @local_A to i32)
  %41 = inttoptr i32 %add102.i to ptr
  tail call void @lockdep_init_map_type(ptr noundef %41, ptr noundef nonnull @.str.689, ptr noundef nonnull @reset_locks.__key.688, i32 noundef 0, i8 noundef zeroext 3, i8 noundef zeroext 0, i8 noundef zeroext 1) #11
  %42 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load i32, ptr %cpu.i, align 4
  %arrayidx111.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %43
  %44 = ptrtoint ptr %arrayidx111.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load i32, ptr %arrayidx111.i, align 4
  %add112.i = add i32 %45, ptrtoint (ptr @local_A to i32)
  %46 = inttoptr i32 %add112.i to ptr
  %owner.i.i = getelementptr inbounds %struct.local_lock_t, ptr %46, i32 0, i32 1
  %47 = ptrtoint ptr %owner.i.i to i32
  call void @__asan_store4_noabort(i32 %47)
  store ptr null, ptr %owner.i.i, align 4
  %48 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 4), align 4
  tail call void @__mutex_init(ptr noundef nonnull @o, ptr noundef %48, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 2)) #11
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 2), align 4
  %49 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 4), align 4
  tail call void @__mutex_init(ptr noundef nonnull @o2, ptr noundef %49, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 2)) #11
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 2), align 4
  %50 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 4), align 4
  tail call void @__mutex_init(ptr noundef nonnull @o3, ptr noundef %50, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 2)) #11
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 1), align 4
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 2), align 4
  %51 = call ptr @memset(ptr @t, i32 0, i32 64)
  %52 = call ptr @memset(ptr @t2, i32 0, i32 64)
  %53 = call ptr @memset(ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 0, i32 16)
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_X1, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_X2, i32 noundef 0) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @AA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_X1, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_X2, i32 noundef 0) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCABC_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABBCCDDA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBDDA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_C) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_D) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_C, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_C) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_D, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_C) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_B) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_D) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ABCDBCDA_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_B, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_C, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_C) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_B) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_D, i32 noundef 0) #11
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_D) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @double_unlock_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  tail call void @rt_mutex_unlock(ptr noundef nonnull @rtmutex_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_spin() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @__raw_spin_lock_init(ptr noundef nonnull @lock_A, ptr noundef nonnull @.str.649, ptr noundef nonnull @init_held_spin.__key, i16 noundef signext 3) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_wlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_A, ptr noundef nonnull @.str.651, ptr noundef nonnull @init_held_wlock.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_rlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @__rwlock_init(ptr noundef nonnull @rwlock_A, ptr noundef nonnull @.str.651, ptr noundef nonnull @init_held_rlock.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_mutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @__mutex_init(ptr noundef nonnull @mutex_A, ptr noundef nonnull @.str.653, ptr noundef nonnull @init_held_mutex.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_wsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_A) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_A, ptr noundef nonnull @.str.655, ptr noundef nonnull @init_held_wsem.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_rsem() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_A) #11
  tail call void @__init_rwsem(ptr noundef nonnull @rwsem_A, ptr noundef nonnull @.str.655, ptr noundef nonnull @init_held_rsem.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @init_held_rtmutex() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @rt_mutex_lock_nested(ptr noundef nonnull @rtmutex_A, i32 noundef 0) #11
  tail call void @__rt_mutex_init(ptr noundef nonnull @rtmutex_A, ptr noundef nonnull @__func__.init_held_rtmutex, ptr noundef nonnull @init_held_rtmutex.__key) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_AA1() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rsem_AA1() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_AA1B() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rsem_AA1B() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_AA2() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rsem_AA2() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_AA3() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rsem_AA3() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_X2) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_ABBA1() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rwsem_ABBA1() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_ABBA2() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rwsem_ABBA2() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @down_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @up_read(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_ABBA3() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rwsem_ABBA3() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @down_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_Y1, i32 noundef 0) #11
  tail call void @down_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @up_write(ptr noundef nonnull @rwsem_X1) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @rlock_chaincache_ABBA1() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_W2R3_W3R1_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_W3R1_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1W2_R2R3_R3W1_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @W1R2_R2R3_W3W1_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Z1) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_X1) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_Y1) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_spin_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 809, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_wlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 815, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_rlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 812, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_spin_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 819, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_wlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 825, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_rlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 822, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_spin_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 809, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_wlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 815, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_hard_rlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 812, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_spin_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 819, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_wlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 825, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe1_soft_rlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 822, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_spin_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i54 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i54)
  %tobool.not = icmp eq i32 %and.i.i54, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 853, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  %15 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i55 = and i32 %15, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i55)
  %tobool43.not = icmp eq i32 %and.i.i55, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool43.not, label %if.then46, label %if.end24.if.end47_crit_edge

if.end24.if.end47_crit_edge:                      ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

if.then46:                                        ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end47

if.end47:                                         ; preds = %if.then46, %if.end24.if.end47_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_wlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i54 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i54)
  %tobool.not = icmp eq i32 %and.i.i54, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 856, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  %15 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i55 = and i32 %15, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i55)
  %tobool43.not = icmp eq i32 %and.i.i55, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool43.not, label %if.then46, label %if.end24.if.end47_crit_edge

if.end24.if.end47_crit_edge:                      ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

if.then46:                                        ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end47

if.end47:                                         ; preds = %if.then46, %if.end24.if.end47_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_rlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i54 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i54)
  %tobool.not = icmp eq i32 %and.i.i54, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 859, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  %15 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i55 = and i32 %15, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i55)
  %tobool43.not = icmp eq i32 %and.i.i55, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool43.not, label %if.then46, label %if.end24.if.end47_crit_edge

if.end24.if.end47_crit_edge:                      ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

if.then46:                                        ; preds = %if.end24
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end47

if.end47:                                         ; preds = %if.then46, %if.end24.if.end47_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_spin_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i52 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i52)
  %tobool.not = icmp eq i32 %and.i.i52, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_disable()
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i53 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i53)
  %tobool7.not = icmp eq i32 %and.i.i53, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 2
  %4 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 139
  %6 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %7, 1
  store i32 %inc, ptr %softirq_context, align 4
  %8 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %11, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool17.not = icmp eq i32 %and, 0
  br i1 %tobool17.not, label %do.end29, label %if.end11.if.end35_crit_edge, !prof !1227

if.end11.if.end35_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

do.end29:                                         ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 853, i32 noundef 9, ptr noundef null) #11
  br label %if.end35

if.end35:                                         ; preds = %do.end29, %if.end11.if.end35_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %12 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task, align 8
  %softirq_context45 = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 139
  %14 = ptrtoint ptr %softirq_context45 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %softirq_context45, align 4
  %dec = add i32 %15, -1
  store i32 %dec, ptr %softirq_context45, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_wlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i52 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i52)
  %tobool.not = icmp eq i32 %and.i.i52, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i53 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i53)
  %tobool7.not = icmp eq i32 %and.i.i53, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 2
  %4 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 139
  %6 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %7, 1
  store i32 %inc, ptr %softirq_context, align 4
  %8 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %11, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool17.not = icmp eq i32 %and, 0
  br i1 %tobool17.not, label %do.end29, label %if.end11.if.end35_crit_edge, !prof !1227

if.end11.if.end35_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

do.end29:                                         ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 856, i32 noundef 9, ptr noundef null) #11
  br label %if.end35

if.end35:                                         ; preds = %do.end29, %if.end11.if.end35_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %12 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task, align 8
  %softirq_context45 = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 139
  %14 = ptrtoint ptr %softirq_context45 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %softirq_context45, align 4
  %dec = add i32 %15, -1
  store i32 %dec, ptr %softirq_context45, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2A_rlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i52 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i52)
  %tobool.not = icmp eq i32 %and.i.i52, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i53 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i53)
  %tobool7.not = icmp eq i32 %and.i.i53, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 2
  %4 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %5, i32 0, i32 139
  %6 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %7, 1
  store i32 %inc, ptr %softirq_context, align 4
  %8 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %11, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool17.not = icmp eq i32 %and, 0
  br i1 %tobool17.not, label %do.end29, label %if.end11.if.end35_crit_edge, !prof !1227

if.end11.if.end35_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

do.end29:                                         ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 859, i32 noundef 9, ptr noundef null) #11
  br label %if.end35

if.end35:                                         ; preds = %do.end29, %if.end11.if.end35_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %12 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load ptr, ptr %task, align 8
  %softirq_context45 = getelementptr inbounds %struct.task_struct, ptr %13, i32 0, i32 139
  %14 = ptrtoint ptr %softirq_context45 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load i32, ptr %softirq_context45, align 4
  %dec = add i32 %15, -1
  store i32 %dec, ptr %softirq_context45, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_spin_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 887, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_wlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 893, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_rlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 890, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_spin_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 897, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_wlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 903, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_rlock_12() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 900, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_spin_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 887, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_wlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 893, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_hard_rlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 890, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_spin_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 897, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_wlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 903, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe2B_soft_rlock_21() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 900, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 935, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 941, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i96 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i96)
  %tobool.not = icmp eq i32 %and.i.i96, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 938, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i94 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i94 to ptr
  %preempt_count.i.i95 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i95 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i95, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i95, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 945, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 951, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe3_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 948, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 985, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 991, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 988, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 995, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1001, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irqsafe4_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 998, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1049, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1055, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1052, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_spin_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1059, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1065, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_inversion_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1062, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1232, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1229, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1240, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1237, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1280, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1277, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1288, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion2_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1285, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_123() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_132() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i107 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i107)
  %tobool.not = icmp eq i32 %and.i.i107, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i108 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i108)
  %tobool7.not = icmp eq i32 %and.i.i108, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i105 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i105 to ptr
  %preempt_count.i.i106 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i106 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i106, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i106, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_213() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_231() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_312() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1336, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_hard_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i109 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i109)
  %tobool.not = icmp eq i32 %and.i.i109, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add13 = add i32 %13, 1
  store i32 %add13, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then16, label %if.end.do.end20_crit_edge

if.end.do.end20_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end20

if.then16:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end20

do.end20:                                         ; preds = %if.then16, %if.end.do.end20_crit_edge
  %task22 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task22, align 8
  %hardirq_threaded28 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded28 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded28, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool32.not = icmp eq i32 %and, 0
  br i1 %tobool32.not, label %do.end45, label %do.end20.if.end51_crit_edge, !prof !1227

do.end20.if.end51_crit_edge:                      ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end51

do.end45:                                         ; preds = %do.end20
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1333, i32 noundef 9, ptr noundef null) #11
  br label %if.end51

if.end51:                                         ; preds = %do.end45, %do.end20.if.end51_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %26 = ptrtoint ptr %task22 to i32
  call void @__asan_load4_noabort(i32 %26)
  %27 = load ptr, ptr %task22, align 8
  tail call void @irqtime_account_irq(ptr noundef %27, i32 noundef 0) #11
  %28 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load i32, ptr %cpu, align 4
  %arrayidx78 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %29
  %30 = ptrtoint ptr %arrayidx78 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %arrayidx78, align 4
  %add79 = add i32 %31, ptrtoint (ptr @hardirq_context to i32)
  %32 = inttoptr i32 %add79 to ptr
  %33 = ptrtoint ptr %32 to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load i32, ptr %32, align 4
  %add80 = add i32 %34, -1
  store i32 %add80, ptr %32, align 4
  %35 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i107 = and i32 %35, -16384
  %36 = inttoptr i32 %and.i.i.i107 to ptr
  %preempt_count.i.i108 = getelementptr inbounds %struct.thread_info, ptr %36, i32 0, i32 1
  %37 = ptrtoint ptr %preempt_count.i.i108 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load volatile i32, ptr %preempt_count.i.i108, align 4
  %sub.i = add i32 %38, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i108, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  %39 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i110 = and i32 %39, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i110)
  %tobool95.not = icmp eq i32 %and.i.i110, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool95.not, label %if.then98, label %if.end51.if.end99_crit_edge

if.end51.if.end99_crit_edge:                      ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end99

if.then98:                                        ; preds = %if.end51
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end99

if.end99:                                         ; preds = %if.then98, %if.end51.if.end99_crit_edge
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_wlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1344, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @irq_read_recursion3_soft_rlock_321() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i41 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i41)
  %tobool.not = icmp eq i32 %and.i.i41, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool6.not = icmp eq i32 %and, 0
  br i1 %tobool6.not, label %do.end18, label %if.end.if.end24_crit_edge, !prof !1227

if.end.if.end24_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end24

do.end18:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1341, i32 noundef 9, ptr noundef null) #11
  br label %if.end24

if.end24:                                         ; preds = %do.end18, %if.end.if.end24_crit_edge
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_B) #11
  %11 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task, align 8
  %softirq_context34 = getelementptr inbounds %struct.task_struct, ptr %12, i32 0, i32 139
  %13 = ptrtoint ptr %softirq_context34 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %softirq_context34, align 4
  %dec = add i32 %14, -1
  store i32 %dec, ptr %softirq_context34, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_write_lock(ptr noundef nonnull @rwlock_B) #11
  tail call void @_raw_read_lock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_read_unlock(ptr noundef nonnull @rwlock_A) #11
  tail call void @_raw_write_unlock(ptr noundef nonnull @rwlock_B) #11
  tail call fastcc void @local_bh_enable()
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @hardirq_deadlock_softirq_not_deadlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i208 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i208)
  %tobool.not = icmp eq i32 %and.i.i208, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  %1 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i209 = and i32 %1, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i209)
  %tobool7.not = icmp eq i32 %and.i.i209, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool7.not, label %if.then10, label %if.end.if.end11_crit_edge

if.end.if.end11_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end11

if.then10:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end.if.end11_crit_edge
  %2 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %2, -16384
  %3 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %3, i32 0, i32 1
  %4 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %5, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %6, -16384
  %7 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 3
  %8 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %9
  %10 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %arrayidx, align 4
  %add = add i32 %11, ptrtoint (ptr @hardirq_context to i32)
  %12 = inttoptr i32 %add to ptr
  %13 = ptrtoint ptr %12 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %12, align 4
  %add24 = add i32 %14, 1
  store i32 %add24, ptr %12, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %cmp = icmp eq i32 %14, 0
  br i1 %cmp, label %if.then27, label %if.end11.do.end31_crit_edge

if.end11.do.end31_crit_edge:                      ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end31

if.then27:                                        ; preds = %if.end11
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %15 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %16, i32 0, i32 136
  %17 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %17)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end31

do.end31:                                         ; preds = %if.then27, %if.end11.do.end31_crit_edge
  %task33 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %18 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %19, i32 noundef 65536) #11
  %20 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %20)
  %21 = load ptr, ptr %task33, align 8
  %hardirq_threaded39 = getelementptr inbounds %struct.task_struct, ptr %21, i32 0, i32 136
  %22 = ptrtoint ptr %hardirq_threaded39 to i32
  call void @__asan_store4_noabort(i32 %22)
  store i32 1, ptr %hardirq_threaded39, align 16
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %26, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool43.not = icmp eq i32 %and, 0
  br i1 %tobool43.not, label %do.end56, label %do.end31.if.end62_crit_edge, !prof !1227

do.end31.if.end62_crit_edge:                      ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end62

do.end56:                                         ; preds = %do.end31
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2809, i32 noundef 9, ptr noundef null) #11
  br label %if.end62

if.end62:                                         ; preds = %do.end56, %do.end31.if.end62_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %27 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load ptr, ptr %task33, align 8
  tail call void @irqtime_account_irq(ptr noundef %28, i32 noundef 0) #11
  %29 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %cpu, align 4
  %arrayidx89 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %30
  %31 = ptrtoint ptr %arrayidx89 to i32
  call void @__asan_load4_noabort(i32 %31)
  %32 = load i32, ptr %arrayidx89, align 4
  %add90 = add i32 %32, ptrtoint (ptr @hardirq_context to i32)
  %33 = inttoptr i32 %add90 to ptr
  %34 = ptrtoint ptr %33 to i32
  call void @__asan_load4_noabort(i32 %34)
  %35 = load i32, ptr %33, align 4
  %add91 = add i32 %35, -1
  store i32 %add91, ptr %33, align 4
  %36 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i204 = and i32 %36, -16384
  %37 = inttoptr i32 %and.i.i.i204 to ptr
  %preempt_count.i.i205 = getelementptr inbounds %struct.thread_info, ptr %37, i32 0, i32 1
  %38 = ptrtoint ptr %preempt_count.i.i205 to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load volatile i32, ptr %preempt_count.i.i205, align 4
  %sub.i = add i32 %39, -65536
  store volatile i32 %sub.i, ptr %preempt_count.i.i205, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %40 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i210 = and i32 %40, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i210)
  %tobool106.not = icmp eq i32 %and.i.i210, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool106.not, label %if.then109, label %if.end62.if.end110_crit_edge

if.end62.if.end110_crit_edge:                     ; preds = %if.end62
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end110

if.then109:                                       ; preds = %if.end62
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end110

if.end110:                                        ; preds = %if.then109, %if.end62.if.end110_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %41 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i211 = and i32 %41, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i211)
  %tobool119.not = icmp eq i32 %and.i.i211, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool119.not, label %if.then122, label %if.end110.if.end123_crit_edge

if.end110.if.end123_crit_edge:                    ; preds = %if.end110
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end123

if.then122:                                       ; preds = %if.end110
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end123

if.end123:                                        ; preds = %if.then122, %if.end110.if.end123_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_disable()
  %42 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i212 = and i32 %42, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i212)
  %tobool132.not = icmp eq i32 %and.i.i212, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool132.not, label %if.then135, label %if.end123.if.end136_crit_edge

if.end123.if.end136_crit_edge:                    ; preds = %if.end123
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end136

if.then135:                                       ; preds = %if.end123
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end136

if.end136:                                        ; preds = %if.then135, %if.end123.if.end136_crit_edge
  %43 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load ptr, ptr %task33, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %44, i32 0, i32 139
  %45 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %45)
  %46 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %46, 1
  store i32 %inc, ptr %softirq_context, align 4
  %47 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i206 = and i32 %47, -16384
  %48 = inttoptr i32 %and.i.i206 to ptr
  %preempt_count.i207 = getelementptr inbounds %struct.thread_info, ptr %48, i32 0, i32 1
  %49 = ptrtoint ptr %preempt_count.i207 to i32
  call void @__asan_load4_noabort(i32 %49)
  %50 = load volatile i32, ptr %preempt_count.i207, align 4
  %and146 = and i32 %50, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and146)
  %tobool147.not = icmp eq i32 %and146, 0
  br i1 %tobool147.not, label %do.end165, label %if.end136.if.end171_crit_edge, !prof !1227

if.end136.if.end171_crit_edge:                    ; preds = %if.end136
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end171

do.end165:                                        ; preds = %if.end136
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2831, i32 noundef 9, ptr noundef null) #11
  br label %if.end171

if.end171:                                        ; preds = %do.end165, %if.end136.if.end171_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  %51 = ptrtoint ptr %task33 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load ptr, ptr %task33, align 8
  %softirq_context182 = getelementptr inbounds %struct.task_struct, ptr %52, i32 0, i32 139
  %53 = ptrtoint ptr %softirq_context182 to i32
  call void @__asan_load4_noabort(i32 %53)
  %54 = load i32, ptr %softirq_context182, align 4
  %dec = add i32 %54, -1
  store i32 %dec, ptr %softirq_context182, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable()
  tail call fastcc void @local_bh_disable()
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call fastcc void @local_bh_enable()
  %55 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i213 = and i32 %55, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i213)
  %tobool191.not = icmp eq i32 %and.i.i213, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool191.not, label %if.then194, label %if.end171.if.end195_crit_edge

if.end171.if.end195_crit_edge:                    ; preds = %if.end171
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end195

if.then194:                                       ; preds = %if.end171
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end195

if.end195:                                        ; preds = %if.then194, %if.end171.if.end195_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_C) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_D) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_C) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @get_option(ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__rt_mutex_init(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @init_class_X(ptr noundef %lock, ptr noundef %rwlock, ptr noundef %mutex, ptr noundef %rwsem) unnamed_addr #4 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__raw_spin_lock_init(ptr noundef %lock, ptr noundef nonnull @.str.590, ptr noundef nonnull @init_class_X.__key, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef %rwlock, ptr noundef nonnull @.str.592, ptr noundef nonnull @init_class_X.__key.591) #11
  tail call void @__mutex_init(ptr noundef %mutex, ptr noundef nonnull @.str.594, ptr noundef nonnull @init_class_X.__key.593) #11
  tail call void @__init_rwsem(ptr noundef %rwsem, ptr noundef nonnull @.str.596, ptr noundef nonnull @init_class_X.__key.595) #11
  ret void
}

; Function Attrs: noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @init_class_Y(ptr noundef %lock, ptr noundef %rwlock, ptr noundef %mutex, ptr noundef %rwsem) unnamed_addr #4 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__raw_spin_lock_init(ptr noundef %lock, ptr noundef nonnull @.str.590, ptr noundef nonnull @init_class_Y.__key, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef %rwlock, ptr noundef nonnull @.str.592, ptr noundef nonnull @init_class_Y.__key.609) #11
  tail call void @__mutex_init(ptr noundef %mutex, ptr noundef nonnull @.str.594, ptr noundef nonnull @init_class_Y.__key.610) #11
  tail call void @__init_rwsem(ptr noundef %rwsem, ptr noundef nonnull @.str.596, ptr noundef nonnull @init_class_Y.__key.611) #11
  ret void
}

; Function Attrs: noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @init_class_Z(ptr noundef %lock, ptr noundef %rwlock, ptr noundef %mutex, ptr noundef %rwsem) unnamed_addr #4 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__raw_spin_lock_init(ptr noundef %lock, ptr noundef nonnull @.str.590, ptr noundef nonnull @init_class_Z.__key, i16 noundef signext 3) #11
  tail call void @__rwlock_init(ptr noundef %rwlock, ptr noundef nonnull @.str.592, ptr noundef nonnull @init_class_Z.__key.624) #11
  tail call void @__mutex_init(ptr noundef %mutex, ptr noundef nonnull @.str.594, ptr noundef nonnull @init_class_Z.__key.625) #11
  tail call void @__init_rwsem(ptr noundef %rwsem, ptr noundef nonnull @.str.596, ptr noundef nonnull @init_class_Z.__key.626) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__raw_spin_lock_init(ptr noundef, ptr noundef, ptr noundef, i16 noundef signext) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__rwlock_init(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__mutex_init(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__init_rwsem(ptr noundef, ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: nounwind readonly
declare i32 @llvm.read_register.i32(metadata) #5

; Function Attrs: null_pointer_is_valid
declare dso_local void @warn_slowpath_fmt(ptr noundef, i32 noundef, i32 noundef, ptr noundef, ...) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_hardirqs_off() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_free_key_range(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_reset_lock(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_reset() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @debug_check_no_locks_freed(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_init_map_type(ptr noundef, ptr noundef, ptr noundef, i32 noundef, i8 noundef zeroext, i8 noundef zeroext, i8 noundef zeroext) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @trace_hardirqs_on() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_write_lock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_read_lock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_lock_nested(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @down_write(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @down_read(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @rt_mutex_lock_nested(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_unlock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_write_unlock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_read_unlock(ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: null_pointer_is_valid
declare dso_local void @mutex_unlock(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @up_write(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @up_read(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @rt_mutex_unlock(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @irqtime_account_irq(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @local_bh_disable() #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__local_bh_disable_ip(i32 noundef ptrtoint (ptr blockaddress(@local_bh_disable, %__here) to i32), i32 noundef 512) #11
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @local_bh_enable() #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @__local_bh_enable_ip(i32 noundef ptrtoint (ptr blockaddress(@local_bh_enable, %__here) to i32), i32 noundef 512) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @__local_bh_disable_ip(i32 noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__local_bh_enable_ip(i32 noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_fail_acquire() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  %9 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %inc = add i32 %9, 1
  store i32 %inc, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  %10 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %tobool.not = icmp eq ptr %10, null
  br i1 %tobool.not, label %do.end12, label %lor.lhs.false.critedge, !prof !1227

do.end12:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1678, i32 noundef 9, ptr noundef null) #11
  br label %cleanup

lor.lhs.false.critedge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool26.not = icmp eq i32 %call, 0
  br i1 %tobool26.not, label %if.end58, label %do.end42, !prof !1224

do.end42:                                         ; preds = %lor.lhs.false.critedge
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1679, i32 noundef 9, ptr noundef null) #11
  br label %cleanup

if.end58:                                         ; preds = %lor.lhs.false.critedge
  %call59 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -114, i32 %call59)
  %cmp.not = icmp eq i32 %call59, -114
  br i1 %cmp.not, label %if.end58.if.end82_crit_edge, label %do.end76, !prof !1224

if.end58.if.end82_crit_edge:                      ; preds = %if.end58
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end82

do.end76:                                         ; preds = %if.end58
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1684, i32 noundef 9, ptr noundef null) #11
  br label %if.end82

if.end82:                                         ; preds = %do.end76, %if.end58.if.end82_crit_edge
  %call90 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call90)
  %tobool92.not = icmp eq i32 %call90, 0
  br i1 %tobool92.not, label %if.end82.if.end114_crit_edge, label %do.end108, !prof !1224

if.end82.if.end114_crit_edge:                     ; preds = %if.end82
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end114

do.end108:                                        ; preds = %if.end82
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1687, i32 noundef 9, ptr noundef null) #11
  br label %if.end114

if.end114:                                        ; preds = %do.end108, %if.end82.if.end114_crit_edge
  %11 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %12 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %inc122 = add i32 %12, 1
  store i32 %inc122, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call123 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t2) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call123)
  %cmp125.not = icmp eq i32 %call123, -35
  br i1 %cmp125.not, label %if.end114.if.end147_crit_edge, label %do.end141, !prof !1224

if.end114.if.end147_crit_edge:                    ; preds = %if.end114
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end147

do.end141:                                        ; preds = %if.end114
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1692, i32 noundef 9, ptr noundef null) #11
  br label %if.end147

if.end147:                                        ; preds = %do.end141, %if.end114.if.end147_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  %call155 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call155)
  %tobool156.not = icmp eq i32 %call155, 0
  br i1 %tobool156.not, label %if.else, label %if.then157

if.then157:                                       ; preds = %if.end147
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  br label %cleanup

if.else:                                          ; preds = %if.end147
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %13 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool158.not = icmp eq i32 %13, 0
  br i1 %tobool158.not, label %do.end162, label %if.else.cleanup_crit_edge

if.else.cleanup_crit_edge:                        ; preds = %if.else
  call void @__sanitizer_cov_trace_pc() #10
  br label %cleanup

do.end162:                                        ; preds = %if.else
  %call163 = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call163)
  %tobool164.not = icmp eq i32 %call163, 0
  br i1 %tobool164.not, label %do.end162.cleanup_crit_edge, label %land.lhs.true

do.end162.cleanup_crit_edge:                      ; preds = %do.end162
  call void @__sanitizer_cov_trace_pc() #10
  br label %cleanup

land.lhs.true:                                    ; preds = %do.end162
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %14 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %tobool165.not = icmp eq i32 %14, 0
  br i1 %tobool165.not, label %do.end179, label %land.lhs.true.cleanup_crit_edge

land.lhs.true.cleanup_crit_edge:                  ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #10
  br label %cleanup

do.end179:                                        ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1699, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.777) #11
  br label %cleanup

cleanup:                                          ; preds = %do.end179, %land.lhs.true.cleanup_crit_edge, %do.end162.cleanup_crit_edge, %if.else.cleanup_crit_edge, %if.then157, %do.end42, %do.end12
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_normal() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  tail call void @mutex_lock_nested(ptr noundef nonnull @o, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  %9 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp.not = icmp eq ptr %9, inttoptr (i32 -1 to ptr)
  br i1 %cmp.not, label %entry.if.end_crit_edge, label %do.end10, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end10:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1735, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end10, %entry.if.end_crit_edge
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %call = tail call i32 @mutex_lock_interruptible_nested(ptr noundef nonnull @o, i32 noundef 0) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool22.not = icmp eq i32 %call, 0
  br i1 %tobool22.not, label %if.then23, label %do.end36

if.then23:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  br label %if.end50

do.end36:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1743, i32 noundef 9, ptr noundef null) #11
  br label %if.end50

if.end50:                                         ; preds = %do.end36, %if.then23
  %10 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp52.not = icmp eq ptr %10, inttoptr (i32 -1 to ptr)
  br i1 %cmp52.not, label %if.end50.if.end74_crit_edge, label %do.end68, !prof !1224

if.end50.if.end74_crit_edge:                      ; preds = %if.end50
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end74

do.end68:                                         ; preds = %if.end50
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1744, i32 noundef 9, ptr noundef null) #11
  br label %if.end74

if.end74:                                         ; preds = %do.end68, %if.end50.if.end74_crit_edge
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %call82 = tail call i32 @mutex_lock_killable_nested(ptr noundef nonnull @o, i32 noundef 0) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call82)
  %tobool83.not = icmp eq i32 %call82, 0
  br i1 %tobool83.not, label %if.then84, label %do.end98

if.then84:                                        ; preds = %if.end74
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  br label %if.end112

do.end98:                                         ; preds = %if.end74
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1752, i32 noundef 9, ptr noundef null) #11
  br label %if.end112

if.end112:                                        ; preds = %do.end98, %if.then84
  %11 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp114.not = icmp eq ptr %11, inttoptr (i32 -1 to ptr)
  br i1 %cmp114.not, label %if.end112.if.end136_crit_edge, label %do.end130, !prof !1224

if.end112.if.end136_crit_edge:                    ; preds = %if.end112
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end136

do.end130:                                        ; preds = %if.end112
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1753, i32 noundef 9, ptr noundef null) #11
  br label %if.end136

if.end136:                                        ; preds = %do.end130, %if.end112.if.end136_crit_edge
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %call144 = tail call i32 @mutex_trylock(ptr noundef nonnull @o) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call144)
  %tobool146.not = icmp eq i32 %call144, 0
  br i1 %tobool146.not, label %do.end164, label %if.then179.critedge, !prof !1227

do.end164:                                        ; preds = %if.end136
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1758, i32 noundef 9, ptr noundef null) #11
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1762, i32 noundef 9, ptr noundef null) #11
  br label %if.end207

if.then179.critedge:                              ; preds = %if.end136
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  br label %if.end207

if.end207:                                        ; preds = %if.then179.critedge, %do.end164
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp209.not = icmp eq ptr %12, inttoptr (i32 -1 to ptr)
  br i1 %cmp209.not, label %if.end207.if.end231_crit_edge, label %do.end225, !prof !1224

if.end207.if.end231_crit_edge:                    ; preds = %if.end207
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end231

do.end225:                                        ; preds = %if.end207
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1763, i32 noundef 9, ptr noundef null) #11
  br label %if.end231

if.end231:                                        ; preds = %do.end225, %if.end207.if.end231_crit_edge
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  tail call void @mutex_lock_nested(ptr noundef nonnull @o, i32 noundef 0) #11
  %call239 = tail call i32 @mutex_trylock(ptr noundef nonnull @o) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call239)
  %tobool241.not = icmp eq i32 %call239, 0
  br i1 %tobool241.not, label %if.end231.if.end263_crit_edge, label %do.end257, !prof !1224

if.end231.if.end263_crit_edge:                    ; preds = %if.end231
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end263

do.end257:                                        ; preds = %if.end231
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1769, i32 noundef 9, ptr noundef null) #11
  br label %if.end263

if.end263:                                        ; preds = %do.end257, %if.end231.if.end263_crit_edge
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  %13 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp272.not = icmp eq ptr %13, inttoptr (i32 -1 to ptr)
  br i1 %cmp272.not, label %if.end263.if.end294_crit_edge, label %do.end288, !prof !1224

if.end263.if.end294_crit_edge:                    ; preds = %if.end263
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end294

do.end288:                                        ; preds = %if.end263
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1771, i32 noundef 9, ptr noundef null) #11
  br label %if.end294

if.end294:                                        ; preds = %do.end288, %if.end263.if.end294_crit_edge
  store ptr inttoptr (i32 -1 to ptr), ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  tail call void @_mutex_lock_nest_lock(ptr noundef nonnull @o, ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8)) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o) #11
  %14 = load ptr, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %cmp308.not = icmp eq ptr %14, inttoptr (i32 -1 to ptr)
  br i1 %cmp308.not, label %if.end294.if.end331_crit_edge, label %do.end325, !prof !1224

if.end294.if.end331_crit_edge:                    ; preds = %if.end294
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end331

do.end325:                                        ; preds = %if.end294
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1777, i32 noundef 9, ptr noundef null) #11
  br label %if.end331

if.end331:                                        ; preds = %do.end325, %if.end294.if.end331_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_unneeded_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %9 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %tobool.not.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %entry.ww_mutex_lock_slow.exit_crit_edge

entry.ww_mutex_lock_slow.exit_crit_edge:          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %entry
  %10 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %10, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %11 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool7.not.i = icmp eq i32 %11, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %entry.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_two_contexts() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i3 = and i32 %9, -16384
  %10 = inttoptr i32 %and.i.i3 to ptr
  %task.i4 = getelementptr inbounds %struct.thread_info, ptr %10, i32 0, i32 2
  %11 = ptrtoint ptr %task.i4 to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load ptr, ptr %task.i4, align 8
  store ptr %12, ptr @t2, align 4
  %call.i.i.i5 = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %13 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i6 = extractvalue { i32, i32 } %13, 0
  store i32 %asmresult.i.i.i.i.i6, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 3), align 4
  %14 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i7 = trunc i32 %14 to i16
  store i16 %conv.i7, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t2, i32 noundef 64) #11
  %15 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 8), ptr noundef %15, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 10), align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_diff_class() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_done_twice() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %9 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %tobool.not.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i, label %entry.if.end.i_crit_edge, label %land.rhs.i

entry.if.end.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

land.rhs.i:                                       ; preds = %entry
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef -1) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i.i)
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %land.rhs.i.if.end.i_crit_edge, !prof !1227

land.rhs.i.if.end.i_crit_edge:                    ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

do.end.i:                                         ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 171, i32 noundef 9, ptr noundef null) #11
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i.if.end.i_crit_edge, %entry.if.end.i_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %10 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %10)
  %tobool24.not.i = icmp eq i32 %10, 0
  br i1 %tobool24.not.i, label %land.lhs.true.i, label %if.end.i.ww_acquire_done.exit_crit_edge

if.end.i.ww_acquire_done.exit_crit_edge:          ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true.i:                                  ; preds = %if.end.i
  %11 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool25.not.i = icmp eq i32 %11, 0
  br i1 %tobool25.not.i, label %land.lhs.true.i.ww_acquire_done.exit_crit_edge, label %do.end35.i, !prof !1224

land.lhs.true.i.ww_acquire_done.exit_crit_edge:   ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end35.i:                                       ; preds = %land.lhs.true.i
  %call36.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call36.i)
  %tobool37.not.i = icmp eq i32 %call36.i, 0
  br i1 %tobool37.not.i, label %do.end35.i.ww_acquire_done.exit_crit_edge, label %land.lhs.true38.i

do.end35.i.ww_acquire_done.exit_crit_edge:        ; preds = %do.end35.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true38.i:                                ; preds = %do.end35.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %12 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %12)
  %tobool39.not.i = icmp eq i32 %12, 0
  br i1 %tobool39.not.i, label %do.end53.i, label %land.lhs.true38.i.ww_acquire_done.exit_crit_edge

land.lhs.true38.i.ww_acquire_done.exit_crit_edge: ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end53.i:                                       ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 173, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.780) #11
  br label %ww_acquire_done.exit

ww_acquire_done.exit:                             ; preds = %do.end53.i, %land.lhs.true38.i.ww_acquire_done.exit_crit_edge, %do.end35.i.ww_acquire_done.exit_crit_edge, %land.lhs.true.i.ww_acquire_done.exit_crit_edge, %if.end.i.ww_acquire_done.exit_crit_edge
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %13 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool.not.i1 = icmp eq i32 %13, 0
  br i1 %tobool.not.i1, label %ww_acquire_done.exit.if.end.i7_crit_edge, label %land.rhs.i4

ww_acquire_done.exit.if.end.i7_crit_edge:         ; preds = %ww_acquire_done.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i7

land.rhs.i4:                                      ; preds = %ww_acquire_done.exit
  %call.i.i2 = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef -1) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i.i2)
  %cmp.not.i3 = icmp eq i32 %call.i.i2, 0
  br i1 %cmp.not.i3, label %do.end.i5, label %land.rhs.i4.if.end.i7_crit_edge, !prof !1227

land.rhs.i4.if.end.i7_crit_edge:                  ; preds = %land.rhs.i4
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i7

do.end.i5:                                        ; preds = %land.rhs.i4
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 171, i32 noundef 9, ptr noundef null) #11
  br label %if.end.i7

if.end.i7:                                        ; preds = %do.end.i5, %land.rhs.i4.if.end.i7_crit_edge, %ww_acquire_done.exit.if.end.i7_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %14 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %14)
  %tobool24.not.i6 = icmp eq i32 %14, 0
  br i1 %tobool24.not.i6, label %land.lhs.true.i9, label %if.end.i7.ww_acquire_done.exit16_crit_edge

if.end.i7.ww_acquire_done.exit16_crit_edge:       ; preds = %if.end.i7
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit16

land.lhs.true.i9:                                 ; preds = %if.end.i7
  %15 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %15)
  %tobool25.not.i8 = icmp eq i32 %15, 0
  br i1 %tobool25.not.i8, label %land.lhs.true.i9.ww_acquire_done.exit16_crit_edge, label %do.end35.i12, !prof !1224

land.lhs.true.i9.ww_acquire_done.exit16_crit_edge: ; preds = %land.lhs.true.i9
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit16

do.end35.i12:                                     ; preds = %land.lhs.true.i9
  %call36.i10 = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call36.i10)
  %tobool37.not.i11 = icmp eq i32 %call36.i10, 0
  br i1 %tobool37.not.i11, label %do.end35.i12.ww_acquire_done.exit16_crit_edge, label %land.lhs.true38.i14

do.end35.i12.ww_acquire_done.exit16_crit_edge:    ; preds = %do.end35.i12
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit16

land.lhs.true38.i14:                              ; preds = %do.end35.i12
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %16 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %16)
  %tobool39.not.i13 = icmp eq i32 %16, 0
  br i1 %tobool39.not.i13, label %do.end53.i15, label %land.lhs.true38.i14.ww_acquire_done.exit16_crit_edge

land.lhs.true38.i14.ww_acquire_done.exit16_crit_edge: ; preds = %land.lhs.true38.i14
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit16

do.end53.i15:                                     ; preds = %land.lhs.true38.i14
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 173, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.780) #11
  br label %ww_acquire_done.exit16

ww_acquire_done.exit16:                           ; preds = %do.end53.i15, %land.lhs.true38.i14.ww_acquire_done.exit16_crit_edge, %do.end35.i12.ww_acquire_done.exit16_crit_edge, %land.lhs.true.i9.ww_acquire_done.exit16_crit_edge, %if.end.i7.ww_acquire_done.exit16_crit_edge
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  tail call fastcc void @ww_acquire_fini(ptr noundef nonnull @t)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_unlock_twice() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %9 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %tobool.not.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i, label %entry.if.end.i_crit_edge, label %land.rhs.i

entry.if.end.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

land.rhs.i:                                       ; preds = %entry
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef -1) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i.i)
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %land.rhs.i.if.end.i_crit_edge, !prof !1227

land.rhs.i.if.end.i_crit_edge:                    ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

do.end.i:                                         ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 171, i32 noundef 9, ptr noundef null) #11
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i.if.end.i_crit_edge, %entry.if.end.i_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %10 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %10)
  %tobool24.not.i = icmp eq i32 %10, 0
  br i1 %tobool24.not.i, label %land.lhs.true.i, label %if.end.i.ww_acquire_done.exit_crit_edge

if.end.i.ww_acquire_done.exit_crit_edge:          ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true.i:                                  ; preds = %if.end.i
  %11 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool25.not.i = icmp eq i32 %11, 0
  br i1 %tobool25.not.i, label %land.lhs.true.i.ww_acquire_done.exit_crit_edge, label %do.end35.i, !prof !1224

land.lhs.true.i.ww_acquire_done.exit_crit_edge:   ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end35.i:                                       ; preds = %land.lhs.true.i
  %call36.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call36.i)
  %tobool37.not.i = icmp eq i32 %call36.i, 0
  br i1 %tobool37.not.i, label %do.end35.i.ww_acquire_done.exit_crit_edge, label %land.lhs.true38.i

do.end35.i.ww_acquire_done.exit_crit_edge:        ; preds = %do.end35.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true38.i:                                ; preds = %do.end35.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %12 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %12)
  %tobool39.not.i = icmp eq i32 %12, 0
  br i1 %tobool39.not.i, label %do.end53.i, label %land.lhs.true38.i.ww_acquire_done.exit_crit_edge

land.lhs.true38.i.ww_acquire_done.exit_crit_edge: ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end53.i:                                       ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 173, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.780) #11
  br label %ww_acquire_done.exit

ww_acquire_done.exit:                             ; preds = %do.end53.i, %land.lhs.true38.i.ww_acquire_done.exit_crit_edge, %do.end35.i.ww_acquire_done.exit_crit_edge, %land.lhs.true.i.ww_acquire_done.exit_crit_edge, %if.end.i.ww_acquire_done.exit_crit_edge
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  tail call fastcc void @ww_acquire_fini(ptr noundef nonnull @t)
  tail call fastcc void @ww_acquire_fini(ptr noundef nonnull @t)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_fini_early() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %9 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %tobool.not.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i, label %entry.if.end.i_crit_edge, label %land.rhs.i

entry.if.end.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

land.rhs.i:                                       ; preds = %entry
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef -1) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i.i)
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %land.rhs.i.if.end.i_crit_edge, !prof !1227

land.rhs.i.if.end.i_crit_edge:                    ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

do.end.i:                                         ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 171, i32 noundef 9, ptr noundef null) #11
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i.if.end.i_crit_edge, %entry.if.end.i_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %10 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %10)
  %tobool24.not.i = icmp eq i32 %10, 0
  br i1 %tobool24.not.i, label %land.lhs.true.i, label %if.end.i.ww_acquire_done.exit_crit_edge

if.end.i.ww_acquire_done.exit_crit_edge:          ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true.i:                                  ; preds = %if.end.i
  %11 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool25.not.i = icmp eq i32 %11, 0
  br i1 %tobool25.not.i, label %land.lhs.true.i.ww_acquire_done.exit_crit_edge, label %do.end35.i, !prof !1224

land.lhs.true.i.ww_acquire_done.exit_crit_edge:   ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end35.i:                                       ; preds = %land.lhs.true.i
  %call36.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call36.i)
  %tobool37.not.i = icmp eq i32 %call36.i, 0
  br i1 %tobool37.not.i, label %do.end35.i.ww_acquire_done.exit_crit_edge, label %land.lhs.true38.i

do.end35.i.ww_acquire_done.exit_crit_edge:        ; preds = %do.end35.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true38.i:                                ; preds = %do.end35.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %12 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %12)
  %tobool39.not.i = icmp eq i32 %12, 0
  br i1 %tobool39.not.i, label %do.end53.i, label %land.lhs.true38.i.ww_acquire_done.exit_crit_edge

land.lhs.true38.i.ww_acquire_done.exit_crit_edge: ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end53.i:                                       ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 173, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.780) #11
  br label %ww_acquire_done.exit

ww_acquire_done.exit:                             ; preds = %do.end53.i, %land.lhs.true38.i.ww_acquire_done.exit_crit_edge, %do.end35.i.ww_acquire_done.exit_crit_edge, %land.lhs.true.i.ww_acquire_done.exit_crit_edge, %if.end.i.ww_acquire_done.exit_crit_edge
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  tail call fastcc void @ww_acquire_fini(ptr noundef nonnull @t)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_lock_after_done() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks to i32))
  %9 = load i32, ptr @debug_locks, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %9)
  %tobool.not.i = icmp eq i32 %9, 0
  br i1 %tobool.not.i, label %entry.if.end.i_crit_edge, label %land.rhs.i

entry.if.end.i_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

land.rhs.i:                                       ; preds = %entry
  %call.i.i = tail call i32 @lock_is_held_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef -1) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i.i)
  %cmp.not.i = icmp eq i32 %call.i.i, 0
  br i1 %cmp.not.i, label %do.end.i, label %land.rhs.i.if.end.i_crit_edge, !prof !1227

land.rhs.i.if.end.i_crit_edge:                    ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end.i

do.end.i:                                         ; preds = %land.rhs.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 171, i32 noundef 9, ptr noundef null) #11
  br label %if.end.i

if.end.i:                                         ; preds = %do.end.i, %land.rhs.i.if.end.i_crit_edge, %entry.if.end.i_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %10 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %10)
  %tobool24.not.i = icmp eq i32 %10, 0
  br i1 %tobool24.not.i, label %land.lhs.true.i, label %if.end.i.ww_acquire_done.exit_crit_edge

if.end.i.ww_acquire_done.exit_crit_edge:          ; preds = %if.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true.i:                                  ; preds = %if.end.i
  %11 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool25.not.i = icmp eq i32 %11, 0
  br i1 %tobool25.not.i, label %land.lhs.true.i.ww_acquire_done.exit_crit_edge, label %do.end35.i, !prof !1224

land.lhs.true.i.ww_acquire_done.exit_crit_edge:   ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end35.i:                                       ; preds = %land.lhs.true.i
  %call36.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call36.i)
  %tobool37.not.i = icmp eq i32 %call36.i, 0
  br i1 %tobool37.not.i, label %do.end35.i.ww_acquire_done.exit_crit_edge, label %land.lhs.true38.i

do.end35.i.ww_acquire_done.exit_crit_edge:        ; preds = %do.end35.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

land.lhs.true38.i:                                ; preds = %do.end35.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %12 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %12)
  %tobool39.not.i = icmp eq i32 %12, 0
  br i1 %tobool39.not.i, label %do.end53.i, label %land.lhs.true38.i.ww_acquire_done.exit_crit_edge

land.lhs.true38.i.ww_acquire_done.exit_crit_edge: ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_acquire_done.exit

do.end53.i:                                       ; preds = %land.lhs.true38.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 173, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.780) #11
  br label %ww_acquire_done.exit

ww_acquire_done.exit:                             ; preds = %do.end53.i, %land.lhs.true38.i.ww_acquire_done.exit_crit_edge, %do.end35.i.ww_acquire_done.exit_crit_edge, %land.lhs.true.i.ww_acquire_done.exit_crit_edge, %if.end.i.ww_acquire_done.exit_crit_edge
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_object_unlock_twice() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_object_lock_unbalanced() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call fastcc void @ww_acquire_fini(ptr noundef nonnull @t)
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_object_lock_stale_context() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_normal() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_normal, %__here) to i32)) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1862, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1865, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here55

__here55:                                         ; preds = %if.end47
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef 0, i32 noundef 1, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_normal, %__here55) to i32)) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  %call57 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_normal_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_normal_slow, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1888, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1891, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here55

__here55:                                         ; preds = %if.end47
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef 0, i32 noundef 1, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_normal_slow, %__here55) to i32)) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %11 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool.not.i = icmp eq i32 %11, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %__here55.ww_mutex_lock_slow.exit_crit_edge

__here55.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %__here55
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %__here55
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %12, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %13 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool7.not.i = icmp eq i32 %13, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %__here55.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_no_unlock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_no_unlock, %__here) to i32)) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1914, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1917, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here55

__here55:                                         ; preds = %if.end47
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef 0, i32 noundef 1, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_no_unlock, %__here55) to i32)) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o2) #11
  %call57 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_no_unlock_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_no_unlock_slow, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1939, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1942, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  store ptr null, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  br label %__here55

__here55:                                         ; preds = %if.end47
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef 0, i32 noundef 1, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_no_unlock_slow, %__here55) to i32)) #11
  tail call void @mutex_unlock(ptr noundef nonnull @o2) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %11 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool.not.i = icmp eq i32 %11, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %__here55.ww_mutex_lock_slow.exit_crit_edge

__here55.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %__here55
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %__here55
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %12, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %13 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool7.not.i = icmp eq i32 %13, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %__here55.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_more() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1964, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1967, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  %call55 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_more_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more_slow, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1985, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cmp.not = icmp eq i32 %call24, -35
  br i1 %cmp.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 1988, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %11 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool.not.i = icmp eq i32 %11, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %if.end47.ww_mutex_lock_slow.exit_crit_edge

if.end47.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %if.end47
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %if.end47
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %12, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %13 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool7.not.i = icmp eq i32 %13, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %if.end47.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_more_edeadlk() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more_edeadlk, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  tail call void @mutex_lock_nested(ptr noundef nonnull @o3, i32 noundef 0) #11
  br label %__here1

__here1:                                          ; preds = %__here
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more_edeadlk, %__here1) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here1.if.end_crit_edge, label %do.end13, !prof !1224

__here1.if.end_crit_edge:                         ; preds = %__here1
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end13:                                         ; preds = %__here1
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2010, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end13, %__here1.if.end_crit_edge
  %call26 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call26)
  %cmp.not = icmp eq i32 %call26, -35
  br i1 %cmp.not, label %if.end.if.end49_crit_edge, label %do.end43, !prof !1224

if.end.if.end49_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end49

do.end43:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2013, i32 noundef 9, ptr noundef null) #11
  br label %if.end49

if.end49:                                         ; preds = %do.end43, %if.end.if.end49_crit_edge
  %call57 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call57)
  %cmp59.not = icmp eq i32 %call57, -35
  br i1 %cmp59.not, label %if.end49.if.end81_crit_edge, label %do.end75, !prof !1224

if.end49.if.end81_crit_edge:                      ; preds = %if.end49
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end81

do.end75:                                         ; preds = %if.end49
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2016, i32 noundef 9, ptr noundef null) #11
  br label %if.end81

if.end81:                                         ; preds = %do.end75, %if.end49.if.end81_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_more_edeadlk_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more_edeadlk_slow, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  tail call void @mutex_lock_nested(ptr noundef nonnull @o3, i32 noundef 0) #11
  br label %__here1

__here1:                                          ; preds = %__here
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_more_edeadlk_slow, %__here1) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o3, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here1.if.end_crit_edge, label %do.end13, !prof !1224

__here1.if.end_crit_edge:                         ; preds = %__here1
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end13:                                         ; preds = %__here1
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2036, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end13, %__here1.if.end_crit_edge
  %call26 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call26)
  %cmp.not = icmp eq i32 %call26, -35
  br i1 %cmp.not, label %if.end.if.end49_crit_edge, label %do.end43, !prof !1224

if.end.if.end49_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end49

do.end43:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2039, i32 noundef 9, ptr noundef null) #11
  br label %if.end49

if.end49:                                         ; preds = %do.end43, %if.end.if.end49_crit_edge
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %11 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool.not.i = icmp eq i32 %11, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %if.end49.ww_mutex_lock_slow.exit_crit_edge

if.end49.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %if.end49
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %if.end49
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %12, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %13 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool7.not.i = icmp eq i32 %13, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %if.end49.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_wrong() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_wrong, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2057, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cond = icmp eq i32 %call24, -35
  br i1 %cond, label %if.end.if.end57_crit_edge, label %do.end41, !prof !1224

if.end.if.end57_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end57

do.end41:                                         ; preds = %if.end
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2060, i32 noundef 9, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call24)
  %tobool55.not = icmp eq i32 %call24, 0
  br i1 %tobool55.not, label %if.then56, label %do.end41.if.end57_crit_edge

do.end41.if.end57_crit_edge:                      ; preds = %do.end41
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end57

if.then56:                                        ; preds = %do.end41
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  br label %if.end57

if.end57:                                         ; preds = %if.then56, %do.end41.if.end57_crit_edge, %if.end.if.end57_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  %call58 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_edeadlk_acquire_wrong_slow() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @o2, i32 noundef 0) #11
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 0, i32 5), i32 noundef ptrtoint (ptr blockaddress(@ww_test_edeadlk_acquire_wrong_slow, %__here) to i32)) #11
  store ptr @t2, ptr getelementptr inbounds (%struct.ww_mutex, ptr @o2, i32 0, i32 1), align 4
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %9 = call ptr @memcpy(ptr @t2, ptr @t, i32 64)
  %10 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %dec = add i32 %10, -1
  store i32 %dec, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t2, i32 0, i32 1), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %__here.if.end_crit_edge, label %do.end11, !prof !1224

__here.if.end_crit_edge:                          ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2082, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %__here.if.end_crit_edge
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 -35, i32 %call24)
  %cond = icmp eq i32 %call24, -35
  br i1 %cond, label %if.end.if.end57_crit_edge, label %do.end41, !prof !1224

if.end.if.end57_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end57

do.end41:                                         ; preds = %if.end
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2085, i32 noundef 9, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call24)
  %tobool55.not = icmp eq i32 %call24, 0
  br i1 %tobool55.not, label %if.then56, label %do.end41.if.end57_crit_edge

do.end41.if.end57_crit_edge:                      ; preds = %do.end41
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end57

if.then56:                                        ; preds = %do.end41
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  br label %if.end57

if.end57:                                         ; preds = %if.then56, %do.end41.if.end57_crit_edge, %if.end.if.end57_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %11 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %11)
  %tobool.not.i = icmp eq i32 %11, 0
  br i1 %tobool.not.i, label %land.lhs.true.i, label %if.end57.ww_mutex_lock_slow.exit_crit_edge

if.end57.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %if.end57
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true.i:                                  ; preds = %if.end57
  %12 = load ptr, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  %tobool1.not.i = icmp eq ptr %12, null
  br i1 %tobool1.not.i, label %do.end.i, label %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, !prof !1227

land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end.i:                                         ; preds = %land.lhs.true.i
  %call.i = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call.i)
  %tobool5.not.i = icmp eq i32 %call.i, 0
  br i1 %tobool5.not.i, label %do.end.i.ww_mutex_lock_slow.exit_crit_edge, label %land.lhs.true6.i

do.end.i.ww_mutex_lock_slow.exit_crit_edge:       ; preds = %do.end.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

land.lhs.true6.i:                                 ; preds = %do.end.i
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %13 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %tobool7.not.i = icmp eq i32 %13, 0
  br i1 %tobool7.not.i, label %do.end20.i, label %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge

land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge: ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %ww_mutex_lock_slow.exit

do.end20.i:                                       ; preds = %land.lhs.true6.i
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 297, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.779) #11
  br label %ww_mutex_lock_slow.exit

ww_mutex_lock_slow.exit:                          ; preds = %do.end20.i, %land.lhs.true6.i.ww_mutex_lock_slow.exit_crit_edge, %do.end.i.ww_mutex_lock_slow.exit_crit_edge, %land.lhs.true.i.ww_mutex_lock_slow.exit_crit_edge, %if.end57.ww_mutex_lock_slow.exit_crit_edge
  %call38.i = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o3, ptr noundef nonnull @t) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_spin_nest_unlocked() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock_nest_lock(ptr noundef nonnull @lock_A, ptr noundef getelementptr inbounds (%struct.ww_mutex, ptr @o, i32 0, i32 0, i32 5)) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_spin_nest_lock() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_X1) #11
  tail call void @_raw_spin_lock_nest_lock(ptr noundef nonnull @lock_Y1, ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_X1, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock_nest_lock(ptr noundef nonnull @lock_Y2, ptr noundef getelementptr inbounds (%struct.spinlock, ptr @lock_X1, i32 0, i32 0, i32 0, i32 4)) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y2) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_Y1) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_X1) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_block() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end11, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2127, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %entry.if.end_crit_edge
  %call23 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef null) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_try() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end11, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2138, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %entry.if.end_crit_edge
  %call23 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o2, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call23)
  %tobool25.not = icmp eq i32 %call23, 0
  br i1 %tobool25.not, label %do.end43, label %if.end.if.end49_crit_edge, !prof !1227

if.end.if.end49_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end49

do.end43:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2141, i32 noundef 9, ptr noundef null) #11
  br label %if.end49

if.end49:                                         ; preds = %do.end43, %if.end.if.end49_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_context_context() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end11, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2153, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %entry.if.end_crit_edge
  %call23 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call23)
  %tobool25.not = icmp eq i32 %call23, 0
  br i1 %tobool25.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2156, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_try_block() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %do.end, label %entry.if.end_crit_edge, !prof !1227

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2167, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end, %entry.if.end_crit_edge
  %call22 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef null) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_try_try() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %do.end, label %entry.if.end_crit_edge, !prof !1227

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2179, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end, %entry.if.end_crit_edge
  %call22 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o2, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call22)
  %tobool23.not = icmp eq i32 %call22, 0
  br i1 %tobool23.not, label %do.end44, label %if.end.if.end50_crit_edge, !prof !1227

if.end.if.end50_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end50

do.end44:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2181, i32 noundef 9, ptr noundef null) #11
  br label %if.end50

if.end50:                                         ; preds = %do.end44, %if.end.if.end50_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o2) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_try_context() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %do.end, label %entry.if.end_crit_edge, !prof !1227

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2191, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end, %entry.if.end_crit_edge
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call24 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call24)
  %tobool26.not = icmp eq i32 %call24, 0
  br i1 %tobool26.not, label %if.end.if.end48_crit_edge, label %do.end42, !prof !1224

if.end.if.end48_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end48

do.end42:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2196, i32 noundef 9, ptr noundef null) #11
  br label %if.end48

if.end48:                                         ; preds = %do.end42, %if.end.if.end48_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_block_block() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  %call1 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef null) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_block_try() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  %call1 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o2, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1)
  %tobool.not = icmp eq i32 %call1, 0
  br i1 %tobool.not, label %do.end, label %entry.if.end_crit_edge, !prof !1227

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2211, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end, %entry.if.end_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_block_context() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call1 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o2, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1)
  %tobool.not = icmp eq i32 %call1, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end12, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end12:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2222, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end12, %entry.if.end_crit_edge
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_spin_block() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %call1 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef null) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_spin_try() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %call = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %do.end, label %entry.if.end_crit_edge, !prof !1227

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2249, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %call22 = tail call i32 @ww_mutex_trylock(ptr noundef nonnull @o, ptr noundef null) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call22)
  %tobool23.not = icmp eq i32 %call22, 0
  br i1 %tobool23.not, label %do.end44, label %if.end.if.end50_crit_edge, !prof !1227

if.end.if.end50_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end50

do.end44:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2256, i32 noundef 9, ptr noundef null) #11
  br label %if.end50

if.end50:                                         ; preds = %do.end44, %if.end.if.end50_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @ww_test_spin_context() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  store ptr %3, ptr @t, align 4
  %call.i.i.i = tail call zeroext i1 @__kasan_check_write(ptr noundef nonnull @ww_lockdep, i32 noundef 4) #11
  tail call void @llvm.prefetch.p0(ptr nonnull @ww_lockdep, i32 1, i32 3, i32 1) #11
  %4 = tail call { i32, i32 } asm sideeffect "@ atomic_add_return\0A1:\09ldrex\09$0, [$3]\0A\09add\09$0, $0, $4\0A\09strex\09$1, $0, [$3]\0A\09teq\09$1, #0\0A\09bne\091b", "=&r,=&r,=*Qo,r,Ir,*Qo,~{cc}"(ptr nonnull elementtype(i32) @ww_lockdep, ptr nonnull @ww_lockdep, i32 1, ptr nonnull elementtype(i32) @ww_lockdep) #11, !srcloc !1228
  %asmresult.i.i.i.i.i = extractvalue { i32, i32 } %4, 0
  store i32 %asmresult.i.i.i.i.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 1), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  store i16 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 3), align 4
  %5 = load i32, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 5), align 4
  %conv.i = trunc i32 %5 to i16
  store i16 %conv.i, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 4), align 2
  store ptr @ww_lockdep, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 6), align 4
  store i32 0, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 5), align 4
  store ptr null, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 7), align 4
  tail call void @debug_check_no_locks_freed(ptr noundef nonnull @t, i32 noundef 64) #11
  %6 = load ptr, ptr getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 3), align 4
  tail call void @lockdep_init_map_type(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), ptr noundef %6, ptr noundef getelementptr inbounds (%struct.ww_class, ptr @ww_lockdep, i32 0, i32 1), i32 noundef 0, i8 noundef zeroext 0, i8 noundef zeroext 0, i8 noundef zeroext 0) #11
  %7 = tail call ptr @llvm.returnaddress(i32 0) #11
  %8 = ptrtoint ptr %7 to i32
  tail call void @lock_acquire(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef %8) #11
  store i32 1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 9), align 4
  store i32 -1, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 10), align 4
  %call = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool.not = icmp eq i32 %call, 0
  br i1 %tobool.not, label %entry.if.end_crit_edge, label %do.end11, !prof !1224

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

do.end11:                                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2271, i32 noundef 9, ptr noundef null) #11
  br label %if.end

if.end:                                           ; preds = %do.end11, %entry.if.end_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %call23 = tail call i32 @ww_mutex_lock(ptr noundef nonnull @o, ptr noundef nonnull @t) #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call23)
  %tobool25.not = icmp eq i32 %call23, 0
  br i1 %tobool25.not, label %if.end.if.end47_crit_edge, label %do.end41, !prof !1224

if.end.if.end47_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end47

do.end41:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2278, i32 noundef 9, ptr noundef null) #11
  br label %if.end47

if.end47:                                         ; preds = %do.end41, %if.end.if.end47_crit_edge
  tail call void @ww_mutex_unlock(ptr noundef nonnull @o) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @ww_mutex_lock(ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @ww_mutex_trylock(ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @ww_mutex_unlock(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @debug_locks_off() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_acquire(ptr noundef, i32 noundef, i32 noundef, i32 noundef, i32 noundef, ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: nocallback nofree nosync nounwind readnone willreturn
declare ptr @llvm.returnaddress(i32 immarg) #7

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @__kasan_check_write(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.prefetch.p0(ptr nocapture readonly, i32 immarg, i32 immarg, i32) #8

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @mutex_lock_interruptible_nested(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @mutex_lock_killable_nested(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @mutex_trylock(ptr noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @_mutex_lock_nest_lock(ptr noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @ww_acquire_fini(ptr nocapture noundef readnone %ctx) #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_release(ptr noundef getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 8), i32 noundef ptrtoint (ptr blockaddress(@ww_acquire_fini, %__here) to i32)) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %0 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %0)
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %land.lhs.true, label %__here.if.end36_crit_edge

__here.if.end36_crit_edge:                        ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

land.lhs.true:                                    ; preds = %__here
  %1 = load i32, ptr getelementptr inbounds (%struct.ww_acquire_ctx, ptr @t, i32 0, i32 2), align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %1)
  %tobool1.not = icmp eq i32 %1, 0
  br i1 %tobool1.not, label %land.lhs.true.if.end36_crit_edge, label %do.end, !prof !1224

land.lhs.true.if.end36_crit_edge:                 ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

do.end:                                           ; preds = %land.lhs.true
  %call = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool4.not = icmp eq i32 %call, 0
  br i1 %tobool4.not, label %do.end.if.end36_crit_edge, label %land.lhs.true5

do.end.if.end36_crit_edge:                        ; preds = %do.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

land.lhs.true5:                                   ; preds = %do.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %2 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %2)
  %tobool6.not = icmp eq i32 %2, 0
  br i1 %tobool6.not, label %do.end19, label %land.lhs.true5.if.end36_crit_edge

land.lhs.true5.if.end36_crit_edge:                ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

do.end19:                                         ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.778, i32 noundef 191, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.781) #11
  br label %if.end36

if.end36:                                         ; preds = %do.end19, %land.lhs.true5.if.end36_crit_edge, %do.end.if.end36_crit_edge, %land.lhs.true.if.end36_crit_edge, %__here.if.end36_crit_edge
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @lock_is_held_type(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lock_release(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @_raw_spin_lock_nest_lock(ptr noundef, ptr noundef) local_unnamed_addr #3 section ".spinlock.text"

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @fs_reclaim_correct_nesting() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @fs_reclaim_acquire(i32 noundef 3264) #11
  tail call void @fs_reclaim_acquire(i32 noundef 3136) #11
  tail call void @fs_reclaim_release(i32 noundef 3136) #11
  tail call void @__might_sleep(ptr noundef nonnull @.str.798, i32 noundef 256) #11
  tail call void @fs_reclaim_release(i32 noundef 3264) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @fs_reclaim_wrong_nesting() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @fs_reclaim_acquire(i32 noundef 3264) #11
  tail call void @fs_reclaim_acquire(i32 noundef 3264) #11
  tail call void @fs_reclaim_release(i32 noundef 3264) #11
  tail call void @__might_sleep(ptr noundef nonnull @.str.798, i32 noundef 256) #11
  tail call void @fs_reclaim_release(i32 noundef 3264) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @fs_reclaim_protected_nesting() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @fs_reclaim_acquire(i32 noundef 3264) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 2
  %2 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load ptr, ptr %task.i, align 8
  %flags1.i = getelementptr inbounds %struct.task_struct, ptr %3, i32 0, i32 3
  %4 = ptrtoint ptr %flags1.i to i32
  call void @__asan_load4_noabort(i32 %4)
  %5 = load i32, ptr %flags1.i, align 4
  %and.i = and i32 %5, 262144
  %or.i = or i32 %5, 262144
  store i32 %or.i, ptr %flags1.i, align 4
  tail call void @fs_reclaim_acquire(i32 noundef 3264) #11
  tail call void @fs_reclaim_release(i32 noundef 3264) #11
  tail call void @__might_sleep(ptr noundef nonnull @.str.798, i32 noundef 256) #11
  %6 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i1 = and i32 %6, -16384
  %7 = inttoptr i32 %and.i.i1 to ptr
  %task.i2 = getelementptr inbounds %struct.thread_info, ptr %7, i32 0, i32 2
  %8 = ptrtoint ptr %task.i2 to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load ptr, ptr %task.i2, align 8
  %flags1.i3 = getelementptr inbounds %struct.task_struct, ptr %9, i32 0, i32 3
  %10 = ptrtoint ptr %flags1.i3 to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load i32, ptr %flags1.i3, align 4
  %and.i4 = and i32 %11, -262145
  %or.i5 = or i32 %and.i4, %and.i
  store i32 %or.i5, ptr %flags1.i3, align 4
  tail call void @fs_reclaim_release(i32 noundef 3264) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @fs_reclaim_acquire(i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @fs_reclaim_release(i32 noundef) local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @__might_sleep(ptr noundef, i32 noundef) local_unnamed_addr #3

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i62 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i62)
  %tobool.not = icmp eq i32 %and.i.i62, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task23, align 8
  %hardirq_threaded29 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded29 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded29, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool33.not = icmp eq i32 %and, 0
  br i1 %tobool33.not, label %do.end46, label %do.end21.if.end52_crit_edge, !prof !1227

do.end21.if.end52_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end52

do.end46:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2639, i32 noundef 9, ptr noundef null) #11
  br label %if.end52

if.end52:                                         ; preds = %do.end46, %do.end21.if.end52_crit_edge
  %26 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %26, -16384
  %27 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 1
  %28 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %29, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %if.end52.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

if.end52.rcu_read_lock.exit_crit_edge:            ; preds = %if.end52
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %if.end52
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %if.end52.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %30 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %30, -16384
  %31 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %31, i32 0, i32 1
  %32 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %33, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %34 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i63 = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i63 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 2
  %36 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %37, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 3
  %38 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %38)
  %39 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %39
  %40 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %arrayidx.i, align 4
  %add.i64 = add i32 %41, ptrtoint (ptr @hardirq_context to i32)
  %42 = inttoptr i32 %add.i64 to ptr
  %43 = ptrtoint ptr %42 to i32
  call void @__asan_load4_noabort(i32 %43)
  %44 = load i32, ptr %42, align 4
  %add10.i = add i32 %44, -1
  store i32 %add10.i, ptr %42, align 4
  %45 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %45, -16384
  %46 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %46, i32 0, i32 1
  %47 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %47)
  %48 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %48, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i62 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i62)
  %tobool.not = icmp eq i32 %and.i.i62, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task23, align 8
  %hardirq_threaded29 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded29 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded29, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool33.not = icmp eq i32 %and, 0
  br i1 %tobool33.not, label %do.end46, label %do.end21.if.end52_crit_edge, !prof !1227

do.end21.if.end52_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end52

do.end46:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2640, i32 noundef 9, ptr noundef null) #11
  br label %if.end52

if.end52:                                         ; preds = %do.end46, %do.end21.if.end52_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %26 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i63 = and i32 %26, -16384
  %27 = inttoptr i32 %and.i.i63 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 2
  %28 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %29, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 3
  %30 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %31
  %32 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %arrayidx.i, align 4
  %add.i64 = add i32 %33, ptrtoint (ptr @hardirq_context to i32)
  %34 = inttoptr i32 %add.i64 to ptr
  %35 = ptrtoint ptr %34 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %34, align 4
  %add10.i = add i32 %36, -1
  store i32 %add10.i, ptr %34, align 4
  %37 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %37, -16384
  %38 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %38, i32 0, i32 1
  %39 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %40, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i62 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i62)
  %tobool.not = icmp eq i32 %and.i.i62, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task23, align 8
  %hardirq_threaded29 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded29 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded29, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool33.not = icmp eq i32 %and, 0
  br i1 %tobool33.not, label %do.end46, label %do.end21.if.end52_crit_edge, !prof !1227

do.end21.if.end52_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end52

do.end46:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2641, i32 noundef 9, ptr noundef null) #11
  br label %if.end52

if.end52:                                         ; preds = %do.end46, %do.end21.if.end52_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %26 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i63 = and i32 %26, -16384
  %27 = inttoptr i32 %and.i.i63 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 2
  %28 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %29, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 3
  %30 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %31
  %32 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %arrayidx.i, align 4
  %add.i64 = add i32 %33, ptrtoint (ptr @hardirq_context to i32)
  %34 = inttoptr i32 %add.i64 to ptr
  %35 = ptrtoint ptr %34 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %34, align 4
  %add10.i = add i32 %36, -1
  store i32 %add10.i, ptr %34, align 4
  %37 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %37, -16384
  %38 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %38, i32 0, i32 1
  %39 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %40, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i62 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i62)
  %tobool.not = icmp eq i32 %and.i.i62, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %19)
  %20 = load ptr, ptr %task23, align 8
  %hardirq_threaded29 = getelementptr inbounds %struct.task_struct, ptr %20, i32 0, i32 136
  %21 = ptrtoint ptr %hardirq_threaded29 to i32
  call void @__asan_store4_noabort(i32 %21)
  store i32 1, ptr %hardirq_threaded29, align 16
  %22 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %22, -16384
  %23 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %23, i32 0, i32 1
  %24 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %24)
  %25 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %25, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool33.not = icmp eq i32 %and, 0
  br i1 %tobool33.not, label %do.end46, label %do.end21.if.end52_crit_edge, !prof !1227

do.end21.if.end52_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end52

do.end46:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2642, i32 noundef 9, ptr noundef null) #11
  br label %if.end52

if.end52:                                         ; preds = %do.end46, %do.end21.if.end52_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %26 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i63 = and i32 %26, -16384
  %27 = inttoptr i32 %and.i.i63 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 2
  %28 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %28)
  %29 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %29, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %27, i32 0, i32 3
  %30 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %31
  %32 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %arrayidx.i, align 4
  %add.i64 = add i32 %33, ptrtoint (ptr @hardirq_context to i32)
  %34 = inttoptr i32 %add.i64 to ptr
  %35 = ptrtoint ptr %34 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %34, align 4
  %add10.i = add i32 %36, -1
  store i32 %add10.i, ptr %34, align 4
  %37 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %37, -16384
  %38 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %38, i32 0, i32 1
  %39 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %39)
  %40 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %40, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_NOTTHREADED_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i56 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i56)
  %tobool.not = icmp eq i32 %and.i.i56, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %22, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool27.not = icmp eq i32 %and, 0
  br i1 %tobool27.not, label %do.end40, label %do.end21.if.end46_crit_edge, !prof !1227

do.end21.if.end46_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end46

do.end40:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2639, i32 noundef 9, ptr noundef null) #11
  br label %if.end46

if.end46:                                         ; preds = %do.end40, %do.end21.if.end46_crit_edge
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 1
  %25 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %26, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %if.end46.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

if.end46.rcu_read_lock.exit_crit_edge:            ; preds = %if.end46
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %if.end46
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %if.end46.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %27 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %27, -16384
  %28 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %28, i32 0, i32 1
  %29 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %30, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %31 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i57 = and i32 %31, -16384
  %32 = inttoptr i32 %and.i.i57 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %32, i32 0, i32 2
  %33 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %33)
  %34 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %34, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %32, i32 0, i32 3
  %35 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %36
  %37 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load i32, ptr %arrayidx.i, align 4
  %add.i58 = add i32 %38, ptrtoint (ptr @hardirq_context to i32)
  %39 = inttoptr i32 %add.i58 to ptr
  %40 = ptrtoint ptr %39 to i32
  call void @__asan_load4_noabort(i32 %40)
  %41 = load i32, ptr %39, align 4
  %add10.i = add i32 %41, -1
  store i32 %add10.i, ptr %39, align 4
  %42 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %42, -16384
  %43 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %43, i32 0, i32 1
  %44 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %45, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_NOTTHREADED_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i56 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i56)
  %tobool.not = icmp eq i32 %and.i.i56, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %22, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool27.not = icmp eq i32 %and, 0
  br i1 %tobool27.not, label %do.end40, label %do.end21.if.end46_crit_edge, !prof !1227

do.end21.if.end46_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end46

do.end40:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2640, i32 noundef 9, ptr noundef null) #11
  br label %if.end46

if.end46:                                         ; preds = %do.end40, %do.end21.if.end46_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i57 = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i57 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 2
  %25 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %26, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 3
  %27 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %28
  %29 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %arrayidx.i, align 4
  %add.i58 = add i32 %30, ptrtoint (ptr @hardirq_context to i32)
  %31 = inttoptr i32 %add.i58 to ptr
  %32 = ptrtoint ptr %31 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %31, align 4
  %add10.i = add i32 %33, -1
  store i32 %add10.i, ptr %31, align 4
  %34 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 1
  %36 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %37, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_NOTTHREADED_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i56 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i56)
  %tobool.not = icmp eq i32 %and.i.i56, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %22, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool27.not = icmp eq i32 %and, 0
  br i1 %tobool27.not, label %do.end40, label %do.end21.if.end46_crit_edge, !prof !1227

do.end21.if.end46_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end46

do.end40:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2641, i32 noundef 9, ptr noundef null) #11
  br label %if.end46

if.end46:                                         ; preds = %do.end40, %do.end21.if.end46_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i57 = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i57 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 2
  %25 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %26, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 3
  %27 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %28
  %29 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %arrayidx.i, align 4
  %add.i58 = add i32 %30, ptrtoint (ptr @hardirq_context to i32)
  %31 = inttoptr i32 %add.i58 to ptr
  %32 = ptrtoint ptr %31 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %31, align 4
  %add10.i = add i32 %33, -1
  store i32 %add10.i, ptr %31, align 4
  %34 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 1
  %36 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %37, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_NOTTHREADED_HARDIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i56 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i56)
  %tobool.not = icmp eq i32 %and.i.i56, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 1
  %3 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %4, 65536
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  %5 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %5, -16384
  %6 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 3
  %7 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %7)
  %8 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %8
  %9 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load i32, ptr %arrayidx, align 4
  %add = add i32 %10, ptrtoint (ptr @hardirq_context to i32)
  %11 = inttoptr i32 %add to ptr
  %12 = ptrtoint ptr %11 to i32
  call void @__asan_load4_noabort(i32 %12)
  %13 = load i32, ptr %11, align 4
  %add14 = add i32 %13, 1
  store i32 %add14, ptr %11, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %13)
  %cmp = icmp eq i32 %13, 0
  br i1 %cmp, label %if.then17, label %if.end.do.end21_crit_edge

if.end.do.end21_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end21

if.then17:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %14 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %15, i32 0, i32 136
  %16 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %16)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end21

do.end21:                                         ; preds = %if.then17, %if.end.do.end21_crit_edge
  %task23 = getelementptr inbounds %struct.thread_info, ptr %6, i32 0, i32 2
  %17 = ptrtoint ptr %task23 to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load ptr, ptr %task23, align 8
  tail call void @irqtime_account_irq(ptr noundef %18, i32 noundef 65536) #11
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 1
  %21 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %22, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool27.not = icmp eq i32 %and, 0
  br i1 %tobool27.not, label %do.end40, label %do.end21.if.end46_crit_edge, !prof !1227

do.end21.if.end46_crit_edge:                      ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end46

do.end40:                                         ; preds = %do.end21
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2642, i32 noundef 9, ptr noundef null) #11
  br label %if.end46

if.end46:                                         ; preds = %do.end40, %do.end21.if.end46_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %23 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i57 = and i32 %23, -16384
  %24 = inttoptr i32 %and.i.i57 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 2
  %25 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load ptr, ptr %task.i, align 8
  tail call void @irqtime_account_irq(ptr noundef %26, i32 noundef 0) #11
  %cpu.i = getelementptr inbounds %struct.thread_info, ptr %24, i32 0, i32 3
  %27 = ptrtoint ptr %cpu.i to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %cpu.i, align 4
  %arrayidx.i = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %28
  %29 = ptrtoint ptr %arrayidx.i to i32
  call void @__asan_load4_noabort(i32 %29)
  %30 = load i32, ptr %arrayidx.i, align 4
  %add.i58 = add i32 %30, ptrtoint (ptr @hardirq_context to i32)
  %31 = inttoptr i32 %add.i58 to ptr
  %32 = ptrtoint ptr %31 to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load i32, ptr %31, align 4
  %add10.i = add i32 %33, -1
  store i32 %add10.i, ptr %31, align 4
  %34 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %34, -16384
  %35 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %35, i32 0, i32 1
  %36 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %36)
  %37 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %sub.i.i = add i32 %37, -65536
  store volatile i32 %sub.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_SOFTIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i34 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i34)
  %tobool.not = icmp eq i32 %and.i.i34, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool7.not = icmp eq i32 %and, 0
  br i1 %tobool7.not, label %do.end20, label %if.end.if.end26_crit_edge, !prof !1227

if.end.if.end26_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end26

do.end20:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2639, i32 noundef 9, ptr noundef null) #11
  br label %if.end26

if.end26:                                         ; preds = %do.end20, %if.end.if.end26_crit_edge
  %11 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 1
  %13 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %14, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %if.end26.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

if.end26.rcu_read_lock.exit_crit_edge:            ; preds = %if.end26
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %if.end26
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %if.end26.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %15 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %15, -16384
  %16 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %16, i32 0, i32 1
  %17 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %17)
  %18 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %18, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %19 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i35 = and i32 %19, -16384
  %20 = inttoptr i32 %and.i.i35 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %20, i32 0, i32 2
  %21 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %21)
  %22 = load ptr, ptr %task.i, align 8
  %softirq_context.i = getelementptr inbounds %struct.task_struct, ptr %22, i32 0, i32 139
  %23 = ptrtoint ptr %softirq_context.i to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load i32, ptr %softirq_context.i, align 4
  %dec.i = add i32 %24, -1
  store i32 %dec.i, ptr %softirq_context.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_SOFTIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i34 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i34)
  %tobool.not = icmp eq i32 %and.i.i34, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool7.not = icmp eq i32 %and, 0
  br i1 %tobool7.not, label %do.end20, label %if.end.if.end26_crit_edge, !prof !1227

if.end.if.end26_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end26

do.end20:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2640, i32 noundef 9, ptr noundef null) #11
  br label %if.end26

if.end26:                                         ; preds = %do.end20, %if.end.if.end26_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %11 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i35 = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i35 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 2
  %13 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %task.i, align 8
  %softirq_context.i = getelementptr inbounds %struct.task_struct, ptr %14, i32 0, i32 139
  %15 = ptrtoint ptr %softirq_context.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %softirq_context.i, align 4
  %dec.i = add i32 %16, -1
  store i32 %dec.i, ptr %softirq_context.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_SOFTIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i34 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i34)
  %tobool.not = icmp eq i32 %and.i.i34, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool7.not = icmp eq i32 %and, 0
  br i1 %tobool7.not, label %do.end20, label %if.end.if.end26_crit_edge, !prof !1227

if.end.if.end26_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end26

do.end20:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2641, i32 noundef 9, ptr noundef null) #11
  br label %if.end26

if.end26:                                         ; preds = %do.end20, %if.end.if.end26_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i35 = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i35 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 2
  %13 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %task.i, align 8
  %softirq_context.i = getelementptr inbounds %struct.task_struct, ptr %14, i32 0, i32 139
  %15 = ptrtoint ptr %softirq_context.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %softirq_context.i, align 4
  %dec.i = add i32 %16, -1
  store i32 %dec.i, ptr %softirq_context.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_SOFTIRQ() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable()
  %0 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i34 = and i32 %0, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i34)
  %tobool.not = icmp eq i32 %and.i.i34, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %1 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %1, -16384
  %2 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %2, i32 0, i32 2
  %3 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %3)
  %4 = load ptr, ptr %task, align 8
  %softirq_context = getelementptr inbounds %struct.task_struct, ptr %4, i32 0, i32 139
  %5 = ptrtoint ptr %softirq_context to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load i32, ptr %softirq_context, align 4
  %inc = add i32 %6, 1
  store i32 %inc, ptr %softirq_context, align 4
  %7 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %7, -16384
  %8 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %8, i32 0, i32 1
  %9 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %9)
  %10 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %10, 65280
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool7.not = icmp eq i32 %and, 0
  br i1 %tobool7.not, label %do.end20, label %if.end.if.end26_crit_edge, !prof !1227

if.end.if.end26_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end26

do.end20:                                         ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2642, i32 noundef 9, ptr noundef null) #11
  br label %if.end26

if.end26:                                         ; preds = %do.end20, %if.end.if.end26_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %11 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i35 = and i32 %11, -16384
  %12 = inttoptr i32 %and.i.i35 to ptr
  %task.i = getelementptr inbounds %struct.thread_info, ptr %12, i32 0, i32 2
  %13 = ptrtoint ptr %task.i to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load ptr, ptr %task.i, align 8
  %softirq_context.i = getelementptr inbounds %struct.task_struct, ptr %14, i32 0, i32 139
  %15 = ptrtoint ptr %softirq_context.i to i32
  call void @__asan_load4_noabort(i32 %15)
  %16 = load i32, ptr %softirq_context.i, align 4
  %dec.i = add i32 %16, -1
  store i32 %dec.i, ptr %softirq_context.i, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_RCU() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i2 = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i2 to ptr
  %preempt_count.i.i.i.i3 = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i3 to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i3, align 4
  %add.i.i.i4 = add i32 %7, 1
  store volatile i32 %add.i.i.i4, ptr %preempt_count.i.i.i.i3, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i5 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i5, label %rcu_read_lock.exit.rcu_read_lock.exit12_crit_edge, label %land.lhs.true.i8

rcu_read_lock.exit.rcu_read_lock.exit12_crit_edge: ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit12

land.lhs.true.i8:                                 ; preds = %rcu_read_lock.exit
  %call1.i6 = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i6)
  %tobool.not.i7 = icmp eq i32 %call1.i6, 0
  br i1 %tobool.not.i7, label %land.lhs.true.i8.rcu_read_lock.exit12_crit_edge, label %land.lhs.true2.i10

land.lhs.true.i8.rcu_read_lock.exit12_crit_edge:  ; preds = %land.lhs.true.i8
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit12

land.lhs.true2.i10:                               ; preds = %land.lhs.true.i8
  %.b4.i9 = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i9, label %land.lhs.true2.i10.rcu_read_lock.exit12_crit_edge, label %if.then.i11

land.lhs.true2.i10.rcu_read_lock.exit12_crit_edge: ; preds = %land.lhs.true2.i10
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit12

if.then.i11:                                      ; preds = %land.lhs.true2.i10
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit12

rcu_read_lock.exit12:                             ; preds = %if.then.i11, %land.lhs.true2.i10.rcu_read_lock.exit12_crit_edge, %land.lhs.true.i8.rcu_read_lock.exit12_crit_edge, %rcu_read_lock.exit.rcu_read_lock.exit12_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit12.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit12.rcu_exit.exit_crit_edge:     ; preds = %rcu_read_lock.exit12
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit12
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit12.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %8 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %11, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %call.i.i13 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i13, label %rcu_exit.exit.rcu_exit.exit23_crit_edge, label %land.lhs.true.i.i16

rcu_exit.exit.rcu_exit.exit23_crit_edge:          ; preds = %rcu_exit.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit23

land.lhs.true.i.i16:                              ; preds = %rcu_exit.exit
  %call1.i.i14 = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i14)
  %tobool.not.i.i15 = icmp eq i32 %call1.i.i14, 0
  br i1 %tobool.not.i.i15, label %land.lhs.true.i.i16.rcu_exit.exit23_crit_edge, label %land.lhs.true2.i.i18

land.lhs.true.i.i16.rcu_exit.exit23_crit_edge:    ; preds = %land.lhs.true.i.i16
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit23

land.lhs.true2.i.i18:                             ; preds = %land.lhs.true.i.i16
  %.b4.i.i17 = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i17, label %land.lhs.true2.i.i18.rcu_exit.exit23_crit_edge, label %if.then.i.i19

land.lhs.true2.i.i18.rcu_exit.exit23_crit_edge:   ; preds = %land.lhs.true2.i.i18
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit23

if.then.i.i19:                                    ; preds = %land.lhs.true2.i.i18
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit23

rcu_exit.exit23:                                  ; preds = %if.then.i.i19, %land.lhs.true2.i.i18.rcu_exit.exit23_crit_edge, %land.lhs.true.i.i16.rcu_exit.exit23_crit_edge, %rcu_exit.exit.rcu_exit.exit23_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %12 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i20 = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i.i.i.i20 to ptr
  %preempt_count.i.i.i.i.i21 = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i.i.i.i21 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i.i.i.i.i21, align 4
  %sub.i.i.i.i22 = add i32 %15, -1
  store volatile i32 %sub.i.i.i.i22, ptr %preempt_count.i.i.i.i.i21, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_RCU() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_RCU() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_RCU() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_RCU_BH() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable() #11
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_bh_lock_map) #11
  %call.i1 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i1, label %entry.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true.i4

entry.rcu_read_lock_bh.exit_crit_edge:            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true.i4:                                 ; preds = %entry
  %call1.i2 = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i2)
  %tobool.not.i3 = icmp eq i32 %call1.i2, 0
  br i1 %tobool.not.i3, label %land.lhs.true.i4.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true2.i6

land.lhs.true.i4.rcu_read_lock_bh.exit_crit_edge: ; preds = %land.lhs.true.i4
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true2.i6:                                ; preds = %land.lhs.true.i4
  %.b4.i5 = load i1, ptr @rcu_read_lock_bh.__warned, align 1
  br i1 %.b4.i5, label %land.lhs.true2.i6.rcu_read_lock_bh.exit_crit_edge, label %if.then.i7

land.lhs.true2.i6.rcu_read_lock_bh.exit_crit_edge: ; preds = %land.lhs.true2.i6
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

if.then.i7:                                       ; preds = %land.lhs.true2.i6
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 750, ptr noundef nonnull @.str.841) #11
  br label %rcu_read_lock_bh.exit

rcu_read_lock_bh.exit:                            ; preds = %if.then.i7, %land.lhs.true2.i6.rcu_read_lock_bh.exit_crit_edge, %land.lhs.true.i4.rcu_read_lock_bh.exit_crit_edge, %entry.rcu_read_lock_bh.exit_crit_edge
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %rcu_read_lock_bh.exit.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

rcu_read_lock_bh.exit.rcu_read_lock.exit_crit_edge: ; preds = %rcu_read_lock_bh.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %rcu_read_lock_bh.exit
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %rcu_read_lock_bh.exit.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %call.i.i8 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i8, label %rcu_exit.exit.rcu_bh_exit.exit_crit_edge, label %land.lhs.true.i.i11

rcu_exit.exit.rcu_bh_exit.exit_crit_edge:         ; preds = %rcu_exit.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true.i.i11:                              ; preds = %rcu_exit.exit
  %call1.i.i9 = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i9)
  %tobool.not.i.i10 = icmp eq i32 %call1.i.i9, 0
  br i1 %tobool.not.i.i10, label %land.lhs.true.i.i11.rcu_bh_exit.exit_crit_edge, label %land.lhs.true2.i.i13

land.lhs.true.i.i11.rcu_bh_exit.exit_crit_edge:   ; preds = %land.lhs.true.i.i11
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true2.i.i13:                             ; preds = %land.lhs.true.i.i11
  %.b4.i.i12 = load i1, ptr @rcu_read_unlock_bh.__warned, align 1
  br i1 %.b4.i.i12, label %land.lhs.true2.i.i13.rcu_bh_exit.exit_crit_edge, label %if.then.i.i14

land.lhs.true2.i.i13.rcu_bh_exit.exit_crit_edge:  ; preds = %land.lhs.true2.i.i13
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

if.then.i.i14:                                    ; preds = %land.lhs.true2.i.i13
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 761, ptr noundef nonnull @.str.840) #11
  br label %rcu_bh_exit.exit

rcu_bh_exit.exit:                                 ; preds = %if.then.i.i14, %land.lhs.true2.i.i13.rcu_bh_exit.exit_crit_edge, %land.lhs.true.i.i11.rcu_bh_exit.exit_crit_edge, %rcu_exit.exit.rcu_bh_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_bh_lock_map) #11
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_RCU_BH() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable() #11
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_bh_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_bh.exit_crit_edge:            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge:  ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock_bh.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge: ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 750, ptr noundef nonnull @.str.841) #11
  br label %rcu_read_lock_bh.exit

rcu_read_lock_bh.exit:                            ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, %entry.rcu_read_lock_bh.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge: ; preds = %rcu_read_lock_bh.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_bh.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge:     ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock_bh.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge:    ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 761, ptr noundef nonnull @.str.840) #11
  br label %rcu_bh_exit.exit

rcu_bh_exit.exit:                                 ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_bh_lock_map) #11
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_RCU_BH() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable() #11
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_bh_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_bh.exit_crit_edge:            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge:  ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock_bh.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge: ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 750, ptr noundef nonnull @.str.841) #11
  br label %rcu_read_lock_bh.exit

rcu_read_lock_bh.exit:                            ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, %entry.rcu_read_lock_bh.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge: ; preds = %rcu_read_lock_bh.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_bh.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge:     ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock_bh.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge:    ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 761, ptr noundef nonnull @.str.840) #11
  br label %rcu_bh_exit.exit

rcu_bh_exit.exit:                                 ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_bh_lock_map) #11
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_RCU_BH() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call fastcc void @local_bh_disable() #11
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_bh_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_bh.exit_crit_edge:            ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge:  ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock_bh.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge: ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_bh.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 750, ptr noundef nonnull @.str.841) #11
  br label %rcu_read_lock_bh.exit

rcu_read_lock_bh.exit:                            ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock_bh.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_bh.exit_crit_edge, %entry.rcu_read_lock_bh.exit_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge: ; preds = %rcu_read_lock_bh.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_bh.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge:     ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock_bh.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge:    ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_bh_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_bh.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 761, ptr noundef nonnull @.str.840) #11
  br label %rcu_bh_exit.exit

rcu_bh_exit.exit:                                 ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_bh_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_bh_exit.exit_crit_edge, %rcu_read_lock_bh.exit.rcu_bh_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_bh_lock_map) #11
  tail call fastcc void @local_bh_enable() #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_RCU_SCHED() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %3, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1231
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_sched_lock_map) #11
  %call.i1 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i1, label %entry.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true.i3

entry.rcu_read_lock_sched.exit_crit_edge:         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true.i3:                                 ; preds = %entry
  %call2.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2.i)
  %tobool.not.i2 = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i2, label %land.lhs.true.i3.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true3.i

land.lhs.true.i3.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true.i3
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i3
  %.b6.i = load i1, ptr @rcu_read_lock_sched.__warned, align 1
  br i1 %.b6.i, label %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, label %if.then.i4

land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

if.then.i4:                                       ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 788, ptr noundef nonnull @.str.843) #11
  br label %rcu_read_lock_sched.exit

rcu_read_lock_sched.exit:                         ; preds = %if.then.i4, %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, %land.lhs.true.i3.rcu_read_lock_sched.exit_crit_edge, %entry.rcu_read_lock_sched.exit_crit_edge
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %7, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %rcu_read_lock_sched.exit.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

rcu_read_lock_sched.exit.rcu_read_lock.exit_crit_edge: ; preds = %rcu_read_lock_sched.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %rcu_read_lock_sched.exit
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %rcu_read_lock_sched.exit.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %8 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %8, -16384
  %9 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %9, i32 0, i32 1
  %10 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %10)
  %11 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %11, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  %call.i.i5 = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i5, label %rcu_exit.exit.rcu_sched_exit.exit_crit_edge, label %land.lhs.true.i.i8

rcu_exit.exit.rcu_sched_exit.exit_crit_edge:      ; preds = %rcu_exit.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true.i.i8:                               ; preds = %rcu_exit.exit
  %call1.i.i6 = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i6)
  %tobool.not.i.i7 = icmp eq i32 %call1.i.i6, 0
  br i1 %tobool.not.i.i7, label %land.lhs.true.i.i8.rcu_sched_exit.exit_crit_edge, label %land.lhs.true2.i.i9

land.lhs.true.i.i8.rcu_sched_exit.exit_crit_edge: ; preds = %land.lhs.true.i.i8
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true2.i.i9:                              ; preds = %land.lhs.true.i.i8
  %.b6.i.i = load i1, ptr @rcu_read_unlock_sched.__warned, align 1
  br i1 %.b6.i.i, label %land.lhs.true2.i.i9.rcu_sched_exit.exit_crit_edge, label %if.then.i.i10

land.lhs.true2.i.i9.rcu_sched_exit.exit_crit_edge: ; preds = %land.lhs.true2.i.i9
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

if.then.i.i10:                                    ; preds = %land.lhs.true2.i.i9
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 806, ptr noundef nonnull @.str.842) #11
  br label %rcu_sched_exit.exit

rcu_sched_exit.exit:                              ; preds = %if.then.i.i10, %land.lhs.true2.i.i9.rcu_sched_exit.exit_crit_edge, %land.lhs.true.i.i8.rcu_sched_exit.exit_crit_edge, %rcu_exit.exit.rcu_sched_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_sched_lock_map) #11
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1232
  %12 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i11 = and i32 %12, -16384
  %13 = inttoptr i32 %and.i.i.i.i.i11 to ptr
  %preempt_count.i.i.i.i12 = getelementptr inbounds %struct.thread_info, ptr %13, i32 0, i32 1
  %14 = ptrtoint ptr %preempt_count.i.i.i.i12 to i32
  call void @__asan_load4_noabort(i32 %14)
  %15 = load volatile i32, ptr %preempt_count.i.i.i.i12, align 4
  %sub.i.i.i = add i32 %15, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i12, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_RCU_SCHED() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %3, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1231
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_sched_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_sched.exit_crit_edge:         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true.i:                                  ; preds = %entry
  %call2.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2.i)
  %tobool.not.i = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true3.i

land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %.b6.i = load i1, ptr @rcu_read_lock_sched.__warned, align 1
  br i1 %.b6.i, label %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, label %if.then.i

land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

if.then.i:                                        ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 788, ptr noundef nonnull @.str.843) #11
  br label %rcu_read_lock_sched.exit

rcu_read_lock_sched.exit:                         ; preds = %if.then.i, %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, %entry.rcu_read_lock_sched.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge: ; preds = %rcu_read_lock_sched.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_sched.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge:  ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b6.i.i = load i1, ptr @rcu_read_unlock_sched.__warned, align 1
  br i1 %.b6.i.i, label %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge: ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 806, ptr noundef nonnull @.str.842) #11
  br label %rcu_sched_exit.exit

rcu_sched_exit.exit:                              ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_sched_lock_map) #11
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1232
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %sub.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_RCU_SCHED() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %3, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1231
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_sched_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_sched.exit_crit_edge:         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true.i:                                  ; preds = %entry
  %call2.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2.i)
  %tobool.not.i = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true3.i

land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %.b6.i = load i1, ptr @rcu_read_lock_sched.__warned, align 1
  br i1 %.b6.i, label %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, label %if.then.i

land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

if.then.i:                                        ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 788, ptr noundef nonnull @.str.843) #11
  br label %rcu_read_lock_sched.exit

rcu_read_lock_sched.exit:                         ; preds = %if.then.i, %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, %entry.rcu_read_lock_sched.exit_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge: ; preds = %rcu_read_lock_sched.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_sched.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge:  ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b6.i.i = load i1, ptr @rcu_read_unlock_sched.__warned, align 1
  br i1 %.b6.i.i, label %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge: ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 806, ptr noundef nonnull @.str.842) #11
  br label %rcu_sched_exit.exit

rcu_sched_exit.exit:                              ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_sched_lock_map) #11
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1232
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %sub.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_RCU_SCHED() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i to ptr
  %preempt_count.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i, align 4
  %add.i.i = add i32 %3, 1
  store volatile i32 %add.i.i, ptr %preempt_count.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1231
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_sched_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock_sched.exit_crit_edge:         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true.i:                                  ; preds = %entry
  %call2.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call2.i)
  %tobool.not.i = icmp eq i32 %call2.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, label %land.lhs.true3.i

land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

land.lhs.true3.i:                                 ; preds = %land.lhs.true.i
  %.b6.i = load i1, ptr @rcu_read_lock_sched.__warned, align 1
  br i1 %.b6.i, label %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, label %if.then.i

land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge: ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock_sched.exit

if.then.i:                                        ; preds = %land.lhs.true3.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 788, ptr noundef nonnull @.str.843) #11
  br label %rcu_read_lock_sched.exit

rcu_read_lock_sched.exit:                         ; preds = %if.then.i, %land.lhs.true3.i.rcu_read_lock_sched.exit_crit_edge, %land.lhs.true.i.rcu_read_lock_sched.exit_crit_edge, %entry.rcu_read_lock_sched.exit_crit_edge
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge: ; preds = %rcu_read_lock_sched.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock_sched.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge:  ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b6.i.i = load i1, ptr @rcu_read_unlock_sched.__warned, align 1
  br i1 %.b6.i.i, label %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge: ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_sched_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock_sched.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 806, ptr noundef nonnull @.str.842) #11
  br label %rcu_sched_exit.exit

rcu_sched_exit.exit:                              ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_sched_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_sched_exit.exit_crit_edge, %rcu_read_lock_sched.exit.rcu_sched_exit.exit_crit_edge
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_sched_lock_map) #11
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1232
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %sub.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_RAW_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_A) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_RAW_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_RAW_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_RAW_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_SPINLOCK() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RCU_in_MUTEX() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i.i.i, align 4
  %add.i.i.i = add i32 %3, 1
  store volatile i32 %add.i.i.i, ptr %preempt_count.i.i.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1229
  tail call fastcc void @rcu_lock_acquire(ptr noundef nonnull @rcu_lock_map) #11
  %call.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i, label %entry.rcu_read_lock.exit_crit_edge, label %land.lhs.true.i

entry.rcu_read_lock.exit_crit_edge:               ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true.i:                                  ; preds = %entry
  %call1.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i)
  %tobool.not.i = icmp eq i32 %call1.i, 0
  br i1 %tobool.not.i, label %land.lhs.true.i.rcu_read_lock.exit_crit_edge, label %land.lhs.true2.i

land.lhs.true.i.rcu_read_lock.exit_crit_edge:     ; preds = %land.lhs.true.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

land.lhs.true2.i:                                 ; preds = %land.lhs.true.i
  %.b4.i = load i1, ptr @rcu_read_lock.__warned, align 1
  br i1 %.b4.i, label %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, label %if.then.i

land.lhs.true2.i.rcu_read_lock.exit_crit_edge:    ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_read_lock.exit

if.then.i:                                        ; preds = %land.lhs.true2.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_lock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 696, ptr noundef nonnull @.str.839) #11
  br label %rcu_read_lock.exit

rcu_read_lock.exit:                               ; preds = %if.then.i, %land.lhs.true2.i.rcu_read_lock.exit_crit_edge, %land.lhs.true.i.rcu_read_lock.exit_crit_edge, %entry.rcu_read_lock.exit_crit_edge
  %call.i.i = tail call zeroext i1 @rcu_is_watching() #11
  br i1 %call.i.i, label %rcu_read_lock.exit.rcu_exit.exit_crit_edge, label %land.lhs.true.i.i

rcu_read_lock.exit.rcu_exit.exit_crit_edge:       ; preds = %rcu_read_lock.exit
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true.i.i:                                ; preds = %rcu_read_lock.exit
  %call1.i.i = tail call i32 @debug_lockdep_rcu_enabled() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call1.i.i)
  %tobool.not.i.i = icmp eq i32 %call1.i.i, 0
  br i1 %tobool.not.i.i, label %land.lhs.true.i.i.rcu_exit.exit_crit_edge, label %land.lhs.true2.i.i

land.lhs.true.i.i.rcu_exit.exit_crit_edge:        ; preds = %land.lhs.true.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

land.lhs.true2.i.i:                               ; preds = %land.lhs.true.i.i
  %.b4.i.i = load i1, ptr @rcu_read_unlock.__warned, align 1
  br i1 %.b4.i.i, label %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, label %if.then.i.i

land.lhs.true2.i.i.rcu_exit.exit_crit_edge:       ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  br label %rcu_exit.exit

if.then.i.i:                                      ; preds = %land.lhs.true2.i.i
  call void @__sanitizer_cov_trace_pc() #10
  store i1 true, ptr @rcu_read_unlock.__warned, align 1
  tail call void @lockdep_rcu_suspicious(ptr noundef nonnull @.str.837, i32 noundef 724, ptr noundef nonnull @.str.838) #11
  br label %rcu_exit.exit

rcu_exit.exit:                                    ; preds = %if.then.i.i, %land.lhs.true2.i.i.rcu_exit.exit_crit_edge, %land.lhs.true.i.i.rcu_exit.exit_crit_edge, %rcu_read_lock.exit.rcu_exit.exit_crit_edge
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1230
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i.i.i.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i.i.i.i.i.i to ptr
  %preempt_count.i.i.i.i.i = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 1
  %6 = ptrtoint ptr %preempt_count.i.i.i.i.i to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load volatile i32, ptr %preempt_count.i.i.i.i.i, align 4
  %sub.i.i.i.i = add i32 %7, -1
  store volatile i32 %sub.i.i.i.i, ptr %preempt_count.i.i.i.i.i, align 4
  tail call void @rcu_read_unlock_strict() #11
  tail call fastcc void @rcu_lock_release(ptr noundef nonnull @rcu_lock_map) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @RAW_SPINLOCK_in_MUTEX() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @raw_lock_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @SPINLOCK_in_MUTEX() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @MUTEX_in_MUTEX() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_A, i32 noundef 0) #11
  tail call void @mutex_lock_nested(ptr noundef nonnull @mutex_B, i32 noundef 0) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_B) #11
  tail call void @mutex_unlock(ptr noundef nonnull @mutex_A) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local zeroext i1 @rcu_is_watching() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local i32 @debug_lockdep_rcu_enabled() local_unnamed_addr #3

; Function Attrs: null_pointer_is_valid
declare dso_local void @lockdep_rcu_suspicious(ptr noundef, i32 noundef, ptr noundef) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rcu_lock_release(ptr noundef %map) #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @lock_release(ptr noundef %map, i32 noundef ptrtoint (ptr blockaddress(@rcu_lock_release, %__here) to i32)) #11
  ret void
}

; Function Attrs: null_pointer_is_valid
declare dso_local void @rcu_read_unlock_strict() local_unnamed_addr #3

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @rcu_lock_acquire(ptr noundef %map) #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @lock_acquire(ptr noundef %map, i32 noundef 0, i32 noundef 0, i32 noundef 2, i32 noundef 0, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@rcu_lock_acquire, %__here) to i32)) #11
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @local_lock_2() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1233
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %add = add i32 %9, ptrtoint (ptr @local_A to i32)
  %10 = inttoptr i32 %add to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %10)
  %11 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu, align 4
  %arrayidx15 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %12
  %13 = ptrtoint ptr %arrayidx15 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %arrayidx15, align 4
  %add16 = add i32 %14, ptrtoint (ptr @local_A to i32)
  %15 = inttoptr i32 %add16 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %15)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1234
  %16 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i169 = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i169 to ptr
  %preempt_count.i.i170 = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i170 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i170, align 4
  %sub.i = add i32 %19, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i170, align 4
  %20 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i183 = and i32 %20, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i183)
  %tobool.not = icmp eq i32 %and.i.i183, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %21 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i171 = and i32 %21, -16384
  %22 = inttoptr i32 %and.i.i.i171 to ptr
  %preempt_count.i.i172 = getelementptr inbounds %struct.thread_info, ptr %22, i32 0, i32 1
  %23 = ptrtoint ptr %preempt_count.i.i172 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %preempt_count.i.i172, align 4
  %add.i173 = add i32 %24, 65536
  store volatile i32 %add.i173, ptr %preempt_count.i.i172, align 4
  %25 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %cpu, align 4
  %arrayidx39 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %26
  %27 = ptrtoint ptr %arrayidx39 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %arrayidx39, align 4
  %add40 = add i32 %28, ptrtoint (ptr @hardirq_context to i32)
  %29 = inttoptr i32 %add40 to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %29, align 4
  %add41 = add i32 %31, 1
  store i32 %add41, ptr %29, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %31)
  %cmp = icmp eq i32 %31, 0
  br i1 %cmp, label %if.then44, label %if.end.do.end48_crit_edge

if.end.do.end48_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end48

if.then44:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %32 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %33, i32 0, i32 136
  %34 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end48

do.end48:                                         ; preds = %if.then44, %if.end.do.end48_crit_edge
  %task50 = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %35 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %36, i32 noundef 65536) #11
  %37 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %task50, align 8
  %hardirq_threaded56 = getelementptr inbounds %struct.task_struct, ptr %38, i32 0, i32 136
  %39 = ptrtoint ptr %hardirq_threaded56 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 1, ptr %hardirq_threaded56, align 16
  %40 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %40, -16384
  %41 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %41, i32 0, i32 1
  %42 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %43, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool60.not = icmp eq i32 %and, 0
  br i1 %tobool60.not, label %do.end73, label %do.end48.if.end79_crit_edge, !prof !1227

do.end48.if.end79_crit_edge:                      ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end79

do.end73:                                         ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2717, i32 noundef 9, ptr noundef null) #11
  br label %if.end79

if.end79:                                         ; preds = %do.end73, %do.end48.if.end79_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %44 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %45, i32 noundef 0) #11
  %46 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %cpu, align 4
  %arrayidx106 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %47
  %48 = ptrtoint ptr %arrayidx106 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx106, align 4
  %add107 = add i32 %49, ptrtoint (ptr @hardirq_context to i32)
  %50 = inttoptr i32 %add107 to ptr
  %51 = ptrtoint ptr %50 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %50, align 4
  %add108 = add i32 %52, -1
  store i32 %add108, ptr %50, align 4
  %53 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i174 = and i32 %53, -16384
  %54 = inttoptr i32 %and.i.i.i174 to ptr
  %preempt_count.i.i175 = getelementptr inbounds %struct.thread_info, ptr %54, i32 0, i32 1
  %55 = ptrtoint ptr %preempt_count.i.i175 to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load volatile i32, ptr %preempt_count.i.i175, align 4
  %sub.i176 = add i32 %56, -65536
  store volatile i32 %sub.i176, ptr %preempt_count.i.i175, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %57 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i184 = and i32 %57, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i184)
  %tobool123.not = icmp eq i32 %and.i.i184, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool123.not, label %if.then126, label %if.end79.if.end127_crit_edge

if.end79.if.end127_crit_edge:                     ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end127

if.then126:                                       ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end127

if.end127:                                        ; preds = %if.then126, %if.end79.if.end127_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %58 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i177 = and i32 %58, -16384
  %59 = inttoptr i32 %and.i.i.i177 to ptr
  %preempt_count.i.i178 = getelementptr inbounds %struct.thread_info, ptr %59, i32 0, i32 1
  %60 = ptrtoint ptr %preempt_count.i.i178 to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load volatile i32, ptr %preempt_count.i.i178, align 4
  %add.i179 = add i32 %61, 1
  store volatile i32 %add.i179, ptr %preempt_count.i.i178, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1235
  %62 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %cpu, align 4
  %arrayidx143 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %63
  %64 = ptrtoint ptr %arrayidx143 to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %arrayidx143, align 4
  %add144 = add i32 %65, ptrtoint (ptr @local_A to i32)
  %66 = inttoptr i32 %add144 to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %66)
  %67 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %cpu, align 4
  %arrayidx157 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %68
  %69 = ptrtoint ptr %arrayidx157 to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %arrayidx157, align 4
  %add158 = add i32 %70, ptrtoint (ptr @local_A to i32)
  %71 = inttoptr i32 %add158 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %71)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1236
  %72 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i180 = and i32 %72, -16384
  %73 = inttoptr i32 %and.i.i.i180 to ptr
  %preempt_count.i.i181 = getelementptr inbounds %struct.thread_info, ptr %73, i32 0, i32 1
  %74 = ptrtoint ptr %preempt_count.i.i181 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load volatile i32, ptr %preempt_count.i.i181, align 4
  %sub.i182 = add i32 %75, -1
  store volatile i32 %sub.i182, ptr %preempt_count.i.i181, align 4
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @local_lock_3A() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1237
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %add = add i32 %9, ptrtoint (ptr @local_A to i32)
  %10 = inttoptr i32 %add to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %10)
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu, align 4
  %arrayidx15 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %12
  %13 = ptrtoint ptr %arrayidx15 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %arrayidx15, align 4
  %add16 = add i32 %14, ptrtoint (ptr @local_A to i32)
  %15 = inttoptr i32 %add16 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %15)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1238
  %16 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i169 = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i169 to ptr
  %preempt_count.i.i170 = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i170 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i170, align 4
  %sub.i = add i32 %19, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i170, align 4
  %20 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i183 = and i32 %20, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i183)
  %tobool.not = icmp eq i32 %and.i.i183, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %21 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i171 = and i32 %21, -16384
  %22 = inttoptr i32 %and.i.i.i171 to ptr
  %preempt_count.i.i172 = getelementptr inbounds %struct.thread_info, ptr %22, i32 0, i32 1
  %23 = ptrtoint ptr %preempt_count.i.i172 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %preempt_count.i.i172, align 4
  %add.i173 = add i32 %24, 65536
  store volatile i32 %add.i173, ptr %preempt_count.i.i172, align 4
  %25 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %cpu, align 4
  %arrayidx39 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %26
  %27 = ptrtoint ptr %arrayidx39 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %arrayidx39, align 4
  %add40 = add i32 %28, ptrtoint (ptr @hardirq_context to i32)
  %29 = inttoptr i32 %add40 to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %29, align 4
  %add41 = add i32 %31, 1
  store i32 %add41, ptr %29, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %31)
  %cmp = icmp eq i32 %31, 0
  br i1 %cmp, label %if.then44, label %if.end.do.end48_crit_edge

if.end.do.end48_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end48

if.then44:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %32 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %33, i32 0, i32 136
  %34 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end48

do.end48:                                         ; preds = %if.then44, %if.end.do.end48_crit_edge
  %task50 = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %35 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %36, i32 noundef 65536) #11
  %37 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %task50, align 8
  %hardirq_threaded56 = getelementptr inbounds %struct.task_struct, ptr %38, i32 0, i32 136
  %39 = ptrtoint ptr %hardirq_threaded56 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 1, ptr %hardirq_threaded56, align 16
  %40 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %40, -16384
  %41 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %41, i32 0, i32 1
  %42 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %43, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool60.not = icmp eq i32 %and, 0
  br i1 %tobool60.not, label %do.end73, label %do.end48.if.end79_crit_edge, !prof !1227

do.end48.if.end79_crit_edge:                      ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end79

do.end73:                                         ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2737, i32 noundef 9, ptr noundef null) #11
  br label %if.end79

if.end79:                                         ; preds = %do.end73, %do.end48.if.end79_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %44 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %45, i32 noundef 0) #11
  %46 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %cpu, align 4
  %arrayidx106 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %47
  %48 = ptrtoint ptr %arrayidx106 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx106, align 4
  %add107 = add i32 %49, ptrtoint (ptr @hardirq_context to i32)
  %50 = inttoptr i32 %add107 to ptr
  %51 = ptrtoint ptr %50 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %50, align 4
  %add108 = add i32 %52, -1
  store i32 %add108, ptr %50, align 4
  %53 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i174 = and i32 %53, -16384
  %54 = inttoptr i32 %and.i.i.i174 to ptr
  %preempt_count.i.i175 = getelementptr inbounds %struct.thread_info, ptr %54, i32 0, i32 1
  %55 = ptrtoint ptr %preempt_count.i.i175 to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load volatile i32, ptr %preempt_count.i.i175, align 4
  %sub.i176 = add i32 %56, -65536
  store volatile i32 %sub.i176, ptr %preempt_count.i.i175, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %57 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i184 = and i32 %57, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i184)
  %tobool123.not = icmp eq i32 %and.i.i184, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool123.not, label %if.then126, label %if.end79.if.end127_crit_edge

if.end79.if.end127_crit_edge:                     ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end127

if.then126:                                       ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end127

if.end127:                                        ; preds = %if.then126, %if.end79.if.end127_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %58 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i177 = and i32 %58, -16384
  %59 = inttoptr i32 %and.i.i.i177 to ptr
  %preempt_count.i.i178 = getelementptr inbounds %struct.thread_info, ptr %59, i32 0, i32 1
  %60 = ptrtoint ptr %preempt_count.i.i178 to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load volatile i32, ptr %preempt_count.i.i178, align 4
  %add.i179 = add i32 %61, 1
  store volatile i32 %add.i179, ptr %preempt_count.i.i178, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1239
  %62 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %cpu, align 4
  %arrayidx143 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %63
  %64 = ptrtoint ptr %arrayidx143 to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %arrayidx143, align 4
  %add144 = add i32 %65, ptrtoint (ptr @local_A to i32)
  %66 = inttoptr i32 %add144 to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %66)
  %67 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %cpu, align 4
  %arrayidx157 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %68
  %69 = ptrtoint ptr %arrayidx157 to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %arrayidx157, align 4
  %add158 = add i32 %70, ptrtoint (ptr @local_A to i32)
  %71 = inttoptr i32 %add158 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %71)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1240
  %72 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i180 = and i32 %72, -16384
  %73 = inttoptr i32 %and.i.i.i180 to ptr
  %preempt_count.i.i181 = getelementptr inbounds %struct.thread_info, ptr %73, i32 0, i32 1
  %74 = ptrtoint ptr %preempt_count.i.i181 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load volatile i32, ptr %preempt_count.i.i181, align 4
  %sub.i182 = add i32 %75, -1
  store volatile i32 %sub.i182, ptr %preempt_count.i.i181, align 4
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  ret void
}

; Function Attrs: nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal void @local_lock_3B() #1 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  %0 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i = and i32 %0, -16384
  %1 = inttoptr i32 %and.i.i.i to ptr
  %preempt_count.i.i = getelementptr inbounds %struct.thread_info, ptr %1, i32 0, i32 1
  %2 = ptrtoint ptr %preempt_count.i.i to i32
  call void @__asan_load4_noabort(i32 %2)
  %3 = load volatile i32, ptr %preempt_count.i.i, align 4
  %add.i = add i32 %3, 1
  store volatile i32 %add.i, ptr %preempt_count.i.i, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1241
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %cpu = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 3
  %6 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load i32, ptr %cpu, align 4
  %arrayidx = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %7
  %8 = ptrtoint ptr %arrayidx to i32
  call void @__asan_load4_noabort(i32 %8)
  %9 = load i32, ptr %arrayidx, align 4
  %add = add i32 %9, ptrtoint (ptr @local_A to i32)
  %10 = inttoptr i32 %add to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %10)
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  %11 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %11)
  %12 = load i32, ptr %cpu, align 4
  %arrayidx15 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %12
  %13 = ptrtoint ptr %arrayidx15 to i32
  call void @__asan_load4_noabort(i32 %13)
  %14 = load i32, ptr %arrayidx15, align 4
  %add16 = add i32 %14, ptrtoint (ptr @local_A to i32)
  %15 = inttoptr i32 %add16 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %15)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1242
  %16 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i189 = and i32 %16, -16384
  %17 = inttoptr i32 %and.i.i.i189 to ptr
  %preempt_count.i.i190 = getelementptr inbounds %struct.thread_info, ptr %17, i32 0, i32 1
  %18 = ptrtoint ptr %preempt_count.i.i190 to i32
  call void @__asan_load4_noabort(i32 %18)
  %19 = load volatile i32, ptr %preempt_count.i.i190, align 4
  %sub.i = add i32 %19, -1
  store volatile i32 %sub.i, ptr %preempt_count.i.i190, align 4
  %20 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i203 = and i32 %20, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i203)
  %tobool.not = icmp eq i32 %and.i.i203, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool.not, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end

if.then:                                          ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry.if.end_crit_edge
  %21 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i191 = and i32 %21, -16384
  %22 = inttoptr i32 %and.i.i.i191 to ptr
  %preempt_count.i.i192 = getelementptr inbounds %struct.thread_info, ptr %22, i32 0, i32 1
  %23 = ptrtoint ptr %preempt_count.i.i192 to i32
  call void @__asan_load4_noabort(i32 %23)
  %24 = load volatile i32, ptr %preempt_count.i.i192, align 4
  %add.i193 = add i32 %24, 65536
  store volatile i32 %add.i193, ptr %preempt_count.i.i192, align 4
  %25 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %25)
  %26 = load i32, ptr %cpu, align 4
  %arrayidx39 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %26
  %27 = ptrtoint ptr %arrayidx39 to i32
  call void @__asan_load4_noabort(i32 %27)
  %28 = load i32, ptr %arrayidx39, align 4
  %add40 = add i32 %28, ptrtoint (ptr @hardirq_context to i32)
  %29 = inttoptr i32 %add40 to ptr
  %30 = ptrtoint ptr %29 to i32
  call void @__asan_load4_noabort(i32 %30)
  %31 = load i32, ptr %29, align 4
  %add41 = add i32 %31, 1
  store i32 %add41, ptr %29, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %31)
  %cmp = icmp eq i32 %31, 0
  br i1 %cmp, label %if.then44, label %if.end.do.end48_crit_edge

if.end.do.end48_crit_edge:                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %do.end48

if.then44:                                        ; preds = %if.end
  call void @__sanitizer_cov_trace_pc() #10
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %32 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %32)
  %33 = load ptr, ptr %task, align 8
  %hardirq_threaded = getelementptr inbounds %struct.task_struct, ptr %33, i32 0, i32 136
  %34 = ptrtoint ptr %hardirq_threaded to i32
  call void @__asan_store4_noabort(i32 %34)
  store i32 0, ptr %hardirq_threaded, align 16
  br label %do.end48

do.end48:                                         ; preds = %if.then44, %if.end.do.end48_crit_edge
  %task50 = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %35 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %35)
  %36 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %36, i32 noundef 65536) #11
  %37 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %37)
  %38 = load ptr, ptr %task50, align 8
  %hardirq_threaded56 = getelementptr inbounds %struct.task_struct, ptr %38, i32 0, i32 136
  %39 = ptrtoint ptr %hardirq_threaded56 to i32
  call void @__asan_store4_noabort(i32 %39)
  store i32 1, ptr %hardirq_threaded56, align 16
  %40 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i = and i32 %40, -16384
  %41 = inttoptr i32 %and.i.i to ptr
  %preempt_count.i = getelementptr inbounds %struct.thread_info, ptr %41, i32 0, i32 1
  %42 = ptrtoint ptr %preempt_count.i to i32
  call void @__asan_load4_noabort(i32 %42)
  %43 = load volatile i32, ptr %preempt_count.i, align 4
  %and = and i32 %43, 983040
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and)
  %tobool60.not = icmp eq i32 %and, 0
  br i1 %tobool60.not, label %do.end73, label %do.end48.if.end79_crit_edge, !prof !1227

do.end48.if.end79_crit_edge:                      ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end79

do.end73:                                         ; preds = %do.end48
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.2, i32 noundef 2757, i32 noundef 9, ptr noundef null) #11
  br label %if.end79

if.end79:                                         ; preds = %do.end73, %do.end48.if.end79_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %44 = ptrtoint ptr %task50 to i32
  call void @__asan_load4_noabort(i32 %44)
  %45 = load ptr, ptr %task50, align 8
  tail call void @irqtime_account_irq(ptr noundef %45, i32 noundef 0) #11
  %46 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %46)
  %47 = load i32, ptr %cpu, align 4
  %arrayidx106 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %47
  %48 = ptrtoint ptr %arrayidx106 to i32
  call void @__asan_load4_noabort(i32 %48)
  %49 = load i32, ptr %arrayidx106, align 4
  %add107 = add i32 %49, ptrtoint (ptr @hardirq_context to i32)
  %50 = inttoptr i32 %add107 to ptr
  %51 = ptrtoint ptr %50 to i32
  call void @__asan_load4_noabort(i32 %51)
  %52 = load i32, ptr %50, align 4
  %add108 = add i32 %52, -1
  store i32 %add108, ptr %50, align 4
  %53 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i194 = and i32 %53, -16384
  %54 = inttoptr i32 %and.i.i.i194 to ptr
  %preempt_count.i.i195 = getelementptr inbounds %struct.thread_info, ptr %54, i32 0, i32 1
  %55 = ptrtoint ptr %preempt_count.i.i195 to i32
  call void @__asan_load4_noabort(i32 %55)
  %56 = load volatile i32, ptr %preempt_count.i.i195, align 4
  %sub.i196 = add i32 %56, -65536
  store volatile i32 %sub.i196, ptr %preempt_count.i.i195, align 4
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %57 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i204 = and i32 %57, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i204)
  %tobool123.not = icmp eq i32 %and.i.i204, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool123.not, label %if.then126, label %if.end79.if.end127_crit_edge

if.end79.if.end127_crit_edge:                     ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end127

if.then126:                                       ; preds = %if.end79
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end127

if.end127:                                        ; preds = %if.then126, %if.end79.if.end127_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  %58 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i197 = and i32 %58, -16384
  %59 = inttoptr i32 %and.i.i.i197 to ptr
  %preempt_count.i.i198 = getelementptr inbounds %struct.thread_info, ptr %59, i32 0, i32 1
  %60 = ptrtoint ptr %preempt_count.i.i198 to i32
  call void @__asan_load4_noabort(i32 %60)
  %61 = load volatile i32, ptr %preempt_count.i.i198, align 4
  %add.i199 = add i32 %61, 1
  store volatile i32 %add.i199, ptr %preempt_count.i.i198, align 4
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1243
  %62 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %62)
  %63 = load i32, ptr %cpu, align 4
  %arrayidx143 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %63
  %64 = ptrtoint ptr %arrayidx143 to i32
  call void @__asan_load4_noabort(i32 %64)
  %65 = load i32, ptr %arrayidx143, align 4
  %add144 = add i32 %65, ptrtoint (ptr @local_A to i32)
  %66 = inttoptr i32 %add144 to ptr
  tail call fastcc void @local_lock_acquire(ptr noundef %66)
  %67 = ptrtoint ptr %cpu to i32
  call void @__asan_load4_noabort(i32 %67)
  %68 = load i32, ptr %cpu, align 4
  %arrayidx157 = getelementptr [4 x i32], ptr @__per_cpu_offset, i32 0, i32 %68
  %69 = ptrtoint ptr %arrayidx157 to i32
  call void @__asan_load4_noabort(i32 %69)
  %70 = load i32, ptr %arrayidx157, align 4
  %add158 = add i32 %70, ptrtoint (ptr @local_A to i32)
  %71 = inttoptr i32 %add158 to ptr
  tail call fastcc void @local_lock_release(ptr noundef %71)
  tail call void asm sideeffect "", "~{memory}"() #11, !srcloc !1244
  %72 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i.i.i200 = and i32 %72, -16384
  %73 = inttoptr i32 %and.i.i.i200 to ptr
  %preempt_count.i.i201 = getelementptr inbounds %struct.thread_info, ptr %73, i32 0, i32 1
  %74 = ptrtoint ptr %preempt_count.i.i201 to i32
  call void @__asan_load4_noabort(i32 %74)
  %75 = load volatile i32, ptr %preempt_count.i.i201, align 4
  %sub.i202 = add i32 %75, -1
  store volatile i32 %sub.i202, ptr %preempt_count.i.i201, align 4
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  tail call void @trace_hardirqs_on() #11
  tail call void asm sideeffect "\09cpsie i\09\09\09@ arch_local_irq_enable", "~{memory},~{cc}"() #11, !srcloc !1226
  %76 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i205 = and i32 %76, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i205)
  %tobool170.not = icmp eq i32 %and.i.i205, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool170.not, label %if.then173, label %if.end127.if.end174_crit_edge

if.end127.if.end174_crit_edge:                    ; preds = %if.end127
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end174

if.then173:                                       ; preds = %if.end127
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end174

if.end174:                                        ; preds = %if.then173, %if.end127.if.end174_crit_edge
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_A) #11
  tail call void @_raw_spin_lock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_B) #11
  tail call void @_raw_spin_unlock(ptr noundef nonnull @lock_A) #11
  %77 = tail call i32 asm sideeffect "\09mrs\09$0, cpsr\09@ local_save_flags", "=r,~{memory},~{cc}"() #11, !srcloc !1223
  %and.i.i206 = and i32 %77, 128
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %and.i.i206)
  %tobool180.not = icmp eq i32 %and.i.i206, 0
  tail call void asm sideeffect "\09cpsid i\09\09\09@ arch_local_irq_disable", "~{memory},~{cc}"() #11, !srcloc !1225
  br i1 %tobool180.not, label %if.then183, label %if.end174.if.end184_crit_edge

if.end174.if.end184_crit_edge:                    ; preds = %if.end174
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end184

if.then183:                                       ; preds = %if.end174
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @trace_hardirqs_off() #11
  br label %if.end184

if.end184:                                        ; preds = %if.then183, %if.end174.if.end184_crit_edge
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @local_lock_acquire(ptr noundef %l) #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  br label %__here

__here:                                           ; preds = %entry
  tail call void @lock_acquire(ptr noundef %l, i32 noundef 0, i32 noundef 0, i32 noundef 0, i32 noundef 1, ptr noundef null, i32 noundef ptrtoint (ptr blockaddress(@local_lock_acquire, %__here) to i32)) #11
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %0 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %0)
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %land.lhs.true, label %__here.if.end36_crit_edge

__here.if.end36_crit_edge:                        ; preds = %__here
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

land.lhs.true:                                    ; preds = %__here
  %owner = getelementptr inbounds %struct.local_lock_t, ptr %l, i32 0, i32 1
  %1 = ptrtoint ptr %owner to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %owner, align 4
  %tobool1.not = icmp eq ptr %2, null
  br i1 %tobool1.not, label %land.lhs.true.if.end36_crit_edge, label %do.end, !prof !1224

land.lhs.true.if.end36_crit_edge:                 ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

do.end:                                           ; preds = %land.lhs.true
  %call = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call)
  %tobool4.not = icmp eq i32 %call, 0
  br i1 %tobool4.not, label %do.end.if.end36_crit_edge, label %land.lhs.true5

do.end.if.end36_crit_edge:                        ; preds = %do.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

land.lhs.true5:                                   ; preds = %do.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %3 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %3)
  %tobool6.not = icmp eq i32 %3, 0
  br i1 %tobool6.not, label %do.end19, label %land.lhs.true5.if.end36_crit_edge

land.lhs.true5.if.end36_crit_edge:                ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end36

do.end19:                                         ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.859, i32 noundef 30, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.860) #11
  br label %if.end36

if.end36:                                         ; preds = %do.end19, %land.lhs.true5.if.end36_crit_edge, %do.end.if.end36_crit_edge, %land.lhs.true.if.end36_crit_edge, %__here.if.end36_crit_edge
  %4 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %4, -16384
  %5 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %5, i32 0, i32 2
  %6 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %6)
  %7 = load ptr, ptr %task, align 8
  %owner39 = getelementptr inbounds %struct.local_lock_t, ptr %l, i32 0, i32 1
  %8 = ptrtoint ptr %owner39 to i32
  call void @__asan_store4_noabort(i32 %8)
  store ptr %7, ptr %owner39, align 4
  ret void
}

; Function Attrs: inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync)
define internal fastcc void @local_lock_release(ptr noundef %l) #6 align 64 {
entry:
  call void @__sanitizer_cov_trace_pc() #10
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @oops_in_progress to i32))
  %0 = load i32, ptr @oops_in_progress, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %0)
  %tobool.not = icmp eq i32 %0, 0
  br i1 %tobool.not, label %land.lhs.true, label %entry.if.end35_crit_edge

entry.if.end35_crit_edge:                         ; preds = %entry
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

land.lhs.true:                                    ; preds = %entry
  %owner = getelementptr inbounds %struct.local_lock_t, ptr %l, i32 0, i32 1
  %1 = ptrtoint ptr %owner to i32
  call void @__asan_load4_noabort(i32 %1)
  %2 = load ptr, ptr %owner, align 4
  %3 = tail call i32 @llvm.read_register.i32(metadata !1214) #11
  %and.i = and i32 %3, -16384
  %4 = inttoptr i32 %and.i to ptr
  %task = getelementptr inbounds %struct.thread_info, ptr %4, i32 0, i32 2
  %5 = ptrtoint ptr %task to i32
  call void @__asan_load4_noabort(i32 %5)
  %6 = load ptr, ptr %task, align 8
  %cmp.not = icmp eq ptr %2, %6
  br i1 %cmp.not, label %land.lhs.true.if.end35_crit_edge, label %do.end, !prof !1224

land.lhs.true.if.end35_crit_edge:                 ; preds = %land.lhs.true
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

do.end:                                           ; preds = %land.lhs.true
  %call3 = tail call i32 @debug_locks_off() #11
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %call3)
  %tobool4.not = icmp eq i32 %call3, 0
  br i1 %tobool4.not, label %do.end.if.end35_crit_edge, label %land.lhs.true5

do.end.if.end35_crit_edge:                        ; preds = %do.end
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

land.lhs.true5:                                   ; preds = %do.end
  call void @__asan_load4_noabort(i32 ptrtoint (ptr @debug_locks_silent to i32))
  %7 = load i32, ptr @debug_locks_silent, align 4
  call void @__sanitizer_cov_trace_const_cmp4(i32 0, i32 %7)
  %tobool6.not = icmp eq i32 %7, 0
  br i1 %tobool6.not, label %do.end19, label %land.lhs.true5.if.end35_crit_edge

land.lhs.true5.if.end35_crit_edge:                ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  br label %if.end35

do.end19:                                         ; preds = %land.lhs.true5
  call void @__sanitizer_cov_trace_pc() #10
  tail call void (ptr, i32, i32, ptr, ...) @warn_slowpath_fmt(ptr noundef nonnull @.str.859, i32 noundef 36, i32 noundef 9, ptr noundef nonnull @.str.776, ptr noundef nonnull @.str.861) #11
  br label %if.end35

if.end35:                                         ; preds = %do.end19, %land.lhs.true5.if.end35_crit_edge, %do.end.if.end35_crit_edge, %land.lhs.true.if.end35_crit_edge, %entry.if.end35_crit_edge
  %owner37 = getelementptr inbounds %struct.local_lock_t, ptr %l, i32 0, i32 1
  %8 = ptrtoint ptr %owner37 to i32
  call void @__asan_store4_noabort(i32 %8)
  store ptr null, ptr %owner37, align 4
  br label %__here

__here:                                           ; preds = %if.end35
  call void @__sanitizer_cov_trace_pc() #10
  tail call void @lock_release(ptr noundef %l, i32 noundef ptrtoint (ptr blockaddress(@local_lock_release, %__here) to i32)) #11
  ret void
}

declare void @__sanitizer_cov_trace_cmp4(i32 zeroext, i32 zeroext)

declare void @__sanitizer_cov_trace_const_cmp4(i32 zeroext, i32 zeroext)

declare void @__sanitizer_cov_trace_pc()

declare void @__asan_load4_noabort(i32)

declare void @__asan_store4_noabort(i32)

declare ptr @memcpy(ptr, ptr, i32)

declare ptr @memset(ptr, i32, i32)

declare void @__asan_register_globals(i32, i32)

declare void @__asan_unregister_globals(i32, i32)

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_ctor() #9 {
  call void @__asan_register_globals(i32 ptrtoint (ptr @0 to i32), i32 687)
  ret void
}

; Function Attrs: nounwind uwtable(sync)
define internal void @asan.module_dtor() #9 {
  call void @__asan_unregister_globals(i32 ptrtoint (ptr @0 to i32), i32 687)
  ret void
}

attributes #0 = { cold nounwind null_pointer_is_valid optsize sanitize_address sspstrong uwtable(sync) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #1 = { nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #2 = { cold null_pointer_is_valid "frame-pointer"="none" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #3 = { null_pointer_is_valid "frame-pointer"="none" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" }
attributes #4 = { noinline nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #5 = { nounwind readonly }
attributes #6 = { inlinehint nounwind null_pointer_is_valid sanitize_address sspstrong uwtable(sync) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="mpcore" "target-features"="+armv6k,+dsp,+soft-float,+strict-align,-aes,-bf16,-d32,-dotprod,-fp-armv8,-fp-armv8d16,-fp-armv8d16sp,-fp-armv8sp,-fp16,-fp16fml,-fp64,-fpregs,-fullfp16,-mve,-mve.fp,-neon,-sha2,-thumb-mode,-vfp2,-vfp2sp,-vfp3,-vfp3d16,-vfp3d16sp,-vfp3sp,-vfp4,-vfp4d16,-vfp4d16sp,-vfp4sp" "use-soft-float"="true" "warn-stack-size"="1024" }
attributes #7 = { nocallback nofree nosync nounwind readnone willreturn }
attributes #8 = { inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn }
attributes #9 = { nounwind uwtable(sync) }
attributes #10 = { nomerge }
attributes #11 = { nounwind }
attributes #12 = { cold nounwind }

!llvm.asan.globals = !{!0, !2, !4, !5, !6, !7, !8, !10, !11, !12, !14, !15, !17, !18, !19, !21, !22, !23, !25, !26, !27, !29, !30, !31, !33, !34, !35, !37, !38, !39, !40, !42, !43, !44, !46, !47, !48, !50, !51, !52, !54, !55, !56, !58, !59, !60, !62, !63, !64, !66, !67, !68, !70, !71, !72, !74, !75, !77, !79, !80, !81, !83, !84, !86, !87, !89, !91, !92, !94, !95, !97, !98, !100, !102, !103, !105, !106, !108, !109, !111, !113, !114, !116, !117, !119, !120, !122, !124, !125, !127, !128, !130, !132, !133, !135, !136, !138, !140, !141, !143, !144, !146, !148, !149, !151, !152, !153, !154, !155, !156, !157, !158, !159, !160, !161, !162, !163, !164, !165, !166, !167, !168, !169, !170, !171, !172, !173, !174, !175, !176, !177, !178, !179, !180, !182, !183, !184, !185, !186, !187, !188, !189, !190, !191, !192, !193, !194, !195, !196, !197, !198, !199, !200, !201, !202, !203, !204, !205, !206, !207, !208, !209, !210, !211, !213, !214, !215, !216, !217, !218, !219, !220, !221, !222, !223, !224, !225, !226, !227, !228, !229, !230, !231, !232, !233, !234, !235, !236, !237, !238, !239, !240, !241, !242, !244, !245, !246, !247, !248, !249, !250, !251, !252, !253, !254, !255, !256, !257, !258, !259, !260, !261, !262, !263, !264, !265, !266, !267, !268, !269, !270, !271, !272, !273, !275, !276, !278, !279, !280, !281, !282, !283, !284, !285, !286, !287, !288, !289, !291, !292, !293, !294, !295, !296, !298, !299, !300, !301, !302, !303, !304, !305, !306, !307, !308, !309, !311, !312, !313, !314, !315, !316, !317, !318, !319, !320, !321, !322, !323, !324, !325, !326, !327, !328, !329, !330, !331, !332, !333, !334, !335, !336, !337, !338, !339, !340, !341, !342, !343, !344, !345, !346, !348, !349, !350, !351, !352, !353, !354, !355, !356, !357, !358, !359, !360, !361, !362, !363, !364, !365, !366, !367, !368, !369, !370, !371, !372, !373, !374, !375, !376, !377, !378, !379, !380, !381, !382, !383, !385, !386, !387, !388, !389, !390, !391, !392, !393, !394, !395, !396, !397, !398, !399, !400, !401, !402, !403, !404, !405, !406, !407, !408, !409, !410, !411, !412, !413, !414, !415, !416, !417, !418, !419, !420, !422, !423, !424, !425, !426, !427, !428, !429, !430, !431, !432, !433, !434, !435, !436, !437, !438, !439, !440, !441, !442, !443, !444, !445, !446, !447, !448, !449, !450, !451, !452, !453, !454, !455, !456, !457, !458, !459, !460, !461, !462, !463, !464, !465, !466, !467, !468, !469, !470, !471, !472, !473, !474, !475, !476, !477, !478, !479, !480, !481, !482, !484, !485, !486, !487, !488, !489, !490, !491, !492, !493, !494, !495, !496, !497, !498, !499, !500, !501, !502, !503, !504, !505, !506, !507, !508, !509, !510, !511, !512, !513, !514, !515, !516, !517, !518, !519, !520, !521, !522, !523, !524, !525, !526, !527, !528, !529, !530, !531, !532, !533, !534, !535, !536, !537, !538, !539, !540, !541, !542, !543, !545, !546, !547, !548, !549, !550, !551, !552, !553, !554, !555, !556, !557, !558, !559, !560, !561, !562, !563, !564, !565, !566, !567, !568, !569, !570, !571, !572, !573, !574, !575, !576, !577, !578, !579, !580, !581, !582, !583, !584, !585, !586, !587, !588, !589, !590, !591, !592, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !604, !606, !608, !609, !611, !612, !613, !615, !616, !617, !619, !620, !622, !623, !624, !626, !627, !628, !630, !631, !632, !634, !635, !637, !638, !639, !641, !642, !643, !645, !646, !647, !649, !650, !651, !653, !654, !655, !657, !659, !660, !662, !664, !666, !668, !669, !671, !673, !675, !677, !679, !681, !682, !683, !685, !686, !687, !689, !690, !691, !693, !694, !695, !697, !698, !699, !701, !702, !703, !705, !706, !707, !708, !709, !710, !711, !712, !714, !715, !717, !718, !720, !721, !722, !724, !725, !726, !728, !729, !731, !732, !734, !735, !736, !738, !739, !740, !742, !743, !744, !745, !747, !748, !750, !751, !753, !754, !755, !757, !758, !759, !761, !762, !764, !765, !767, !768, !769, !771, !772, !773, !775, !776, !777, !778, !780, !781, !783, !784, !786, !787, !788, !790, !791, !792, !794, !795, !797, !798, !800, !801, !802, !804, !805, !806, !808, !809, !810, !811, !813, !814, !815, !816, !818, !819, !820, !822, !823, !824, !826, !827, !828, !829, !830, !831, !832, !833, !834, !835, !837, !838, !839, !840, !841, !842, !843, !844, !845, !847, !848, !849, !850, !851, !852, !853, !854, !855, !857, !858, !859, !860, !861, !862, !863, !864, !865, !867, !868, !870, !871, !873, !874, !876, !877, !878, !880, !881, !883, !884, !886, !887, !888, !890, !891, !892, !894, !895, !896, !898, !899, !901, !902, !904, !905, !906, !908, !909, !910, !912, !913, !914, !916, !917, !919, !920, !922, !923, !924, !926, !927, !928, !930, !931, !932, !934, !935, !937, !938, !940, !941, !942, !944, !945, !946, !948, !949, !950, !952, !954, !956, !958, !960, !962, !963, !965, !966, !968, !970, !972, !974, !976, !978, !980, !981, !983, !984, !986, !987, !988, !990, !991, !992, !994, !995, !996, !998, !1000, !1001, !1003, !1005, !1006, !1008, !1010, !1011, !1013, !1015, !1016, !1018, !1020, !1021, !1023, !1025, !1026, !1028, !1030, !1031, !1033, !1034, !1035, !1037, !1038, !1039, !1041, !1042, !1044, !1046, !1047, !1049, !1051, !1052, !1054, !1056, !1057, !1059, !1061, !1062, !1064, !1065, !1067, !1068, !1070, !1072, !1074, !1075, !1076, !1077, !1079, !1080, !1081, !1083, !1084, !1086, !1088, !1089, !1091, !1093, !1094, !1096, !1098, !1099, !1101, !1103, !1104, !1105, !1107, !1108, !1109, !1111, !1112, !1114, !1115, !1116, !1118, !1119, !1121, !1123, !1124, !1126, !1128, !1129, !1131, !1133, !1134, !1136, !1138, !1139, !1141, !1143, !1144, !1146, !1148, !1149, !1151, !1153, !1154, !1156, !1158, !1159, !1161, !1163, !1164, !1166, !1167, !1168, !1170, !1171, !1173, !1174, !1176, !1177, !1179, !1180, !1182, !1183, !1185, !1186, !1187, !1189, !1190, !1191, !1193, !1194, !1196, !1198, !1199, !1201, !1203, !1204, !1206, !1208, !1209, !1211, !1212}
!llvm.named.register.sp = !{!1214}
!llvm.module.flags = !{!1215, !1216, !1217, !1218, !1219, !1220, !1221}
!llvm.ident = !{!1222}

!0 = !{ptr @__setup_setup_debug_locks_verbose, !1, !"__setup_setup_debug_locks_verbose", i1 false, i1 false}
!1 = !{!"../lib/locking-selftest.c", i32 50, i32 1}
!2 = !{ptr @.str, !3, !"<string literal>", i1 false, i1 false}
!3 = !{!"../lib/locking-selftest.c", i32 2863, i32 3}
!4 = !{ptr @.str.1, !3, !"<string literal>", i1 false, i1 false}
!5 = !{ptr @.str.2, !3, !"<string literal>", i1 false, i1 false}
!6 = !{ptr @locking_selftest._entry, !3, !"_entry", i1 false, i1 false}
!7 = !{ptr @locking_selftest._entry_ptr, !3, !"_entry_ptr", i1 false, i1 false}
!8 = !{ptr @.str.4, !9, !"<string literal>", i1 false, i1 false}
!9 = !{!"../lib/locking-selftest.c", i32 2864, i32 3}
!10 = !{ptr @locking_selftest._entry.3, !9, !"_entry", i1 false, i1 false}
!11 = !{ptr @locking_selftest._entry_ptr.5, !9, !"_entry_ptr", i1 false, i1 false}
!12 = !{ptr @locking_selftest._entry.6, !13, !"_entry", i1 false, i1 false}
!13 = !{!"../lib/locking-selftest.c", i32 2865, i32 3}
!14 = !{ptr @locking_selftest._entry_ptr.7, !13, !"_entry_ptr", i1 false, i1 false}
!15 = !{ptr @.str.9, !16, !"<string literal>", i1 false, i1 false}
!16 = !{!"../lib/locking-selftest.c", i32 2877, i32 2}
!17 = !{ptr @locking_selftest._entry.8, !16, !"_entry", i1 false, i1 false}
!18 = !{ptr @locking_selftest._entry_ptr.10, !16, !"_entry_ptr", i1 false, i1 false}
!19 = !{ptr @.str.12, !20, !"<string literal>", i1 false, i1 false}
!20 = !{!"../lib/locking-selftest.c", i32 2878, i32 2}
!21 = !{ptr @locking_selftest._entry.11, !20, !"_entry", i1 false, i1 false}
!22 = !{ptr @locking_selftest._entry_ptr.13, !20, !"_entry_ptr", i1 false, i1 false}
!23 = !{ptr @.str.15, !24, !"<string literal>", i1 false, i1 false}
!24 = !{!"../lib/locking-selftest.c", i32 2879, i32 2}
!25 = !{ptr @locking_selftest._entry.14, !24, !"_entry", i1 false, i1 false}
!26 = !{ptr @locking_selftest._entry_ptr.16, !24, !"_entry_ptr", i1 false, i1 false}
!27 = !{ptr @.str.18, !28, !"<string literal>", i1 false, i1 false}
!28 = !{!"../lib/locking-selftest.c", i32 2880, i32 2}
!29 = !{ptr @locking_selftest._entry.17, !28, !"_entry", i1 false, i1 false}
!30 = !{ptr @locking_selftest._entry_ptr.19, !28, !"_entry_ptr", i1 false, i1 false}
!31 = !{ptr @.str.21, !32, !"<string literal>", i1 false, i1 false}
!32 = !{!"../lib/locking-selftest.c", i32 2881, i32 2}
!33 = !{ptr @locking_selftest._entry.20, !32, !"_entry", i1 false, i1 false}
!34 = !{ptr @locking_selftest._entry_ptr.22, !32, !"_entry_ptr", i1 false, i1 false}
!35 = !{ptr @.str.23, !36, !"<string literal>", i1 false, i1 false}
!36 = !{!"../lib/locking-selftest.c", i32 2886, i32 2}
!37 = !{ptr @.str.25, !36, !"<string literal>", i1 false, i1 false}
!38 = !{ptr @locking_selftest._entry.24, !36, !"_entry", i1 false, i1 false}
!39 = !{ptr @locking_selftest._entry_ptr.26, !36, !"_entry_ptr", i1 false, i1 false}
!40 = !{ptr @.str.27, !41, !"<string literal>", i1 false, i1 false}
!41 = !{!"../lib/locking-selftest.c", i32 2887, i32 2}
!42 = !{ptr @locking_selftest._entry.28, !41, !"_entry", i1 false, i1 false}
!43 = !{ptr @locking_selftest._entry_ptr.29, !41, !"_entry_ptr", i1 false, i1 false}
!44 = !{ptr @.str.30, !45, !"<string literal>", i1 false, i1 false}
!45 = !{!"../lib/locking-selftest.c", i32 2888, i32 2}
!46 = !{ptr @locking_selftest._entry.31, !45, !"_entry", i1 false, i1 false}
!47 = !{ptr @locking_selftest._entry_ptr.32, !45, !"_entry_ptr", i1 false, i1 false}
!48 = !{ptr @.str.33, !49, !"<string literal>", i1 false, i1 false}
!49 = !{!"../lib/locking-selftest.c", i32 2889, i32 2}
!50 = !{ptr @locking_selftest._entry.34, !49, !"_entry", i1 false, i1 false}
!51 = !{ptr @locking_selftest._entry_ptr.35, !49, !"_entry_ptr", i1 false, i1 false}
!52 = !{ptr @.str.36, !53, !"<string literal>", i1 false, i1 false}
!53 = !{!"../lib/locking-selftest.c", i32 2890, i32 2}
!54 = !{ptr @locking_selftest._entry.37, !53, !"_entry", i1 false, i1 false}
!55 = !{ptr @locking_selftest._entry_ptr.38, !53, !"_entry_ptr", i1 false, i1 false}
!56 = !{ptr @.str.39, !57, !"<string literal>", i1 false, i1 false}
!57 = !{!"../lib/locking-selftest.c", i32 2891, i32 2}
!58 = !{ptr @locking_selftest._entry.40, !57, !"_entry", i1 false, i1 false}
!59 = !{ptr @locking_selftest._entry_ptr.41, !57, !"_entry_ptr", i1 false, i1 false}
!60 = !{ptr @.str.42, !61, !"<string literal>", i1 false, i1 false}
!61 = !{!"../lib/locking-selftest.c", i32 2892, i32 2}
!62 = !{ptr @locking_selftest._entry.43, !61, !"_entry", i1 false, i1 false}
!63 = !{ptr @locking_selftest._entry_ptr.44, !61, !"_entry_ptr", i1 false, i1 false}
!64 = !{ptr @.str.45, !65, !"<string literal>", i1 false, i1 false}
!65 = !{!"../lib/locking-selftest.c", i32 2893, i32 2}
!66 = !{ptr @locking_selftest._entry.46, !65, !"_entry", i1 false, i1 false}
!67 = !{ptr @locking_selftest._entry_ptr.47, !65, !"_entry_ptr", i1 false, i1 false}
!68 = !{ptr @.str.48, !69, !"<string literal>", i1 false, i1 false}
!69 = !{!"../lib/locking-selftest.c", i32 2894, i32 2}
!70 = !{ptr @locking_selftest._entry.49, !69, !"_entry", i1 false, i1 false}
!71 = !{ptr @locking_selftest._entry_ptr.50, !69, !"_entry_ptr", i1 false, i1 false}
!72 = !{ptr @locking_selftest._entry.51, !73, !"_entry", i1 false, i1 false}
!73 = !{!"../lib/locking-selftest.c", i32 2896, i32 2}
!74 = !{ptr @locking_selftest._entry_ptr.52, !73, !"_entry_ptr", i1 false, i1 false}
!75 = !{ptr @.str.53, !76, !"<string literal>", i1 false, i1 false}
!76 = !{!"../lib/locking-selftest.c", i32 2897, i32 17}
!77 = !{ptr @.str.55, !78, !"<string literal>", i1 false, i1 false}
!78 = !{!"../lib/locking-selftest.c", i32 2898, i32 2}
!79 = !{ptr @locking_selftest._entry.54, !78, !"_entry", i1 false, i1 false}
!80 = !{ptr @locking_selftest._entry_ptr.56, !78, !"_entry_ptr", i1 false, i1 false}
!81 = !{ptr @locking_selftest._entry.57, !82, !"_entry", i1 false, i1 false}
!82 = !{!"../lib/locking-selftest.c", i32 2900, i32 2}
!83 = !{ptr @locking_selftest._entry_ptr.58, !82, !"_entry_ptr", i1 false, i1 false}
!84 = !{ptr @locking_selftest._entry.59, !85, !"_entry", i1 false, i1 false}
!85 = !{!"../lib/locking-selftest.c", i32 2902, i32 2}
!86 = !{ptr @locking_selftest._entry_ptr.60, !85, !"_entry_ptr", i1 false, i1 false}
!87 = !{ptr @.str.61, !88, !"<string literal>", i1 false, i1 false}
!88 = !{!"../lib/locking-selftest.c", i32 2904, i32 17}
!89 = !{ptr @locking_selftest._entry.62, !90, !"_entry", i1 false, i1 false}
!90 = !{!"../lib/locking-selftest.c", i32 2905, i32 2}
!91 = !{ptr @locking_selftest._entry_ptr.63, !90, !"_entry_ptr", i1 false, i1 false}
!92 = !{ptr @locking_selftest._entry.64, !93, !"_entry", i1 false, i1 false}
!93 = !{!"../lib/locking-selftest.c", i32 2907, i32 2}
!94 = !{ptr @locking_selftest._entry_ptr.65, !93, !"_entry_ptr", i1 false, i1 false}
!95 = !{ptr @locking_selftest._entry.66, !96, !"_entry", i1 false, i1 false}
!96 = !{!"../lib/locking-selftest.c", i32 2909, i32 2}
!97 = !{ptr @locking_selftest._entry_ptr.67, !96, !"_entry_ptr", i1 false, i1 false}
!98 = !{ptr @.str.68, !99, !"<string literal>", i1 false, i1 false}
!99 = !{!"../lib/locking-selftest.c", i32 2911, i32 17}
!100 = !{ptr @locking_selftest._entry.69, !101, !"_entry", i1 false, i1 false}
!101 = !{!"../lib/locking-selftest.c", i32 2912, i32 2}
!102 = !{ptr @locking_selftest._entry_ptr.70, !101, !"_entry_ptr", i1 false, i1 false}
!103 = !{ptr @locking_selftest._entry.71, !104, !"_entry", i1 false, i1 false}
!104 = !{!"../lib/locking-selftest.c", i32 2914, i32 2}
!105 = !{ptr @locking_selftest._entry_ptr.72, !104, !"_entry_ptr", i1 false, i1 false}
!106 = !{ptr @locking_selftest._entry.73, !107, !"_entry", i1 false, i1 false}
!107 = !{!"../lib/locking-selftest.c", i32 2916, i32 2}
!108 = !{ptr @locking_selftest._entry_ptr.74, !107, !"_entry_ptr", i1 false, i1 false}
!109 = !{ptr @.str.75, !110, !"<string literal>", i1 false, i1 false}
!110 = !{!"../lib/locking-selftest.c", i32 2918, i32 17}
!111 = !{ptr @locking_selftest._entry.76, !112, !"_entry", i1 false, i1 false}
!112 = !{!"../lib/locking-selftest.c", i32 2919, i32 2}
!113 = !{ptr @locking_selftest._entry_ptr.77, !112, !"_entry_ptr", i1 false, i1 false}
!114 = !{ptr @locking_selftest._entry.78, !115, !"_entry", i1 false, i1 false}
!115 = !{!"../lib/locking-selftest.c", i32 2921, i32 2}
!116 = !{ptr @locking_selftest._entry_ptr.79, !115, !"_entry_ptr", i1 false, i1 false}
!117 = !{ptr @locking_selftest._entry.80, !118, !"_entry", i1 false, i1 false}
!118 = !{!"../lib/locking-selftest.c", i32 2923, i32 2}
!119 = !{ptr @locking_selftest._entry_ptr.81, !118, !"_entry_ptr", i1 false, i1 false}
!120 = !{ptr @.str.82, !121, !"<string literal>", i1 false, i1 false}
!121 = !{!"../lib/locking-selftest.c", i32 2925, i32 17}
!122 = !{ptr @locking_selftest._entry.83, !123, !"_entry", i1 false, i1 false}
!123 = !{!"../lib/locking-selftest.c", i32 2926, i32 2}
!124 = !{ptr @locking_selftest._entry_ptr.84, !123, !"_entry_ptr", i1 false, i1 false}
!125 = !{ptr @locking_selftest._entry.85, !126, !"_entry", i1 false, i1 false}
!126 = !{!"../lib/locking-selftest.c", i32 2928, i32 2}
!127 = !{ptr @locking_selftest._entry_ptr.86, !126, !"_entry_ptr", i1 false, i1 false}
!128 = !{ptr @.str.87, !129, !"<string literal>", i1 false, i1 false}
!129 = !{!"../lib/locking-selftest.c", i32 2931, i32 17}
!130 = !{ptr @locking_selftest._entry.88, !131, !"_entry", i1 false, i1 false}
!131 = !{!"../lib/locking-selftest.c", i32 2932, i32 2}
!132 = !{ptr @locking_selftest._entry_ptr.89, !131, !"_entry_ptr", i1 false, i1 false}
!133 = !{ptr @locking_selftest._entry.90, !134, !"_entry", i1 false, i1 false}
!134 = !{!"../lib/locking-selftest.c", i32 2934, i32 2}
!135 = !{ptr @locking_selftest._entry_ptr.91, !134, !"_entry_ptr", i1 false, i1 false}
!136 = !{ptr @.str.92, !137, !"<string literal>", i1 false, i1 false}
!137 = !{!"../lib/locking-selftest.c", i32 2937, i32 17}
!138 = !{ptr @locking_selftest._entry.93, !139, !"_entry", i1 false, i1 false}
!139 = !{!"../lib/locking-selftest.c", i32 2938, i32 2}
!140 = !{ptr @locking_selftest._entry_ptr.94, !139, !"_entry_ptr", i1 false, i1 false}
!141 = !{ptr @locking_selftest._entry.95, !142, !"_entry", i1 false, i1 false}
!142 = !{!"../lib/locking-selftest.c", i32 2940, i32 2}
!143 = !{ptr @locking_selftest._entry_ptr.96, !142, !"_entry_ptr", i1 false, i1 false}
!144 = !{ptr @.str.97, !145, !"<string literal>", i1 false, i1 false}
!145 = !{!"../lib/locking-selftest.c", i32 2943, i32 17}
!146 = !{ptr @locking_selftest._entry.98, !147, !"_entry", i1 false, i1 false}
!147 = !{!"../lib/locking-selftest.c", i32 2944, i32 2}
!148 = !{ptr @locking_selftest._entry_ptr.99, !147, !"_entry_ptr", i1 false, i1 false}
!149 = !{ptr @.str.100, !150, !"<string literal>", i1 false, i1 false}
!150 = !{!"../lib/locking-selftest.c", i32 2947, i32 2}
!151 = !{ptr @locking_selftest._entry.101, !150, !"_entry", i1 false, i1 false}
!152 = !{ptr @locking_selftest._entry_ptr.102, !150, !"_entry_ptr", i1 false, i1 false}
!153 = !{ptr @locking_selftest._entry.103, !150, !"_entry", i1 false, i1 false}
!154 = !{ptr @locking_selftest._entry_ptr.104, !150, !"_entry_ptr", i1 false, i1 false}
!155 = !{ptr @.str.105, !150, !"<string literal>", i1 false, i1 false}
!156 = !{ptr @locking_selftest._entry.106, !150, !"_entry", i1 false, i1 false}
!157 = !{ptr @locking_selftest._entry_ptr.107, !150, !"_entry_ptr", i1 false, i1 false}
!158 = !{ptr @locking_selftest._entry.108, !150, !"_entry", i1 false, i1 false}
!159 = !{ptr @locking_selftest._entry_ptr.109, !150, !"_entry_ptr", i1 false, i1 false}
!160 = !{ptr @.str.110, !150, !"<string literal>", i1 false, i1 false}
!161 = !{ptr @locking_selftest._entry.111, !150, !"_entry", i1 false, i1 false}
!162 = !{ptr @locking_selftest._entry_ptr.112, !150, !"_entry_ptr", i1 false, i1 false}
!163 = !{ptr @locking_selftest._entry.113, !150, !"_entry", i1 false, i1 false}
!164 = !{ptr @locking_selftest._entry_ptr.114, !150, !"_entry_ptr", i1 false, i1 false}
!165 = !{ptr @.str.115, !150, !"<string literal>", i1 false, i1 false}
!166 = !{ptr @locking_selftest._entry.116, !150, !"_entry", i1 false, i1 false}
!167 = !{ptr @locking_selftest._entry_ptr.117, !150, !"_entry_ptr", i1 false, i1 false}
!168 = !{ptr @locking_selftest._entry.118, !150, !"_entry", i1 false, i1 false}
!169 = !{ptr @locking_selftest._entry_ptr.119, !150, !"_entry_ptr", i1 false, i1 false}
!170 = !{ptr @.str.120, !150, !"<string literal>", i1 false, i1 false}
!171 = !{ptr @locking_selftest._entry.121, !150, !"_entry", i1 false, i1 false}
!172 = !{ptr @locking_selftest._entry_ptr.122, !150, !"_entry_ptr", i1 false, i1 false}
!173 = !{ptr @locking_selftest._entry.123, !150, !"_entry", i1 false, i1 false}
!174 = !{ptr @locking_selftest._entry_ptr.124, !150, !"_entry_ptr", i1 false, i1 false}
!175 = !{ptr @.str.125, !150, !"<string literal>", i1 false, i1 false}
!176 = !{ptr @locking_selftest._entry.126, !150, !"_entry", i1 false, i1 false}
!177 = !{ptr @locking_selftest._entry_ptr.127, !150, !"_entry_ptr", i1 false, i1 false}
!178 = !{ptr @locking_selftest._entry.128, !150, !"_entry", i1 false, i1 false}
!179 = !{ptr @locking_selftest._entry_ptr.129, !150, !"_entry_ptr", i1 false, i1 false}
!180 = !{ptr @.str.130, !181, !"<string literal>", i1 false, i1 false}
!181 = !{!"../lib/locking-selftest.c", i32 2948, i32 2}
!182 = !{ptr @locking_selftest._entry.131, !181, !"_entry", i1 false, i1 false}
!183 = !{ptr @locking_selftest._entry_ptr.132, !181, !"_entry_ptr", i1 false, i1 false}
!184 = !{ptr @locking_selftest._entry.133, !181, !"_entry", i1 false, i1 false}
!185 = !{ptr @locking_selftest._entry_ptr.134, !181, !"_entry_ptr", i1 false, i1 false}
!186 = !{ptr @.str.135, !181, !"<string literal>", i1 false, i1 false}
!187 = !{ptr @locking_selftest._entry.136, !181, !"_entry", i1 false, i1 false}
!188 = !{ptr @locking_selftest._entry_ptr.137, !181, !"_entry_ptr", i1 false, i1 false}
!189 = !{ptr @locking_selftest._entry.138, !181, !"_entry", i1 false, i1 false}
!190 = !{ptr @locking_selftest._entry_ptr.139, !181, !"_entry_ptr", i1 false, i1 false}
!191 = !{ptr @.str.140, !181, !"<string literal>", i1 false, i1 false}
!192 = !{ptr @locking_selftest._entry.141, !181, !"_entry", i1 false, i1 false}
!193 = !{ptr @locking_selftest._entry_ptr.142, !181, !"_entry_ptr", i1 false, i1 false}
!194 = !{ptr @locking_selftest._entry.143, !181, !"_entry", i1 false, i1 false}
!195 = !{ptr @locking_selftest._entry_ptr.144, !181, !"_entry_ptr", i1 false, i1 false}
!196 = !{ptr @.str.145, !181, !"<string literal>", i1 false, i1 false}
!197 = !{ptr @locking_selftest._entry.146, !181, !"_entry", i1 false, i1 false}
!198 = !{ptr @locking_selftest._entry_ptr.147, !181, !"_entry_ptr", i1 false, i1 false}
!199 = !{ptr @locking_selftest._entry.148, !181, !"_entry", i1 false, i1 false}
!200 = !{ptr @locking_selftest._entry_ptr.149, !181, !"_entry_ptr", i1 false, i1 false}
!201 = !{ptr @.str.150, !181, !"<string literal>", i1 false, i1 false}
!202 = !{ptr @locking_selftest._entry.151, !181, !"_entry", i1 false, i1 false}
!203 = !{ptr @locking_selftest._entry_ptr.152, !181, !"_entry_ptr", i1 false, i1 false}
!204 = !{ptr @locking_selftest._entry.153, !181, !"_entry", i1 false, i1 false}
!205 = !{ptr @locking_selftest._entry_ptr.154, !181, !"_entry_ptr", i1 false, i1 false}
!206 = !{ptr @.str.155, !181, !"<string literal>", i1 false, i1 false}
!207 = !{ptr @locking_selftest._entry.156, !181, !"_entry", i1 false, i1 false}
!208 = !{ptr @locking_selftest._entry_ptr.157, !181, !"_entry_ptr", i1 false, i1 false}
!209 = !{ptr @locking_selftest._entry.158, !181, !"_entry", i1 false, i1 false}
!210 = !{ptr @locking_selftest._entry_ptr.159, !181, !"_entry_ptr", i1 false, i1 false}
!211 = !{ptr @.str.160, !212, !"<string literal>", i1 false, i1 false}
!212 = !{!"../lib/locking-selftest.c", i32 2949, i32 2}
!213 = !{ptr @locking_selftest._entry.161, !212, !"_entry", i1 false, i1 false}
!214 = !{ptr @locking_selftest._entry_ptr.162, !212, !"_entry_ptr", i1 false, i1 false}
!215 = !{ptr @locking_selftest._entry.163, !212, !"_entry", i1 false, i1 false}
!216 = !{ptr @locking_selftest._entry_ptr.164, !212, !"_entry_ptr", i1 false, i1 false}
!217 = !{ptr @.str.165, !212, !"<string literal>", i1 false, i1 false}
!218 = !{ptr @locking_selftest._entry.166, !212, !"_entry", i1 false, i1 false}
!219 = !{ptr @locking_selftest._entry_ptr.167, !212, !"_entry_ptr", i1 false, i1 false}
!220 = !{ptr @locking_selftest._entry.168, !212, !"_entry", i1 false, i1 false}
!221 = !{ptr @locking_selftest._entry_ptr.169, !212, !"_entry_ptr", i1 false, i1 false}
!222 = !{ptr @.str.170, !212, !"<string literal>", i1 false, i1 false}
!223 = !{ptr @locking_selftest._entry.171, !212, !"_entry", i1 false, i1 false}
!224 = !{ptr @locking_selftest._entry_ptr.172, !212, !"_entry_ptr", i1 false, i1 false}
!225 = !{ptr @locking_selftest._entry.173, !212, !"_entry", i1 false, i1 false}
!226 = !{ptr @locking_selftest._entry_ptr.174, !212, !"_entry_ptr", i1 false, i1 false}
!227 = !{ptr @.str.175, !212, !"<string literal>", i1 false, i1 false}
!228 = !{ptr @locking_selftest._entry.176, !212, !"_entry", i1 false, i1 false}
!229 = !{ptr @locking_selftest._entry_ptr.177, !212, !"_entry_ptr", i1 false, i1 false}
!230 = !{ptr @locking_selftest._entry.178, !212, !"_entry", i1 false, i1 false}
!231 = !{ptr @locking_selftest._entry_ptr.179, !212, !"_entry_ptr", i1 false, i1 false}
!232 = !{ptr @.str.180, !212, !"<string literal>", i1 false, i1 false}
!233 = !{ptr @locking_selftest._entry.181, !212, !"_entry", i1 false, i1 false}
!234 = !{ptr @locking_selftest._entry_ptr.182, !212, !"_entry_ptr", i1 false, i1 false}
!235 = !{ptr @locking_selftest._entry.183, !212, !"_entry", i1 false, i1 false}
!236 = !{ptr @locking_selftest._entry_ptr.184, !212, !"_entry_ptr", i1 false, i1 false}
!237 = !{ptr @.str.185, !212, !"<string literal>", i1 false, i1 false}
!238 = !{ptr @locking_selftest._entry.186, !212, !"_entry", i1 false, i1 false}
!239 = !{ptr @locking_selftest._entry_ptr.187, !212, !"_entry_ptr", i1 false, i1 false}
!240 = !{ptr @locking_selftest._entry.188, !212, !"_entry", i1 false, i1 false}
!241 = !{ptr @locking_selftest._entry_ptr.189, !212, !"_entry_ptr", i1 false, i1 false}
!242 = !{ptr @.str.190, !243, !"<string literal>", i1 false, i1 false}
!243 = !{!"../lib/locking-selftest.c", i32 2950, i32 2}
!244 = !{ptr @locking_selftest._entry.191, !243, !"_entry", i1 false, i1 false}
!245 = !{ptr @locking_selftest._entry_ptr.192, !243, !"_entry_ptr", i1 false, i1 false}
!246 = !{ptr @locking_selftest._entry.193, !243, !"_entry", i1 false, i1 false}
!247 = !{ptr @locking_selftest._entry_ptr.194, !243, !"_entry_ptr", i1 false, i1 false}
!248 = !{ptr @.str.195, !243, !"<string literal>", i1 false, i1 false}
!249 = !{ptr @locking_selftest._entry.196, !243, !"_entry", i1 false, i1 false}
!250 = !{ptr @locking_selftest._entry_ptr.197, !243, !"_entry_ptr", i1 false, i1 false}
!251 = !{ptr @locking_selftest._entry.198, !243, !"_entry", i1 false, i1 false}
!252 = !{ptr @locking_selftest._entry_ptr.199, !243, !"_entry_ptr", i1 false, i1 false}
!253 = !{ptr @.str.200, !243, !"<string literal>", i1 false, i1 false}
!254 = !{ptr @locking_selftest._entry.201, !243, !"_entry", i1 false, i1 false}
!255 = !{ptr @locking_selftest._entry_ptr.202, !243, !"_entry_ptr", i1 false, i1 false}
!256 = !{ptr @locking_selftest._entry.203, !243, !"_entry", i1 false, i1 false}
!257 = !{ptr @locking_selftest._entry_ptr.204, !243, !"_entry_ptr", i1 false, i1 false}
!258 = !{ptr @.str.205, !243, !"<string literal>", i1 false, i1 false}
!259 = !{ptr @locking_selftest._entry.206, !243, !"_entry", i1 false, i1 false}
!260 = !{ptr @locking_selftest._entry_ptr.207, !243, !"_entry_ptr", i1 false, i1 false}
!261 = !{ptr @locking_selftest._entry.208, !243, !"_entry", i1 false, i1 false}
!262 = !{ptr @locking_selftest._entry_ptr.209, !243, !"_entry_ptr", i1 false, i1 false}
!263 = !{ptr @.str.210, !243, !"<string literal>", i1 false, i1 false}
!264 = !{ptr @locking_selftest._entry.211, !243, !"_entry", i1 false, i1 false}
!265 = !{ptr @locking_selftest._entry_ptr.212, !243, !"_entry_ptr", i1 false, i1 false}
!266 = !{ptr @locking_selftest._entry.213, !243, !"_entry", i1 false, i1 false}
!267 = !{ptr @locking_selftest._entry_ptr.214, !243, !"_entry_ptr", i1 false, i1 false}
!268 = !{ptr @.str.215, !243, !"<string literal>", i1 false, i1 false}
!269 = !{ptr @locking_selftest._entry.216, !243, !"_entry", i1 false, i1 false}
!270 = !{ptr @locking_selftest._entry_ptr.217, !243, !"_entry_ptr", i1 false, i1 false}
!271 = !{ptr @locking_selftest._entry.218, !243, !"_entry", i1 false, i1 false}
!272 = !{ptr @locking_selftest._entry_ptr.219, !243, !"_entry_ptr", i1 false, i1 false}
!273 = !{ptr @locking_selftest._entry.220, !274, !"_entry", i1 false, i1 false}
!274 = !{!"../lib/locking-selftest.c", i32 2952, i32 2}
!275 = !{ptr @locking_selftest._entry_ptr.221, !274, !"_entry_ptr", i1 false, i1 false}
!276 = !{ptr @.str.222, !277, !"<string literal>", i1 false, i1 false}
!277 = !{!"../lib/locking-selftest.c", i32 2956, i32 2}
!278 = !{ptr @locking_selftest._entry.223, !277, !"_entry", i1 false, i1 false}
!279 = !{ptr @locking_selftest._entry_ptr.224, !277, !"_entry_ptr", i1 false, i1 false}
!280 = !{ptr @.str.225, !277, !"<string literal>", i1 false, i1 false}
!281 = !{ptr @locking_selftest._entry.226, !277, !"_entry", i1 false, i1 false}
!282 = !{ptr @locking_selftest._entry_ptr.227, !277, !"_entry_ptr", i1 false, i1 false}
!283 = !{ptr @.str.228, !277, !"<string literal>", i1 false, i1 false}
!284 = !{ptr @locking_selftest._entry.229, !277, !"_entry", i1 false, i1 false}
!285 = !{ptr @locking_selftest._entry_ptr.230, !277, !"_entry_ptr", i1 false, i1 false}
!286 = !{ptr @.str.231, !277, !"<string literal>", i1 false, i1 false}
!287 = !{ptr @locking_selftest._entry.232, !277, !"_entry", i1 false, i1 false}
!288 = !{ptr @locking_selftest._entry_ptr.233, !277, !"_entry_ptr", i1 false, i1 false}
!289 = !{ptr @.str.234, !290, !"<string literal>", i1 false, i1 false}
!290 = !{!"../lib/locking-selftest.c", i32 2957, i32 2}
!291 = !{ptr @locking_selftest._entry.235, !290, !"_entry", i1 false, i1 false}
!292 = !{ptr @locking_selftest._entry_ptr.236, !290, !"_entry_ptr", i1 false, i1 false}
!293 = !{ptr @.str.237, !290, !"<string literal>", i1 false, i1 false}
!294 = !{ptr @locking_selftest._entry.238, !290, !"_entry", i1 false, i1 false}
!295 = !{ptr @locking_selftest._entry_ptr.239, !290, !"_entry_ptr", i1 false, i1 false}
!296 = !{ptr @.str.240, !297, !"<string literal>", i1 false, i1 false}
!297 = !{!"../lib/locking-selftest.c", i32 2958, i32 2}
!298 = !{ptr @locking_selftest._entry.241, !297, !"_entry", i1 false, i1 false}
!299 = !{ptr @locking_selftest._entry_ptr.242, !297, !"_entry_ptr", i1 false, i1 false}
!300 = !{ptr @.str.243, !297, !"<string literal>", i1 false, i1 false}
!301 = !{ptr @locking_selftest._entry.244, !297, !"_entry", i1 false, i1 false}
!302 = !{ptr @locking_selftest._entry_ptr.245, !297, !"_entry_ptr", i1 false, i1 false}
!303 = !{ptr @.str.246, !297, !"<string literal>", i1 false, i1 false}
!304 = !{ptr @locking_selftest._entry.247, !297, !"_entry", i1 false, i1 false}
!305 = !{ptr @locking_selftest._entry_ptr.248, !297, !"_entry_ptr", i1 false, i1 false}
!306 = !{ptr @.str.249, !297, !"<string literal>", i1 false, i1 false}
!307 = !{ptr @locking_selftest._entry.250, !297, !"_entry", i1 false, i1 false}
!308 = !{ptr @locking_selftest._entry_ptr.251, !297, !"_entry_ptr", i1 false, i1 false}
!309 = !{ptr @.str.252, !310, !"<string literal>", i1 false, i1 false}
!310 = !{!"../lib/locking-selftest.c", i32 2959, i32 2}
!311 = !{ptr @locking_selftest._entry.253, !310, !"_entry", i1 false, i1 false}
!312 = !{ptr @locking_selftest._entry_ptr.254, !310, !"_entry_ptr", i1 false, i1 false}
!313 = !{ptr @.str.255, !310, !"<string literal>", i1 false, i1 false}
!314 = !{ptr @locking_selftest._entry.256, !310, !"_entry", i1 false, i1 false}
!315 = !{ptr @locking_selftest._entry_ptr.257, !310, !"_entry_ptr", i1 false, i1 false}
!316 = !{ptr @.str.258, !310, !"<string literal>", i1 false, i1 false}
!317 = !{ptr @locking_selftest._entry.259, !310, !"_entry", i1 false, i1 false}
!318 = !{ptr @locking_selftest._entry_ptr.260, !310, !"_entry_ptr", i1 false, i1 false}
!319 = !{ptr @.str.261, !310, !"<string literal>", i1 false, i1 false}
!320 = !{ptr @locking_selftest._entry.262, !310, !"_entry", i1 false, i1 false}
!321 = !{ptr @locking_selftest._entry_ptr.263, !310, !"_entry_ptr", i1 false, i1 false}
!322 = !{ptr @.str.264, !310, !"<string literal>", i1 false, i1 false}
!323 = !{ptr @locking_selftest._entry.265, !310, !"_entry", i1 false, i1 false}
!324 = !{ptr @locking_selftest._entry_ptr.266, !310, !"_entry_ptr", i1 false, i1 false}
!325 = !{ptr @.str.267, !310, !"<string literal>", i1 false, i1 false}
!326 = !{ptr @locking_selftest._entry.268, !310, !"_entry", i1 false, i1 false}
!327 = !{ptr @locking_selftest._entry_ptr.269, !310, !"_entry_ptr", i1 false, i1 false}
!328 = !{ptr @.str.270, !310, !"<string literal>", i1 false, i1 false}
!329 = !{ptr @locking_selftest._entry.271, !310, !"_entry", i1 false, i1 false}
!330 = !{ptr @locking_selftest._entry_ptr.272, !310, !"_entry_ptr", i1 false, i1 false}
!331 = !{ptr @.str.273, !310, !"<string literal>", i1 false, i1 false}
!332 = !{ptr @locking_selftest._entry.274, !310, !"_entry", i1 false, i1 false}
!333 = !{ptr @locking_selftest._entry_ptr.275, !310, !"_entry_ptr", i1 false, i1 false}
!334 = !{ptr @.str.276, !310, !"<string literal>", i1 false, i1 false}
!335 = !{ptr @locking_selftest._entry.277, !310, !"_entry", i1 false, i1 false}
!336 = !{ptr @locking_selftest._entry_ptr.278, !310, !"_entry_ptr", i1 false, i1 false}
!337 = !{ptr @.str.279, !310, !"<string literal>", i1 false, i1 false}
!338 = !{ptr @locking_selftest._entry.280, !310, !"_entry", i1 false, i1 false}
!339 = !{ptr @locking_selftest._entry_ptr.281, !310, !"_entry_ptr", i1 false, i1 false}
!340 = !{ptr @.str.282, !310, !"<string literal>", i1 false, i1 false}
!341 = !{ptr @locking_selftest._entry.283, !310, !"_entry", i1 false, i1 false}
!342 = !{ptr @locking_selftest._entry_ptr.284, !310, !"_entry_ptr", i1 false, i1 false}
!343 = !{ptr @.str.285, !310, !"<string literal>", i1 false, i1 false}
!344 = !{ptr @locking_selftest._entry.286, !310, !"_entry", i1 false, i1 false}
!345 = !{ptr @locking_selftest._entry_ptr.287, !310, !"_entry_ptr", i1 false, i1 false}
!346 = !{ptr @.str.288, !347, !"<string literal>", i1 false, i1 false}
!347 = !{!"../lib/locking-selftest.c", i32 2960, i32 2}
!348 = !{ptr @locking_selftest._entry.289, !347, !"_entry", i1 false, i1 false}
!349 = !{ptr @locking_selftest._entry_ptr.290, !347, !"_entry_ptr", i1 false, i1 false}
!350 = !{ptr @.str.291, !347, !"<string literal>", i1 false, i1 false}
!351 = !{ptr @locking_selftest._entry.292, !347, !"_entry", i1 false, i1 false}
!352 = !{ptr @locking_selftest._entry_ptr.293, !347, !"_entry_ptr", i1 false, i1 false}
!353 = !{ptr @.str.294, !347, !"<string literal>", i1 false, i1 false}
!354 = !{ptr @locking_selftest._entry.295, !347, !"_entry", i1 false, i1 false}
!355 = !{ptr @locking_selftest._entry_ptr.296, !347, !"_entry_ptr", i1 false, i1 false}
!356 = !{ptr @.str.297, !347, !"<string literal>", i1 false, i1 false}
!357 = !{ptr @locking_selftest._entry.298, !347, !"_entry", i1 false, i1 false}
!358 = !{ptr @locking_selftest._entry_ptr.299, !347, !"_entry_ptr", i1 false, i1 false}
!359 = !{ptr @.str.300, !347, !"<string literal>", i1 false, i1 false}
!360 = !{ptr @locking_selftest._entry.301, !347, !"_entry", i1 false, i1 false}
!361 = !{ptr @locking_selftest._entry_ptr.302, !347, !"_entry_ptr", i1 false, i1 false}
!362 = !{ptr @.str.303, !347, !"<string literal>", i1 false, i1 false}
!363 = !{ptr @locking_selftest._entry.304, !347, !"_entry", i1 false, i1 false}
!364 = !{ptr @locking_selftest._entry_ptr.305, !347, !"_entry_ptr", i1 false, i1 false}
!365 = !{ptr @.str.306, !347, !"<string literal>", i1 false, i1 false}
!366 = !{ptr @locking_selftest._entry.307, !347, !"_entry", i1 false, i1 false}
!367 = !{ptr @locking_selftest._entry_ptr.308, !347, !"_entry_ptr", i1 false, i1 false}
!368 = !{ptr @.str.309, !347, !"<string literal>", i1 false, i1 false}
!369 = !{ptr @locking_selftest._entry.310, !347, !"_entry", i1 false, i1 false}
!370 = !{ptr @locking_selftest._entry_ptr.311, !347, !"_entry_ptr", i1 false, i1 false}
!371 = !{ptr @.str.312, !347, !"<string literal>", i1 false, i1 false}
!372 = !{ptr @locking_selftest._entry.313, !347, !"_entry", i1 false, i1 false}
!373 = !{ptr @locking_selftest._entry_ptr.314, !347, !"_entry_ptr", i1 false, i1 false}
!374 = !{ptr @.str.315, !347, !"<string literal>", i1 false, i1 false}
!375 = !{ptr @locking_selftest._entry.316, !347, !"_entry", i1 false, i1 false}
!376 = !{ptr @locking_selftest._entry_ptr.317, !347, !"_entry_ptr", i1 false, i1 false}
!377 = !{ptr @.str.318, !347, !"<string literal>", i1 false, i1 false}
!378 = !{ptr @locking_selftest._entry.319, !347, !"_entry", i1 false, i1 false}
!379 = !{ptr @locking_selftest._entry_ptr.320, !347, !"_entry_ptr", i1 false, i1 false}
!380 = !{ptr @.str.321, !347, !"<string literal>", i1 false, i1 false}
!381 = !{ptr @locking_selftest._entry.322, !347, !"_entry", i1 false, i1 false}
!382 = !{ptr @locking_selftest._entry_ptr.323, !347, !"_entry_ptr", i1 false, i1 false}
!383 = !{ptr @.str.324, !384, !"<string literal>", i1 false, i1 false}
!384 = !{!"../lib/locking-selftest.c", i32 2961, i32 2}
!385 = !{ptr @locking_selftest._entry.325, !384, !"_entry", i1 false, i1 false}
!386 = !{ptr @locking_selftest._entry_ptr.326, !384, !"_entry_ptr", i1 false, i1 false}
!387 = !{ptr @.str.327, !384, !"<string literal>", i1 false, i1 false}
!388 = !{ptr @locking_selftest._entry.328, !384, !"_entry", i1 false, i1 false}
!389 = !{ptr @locking_selftest._entry_ptr.329, !384, !"_entry_ptr", i1 false, i1 false}
!390 = !{ptr @.str.330, !384, !"<string literal>", i1 false, i1 false}
!391 = !{ptr @locking_selftest._entry.331, !384, !"_entry", i1 false, i1 false}
!392 = !{ptr @locking_selftest._entry_ptr.332, !384, !"_entry_ptr", i1 false, i1 false}
!393 = !{ptr @.str.333, !384, !"<string literal>", i1 false, i1 false}
!394 = !{ptr @locking_selftest._entry.334, !384, !"_entry", i1 false, i1 false}
!395 = !{ptr @locking_selftest._entry_ptr.335, !384, !"_entry_ptr", i1 false, i1 false}
!396 = !{ptr @.str.336, !384, !"<string literal>", i1 false, i1 false}
!397 = !{ptr @locking_selftest._entry.337, !384, !"_entry", i1 false, i1 false}
!398 = !{ptr @locking_selftest._entry_ptr.338, !384, !"_entry_ptr", i1 false, i1 false}
!399 = !{ptr @.str.339, !384, !"<string literal>", i1 false, i1 false}
!400 = !{ptr @locking_selftest._entry.340, !384, !"_entry", i1 false, i1 false}
!401 = !{ptr @locking_selftest._entry_ptr.341, !384, !"_entry_ptr", i1 false, i1 false}
!402 = !{ptr @.str.342, !384, !"<string literal>", i1 false, i1 false}
!403 = !{ptr @locking_selftest._entry.343, !384, !"_entry", i1 false, i1 false}
!404 = !{ptr @locking_selftest._entry_ptr.344, !384, !"_entry_ptr", i1 false, i1 false}
!405 = !{ptr @.str.345, !384, !"<string literal>", i1 false, i1 false}
!406 = !{ptr @locking_selftest._entry.346, !384, !"_entry", i1 false, i1 false}
!407 = !{ptr @locking_selftest._entry_ptr.347, !384, !"_entry_ptr", i1 false, i1 false}
!408 = !{ptr @.str.348, !384, !"<string literal>", i1 false, i1 false}
!409 = !{ptr @locking_selftest._entry.349, !384, !"_entry", i1 false, i1 false}
!410 = !{ptr @locking_selftest._entry_ptr.350, !384, !"_entry_ptr", i1 false, i1 false}
!411 = !{ptr @.str.351, !384, !"<string literal>", i1 false, i1 false}
!412 = !{ptr @locking_selftest._entry.352, !384, !"_entry", i1 false, i1 false}
!413 = !{ptr @locking_selftest._entry_ptr.353, !384, !"_entry_ptr", i1 false, i1 false}
!414 = !{ptr @.str.354, !384, !"<string literal>", i1 false, i1 false}
!415 = !{ptr @locking_selftest._entry.355, !384, !"_entry", i1 false, i1 false}
!416 = !{ptr @locking_selftest._entry_ptr.356, !384, !"_entry_ptr", i1 false, i1 false}
!417 = !{ptr @.str.357, !384, !"<string literal>", i1 false, i1 false}
!418 = !{ptr @locking_selftest._entry.358, !384, !"_entry", i1 false, i1 false}
!419 = !{ptr @locking_selftest._entry_ptr.359, !384, !"_entry_ptr", i1 false, i1 false}
!420 = !{ptr @.str.360, !421, !"<string literal>", i1 false, i1 false}
!421 = !{!"../lib/locking-selftest.c", i32 2963, i32 2}
!422 = !{ptr @.str.362, !421, !"<string literal>", i1 false, i1 false}
!423 = !{ptr @locking_selftest._entry.361, !421, !"_entry", i1 false, i1 false}
!424 = !{ptr @locking_selftest._entry_ptr.363, !421, !"_entry_ptr", i1 false, i1 false}
!425 = !{ptr @locking_selftest._entry.364, !421, !"_entry", i1 false, i1 false}
!426 = !{ptr @locking_selftest._entry_ptr.365, !421, !"_entry_ptr", i1 false, i1 false}
!427 = !{ptr @.str.366, !421, !"<string literal>", i1 false, i1 false}
!428 = !{ptr @locking_selftest._entry.367, !421, !"_entry", i1 false, i1 false}
!429 = !{ptr @locking_selftest._entry_ptr.368, !421, !"_entry_ptr", i1 false, i1 false}
!430 = !{ptr @locking_selftest._entry.369, !421, !"_entry", i1 false, i1 false}
!431 = !{ptr @locking_selftest._entry_ptr.370, !421, !"_entry_ptr", i1 false, i1 false}
!432 = !{ptr @.str.371, !421, !"<string literal>", i1 false, i1 false}
!433 = !{ptr @locking_selftest._entry.372, !421, !"_entry", i1 false, i1 false}
!434 = !{ptr @locking_selftest._entry_ptr.373, !421, !"_entry_ptr", i1 false, i1 false}
!435 = !{ptr @locking_selftest._entry.374, !421, !"_entry", i1 false, i1 false}
!436 = !{ptr @locking_selftest._entry_ptr.375, !421, !"_entry_ptr", i1 false, i1 false}
!437 = !{ptr @.str.376, !421, !"<string literal>", i1 false, i1 false}
!438 = !{ptr @locking_selftest._entry.377, !421, !"_entry", i1 false, i1 false}
!439 = !{ptr @locking_selftest._entry_ptr.378, !421, !"_entry_ptr", i1 false, i1 false}
!440 = !{ptr @locking_selftest._entry.379, !421, !"_entry", i1 false, i1 false}
!441 = !{ptr @locking_selftest._entry_ptr.380, !421, !"_entry_ptr", i1 false, i1 false}
!442 = !{ptr @.str.381, !421, !"<string literal>", i1 false, i1 false}
!443 = !{ptr @locking_selftest._entry.382, !421, !"_entry", i1 false, i1 false}
!444 = !{ptr @locking_selftest._entry_ptr.383, !421, !"_entry_ptr", i1 false, i1 false}
!445 = !{ptr @locking_selftest._entry.384, !421, !"_entry", i1 false, i1 false}
!446 = !{ptr @locking_selftest._entry_ptr.385, !421, !"_entry_ptr", i1 false, i1 false}
!447 = !{ptr @.str.386, !421, !"<string literal>", i1 false, i1 false}
!448 = !{ptr @locking_selftest._entry.387, !421, !"_entry", i1 false, i1 false}
!449 = !{ptr @locking_selftest._entry_ptr.388, !421, !"_entry_ptr", i1 false, i1 false}
!450 = !{ptr @locking_selftest._entry.389, !421, !"_entry", i1 false, i1 false}
!451 = !{ptr @locking_selftest._entry_ptr.390, !421, !"_entry_ptr", i1 false, i1 false}
!452 = !{ptr @.str.391, !421, !"<string literal>", i1 false, i1 false}
!453 = !{ptr @locking_selftest._entry.392, !421, !"_entry", i1 false, i1 false}
!454 = !{ptr @locking_selftest._entry_ptr.393, !421, !"_entry_ptr", i1 false, i1 false}
!455 = !{ptr @locking_selftest._entry.394, !421, !"_entry", i1 false, i1 false}
!456 = !{ptr @locking_selftest._entry_ptr.395, !421, !"_entry_ptr", i1 false, i1 false}
!457 = !{ptr @.str.396, !421, !"<string literal>", i1 false, i1 false}
!458 = !{ptr @locking_selftest._entry.397, !421, !"_entry", i1 false, i1 false}
!459 = !{ptr @locking_selftest._entry_ptr.398, !421, !"_entry_ptr", i1 false, i1 false}
!460 = !{ptr @locking_selftest._entry.399, !421, !"_entry", i1 false, i1 false}
!461 = !{ptr @locking_selftest._entry_ptr.400, !421, !"_entry_ptr", i1 false, i1 false}
!462 = !{ptr @.str.401, !421, !"<string literal>", i1 false, i1 false}
!463 = !{ptr @locking_selftest._entry.402, !421, !"_entry", i1 false, i1 false}
!464 = !{ptr @locking_selftest._entry_ptr.403, !421, !"_entry_ptr", i1 false, i1 false}
!465 = !{ptr @locking_selftest._entry.404, !421, !"_entry", i1 false, i1 false}
!466 = !{ptr @locking_selftest._entry_ptr.405, !421, !"_entry_ptr", i1 false, i1 false}
!467 = !{ptr @.str.406, !421, !"<string literal>", i1 false, i1 false}
!468 = !{ptr @locking_selftest._entry.407, !421, !"_entry", i1 false, i1 false}
!469 = !{ptr @locking_selftest._entry_ptr.408, !421, !"_entry_ptr", i1 false, i1 false}
!470 = !{ptr @locking_selftest._entry.409, !421, !"_entry", i1 false, i1 false}
!471 = !{ptr @locking_selftest._entry_ptr.410, !421, !"_entry_ptr", i1 false, i1 false}
!472 = !{ptr @.str.411, !421, !"<string literal>", i1 false, i1 false}
!473 = !{ptr @locking_selftest._entry.412, !421, !"_entry", i1 false, i1 false}
!474 = !{ptr @locking_selftest._entry_ptr.413, !421, !"_entry_ptr", i1 false, i1 false}
!475 = !{ptr @locking_selftest._entry.414, !421, !"_entry", i1 false, i1 false}
!476 = !{ptr @locking_selftest._entry_ptr.415, !421, !"_entry_ptr", i1 false, i1 false}
!477 = !{ptr @.str.416, !421, !"<string literal>", i1 false, i1 false}
!478 = !{ptr @locking_selftest._entry.417, !421, !"_entry", i1 false, i1 false}
!479 = !{ptr @locking_selftest._entry_ptr.418, !421, !"_entry_ptr", i1 false, i1 false}
!480 = !{ptr @locking_selftest._entry.419, !421, !"_entry", i1 false, i1 false}
!481 = !{ptr @locking_selftest._entry_ptr.420, !421, !"_entry_ptr", i1 false, i1 false}
!482 = !{ptr @.str.421, !483, !"<string literal>", i1 false, i1 false}
!483 = !{!"../lib/locking-selftest.c", i32 2964, i32 2}
!484 = !{ptr @locking_selftest._entry.422, !483, !"_entry", i1 false, i1 false}
!485 = !{ptr @locking_selftest._entry_ptr.423, !483, !"_entry_ptr", i1 false, i1 false}
!486 = !{ptr @locking_selftest._entry.424, !483, !"_entry", i1 false, i1 false}
!487 = !{ptr @locking_selftest._entry_ptr.425, !483, !"_entry_ptr", i1 false, i1 false}
!488 = !{ptr @.str.426, !483, !"<string literal>", i1 false, i1 false}
!489 = !{ptr @locking_selftest._entry.427, !483, !"_entry", i1 false, i1 false}
!490 = !{ptr @locking_selftest._entry_ptr.428, !483, !"_entry_ptr", i1 false, i1 false}
!491 = !{ptr @locking_selftest._entry.429, !483, !"_entry", i1 false, i1 false}
!492 = !{ptr @locking_selftest._entry_ptr.430, !483, !"_entry_ptr", i1 false, i1 false}
!493 = !{ptr @.str.431, !483, !"<string literal>", i1 false, i1 false}
!494 = !{ptr @locking_selftest._entry.432, !483, !"_entry", i1 false, i1 false}
!495 = !{ptr @locking_selftest._entry_ptr.433, !483, !"_entry_ptr", i1 false, i1 false}
!496 = !{ptr @locking_selftest._entry.434, !483, !"_entry", i1 false, i1 false}
!497 = !{ptr @locking_selftest._entry_ptr.435, !483, !"_entry_ptr", i1 false, i1 false}
!498 = !{ptr @.str.436, !483, !"<string literal>", i1 false, i1 false}
!499 = !{ptr @locking_selftest._entry.437, !483, !"_entry", i1 false, i1 false}
!500 = !{ptr @locking_selftest._entry_ptr.438, !483, !"_entry_ptr", i1 false, i1 false}
!501 = !{ptr @locking_selftest._entry.439, !483, !"_entry", i1 false, i1 false}
!502 = !{ptr @locking_selftest._entry_ptr.440, !483, !"_entry_ptr", i1 false, i1 false}
!503 = !{ptr @.str.441, !483, !"<string literal>", i1 false, i1 false}
!504 = !{ptr @locking_selftest._entry.442, !483, !"_entry", i1 false, i1 false}
!505 = !{ptr @locking_selftest._entry_ptr.443, !483, !"_entry_ptr", i1 false, i1 false}
!506 = !{ptr @locking_selftest._entry.444, !483, !"_entry", i1 false, i1 false}
!507 = !{ptr @locking_selftest._entry_ptr.445, !483, !"_entry_ptr", i1 false, i1 false}
!508 = !{ptr @.str.446, !483, !"<string literal>", i1 false, i1 false}
!509 = !{ptr @locking_selftest._entry.447, !483, !"_entry", i1 false, i1 false}
!510 = !{ptr @locking_selftest._entry_ptr.448, !483, !"_entry_ptr", i1 false, i1 false}
!511 = !{ptr @locking_selftest._entry.449, !483, !"_entry", i1 false, i1 false}
!512 = !{ptr @locking_selftest._entry_ptr.450, !483, !"_entry_ptr", i1 false, i1 false}
!513 = !{ptr @.str.451, !483, !"<string literal>", i1 false, i1 false}
!514 = !{ptr @locking_selftest._entry.452, !483, !"_entry", i1 false, i1 false}
!515 = !{ptr @locking_selftest._entry_ptr.453, !483, !"_entry_ptr", i1 false, i1 false}
!516 = !{ptr @locking_selftest._entry.454, !483, !"_entry", i1 false, i1 false}
!517 = !{ptr @locking_selftest._entry_ptr.455, !483, !"_entry_ptr", i1 false, i1 false}
!518 = !{ptr @.str.456, !483, !"<string literal>", i1 false, i1 false}
!519 = !{ptr @locking_selftest._entry.457, !483, !"_entry", i1 false, i1 false}
!520 = !{ptr @locking_selftest._entry_ptr.458, !483, !"_entry_ptr", i1 false, i1 false}
!521 = !{ptr @locking_selftest._entry.459, !483, !"_entry", i1 false, i1 false}
!522 = !{ptr @locking_selftest._entry_ptr.460, !483, !"_entry_ptr", i1 false, i1 false}
!523 = !{ptr @.str.461, !483, !"<string literal>", i1 false, i1 false}
!524 = !{ptr @locking_selftest._entry.462, !483, !"_entry", i1 false, i1 false}
!525 = !{ptr @locking_selftest._entry_ptr.463, !483, !"_entry_ptr", i1 false, i1 false}
!526 = !{ptr @locking_selftest._entry.464, !483, !"_entry", i1 false, i1 false}
!527 = !{ptr @locking_selftest._entry_ptr.465, !483, !"_entry_ptr", i1 false, i1 false}
!528 = !{ptr @.str.466, !483, !"<string literal>", i1 false, i1 false}
!529 = !{ptr @locking_selftest._entry.467, !483, !"_entry", i1 false, i1 false}
!530 = !{ptr @locking_selftest._entry_ptr.468, !483, !"_entry_ptr", i1 false, i1 false}
!531 = !{ptr @locking_selftest._entry.469, !483, !"_entry", i1 false, i1 false}
!532 = !{ptr @locking_selftest._entry_ptr.470, !483, !"_entry_ptr", i1 false, i1 false}
!533 = !{ptr @.str.471, !483, !"<string literal>", i1 false, i1 false}
!534 = !{ptr @locking_selftest._entry.472, !483, !"_entry", i1 false, i1 false}
!535 = !{ptr @locking_selftest._entry_ptr.473, !483, !"_entry_ptr", i1 false, i1 false}
!536 = !{ptr @locking_selftest._entry.474, !483, !"_entry", i1 false, i1 false}
!537 = !{ptr @locking_selftest._entry_ptr.475, !483, !"_entry_ptr", i1 false, i1 false}
!538 = !{ptr @.str.476, !483, !"<string literal>", i1 false, i1 false}
!539 = !{ptr @locking_selftest._entry.477, !483, !"_entry", i1 false, i1 false}
!540 = !{ptr @locking_selftest._entry_ptr.478, !483, !"_entry_ptr", i1 false, i1 false}
!541 = !{ptr @locking_selftest._entry.479, !483, !"_entry", i1 false, i1 false}
!542 = !{ptr @locking_selftest._entry_ptr.480, !483, !"_entry_ptr", i1 false, i1 false}
!543 = !{ptr @.str.481, !544, !"<string literal>", i1 false, i1 false}
!544 = !{!"../lib/locking-selftest.c", i32 2965, i32 2}
!545 = !{ptr @locking_selftest._entry.482, !544, !"_entry", i1 false, i1 false}
!546 = !{ptr @locking_selftest._entry_ptr.483, !544, !"_entry_ptr", i1 false, i1 false}
!547 = !{ptr @locking_selftest._entry.484, !544, !"_entry", i1 false, i1 false}
!548 = !{ptr @locking_selftest._entry_ptr.485, !544, !"_entry_ptr", i1 false, i1 false}
!549 = !{ptr @.str.486, !544, !"<string literal>", i1 false, i1 false}
!550 = !{ptr @locking_selftest._entry.487, !544, !"_entry", i1 false, i1 false}
!551 = !{ptr @locking_selftest._entry_ptr.488, !544, !"_entry_ptr", i1 false, i1 false}
!552 = !{ptr @locking_selftest._entry.489, !544, !"_entry", i1 false, i1 false}
!553 = !{ptr @locking_selftest._entry_ptr.490, !544, !"_entry_ptr", i1 false, i1 false}
!554 = !{ptr @.str.491, !544, !"<string literal>", i1 false, i1 false}
!555 = !{ptr @locking_selftest._entry.492, !544, !"_entry", i1 false, i1 false}
!556 = !{ptr @locking_selftest._entry_ptr.493, !544, !"_entry_ptr", i1 false, i1 false}
!557 = !{ptr @locking_selftest._entry.494, !544, !"_entry", i1 false, i1 false}
!558 = !{ptr @locking_selftest._entry_ptr.495, !544, !"_entry_ptr", i1 false, i1 false}
!559 = !{ptr @.str.496, !544, !"<string literal>", i1 false, i1 false}
!560 = !{ptr @locking_selftest._entry.497, !544, !"_entry", i1 false, i1 false}
!561 = !{ptr @locking_selftest._entry_ptr.498, !544, !"_entry_ptr", i1 false, i1 false}
!562 = !{ptr @locking_selftest._entry.499, !544, !"_entry", i1 false, i1 false}
!563 = !{ptr @locking_selftest._entry_ptr.500, !544, !"_entry_ptr", i1 false, i1 false}
!564 = !{ptr @.str.501, !544, !"<string literal>", i1 false, i1 false}
!565 = !{ptr @locking_selftest._entry.502, !544, !"_entry", i1 false, i1 false}
!566 = !{ptr @locking_selftest._entry_ptr.503, !544, !"_entry_ptr", i1 false, i1 false}
!567 = !{ptr @locking_selftest._entry.504, !544, !"_entry", i1 false, i1 false}
!568 = !{ptr @locking_selftest._entry_ptr.505, !544, !"_entry_ptr", i1 false, i1 false}
!569 = !{ptr @.str.506, !544, !"<string literal>", i1 false, i1 false}
!570 = !{ptr @locking_selftest._entry.507, !544, !"_entry", i1 false, i1 false}
!571 = !{ptr @locking_selftest._entry_ptr.508, !544, !"_entry_ptr", i1 false, i1 false}
!572 = !{ptr @locking_selftest._entry.509, !544, !"_entry", i1 false, i1 false}
!573 = !{ptr @locking_selftest._entry_ptr.510, !544, !"_entry_ptr", i1 false, i1 false}
!574 = !{ptr @.str.511, !544, !"<string literal>", i1 false, i1 false}
!575 = !{ptr @locking_selftest._entry.512, !544, !"_entry", i1 false, i1 false}
!576 = !{ptr @locking_selftest._entry_ptr.513, !544, !"_entry_ptr", i1 false, i1 false}
!577 = !{ptr @locking_selftest._entry.514, !544, !"_entry", i1 false, i1 false}
!578 = !{ptr @locking_selftest._entry_ptr.515, !544, !"_entry_ptr", i1 false, i1 false}
!579 = !{ptr @.str.516, !544, !"<string literal>", i1 false, i1 false}
!580 = !{ptr @locking_selftest._entry.517, !544, !"_entry", i1 false, i1 false}
!581 = !{ptr @locking_selftest._entry_ptr.518, !544, !"_entry_ptr", i1 false, i1 false}
!582 = !{ptr @locking_selftest._entry.519, !544, !"_entry", i1 false, i1 false}
!583 = !{ptr @locking_selftest._entry_ptr.520, !544, !"_entry_ptr", i1 false, i1 false}
!584 = !{ptr @.str.521, !544, !"<string literal>", i1 false, i1 false}
!585 = !{ptr @locking_selftest._entry.522, !544, !"_entry", i1 false, i1 false}
!586 = !{ptr @locking_selftest._entry_ptr.523, !544, !"_entry_ptr", i1 false, i1 false}
!587 = !{ptr @locking_selftest._entry.524, !544, !"_entry", i1 false, i1 false}
!588 = !{ptr @locking_selftest._entry_ptr.525, !544, !"_entry_ptr", i1 false, i1 false}
!589 = !{ptr @.str.526, !544, !"<string literal>", i1 false, i1 false}
!590 = !{ptr @locking_selftest._entry.527, !544, !"_entry", i1 false, i1 false}
!591 = !{ptr @locking_selftest._entry_ptr.528, !544, !"_entry_ptr", i1 false, i1 false}
!592 = !{ptr @locking_selftest._entry.529, !544, !"_entry", i1 false, i1 false}
!593 = !{ptr @locking_selftest._entry_ptr.530, !544, !"_entry_ptr", i1 false, i1 false}
!594 = !{ptr @.str.531, !544, !"<string literal>", i1 false, i1 false}
!595 = !{ptr @locking_selftest._entry.532, !544, !"_entry", i1 false, i1 false}
!596 = !{ptr @locking_selftest._entry_ptr.533, !544, !"_entry_ptr", i1 false, i1 false}
!597 = !{ptr @locking_selftest._entry.534, !544, !"_entry", i1 false, i1 false}
!598 = !{ptr @locking_selftest._entry_ptr.535, !544, !"_entry_ptr", i1 false, i1 false}
!599 = !{ptr @.str.536, !544, !"<string literal>", i1 false, i1 false}
!600 = !{ptr @locking_selftest._entry.537, !544, !"_entry", i1 false, i1 false}
!601 = !{ptr @locking_selftest._entry_ptr.538, !544, !"_entry_ptr", i1 false, i1 false}
!602 = !{ptr @locking_selftest._entry.539, !544, !"_entry", i1 false, i1 false}
!603 = !{ptr @locking_selftest._entry_ptr.540, !544, !"_entry_ptr", i1 false, i1 false}
!604 = !{ptr @.str.541, !605, !"<string literal>", i1 false, i1 false}
!605 = !{!"../lib/locking-selftest.c", i32 2984, i32 17}
!606 = !{ptr @locking_selftest._entry.542, !607, !"_entry", i1 false, i1 false}
!607 = !{!"../lib/locking-selftest.c", i32 2986, i32 2}
!608 = !{ptr @locking_selftest._entry_ptr.543, !607, !"_entry_ptr", i1 false, i1 false}
!609 = !{ptr @.str.545, !610, !"<string literal>", i1 false, i1 false}
!610 = !{!"../lib/locking-selftest.c", i32 2989, i32 3}
!611 = !{ptr @locking_selftest._entry.544, !610, !"_entry", i1 false, i1 false}
!612 = !{ptr @locking_selftest._entry_ptr.546, !610, !"_entry_ptr", i1 false, i1 false}
!613 = !{ptr @.str.548, !614, !"<string literal>", i1 false, i1 false}
!614 = !{!"../lib/locking-selftest.c", i32 2991, i32 3}
!615 = !{ptr @locking_selftest._entry.547, !614, !"_entry", i1 false, i1 false}
!616 = !{ptr @locking_selftest._entry_ptr.549, !614, !"_entry_ptr", i1 false, i1 false}
!617 = !{ptr @locking_selftest._entry.550, !618, !"_entry", i1 false, i1 false}
!618 = !{!"../lib/locking-selftest.c", i32 2993, i32 3}
!619 = !{ptr @locking_selftest._entry_ptr.551, !618, !"_entry_ptr", i1 false, i1 false}
!620 = !{ptr @.str.553, !621, !"<string literal>", i1 false, i1 false}
!621 = !{!"../lib/locking-selftest.c", i32 2995, i32 3}
!622 = !{ptr @locking_selftest._entry.552, !621, !"_entry", i1 false, i1 false}
!623 = !{ptr @locking_selftest._entry_ptr.554, !621, !"_entry_ptr", i1 false, i1 false}
!624 = !{ptr @.str.556, !625, !"<string literal>", i1 false, i1 false}
!625 = !{!"../lib/locking-selftest.c", i32 2996, i32 3}
!626 = !{ptr @locking_selftest._entry.555, !625, !"_entry", i1 false, i1 false}
!627 = !{ptr @locking_selftest._entry_ptr.557, !625, !"_entry_ptr", i1 false, i1 false}
!628 = !{ptr @.str.559, !629, !"<string literal>", i1 false, i1 false}
!629 = !{!"../lib/locking-selftest.c", i32 2998, i32 3}
!630 = !{ptr @locking_selftest._entry.558, !629, !"_entry", i1 false, i1 false}
!631 = !{ptr @locking_selftest._entry_ptr.560, !629, !"_entry_ptr", i1 false, i1 false}
!632 = !{ptr @locking_selftest._entry.561, !633, !"_entry", i1 false, i1 false}
!633 = !{!"../lib/locking-selftest.c", i32 3001, i32 3}
!634 = !{ptr @locking_selftest._entry_ptr.562, !633, !"_entry_ptr", i1 false, i1 false}
!635 = !{ptr @.str.564, !636, !"<string literal>", i1 false, i1 false}
!636 = !{!"../lib/locking-selftest.c", i32 3002, i32 3}
!637 = !{ptr @locking_selftest._entry.563, !636, !"_entry", i1 false, i1 false}
!638 = !{ptr @locking_selftest._entry_ptr.565, !636, !"_entry_ptr", i1 false, i1 false}
!639 = !{ptr @.str.567, !640, !"<string literal>", i1 false, i1 false}
!640 = !{!"../lib/locking-selftest.c", i32 3004, i32 3}
!641 = !{ptr @locking_selftest._entry.566, !640, !"_entry", i1 false, i1 false}
!642 = !{ptr @locking_selftest._entry_ptr.568, !640, !"_entry_ptr", i1 false, i1 false}
!643 = !{ptr @.str.570, !644, !"<string literal>", i1 false, i1 false}
!644 = !{!"../lib/locking-selftest.c", i32 3007, i32 3}
!645 = !{ptr @locking_selftest._entry.569, !644, !"_entry", i1 false, i1 false}
!646 = !{ptr @locking_selftest._entry_ptr.571, !644, !"_entry_ptr", i1 false, i1 false}
!647 = !{ptr @.str.573, !648, !"<string literal>", i1 false, i1 false}
!648 = !{!"../lib/locking-selftest.c", i32 3008, i32 3}
!649 = !{ptr @locking_selftest._entry.572, !648, !"_entry", i1 false, i1 false}
!650 = !{ptr @locking_selftest._entry_ptr.574, !648, !"_entry_ptr", i1 false, i1 false}
!651 = !{ptr @.str.576, !652, !"<string literal>", i1 false, i1 false}
!652 = !{!"../lib/locking-selftest.c", i32 3010, i32 3}
!653 = !{ptr @locking_selftest._entry.575, !652, !"_entry", i1 false, i1 false}
!654 = !{ptr @locking_selftest._entry_ptr.577, !652, !"_entry_ptr", i1 false, i1 false}
!655 = !{ptr @force_read_lock_recursive, !656, !"force_read_lock_recursive", i1 false, i1 false}
!656 = !{!"../lib/locking-selftest.c", i32 39, i32 14}
!657 = !{ptr @__pcpu_unique_local_A, !658, !"__pcpu_unique_local_A", i1 false, i1 false}
!658 = !{!"../lib/locking-selftest.c", i32 148, i32 8}
!659 = !{ptr @local_A, !658, !"local_A", i1 false, i1 false}
!660 = !{ptr @testcase_total, !661, !"testcase_total", i1 false, i1 false}
!661 = !{!"../lib/locking-selftest.c", i32 1425, i32 12}
!662 = !{ptr @testcase_successes, !663, !"testcase_successes", i1 false, i1 false}
!663 = !{!"../lib/locking-selftest.c", i32 1426, i32 12}
!664 = distinct !{null, !665, !"expected_testcase_failures", i1 false, i1 false}
!665 = !{!"../lib/locking-selftest.c", i32 1427, i32 12}
!666 = !{ptr @unexpected_testcase_failures, !667, !"unexpected_testcase_failures", i1 false, i1 false}
!667 = !{!"../lib/locking-selftest.c", i32 1428, i32 12}
!668 = !{ptr @__setup_str_setup_debug_locks_verbose, !1, !"__setup_str_setup_debug_locks_verbose", i1 false, i1 false}
!669 = !{ptr @debug_locks_verbose, !670, !"debug_locks_verbose", i1 false, i1 false}
!670 = !{!"../lib/locking-selftest.c", i32 38, i32 21}
!671 = !{ptr @init_shared_classes.rt_X, !672, !"rt_X", i1 false, i1 false}
!672 = !{!"../lib/locking-selftest.c", i32 172, i32 31}
!673 = !{ptr @init_shared_classes.rt_Y, !674, !"rt_Y", i1 false, i1 false}
!674 = !{!"../lib/locking-selftest.c", i32 172, i32 37}
!675 = !{ptr @init_shared_classes.rt_Z, !676, !"rt_Z", i1 false, i1 false}
!676 = !{!"../lib/locking-selftest.c", i32 172, i32 43}
!677 = !{ptr @__func__.init_shared_classes, !678, !"<string literal>", i1 false, i1 false}
!678 = !{!"../lib/locking-selftest.c", i32 174, i32 31}
!679 = !{ptr @.str.578, !680, !"<string literal>", i1 false, i1 false}
!680 = !{!"../lib/locking-selftest.c", i32 139, i32 8}
!681 = !{ptr @.str.579, !680, !"<string literal>", i1 false, i1 false}
!682 = !{ptr @rtmutex_X1, !680, !"rtmutex_X1", i1 false, i1 false}
!683 = !{ptr @.str.580, !684, !"<string literal>", i1 false, i1 false}
!684 = !{!"../lib/locking-selftest.c", i32 140, i32 8}
!685 = !{ptr @.str.581, !684, !"<string literal>", i1 false, i1 false}
!686 = !{ptr @rtmutex_X2, !684, !"rtmutex_X2", i1 false, i1 false}
!687 = !{ptr @.str.582, !688, !"<string literal>", i1 false, i1 false}
!688 = !{!"../lib/locking-selftest.c", i32 141, i32 8}
!689 = !{ptr @.str.583, !688, !"<string literal>", i1 false, i1 false}
!690 = !{ptr @rtmutex_Y1, !688, !"rtmutex_Y1", i1 false, i1 false}
!691 = !{ptr @.str.584, !692, !"<string literal>", i1 false, i1 false}
!692 = !{!"../lib/locking-selftest.c", i32 142, i32 8}
!693 = !{ptr @.str.585, !692, !"<string literal>", i1 false, i1 false}
!694 = !{ptr @rtmutex_Y2, !692, !"rtmutex_Y2", i1 false, i1 false}
!695 = !{ptr @.str.586, !696, !"<string literal>", i1 false, i1 false}
!696 = !{!"../lib/locking-selftest.c", i32 143, i32 8}
!697 = !{ptr @.str.587, !696, !"<string literal>", i1 false, i1 false}
!698 = !{ptr @rtmutex_Z1, !696, !"rtmutex_Z1", i1 false, i1 false}
!699 = !{ptr @.str.588, !700, !"<string literal>", i1 false, i1 false}
!700 = !{!"../lib/locking-selftest.c", i32 144, i32 8}
!701 = !{ptr @.str.589, !700, !"<string literal>", i1 false, i1 false}
!702 = !{ptr @rtmutex_Z2, !700, !"rtmutex_Z2", i1 false, i1 false}
!703 = !{ptr @init_class_X.__key, !704, !"__key", i1 false, i1 false}
!704 = !{!"../lib/locking-selftest.c", i32 165, i32 1}
!705 = !{ptr @.str.590, !704, !"<string literal>", i1 false, i1 false}
!706 = !{ptr @init_class_X.__key.591, !704, !"__key", i1 false, i1 false}
!707 = !{ptr @.str.592, !704, !"<string literal>", i1 false, i1 false}
!708 = !{ptr @init_class_X.__key.593, !704, !"__key", i1 false, i1 false}
!709 = !{ptr @.str.594, !704, !"<string literal>", i1 false, i1 false}
!710 = !{ptr @init_class_X.__key.595, !704, !"__key", i1 false, i1 false}
!711 = !{ptr @.str.596, !704, !"<string literal>", i1 false, i1 false}
!712 = !{ptr @.str.597, !713, !"<string literal>", i1 false, i1 false}
!713 = !{!"../lib/locking-selftest.c", i32 109, i32 8}
!714 = !{ptr @lock_X1, !713, !"lock_X1", i1 false, i1 false}
!715 = !{ptr @.str.598, !716, !"<string literal>", i1 false, i1 false}
!716 = !{!"../lib/locking-selftest.c", i32 116, i32 8}
!717 = !{ptr @rwlock_X1, !716, !"rwlock_X1", i1 false, i1 false}
!718 = !{ptr @.str.599, !719, !"<string literal>", i1 false, i1 false}
!719 = !{!"../lib/locking-selftest.c", i32 123, i32 8}
!720 = !{ptr @.str.600, !719, !"<string literal>", i1 false, i1 false}
!721 = !{ptr @mutex_X1, !719, !"mutex_X1", i1 false, i1 false}
!722 = !{ptr @.str.601, !723, !"<string literal>", i1 false, i1 false}
!723 = !{!"../lib/locking-selftest.c", i32 130, i32 8}
!724 = !{ptr @.str.602, !723, !"<string literal>", i1 false, i1 false}
!725 = !{ptr @rwsem_X1, !723, !"rwsem_X1", i1 false, i1 false}
!726 = !{ptr @.str.603, !727, !"<string literal>", i1 false, i1 false}
!727 = !{!"../lib/locking-selftest.c", i32 110, i32 8}
!728 = !{ptr @lock_X2, !727, !"lock_X2", i1 false, i1 false}
!729 = !{ptr @.str.604, !730, !"<string literal>", i1 false, i1 false}
!730 = !{!"../lib/locking-selftest.c", i32 117, i32 8}
!731 = !{ptr @rwlock_X2, !730, !"rwlock_X2", i1 false, i1 false}
!732 = !{ptr @.str.605, !733, !"<string literal>", i1 false, i1 false}
!733 = !{!"../lib/locking-selftest.c", i32 124, i32 8}
!734 = !{ptr @.str.606, !733, !"<string literal>", i1 false, i1 false}
!735 = !{ptr @mutex_X2, !733, !"mutex_X2", i1 false, i1 false}
!736 = !{ptr @.str.607, !737, !"<string literal>", i1 false, i1 false}
!737 = !{!"../lib/locking-selftest.c", i32 131, i32 8}
!738 = !{ptr @.str.608, !737, !"<string literal>", i1 false, i1 false}
!739 = !{ptr @rwsem_X2, !737, !"rwsem_X2", i1 false, i1 false}
!740 = !{ptr @init_class_Y.__key, !741, !"__key", i1 false, i1 false}
!741 = !{!"../lib/locking-selftest.c", i32 166, i32 1}
!742 = !{ptr @init_class_Y.__key.609, !741, !"__key", i1 false, i1 false}
!743 = !{ptr @init_class_Y.__key.610, !741, !"__key", i1 false, i1 false}
!744 = !{ptr @init_class_Y.__key.611, !741, !"__key", i1 false, i1 false}
!745 = !{ptr @.str.612, !746, !"<string literal>", i1 false, i1 false}
!746 = !{!"../lib/locking-selftest.c", i32 111, i32 8}
!747 = !{ptr @lock_Y1, !746, !"lock_Y1", i1 false, i1 false}
!748 = !{ptr @.str.613, !749, !"<string literal>", i1 false, i1 false}
!749 = !{!"../lib/locking-selftest.c", i32 118, i32 8}
!750 = !{ptr @rwlock_Y1, !749, !"rwlock_Y1", i1 false, i1 false}
!751 = !{ptr @.str.614, !752, !"<string literal>", i1 false, i1 false}
!752 = !{!"../lib/locking-selftest.c", i32 125, i32 8}
!753 = !{ptr @.str.615, !752, !"<string literal>", i1 false, i1 false}
!754 = !{ptr @mutex_Y1, !752, !"mutex_Y1", i1 false, i1 false}
!755 = !{ptr @.str.616, !756, !"<string literal>", i1 false, i1 false}
!756 = !{!"../lib/locking-selftest.c", i32 132, i32 8}
!757 = !{ptr @.str.617, !756, !"<string literal>", i1 false, i1 false}
!758 = !{ptr @rwsem_Y1, !756, !"rwsem_Y1", i1 false, i1 false}
!759 = !{ptr @.str.618, !760, !"<string literal>", i1 false, i1 false}
!760 = !{!"../lib/locking-selftest.c", i32 112, i32 8}
!761 = !{ptr @lock_Y2, !760, !"lock_Y2", i1 false, i1 false}
!762 = !{ptr @.str.619, !763, !"<string literal>", i1 false, i1 false}
!763 = !{!"../lib/locking-selftest.c", i32 119, i32 8}
!764 = !{ptr @rwlock_Y2, !763, !"rwlock_Y2", i1 false, i1 false}
!765 = !{ptr @.str.620, !766, !"<string literal>", i1 false, i1 false}
!766 = !{!"../lib/locking-selftest.c", i32 126, i32 8}
!767 = !{ptr @.str.621, !766, !"<string literal>", i1 false, i1 false}
!768 = !{ptr @mutex_Y2, !766, !"mutex_Y2", i1 false, i1 false}
!769 = !{ptr @.str.622, !770, !"<string literal>", i1 false, i1 false}
!770 = !{!"../lib/locking-selftest.c", i32 133, i32 8}
!771 = !{ptr @.str.623, !770, !"<string literal>", i1 false, i1 false}
!772 = !{ptr @rwsem_Y2, !770, !"rwsem_Y2", i1 false, i1 false}
!773 = !{ptr @init_class_Z.__key, !774, !"__key", i1 false, i1 false}
!774 = !{!"../lib/locking-selftest.c", i32 167, i32 1}
!775 = !{ptr @init_class_Z.__key.624, !774, !"__key", i1 false, i1 false}
!776 = !{ptr @init_class_Z.__key.625, !774, !"__key", i1 false, i1 false}
!777 = !{ptr @init_class_Z.__key.626, !774, !"__key", i1 false, i1 false}
!778 = !{ptr @.str.627, !779, !"<string literal>", i1 false, i1 false}
!779 = !{!"../lib/locking-selftest.c", i32 113, i32 8}
!780 = !{ptr @lock_Z1, !779, !"lock_Z1", i1 false, i1 false}
!781 = !{ptr @.str.628, !782, !"<string literal>", i1 false, i1 false}
!782 = !{!"../lib/locking-selftest.c", i32 120, i32 8}
!783 = !{ptr @rwlock_Z1, !782, !"rwlock_Z1", i1 false, i1 false}
!784 = !{ptr @.str.629, !785, !"<string literal>", i1 false, i1 false}
!785 = !{!"../lib/locking-selftest.c", i32 127, i32 8}
!786 = !{ptr @.str.630, !785, !"<string literal>", i1 false, i1 false}
!787 = !{ptr @mutex_Z1, !785, !"mutex_Z1", i1 false, i1 false}
!788 = !{ptr @.str.631, !789, !"<string literal>", i1 false, i1 false}
!789 = !{!"../lib/locking-selftest.c", i32 134, i32 8}
!790 = !{ptr @.str.632, !789, !"<string literal>", i1 false, i1 false}
!791 = !{ptr @rwsem_Z1, !789, !"rwsem_Z1", i1 false, i1 false}
!792 = !{ptr @.str.633, !793, !"<string literal>", i1 false, i1 false}
!793 = !{!"../lib/locking-selftest.c", i32 114, i32 8}
!794 = !{ptr @lock_Z2, !793, !"lock_Z2", i1 false, i1 false}
!795 = !{ptr @.str.634, !796, !"<string literal>", i1 false, i1 false}
!796 = !{!"../lib/locking-selftest.c", i32 121, i32 8}
!797 = !{ptr @rwlock_Z2, !796, !"rwlock_Z2", i1 false, i1 false}
!798 = !{ptr @.str.635, !799, !"<string literal>", i1 false, i1 false}
!799 = !{!"../lib/locking-selftest.c", i32 128, i32 8}
!800 = !{ptr @.str.636, !799, !"<string literal>", i1 false, i1 false}
!801 = !{ptr @mutex_Z2, !799, !"mutex_Z2", i1 false, i1 false}
!802 = !{ptr @.str.637, !803, !"<string literal>", i1 false, i1 false}
!803 = !{!"../lib/locking-selftest.c", i32 135, i32 8}
!804 = !{ptr @.str.638, !803, !"<string literal>", i1 false, i1 false}
!805 = !{ptr @rwsem_Z2, !803, !"rwsem_Z2", i1 false, i1 false}
!806 = !{ptr @.str.639, !807, !"<string literal>", i1 false, i1 false}
!807 = !{!"../lib/locking-selftest.c", i32 1502, i32 2}
!808 = !{ptr @.str.640, !807, !"<string literal>", i1 false, i1 false}
!809 = !{ptr @print_testname._entry, !807, !"_entry", i1 false, i1 false}
!810 = !{ptr @print_testname._entry_ptr, !807, !"_entry_ptr", i1 false, i1 false}
!811 = !{ptr @.str.641, !812, !"<string literal>", i1 false, i1 false}
!812 = !{!"../lib/locking-selftest.c", i32 1457, i32 3}
!813 = !{ptr @.str.642, !812, !"<string literal>", i1 false, i1 false}
!814 = !{ptr @dotest._entry, !812, !"_entry", i1 false, i1 false}
!815 = !{ptr @dotest._entry_ptr, !812, !"_entry_ptr", i1 false, i1 false}
!816 = !{ptr @.str.644, !817, !"<string literal>", i1 false, i1 false}
!817 = !{!"../lib/locking-selftest.c", i32 1460, i32 3}
!818 = !{ptr @dotest._entry.643, !817, !"_entry", i1 false, i1 false}
!819 = !{ptr @dotest._entry_ptr.645, !817, !"_entry_ptr", i1 false, i1 false}
!820 = !{ptr @.str.647, !821, !"<string literal>", i1 false, i1 false}
!821 = !{!"../lib/locking-selftest.c", i32 1465, i32 3}
!822 = !{ptr @dotest._entry.646, !821, !"_entry", i1 false, i1 false}
!823 = !{ptr @dotest._entry_ptr.648, !821, !"_entry_ptr", i1 false, i1 false}
!824 = !{ptr @reset_locks.__key, !825, !"__key", i1 false, i1 false}
!825 = !{!"../lib/locking-selftest.c", i32 1410, i32 2}
!826 = !{ptr @.str.649, !825, !"<string literal>", i1 false, i1 false}
!827 = !{ptr @reset_locks.__key.650, !825, !"__key", i1 false, i1 false}
!828 = !{ptr @.str.651, !825, !"<string literal>", i1 false, i1 false}
!829 = !{ptr @reset_locks.__key.652, !825, !"__key", i1 false, i1 false}
!830 = !{ptr @.str.653, !825, !"<string literal>", i1 false, i1 false}
!831 = !{ptr @reset_locks.__key.654, !825, !"__key", i1 false, i1 false}
!832 = !{ptr @.str.655, !825, !"<string literal>", i1 false, i1 false}
!833 = !{ptr @reset_locks.__key.656, !825, !"__key", i1 false, i1 false}
!834 = !{ptr @__func__.reset_locks, !825, !"<string literal>", i1 false, i1 false}
!835 = !{ptr @reset_locks.__key.657, !836, !"__key", i1 false, i1 false}
!836 = !{!"../lib/locking-selftest.c", i32 1410, i32 9}
!837 = !{ptr @.str.658, !836, !"<string literal>", i1 false, i1 false}
!838 = !{ptr @reset_locks.__key.659, !836, !"__key", i1 false, i1 false}
!839 = !{ptr @.str.660, !836, !"<string literal>", i1 false, i1 false}
!840 = !{ptr @reset_locks.__key.661, !836, !"__key", i1 false, i1 false}
!841 = !{ptr @.str.662, !836, !"<string literal>", i1 false, i1 false}
!842 = !{ptr @reset_locks.__key.663, !836, !"__key", i1 false, i1 false}
!843 = !{ptr @.str.664, !836, !"<string literal>", i1 false, i1 false}
!844 = !{ptr @reset_locks.__key.665, !836, !"__key", i1 false, i1 false}
!845 = !{ptr @reset_locks.__key.666, !846, !"__key", i1 false, i1 false}
!846 = !{!"../lib/locking-selftest.c", i32 1410, i32 16}
!847 = !{ptr @.str.667, !846, !"<string literal>", i1 false, i1 false}
!848 = !{ptr @reset_locks.__key.668, !846, !"__key", i1 false, i1 false}
!849 = !{ptr @.str.669, !846, !"<string literal>", i1 false, i1 false}
!850 = !{ptr @reset_locks.__key.670, !846, !"__key", i1 false, i1 false}
!851 = !{ptr @.str.671, !846, !"<string literal>", i1 false, i1 false}
!852 = !{ptr @reset_locks.__key.672, !846, !"__key", i1 false, i1 false}
!853 = !{ptr @.str.673, !846, !"<string literal>", i1 false, i1 false}
!854 = !{ptr @reset_locks.__key.674, !846, !"__key", i1 false, i1 false}
!855 = !{ptr @reset_locks.__key.675, !856, !"__key", i1 false, i1 false}
!856 = !{!"../lib/locking-selftest.c", i32 1410, i32 23}
!857 = !{ptr @.str.676, !856, !"<string literal>", i1 false, i1 false}
!858 = !{ptr @reset_locks.__key.677, !856, !"__key", i1 false, i1 false}
!859 = !{ptr @.str.678, !856, !"<string literal>", i1 false, i1 false}
!860 = !{ptr @reset_locks.__key.679, !856, !"__key", i1 false, i1 false}
!861 = !{ptr @.str.680, !856, !"<string literal>", i1 false, i1 false}
!862 = !{ptr @reset_locks.__key.681, !856, !"__key", i1 false, i1 false}
!863 = !{ptr @.str.682, !856, !"<string literal>", i1 false, i1 false}
!864 = !{ptr @reset_locks.__key.683, !856, !"__key", i1 false, i1 false}
!865 = !{ptr @reset_locks.__key.684, !866, !"__key", i1 false, i1 false}
!866 = !{!"../lib/locking-selftest.c", i32 1412, i32 2}
!867 = !{ptr @.str.685, !866, !"<string literal>", i1 false, i1 false}
!868 = !{ptr @reset_locks.__key.686, !869, !"__key", i1 false, i1 false}
!869 = !{!"../lib/locking-selftest.c", i32 1413, i32 2}
!870 = !{ptr @.str.687, !869, !"<string literal>", i1 false, i1 false}
!871 = !{ptr @reset_locks.__key.688, !872, !"__key", i1 false, i1 false}
!872 = !{!"../lib/locking-selftest.c", i32 1414, i32 2}
!873 = !{ptr @.str.689, !872, !"<string literal>", i1 false, i1 false}
!874 = !{ptr @.str.690, !875, !"<string literal>", i1 false, i1 false}
!875 = !{!"../lib/locking-selftest.c", i32 41, i32 8}
!876 = !{ptr @.str.691, !875, !"<string literal>", i1 false, i1 false}
!877 = !{ptr @ww_lockdep, !875, !"ww_lockdep", i1 false, i1 false}
!878 = !{ptr @.str.692, !879, !"<string literal>", i1 false, i1 false}
!879 = !{!"../lib/locking-selftest.c", i32 71, i32 8}
!880 = !{ptr @lock_A, !879, !"lock_A", i1 false, i1 false}
!881 = !{ptr @.str.693, !882, !"<string literal>", i1 false, i1 false}
!882 = !{!"../lib/locking-selftest.c", i32 79, i32 8}
!883 = !{ptr @rwlock_A, !882, !"rwlock_A", i1 false, i1 false}
!884 = !{ptr @.str.694, !885, !"<string literal>", i1 false, i1 false}
!885 = !{!"../lib/locking-selftest.c", i32 84, i32 8}
!886 = !{ptr @.str.695, !885, !"<string literal>", i1 false, i1 false}
!887 = !{ptr @mutex_A, !885, !"mutex_A", i1 false, i1 false}
!888 = !{ptr @.str.696, !889, !"<string literal>", i1 false, i1 false}
!889 = !{!"../lib/locking-selftest.c", i32 89, i32 8}
!890 = !{ptr @.str.697, !889, !"<string literal>", i1 false, i1 false}
!891 = !{ptr @rwsem_A, !889, !"rwsem_A", i1 false, i1 false}
!892 = !{ptr @.str.698, !893, !"<string literal>", i1 false, i1 false}
!893 = !{!"../lib/locking-selftest.c", i32 96, i32 8}
!894 = !{ptr @.str.699, !893, !"<string literal>", i1 false, i1 false}
!895 = !{ptr @rtmutex_A, !893, !"rtmutex_A", i1 false, i1 false}
!896 = !{ptr @.str.700, !897, !"<string literal>", i1 false, i1 false}
!897 = !{!"../lib/locking-selftest.c", i32 72, i32 8}
!898 = !{ptr @lock_B, !897, !"lock_B", i1 false, i1 false}
!899 = !{ptr @.str.701, !900, !"<string literal>", i1 false, i1 false}
!900 = !{!"../lib/locking-selftest.c", i32 80, i32 8}
!901 = !{ptr @rwlock_B, !900, !"rwlock_B", i1 false, i1 false}
!902 = !{ptr @.str.702, !903, !"<string literal>", i1 false, i1 false}
!903 = !{!"../lib/locking-selftest.c", i32 85, i32 8}
!904 = !{ptr @.str.703, !903, !"<string literal>", i1 false, i1 false}
!905 = !{ptr @mutex_B, !903, !"mutex_B", i1 false, i1 false}
!906 = !{ptr @.str.704, !907, !"<string literal>", i1 false, i1 false}
!907 = !{!"../lib/locking-selftest.c", i32 90, i32 8}
!908 = !{ptr @.str.705, !907, !"<string literal>", i1 false, i1 false}
!909 = !{ptr @rwsem_B, !907, !"rwsem_B", i1 false, i1 false}
!910 = !{ptr @.str.706, !911, !"<string literal>", i1 false, i1 false}
!911 = !{!"../lib/locking-selftest.c", i32 97, i32 8}
!912 = !{ptr @.str.707, !911, !"<string literal>", i1 false, i1 false}
!913 = !{ptr @rtmutex_B, !911, !"rtmutex_B", i1 false, i1 false}
!914 = !{ptr @.str.708, !915, !"<string literal>", i1 false, i1 false}
!915 = !{!"../lib/locking-selftest.c", i32 73, i32 8}
!916 = !{ptr @lock_C, !915, !"lock_C", i1 false, i1 false}
!917 = !{ptr @.str.709, !918, !"<string literal>", i1 false, i1 false}
!918 = !{!"../lib/locking-selftest.c", i32 81, i32 8}
!919 = !{ptr @rwlock_C, !918, !"rwlock_C", i1 false, i1 false}
!920 = !{ptr @.str.710, !921, !"<string literal>", i1 false, i1 false}
!921 = !{!"../lib/locking-selftest.c", i32 86, i32 8}
!922 = !{ptr @.str.711, !921, !"<string literal>", i1 false, i1 false}
!923 = !{ptr @mutex_C, !921, !"mutex_C", i1 false, i1 false}
!924 = !{ptr @.str.712, !925, !"<string literal>", i1 false, i1 false}
!925 = !{!"../lib/locking-selftest.c", i32 91, i32 8}
!926 = !{ptr @.str.713, !925, !"<string literal>", i1 false, i1 false}
!927 = !{ptr @rwsem_C, !925, !"rwsem_C", i1 false, i1 false}
!928 = !{ptr @.str.714, !929, !"<string literal>", i1 false, i1 false}
!929 = !{!"../lib/locking-selftest.c", i32 98, i32 8}
!930 = !{ptr @.str.715, !929, !"<string literal>", i1 false, i1 false}
!931 = !{ptr @rtmutex_C, !929, !"rtmutex_C", i1 false, i1 false}
!932 = !{ptr @.str.716, !933, !"<string literal>", i1 false, i1 false}
!933 = !{!"../lib/locking-selftest.c", i32 74, i32 8}
!934 = !{ptr @lock_D, !933, !"lock_D", i1 false, i1 false}
!935 = !{ptr @.str.717, !936, !"<string literal>", i1 false, i1 false}
!936 = !{!"../lib/locking-selftest.c", i32 82, i32 8}
!937 = !{ptr @rwlock_D, !936, !"rwlock_D", i1 false, i1 false}
!938 = !{ptr @.str.718, !939, !"<string literal>", i1 false, i1 false}
!939 = !{!"../lib/locking-selftest.c", i32 87, i32 8}
!940 = !{ptr @.str.719, !939, !"<string literal>", i1 false, i1 false}
!941 = !{ptr @mutex_D, !939, !"mutex_D", i1 false, i1 false}
!942 = !{ptr @.str.720, !943, !"<string literal>", i1 false, i1 false}
!943 = !{!"../lib/locking-selftest.c", i32 92, i32 8}
!944 = !{ptr @.str.721, !943, !"<string literal>", i1 false, i1 false}
!945 = !{ptr @rwsem_D, !943, !"rwsem_D", i1 false, i1 false}
!946 = !{ptr @.str.722, !947, !"<string literal>", i1 false, i1 false}
!947 = !{!"../lib/locking-selftest.c", i32 99, i32 8}
!948 = !{ptr @.str.723, !947, !"<string literal>", i1 false, i1 false}
!949 = !{ptr @rtmutex_D, !947, !"rtmutex_D", i1 false, i1 false}
!950 = !{ptr @t, !951, !"t", i1 false, i1 false}
!951 = !{!"../lib/locking-selftest.c", i32 64, i32 30}
!952 = !{ptr @t2, !953, !"t2", i1 false, i1 false}
!953 = !{!"../lib/locking-selftest.c", i32 64, i32 33}
!954 = !{ptr @o, !955, !"o", i1 false, i1 false}
!955 = !{!"../lib/locking-selftest.c", i32 65, i32 24}
!956 = !{ptr @o2, !957, !"o2", i1 false, i1 false}
!957 = !{!"../lib/locking-selftest.c", i32 65, i32 27}
!958 = !{ptr @o3, !959, !"o3", i1 false, i1 false}
!959 = !{!"../lib/locking-selftest.c", i32 65, i32 31}
!960 = !{ptr @.str.724, !961, !"<string literal>", i1 false, i1 false}
!961 = !{!"../lib/locking-selftest.c", i32 76, i32 8}
!962 = !{ptr @raw_lock_A, !961, !"raw_lock_A", i1 false, i1 false}
!963 = !{ptr @.str.725, !964, !"<string literal>", i1 false, i1 false}
!964 = !{!"../lib/locking-selftest.c", i32 77, i32 8}
!965 = !{ptr @raw_lock_B, !964, !"raw_lock_B", i1 false, i1 false}
!966 = !{ptr @init_held_spin.__key, !967, !"__key", i1 false, i1 false}
!967 = !{!"../lib/locking-selftest.c", i32 771, i32 1}
!968 = !{ptr @init_held_wlock.__key, !969, !"__key", i1 false, i1 false}
!969 = !{!"../lib/locking-selftest.c", i32 773, i32 1}
!970 = !{ptr @init_held_rlock.__key, !971, !"__key", i1 false, i1 false}
!971 = !{!"../lib/locking-selftest.c", i32 775, i32 1}
!972 = !{ptr @init_held_mutex.__key, !973, !"__key", i1 false, i1 false}
!973 = !{!"../lib/locking-selftest.c", i32 777, i32 1}
!974 = !{ptr @init_held_wsem.__key, !975, !"__key", i1 false, i1 false}
!975 = !{!"../lib/locking-selftest.c", i32 779, i32 1}
!976 = !{ptr @init_held_rsem.__key, !977, !"__key", i1 false, i1 false}
!977 = !{!"../lib/locking-selftest.c", i32 781, i32 1}
!978 = !{ptr @init_held_rtmutex.__key, !979, !"__key", i1 false, i1 false}
!979 = !{!"../lib/locking-selftest.c", i32 785, i32 1}
!980 = !{ptr @__func__.init_held_rtmutex, !979, !"<string literal>", i1 false, i1 false}
!981 = distinct !{null, !982, !"<string literal>", i1 false, i1 false}
!982 = !{!"../lib/locking-selftest.c", i32 809, i32 1}
!983 = distinct !{null, !982, !"<string literal>", i1 false, i1 false}
!984 = !{ptr @.str.728, !985, !"<string literal>", i1 false, i1 false}
!985 = !{!"../lib/locking-selftest.c", i32 2285, i32 2}
!986 = !{ptr @ww_tests._entry, !985, !"_entry", i1 false, i1 false}
!987 = !{ptr @ww_tests._entry_ptr, !985, !"_entry_ptr", i1 false, i1 false}
!988 = !{ptr @.str.730, !989, !"<string literal>", i1 false, i1 false}
!989 = !{!"../lib/locking-selftest.c", i32 2286, i32 2}
!990 = !{ptr @ww_tests._entry.729, !989, !"_entry", i1 false, i1 false}
!991 = !{ptr @ww_tests._entry_ptr.731, !989, !"_entry_ptr", i1 false, i1 false}
!992 = !{ptr @.str.733, !993, !"<string literal>", i1 false, i1 false}
!993 = !{!"../lib/locking-selftest.c", i32 2287, i32 2}
!994 = !{ptr @ww_tests._entry.732, !993, !"_entry", i1 false, i1 false}
!995 = !{ptr @ww_tests._entry_ptr.734, !993, !"_entry_ptr", i1 false, i1 false}
!996 = !{ptr @.str.735, !997, !"<string literal>", i1 false, i1 false}
!997 = !{!"../lib/locking-selftest.c", i32 2289, i32 17}
!998 = !{ptr @ww_tests._entry.736, !999, !"_entry", i1 false, i1 false}
!999 = !{!"../lib/locking-selftest.c", i32 2293, i32 2}
!1000 = !{ptr @ww_tests._entry_ptr.737, !999, !"_entry_ptr", i1 false, i1 false}
!1001 = !{ptr @.str.738, !1002, !"<string literal>", i1 false, i1 false}
!1002 = !{!"../lib/locking-selftest.c", i32 2295, i32 17}
!1003 = !{ptr @ww_tests._entry.739, !1004, !"_entry", i1 false, i1 false}
!1004 = !{!"../lib/locking-selftest.c", i32 2298, i32 2}
!1005 = !{ptr @ww_tests._entry_ptr.740, !1004, !"_entry_ptr", i1 false, i1 false}
!1006 = !{ptr @.str.741, !1007, !"<string literal>", i1 false, i1 false}
!1007 = !{!"../lib/locking-selftest.c", i32 2300, i32 17}
!1008 = !{ptr @ww_tests._entry.742, !1009, !"_entry", i1 false, i1 false}
!1009 = !{!"../lib/locking-selftest.c", i32 2305, i32 2}
!1010 = !{ptr @ww_tests._entry_ptr.743, !1009, !"_entry_ptr", i1 false, i1 false}
!1011 = !{ptr @.str.744, !1012, !"<string literal>", i1 false, i1 false}
!1012 = !{!"../lib/locking-selftest.c", i32 2307, i32 17}
!1013 = !{ptr @ww_tests._entry.745, !1014, !"_entry", i1 false, i1 false}
!1014 = !{!"../lib/locking-selftest.c", i32 2311, i32 2}
!1015 = !{ptr @ww_tests._entry_ptr.746, !1014, !"_entry_ptr", i1 false, i1 false}
!1016 = !{ptr @.str.747, !1017, !"<string literal>", i1 false, i1 false}
!1017 = !{!"../lib/locking-selftest.c", i32 2313, i32 17}
!1018 = !{ptr @ww_tests._entry.748, !1019, !"_entry", i1 false, i1 false}
!1019 = !{!"../lib/locking-selftest.c", i32 2324, i32 2}
!1020 = !{ptr @ww_tests._entry_ptr.749, !1019, !"_entry_ptr", i1 false, i1 false}
!1021 = !{ptr @.str.750, !1022, !"<string literal>", i1 false, i1 false}
!1022 = !{!"../lib/locking-selftest.c", i32 2326, i32 17}
!1023 = !{ptr @ww_tests._entry.751, !1024, !"_entry", i1 false, i1 false}
!1024 = !{!"../lib/locking-selftest.c", i32 2328, i32 2}
!1025 = !{ptr @ww_tests._entry_ptr.752, !1024, !"_entry_ptr", i1 false, i1 false}
!1026 = !{ptr @.str.753, !1027, !"<string literal>", i1 false, i1 false}
!1027 = !{!"../lib/locking-selftest.c", i32 2330, i32 17}
!1028 = !{ptr @ww_tests._entry.754, !1029, !"_entry", i1 false, i1 false}
!1029 = !{!"../lib/locking-selftest.c", i32 2332, i32 2}
!1030 = !{ptr @ww_tests._entry_ptr.755, !1029, !"_entry_ptr", i1 false, i1 false}
!1031 = !{ptr @.str.757, !1032, !"<string literal>", i1 false, i1 false}
!1032 = !{!"../lib/locking-selftest.c", i32 2334, i32 2}
!1033 = !{ptr @ww_tests._entry.756, !1032, !"_entry", i1 false, i1 false}
!1034 = !{ptr @ww_tests._entry_ptr.758, !1032, !"_entry_ptr", i1 false, i1 false}
!1035 = !{ptr @.str.760, !1036, !"<string literal>", i1 false, i1 false}
!1036 = !{!"../lib/locking-selftest.c", i32 2335, i32 2}
!1037 = !{ptr @ww_tests._entry.759, !1036, !"_entry", i1 false, i1 false}
!1038 = !{ptr @ww_tests._entry_ptr.761, !1036, !"_entry_ptr", i1 false, i1 false}
!1039 = !{ptr @ww_tests._entry.762, !1040, !"_entry", i1 false, i1 false}
!1040 = !{!"../lib/locking-selftest.c", i32 2336, i32 2}
!1041 = !{ptr @ww_tests._entry_ptr.763, !1040, !"_entry_ptr", i1 false, i1 false}
!1042 = !{ptr @.str.764, !1043, !"<string literal>", i1 false, i1 false}
!1043 = !{!"../lib/locking-selftest.c", i32 2338, i32 17}
!1044 = !{ptr @ww_tests._entry.765, !1045, !"_entry", i1 false, i1 false}
!1045 = !{!"../lib/locking-selftest.c", i32 2342, i32 2}
!1046 = !{ptr @ww_tests._entry_ptr.766, !1045, !"_entry_ptr", i1 false, i1 false}
!1047 = !{ptr @.str.767, !1048, !"<string literal>", i1 false, i1 false}
!1048 = !{!"../lib/locking-selftest.c", i32 2344, i32 17}
!1049 = !{ptr @ww_tests._entry.768, !1050, !"_entry", i1 false, i1 false}
!1050 = !{!"../lib/locking-selftest.c", i32 2348, i32 2}
!1051 = !{ptr @ww_tests._entry_ptr.769, !1050, !"_entry_ptr", i1 false, i1 false}
!1052 = !{ptr @.str.770, !1053, !"<string literal>", i1 false, i1 false}
!1053 = !{!"../lib/locking-selftest.c", i32 2350, i32 17}
!1054 = !{ptr @ww_tests._entry.771, !1055, !"_entry", i1 false, i1 false}
!1055 = !{!"../lib/locking-selftest.c", i32 2354, i32 2}
!1056 = !{ptr @ww_tests._entry_ptr.772, !1055, !"_entry_ptr", i1 false, i1 false}
!1057 = !{ptr @.str.773, !1058, !"<string literal>", i1 false, i1 false}
!1058 = !{!"../lib/locking-selftest.c", i32 2356, i32 17}
!1059 = !{ptr @ww_tests._entry.774, !1060, !"_entry", i1 false, i1 false}
!1060 = !{!"../lib/locking-selftest.c", i32 2360, i32 2}
!1061 = !{ptr @ww_tests._entry_ptr.775, !1060, !"_entry_ptr", i1 false, i1 false}
!1062 = !{ptr @.str.776, !1063, !"<string literal>", i1 false, i1 false}
!1063 = !{!"../lib/locking-selftest.c", i32 1699, i32 3}
!1064 = !{ptr @.str.777, !1063, !"<string literal>", i1 false, i1 false}
!1065 = !{ptr @.str.778, !1066, !"<string literal>", i1 false, i1 false}
!1066 = !{!"../include/linux/ww_mutex.h", i32 297, i32 2}
!1067 = !{ptr @.str.779, !1066, !"<string literal>", i1 false, i1 false}
!1068 = !{ptr @.str.780, !1069, !"<string literal>", i1 false, i1 false}
!1069 = !{!"../include/linux/ww_mutex.h", i32 173, i32 2}
!1070 = !{ptr @.str.781, !1071, !"<string literal>", i1 false, i1 false}
!1071 = !{!"../include/linux/ww_mutex.h", i32 191, i32 2}
!1072 = !{ptr @.str.782, !1073, !"<string literal>", i1 false, i1 false}
!1073 = !{!"../lib/locking-selftest.c", i32 2492, i32 2}
!1074 = !{ptr @.str.783, !1073, !"<string literal>", i1 false, i1 false}
!1075 = !{ptr @fs_reclaim_tests._entry, !1073, !"_entry", i1 false, i1 false}
!1076 = !{ptr @fs_reclaim_tests._entry_ptr, !1073, !"_entry_ptr", i1 false, i1 false}
!1077 = !{ptr @.str.785, !1078, !"<string literal>", i1 false, i1 false}
!1078 = !{!"../lib/locking-selftest.c", i32 2493, i32 2}
!1079 = !{ptr @fs_reclaim_tests._entry.784, !1078, !"_entry", i1 false, i1 false}
!1080 = !{ptr @fs_reclaim_tests._entry_ptr.786, !1078, !"_entry_ptr", i1 false, i1 false}
!1081 = !{ptr @fs_reclaim_tests._entry.787, !1082, !"_entry", i1 false, i1 false}
!1082 = !{!"../lib/locking-selftest.c", i32 2494, i32 2}
!1083 = !{ptr @fs_reclaim_tests._entry_ptr.788, !1082, !"_entry_ptr", i1 false, i1 false}
!1084 = !{ptr @.str.789, !1085, !"<string literal>", i1 false, i1 false}
!1085 = !{!"../lib/locking-selftest.c", i32 2496, i32 17}
!1086 = !{ptr @fs_reclaim_tests._entry.790, !1087, !"_entry", i1 false, i1 false}
!1087 = !{!"../lib/locking-selftest.c", i32 2498, i32 2}
!1088 = !{ptr @fs_reclaim_tests._entry_ptr.791, !1087, !"_entry_ptr", i1 false, i1 false}
!1089 = !{ptr @.str.792, !1090, !"<string literal>", i1 false, i1 false}
!1090 = !{!"../lib/locking-selftest.c", i32 2500, i32 17}
!1091 = !{ptr @fs_reclaim_tests._entry.793, !1092, !"_entry", i1 false, i1 false}
!1092 = !{!"../lib/locking-selftest.c", i32 2502, i32 2}
!1093 = !{ptr @fs_reclaim_tests._entry_ptr.794, !1092, !"_entry_ptr", i1 false, i1 false}
!1094 = !{ptr @.str.795, !1095, !"<string literal>", i1 false, i1 false}
!1095 = !{!"../lib/locking-selftest.c", i32 2504, i32 17}
!1096 = !{ptr @fs_reclaim_tests._entry.796, !1097, !"_entry", i1 false, i1 false}
!1097 = !{!"../lib/locking-selftest.c", i32 2506, i32 2}
!1098 = !{ptr @fs_reclaim_tests._entry_ptr.797, !1097, !"_entry_ptr", i1 false, i1 false}
!1099 = !{ptr @.str.798, !1100, !"<string literal>", i1 false, i1 false}
!1100 = !{!"../include/linux/sched/mm.h", i32 256, i32 2}
!1101 = !{ptr @.str.799, !1102, !"<string literal>", i1 false, i1 false}
!1102 = !{!"../lib/locking-selftest.c", i32 2670, i32 2}
!1103 = !{ptr @wait_context_tests._entry, !1102, !"_entry", i1 false, i1 false}
!1104 = !{ptr @wait_context_tests._entry_ptr, !1102, !"_entry_ptr", i1 false, i1 false}
!1105 = !{ptr @.str.801, !1106, !"<string literal>", i1 false, i1 false}
!1106 = !{!"../lib/locking-selftest.c", i32 2671, i32 2}
!1107 = !{ptr @wait_context_tests._entry.800, !1106, !"_entry", i1 false, i1 false}
!1108 = !{ptr @wait_context_tests._entry_ptr.802, !1106, !"_entry_ptr", i1 false, i1 false}
!1109 = !{ptr @wait_context_tests._entry.803, !1110, !"_entry", i1 false, i1 false}
!1110 = !{!"../lib/locking-selftest.c", i32 2672, i32 2}
!1111 = !{ptr @wait_context_tests._entry_ptr.804, !1110, !"_entry_ptr", i1 false, i1 false}
!1112 = !{ptr @.str.806, !1113, !"<string literal>", i1 false, i1 false}
!1113 = !{!"../lib/locking-selftest.c", i32 2673, i32 2}
!1114 = !{ptr @wait_context_tests._entry.805, !1113, !"_entry", i1 false, i1 false}
!1115 = !{ptr @wait_context_tests._entry_ptr.807, !1113, !"_entry_ptr", i1 false, i1 false}
!1116 = !{ptr @wait_context_tests._entry.808, !1117, !"_entry", i1 false, i1 false}
!1117 = !{!"../lib/locking-selftest.c", i32 2674, i32 2}
!1118 = !{ptr @wait_context_tests._entry_ptr.809, !1117, !"_entry_ptr", i1 false, i1 false}
!1119 = !{ptr @.str.810, !1120, !"<string literal>", i1 false, i1 false}
!1120 = !{!"../lib/locking-selftest.c", i32 2675, i32 17}
!1121 = !{ptr @wait_context_tests._entry.811, !1122, !"_entry", i1 false, i1 false}
!1122 = !{!"../lib/locking-selftest.c", i32 2677, i32 2}
!1123 = !{ptr @wait_context_tests._entry_ptr.812, !1122, !"_entry_ptr", i1 false, i1 false}
!1124 = !{ptr @.str.813, !1125, !"<string literal>", i1 false, i1 false}
!1125 = !{!"../lib/locking-selftest.c", i32 2679, i32 17}
!1126 = !{ptr @wait_context_tests._entry.814, !1127, !"_entry", i1 false, i1 false}
!1127 = !{!"../lib/locking-selftest.c", i32 2681, i32 2}
!1128 = !{ptr @wait_context_tests._entry_ptr.815, !1127, !"_entry_ptr", i1 false, i1 false}
!1129 = !{ptr @.str.816, !1130, !"<string literal>", i1 false, i1 false}
!1130 = !{!"../lib/locking-selftest.c", i32 2683, i32 17}
!1131 = !{ptr @wait_context_tests._entry.817, !1132, !"_entry", i1 false, i1 false}
!1132 = !{!"../lib/locking-selftest.c", i32 2685, i32 2}
!1133 = !{ptr @wait_context_tests._entry_ptr.818, !1132, !"_entry_ptr", i1 false, i1 false}
!1134 = !{ptr @.str.819, !1135, !"<string literal>", i1 false, i1 false}
!1135 = !{!"../lib/locking-selftest.c", i32 2687, i32 17}
!1136 = !{ptr @wait_context_tests._entry.820, !1137, !"_entry", i1 false, i1 false}
!1137 = !{!"../lib/locking-selftest.c", i32 2689, i32 2}
!1138 = !{ptr @wait_context_tests._entry_ptr.821, !1137, !"_entry_ptr", i1 false, i1 false}
!1139 = !{ptr @.str.822, !1140, !"<string literal>", i1 false, i1 false}
!1140 = !{!"../lib/locking-selftest.c", i32 2691, i32 17}
!1141 = !{ptr @wait_context_tests._entry.823, !1142, !"_entry", i1 false, i1 false}
!1142 = !{!"../lib/locking-selftest.c", i32 2693, i32 2}
!1143 = !{ptr @wait_context_tests._entry_ptr.824, !1142, !"_entry_ptr", i1 false, i1 false}
!1144 = !{ptr @.str.825, !1145, !"<string literal>", i1 false, i1 false}
!1145 = !{!"../lib/locking-selftest.c", i32 2695, i32 17}
!1146 = !{ptr @wait_context_tests._entry.826, !1147, !"_entry", i1 false, i1 false}
!1147 = !{!"../lib/locking-selftest.c", i32 2697, i32 2}
!1148 = !{ptr @wait_context_tests._entry_ptr.827, !1147, !"_entry_ptr", i1 false, i1 false}
!1149 = !{ptr @.str.828, !1150, !"<string literal>", i1 false, i1 false}
!1150 = !{!"../lib/locking-selftest.c", i32 2699, i32 17}
!1151 = !{ptr @wait_context_tests._entry.829, !1152, !"_entry", i1 false, i1 false}
!1152 = !{!"../lib/locking-selftest.c", i32 2701, i32 2}
!1153 = !{ptr @wait_context_tests._entry_ptr.830, !1152, !"_entry_ptr", i1 false, i1 false}
!1154 = !{ptr @.str.831, !1155, !"<string literal>", i1 false, i1 false}
!1155 = !{!"../lib/locking-selftest.c", i32 2703, i32 17}
!1156 = !{ptr @wait_context_tests._entry.832, !1157, !"_entry", i1 false, i1 false}
!1157 = !{!"../lib/locking-selftest.c", i32 2705, i32 2}
!1158 = !{ptr @wait_context_tests._entry_ptr.833, !1157, !"_entry_ptr", i1 false, i1 false}
!1159 = !{ptr @.str.834, !1160, !"<string literal>", i1 false, i1 false}
!1160 = !{!"../lib/locking-selftest.c", i32 2707, i32 17}
!1161 = !{ptr @wait_context_tests._entry.835, !1162, !"_entry", i1 false, i1 false}
!1162 = !{!"../lib/locking-selftest.c", i32 2709, i32 2}
!1163 = !{ptr @wait_context_tests._entry_ptr.836, !1162, !"_entry_ptr", i1 false, i1 false}
!1164 = distinct !{null, !1165, !"__warned", i1 false, i1 false}
!1165 = !{!"../include/linux/rcupdate.h", i32 723, i32 2}
!1166 = !{ptr @.str.837, !1165, !"<string literal>", i1 false, i1 false}
!1167 = !{ptr @.str.838, !1165, !"<string literal>", i1 false, i1 false}
!1168 = distinct !{null, !1169, !"__warned", i1 false, i1 false}
!1169 = !{!"../include/linux/rcupdate.h", i32 695, i32 2}
!1170 = !{ptr @.str.839, !1169, !"<string literal>", i1 false, i1 false}
!1171 = distinct !{null, !1172, !"__warned", i1 false, i1 false}
!1172 = !{!"../include/linux/rcupdate.h", i32 760, i32 2}
!1173 = !{ptr @.str.840, !1172, !"<string literal>", i1 false, i1 false}
!1174 = distinct !{null, !1175, !"__warned", i1 false, i1 false}
!1175 = !{!"../include/linux/rcupdate.h", i32 749, i32 2}
!1176 = !{ptr @.str.841, !1175, !"<string literal>", i1 false, i1 false}
!1177 = distinct !{null, !1178, !"__warned", i1 false, i1 false}
!1178 = !{!"../include/linux/rcupdate.h", i32 805, i32 2}
!1179 = !{ptr @.str.842, !1178, !"<string literal>", i1 false, i1 false}
!1180 = distinct !{null, !1181, !"__warned", i1 false, i1 false}
!1181 = !{!"../include/linux/rcupdate.h", i32 787, i32 2}
!1182 = !{ptr @.str.843, !1181, !"<string literal>", i1 false, i1 false}
!1183 = !{ptr @.str.844, !1184, !"<string literal>", i1 false, i1 false}
!1184 = !{!"../lib/locking-selftest.c", i32 2780, i32 2}
!1185 = !{ptr @local_lock_tests._entry, !1184, !"_entry", i1 false, i1 false}
!1186 = !{ptr @local_lock_tests._entry_ptr, !1184, !"_entry_ptr", i1 false, i1 false}
!1187 = !{ptr @.str.846, !1188, !"<string literal>", i1 false, i1 false}
!1188 = !{!"../lib/locking-selftest.c", i32 2781, i32 2}
!1189 = !{ptr @local_lock_tests._entry.845, !1188, !"_entry", i1 false, i1 false}
!1190 = !{ptr @local_lock_tests._entry_ptr.847, !1188, !"_entry_ptr", i1 false, i1 false}
!1191 = !{ptr @local_lock_tests._entry.848, !1192, !"_entry", i1 false, i1 false}
!1192 = !{!"../lib/locking-selftest.c", i32 2782, i32 2}
!1193 = !{ptr @local_lock_tests._entry_ptr.849, !1192, !"_entry_ptr", i1 false, i1 false}
!1194 = !{ptr @.str.850, !1195, !"<string literal>", i1 false, i1 false}
!1195 = !{!"../lib/locking-selftest.c", i32 2784, i32 17}
!1196 = !{ptr @local_lock_tests._entry.851, !1197, !"_entry", i1 false, i1 false}
!1197 = !{!"../lib/locking-selftest.c", i32 2786, i32 2}
!1198 = !{ptr @local_lock_tests._entry_ptr.852, !1197, !"_entry_ptr", i1 false, i1 false}
!1199 = !{ptr @.str.853, !1200, !"<string literal>", i1 false, i1 false}
!1200 = !{!"../lib/locking-selftest.c", i32 2788, i32 17}
!1201 = !{ptr @local_lock_tests._entry.854, !1202, !"_entry", i1 false, i1 false}
!1202 = !{!"../lib/locking-selftest.c", i32 2790, i32 2}
!1203 = !{ptr @local_lock_tests._entry_ptr.855, !1202, !"_entry_ptr", i1 false, i1 false}
!1204 = !{ptr @.str.856, !1205, !"<string literal>", i1 false, i1 false}
!1205 = !{!"../lib/locking-selftest.c", i32 2792, i32 17}
!1206 = !{ptr @local_lock_tests._entry.857, !1207, !"_entry", i1 false, i1 false}
!1207 = !{!"../lib/locking-selftest.c", i32 2794, i32 2}
!1208 = !{ptr @local_lock_tests._entry_ptr.858, !1207, !"_entry_ptr", i1 false, i1 false}
!1209 = !{ptr @.str.859, !1210, !"<string literal>", i1 false, i1 false}
!1210 = !{!"../include/linux/local_lock_internal.h", i32 30, i32 2}
!1211 = !{ptr @.str.860, !1210, !"<string literal>", i1 false, i1 false}
!1212 = !{ptr @.str.861, !1213, !"<string literal>", i1 false, i1 false}
!1213 = !{!"../include/linux/local_lock_internal.h", i32 36, i32 2}
!1214 = !{!"sp"}
!1215 = !{i32 1, !"wchar_size", i32 2}
!1216 = !{i32 1, !"min_enum_size", i32 4}
!1217 = !{i32 8, !"branch-target-enforcement", i32 0}
!1218 = !{i32 8, !"sign-return-address", i32 0}
!1219 = !{i32 8, !"sign-return-address-all", i32 0}
!1220 = !{i32 8, !"sign-return-address-with-bkey", i32 0}
!1221 = !{i32 7, !"uwtable", i32 1}
!1222 = !{!"clang version 15.0.0 (git@github.com:linkeLi0421/llvm-project15-IRDumperPass.git 23ab625cb005cd08da083f9b643a7feed9af8abe)"}
!1223 = !{i64 957490}
!1224 = !{!"branch_weights", i32 2000, i32 1}
!1225 = !{i64 955193}
!1226 = !{i64 955003}
!1227 = !{!"branch_weights", i32 1, i32 2000}
!1228 = !{i64 2148550798, i64 2148550830, i64 2148550859, i64 2148550893, i64 2148550924, i64 2148550947}
!1229 = !{i64 2149446727}
!1230 = !{i64 2149446993}
!1231 = !{i64 2149454559}
!1232 = !{i64 2149455954}
!1233 = !{i64 2156244213}
!1234 = !{i64 2156246129}
!1235 = !{i64 2156260372}
!1236 = !{i64 2156262288}
!1237 = !{i64 2156262760}
!1238 = !{i64 2156264676}
!1239 = !{i64 2156278919}
!1240 = !{i64 2156280835}
!1241 = !{i64 2156281307}
!1242 = !{i64 2156283223}
!1243 = !{i64 2156297466}
!1244 = !{i64 2156299382}
